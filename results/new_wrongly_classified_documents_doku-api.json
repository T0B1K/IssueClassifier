[{"classified_as": "api", "text": "In extrinsics v3, the API adds the tip to to the transaction, however a chain that does not have the balances module doesn't expect the tip in the payload so it will barf on handling it with the following error:\r\n```\r\nERROR: Error: \"submitAndWatchExtrinsic (extrinsic: Extrinsic): ExtrinsicStatus:: 1002: Verification Error: Execution: Could not convert parameter `tx` between node and runtime! (Client(Exe)\"\r\n```\r\n\r\nYou would need to implement your own payload format for the chain in the PolkadotJS API that doesn't include the tip."}, {"classified_as": "api", "text": "These methods have minimal documentation that basically only describes the types of the parameters and the scenario in which the method would be useful, but no information on how the parameters are used to render the atlas.\r\n\r\nA description of how the lists of `Rect` and `RSTransform` objects are applied to render (parts of) the atlas to the destination would be helpful, as well as an example."}, {"classified_as": "api", "text": "\r\nHere are the instructions and at the bottom is exp-11's script. I have no idea what to do. VERY new to programming.. thank you ahead of time!\r\n\r\nUsing the Exp-11.py script provide as a baseline your assignment is as follows:\r\n\r\n1) Allow the user to enter a path\r\n\r\n2) Using that path, process all the .jpg files contained in that folder  (note you will need to create a directory with jpg images)\r\n\r\n3) Extract, EXIF data from each of the images and create a pretty table output.  Note, you will go beyond the basics and extract whatever camera or photo data exists for each photo.\r\n\r\n4) Plot the geolocation of each image on a map. \r\n\r\n(Note, there are several ways to do this)  However, the easiest method would be to use MapMaker App, at https://mapmakerapp.com/\r\nyou can either manually enter the lat/long values your code generates or you can place your results in a CSV file and upload the data to the map.   \r\nNOTE, this is a manual step process\r\n\r\n5) Submit both your script and a screenshot of the results.\r\n\r\n\r\n\r\n\r\n\r\n'''\r\nEXIF Data Acquistion\r\nJanuary 2019\r\nVersion 1.1\r\n'''\r\nfrom __future__ import print_function\r\n\r\n'''\r\nCopyright (c) 2019 Chet Hosmer, Python Forensics\r\n\r\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software\r\nand associated documentation files (the \"Software\"), to deal in the Software without restriction, \r\nincluding without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, \r\nand/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, \r\nsubject to the following conditions:\r\n\r\nThe above copyright notice and this permission notice shall be included in all copies or substantial \r\nportions of the Software.\r\n\r\n'''\r\n# Usage Example:\r\n# python Exp-11.py \r\n#\r\n# Requirement: Python 2.x or 3.x\r\n#\r\n# Requirement: 3rd Party Library that is utilized is: PILLOW\r\n#                   pip install PILLOW  from the command line\r\n\r\n\r\n''' LIBRARY IMPORT SECTION '''\r\n\r\nimport os                       # Python Standard Library : Operating System Methods\r\nimport sys                      # Python Standard Library : System Methods\r\nfrom datetime import datetime   # Python Standard Libary datetime method from Standard Library\r\n\r\n# import the Python Image Library \r\n# along with TAGS and GPS related TAGS\r\n# Note you must install the PILLOW Module\r\n# pip install PILLOW\r\n\r\nfrom PIL import Image\r\nfrom PIL.ExifTags import TAGS, GPSTAGS\r\n\r\n\r\n# import the prettytable library\r\nfrom prettytable import PrettyTable\r\n\r\ndef ExtractGPSDictionary(fileName):\r\n    ''' Function to Extract GPS Dictionary '''\r\n    try:\r\n        pilImage = Image.open(fileName)\r\n        exifData = pilImage._getexif()\r\n\r\n    except Exception:\r\n        # If exception occurs from PIL processing\r\n        # Report the \r\n        return None, None\r\n\r\n    # Interate through the exifData\r\n    # Searching for GPS Tags\r\n\r\n    imageTimeStamp = \"NA\"\r\n    cameraModel = \"NA\"\r\n    cameraMake = \"NA\"\r\n    gpsData = False\r\n\r\n    gpsDictionary = {}\r\n\r\n    if exifData:\r\n\r\n        for tag, theValue in exifData.items():\r\n\r\n            # obtain the tag\r\n            tagValue = TAGS.get(tag, tag)\r\n\r\n            # Collect basic image data if available\r\n\r\n            if tagValue == 'DateTimeOriginal':\r\n                imageTimeStamp = exifData.get(tag).strip()\r\n\r\n            if tagValue == \"Make\":\r\n                cameraMake = exifData.get(tag).strip()\r\n\r\n            if tagValue == 'Model':\r\n                cameraModel = exifData.get(tag).strip()\r\n\r\n            # check the tag for GPS\r\n            if tagValue == \"GPSInfo\":\r\n\r\n                gpsData = True;\r\n\r\n                # Found it !\r\n                # Now create a Dictionary to hold the GPS Data\r\n\r\n                # Loop through the GPS Information\r\n                for curTag in theValue:\r\n                    gpsTag = GPSTAGS.get(curTag, curTag)\r\n                    gpsDictionary[gpsTag] = theValue[curTag]\r\n\r\n        basicExifData = [imageTimeStamp, cameraMake, cameraModel]    \r\n\r\n        return gpsDictionary, basicExifData\r\n\r\n    else:\r\n        return None, None\r\n\r\n# End ExtractGPSDictionary ============================\r\n\r\n\r\ndef ExtractLatLon(gps):\r\n    ''' Function to Extract Lattitude and Longitude Values '''\r\n\r\n    # to perform the calcuation we need at least\r\n    # lat, lon, latRef and lonRef\r\n    \r\n    try:\r\n        latitude     = gps[\"GPSLatitude\"]\r\n        latitudeRef  = gps[\"GPSLatitudeRef\"]\r\n        longitude    = gps[\"GPSLongitude\"]\r\n        longitudeRef = gps[\"GPSLongitudeRef\"]\r\n\r\n        lat = ConvertToDegrees(latitude)\r\n        lon = ConvertToDegrees(longitude)\r\n\r\n        # Check Latitude Reference\r\n        # If South of the Equator then lat value is negative\r\n\r\n        if latitudeRef == \"S\":\r\n            lat = 0 - lat\r\n\r\n        # Check Longitude Reference\r\n        # If West of the Prime Meridian in \r\n        # Greenwich then the Longitude value is negative\r\n\r\n        if longitudeRef == \"W\":\r\n            lon = 0- lon\r\n\r\n        gpsCoor = {\"Lat\": lat, \"LatRef\":latitudeRef, \"Lon\": lon, \"LonRef\": longitudeRef}\r\n\r\n        return gpsCoor\r\n\r\n    except:\r\n        return None\r\n\r\n# End Extract Lat Lon ==============================================\r\n\r\n\r\ndef ConvertToDegrees(gpsCoordinate):\r\n    ''' Function to CONVERT GPS COORIDINATES TO DEGRESS '''\r\n    d0 = gpsCoordinate[0][0]\r\n    d1 = gpsCoordinate[0][1]\r\n    try:\r\n        degrees = float(d0) / float(d1)\r\n    except:\r\n        degrees = 0.0\r\n\r\n    m0 = gpsCoordinate[1][0]\r\n    m1 = gpsCoordinate[1][1]\r\n    try:\r\n        minutes = float(m0) / float(m1)\r\n    except:\r\n        minutes=0.0\r\n\r\n    s0 = gpsCoordinate[2][0]\r\n    s1 = gpsCoordinate[2][1]\r\n    try:\r\n        seconds = float(s0) / float(s1)\r\n    except:\r\n        seconds = 0.0\r\n\r\n    floatCoordinate = float (degrees + (minutes / 60.0) + (seconds / 3600.0))\r\n\r\n    return floatCoordinate\r\n\r\n''' MAIN PROGRAM ENTRY SECTION '''\r\n\r\nif __name__ == \"__main__\":\r\n    '''\r\n    pyExif Main Entry Point\r\n    '''\r\n    print(\"\\nExtract EXIF Data from JPEG Files\")\r\n\r\n    print(\"Script Started\", str(datetime.now()))\r\n    print()\r\n\r\n    ''' PROCESS EACH JPEG FILE SECTION '''\r\n\r\n    latLonList = []\r\n    targetFile = \"test.jpg\"                 # file must be located in the same folder\r\n    if os.path.isfile(targetFile):\r\n        gpsDictionary, exifList = ExtractGPSDictionary(targetFile)\r\n            \r\n        if exifList:\r\n            TS = exifList[0]\r\n            MAKE = exifList[1]\r\n            MODEL = exifList[2]\r\n        else:\r\n            TS = 'NA'\r\n            MAKE = 'NA'\r\n            MODEL = 'NA'\r\n\r\n        print(\"Photo Details\")\r\n        print(\"-------------\")\r\n        print(\"TimeStamp:    \", TS)\r\n        print(\"Camera Make:  \", MAKE)\r\n        print(\"Camera Model: \", MODEL)\r\n        \r\n        if (gpsDictionary != None):\r\n\r\n            # Obtain the Lat Lon values from the gpsDictionary\r\n            # Converted to degrees\r\n            # The return value is a dictionary key value pairs\r\n\r\n            dCoor = ExtractLatLon(gpsDictionary)\r\n\r\n            print(\"\\nGeo-Location Data\")\r\n            print(\"-----------------\")\r\n\r\n            if dCoor:\r\n                lat = dCoor.get(\"Lat\")\r\n                latRef = dCoor.get(\"LatRef\")\r\n                lon = dCoor.get(\"Lon\")\r\n                lonRef = dCoor.get(\"LonRef\")\r\n                \r\n                if ( lat and lon and latRef and lonRef):\r\n                    print(\"Lattitude: \", '{:4.4f}'.format(lat))\r\n                    print(\"Longitude: \", '{:4.4f}'.format(lon))\r\n                else:\r\n                    print(\"WARNING No GPS EXIF Data\")\r\n            else:\r\n                print(\"WARNING No GPS EXIF Data\")                    \r\n        else:\r\n            print(\"WARNING\", \" not a valid file\", targetFile)\r\n\r\n    # Create Result Table Display using PrettyTable\r\n    ''' GENERATE RESULTS TABLE SECTION'''\r\n\r\n    ''' Result Table Heading'''\r\n    resultTable = PrettyTable(['File-Name', 'Lat','Lon', 'TimeStamp', 'Make', 'Model'])\r\n    ''' Your work starts here '''\r\n    \r\n    print()"}, {"classified_as": "doku", "text": "`tshift` is broken for `Panel` because `Panel.shift` does not handle `freq`.\n"}, {"classified_as": "doku", "text": "Refs: #93767\r\n\r\nIt seems to me that `onDidEdit` should force to send the edit, but this typing allows `undefined` from the `fire` method:\r\n\r\n![image](https://user-images.githubusercontent.com/900690/78014273-fea01e00-7347-11ea-831a-7887f6a5022e.png)\r\n"}, {"classified_as": "api", "text": "Document MCP protocol semantics. MCP is conceptually aligned with [xDS](https://github.com/envoyproxy/data-plane-api/blob/master/XDS_PROTOCOL.md), but behavior may different slightly as the protocols evolve. "}, {"classified_as": "api", "text": "I would like to propose that we make a separate repository in github for jupyter notebooks.\r\n\r\nI think it should be separate from the main tensorflow github so that people can check it out without having to check out all of tensorflow.\r\n\r\nI've created such a github and will work on it by myself for now but I think eventually there should be something more official or at least maybe what I have can be considered official enough to have pointers to it from the main tensorflow github.\r\n\r\nhttps://github.com/reedkotler/tensorflow-notebooks\r\n"}, {"classified_as": "doku", "text": "https://flow.org/en/docs/linting/"}, {"classified_as": "api", "text": "**Where**\r\nhttps://perldoc.perl.org/perlreref.html under **EXTENDED CONSTRUCTS**\r\n\r\n**Description**\r\n\r\n* `(*pla:...)`, the synonym for `(?=...)`, is incorrectly shown as `(?*pla:...)`\r\n* `(*nla:...)`, the synonym for `(?!...)`, is incorrectly shown as `(?*nla:...)`\r\n* `(*plb:...)`, the synonym for `(?<=...)`, is incorrectly shown as `(?*plb:...)`\r\n* `(*nlb:...)`, the synonym for `(?<!...)`, is incorrectly shown as `(?*nlb:...)`\r\n* `(*atomic:...)`, the synonym for `(?>...)`, is incorrectly shown as `(?*atomic:...)`\r\n\r\nWhen testing these in Perl v5.30.1, the versions without `?` are the only ones that work. Any attempt to use ones with `?` results in the error `Sequence (?*...) not recognized in regex; marked by <-- HERE in `...\r\n\r\nIn https://perldoc.perl.org/perlre.html these are already documented correctly.\r\n\r\n---\r\n\r\nNow, for a proposal: `(?*...)` is currently not mapped to anything in any regex engine [except for mine](https://github.com/Davidebyzero/RegexMathEngine/blob/master/parser.cpp#L408), in which it is **non-atomic** lookahead (a.k.a. [molecular lookahead](https://github.com/Davidebyzero/RegexMathEngine/commit/db4e4a266d55ec66663ccaa17de944508ace4067)). I believe this mapping makes a great deal of sense, and is the best meaning `(?*...)` and `(?<*...)` could have (lookahead and lookbehind, respectively). My rationale:\r\n\r\n* The `*` shows that it tries all possibilities when backtracked into, rather than sticking with the first one it finds and being skipped over by backtracking, like regular atomic positive lookarounds do.\r\n* If non-atomic negative lookarounds were needed, that might be an argument for using a symbol that contains `=` for the positive version (for symmetry). But there is no need for negative non-atomic lookarounds, because a negative lookaround that results in a match outside will always have already tried all possibilities the first time it was hit; when backtracking into it, there would be no possibilities left to try, anyway. (As far as PCRE is concerned, a second reason could be given: molecular lookaround is only useful when capture(s) are made inside, and no captures made inside a negative lookaround should survive outside of it. But I realize that in Perl, once a negative lookaround is exited after failing to find any match, thus matching outside, captures made inside of it will contain the last thing they did when it made its last failed match inside.)\r\n* The one case in which a negative non-atomic lookaround might make sense is for lookaround conditionals, because in Perl and PCRE2, a negative lookaround conditional that matches inside (thus failing to match outside) will give its captures from that match to the conditional's negative alternative. However, anything that a negative lookaround conditional can do, a positive one can also do, just by swapping the two alternatives. So the argument holds, that negative non-atomic lookaround is not needed. It's not worth putting one extra character in the symbol for non-atomic positive lookaround just so there can be a symmetric negative non-atomic lookaround conditional.\r\n\r\n`(?*...)` and `(?<*...)` have no meaning in any other engine, and are ripe for the taking. And somebody has to take the initiative, otherwise this opportunity for intuitive and useful symbol mapping will just go unused (or worse, used for something less useful).\r\n\r\nSo, I would argue that in Perl, `(?*...)` and `(?<*...)` should be reserved until non-atomic lookarounds are implemented, and then mapped to those functions when they are."}, {"classified_as": "api", "text": "Currently Flutter for web build command generates a big single Javascript file in release mode. \r\n\r\nIt is proposed that new routing APIs should allow groping of related routes and then the build command should generate separate Javascript files for each group of routes these files can than be pre-fetched separately. This will help to improve Time to Interactive TTI score and defer or remove unnecessary JavaScript work that occurs during initial page load."}, {"classified_as": "doku", "text": "`pip intall zulip` for Python 3 fails.\r\n\r\n```python\r\nuser@user-ThinkPad-T400 ~/c/zulip> pip install zulip\r\nCollecting zulip\r\n  Using cached zulip-0.2.4.tar.gz\r\n    Complete output from command python setup.py egginfo:\r\n    Traceback (most recent call last):\r\n      File \"<string>\", line 1, in <module>\r\n      File \"/tmp/pip-build-9bng7ux4/zulip/setup.py\", line 26, in <module>\r\n        version=version(),\r\n      File \"/tmp/pip-build-9bng7ux4/zulip/setup.py\", line 13, in version\r\n        inhandle).next()\r\n    AttributeError: 'itertools.dropwhile' object has no attribute 'next'\r\n    \r\n    ----------------------------------------\r\nCommand \"python setup.py egginfo\" failed with error code 1 in /tmp/pip-build-9bng7ux4/zulip/\r\n```\r\nInstallation candidate in `api` directory works.\r\n\r\n```python\r\nuser@user-ThinkPad-T400 ~/c/z/api> python setup.py develop\r\nrunning develop\r\nrunning egginfo\r\nwriting requirements to zulip.egg-info/requires.txt\r\nwriting dependencylinks to zulip.egg-info/dependencylinks.txt\r\nwriting zulip.egg-info/PKG-INFO\r\n...\r\nInstalled /home/user/.virtualenvs/zulip-sand-3/lib/python3.5/site-packages/requests-2.12.1-py3.5.egg\r\nFinished processing dependencies for zulip==0.2.5\r\n\r\n```\r\n\r\nAlso PyPI package version is `0.2.4`."}, {"classified_as": "api", "text": "For example, in SparseCategoricalAccuracy(), the words in this API does not help to give a clear picture to understand what it is doing. Why not give a formula. A formula, associated with an example, is clear enough for this API."}, {"classified_as": "api", "text": "Based on this https://github.com/polkadot-js/api/pull/527/files#diff-4ac32a78649ca5bdd8e0ba38b7006a1eR1 for api/promise -\r\n\r\n- Update in-code samples\r\n- Update actual docs/examples samples"}, {"classified_as": "api", "text": "I dont like java and swift.\r\nI prefer c++.\r\nHowever, I seldom see any c++ api helps."}, {"classified_as": "doku", "text": "`pip intall zulip` for Python 3 fails.\r\n\r\n```python\r\nuser@user-ThinkPad-T400 ~/c/zulip> pip install zulip\r\nCollecting zulip\r\n  Using cached zulip-0.2.4.tar.gz\r\n    Complete output from command python setup.py egginfo:\r\n    Traceback (most recent call last):\r\n      File \"<string>\", line 1, in <module>\r\n      File \"/tmp/pip-build-9bng7ux4/zulip/setup.py\", line 26, in <module>\r\n        version=version(),\r\n      File \"/tmp/pip-build-9bng7ux4/zulip/setup.py\", line 13, in version\r\n        inhandle).next()\r\n    AttributeError: 'itertools.dropwhile' object has no attribute 'next'\r\n    \r\n    ----------------------------------------\r\nCommand \"python setup.py egginfo\" failed with error code 1 in /tmp/pip-build-9bng7ux4/zulip/\r\n```\r\nInstallation candidate in `api` directory works.\r\n\r\n```python\r\nuser@user-ThinkPad-T400 ~/c/z/api> python setup.py develop\r\nrunning develop\r\nrunning egginfo\r\nwriting requirements to zulip.egg-info/requires.txt\r\nwriting dependencylinks to zulip.egg-info/dependencylinks.txt\r\nwriting zulip.egg-info/PKG-INFO\r\n...\r\nInstalled /home/user/.virtualenvs/zulip-sand-3/lib/python3.5/site-packages/requests-2.12.1-py3.5.egg\r\nFinished processing dependencies for zulip==0.2.5\r\n\r\n```\r\n\r\nAlso PyPI package version is `0.2.4`."}, {"classified_as": "api", "text": "Not really a bug but for a lack of a better category, I'm posting it as such. \r\n\r\nOn the Wiki \"plugins\" page, there is a link to a \"thefuck\" plugin, but it appears to be dead. Searching the page doesn't yield any results other than the table of contents. \r\n\r\nSorry but I don't have time to investigate now - just signaling it in case you want to fix it !\r\n\r\nEdit: apparently it labeled the issue as support rather than bug? pretty sure I selected bug. anyhow :)\r\n"}, {"classified_as": "api", "text": "As part of removing all of our analysis_options.yaml for the plugins we need to document all of the public members in `video_player_platform_interface`. See flutter/flutter#45440 for the meta issue on all of these analysis rules.\r\n\r\nThe missing classes here are:\r\n\r\n- DataSource and its members\r\n- VideoEvent and its members\r\n- VideoEventType and all of its values\r\n\r\n/cc @cbenhagen do you mind taking this one? It looks like you created the undocumented public members, so I think you'd probably have the best shot at describing these correctly. I took a look but it wasn't obvious to me what the new classes were supposed to be."}, {"classified_as": "api", "text": "I'm not sure if this can be considered a bug or it is intentional:\r\n\r\nWhenever I send a request to the checkout update endpoint, spree generates a new address entry although the address did not change at all. This behaviour is not as described or expected in https://guides.spreecommerce.org/api/v2/storefront#operation/Update%20Checkout (to be fair: no behaviour is described for this).\r\n\r\nI think it would be good to check if the address attributes for bill and / or ship are exactly the same / unchanged even if included in the request and do not create a new address entry. Also maybe it makes sense to define what parameters should trigger a \"new\" address entry and what parameters just update the existing one. My main concern is, that the database is bloating a lot with this and the user also has a lot of duplicate addresses in his address book this way.\r\n\r\nHappy to hear your thoughts and maybe we convert this into an issue / bug if it was not intentional."}, {"classified_as": "api", "text": "Hi.\r\nI've used official plugin for payments. I would like to implement auto-renewal subscriptions. In android implementation it is very easy. Problem is in iOS. serverVerificationData isn't a payment token (as in android payment). I must valid it before sending to server and I must decode it. Decoding by base64 return bytes. It is probably ASN1. I am trying to get to payment token from it by plugin asn1lib. My attemps are failed. \r\nHow can I get payment token from iOS?"}, {"classified_as": "api", "text": "The docs building times are just crazy long, since everything gets built atm and it is getting worse. There is a known issue in Vuepress, https://github.com/vuejs/vuepress/issues/1560\r\n\r\nIt may be worth-while seeing if we cannot just skip the generated stuff."}, {"classified_as": "doku", "text": "I have just rolled through the Getting Started section in tandem with the Substrate intro tutorial. Awesome work on the platform and the docs BTW, it was really fun to get straight in and have a jam.\r\n\r\nSome constrictive feedback:\r\nAs a newcomer to blockchain tech in general, I stumbled on the Transactions / Keyring section. I would suggest putting an even simpler high level primer at the start of the Keyring section to ensure the basic concept of a decentralised identity/wallet is clear. Also a bit more explanation about the demo accounts that are preloaded in the substrate demo node and that they're URI based would be helpful for the uninitiated amongst us.\r\n\r\nAgain, thanks for all the awesome work on this!"}, {"classified_as": "api", "text": "Could we have a proper documentation (either in the pod files with a custom header) or in the readme?\r\nIt would help greatly to have the list of available methods and what they do (unless method name is self-explanatory).\r\nHaving to dig into ~20 objective-c files to get a grasp of what is possible in swift is not equivalent to a proper documentation"}, {"classified_as": "api", "text": "## Use case\r\n\r\nDevelopers occasionally need to apply an ImageFilter to part of their Widget tree. We created a BackdropFilter widget to satisfy a common use of that technique, but there were other uses for which it was not as suited, such as blurring a widget in isolation. It is possible to use BackdropFilter to achieve those other results, but the construction is not obvious and there are a number of pitfalls that a developer can fall into.\r\n\r\nMore recently a new ImageFiltered widget was added which more directly serves the other needs to filter a part of an app with a more straightforward construction and an easier to manage behavior. But, developers continue to use BackdropFilter as it has been around longer and has more awareness built for it.\r\n\r\n## Proposal\r\n\r\nDocument the existence of the two widgets in each other's doc comments and provide examples and guidance on when to use each."}, {"classified_as": "api", "text": "A co-worker introduced me to Oh-My-Zsh several months back, and it has since migrated to be on a number of my own personal systems. It's going to stay on these, so I stay up to date with the latest and greatest from Oh-My-Zsh. :+1:\n\nHowever, I'd also like to extend some of the goodness to more restricted environments, like servers, in a more light-weight and controlled manner. How would I go about understanding how Oh-My-Zsh hooks into Zsh and then extracting specific pieces of Oh-My-Zsh into a flat .zshrc file?\n"}, {"classified_as": "doku", "text": "These show a super-ancient version of the UI:\r\n\r\n![image](https://user-images.githubusercontent.com/2746074/38837624-7bfda3e4-4187-11e8-8cec-38089e69a166.png)\r\n\r\n(There's probably other cleanup that would be valuable on this page)\r\n\r\nWe should make sure the screenshots show sensible examples (e.g. a \"GitHub Bot\" with the GitHub logo as its avatar)"}, {"classified_as": "doku", "text": "After Events are exposed through the API and docs are generated, add section list with anchors and order the sections and methods alphabetically as done in PR #291 and PR #302 for RPC, Extrinsics, and Storage\r\n\r\n"}, {"classified_as": "doku", "text": "As soon as paritytech/substrate#4895 is merged"}, {"classified_as": "api", "text": "So... today I've been at the FITC Web Unleashed 2016 conference, where I've met amazing @bpainter (Those who don't know of him, shame on you! jk)... and this rockstar of a guy thinks he may get us in touch with the SASS people so we can improve their documentation, and maybe reshape it a bit more newbie friendly. This would help us teach campers so much better, and in the process help us shape our own sass contents. Right? no? Comment!\n\nThus, I humbly bequest this community with the task of helping me figure out what needs to be changed or added. Maybe we could ask the general population for hints and requests?\nAny and all \u2014constructive\u2014 input shall be welcome and considered. Let's make it happen!\n\n@QuincyLarson @FreeCodeCamp/issue-moderators Thoughts on how to lead this?\n"}, {"classified_as": "api", "text": "[Just the other day](https://debbugs.gnu.org/cgi/bugreport.cgi?bug=38154) we were having an argument about if e.g.,\r\n\r\n $ man perldoc\r\n> \r\n> SEE ALSO\r\n>        perlpod, Pod::Perldoc\r\n\r\nshould instead say\r\n> SEE ALSO\r\n>        perlpod(1), Pod::Perldoc(3perl)\r\n\r\nI.e., all perl man pages' SEE ALSO sections should have standard numbers attached to them,\r\nlike\r\n$ man cat\r\nhas.\r\n"}, {"classified_as": "api", "text": "```\r\nconst log = x => console.log(JSON.stringify(x, null, 2));\r\n\r\nconst { metadata } = await api.rpc.state.getMetadata();\r\nconst modules = metadata.asV3.modules;\r\n\r\nconst system = modules.find(m => m.name === 'system');\r\nlog(system);\r\n```\r\n\r\nThis won't work because `new Text('system') === 'system'` is false.\r\n\r\n`const system = modules.find(m => m.name.toString() === 'system');` can be used as workaround but I don't think it is good code."}, {"classified_as": "api", "text": "I am trying to compile TensorflowLite for emscripten (I am aware of TensorflowJS) and pthreads are currently disabled. Is there a way to use it without pthreads?\r\n\r\n"}, {"classified_as": "api", "text": "The case is quite simple: https://www.conventionalcommits.org/en/v1.0.0/\r\n\r\n- There are some public GitHub repositories (like [ESLint](https://github.com/eslint/eslint/commits/master)) using conventional commits workflow, personally I like it too. \r\n- I see many people using `feat`, `chore`, `bug` prefixes for their commit messages on GitHub.\r\n- There are some tools which allow to validate commit messages against conventional commits standard and tools to generate change log.\r\n\r\nWhat do you think about following this formal specification for `git` commit messages for Flutter repository?\r\n\r\n\r\n"}, {"classified_as": "api", "text": "perldata says\r\n\r\n> Since you can assign to a list of variables, you can also assign to an array or hash slice ...\r\n> > `@colors{'red','blue','green'} = (0xff0000, 0x0000ff, 0x00ff00);`\r\n> \r\n> The previous assignments are exactly equivalent to ...\r\n> > `($colors{'red'}, $colors{'blue'}, $colors{'green'}) = (0xff0000, 0x0000ff, 0x00ff00);`\r\n\r\nOK, but it needs to mention more than just one depth,\r\n> @{$colors{favorites}}{ 'red', 'blue', 'green' } #OK\r\n\r\nElse users will extend the analogy presented, and assume\r\n> `@colors{favorites}{ 'red', 'blue', 'green' } #syntax error`\r\n\r\nwill work !\r\n\r\nAlso mention there is no way to use a consistent syntax for first vs.\r\nmore layers."}, {"classified_as": "api", "text": "I know that the privacy policy says that FCC can gather and publish statistics, but some campers don't realize that the contents of their community posts will be shared (especially associated with their usernames).  In the spirit of transparency, should there be some information about this clearly laid out in the privacy policy? It seems consistent with FCC's values to do so."}, {"classified_as": "api", "text": "**Original bug ID:** 7392\n**Reporter:** bartjacobs\n**Status:** resolved (set by @xavierleroy on 2016-12-07T18:14:17Z)\n**Resolution:** duplicate\n**Priority:** normal\n**Severity:** minor\n**Version:** 4.03.0\n**Category:** documentation\n**Related to:** #7394\n**Monitored by:** @gasche\n\n## Bug description\n\nSince #254 (Warning on fragile literals in constructor argument patterns) (released in OCaml 4.03), the documentation for int_of_string, which says \"Raise Failure \"int_of_string\" if the given string is not a valid representation of an integer, or if the integer represented exceeds the range of integers representable in type int.\", is inconsistent with the OCaml implementation (specifically, file typing/predef.ml), which declares exception Failure with the warn_on_literal_pattern attribute. The documentation for int_of_string is pretty unequivocal that the behavior of int_of_string in case of malformed input is exactly to raise the exception Failure \"int_of_string\". The warn_on_literal_pattern attribute, on the other hand, suggests that the value of the argument of Failure should not be relied upon, i.e. that instead of throwing Failure \"int_of_string\", int_of_string might in a future OCaml release throw something else in case of malformed input.\r\n\r\nThis is problematic for someone trying to write code that uses int_of_string and that does something other than propagating the exception in case of malformed input.\r\n\r\nThe warning 52 documentation (Sec. 8.5.1, in the Batch compilation chapter) suggests that this person should simply catch any exception that matches Failure _.\r\n\r\nHowever, this raises the following question: What if int_of_string throws a Failure exception for a reason other than malformed input? Perhaps, for int_of_string this is a rather far-fetched scenario, but (without looking at the source code) it is not entirely inconceivable. And for some of the other similar cases, such as int_of_big_int, with presumably a more complex implementation with more failure modes, this is somewhat more conceivable still. And in any case, the documentation for these functions does not state that this will not happen.\r\n\r\nClient code should propagate such an exception instead of treating it as if it indicated malformed input.\r\n\r\nTo fix this problem in a backward-compatible way, I suggest to update the documentation for int_of_string and similar functions (including int_of_big_int), by adding the sentence \"Do not raise a Failure for any other reason.\" Another way to put it is to replace \"Raise Failure \"int_of_string\" if the given string is not a valid representation of an integer, or if the integer represented exceeds the range of integers representable in type int.\" by \"Raise Failure if (and only if) the given string is not a valid representation of an integer, or if the integer represented exceeds the range of integers representable in type int.\" (while of course continuing to raise only Failure \"int_of_string\" for backward compatibility).\r\n\r\n(Of course, one should also check that the current implementations of these functions do indeed not throw Failure for other reasons!)\r\n\r\n(Note: a (much less severe) lack of clarity in the documentation of int_of_string and similar functions existed already before OCaml 4.03: it did not explicitly guarantee that it would not throw Failure \"int_of_string\" for a reason other than malformed input. To see how this is not entirely inconceivable, one could vaguely imagine an implementation that would in some cases directly or indirectly perform a nested int_of_string call with some other input. Again, this is more conceivable with functions that are more complex than int_of_string. But again, the main argument is not about whether it is conceivable, but about whether the documentation should be explicit about it, which seems a clear \"yes\" since people do rely on it and furthermore it's not hard to fix.)\r\n\r\n((Even more parenthesized note: for any function with a non-trivial implementation that involves nested function calls, it is not actually easy to guarantee that the function will *not* throw any given exception, especially if the exception is a generic one such as Failure. This suggests that attaching any postcondition (other than \"true\") to a function raising an exception is dubious, and instead the function's return type should probably be enriched (from 'a to 'a option or 'a + string) so that the exceptional condition can be indicated as a special return value. A client who wishes to ignore the exceptional case can easily turn the special return value into an exception using a partial match (or a helper function that raises an appropriate exception). Note that this is pretty much how error handling is done in Erlang. So, perhaps a better solution would be to introduce a new function, perhaps called int_option_of_string, that returns an int option.))\n\n## Additional information\n\n(I put Severity \"minor\" because this issue is unlikely to lead to many problems at run time, but on the other hand I think this is currently impacting many people who care about writing clearly correct code.)\n"}, {"classified_as": "doku", "text": "Some of the examples listed in the below \"Usage\" section:\r\n\r\n<img width=\"737\" alt=\"screen shot 2018-10-15 at 18 03 25\" src=\"https://user-images.githubusercontent.com/6226175/46962960-c568e500-d0a4-11e8-844f-f5457c16ad4d.png\">\r\n\r\nAre duplicated to an extent in the examples in the \"Examples\" section at links shown below. Note however that often the version in the \"Usage\" section (such as \"Submitting a transaction\") is often more concise and makes more use of chaining:\r\n\r\n<img width=\"227\" alt=\"screen shot 2018-10-15 at 18 03 37\" src=\"https://user-images.githubusercontent.com/6226175/46963018-e8939480-d0a4-11e8-9cc1-aa4739e2fbdd.png\">\r\n "}, {"classified_as": "api", "text": "The `Tooltip` docs say:\r\n\r\n>Wrap the button in a Tooltip widget to show a label when the widget long pressed (or when the user takes some other appropriate action).\r\n\r\nThe `(or when the user takes some other appropriate action)` implies we could choose other actions to show the `Tooltip`, or that at least they are already built-in, but the docs don't mention any other ways to show the `Tooltip` neither how to reconfigure it's default behavior, like changing \"long-press\" to \"on tap\".\r\n\r\nThe only hint I could get to the explanation of this sentence is in the `waitDuration` description where it says the `Tooltip` will also be shown on a pointer hover.\r\n\r\nSo are the docs incomplete or the `Tooltip` should have additional functionality? "}, {"classified_as": "doku", "text": "`startingMonth` is the month the quarter ends. This is confusing.\n"}, {"classified_as": "api", "text": "I am sure the API can do it, because the error is also displayed in the App.\r\n\r\nBut when using the API itself, how do I know the error being returned when an extrinsic fail? Is this just a lack of documentation or there is no public API for this?\r\n\r\nI can try to work on this too."}, {"classified_as": "doku", "text": "When I go to the API Docs > Chain state (runtime), it has a \"contract\" section https://polkadot.js.org/api/METHODSSTORAGE.html#contract in the menu but no methods associated when I click the link, and there isn't a \"substrate\" section at all (differs from Substrate UI at https://polkadot.js.org/apps/next/#/chainstate which does have that section)"}, {"classified_as": "api", "text": "I think need some example to show submit Extrinsics, such as stake, unstake, nominate, and Voting."}, {"classified_as": "api", "text": "This is a continuation of [this discussion](https://gitter.im/FreeCodeCamp/Contributors?at=58b459bc4150746b151525c9) about how to use labels for PRs.\r\n\r\nInstead of using the `blocked` label for PRs that have been reviewed but need further changes, we concluded that something like `changes requested` could be more friendly towards contributors than the `blocked` label.\r\n\r\nIf we want to make this change, we probably want to add this to the moderator guidelines or labeling guide.\r\n\r\n@freeCodeCamp/moderators What do you think?"}, {"classified_as": "doku", "text": "These show a super-ancient version of the UI:\r\n\r\n![image](https://user-images.githubusercontent.com/2746074/38837624-7bfda3e4-4187-11e8-8cec-38089e69a166.png)\r\n\r\n(There's probably other cleanup that would be valuable on this page)\r\n\r\nWe should make sure the screenshots show sensible examples (e.g. a \"GitHub Bot\" with the GitHub logo as its avatar)"}, {"classified_as": "api", "text": " In perlop,\r\n```\r\n           next LINE if (1 .. /^$/);  # skip header lines, short for\r\n                                      #   next LINE if ($. == 1 .. /^$/);\r\n```\r\nActually all the parentheses can be removed from the example.\r\n\r\n```\r\n                                                 # (typically in a loop labeled LINE)\r\n```\r\nActually LINE is special. Using e.g., LINEz would need a existing label."}, {"classified_as": "doku", "text": "Hello,\n\nI'm trying to parse a file with the extension 'xls' which is not an Excel file but it's clearly an html file (open with a text editor it's clearly html code).\n\nOne of my columns uses the italian convention of using the comma instead of the dot before decimals: 5,5 instead of 5.5. I was hoping to parse it at least as string and replace commas with dots and convert the string to a float.\n\nThe problem is that the commas are completely ignored and instead of getting 5,5 or 7,04, I'm getting 55 and 704.\n\nIs this known? Any idea on how to solve it?\n"}, {"classified_as": "api", "text": "I'm using vector_math-2.0.8/lib/src/vector_math_64/ray.dart for a ray-sphere intersection test, but I think the method supplied will only work correctly if the _direction component of a ray is a unit vector.\r\n\r\nIt also seems that at least one other method in the same file, at, assumes that _direction also has a magnitude of one.\r\n\r\nThere's nothing I've seen in the class or the documentation to suggest that the caller would know by convention that a unit vector is needed here, and actually to preserve the generality of the ray routines, I don't think we would require _direction to be a unit vector at the caller's end.\r\n\r\nTo fix this, we could normalise the direction vector in these two methods.  For intersectsWithSphere, I think line 57 could be changed to:\r\n\r\n`final double s = l.dot(_direction.normalized());`\r\n\r\nAnd for at, line 40 could be:\r\n\r\n`Vector3 at(double t) => _direction.normalized().scale(t)..add(_origin);`\r\n\r\nDoes this sound like a good plan?\r\n\r\n(Ps. just looking through the file, looks like generally the direction vector might need normalising before use eg. in copyAt.  Don't understand enough about the other intersection routines to have assessed those yet.)"}, {"classified_as": "api", "text": "There were additional topics discussed that could not be turned into coherent notes after the fact.\r\n\r\n## Action items\r\n   * TensorFlow team to create a block diagram and then go deeper.  Goal is to help people who want to contribute plugins or extensions. [#22356](https://github.com/tensorflow/tensorflow/issues/22356)\r\n   * Make the NVIDIA Library to TF Version matrix more visible and consider better error messages. [#22357](https://github.com/tensorflow/tensorflow/issues/22357)\r\n   * Document tips and methods to use for large batch scaling with TensorFlow.  Possibly mention where this is proven and unproven to work.  This would include adding optimizers or wrapper to simplify usage.  Researchers are large labs want to scale but do not have the knowledge to do it quickly. [#22358](https://github.com/tensorflow/tensorflow/issues/22358)\r\n\r\n## General Questions and discussion results\r\n\r\n   * Should TensorFlow default builds move forward more aggressively with newer versions of CUDA/cuDNN?\r\n      * Internally Google moves slowly to new versions of CUDA as the verification process is long and often includes multiple patches with NVIDIA until all edge cases are covered.  The bar is extremely high for obvious reasons.\r\n      * Group thought was it doesn\u2019t matter. Situation would be improved with better error messages indicating what version is needed and making the matrix showing what NVIDIA libs are needed for each TensorFlow version.\r\n   * Provide more models with good performance and accuracy in github.com/tensorflow/models.  Too many different versions and unsure which one to use.  Example:  There are 3+ ResNet models.\r\n      * Contact tfboyd@ or comment in this thread if there is a specific model of interest and why.  MLPerf may improve this situation.\r\n   * Auto regressive models with long dependency chains are hard to optimize by doing fusion by hand.\r\n      * Consider trying XLA and providing feedback. An objective of XLA is to reduce the need for custom fusion.\r\n   * [Ask] Distributing the input pipeline across servers.  Some work has been done and rumored to have occured in production but not trivial to setup.  Consider an RFP and/or reach out to the tf.data team.\r\n   * TensorCores are only used if you are using tf.16.  You can do Pseudo FP16 with an envar that should be in TF 1.11 from NVIDIA as an experimental feature.  You still need to do loss scaling.\r\n\r\n## Debugging and performance investigations\r\n   * Hard to get timelines and profiler results.\r\n      * New guide is on the way, not positive this will make it as easy as desired.\r\n   * [Ask] Provide an interface to autotuning parameters such as intra and inter thread pools.\r\n      * In hindsight, more information is needed to make this actionable.  Please add info to the comments.  \r\n\r\n## Distributed compute (multi-gpu and multi-node)\r\n   * All reduce API for multi-node and support MPI.\r\n      * MPI would be useful for supercomputers where you need to use their MPI library to get good communication.\r\n      * NCCL currently used by MirroredStrategy but only for multi-GPU.  TensorFlow\u2019s own `ops` are used for multi-node all-reduce.\r\n\r\n   * Document on how the distribution strategies is setup with the goal of showing how others can add their own solution and collective ops.  The API is the best place right now to figure this out.\r\n   * [AI] TensorFlow team to create a block diagram and then go deeper.  Goal is to help people who want to contribute plugins or extensions.\r\n   * Having a hard time with MPI.  People are using a newer versions of MPI\r\n   * How do we plan to support fault tolerance? Will it allow dynamic addition and removal of machines to the collective. E.g. preemption but keep training with a smaller pool. Also increasing machines & batch size as training progresses. Need to adjust the learning rate, so maybe get a callback, especially when you are going to lose or have just lost a machine. Response to call back is starting with revised set of machines an new learning rate.\r\n   *[AI] Document strategies for large batch training.  LARS looking to automatic learning rate, warmup rate and stuff.  \r\n\r\n## Model parallelism and Data parallelism\r\n   * Model parallelism is currently manual.  Work to automate it is on going and it can be phrased as an RL problem.  \r\n   * Data parallelism supported via MirroredStrategy discussed today\r\n"}, {"classified_as": "api", "text": "The router widget is pretty complex because it solved a whole range of issues. We should think about how do we make it easier for developers to use it.\r\n\r\n\r\n\r\nHere are some ideas:\r\n1. Add more sample code on how to implement different delegates for different use cases.\r\n2. Add more opinionated delegates with a simpler API for common use cases\r\n3. Add some guidelines on how to manage app state.\r\n\r\n"}, {"classified_as": "doku", "text": "- [x] Add a chapter for ApiRx examples like https://polkadot.js.org/api/examples/promise/\r\n- [x] Go through examples in https://polkadot.js.org/api/api/classes/rxindex.apirx.html and update them to work with current API, polkadot and substrate versions"}, {"classified_as": "doku", "text": "It should be called `getSuggestionForNonexistentExport`."}, {"classified_as": "api", "text": "# Problem\r\n\r\nLet's say I have the following definition:\r\n\r\n```\r\n\"Document\": {\r\n  \"name\": \"DocumentName\",\r\n  \"uri\": \"DocumentUri\",\r\n  \"hash\": \"Text\"\r\n}\r\n```\r\n\r\nAfter generating types with `@polkadot/typegen`, the following error will appear where `Document` is defined:\r\n\r\n```\r\nType 'Document' does not satisfy the constraint 'Codec'.\r\n  Types of property 'hash' are incompatible.\r\n    Type 'Text' is missing the following properties from type 'H256': bitLength, subarray, BYTES_PER_ELEMENT, buffer, and 21 more.\r\n```\r\n\r\nThe reason, of course, is that my `Document`'s `hash` property is shadowing `Codec`'s `hash` property. This would also happen if I used `registry`, `isEmpty`, `encodedLength`, etc (all reasonable names for props).\r\n\r\n# Suggestion\r\n\r\nSince any change to `Codec` or `Struct` would break a lot of stuff, I suggest adding a note to the docs (probably in the section regarding user-defined types and maybe in the substrate docs as well) advising devs to either prefix their struct variables in some manner or listing the property names that would cause conflicts (`hash`, `registry`, `isEmpty`, etc)"}, {"classified_as": "api", "text": "Could you provide some examples of how to create and submit a mortal transaction? e.g. I want this transaction expire after block 10000 or after 100 blocks from current height\r\n\r\nAll I can found is [ExtrinsicEra](https://github.com/polkadot-js/api/blob/master/packages/types/src/type/ExtrinsicEra.ts) which requires me to construct the details from bytes. It should provide helper methods to construct `ExtrinsicEra` from block number.\r\n\r\nI did found this https://github.com/paritytech/wiki/blob/master/Extrinsic.md#transaction-era\r\nI can try to understand the algorithm and implement the encode method but it will be good if it is done by someone already knows how to do it."}, {"classified_as": "api", "text": "... and make sure we have proper docs here\r\n\r\n~~https://github.com/polkadot-js/dev/issues/132~~"}, {"classified_as": "api", "text": "Need to be more explicit in the url strings to pass through in the samples. Ie. \r\n\r\n\"Somewhere.com:9944\" will not work, however \"ws://somewhere.com:9944\" will (also with secure)\r\n\r\nAlso just check errors thrown on these, no silent failures. (We just need to be slightly more explicit to convey the info, it is there, but not always 100% obvious and/or somewhat hidden)"}, {"classified_as": "api", "text": "#### Issue Description\r\nI have noticed over the past week and a half that it is difficult to find issues to work on without stepping on toes or waiting to hear from someone several hours later if it's okay to work on it. In many instances, I've ended up playing with something that was marked as Help Wanted and unassigned and in the Todo bucket, only to realize that someone else was working on it!\r\n\r\nWork-items should reflect current and accurate status. I would like to see the following:\r\n\r\n1. People working on issues need to be assigned to it, or at least a note stating that a specific person is investigating needs to be posted.\r\n\r\n2. The issue must be moved to in-progress (or in an investigating bucket)\r\n\r\n3. The issue needs to be tagged appropriately\r\n\r\nI spent a week trying to get started because I couldn't find an available issue to work on and almost gave up.\r\n"}]