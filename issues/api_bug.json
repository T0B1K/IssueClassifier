[{"text": "#### Problem description\r\nWhen creating a `DatetimeIndex` partially-bounded, i.e., only specifying either `start` or `end` the use of a `closed` parameter different from `None` was intended to be disallowed. This behaviour is bugged as shown in #23198. #23199 solves this bug.\r\n\r\nBefore #23199, the DatetimeIndex was successfully created. The result contained one less than the requested `periods` in some cases as shown in #23176.\r\n\r\nAfter #23199, a `ValueError` will be raised as it seemed to be intended.\r\n\r\nThe proposal is to allow `closed` parameters different to `None` for partially-bounded `DatetimeIndex`es. The behaviour should be as defined in the following table\r\n\r\nPeriods | Ommited parameter | Closed | Current number of items | After #23199 | Proposed number of items\r\n-|-|-|-|-|-\r\nN | `end` | `None` | N | N | N\r\nN | `end` | `\"left\"` | N-1 | `ValueError` | N\r\nN | `end` | `\"right\"` | N | `ValueError` | N\r\nN | `start` | `None` | N | N | N\r\nN | `start` | `\"left\"` | N | `ValueError` | N\r\nN | `start` | `\"right\"` | N-1 | `ValueError` | N"},
{"text": "```\r\npd.TimedeltaIndex(['1D']) == 1\r\n[...]\r\nTypeError: cannot compare a TimedeltaIndex with type int\r\n\r\npd.TimedeltaIndex(['1D']) == 1.\r\n[...]\r\nTypeError: cannot compare a TimedeltaIndex with type float\r\n```"},
{"text": "Is this required? Right now https://github.com/pandas-dev/pandas/blob/a03d9535b16a6d5441334ef2e698d72778cf8115/pandas/core/algorithms.py#L708-L711 assumes that it's implemented, but we don't document / implement it by default, so we end up with an AttributeError at runtime."},
{"text": "I recently had a colleague that ran into a nasty bug, due to the fact that on Python >= 3.6 we no longer sort the columns when creating a DataFrame from a dict.\r\n\r\nEg on Python 3.5:\r\n\r\n```\r\nIn [1]: df = pd.DataFrame({'B': [1, 2], 'A': [3, 4]})\r\n\r\nIn [2]: df\r\nOut[2]: \r\n   A  B\r\n0  3  1\r\n1  4  2\r\n```\r\n\r\nOn Python 3.6/3.7 this would keep the column order as `['B', 'A']`. \r\n\r\nIf you write code that depends on the ordering of columns, like `df.columns = ['other', 'name']` (not the most robust way, but people do that), or like `df.iloc[..]`, you will silently get different results, leading to bugs.\r\n\r\n---\r\n\r\nOpening the issue mainly to discuss to see if we can somewhat alleviate such problem and what other people think (did other people similar problems), not necessarily to propose to completely revert the change (that would also be annoying given that is already out for some time).\r\n\r\nBut we could think about raising a warning in the specific case of using dict on Python >= 3.6 where the sorted column order and dict keys order does not match. \r\nBut the annoying thing is that there is no easy way then for people to silence the warning, apart from adding a new keyword we then later would deprecate itself.\r\n\r\ncc @topper-123 @TomAugspurger \r\n\r\n"},
{"text": "#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\nimport pandas as pd\r\n\r\nprint(\"Pandas version :  \", pd.version)\r\n\r\ndef printdict(fn):\r\n    print(fn.name)\r\n    print(fn(dict(C=[3], B=[2], A=[1])))\r\n\r\nwith pd.optioncontext('display.maxrows', 10, 'display.maxcolumns', 5):\r\n    printdict(pd.DataFrame)\r\n    printdict(pd.DataFrame.fromdict)\r\n    printdict(pd.DataFrame.fromrecords)\r\n```\r\n#### Problem description\r\n\r\npandas 0.22 gave consistent output when creating a DataFrame passing a dictionary using any of `DataFrame` constructor, `DataFrame.fromdict` and `DataFrame.fromrecords`. pandas 0.23 changed the behaviour of creating from dictionaries to respect key ordering in Python version 3.6+ for both the `DataFrame` constructor and `DataFrame.fromdict` but not using `DataFrame.fromrecords`. \r\n\r\n\r\n#### Output 0.23\r\nDifferent ordering of columns depending on construction method\r\n\r\n```\r\nPandas version :   0.23.4\r\nDataFrame\r\n   C  B  A\r\n0  3  2  1\r\nfromdict\r\n   C  B  A\r\n0  3  2  1\r\nfromrecords\r\n   A  B  C\r\n0  1  2  3\r\n```\r\n\r\n#### Output 0.22\r\nConsistent ordering of columns (sorted keys)\r\n\r\n```\r\nPandas version :   0.22.0\r\nDataFrame\r\n   A  B  C\r\n0  1  2  3\r\nfromdict\r\n   A  B  C\r\n0  1  2  3\r\nfromrecords\r\n   A  B  C\r\n0  1  2  3\r\n```\r\n\r\n#### Expected Output (my local build including #22687)\r\nConsistent ordering of columns (dict key order respected)\r\n\r\n```\r\nPandas version :   0.24.0.dev0+570.g434910bcb\r\nDataFrame\r\n   C  B  A\r\n0  3  2  1\r\nfromdict\r\n   C  B  A\r\n0  3  2  1\r\nfromrecords\r\n   C  B  A\r\n0  3  2  1\r\n```\r\n"},
{"text": "ATM `pd.Timestamp.utcnow()` returns a UTC-localized `Timestamp` object, but `pd.Timestamp.utcfromtimestamp()` does not.  As a result, the following round-trip fails:\r\n\r\n```\r\nunow = pd.Timestamp.utcnow()\r\nresult = pd.Timestamp.utcfromtimestamp(unow.timestamp())\r\nassert unow == result  # <-- TypeError because unow is tzaware and result is tznaive\r\n```\r\n\r\nChanging this would mean breaking with the stdlib, but our `utcnow` already breaks with the stdlib (see also #22450)"},
{"text": "ndarray.take accepts scalars, and returns a scalar. We should probably make that part of the interface, or document that we don't support it.\r\n\r\n\r\n```python\r\nIn [18]: np.array([1, 2]).take(0)\r\nOut[18]: 1\r\n```\r\n\r\nCategorical currently returns an invalid categorical:\r\n\r\n```\r\nIn [19]: res = pd.Categorical([0, 1]).take(0)\r\n\r\nIn [20]: type(res)\r\nOut[20]: pandas.core.arrays.categorical.Categorical\r\n```\r\n\r\n```pytb\r\nIn [21]: res\r\nOut[21]: ---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n~/Envs/pandas-dev/lib/python3.6/site-packages/IPython/core/formatters.py in call(self, obj)\r\n    700                 typepprinters=self.typeprinters,\r\n    701                 deferredpprinters=self.deferredprinters)\r\n--> 702             printer.pretty(obj)\r\n    703             printer.flush()\r\n    704             return stream.getvalue()\r\n\r\n~/Envs/pandas-dev/lib/python3.6/site-packages/IPython/lib/pretty.py in pretty(self, obj)\r\n    398                         if cls is not object \\\r\n    399                                 and callable(cls.dict.get('repr')):\r\n--> 400                             return reprpprint(obj, self, cycle)\r\n    401\r\n    402             return defaultpprint(obj, self, cycle)\r\n\r\n~/Envs/pandas-dev/lib/python3.6/site-packages/IPython/lib/pretty.py in reprpprint(obj, p, cycle)\r\n    693     \"\"\"A pprint that just redirects to the normal repr function.\"\"\"\r\n    694     # Find newlines and replace them with p.break()\r\n--> 695     output = repr(obj)\r\n    696     for idx,outputline in enumerate(output.splitlines()):\r\n    697         if idx:\r\n\r\n~/sandbox/pandas/pandas/core/base.py in repr(self)\r\n     80         Yields Bytestring in Py2, Unicode String in py3.\r\n     81         \"\"\"\r\n---> 82         return str(self)\r\n     83\r\n     84\r\n\r\n~/sandbox/pandas/pandas/core/base.py in str(self)\r\n     59\r\n     60         if compat.PY3:\r\n---> 61             return self.unicode()\r\n     62         return self.bytes()\r\n     63\r\n\r\n~/sandbox/pandas/pandas/core/arrays/categorical.py in unicode(self)\r\n   1942         \"\"\" Unicode representation. \"\"\"\r\n   1943         maxlen = 10\r\n-> 1944         if len(self.codes) > maxlen:\r\n   1945             result = self.tidyrepr(maxlen)\r\n   1946         elif len(self.codes) > 0:\r\n\r\nTypeError: len() of unsized object\r\n```\r\n\r\n- IntervalArray.take fails on `take`\r\n- SparseArray allows it.\r\n"},
{"text": "#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\nimport pandas as pd\r\ns = pd.Series([0.9999,2,3,4.0001])\r\nbins = 4\r\nhistdata = s.valuecounts(bins=bins, sort=False)\r\n\r\n\"\"\"histdata is shown below\r\n(0.996, 1.75]    1\r\n(1.75, 2.5]      1\r\n(2.5, 3.25]      1\r\n(3.25, 4.0]      1\r\ndtype: int64\r\n\"\"\"\r\n#The following statement should be true (according to the data returned by Series.valuecounts\r\nhistdata.index[-1].right >= s.iloc[-1]\r\n\r\n```\r\n#### Problem description\r\n\r\nvaluecounts returns a series.  The index of that series contains the histogram bin limits.  As shown in the code, histdata shows that there is 1 value in the range (3.25, 4.0], but that isn't the case. 4.0001 is not in that range.  It appears that the bin limits are truncated to 3 decimal places.  This does not appear to be a problem on the minimum value in the series as 0.9999 does lie in the range (0.996, 1.75].\r\n\r\n#### Expected Output\r\nTrue \r\n\r\n#### Output of ``pd.showversions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.6.6.final.0\r\npython-bits: 64\r\nOS: Windows\r\nOS-release: 10\r\nmachine: AMD64\r\nprocessor: Intel64 Family 6 Model 63 Stepping 2, GenuineIntel\r\nbyteorder: little\r\nLCALL: None\r\nLANG: None\r\nLOCALE: None.None\r\n\r\npandas: 0.23.3\r\npytest: 3.6.1\r\npip: 18.0\r\nsetuptools: 39.2.0\r\nCython: None\r\nnumpy: 1.14.5\r\nscipy: 1.1.0\r\npyarrow: None\r\nxarray: None\r\nIPython: 6.4.0\r\nsphinx: None\r\npatsy: None\r\ndateutil: 2.7.3\r\npytz: 2018.5\r\nblosc: None\r\nbottleneck: None\r\ntables: None\r\nnumexpr: None\r\nfeather: None\r\nmatplotlib: 2.2.2\r\nopenpyxl: None\r\nxlrd: None\r\nxlwt: None\r\nxlsxwriter: None\r\nlxml: None\r\nbs4: None\r\nhtml5lib: 1.0.1\r\nsqlalchemy: None\r\npymysql: None\r\npsycopg2: None\r\njinja2: 2.10\r\ns3fs: None\r\nfastparquet: None\r\npandasgbq: None\r\npandasdatareader: None\r\n</details>\r\n"},
{"text": "#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\nimport pandas as pd\r\nseries = pd.Series([1, 2, 3], pd.daterange('201701010000', '201701010030', freq='15min'))\r\nprint(pd.inferfreq(series.index))\r\n# Error\r\npd.Timedelta(pd.inferfreq(series.index))\r\n# While this works\r\npd.Timedelta(series.index.freq)\r\n```\r\n#### Problem description\r\n\r\npd.Timedelta constructor works with e.g. '15min' but not with '15T',\r\nwhile pd.inferfreq() returns '15T' and pd.Series.index.freq returns '15min'.\r\nThis leads to errors.\r\n\r\n#### Expected Output\r\n\r\nSame behaviour of pd.Timedelta() for 'min' and 'T' offset alias or deprecation of 'T' as an offset alias.\r\n\r\n#### Output of ``pd.showversions()``\r\n\r\n<details>\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.6.4.final.0\r\npython-bits: 64\r\nOS: Windows\r\nOS-release: 10\r\nmachine: AMD64\r\nprocessor: Intel64 Family 6 Model 142 Stepping 9, GenuineIntel\r\nbyteorder: little\r\nLCALL: None\r\nLANG: None\r\nLOCALE: None.None\r\npandas: 0.23.1\r\npytest: 3.6.2\r\npip: 10.0.1\r\nsetuptools: 39.2.0\r\nCython: None\r\nnumpy: 1.14.5\r\nscipy: 1.1.0\r\npyarrow: None\r\nxarray: None\r\nIPython: 6.4.0\r\nsphinx: None\r\npatsy: None\r\ndateutil: 2.7.3\r\npytz: 2018.5\r\nblosc: None\r\nbottleneck: None\r\ntables: None\r\nnumexpr: None\r\nfeather: None\r\nmatplotlib: 2.2.2\r\nopenpyxl: None\r\nxlrd: None\r\nxlwt: None\r\nxlsxwriter: None\r\nlxml: None\r\nbs4: None\r\nhtml5lib: None\r\nsqlalchemy: None\r\npymysql: None\r\npsycopg2: None\r\njinja2: None\r\ns3fs: None\r\nfastparquet: None\r\npandasgbq: None\r\npandasdatareader: None\r\n\r\n</details>\r\n"},
{"text": "#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\nimport pandas as pd\r\n\r\nset1 = ['a', 'b', 'c']\r\nset2 = ['1', '2', '3']\r\nset3 = ['test']\r\n\r\ntupleindex = [(s1, s2) for s1 in set1 for s2 in set2]\r\ndf = pd.DataFrame(index=tupleindex, columns=set3)\r\n\r\ndf.loc[('a', '1'), 'test'] = 5\r\nprint(df)  # Shows assignment occurs\r\nprint(df.loc[('a', '1'), 'test'])  # Raises KeyError: \"None of [('a', '1')] are in the [index]\"\r\n\r\n```\r\n#### Problem description\r\n\r\nIndexing with tuples is permitted only for setting but not getting.\r\n\r\n#### Expected Output\r\n\r\nShould either:\r\n1. Refuse to set the item because using tuple indicies is a silly idea, see #20991\r\n2. Successfully get the item.\r\n\r\n#### Output of ``pd.showversions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.6.2.final.0\r\npython-bits: 64\r\nOS: Windows\r\nOS-release: 10\r\nmachine: AMD64\r\nprocessor: Intel64 Family 6 Model 94 Stepping 3, GenuineIntel\r\nbyteorder: little\r\nLCALL: None\r\nLANG: None\r\nLOCALE: None.None\r\n\r\npandas: 0.22.0\r\npytest: 3.2.3\r\npip: 10.0.1\r\nsetuptools: 38.4.0\r\nCython: 0.27.3\r\nnumpy: 1.14.2\r\nscipy: 1.0.0\r\npyarrow: None\r\nxarray: None\r\nIPython: 6.3.1\r\nsphinx: None\r\npatsy: 0.5.0\r\ndateutil: 2.7.0\r\npytz: 2018.3\r\nblosc: None\r\nbottleneck: None\r\ntables: None\r\nnumexpr: None\r\nfeather: None\r\nmatplotlib: 2.0.2\r\nopenpyxl: 2.4.8\r\nxlrd: 1.1.0\r\nxlwt: None\r\nxlsxwriter: None\r\nlxml: 4.2.1\r\nbs4: 4.6.0\r\nhtml5lib: 1.0.1\r\nsqlalchemy: None\r\npymysql: None\r\npsycopg2: None\r\njinja2: 2.10\r\ns3fs: None\r\nfastparquet: None\r\npandasgbq: None\r\npandasdatareader: None\r\n\r\n</details>\r\nCredit @jameshowse for finding."},
{"text": "See #21427 \r\n\r\nThe issue is that a (non-`Day`) `Tick` object with `normalize=True` breaks addition monotonicity/associativity:\r\n\r\n```\r\nnow = pd.Timestamp.now()\r\ntick = pd.offsets.Minute(n=3, normalize=True)\r\n\r\n>>> now\r\nTimestamp('2018-06-11 17:38:10.135400')\r\n>>> now + tick\r\nTimestamp('2018-06-11 00:00:00')\r\n\r\n>>> now + 64*tick + 64*tick\r\nTimestamp('2018-06-11 00:00:00')\r\n>>> now + 128*tick\r\nTimestamp('2018-06-12 00:00:00')\r\n```\r\n\r\nThe `Day` tick doesn't have the same problem, but I'd prefer to disallow it rather than make it a double-special-case.  (See #20633 for more discussion about how `Day` should behave)"},
{"text": "I hadn't even noticed that `resolution` was a `datetime` property until now, but it returns `timedelta(0, 0, 1)`.  `Timestamp` doesn't override that.  I expect the correct thing to do is to return `Timedelta(nanoseconds=1)`.  Pretty low priority."},
{"text": "#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\nimport pandas\r\n\r\nclass List(list):\r\n    pass\r\n\r\npandas.DataFrame(List([List([1,2,3]), List([4,5,6])]))\r\n```\r\n```\r\nTypeError: Argument 'rows' has incorrect type (expected list, got List)\r\n```\r\n\r\n#### Problem description\r\n\r\nIt seems it is not possible to create a DataFrame from subclasses of lists. The code seems to have a too strict check.\r\n\r\n#### Expected Output\r\n\r\nIt should create a DataFrame like it would with regular lists.\r\n\r\n#### Output of ``pd.showversions()``\r\n\r\n<details>\r\n\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.6.3.final.0\r\npython-bits: 64\r\nOS: Linux\r\nOS-release: 4.13.0-41-generic\r\nmachine: x8664\r\nprocessor: x8664\r\nbyteorder: little\r\nLCALL: None\r\nLANG: enUS.UTF-8\r\nLOCALE: enUS.UTF-8\r\n\r\npandas: 0.22.0\r\npytest: 3.3.0\r\npip: 9.0.1\r\nsetuptools: 39.1.0\r\nCython: 0.28.2\r\nnumpy: 1.14.3\r\nscipy: 1.0.0\r\npyarrow: 0.9.0\r\nxarray: None\r\nIPython: 6.2.1\r\nsphinx: 1.7.4\r\npatsy: 0.4.1\r\ndateutil: 2.6.1\r\npytz: 2017.3\r\nblosc: None\r\nbottleneck: None\r\ntables: None\r\nnumexpr: None\r\nfeather: None\r\nmatplotlib: 2.1.0\r\nopenpyxl: None\r\nxlrd: None\r\nxlwt: None\r\nxlsxwriter: None\r\nlxml: None\r\nbs4: None\r\nhtml5lib: 0.999999999\r\nsqlalchemy: None\r\npymysql: None\r\npsycopg2: None\r\njinja2: 2.9.4\r\ns3fs: None\r\nfastparquet: None\r\npandasgbq: None\r\npandasdatareader: None\r\n\r\n\r\n</details>\r\n"},
{"text": "xref https://github.com/pandas-dev/pandas/pull/17361\r\n\r\n```\r\nIn [24]: df = pd.DataFrame({\"a\": [1, 2], \"b\": [3, 4]}, index=pd.Index([1, 2], name='a'))\r\n\r\nIn [25]: df.sortvalues(['a', 'b'])\r\n/Users/taugspurger/.virtualenvs/pandas-dev/bin/ipython:1: FutureWarning: 'a' is both an index level and a column label.\r\nDefaulting to column, but this will raise an ambiguity error in a future version\r\n  #!/Users/taugspurger/Envs/pandas-dev/bin/python3\r\nOut[25]:\r\n   a  b\r\na\r\n1  1  3\r\n2  2  4\r\n```\r\n\r\nWhat should the user do in this situation? Should we provide a keyword to disambiguate? A literal like `pd.ColumnLabel('a')` or `pd.IndexName('a')`? Or do we require that they rename an index or column? \r\nRight now, they're essentially stuck with the last one. If we want to discourage that, then I suppose that's OK. But it's somewhat common to end up with overlapping names, from e.g. a groupby.\r\n\r\ncc @jmmease "},
{"text": "#### Code Sample, a copy-pastable example if possible\r\n\r\n* `pd.readexcel()`\r\n```python\r\n>>> import pandas as pd\r\n>>> pd.readexcel('sampledata.xlsx', sheetname='Sheet2')\r\n      a   b       c\r\n0  this  is  sheet2\r\n>>> pd.readexcel('sampledata.xlsx', sheetname='Sheet2')\r\n/Users/<myname>/.pyenv/versions/miniconda3-latest/envs/py36/envs/py36/lib/python3.6/site-packages/pandas/util/decorators.py:118: FutureWarning: The `sheetname` keyword is deprecated, use `sheetname` instead\r\n  return func(*args, **kwargs)\r\n      a   b       c\r\n0  this  is  sheet2\r\n```\r\n\r\n* `ExcelFile.parse()`\r\n```python\r\n>>> import pandas as pd\r\n>>> xlsxfile=pd.ExcelFile('sampledata.xlsx')\r\n>>> xlsxfile.sheetnames\r\n['Sheet1', 'Sheet2', 'Sheet3']\r\n>>> xlsxfile.parse(sheetname='Sheet2')\r\n      a   b       c\r\n0  this  is  sheet2\r\n>>> xlsxfile.parse(sheetname='Sheet2')\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/Users/<myname>/.pyenv/versions/miniconda3-latest/envs/py36/envs/py36/lib/python3.6/site-packages/pandas/io/excel.py\", line 327, in parse\r\n    **kwds)\r\nTypeError: parseexcel() got multiple values for keyword argument 'sheetname'\r\n```\r\n\r\n#### Problem description\r\n\r\n* The document says ExcelFile.parse() is \"Equivalent to readexcel(ExcelFile, ...)\", but when using argument `sheetname`,which is deprecated, these two gives different results.\r\n  * pd.readexcel() works with `FutureWarning`, but ExcelFile.parse() gives `TypeError` instead.\r\n\r\n#### Expected Output\r\n\r\n ExcelFile.parse() should raise `FutureWarning` and use the value of `sheetname` as that of `sheetname`\r\n\r\n#### Output of ``pd.showversions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.6.4.final.0\r\npython-bits: 64\r\nOS: Darwin\r\nOS-release: 17.5.0\r\nmachine: x8664\r\nprocessor: i386\r\nbyteorder: little\r\nLCALL: None\r\nLANG: jaJP.UTF-8\r\nLOCALE: jaJP.UTF-8\r\n\r\npandas: 0.22.0\r\npytest: 3.3.2\r\npip: 9.0.1\r\nsetuptools: 38.4.0\r\nCython: 0.27.3\r\nnumpy: 1.14.0\r\nscipy: 1.0.0\r\npyarrow: None\r\nxarray: None\r\nIPython: 6.2.1\r\nsphinx: 1.6.6\r\npatsy: 0.5.0\r\ndateutil: 2.6.1\r\npytz: 2017.3\r\nblosc: None\r\nbottleneck: 1.2.1\r\ntables: 3.4.2\r\nnumexpr: 2.6.4\r\nfeather: None\r\nmatplotlib: 2.1.2\r\nopenpyxl: 2.4.10\r\nxlrd: 1.1.0\r\nxlwt: 1.2.0\r\nxlsxwriter: 1.0.2\r\nlxml: 4.1.1\r\nbs4: 4.6.0\r\nhtml5lib: 1.0.1\r\nsqlalchemy: 1.2.1\r\npymysql: None\r\npsycopg2: None\r\njinja2: 2.10\r\ns3fs: None\r\nfastparquet: None\r\npandasgbq: None\r\npandasdatareader: None\r\n</details>\r\n"},
{"text": "#### well, my function's input is ndarray-like and it's output is a scaler. The question is I have no method to apply this function on rolling object.\r\n\r\n```python\r\nfrom sklearn.decomposition import PCA\r\n\r\ndf = pd.DataFrame({\"A\": [1, 2, 3, 4, 5, 6, 7, 8], \"B\": [2, 3, 4, 5, 6, 7, 8, 9]})\r\n\r\ndef firstvariance(X):\r\n    pca = PCA(ncomponents=1)\r\n    pca.fit(X)\r\n    return pca.explainedvariance\r\n\r\ndf.rolling(4).apply(firstvariance)\r\n\r\n```\r\n#### The domo is incorrect because the \"apply\" method only can apply by index or column.\r\n"},
{"text": "If I add two `Series` objects, both of which contain the same duplicate label, it appears that I get a result in which every possible combination for that label appears. In the below: `s1` has the label `b` twice, `s2` has the label `b` thrice, and the result has the label `b` six times.\r\n\r\n```python\r\nPython 3.6.5 (default, Mar 29 2018, 15:37:32) \r\n[GCC 4.2.1 Compatible Apple LLVM 9.0.0 (clang-900.0.39.2)] on darwin\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import pandas as pd\r\n>>> s1 = pd.Series(range(3), list('abb'))\r\n>>> s2 = pd.Series(range(4), list('abbb'))\r\n>>> s1 + s2\r\na    0\r\nb    2\r\nb    3\r\nb    4\r\nb    3\r\nb    4\r\nb    5\r\ndtype: int64\r\n```\r\n\r\nThat doesn't seem an unreasonable behaviour, but it's not applied consistently. If instead the second series has the same number of occurrences, then the data entries are added elementwise:\r\n```python\r\n>>> s3 = pd.Series(range(3), list('abb'))\r\n>>> s4 = pd.Series(range(3), list('abb'))\r\n>>> s3 + s4\r\na    0\r\nb    2\r\nb    4\r\ndtype: int64\r\n```\r\n\r\nThat seems to make the \"outer product\" behaviour in the first example somewhat dangerous, because any code that depends on it is at risk of giving inconsistent results if it happens to get a dataset where the numbers of the various labels match exactly. Should the second behaviour be altered to be consistent with the first? Or should maybe the first behaviour become an error (after a suitable deprecation period)?\r\n\r\n#### Output of ``pd.showversions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.6.5.final.0\r\npython-bits: 64\r\nOS: Darwin\r\nOS-release: 17.5.0\r\nmachine: x8664\r\nprocessor: i386\r\nbyteorder: little\r\nLCALL: None\r\nLANG: enGB.UTF-8\r\nLOCALE: enGB.UTF-8\r\n\r\npandas: 0.22.0\r\npytest: None\r\npip: 10.0.0\r\nsetuptools: 39.0.1\r\nCython: 0.28.2\r\nnumpy: 1.14.2\r\nscipy: 1.0.1\r\npyarrow: None\r\nxarray: None\r\nIPython: 6.3.1\r\nsphinx: None\r\npatsy: None\r\ndateutil: 2.6.1\r\npytz: 2018.4\r\nblosc: None\r\nbottleneck: 1.2.1\r\ntables: 3.4.2\r\nnumexpr: 2.6.4\r\nfeather: None\r\nmatplotlib: 2.2.2\r\nopenpyxl: None\r\nxlrd: None\r\nxlwt: None\r\nxlsxwriter: None\r\nlxml: None\r\nbs4: None\r\nhtml5lib: 1.0.1\r\nsqlalchemy: None\r\npymysql: None\r\npsycopg2: None\r\njinja2: 2.10\r\ns3fs: None\r\nfastparquet: None\r\npandasgbq: None\r\npandasdatareader: None\r\n\r\n</details>\r\n"},
{"text": "#### Code Sample\r\n\r\n```python\r\nIn [61]: dftest = pd.DataFrame({\"A\":[1,1,2,2],\"B\":[1,1,1,1]})\r\n\r\nIn [62]: dftest.groupby(\"B\").rank(method=\"dense\", ascending=True, pct=False, naoption='top')\r\nOut[62]:\r\n     A\r\n0  1.0\r\n1  1.0\r\n2  2.0\r\n3  2.0\r\n\r\nIn [63]: dftest.groupby(\"B\").rank(method=\"dense\", ascending=True, pct=True, naoption='top')\r\nOut[63]:\r\n      A\r\n0  0.25\r\n1  0.25\r\n2  0.50\r\n3  0.50\r\n```\r\n#### Problem description\r\n``pd.groupby.rank`` result does not scale to 100% when method is \"dense\". \r\n#### Expected Output\r\n``` python\r\nIn [65]: dftest['A'].rank(method=\"dense\", ascending=True, pct=True, naoption='top')\r\nOut[65]:\r\n0    0.5\r\n1    0.5\r\n2    1.0\r\n3    1.0\r\nName: A, dtype: float64\r\n```\r\n#### Output of ``pd.showversions()``\r\n\r\n<details>\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: 448124c138dc39001638aacd68f253b1034d7f04\r\npython: 3.6.4.final.0\r\npython-bits: 64\r\nOS: Windows\r\nOS-release: 7\r\nmachine: AMD64\r\nprocessor: Intel64 Family 6 Model 60 Stepping 3, GenuineIntel\r\nbyteorder: little\r\nLCALL: None\r\nLANG: zhCN.UTF-8\r\nLOCALE: None.None\r\n\r\npandas: 0.23.0.dev0+743.g448124c13\r\npytest: 3.3.2\r\npip: 9.0.1\r\nsetuptools: 38.4.0\r\nCython: 0.27.3\r\nnumpy: 1.14.0\r\nscipy: 1.0.0\r\npyarrow: None\r\nxarray: None\r\nIPython: 6.2.1\r\nsphinx: 1.6.7\r\npatsy: 0.5.0\r\ndateutil: 2.6.1\r\npytz: 2017.3\r\nblosc: None\r\nbottleneck: 1.2.1\r\ntables: 3.4.2\r\nnumexpr: 2.6.4\r\nfeather: None\r\nmatplotlib: 2.1.2\r\nopenpyxl: 2.4.10\r\nxlrd: 1.1.0\r\nxlwt: 1.3.0\r\nxlsxwriter: 1.0.2\r\nlxml: 4.1.1\r\nbs4: 4.6.0\r\nhtml5lib: 1.0.1\r\nsqlalchemy: 1.2.1\r\npymysql: 0.7.11.None\r\npsycopg2: None\r\njinja2: 2.10\r\ns3fs: None\r\nfastparquet: None\r\npandasgbq: None\r\npandasdatareader: None\r\n\r\n</details>\r\n"},
{"text": "#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\nIn [1]: import pandas as pd\r\n\r\nIn [2]: s1 = pd.Series([1,2,3], index=pd.Index([1,2,3], name=\"T\"))\r\n\r\nIn [3]: s1\r\nOut[3]:\r\nT\r\n1    1\r\n2    2\r\n3    3\r\ndtype: int64\r\n\r\nIn [4]: s2 = pd.Series([10,20,30], index=pd.Index([1,2,3], name=\"Time\"))\r\n\r\nIn [5]: s2\r\nOut[5]:\r\nTime\r\n1    10\r\n2    20\r\n3    30\r\ndtype: int64\r\n\r\nIn [6]: s1.align(s2)\r\nOut[6]:\r\n(T\r\n 1    1\r\n 2    2\r\n 3    3\r\n dtype: int64, Time\r\n 1    10\r\n 2    20\r\n 3    30\r\n dtype: int64)\r\n\r\nIn [7]: s3 = pd.Series([1,2,4], index=pd.Index([1,2,4], name=\"T\"))\r\n\r\nIn [8]: s3\r\nOut[8]:\r\nT\r\n1    1\r\n2    2\r\n4    4\r\ndtype: int64\r\n\r\nIn [9]: s3.align(s2)\r\nOut[9]:\r\n(1    1.0\r\n 2    2.0\r\n 3    NaN\r\n 4    4.0\r\n dtype: float64, 1    10.0\r\n 2    20.0\r\n 3    30.0\r\n 4     NaN\r\n dtype: float64)\r\n\r\nIn [10]: s4 = pd.Series([10,20,30], index=pd.Index([1,2,3], name=\"T\"))\r\n\r\nIn [11]: s4\r\nOut[11]:\r\nT\r\n1    10\r\n2    20\r\n3    30\r\ndtype: int64\r\n\r\nIn [12]: s3.align(s4)\r\nOut[12]:\r\n(T\r\n 1    1.0\r\n 2    2.0\r\n 3    NaN\r\n 4    4.0\r\n dtype: float64, T\r\n 1    10.0\r\n 2    20.0\r\n 3    30.0\r\n 4     NaN\r\n dtype: float64)\r\n\r\nIn [15]: s1 + s2\r\nOut[15]:\r\nT\r\n1    11\r\n2    22\r\n3    33\r\ndtype: int64\r\n\r\nIn [16]: s2 + s1\r\nOut[16]:\r\nTime\r\n1    11\r\n2    22\r\n3    33\r\ndtype: int64\r\n\r\n```\r\n#### Problem description\r\n\r\nIt's not clear if this is a bug or a feature, and if the latter, then the behavior should be documented.\r\n\r\nIn the first example `s1.align(s2)`, the two series have the same index values, but the names of the respective index for each series is different.  In this case, `s1.align(s2)` returns the two series, preserving the names of the respective indexes.\r\n\r\nIn the second example, `s3.align(s2)`, the two series have different index values, and the names of the respective index for each series is different.   In this case, `s3.align(s2)` returns the two series, but the names of the indices have disappeared.\r\n\r\nIn the third example, `s3.align(s4)`, the two series have different index values, and the names of the respective index for each series is the same.   In this case, `s3.align(s4)` returns the two series, and the names of each index are the same name.\r\n\r\nSo in the first two cases, the names are different, but in the first case, the names are preserved, while in the second case, the names are lost.\r\n\r\nIn the last two cases, the index values are the different, but the names are preserved if they are the same, otherwise they are lost.\r\n\r\nFinally, the last 2 examples, involving addition show some asymmetries due to this issue with `Series.align()` with respect to name handling when adding two series with different names.  In this case, `s1+s2` and `s2+s1` have indices with different names, which seems a bit odd.\r\n\r\n#### Expected Output\r\n\r\nThis is not clear to me.  Either\r\n1. If the names are different, then return no names on the corresponding indexes\r\n2. If the names are different, then raise an Exception\r\n\r\n#### Output of ``pd.showversions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: 6c1ab7f2c0ec13237c383f5c485d92e8ce158b14\r\npython: 3.6.4.final.0\r\npython-bits: 64\r\nOS: Windows\r\nOS-release: 10\r\nmachine: AMD64\r\nprocessor: Intel64 Family 6 Model 60 Stepping 3, GenuineIntel\r\nbyteorder: little\r\nLCALL: None\r\nLANG: None\r\nLOCALE: None.None\r\n\r\npandas: 0.23.0.dev0+685.g6c1ab7f2c\r\npytest: 3.3.2\r\npip: 9.0.1\r\nsetuptools: 38.4.0\r\nCython: 0.27.3\r\nnumpy: 1.14.0\r\nscipy: 1.0.0\r\npyarrow: None\r\nxarray: None\r\nIPython: 6.2.1\r\nsphinx: 1.6.6\r\npatsy: 0.5.0\r\ndateutil: 2.6.1\r\npytz: 2017.3\r\nblosc: None\r\nbottleneck: 1.2.1\r\ntables: 3.4.2\r\nnumexpr: 2.6.4\r\nfeather: None\r\nmatplotlib: 2.1.2\r\nopenpyxl: 2.4.10\r\nxlrd: 1.1.0\r\nxlwt: 1.3.0\r\nxlsxwriter: 1.0.2\r\nlxml: 4.1.1\r\nbs4: 4.6.0\r\nhtml5lib: 1.0.1\r\nsqlalchemy: 1.2.1\r\npymysql: 0.7.11.None\r\npsycopg2: None\r\njinja2: 2.10\r\ns3fs: None\r\nfastparquet: None\r\npandasgbq: None\r\npandasdatareader: None\r\n</details>\r\n"},
{"text": "I think I got a bug here.\r\n```python\r\nimport pandas as pd\r\ndf = pd.DataFrame({\"A\": [1, 2, 3, 4, 5], \"B\": [3.125, 4.12, 3.1, 6.2, 7.],\"C\":['a','a','b','b','a']})\r\na=df.pivot(index=\"A\",columns=\"C\",values=\"B\")\r\nb=a.copy()\r\ndef func(x):\r\n    x['a']=3\r\na.apply(func,axis=1)\r\nb.apply(func,axis=1)\r\n\r\nIn [2]: a\r\nOut[2]:\r\nC    a    b\r\nA\r\n1  3.0  NaN\r\n2  3.0  NaN\r\n3  3.0  3.1\r\n4  3.0  6.2\r\n5  3.0  NaN\r\n\r\nIn [3]: b\r\nOut[3]:\r\nC      a    b\r\nA\r\n1  3.125  NaN\r\n2  4.120  NaN\r\n3    NaN  3.1\r\n4    NaN  6.2\r\n5  7.000  NaN\r\n```\r\nFirst, I get `a` after call pivot on the  dataframe `df`, and `b,` which is a copy of `a`. Then I call apply on `a` and `b` respectively. Now we can see the `a` and `b` is different.\r\n"},
{"text": "#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\nIn [1]: import pandas as pd\r\n\r\nIn [2]: pd.version\r\nOut[2]: '0.23.0.dev0+657.g01882ba5b'\r\n\r\nIn [3]: df1 =  pd.DataFrame({'v1' : range(12)}, index=pd.MultiIndex.fromproduct([list('abc'),list('xy'),[1,2]], names=['abc','xy','num']))\r\n   ...: df1\r\n   ...:\r\nOut[3]:\r\n            v1\r\nabc xy num\r\na   x  1     0\r\n       2     1\r\n    y  1     2\r\n       2     3\r\nb   x  1     4\r\n       2     5\r\n    y  1     6\r\n       2     7\r\nc   x  1     8\r\n       2     9\r\n    y  1    10\r\n       2    11\r\n\r\nIn [4]: df2 = pd.DataFrame({'v2': [100*i for i in range(1,7)]}, index=pd.MultiIndex.fromproduct([list('abc'), list('xy')],names=['abc','xy']))\r\n\r\nIn [5]: df2\r\nOut[5]:\r\n         v2\r\nabc xy\r\na   x   100\r\n    y   200\r\nb   x   300\r\n    y   400\r\nc   x   500\r\n    y   600\r\n\r\nIn [6]: df1.merge(df2, on=['abc','xy'])  # 'num' disappears\r\nOut[6]:\r\n        v1   v2\r\nabc xy\r\na   x    0  100\r\n    x    1  100\r\n    y    2  200\r\n    y    3  200\r\nb   x    4  300\r\n    x    5  300\r\n    y    6  400\r\n    y    7  400\r\nc   x    8  500\r\n    x    9  500\r\n    y   10  600\r\n    y   11  600\r\n\r\nIn [7]: df1.resetindex().merge(df2, on=['abc','xy']) # This preserves 'num'\r\nOut[7]:\r\n   abc xy  num  v1   v2\r\n0    a  x    1   0  100\r\n1    a  x    2   1  100\r\n2    a  y    1   2  200\r\n3    a  y    2   3  200\r\n4    b  x    1   4  300\r\n5    b  x    2   5  300\r\n6    b  y    1   6  400\r\n7    b  y    2   7  400\r\n8    c  x    1   8  500\r\n9    c  x    2   9  500\r\n10   c  y    1  10  600\r\n11   c  y    2  11  600\r\n\r\nIn [8]: df1.merge(df2, on='xy')  # 'abc' and 'num' disappear\r\nOut[8]:\r\n    v1   v2\r\nxy\r\nx    0  100\r\nx    0  300\r\nx    0  500\r\nx    1  100\r\nx    1  300\r\nx    1  500\r\nx    4  100\r\nx    4  300\r\nx    4  500\r\nx    5  100\r\nx    5  300\r\nx    5  500\r\nx    8  100\r\nx    8  300\r\nx    8  500\r\nx    9  100\r\nx    9  300\r\nx    9  500\r\ny    2  200\r\ny    2  400\r\ny    2  600\r\ny    3  200\r\ny    3  400\r\ny    3  600\r\ny    6  200\r\ny    6  400\r\ny    6  600\r\ny    7  200\r\ny    7  400\r\ny    7  600\r\ny   10  200\r\ny   10  400\r\ny   10  600\r\ny   11  200\r\ny   11  400\r\ny   11  600\r\n\r\n```\r\n#### Problem description\r\n\r\nIt seems that the new feature implemented in #17484 that allows merging on a combination of columns and index levels can drop index levels, which is really non-intuitive.  In the first example, the index level named \"num\" gets dropped, while in the last example, both \"abc\" and \"xy\" are dropped.\r\n\r\nIf this is the desired behavior, then it needs to be carefully documented.\r\n\r\nN.B. There is also an error in the docs of merging.rst that says this feature was introduced in v.0.22, but it will be introduced in v0.23\r\n\r\nI'm guessing @jmmease will need to look at this.\r\n\r\n#### Expected Output\r\n\r\n```python\r\nIn [6]: df1.merge(df2, on=['abc','xy'])\r\nOut[6]:\r\n            v1   v2\r\nabc xy num\r\na   x  1     0  100\r\n       2     1  100\r\n    y  1     2  200\r\n       2     3  200\r\nb   x  1     4  300\r\n       2     5  300\r\n    y  1     6  400\r\n       2     7  400\r\nc   x  1     8  500\r\n       2     9  500\r\n    y  1    10  600\r\n       2    11  600\r\n\r\nIn [8]: df1.merge(df2, on='xy')\r\nOut[8]:\r\n   abcx  num  v1 abcy   v2\r\nxy\r\nx      a    1   0     a  100\r\nx      a    1   0     b  300\r\nx      a    1   0     c  500\r\nx      a    2   1     a  100\r\nx      a    2   1     b  300\r\nx      a    2   1     c  500\r\nx      b    1   4     a  100\r\nx      b    1   4     b  300\r\nx      b    1   4     c  500\r\nx      b    2   5     a  100\r\nx      b    2   5     b  300\r\nx      b    2   5     c  500\r\nx      c    1   8     a  100\r\nx      c    1   8     b  300\r\nx      c    1   8     c  500\r\nx      c    2   9     a  100\r\nx      c    2   9     b  300\r\nx      c    2   9     c  500\r\ny      a    1   2     a  200\r\ny      a    1   2     b  400\r\ny      a    1   2     c  600\r\ny      a    2   3     a  200\r\ny      a    2   3     b  400\r\ny      a    2   3     c  600\r\ny      b    1   6     a  200\r\ny      b    1   6     b  400\r\ny      b    1   6     c  600\r\ny      b    2   7     a  200\r\ny      b    2   7     b  400\r\ny      b    2   7     c  600\r\ny      c    1  10     a  200\r\ny      c    1  10     b  400\r\ny      c    1  10     c  600\r\ny      c    2  11     a  200\r\ny      c    2  11     b  400\r\ny      c    2  11     c  600\r\n```\r\n\r\n#### Output of ``pd.showversions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.6.4.final.0\r\npython-bits: 64\r\nOS: Windows\r\nOS-release: 10\r\nmachine: AMD64\r\nprocessor: Intel64 Family 6 Model 60 Stepping 3, GenuineIntel\r\nbyteorder: little\r\nLCALL: None\r\nLANG: None\r\nLOCALE: None.None\r\n\r\npandas: 0.23.0.dev0+657.g01882ba5b\r\npytest: 3.4.0\r\npip: 9.0.1\r\nsetuptools: 38.5.1\r\nCython: 0.25.1\r\nnumpy: 1.14.1\r\nscipy: 1.0.0\r\npyarrow: 0.8.0\r\nxarray: None\r\nIPython: 6.2.1\r\nsphinx: 1.7.1\r\npatsy: 0.5.0\r\ndateutil: 2.6.1\r\npytz: 2018.3\r\nblosc: 1.5.1\r\nbottleneck: 1.2.1\r\ntables: 3.4.2\r\nnumexpr: 2.6.4\r\nfeather: None\r\nmatplotlib: 2.2.0\r\nopenpyxl: 2.5.0\r\nxlrd: 1.1.0\r\nxlwt: 1.3.0\r\nxlsxwriter: 1.0.2\r\nlxml: 4.1.1\r\nbs4: 4.6.0\r\nhtml5lib: 1.0.1\r\nsqlalchemy: 1.2.5\r\npymysql: 0.8.0\r\npsycopg2: None\r\njinja2: 2.10\r\ns3fs: 0.1.3\r\nfastparquet: None\r\npandasgbq: None\r\npandasdatareader: None\r\n\r\n</details>\r\n"},
{"text": "``Index.strftime`` should be returning an ``Index`` and not an array, we do this for other accessors. see https://github.com/pandas-dev/pandas/pull/20103/files#r173622263\r\n\r\n\r\n\r\n```\r\nIn [6]: pd.daterange('20130101',periods=3).hour\r\nOut[6]: Int64Index([0, 0, 0], dtype='int64')\r\n\r\nIn [7]: pd.daterange('20130101',periods=3).strftime('%Y%m%d')\r\nOut[7]: array(['20130101', '20130102', '20130103'], dtype='<U8')\r\n```"},
{"text": "#### Code Sample\r\n\r\n```python\r\ndf = pd.DataFrame({\"date\": ['10000101', '20180220']})\r\n\r\n# Timestamp limitations correctly raise exception\r\npd.todatetime(df.date, errors='raise')\r\n...\r\nOutOfBoundsDatetime: Out of bounds nanosecond timestamp: 1000-01-01 00:00:00\r\n\r\n# Timestamp limitations correctly coerce to NaT\r\npd.todatetime(df.date, errors='coerce')\r\n...\r\n0          NaT\r\n1   2018-02-20\r\nName: date, dtype: datetime64[ns]\r\n\r\n# errors=`ignore` incorrectly results in datetime like object\r\npd.todatetime(df.date, errors='ignore', format=\"%Y%m%d\")\r\n0    1000-01-01 00:00:00\r\n1    2018-02-20 00:00:00\r\nName: date, dtype: object\r\n```\r\n#### Problem description\r\n\r\nI believe that when `errors='ignore'`, and the timestamp limitations are violated by a datum, the result [should be the original input](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.todatetime.html) \u2013 not a datetime like object.\r\n\r\n#### Expected Output\r\n\r\n```python\r\npd.todatetime(df.date, errors='ignore', format=\"%Y%m%d\")\r\n0    '10000101'\r\n1    2018-02-20 00:00:00\r\nName: date, dtype: object\r\n```\r\n\r\n#### Output of ``pd.showversions()``\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.5.2.final.0\r\npython-bits: 64\r\nOS: Darwin\r\nOS-release: 16.7.0\r\nmachine: x8664\r\nprocessor: i386\r\nbyteorder: little\r\nLCALL: None\r\nLANG: enUS.UTF-8\r\nLOCALE: enUS.UTF-8\r\n\r\npandas: 0.21.0\r\npytest: 2.9.2\r\npip: 9.0.1\r\nsetuptools: 27.2.0\r\nCython: 0.24.1\r\nnumpy: 1.11.1\r\nscipy: 0.18.1\r\npyarrow: None\r\nxarray: None\r\nIPython: 5.1.0\r\nsphinx: 1.4.6\r\npatsy: 0.4.1\r\ndateutil: 2.5.3\r\npytz: 2016.6.1\r\nblosc: None\r\nbottleneck: 1.1.0\r\ntables: 3.2.3.1\r\nnumexpr: 2.6.1\r\nfeather: None\r\nmatplotlib: 1.5.3\r\nopenpyxl: 2.3.2\r\nxlrd: 1.0.0\r\nxlwt: 1.2.0\r\nxlsxwriter: 0.9.3\r\nlxml: 3.6.4\r\nbs4: 4.5.1\r\nhtml5lib: None\r\nsqlalchemy: 1.0.13\r\npymysql: None\r\npsycopg2: None\r\njinja2: 2.8\r\ns3fs: None\r\nfastparquet: None\r\npandasgbq: None\r\npandasdatareader: None\r\n\r\n</details>\r\n"},
{"text": "#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\ndf = pd.concat([pd.DataFrame({'x':np.random.randn(3), 'gp': 'a'}), pd.DataFrame({'x':np.random.randn(3), 'gp': 'b'})])\r\ndf.groupby('gp')['x'].cumsum(skipna=False)\r\n```\r\n#### Problem description\r\n\r\nDataFrame.cumsum(skipna=False) works. \r\nBut DataFrame.groupby['var'].cumsum(skipna=False) does not work. \r\n\r\nas seen from the above codes. Error message says numpy operations are not valid with groupby. This is inconsistent behavior, and is in conflict with docs http://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.core.groupby.DataFrameGroupBy.cumsum.html\r\n\r\n"},
{"text": "Index op naming and pinning is inconsistent:\r\n\r\n - no `Index.rsub`, https://github.com/pandas-dev/pandas/blob/master/pandas/core/indexes/base.py#L2200\r\n- `iadd, isub` aren't getting pinned to `cls` https://github.com/pandas-dev/pandas/blob/master/pandas/core/indexes/base.py#L3998\r\n- `radd, rpow, rmul, ...` aren't getting the correct names (not such a big deal)\r\n- numeric subclass methods names:\r\n\r\n```\r\n>>> pd.Int64Index.add.name\r\n'evaluatenumericbinop'\r\n>>> pd.Float64Index.mul.name\r\n'evaluatenumericbinop'\r\n>>> pd.DatetimeIndex.radd.name\r\n'add'\r\n```"},
{"text": "```\r\nIn [1]: import pandas as pd\r\n\r\nIn [2]: pd.Categorical(['a', 'b', None]).fillna({2: 'a'})\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-2-099b4b7d5652> in <module>()\r\n----> 1 pd.Categorical(['a', 'b', None]).fillna({2: 'a'})\r\n\r\n~/Envs/pandas-dev/lib/python3.6/site-packages/pandas/pandas/util/decorators.py in wrapper(*args, **kwargs)\r\n    136                 else:\r\n    137                     kwargs[newargname] = newargvalue\r\n--> 138             return func(*args, **kwargs)\r\n    139         return wrapper\r\n    140     return deprecatekwarg\r\n\r\n~/Envs/pandas-dev/lib/python3.6/site-packages/pandas/pandas/core/arrays/categorical.py in fillna(self, value, method, limit)\r\n   1661                 raise TypeError('\"value\" parameter must be a scalar, dict '\r\n   1662                                 'or Series, but you passed a '\r\n-> 1663                                 '\"{0}\"'.format(type(value).name))\r\n   1664\r\n   1665         return self.constructor(values, categories=self.categories,\r\n\r\nTypeError: \"value\" parameter must be a scalar, dict or Series, but you passed a \"dict\"\r\n```\r\n\r\nI suppose that mappings don't make sense for `Categorical.fillna`\r\n\r\nAlso... this seems strange...\r\n\r\n```python\r\nIn [10]: pd.Categorical(['a', 'b', None]).fillna(pd.Series(['a'], index=[0, 1, 2]))\r\nOut[10]:\r\n[a, a, a]\r\nCategories (2, object): [a, b]\r\n```\r\n\r\nWe shouldn't be affecting valid values here.\r\n\r\nPerhaps best to just raise for all series / dict like? Unless I'm missing something."},
{"text": "```python\r\nIn [3]: pd.Categorical(['a', 'b']).fillna(value='a', method='ffill')\r\nOut[3]:\r\n[a, b]\r\nCategories (2, object): [a, b]\r\n\r\nIn [4]: pd.Series(pd.Categorical(['a', 'b'])).fillna(value='a', method='ffill')\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-4-141070886f71> in <module>()\r\n----> 1 pd.Series(pd.Categorical(['a', 'b'])).fillna(value='a', method='ffill')\r\n\r\n~/sandbox/pandas-ip/pandas/pandas/core/series.py in fillna(self, value, method, axis, inplace, limit, downcast, **kwargs)\r\n   2659                                           axis=axis, inplace=inplace,\r\n   2660                                           limit=limit, downcast=downcast,\r\n-> 2661                                           **kwargs)\r\n   2662\r\n   2663     @Appender(generic.shareddocs['replace'] % shareddockwargs)\r\n\r\n~/sandbox/pandas-ip/pandas/pandas/core/generic.py in fillna(self, value, method, axis, inplace, limit, downcast)\r\n   4745         else:\r\n   4746             if method is not None:\r\n-> 4747                 raise ValueError('cannot specify both a fill method and value')\r\n   4748\r\n   4749             if len(self.getaxis(axis)) == 0:\r\n\r\nValueError: cannot specify both a fill method and value\r\n\r\n\r\n```\r\n\r\nBoth of these should raise. PR coming shortly."},
{"text": "Follow-up issue on https://github.com/pandas-dev/pandas/pull/18577\r\n\r\nIn that PR @jreback cleaned up the `apply(..., axis=1)` result shape inconsistencies, and we added a keyword to control this.\r\n\r\nFor example, when the applied function returns an array or a list, it now defaults to returning a Series of those objects, or expanding it to multiple columns if you pass `resulttype` explicitly:\r\n\r\n```\r\nIn [1]: df = pd.DataFrame(np.tile(np.arange(3), 4).reshape(4, -1) + 1, columns=['A', 'B', 'C'], index=pd.daterange(\"2012-01-01\", periods=4))\r\n\r\nIn [2]: df\r\nOut[2]: \r\n            A  B  C\r\n2012-01-01  1  2  3\r\n2012-01-02  1  2  3\r\n2012-01-03  1  2  3\r\n2012-01-04  1  2  3\r\n\r\nIn [3]: df.apply(lambda x: np.array([0, 1, 2]), axis=1)\r\nOut[3]: \r\n2012-01-01    [0, 1, 2]\r\n2012-01-02    [0, 1, 2]\r\n2012-01-03    [0, 1, 2]\r\n2012-01-04    [0, 1, 2]\r\nFreq: D, dtype: object\r\n\r\nIn [4]: df.apply(lambda x: np.array([0, 1, 2]), axis=1, resulttype='expand')\r\nOut[4]: \r\n            0  1  2\r\n2012-01-01  0  1  2\r\n2012-01-02  0  1  2\r\n2012-01-03  0  1  2\r\n2012-01-04  0  1  2\r\n\r\nIn [5]: df.apply(lambda x: np.array([0, 1, 2]), axis=1, resulttype='broadcast')\r\nOut[5]: \r\n            A  B  C\r\n2012-01-01  0  1  2\r\n2012-01-02  0  1  2\r\n2012-01-03  0  1  2\r\n2012-01-04  0  1  2\r\n```\r\n\r\nHowever, for `axis=0`, the default, we don't yet follow the same rules / the keyword in all cases. Some examples:\r\n    \r\n*  For list, it depends on the length (and if the length matches, it preserves the original index instead of new range index):\r\n    ```\r\n    In [16]: df.apply(lambda x: [0, 1, 2, 3])\r\n    Out[16]: \r\n                A  B  C\r\n    2012-01-01  0  0  0\r\n    2012-01-02  1  1  1\r\n    2012-01-03  2  2  2\r\n    2012-01-04  3  3  3\r\n\r\n    In [17]: df.apply(lambda x: [0, 1, 2, 3, 4])\r\n    Out[17]: \r\n    A    [0, 1, 2, 3, 4]\r\n    B    [0, 1, 2, 3, 4]\r\n    C    [0, 1, 2, 3, 4]\r\n    dtype: object\r\n    ```\r\n\r\n    (`resulttype='expand'` and `resulttype='broadcast'` do work correctly here)\r\n\r\n*   For an array, it expands when the length does not match (so different as for `axis=1`, and also different as for list):\r\n\r\n    ```\r\n    In [23]: df.apply(lambda x: np.array([0, 1, 2, 3]))\r\n    Out[23]: \r\n                A  B  C\r\n    2012-01-01  0  0  0\r\n    2012-01-02  1  1  1\r\n    2012-01-03  2  2  2\r\n    2012-01-04  3  3  3\r\n\r\n    In [24]: df.apply(lambda x: np.array([0, 1, 2, 3, 4]))\r\n    Out[24]: \r\n       A  B  C\r\n    0  0  0  0\r\n    1  1  1  1\r\n    2  2  2  2\r\n    3  3  3  3\r\n    4  4  4  4\r\n    ```\r\n\r\nSo the question is: should we follow the same rules for `axis=0` as for `axis=1`? \r\nI would say: ideally yes. But doing so might break some behaviour (although it might be possible to do that with warnings).\r\n\r\n\r\n     \r\n     \r\n     \r\n \r\n \r\n \r\n \r\n \r\n \r\n \r\n \r\n "},
{"text": "Series[not-categorical] > CategoricalIndex is inconsistent with the reversed operation.  Which one is canonical?\r\n\r\n```\r\nser = pd.Series([1, 2, 3])\r\nidx = pd.CategoricalIndex(['A', 'B', 'A'])\r\n\r\n>>> ser > idx\r\n0    False\r\n1    False\r\n2    False\r\n\r\n>>> idx < ser\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"pandas/core/indexes/category.py\", line 752, in evaluatecompare\r\n    return getattr(self.values, opname)(other)\r\n  File \"pandas/core/arrays/categorical.py\", line 56, in f\r\n    raise TypeError(\"Unordered Categoricals can only compare \"\r\nTypeError: Unordered Categoricals can only compare equality or not\r\n\r\n>>> ser > idx.values\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"pandas/core/ops.py\", line 819, in wrapper\r\n    .format(op=op, typ=self.dtype))\r\nTypeError: Cannot compare a Categorical for op <built-in function gt> with Series of dtype int64.\r\nIf you want to compare values, use 'series <op> np.asarray(other)'.\r\n```\r\n\r\nI'm guessing the right thing to do is to a) have `Series[categorical].op` wrap `CategoricalIndex.op`, and b) have `Series[non-categorical]` to dispatch to reversed-op for `iscategoricaldtype(other)`, want to confirm before making a PR."},
{"text": "#### Code Sample, a copy-pastable example if possible\r\n\r\nThe `closed` parameter of `IntervalIndex` is currently a bit inconsistent, and it's behavior is input dependent.  By my count, there are 3 different behaviors:\r\n\r\n**1.  `closed` parameter overrides the inferred `closed` when the input data is empty or purely NA**\r\n```python\r\nIn [2]: pd.IntervalIndex([], closed='both')\r\nOut[2]:\r\nIntervalIndex([]\r\n              closed='both',\r\n              dtype='interval[int64]')\r\n\r\nIn [3]: pd.IntervalIndex([np.nan, np.nan], closed='neither')\r\nOut[3]:\r\nIntervalIndex([nan, nan]\r\n              closed='neither',\r\n              dtype='interval[float64]')\r\n```\r\n\r\n**2. `closed` is ignored when the input data is an `IntervalIndex`:**\r\n```python\r\nIn [4]: ii = pd.intervalrange(0, 3, closed='both')\r\n\r\nIn [5]: ii\r\nOut[5]:\r\nIntervalIndex([[0, 1], [1, 2], [2, 3]]\r\n              closed='both',\r\n              dtype='interval[int64]')\r\n\r\nIn [6]: pd.IntervalIndex(ii, closed='neither')\r\nOut[6]:\r\nIntervalIndex([[0, 1], [1, 2], [2, 3]]\r\n              closed='both',\r\n              dtype='interval[int64]')\r\n```\r\n\r\n**3. `closed` raises a `ValueError` when a list-like of `Interval` objects with a conflicting value for `closed` is passed as input data:**\r\n```python\r\nIn [7]: ivs = [pd.Interval(0, 1, closed='both'), pd.Interval(1, 2, closed='both')]\r\n\r\nIn [8]: pd.IntervalIndex(ivs, closed='neither')\r\n---------------------------------------------------------------------------\r\nValueError: conflicting values for closed: constructor got 'neither', inferred from data 'both'\r\n```\r\nxref #18421 where I implemented this behavior; I'm no longer sure it's the best approach to take.\r\n\r\n\r\n#### Problem description\r\nThis behavior is inconsistent, and could lead to confusion.  As it's currently implemented, the `closed` parameter is useless in the majority of cases, either doing nothing or raising an error.\r\n\r\n#### Expected Output\r\nI'd expect there to be consistency as to how the `closed` parameter is handled.  My preference would be to have it override the inferred `closed` if explicitly passed by the user.  Note that this is consistent with how the `dtype` parameter is used in constructors throughout the codebase.\r\n\r\nxref #19371 (may render this issue moot)"},
{"text": "This one is a bit complex to explain, but I'll do my best.\r\n\r\nCurrently ``IntervalIndex.getindexer`` fails if the other index doesn't contain  ``Interval`` only (there's also another bug, but let's keep it simple here).\r\n\r\nThe underlying issue is that ``IntervalIndex.getindexer`` depends on ``IntervalIndex.getloc`` which is ambigous for how it treats number inputs:\r\n\r\n```python\r\n>> ii = pd.IntervalIndex.frombreaks([0,1,2,3])\r\n>> ii.getloc(pd.Interval(1, 2))\r\n1  # ok\r\n>> ii.getloc(1)  # do we mean exactly 1, or if an interval contains the number 1?\r\n1  # ambigous\r\n```\r\nThe issue is that ``getloc`` returns the location for both exact matches and inexact matches (i.e. if the number input is in an interval). For the purposes of ``getindexer`` however, this behavious fails, as ``getindexer`` needs ``getloc`` to find exact matches only.\r\n\r\nSee https://github.com/pandas-dev/pandas/pull/19021#issuecomment-359544778 for further discussion.\r\n\r\n## Solution\r\nA solution could be adding a ``'strict'`` option to the ``method`` parameter of ``IntervalIndex.getloc``.\r\n\r\nThis wasn't so difficult after all, and I've already made a PR on this, see #19353"},
{"text": "We're inconsistent with excluding nuisance columns\r\n\r\n```python\r\nIn [37]: df = pd.DataFrame({\r\n    ...:     \"A\": [1, 2, 3, 4],\r\n    ...:     \"B\": pd.intervalrange(0, 4),\r\n    ...: })\r\n\r\nIn [38]: df.dtypes\r\nOut[38]:\r\nA     int64\r\nB    object\r\ndtype: object\r\n\r\nIn [39]: df.sum()\r\nOut[39]:\r\nA    10\r\ndtype: int64\r\n\r\nIn [40]: df.cumsum()\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-40-1c578612e53e> in <module>()\r\n----> 1 df.cumsum()\r\n\r\n~/Envs/pandas-dev/lib/python3.6/site-packages/pandas/pandas/core/generic.py in cumfunc(self, axis, skipna, *args, **kwargs)\r\n   7781             mask = isna(self)\r\n   7782             np.putmask(y, mask, maska)\r\n-> 7783             result = accumfunc(y, axis)\r\n   7784             np.putmask(result, mask, maskb)\r\n   7785         else:\r\n\r\n~/Envs/pandas-dev/lib/python3.6/site-packages/pandas/pandas/core/generic.py in <lambda>(y, axis)\r\n   7400         cls.cumsum = makecumfunction(\r\n   7401             cls, 'cumsum', name, name2, axisdescr, \"cumulative sum\",\r\n-> 7402             lambda y, axis: y.cumsum(axis), \"sum\", 0., np.nan)\r\n   7403         cls.cumprod = makecumfunction(\r\n   7404             cls, 'cumprod', name, name2, axisdescr, \"cumulative product\",\r\n\r\nTypeError: unsupported operand type(s) for +: 'pandas.libs.interval.Interval' and 'pandas.libs.interval.Interval'\r\n```\r\n\r\nI'll update this with more dtypes (datetime, period, categorical) and more aggregations. Ideally we'd be consistent between the cumulative and non-cumulative versions."},
{"text": "#### Code Sample, a copy-pastable example if possible\r\nThe `IntervalIndex` constructor takes a `dtype` parameter but doesn't use it (no references to it in the code):\r\n\r\n```python\r\nIn [2]:  pd.IntervalIndex([pd.Interval(0, 1), pd.Interval(2, 3)], dtype='float64')\r\nOut[2]:\r\nIntervalIndex([(0, 1], (2, 3]]\r\n              closed='right',\r\n              dtype='interval[int64]')\r\n```\r\n\r\nThe constructor methods do not support a `dtype` parameter:\r\n```python\r\nIn [3]: pd.IntervalIndex.fromintervals([pd.Interval(0, 1), pd.Interval(2, 3)], dtype='float64')\r\n---------------------------------------------------------------------------\r\nTypeError: fromintervals() got an unexpected keyword argument 'dtype'\r\n\r\nIn [4]: pd.IntervalIndex.fromarrays([0, 2], [1, 3], dtype='float64')\r\n---------------------------------------------------------------------------\r\nTypeError: fromarrays() got an unexpected keyword argument 'dtype'\r\n\r\nIn [5]: pd.IntervalIndex.frombreaks([0, 1, 2, 3], dtype='float64')\r\n---------------------------------------------------------------------------\r\nTypeError: frombreaks() got an unexpected keyword argument 'dtype'\r\n\r\nIn [6]: pd.IntervalIndex.fromtuples([(0, 1), (2, 3)], dtype='float64')\r\n---------------------------------------------------------------------------\r\nTypeError: fromtuples() got an unexpected keyword argument 'dtype'\r\n```\r\n\r\n#### Expected Output\r\n\r\nI'd expect the `IntervalIndex` constructor and constructor methods to support a `dtype` parameter, which can be used to override the inferred dtype.\r\n\r\n"},
{"text": "xref #19187 \r\n\r\n\r\n#### Code Sample, a copy-pastable example if possible\r\n\r\n```\r\nIn [2]: pd.DatetimeIndex(['2000-02-01', '2000-02-02']).isalldates\r\nOut[2]: True\r\n\r\nIn [3]: pd.DatetimeIndex(['2000-02-01', '2000-02-02']).append(pd.Index(['not a date']))[:2].isalldates\r\nOut[3]: True\r\n\r\nIn [4]: pd.PeriodIndex(['2000', '2001'], freq='A').isalldates\r\nOut[4]: True\r\n\r\nIn [5]: pd.PeriodIndex(['2000', '2001'], freq='A').append(pd.Index(['not a date']))[:2].isalldates\r\nOut[5]: False\r\n\r\nIn [6]: pd.TimedeltaIndex([2000, 2001]).append(pd.Index(['not a date']))[:2].isalldates\r\nOut[6]: False\r\n```\r\n\r\n#### Problem description\r\n\r\n``isalldates`` is smart for ``object`` indexes but only for ``DatetimeIndex``, which is inconsistent since the other datetimelike indexes are also considered ``isalldates``.\r\n\r\n#### Expected Output\r\n\r\n``Out[5]:`` and ``Out[6]:`` should be the same as ``Out[3]:``.\r\n\r\n#### Output of ``pd.showversions()``\r\n\r\n<details>\r\n\r\n[paste the output of ``pd.showversions()`` here below this line]\r\n\r\n</details>\r\n"},
{"text": "#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\ndf=pd.DataFrame({'Year': np.random.randint(2000,2017,10000), 'Month': np.random.randint(1,12,10000), 'Data': np.random.randint(0,100,10000)})\r\ngrouped=df.groupby(['Year','Month', pd.cut(df.Data, range(0,100,10))]).size().unstack()\r\n\r\n# This doesn't work:\r\ngrouped.resetindex() #returns TypeError: unorderable types: int() < str()\r\n\r\n# This works:\r\ngrouped.columns=grouped.columns.astype('str')\r\ngrouped.resetindex()\r\n\r\n```\r\n#### Problem description\r\n\r\nresetindex() should work with dataframes that have any types of columns.\r\n\r\n#### Expected Output\r\n\r\nTwo extra columns with multiindex content, in the example above - Year and Month.\r\nColumn's type changes to string? Or documentation should specify that resetindex() doesn't work with specific types of columns.\r\n\r\n#### Output of ``pd.showversions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\n\r\npandas: 0.22.0\r\npytest: None\r\npip: 9.0.1\r\nsetuptools: 36.4.0\r\nCython: 0.26\r\nnumpy: 1.13.3\r\nscipy: 1.0.0\r\npyarrow: None\r\nxarray: None\r\nIPython: 6.1.0\r\nsphinx: None\r\npatsy: 0.4.1\r\ndateutil: 2.6.1\r\npytz: 2017.3\r\nblosc: None\r\nbottleneck: None\r\ntables: 3.4.2\r\nnumexpr: 2.6.4\r\nfeather: None\r\nmatplotlib: 2.1.1\r\nopenpyxl: None\r\nxlrd: 1.1.0\r\nxlwt: None\r\nxlsxwriter: None\r\nlxml: None\r\nbs4: None\r\nhtml5lib: 0.9999999\r\nsqlalchemy: 1.2.0\r\npymysql: None\r\npsycopg2: None\r\njinja2: 2.9.6\r\ns3fs: None\r\nfastparquet: None\r\npandasgbq: None\r\npandasdatareader: None\r\n\r\n</details>\r\n"},
{"text": "#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\nIn [2]: 2 in pd.MultiIndex.fromproduct([[1, 2], [3, 4]]).drop(2)\r\nOut[2]: True\r\n```\r\n\r\n#### Problem description\r\n\r\n#2770 was actually more complex than what I understood when I suggested to close it. While ``removeunusedlevels()`` did solve the problem of just resetting the ``.levels``, the above is still buggy. Ironically, the above is [even tested](https://github.com/pandas-dev/pandas/blob/master/pandas/tests/frame/testmutatecolumns.py#L198).\r\n\r\n#### Expected Output\r\n\r\n``False``\r\n\r\n#### Output of ``pd.showversions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: 84335621ad0a0d83302a80b6911d3985c00b5cee\r\npython: 3.5.3.final.0\r\npython-bits: 64\r\nOS: Linux\r\nOS-release: 4.9.0-4-amd64\r\nmachine: x8664\r\nprocessor: \r\nbyteorder: little\r\nLCALL: None\r\nLANG: itIT.UTF-8\r\nLOCALE: itIT.UTF-8\r\n\r\npandas: 0.23.0.dev0+10.g84335621a\r\npytest: 3.2.3\r\npip: 9.0.1\r\nsetuptools: 36.7.0\r\nCython: 0.25.2\r\nnumpy: 1.12.1\r\nscipy: 0.19.0\r\npyarrow: None\r\nxarray: None\r\nIPython: 6.2.1\r\nsphinx: 1.5.6\r\npatsy: 0.4.1\r\ndateutil: 2.6.1\r\npytz: 2017.2\r\nblosc: None\r\nbottleneck: 1.2.0dev\r\ntables: 3.3.0\r\nnumexpr: 2.6.1\r\nfeather: 0.3.1\r\nmatplotlib: 2.0.0\r\nopenpyxl: 2.3.0\r\nxlrd: 1.0.0\r\nxlwt: 1.3.0\r\nxlsxwriter: 0.9.6\r\nlxml: 4.1.1\r\nbs4: 4.5.3\r\nhtml5lib: 0.999999999\r\nsqlalchemy: 1.0.15\r\npymysql: None\r\npsycopg2: None\r\njinja2: 2.10\r\ns3fs: None\r\nfastparquet: None\r\npandasgbq: None\r\npandasdatareader: 0.2.1\r\n\r\n\r\n</details>\r\n"},
{"text": "There looks like something is wrong with the `compression` argument in `tocsv` for`pd.Series` but `pd.DataFrame`.  This error is also in 0.20.3.\r\n```python\r\nIn [1]: Setmp = pd.Series(list(\"ACGT\"))\r\n   ...: Setmp.tocsv(\"~/test.tsv.gz\", sep=\"\\t\", compression=\"gzip\")\r\n   ...:\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-1-de7ce483228f> in <module>()\r\n      1 Setmp = pd.Series(list(\"ACGT\"))\r\n----> 2 Setmp.tocsv(\"~/test.tsv.gz\", sep=\"\\t\", compression=\"gzip\")\r\n\r\nTypeError: tocsv() got an unexpected keyword argument 'compression'\r\n\r\nIn [2]: Setmp.toframe(\"testingcolumn\").tocsv(\"~/test.tsv.gz\", sep=\"\\t\", compression=\"gzip\")\r\n\r\nIn [3]: pd.version\r\nOut[3]: '0.21.1'\r\n```"},
{"text": "`PeriodIndex` w/ `Series` is allowed, `PeriodIndex` w/ `DatetimeIndex` is not.  Is this intentional?  If not, which should be made to match the other?\r\n\r\n```\r\n>>> dti = pd.daterange('2016-01-01', periods=3)\r\n>>> ser = pd.Series(dti)\r\n>>> pi = dti.toperiod()\r\n\r\n>>> ser - pi\r\n0   0 days\r\n1   0 days\r\n2   0 days\r\ndtype: timedelta64[ns]\r\n\r\n>>> dti - pi\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"pandas/core/indexes/datetimelike.py\", line 724, in sub\r\n    typ2=type(other).name))\r\nTypeError: cannot subtract DatetimeIndex and PeriodIndex\r\n\r\n>>> pi - ser\r\n0   0 days\r\n1   0 days\r\n2   0 days\r\ndtype: timedelta64[ns]\r\n\r\n>>> pi - dti\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"pandas/core/indexes/datetimelike.py\", line 731, in rsub\r\n    return -(self - other)\r\n  File \"pandas/core/indexes/datetimelike.py\", line 724, in sub\r\n    typ2=type(other).name))\r\nTypeError: cannot subtract DatetimeIndex and PeriodIndex\r\n```"},
{"text": "#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\nIn [2]: pd.Series([1], [0,1])\r\nOut[2]: \r\n0    1\r\n1    1\r\ndtype: int64\r\n```\r\n\r\n#### Problem description\r\n\r\nThis is undocumented, conceptually wrong, works only because of an implementation glitch, and is used in 3 tests only  - I think - by mistake.\r\n\r\nAlready discussed (and potentially fixed) inside #18626 (where @jorisvandenbossche suggested a proper deprecation cycle), but @jreback [suggested](https://github.com/pandas-dev/pandas/pull/18769#discussionr157476271) to open a specific issue.\r\n\r\n#### Expected Output\r\n\r\n```ValueError: Wrong number of items passed 1, placement implies 2```\r\n\r\n#### Output of ``pd.showversions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: b5f1e716d89487423bb12d6cc4e6da2b39184531\r\npython: 3.5.3.final.0\r\npython-bits: 64\r\nOS: Linux\r\nOS-release: 4.9.0-4-amd64\r\nmachine: x8664\r\nprocessor: \r\nbyteorder: little\r\nLCALL: None\r\nLANG: itIT.UTF-8\r\nLOCALE: itIT.UTF-8\r\n\r\npandas: 0.22.0.dev0+371.gb5f1e716d\r\npytest: 3.2.3\r\npip: 9.0.1\r\nsetuptools: 36.7.0\r\nCython: 0.25.2\r\nnumpy: 1.12.1\r\nscipy: 0.19.0\r\npyarrow: None\r\nxarray: None\r\nIPython: 6.2.1\r\nsphinx: 1.5.6\r\npatsy: 0.4.1\r\ndateutil: 2.6.1\r\npytz: 2017.2\r\nblosc: None\r\nbottleneck: 1.2.0dev\r\ntables: 3.3.0\r\nnumexpr: 2.6.1\r\nfeather: 0.3.1\r\nmatplotlib: 2.0.0\r\nopenpyxl: 2.3.0\r\nxlrd: 1.0.0\r\nxlwt: 1.3.0\r\nxlsxwriter: 0.9.6\r\nlxml: 4.1.1\r\nbs4: 4.5.3\r\nhtml5lib: 0.999999999\r\nsqlalchemy: 1.0.15\r\npymysql: None\r\npsycopg2: None\r\njinja2: 2.10\r\ns3fs: None\r\nfastparquet: None\r\npandasgbq: None\r\npandasdatareader: 0.2.1\r\n\r\n\r\n</details>\r\n"},
{"text": "\r\n```\r\n>>> idx = pd.daterange('1994-10-06', freq='D', periods=4)\r\n>>> idx.day.toseries(index=idx)\r\n>>> idx.day.toseries(index=idx)\r\n6    6\r\n7    7\r\n8    8\r\n9    9\r\n```\r\n\r\nExpected:\r\n\r\n```\r\n>>> idx.day.toseries(index=idx)\r\n1994-10-06    6\r\n1994-10-07    7\r\n1994-10-08    8\r\n1994-10-09    9\r\n```\r\n\r\nLooks like Index.toseries takes **kwargs but then ignores them.  Should be an easy fix; would be nice to systematically track down other places this might happen."},
{"text": "#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\nvibedf.plot(x='Time', y='Fz')     # This works just fine.\r\nvibedf.plot(x='Time', y=['Fz'])     # This raises a UserWarning:\r\n\r\n```\r\n#### Problem description\r\n\r\nI get a UserWarning while plotting a DataFrame.  It only occurs if I pass a list of columns for y.\r\n\r\nUserWarning is:\r\nC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\plotting\\core.py:1714: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\r\n  series.name = label\r\n\r\n#### Expected Output\r\n<just the graph>\r\n\r\n#### Output of ``pd.showversions()``\r\n<details>\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.5.4.final.0\r\npython-bits: 64\r\nOS: Windows\r\nOS-release: 10\r\nmachine: AMD64\r\nprocessor: Intel64 Family 6 Model 60 Stepping 3, GenuineIntel\r\nbyteorder: little\r\nLCALL: None\r\nLANG: None\r\nLOCALE: None.None\r\n\r\npandas: 0.21.0\r\npytest: 2.9.2\r\npip: 9.0.1\r\nsetuptools: 27.2.0\r\nCython: 0.24.1\r\nnumpy: 1.11.3\r\nscipy: 1.0.0\r\npyarrow: None\r\nxarray: None\r\nIPython: 6.2.1\r\nsphinx: 1.4.6\r\npatsy: 0.4.1\r\ndateutil: 2.6.0\r\npytz: 2017.2\r\nblosc: None\r\nbottleneck: 1.1.0\r\ntables: 3.2.2\r\nnumexpr: 2.6.4\r\nfeather: None\r\nmatplotlib: 2.1.0\r\nopenpyxl: 2.3.2\r\nxlrd: 1.0.0\r\nxlwt: 1.1.2\r\nxlsxwriter: 0.9.3\r\nlxml: 3.6.4\r\nbs4: 4.5.1\r\nhtml5lib: None\r\nsqlalchemy: 1.0.13\r\npymysql: None\r\npsycopg2: None\r\njinja2: 2.8\r\ns3fs: None\r\nfastparquet: None\r\npandasgbq: None\r\npandasdatareader: None\r\n\r\n"},
{"text": "The implicit index-matching of `pandas` for operations between different `DataFrame`/`Series` is great and most of the times, it just works. It does so consistently enough, that the expectation (for me) is that different Series will be aligned before an operation is performed.\r\n\r\nFor some reason, `str.cat` does not seem to do so.\r\n\r\n```\r\nimport pandas as pd # 0.21.0\r\nimport numpy as np # 1.13.3\r\ncol = pd.Series(['a','b','c','d','e','f','g','h','i','j'])\r\n\r\n# choose random subsets\r\nss1 = [8, 1, 2, 0, 6] # list(col.sample(5).index) \r\nss2 = [4, 0, 9, 2, 6] # list(col.sample(5).index)\r\n\r\n# perform str.cat\r\ncol.loc[ss1].str.cat(col.loc[ss2], sep = '').sortindex()\r\n# 0    ac <-- UNMATCHED!\r\n# 1    ba <-- UNMATCHED!\r\n# 2    cj <-- UNMATCHED!\r\n# 6    gg <-- correct by sheer luck\r\n# 8    ie <-- UNMATCHED!\r\n\r\n# compared for example with Boolean operations on unmatched series\r\n# (matching indices and returning Series with union of both indices),\r\n# this is inconsistent!\r\nb = col.loc[ss1].astype(bool) & col.loc[ss2].astype(bool)\r\nb\r\n# 0     True\r\n# 1    False\r\n# 2     True\r\n# 4    False\r\n# 6     True\r\n# 8    False\r\n# 9    False\r\n\r\n# if we manually align the Series\r\n# (easy here by masking from the Series we just subsampled, hard in practice),\r\n# then the NaNs are handled as expected:\r\nm = col.where(np.isin(col.index, ss1)).str.cat(col.where(np.isin(col.index, ss2)), sep = '')\r\nm\r\n# 0     aa\r\n# 1    NaN\r\n# 2     cc\r\n# 3    NaN\r\n# 4    NaN\r\n# 5    NaN\r\n# 6     gg\r\n# 7    NaN\r\n# 8    NaN\r\n# 9    NaN\r\n\r\n# based on the normal pandas-behaviour for unmatched Series\r\n# (for example as for Boolean \"and\" above), the following would be\r\n# the expected result of col.loc[ss1].str.cat(col.loc[ss2], sep = '').sortindex() !\r\nm.loc[b.index]\r\n# 0     aa <-- MATCHED!\r\n# 1    NaN\r\n# 2     cc <-- MATCHED!\r\n# 4    NaN\r\n# 6     gg <-- MATCHED!\r\n# 8    NaN\r\n# 9    NaN\r\n```\r\n"},
{"text": "#### Problem description\r\nThe fixes in #18424 allow for and `IntervalIndex` to be constructed with tz aware timestamps, but there are a few attributes/methods that still do not work properly with tz aware:\r\n\r\n-  Disallow an `IntervalIndex` to contain elements with differing tz\r\n- `IntervalIndex.mid` returns tz naive\r\n- Anything using `getnextlabel` or `getpreviouslabel` will raise\r\n  - `getindexer` when passed an `IntervalIndex`\r\n  - `getloc` for overlapping/non-monotonic `IntervalIndex`\r\n  - `contains` always returns `False` for overlapping/non-monotonic due to `Try`/`Except`\r\n  - etc.\r\n\r\n#### Code Sample, a copy-pastable example if possible\r\nSetup:\r\n```python\r\nIn [2]: start = pd.Timestamp('2017-01-01', tz='US/Eastern')\r\n   ...: index = pd.intervalrange(start, periods=3)\r\n   ...: index\r\n   ...:\r\nOut[2]:\r\nIntervalIndex([(2017-01-01, 2017-01-02], (2017-01-02, 2017-01-03], (2017-01-03, 2017-01-04]]\r\n              closed='right',\r\n              dtype='interval[datetime64[ns, US/Eastern]]')\r\n```\r\n`IntervalIndex.mid` returns tz naive:\r\n```python\r\nIn [3]: index.mid\r\nOut[3]:\r\nDatetimeIndex(['2017-01-01 17:00:00', '2017-01-02 17:00:00',\r\n               '2017-01-03 17:00:00'],\r\n              dtype='datetime64[ns]', freq=None)\r\n```\r\n\r\n`getindexer` raises when passed an `IntervalIndex`:\r\n```python\r\nIn [4]: index.getindexer(index[:-1])\r\n---------------------------------------------------------------------------\r\nTypeError: cannot determine next label for type <class 'pandas.core.indexes.datetimes.DatetimeIndex'>\r\n```\r\n\r\nDiffering tz:\r\n```python\r\nIn [5]: left = pd.daterange('2017-01-01', periods=3, tz='US/Eastern')\r\n   ...: right = pd.daterange('2017-01-02', periods=3, tz='US/Pacific')\r\n   ...: index = pd.IntervalIndex.fromarrays(left, right)\r\n   ...: index\r\n   ...:\r\nOut[5]:\r\nIntervalIndex([(2017-01-01, 2017-01-02], (2017-01-02, 2017-01-03], (2017-01-03, 2017-01-04]]\r\n              closed='right',\r\n              dtype='interval[datetime64[ns, US/Eastern]]')\r\n\r\nIn [6]: index.left.dtype\r\nOut[6]: datetime64[ns, US/Eastern]\r\n\r\nIn [7]: index.right.dtype\r\nOut[7]: datetime64[ns, US/Pacific]\r\n```"},
{"text": "#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\nIn [2]: d = {(0, 1) : 2, (3, 4) : 5}\r\n\r\nIn [3]: pd.Index(d)\r\nOut[3]: Index([(0, 1), (3, 4)], dtype='object')\r\n\r\nIn [4]: pd.Index(list(d))\r\nOut[4]: \r\nMultiIndex(levels=[[0, 3], [1, 4]],\r\n           labels=[[0, 1], [0, 1]])\r\n\r\nIn [5]: pd.Series(d).index\r\nOut[5]: \r\nMultiIndex(levels=[[0, 3], [1, 4]],\r\n           labels=[[0, 1], [0, 1]])\r\n\r\nIn [6]: pd.Series(index=list(d)).index\r\nOut[6]: Index([(0, 1), (3, 4)], dtype='object')\r\n\r\n```\r\n#### Problem description\r\n\r\nI guess ``Out[3]:`` and ``Out[6]:`` are wrong.\r\n\r\n#### Expected Output\r\n\r\n``Out[4]:``\r\n\r\n#### Output of ``pd.showversions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.5.3.final.0\r\npython-bits: 64\r\nOS: Linux\r\nOS-release: 4.9.0-4-amd64\r\nmachine: x8664\r\nprocessor: \r\nbyteorder: little\r\nLCALL: None\r\nLANG: enGB.UTF-8\r\nLOCALE: enGB.UTF-8\r\n\r\npandas: 0.22.0.dev0+202.g97bd66ea8\r\npytest: 3.0.6\r\npip: 9.0.1\r\nsetuptools: 33.1.1\r\nCython: 0.25.2\r\nnumpy: 1.12.1\r\nscipy: 0.18.1\r\npyarrow: None\r\nxarray: None\r\nIPython: 5.2.2\r\nsphinx: None\r\npatsy: 0.4.1+dev\r\ndateutil: 2.6.0\r\npytz: 2016.10\r\nblosc: None\r\nbottleneck: 1.2.0\r\ntables: 3.3.0\r\nnumexpr: 2.6.1\r\nfeather: 0.3.1\r\nmatplotlib: 2.0.0\r\nopenpyxl: 2.3.0\r\nxlrd: 1.0.0\r\nxlwt: 1.2.0\r\nxlsxwriter: None\r\nlxml: 3.7.1\r\nbs4: 4.5.3\r\nhtml5lib: 0.999999999\r\nsqlalchemy: 1.0.15\r\npymysql: None\r\npsycopg2: None\r\njinja2: 2.8\r\ns3fs: None\r\nfastparquet: None\r\npandasgbq: None\r\npandasdatareader: None\r\n\r\n</details>\r\n"},
{"text": "TLDR: enforcing tzaware vs tznaive compat in DatetimeIndex comparisons (#18162) appears to be inconsistent with current slicing behavior.\r\n\r\nThe following example is based off of tests.series.testindexing.testgetitemsetitemdatetimeindex:\r\n\r\n```\r\ndti = pd.daterange('1/1/1990', periods=50, freq='H', tz='US/Eastern')\r\nts = pd.Series(np.random.randn(50), index=dti)\r\n\r\nlb = '1990-01-01 04:00:00'\r\nrb = '1990-01-01 07:00:00'\r\n```\r\n\r\nThe behavior that we want to enforce is #18162 requires that `dti < pd.Timestamp(lb)` should raise, as should `dti < lb`.  At the moment they effectively get treated as UTC.  But if we change this so that it does raise, the following from `testgetitemsetitemdatetimeindex` breaks pretty irrevocably:\r\n\r\n```\r\nts[(ts.index >= lb) & (ts.index <= rb)]\r\n```\r\n\r\nThere is also `ts[lb:rb]` which if we're being strict should raise, but at least we could make that still work.  (BTW this implicitly casts lb and rb to US/Eastern, albeit in different places.  So far that appears to be a related but distinct can of worms.)\r\n"},
{"text": "Hi everyone,\r\n\r\nIt seems that pandas readhtml doesn't process numeric values properly, the detailed issue with code examples on stackoverflow: https://stackoverflow.com/questions/47327966/pandas-converting-numbers-to-strings-unexpected-results\r\n\r\n\r\n**Source table:**\r\n```\r\n<body>\r\n    <table>\r\n        <thead>\r\n            <tr>\r\n                <th class=\"tabHead\" x:autofilter=\"all\">Number</th>\r\n            </tr>\r\n        </thead>\r\n        <tbody>\r\n            <tr>\r\n                <td class=\"tDetail\">1.320,00</td>\r\n            </tr>\r\n            <tr>\r\n                <td class=\"tDetail\">600,00</td>\r\n            </tr>\r\n        </tbody>\r\n    </table>\r\n</body>\r\n```\r\n**Obviously, the expected output is:**\r\n```\r\n     Number\r\n0  1.320,00\r\n1    600,00\r\n```\r\n\r\n### (1) Straightforward reading of the file\r\n**Processing code:**\r\n```\r\nimport pandas\r\n\r\ndf = pandas.readhtml('testfile.xls')\r\nprint(df[0])\r\nprint(df[0].dtypes)\r\n```\r\n**Output:**\r\n```\r\n     Number\r\n0      1.32\r\n1  60000.00\r\n\r\nNumber    float64\r\ndtype: object\r\n```\r\n\r\n### (2) Applying str function as a convertor for each dimension\r\n\r\n**Processing code:**\r\n```\r\nconverters = {columnname: str for columnname in df[0].dtypes.index}\r\ndf = pandas.readhtml(f, converters = converters)\r\nprint(df[0])\r\nprint(df[0].dtypes)\r\n```\r\n**Output:**\r\n```\r\n    Number\r\n0  1.32000\r\n1    60000\r\n\r\nNumber    object\r\ndtype: object\r\n```\r\n\r\nThere could be cases when one file contains numbers typed in different formats (American / European / etc). This numbers differs with decimal mark, thousand mark, etc. So the logical way to handle such files will be to extract the data \"as it is\" in strings and perform parsing with regexps / other modules separately for each row. Is there a way how to do it in pandas? Thanks guys!\r\n\r\n\r\n**Notes:**\r\n\r\n1. The input value of <td class=\"tDetail\">,,,2,,,,5,,,,,5,,,,0,,,.,,,7,,,7,,,</td> (mind the dote!) also converts to 2550.77\r\n2. Specification of \"decimal\" and \"thousands\" parameters for pandas.read* doesn't look like a reliable solution because it is appled for all fields. Quick example: it can treat date fields in \"02.2017\" format as numbers and convert it to \"022017\" (even to \"22017\" without leading zero)\r\n3. The workaround if you have 100.000,00 formatted numerical values and 01.12.2017 dates is the following: using decimal = ',', thousands = '.' and passing the convertor dictionary that maps all columns to str: converters = {columnname: str for columnname in df[0].dtypes.index} in readhtml call. So the numbers will be correct (according to this format) and dates won't be changed to something like 1122017 (remember that leading zero might be removed!)\r\n\r\nSimilar issues is https://github.com/pandas-dev/pandas/issues/10534.\r\nIt is still opened, but here I also mention a direct unexpected behavior, like:\r\n\r\n1. \"01.12.2017\" -> 1122017\r\n2. \",,,,,42.......42,,.,.,.,.,.,.42........\" -> 424242\r\n\r\nI guess this issue is not about \"how to convert numbers properly\" but \"how to get actual data from html table\". It's clear that pandas provides an analytical way of data processing and management, but at the same time pandas.readhtml is **the only reliable way in Python** of obtaining raw data from html tables without parsing tr, th, td, etc... So I think it's really important to think about just \"conversion\" behavior of pandas in these terms."},
{"text": "When using the `fields` query param on api/v2 the objects returned do not include any `relationships`.\r\n\r\n/edit Actually I just noticed that they are included when I pass them into the `fields` set which makes sense to me. So for example I can get all product with product.name and product.variants by calling `/api/v2/storefront/products?fields[product]=name,variants&include=variants`. This makes sense to me so now I'm wondering if this is intended behavior?\r\n\r\n## Expected Behavior\r\nI expect relationships to be returned regardless of whether I limit which fields should be returned.\r\n\r\n## Actual Behavior\r\nRelationships are not returned if I limit which fields I want returned.\r\n\r\n## Possible Fix\r\nn/a\r\n\r\n## Steps to Reproduce\r\n1. `GET /api/v2/storefront/products?fields[product]=name` and notice that none of the products include any relationships.\r\n\r\n## Your Environment\r\n* Version used: 4.1.7"},
{"text": "I'm not sure if this can be considered a bug or it is intentional:\r\n\r\nWhenever I send a request to the checkout update endpoint, spree generates a new address entry although the address did not change at all. This behaviour is not as described or expected in https://guides.spreecommerce.org/api/v2/storefront#operation/Update%20Checkout (to be fair: no behaviour is described for this).\r\n\r\nI think it would be good to check if the address attributes for bill and / or ship are exactly the same / unchanged even if included in the request and do not create a new address entry. Also maybe it makes sense to define what parameters should trigger a \"new\" address entry and what parameters just update the existing one. My main concern is, that the database is bloating a lot with this and the user also has a lot of duplicate addresses in his address book this way.\r\n\r\nHappy to hear your thoughts and maybe we convert this into an issue / bug if it was not intentional."},
{"text": "N+1 queries about icon image on /api/v2/storefront/taxons.\r\n\r\n\r\n## Context\r\ndevelopment.log\r\nActiveStorage::Attachment and ActiveStorage::Blob fetch by every taxon.\r\n\r\n```\r\nrails1            |   ActiveStorage::Attachment Load (0.9ms)  SELECT \"activestorageattachments\".* FROM \"activestorageattachments\" WHERE \"activestorageattachments\".\"recordid\" = $1 AND \"activestorageattachments\".\"recordtype\" = $2 AND \"activestorageattachments\".\"name\" = $3 LIMIT $4  [[\"recordid\", 5], [\"recordtype\", \"Spree::Asset\"], [\"name\", \"attachment\"], [\"LIMIT\", 1]]\r\nrails1            |   ActiveStorage::Blob Load (0.4ms)  SELECT \"activestorageblobs\".* FROM \"activestorageblobs\" WHERE \"activestorageblobs\".\"id\" = $1 LIMIT $2  [[\"id\", 5], [\"LIMIT\", 1]]\r\nrails1            |   Spree::Taxon Load (0.8ms)  SELECT \"spreetaxons\".* FROM \"spreetaxons\" WHERE \"spreetaxons\".\"lft\" <= 7 AND \"spreetaxons\".\"rgt\" >= 12 AND (\"spreetaxons\".\"id\" != 4) ORDER BY \"spreetaxons\".\"lft\" ASC\r\nrails1            |   ActiveStorage::Attachment Load (0.4ms)  SELECT \"activestorageattachments\".* FROM \"activestorageattachments\" WHERE \"activestorageattachments\".\"recordid\" = $1 AND \"activestorageattachments\".\"recordtype\" = $2 AND \"activestorageattachments\".\"name\" = $3 LIMIT $4  [[\"recordid\", 6], [\"recordtype\", \"Spree::Asset\"], [\"name\", \"attachment\"], [\"LIMIT\", 1]]\r\nrails1            |   ActiveStorage::Blob Load (0.3ms)  SELECT \"activestorageblobs\".* FROM \"activestorageblobs\" WHERE \"activestorageblobs\".\"id\" = $1 LIMIT $2  [[\"id\", 6], [\"LIMIT\", 1]]\r\nrails1            |   Spree::Taxon Load (1.1ms)  SELECT \"spreetaxons\".* FROM \"spreetaxons\" WHERE \"spreetaxons\".\"lft\" <= 13 AND \"spreetaxons\".\"rgt\" >= 20 AND (\"spreetaxons\".\"id\" != 7) ORDER BY \"spreetaxons\".\"lft\" ASC\r\nrails1            |   ActiveStorage::Attachment Load (0.5ms)  SELECT \"activestorageattachments\".* FROM \"activestorageattachments\" WHERE \"activestorageattachments\".\"recordid\" = $1 AND \"activestorageattachments\".\"recordtype\" = $2 AND \"activestorageattachments\".\"name\" = $3 LIMIT $4  [[\"recordid\", 7], [\"recordtype\", \"Spree::Asset\"], [\"name\", \"attachment\"], [\"LIMIT\", 1]]\r\nrails1            |   ActiveStorage::Blob Load (0.6ms)  SELECT \"activestorageblobs\".* FROM \"activestorageblobs\" WHERE \"activestorageblobs\".\"id\" = $1 LIMIT $2  [[\"id\", 7], [\"LIMIT\", 1]]\r\nrails1            |   Spree::Taxon Load (0.8ms)  SELECT \"spreetaxons\".* FROM \"spreetaxons\" WHERE \"spreetaxons\".\"lft\" <= 21 AND \"spreetaxons\".\"rgt\" >= 26 AND (\"spreetaxons\".\"id\" != 11) ORDER BY \"spreetaxons\".\"lft\" ASC\r\nrails1            |   ActiveStorage::Attachment Load (0.6ms)  SELECT \"activestorageattachments\".* FROM \"activestorageattachments\" WHERE \"activestorageattachments\".\"recordid\" = $1 AND \"activestorageattachments\".\"recordtype\" = $2 AND \"activestorageattachments\".\"name\" = $3 LIMIT $4  [[\"recordid\", 8], [\"recordtype\", \"Spree::Asset\"], [\"name\", \"attachment\"], [\"LIMIT\", 1]]\r\nrails1            |   ActiveStorage::Blob Load (0.5ms)  SELECT \"activestorageblobs\".* FROM \"activestorageblobs\" WHERE \"activestorageblobs\".\"id\" = $1 LIMIT $2  [[\"id\", 8], [\"LIMIT\", 1]]\r\nrails1            |   Spree::Taxon Load (1.2ms)  SELECT \"spreetaxons\".* FROM \"spreetaxons\" WHERE \"spreetaxons\".\"lft\" <= 27 AND \"spreetaxons\".\"rgt\" >= 42 AND (\"spreetaxons\".\"id\" != 14) ORDER BY \"spreetaxons\".\"lft\" ASC\r\n```\r\n\r\n## Actual Behavior\r\n\r\n## Possible Fix\r\n\r\nFix scope includes.\r\n\r\napi/app/controllers/spree/api/v2/storefront/taxonscontroller.rb\r\n\r\n```\r\n          def scopeincludes\r\n              ...\r\n              icon: [attachmentattachment: :blob]\r\n          end\r\n```\r\n\r\n\r\n\r\n## Steps to Reproduce\r\n\r\n## Your Environment\r\n"},
{"text": "## Context\r\n\r\nHi, I was just trying out the headless install on a new Rails project following the README.md, so I added these gems to the Gemfile and ran the generators.\r\n\r\n```ruby\r\ngem 'spreeapi', '~> 4.1'                                                                                                                                    \r\ngem 'spreebackend', '~> 4.1'                                                                                                                                \r\ngem 'spreeauthdevise', '~> 4.1'                                                                                                                            \r\ngem 'spreegateway', '~> 3.7'\r\n```\r\n\r\n```bash\r\nbundle exec rails g spree:install --userclass=Spree::User\r\nbundle exec rails g spree:backend:copyviews\r\n```\r\n\r\nBut when I try to open http://localhost:3000/admin I get redirected to `/login` and then I get a `Missing template spree/layouts/spreeapplication` exception.  I see this file exists in spreefrontend, but shouldn't it be included on spreebackend?\r\n\r\n## Your Environment\r\n\r\n```\r\nMissing template spree/layouts/spreeapplication with {:locale=>[:en], :formats=>[:html], :variants=>[], :handlers=>[:raw, :erb, :html, :builder, :ruby, :jbuilder, :rabl]}. Searched in: * \"/home/fauno/Projects/sutty/tienda.sutty.nl/app/views\" * \"/home/fauno/.rbenv/versions/2.6.6/lib/ruby/gems/2.6.0/gems/spreegateway-3.7.5/lib/views/backend\" * \"/home/fauno/.rbenv/versions/2.6.6/lib/ruby/gems/2.6.0/gems/spreeauthdevise-4.1.0/app/views\" * \"/home/fauno/.rbenv/versions/2.6.6/lib/ruby/gems/2.6.0/gems/spreeauthdevise-4.1.0/lib/views/backend\" * \"/home/fauno/.rbenv/versions/2.6.6/lib/ruby/gems/2.6.0/gems/devise-4.7.1/app/views\" * \"/home/fauno/.rbenv/versions/2.6.6/lib/ruby/gems/2.6.0/gems/spreebackend-4.1.6/app/views\" * \"/home/fauno/.rbenv/versions/2.6.6/lib/ruby/gems/2.6.0/gems/doorkeeper-5.4.0/app/views\" * \"/home/fauno/.rbenv/versions/2.6.6/lib/ruby/gems/2.6.0/gems/spreeapi-4.1.6/app/views\" * \"/home/fauno/.rbenv/versions/2.6.6/lib/ruby/gems/2.6.0/gems/spreecore-4.1.6/app/views\" * \"/home/fauno/.rbenv/versions/2.6.6/lib/ruby/gems/2.6.0/gems/kaminari-core-1.1.1/app/views\" * \"/home/fauno/.rbenv/versions/2.6.6/lib/ruby/gems/2.6.0/gems/actionmailbox-6.0.3.1/app/views\" * \"/home/fauno/.rbenv/versions/2.6.6/lib/ruby/gems/2.6.0/gems/actiontext-6.0.3.1/app/views\" \r\n```"},
{"text": "If you want to use the cart request to display a cart with product images, you need all images related to the variant the user has in her/his cart.\r\n\r\n## Context\r\nCurrently we are only able to display product variant images in the cart. This means unnecessary data storage or no images at all.\r\n\r\n## Expected Behavior\r\nIf an image is saved for \"all\" variants I want it to be returned in the images array for every variant.\r\n\r\n## Actual Behavior\r\nOnly images that are tagged for a specific variant are returned.\r\n\r\n## Possible Fix\r\nI did not look into the code yet but probably it's just a simple \"OR\" / relation that is missing :)\r\n\r\n## Steps to Reproduce\r\n1. Add a new Product with\r\n-  at least one variant and\r\n-  with an image that is tagged for \"all\" variants and\r\n-  with an image that is tagged for the variant\r\n\r\n![image](https://user-images.githubusercontent.com/159259/82534642-c053fd80-9b45-11ea-8988-dc65280d704c.png)\r\n\r\n2. Add the product to your cart via API v2\r\n`/api/v2/storefront/cart/additem.json?include=lineitems,variants,variants.images`\r\n\r\n3. The result does not return the product image for \"all\" variants but only the one for the specific variant\r\n\r\nThis is also true for all other cart requests\r\n\r\n## Your Environment\r\n* Version used: spree master at commit `b0f2e86591ee9ae071807bffb9d1243b4eaa8700`"},
{"text": "**Is your feature request related to a problem? Please describe.**\r\nI'm using json api serializer in frontend.\r\nhttps://github.com/SeyZ/jsonapi-serializer\r\n\r\nthis can deserialize for fastjson-api response including hasmany relatitonships.\r\nhttps://github.com/SeyZ/jsonapi-serializer/blob/master/test/deserializer.js#L228-L232\r\n\r\nBut, some spree api response can't deserialize\r\n\r\nexample:\r\n```\r\nmodule Spree\r\n  module V2\r\n    module Storefront\r\n      class CartSerializer < BaseSerializer\r\n        ...\r\n        # this is can serialize by jsonapi-serializer\r\n        belongsto :user\r\n\r\n        # this is can not serlizaised by jsonapi-serializer\r\n        belongsto :billingaddress,\r\n          idmethodname: :billaddressid,\r\n          serializer: :address\r\n```\r\n\r\nA response for relationships billing address data type is 'billingaddress'.\r\nAnd, a response for included data type is 'address'\r\nthis mismatch caused cannnot deserialized.\r\n\r\n<img width=\"529\" alt=\"\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8 2020-04-28 5 55 53\" src=\"https://user-images.githubusercontent.com/24713957/80421182-089d4880-8917-11ea-9ccc-41b8322538e1.png\">\r\n\r\n**Describe the solution you'd like**\r\nI would like to add `recordtype` for deserialize.\r\nhttps://github.com/Netflix/fastjsonapi#customizable-options\r\n\r\n```\r\nmodule Spree\r\n  module V2\r\n    module Storefront\r\n      class CartSerializer < BaseSerializer\r\n        belongsto :billingaddress,\r\n          idmethodname: :billaddressid,\r\n          serializer: :address,\r\n          recordtype: :address\r\n```\r\n\r\nA response for relationships billing address data type is 'address'.\r\nAnd can serialize.\r\n\r\n"},
{"text": "GET /checkout/shippingrates crashes the server when checkout step has already advanced from Delivery step using the web. Server crashes and needs to be restarted\r\n\r\nThe endpoint should reply with the shipping rates response according to the guide, https://guides.spreecommerce.org/api/v2/storefront#operation/Shipping%20Rates\r\n\r\nBut, instead of responding, it just hangs and crashes the server.\r\n\r\nYou can reproduce on both Spree 3.7 and Spree 4 using the following steps:\r\n1. Web: Add item to cart\r\n2. Web: Checkout\r\n3. Web: Fill in Address and advance to Delivery step\r\n4. Web: Choose shipping rate and advance to Payment step\r\n5. API: http://localhost:3000/api/v2/storefront/checkout/shippingrates\r\n"},
{"text": "**Context**\r\nRunning tests on fresh install from master branch\r\nRuby 2.5.1\r\nRails 5.2\r\n\r\n**Expected Behavior**\r\nTests pass.\r\n\r\n**Actual Behavior**\r\n2 Failures\r\n```\r\n1) Spree::Api::V1::CheckoutsController PUT 'update' transitioning to delivery can update addresses and transition from address to delivery\r\n     Failure/Error: if @order.completed? || @order.next\r\n     \r\n     ActiveRecord::RecordNotUnique:\r\n       SQLite3::ConstraintException: UNIQUE constraint failed: spreeshippingrates.shipmentid, spreeshippingrates.shippingmethodid: INSERT INTO \"spreeshippingrates\" (\"shipmentid\", \"shippingmethodid\", \"createdat\", \"updatedat\") VALUES (?, ?, ?, ?)\r\n     # /home/michael/.rvm/gems/ruby-2.5.1@5.2.1/gems/sqlite3-1.3.13/lib/sqlite3/statement.rb:108:in `step'\r\n     # /home/michael/.rvm/gems/ruby-2.5.1@5.2.1/gems/sqlite3-1.3.13/lib/sqlite3/statement.rb:108:in `block in each'\r\n     # /home/michael/.rvm/gems/ruby-2.5.1@5.2.1/gems/sqlite3-1.3.13/lib/sqlite3/statement.rb:107:in `loop'\r\n     # /home/michael/.rvm/gems/ruby-2.5.1@5.2.1/gems/sqlite3-1.3.13/lib/sqlite3/statement.rb:107:in `each'\r\n\r\n  2) Spree::Api::V1::CheckoutsController PUT 'update' transitioning to delivery does not contain duplicate variant data in delivery return\r\n     Failure/Error: if @order.completed? || @order.next\r\n     \r\n     ActiveRecord::RecordNotUnique:\r\n       SQLite3::ConstraintException: UNIQUE constraint failed: spreeshippingrates.shipmentid, spreeshippingrates.shippingmethodid: INSERT INTO \"spreeshippingrates\" (\"shipmentid\", \"shippingmethodid\", \"createdat\", \"updatedat\") VALUES (?, ?, ?, ?)\r\n     # /home/michael/.rvm/gems/ruby-2.5.1@5.2.1/gems/sqlite3-1.3.13/lib/sqlite3/statement.rb:108:in `step'\r\n     # /home/michael/.rvm/gems/ruby-2.5.1@5.2.1/gems/sqlite3-1.3.13/lib/sqlite3/statement.rb:108:in `block in each'\r\n     # /home/michael/.rvm/gems/ruby-2.5.1@5.2.1/gems/sqlite3-1.3.13/lib/sqlite3/statement.rb:107:in `loop'\r\n     # /home/michael/.rvm/gems/ruby-2.5.1@5.2.1/gems/sqlite3-1.3.13/lib/sqlite3/statement.rb:107:in `each'\r\n\r\n```\r\n\r\n**Steps to Reproduce**\r\n1. Follow \"Developing Spree\" instructions for API gem"},
{"text": "There're cases we want to query metadata of a past block for comparison and don't want to have any side effects for such query. But with current implementation, it actually call `registry.setMetadata()`.\r\nI believe this is an unexpected behavior for most people.\r\n\r\nhttps://github.com/polkadot-js/api/blob/9c1327ea22e1e8600fa8d216ce36f6618ffdb093/packages/metadata/src/Metadata/MetadataVersioned.ts#L44"},
{"text": "I'm running into this error when using `@polkadot/api` `1.24.1` with next.js.\r\n\r\nSeems that `setImmediate` was introduced recently, and this is causing things to things to break when using in browser (setImmediate works in node but not browser?). \r\n\r\n`subscription Api.js:75`\r\n\r\nIntorduced: https://github.com/polkadot-js/api/pull/2385/files#diff-720ad58d2f28c4d558cb24bca641b1e4\r\n\r\n"},
{"text": "After https://github.com/polkadot-js/api/pull/1844\r\n\r\nNot yet on Polkadot, but PR incoming. Replace with system.account\r\n\r\nThis is -\r\n\r\n- all comments\r\n- all examples\r\n- all doc walk-throughs"},
{"text": "TS complains with a:\r\n> Property 'signAndSend' does not exist on type 'Call'.ts(2339)\r\n\r\nwhen using the following code:\r\n```js\r\nconst wsProvider = new WsProvider('ws://127.0.0.1:9944');\r\nconst api = await ApiPromise.create({ provider: wsProvider });\r\nawait web3Enable(APP);\r\n\r\nconst allAccounts = await web3Accounts();\r\nconst injected = await web3FromSource(allAccounts[0].meta.source);\r\napi.setSigner(injected.signer);\r\nconst keyring = new Keyring({ type: 'sr25519' });\r\nconst account = keyring.getPair(allAccounts[0].address);\r\nconst transfer = api.tx.democracy.second('0x01');\r\n\r\n// Sign and Send the extrinsic\r\ntransfer.signAndSend(account, ({ events = [], status }) => {\r\nif (status.isFinalized) {\r\n  console.log('Successful extrinsic with hash ' + status.asFinalized.toHex());\r\n} else {\r\n  console.log('Status of extrinsic: ' + status.type);\r\n}\r\n```\r\n\r\ncc @niklabh https://github.com/paritytech/polkassembly/pull/265"},
{"text": "https://github.com/paritytech/substrate/pull/4718\r\n\r\n`stategetKeys` should be avoided and usage should be replaced by `stategetKeysPaged`"},
{"text": "PR https://github.com/polkadot-js/api/pull/1758\r\n\r\nThis PR broke ability to bundle the api package with wepback because of unsafe require.\r\n\r\nI used to bundle this package with webpack, but updating to the new version (from v0.100.1 to v1.0.1) broke webpack bundle ability.\r\n\r\nMy webpack.config.js:\r\n```javascript\r\n        target: \"node\",\r\n        mode: \"development\",\r\n        output: {\r\n            path: path.resolve(profilePath, 'dist'),\r\n            filename: 'file.js',\r\n            libraryTarget: 'umd',\r\n            library: 'profile',\r\n            umdNamedDefine: true\r\n        },\r\n        resolve: {\r\n            extensions: ['.ts', '.js']\r\n        },\r\n        node: {\r\n            fs: \"empty\"\r\n        },\r\n        module: {\r\n            exprContextCritical: false,\r\n            rules: [\r\n                {\r\n                    test: /\\.ts$/,\r\n                    loader: require.resolve('ts-loader'),\r\n                    exclude: /nodemodules/,\r\n                    options: {\r\n                        configFile: tsconfig,\r\n                        context: profilePath,\r\n                    }\r\n                }\r\n            ]\r\n        }\r\n```\r\n\r\nWebpack error:\r\n`\r\n./nodemodules/@polkadot/api/index.js\r\nModule not found: Error: Can't resolve '../package.json' in '/myproject/nodemodules/@polkadot/api'\r\nresolve '../package.json' in '/myproject/nodemodules/@polkadot/api'\r\n  using description file: /myproject/nodemodules/@polkadot/api/package.json (relative path: .)\r\n    using description file: /myproject/package.json (relative path: ./nodemodules/@polkadot/package.json)\r\n      no extension\r\n        /myproject/nodemodules/@polkadot/package.json doesn't exist\r\n      .ts\r\n        /myproject/nodemodules/@polkadot/package.json.ts doesn't exist\r\n      .js\r\n        /myproject/nodemodules/@polkadot/package.json.js doesn't exist\r\n      as directory\r\n        /myproject/nodemodules/@polkadot/package.json doesn't exist\r\n[/myproject/nodemodules/@polkadot/package.json]\r\n[/myproject/nodemodules/@polkadot/package.json.ts]\r\n[/myproject/nodemodules/@polkadot/package.json.js]\r\n`"},
{"text": "I'm trying to connect to my unsynced node with api 1.0.0-beta.17 \r\n```\r\ntarget=#750431 (25 peers), best: #520014\r\n```\r\nI'm getting \r\n![Screen Shot 2020-01-23 at 16 42 13](https://user-images.githubusercontent.com/3409250/72999295-74938080-3dff-11ea-9667-bd96dcc9c5bd.png)\r\n\r\nwhich is uncatchable with both of these\r\n\r\n```javascript \r\ntry {\r\n  let api = await ApiPromise.create().catch(e => {})\r\n} catch (e) {}\r\n```\r\n\r\nIt also doesn't emit error on \r\n```javascript\r\nprovider.on('error',(e)=>{})\r\n```\r\n\r\nIt results in stuck application since I can't react on anything that happened here. It also happens when you get error while connecting to ``wsprovider`` but it can be handled by wrapping api creation inside another promise, which I can reject. It is not ideal, but it works.\r\n\r\nWhen trying to connect to ``wss://cc3-5.kusama.network/`` I get this on the other hand\r\n\r\n![Screen Shot 2020-01-23 at 16 41 42](https://user-images.githubusercontent.com/3409250/72999309-79583480-3dff-11ea-839f-8dc55b605d44.png)\r\n"},
{"text": "Conversely, `signAndSend` does support external signers"},
{"text": "Currently it does not complain when sending too many args."},
{"text": "This may seem a dumb issue but when trying to fetch metadata from Edgeware via `yarn run chain:info --ws  wss://mainnet1.edgewa.re`, the connection is always rejected with error message: `API-WS: disconnected from wss://mainnet1.edgewa.re code: '1006' reason: 'connection failed'`. This is not the case with any of the other hosted nodes (Kusama, Flaming Fir, etc.) nor with a local node.\r\n\r\nWeird part is that I'm able to connect to Edgeware on apps and get the metadata through the apps toolbox no problem. "},
{"text": "SubmittableExtrinsic.js: send and sendAndSign's subscribe does not work\r\n```\r\nextrinsic.signAndSend(signer, { nonce }, ({ events = [], status }) => {\r\n                console.log('Transaction status:', status.type);\r\n\r\n                if (status.isFinalized) {\r\n                    console.log('Completed at block hash', status.asFinalized.toHex());\r\n                    console.log('Events:');\r\n\r\n                    events.forEach(({ phase, event: { data, method, section } }) => {\r\n                        console.log('\\t', phase.toString(), `: ${section}.${method}`, data.toString());\r\n                    });\r\n\r\n                    process.exit(0);\r\n                }\r\n            });\r\n```\r\nTypeError: Cannot read property 'type' of undefined"},
{"text": "When using custom extrinsic, got an error `1010: Invalid Transaction (-20)`.\r\n\r\nAfter some debugging, it is because of Submittable extends original Extrinsic not the customized impl, then in `Extrinsic.ts:55` where it should pass the if check it fails. (value is a Submittable)\r\n"},
{"text": "Usually customization of extrinsic adds extra fields, like the one we do on our chain adds two extra fields. These extra fields usually need to be passed to signer as part of ExtrinsicPayload.\r\n\r\nCurrently ExtrinsicPayloadValue and SignerPayload are quite specific to the default impl, because it uses method not extrinsic. Things were different at v0.81.x, which is the version we are upgrading our lib from.\r\n"},
{"text": "Currently it only allows for Extrinsic payloads."},
{"text": "i.e. https://github.com/polkadot-js/api/pull/1171/files#diff-a60854aee74a1ede6dc8edf6544d4240R1485\r\n\r\n(These have a specific meaning, code-time constants)\r\n\r\nCurrently: `api.consts.session.dedupKeyPrefix`\r\nExpected: `api.consts.session.DEDUPKEYPREFIX`"},
{"text": "When trying to call `api.tx.system.setCode()` with a large code example (eb 262146 or 131072 bytes),  the transaction starts is return `Finalized`, but the extrinsic fails:\r\n` {\"ApplyExtrinsic\":2} : system.ExtrinsicFailed []`\r\n\r\nThis happens both wrapped in an democracy proposal or called directly via sudo.\r\n<img width=\"1391\" alt=\"Screenshot 2019-07-24 at 11 10 05\" src=\"https://user-images.githubusercontent.com/125398/61781915-773bfb80-ae05-11e9-96f5-a31089d13857.png\">\r\n\r\nThe behaviour can be reproduced by uploading this file (262146 bytes) https://github.com/polkadot-js/api/blob/b1b4530bf13ab6ef2480e42ac0b71bde14a0e707/packages/api/test/mock-data/randomAsHexRaw in the PolkadotJS UI https://polkadot.js.org/apps/#/democracy/propose\r\n\r\nor by running this test https://github.com/polkadot-js/api/blob/b1b4530bf13ab6ef2480e42ac0b71bde14a0e707/packages/api/test/e2e/api/promise-tx.spec.ts#L112\r\n\r\nBoth the UI and the e2e tests are working fine with smaller code examples."},
{"text": "Addresses \"Fix broken / outdated tests\" of https://github.com/polkadot-js/api/issues/908\r\n\r\nConvert all e2e tests to use describeE2E as introduced in https://github.com/polkadot-js/api/pull/1117: \r\n\r\nThese tests should pass without errors/ warnings:\r\n`$ yarn run test:e2e-docker`\r\n`$ yarn run test:e2e-remote`\r\n\r\nFiles that need fixing in `packages/api/test/e2e`:\r\n\r\n`/api/`\r\n- [ ] ( promise-alex-archive.spec.ts ??)\r\n- [x] promise-alex.spec.ts\r\n- [x] promise-consts.spec.ts\r\n- [x] promise-contract.spec.ts\r\n- [x] promise-queries-dev.spec.ts (see known failing tests)\r\n- [x] promise-queries-doubleMap.spec.ts\r\n- [x] promise-queries.spec.ts (see known failing tests)\r\n- [ ] promise-tx-era.spec.ts\r\n- [x] promise-tx-signer.spec.ts (see known failing tests)\r\n- [x] promise-tx.spec.ts (see known failing tests)\r\n- [x] rx-queries-dev.spec.ts\r\n- [x] rx-queries.spec.ts\r\n- [ ] rx-tx.spec.ts\r\n\r\n`/api-derive/`\r\n- [ ] promise-dev.spec.ts\r\n- [ ] promise.spec.ts\r\n- [ ] rx-dev.spec.ts\r\n- [ ] rx.spec.ts\r\n\r\n`/rpc-core/`\r\n- [x] alexander.spec.ts\r\n- [x] basics.spec.ts\r\n- [x] chain.spec.ts\r\n- [x] state.spec.ts\r\n- [x] child-storage.spec.ts\r\n- [x] subscribe.spec.ts\r\n\r\n\r\n\r\n"},
{"text": "Encode to hex, external signer can decode. Will break the interface if people rely on having the codec methods there.\r\n\r\nMentioned in https://github.com/polkadot-js/api/pull/1114#discussionr303033434"},
{"text": "On a recent v2.0 Substrate node\r\n\r\nThe test \"derive e2e \u203a retrieves all staking info (for controller)\" fails with the following:\r\n```bash\r\n    TypeError: Cannot read property 'creator' of undefined\r\n\r\n      560 |           // the input is a QueryableStorageEntry, convert to StorageEntry\r\n      561 |           Array.isArray(arg)\r\n    > 562 |             ? [arg[0].creator, ...arg.slice(1)]\r\n          |                       ^\r\n      563 |             : [arg.creator] as any\r\n      564 |         );\r\n      565 | \r\n\r\n      at creator (packages/api/src/Base.ts:562:23)\r\n          at Array.map (<anonymous>)\r\n      at Object.map [as queryMulti] (packages/api/src/Base.ts:559:30)\r\n      at queryMulti (packages/api-derive/src/staking/info.ts:125:9)\r\n      at SwitchMapSubscriber.withControllerLedger [as project] (packages/api-derive/src/staking/info.ts:167:17)\r\n      at SwitchMapSubscriber.Object.<anonymous>.SwitchMapSubscriber.next (nodemodules/rxjs/src/internal/operators/switchMap.ts:123:21)\r\n      at SwitchMapSubscriber.Object.<anonymous>.Subscriber.next (nodemodules/rxjs/src/internal/Subscriber.ts:99:12)\r\n      at RefCountSubscriber.Object.<anonymous>.Subscriber.next (nodemodules/rxjs/src/internal/Subscriber.ts:139:22)\r\n      at RefCountSubscriber.Object.<anonymous>.Subscriber.next (nodemodules/rxjs/src/internal/Subscriber.ts:99:12)\r\n      at ReplaySubject.Object.<anonymous>.Subject.next (nodemodules/rxjs/src/internal/Subject.ts:70:17)\r\n      at ReplaySubject.Object.<anonymous>.ReplaySubject.nextInfiniteTimeWindow (nodemodules/rxjs/src/internal/ReplaySubject.ts:46:15)\r\n      at ConnectableSubscriber.Object.<anonymous>.Subscriber.next (nodemodules/rxjs/src/internal/Subscriber.ts:139:22)\r\n      at ConnectableSubscriber.Object.<anonymous>.Subscriber.next (nodemodules/rxjs/src/internal/Subscriber.ts:99:12)\r\n      at Object.next [as callback] (packages/rpc-core/src/index.ts:183:22)\r\n      at WsProvider.callback [as onSocketMessageSubscribe] (packages/rpc-provider/src/ws/Provider.ts:352:15)\r\n      at WsProvider.onSocketMessageSubscribe [as onSocketMessageResult] (packages/rpc-provider/src/ws/Provider.ts:323:16)\r\n      at WebSocket.onSocketMessageResult (packages/rpc-provider/src/ws/Provider.ts:292:14)\r\n      at WebSocket.<anonymous> (nodemodules/jsdom/lib/jsdom/living/helpers/create-event-accessor.js:33:32)\r\n      at invokeEventListeners (nodemodules/jsdom/lib/jsdom/living/events/EventTarget-impl.js:193:27)\r\n      at WebSocketImpl.dispatch (nodemodules/jsdom/lib/jsdom/living/events/EventTarget-impl.js:119:9)\r\n      at WebSocketImpl.onMessageReceived (nodemodules/jsdom/lib/jsdom/living/websockets/WebSocket-impl.js:208:10)\r\n      at Receiver.receiverOnMessage (nodemodules/ws/lib/websocket.js:720:20)\r\n      at Receiver.dataMessage (nodemodules/ws/lib/receiver.js:414:14)\r\n      at Receiver.getData (nodemodules/ws/lib/receiver.js:346:17)\r\n      at Receiver.startLoop (nodemodules/ws/lib/receiver.js:133:22)\r\n      at Receiver.write (nodemodules/ws/lib/receiver.js:69:10)\r\n      at Socket.socketOnData (nodemodules/ws/lib/websocket.js:795:35)\r\n```\r\n\r\nlinked to https://github.com/polkadot-js/apps/issues/1386"},
{"text": "**Repro:**\r\n\r\n```javascript\r\n      api.derive.staking.info(stashId, (result) => {\r\n        ++count;\r\n\r\n        console.error('***', count, JSON.stringify(result));\r\n      }).catch(console.error);\r\n```\r\n\r\n**Expected:**\r\n\r\n```\r\n *** 7 {\"accountId\":\"5GNJqTPyNqANBkUVMN1LPPrxXnFouWXoe2wNSmmEoLctxiZY\",\"controllerId\":\"5GrwvaEF5zXb26Fz9rcQpDWS57CtERHpNehXCPcNoHGKutQY\",\"nextSessionId\":\"5FA9nQDVg267DEd8m1ZypXLBnvN7SFxYwV7ndqSYGiN9TTpu\",\"nominators\":[],\"redeemable\":\"0\",\"rewardDestination\":1,\"stakers\":{\"total\":\"0x0000000000000000002386f26fc10000\",\"own\":\"0x0000000000000000002386f26fc10000\",\"others\":[]},\"stakingLedger\":{\"stash\":\"5GNJqTPyNqANBkUVMN1LPPrxXnFouWXoe2wNSmmEoLctxiZY\",\"total\":\"0x0000000000000000002386f26fc10000\",\"active\":\"0x0000000000000000002386f26fc10000\",\"unlocking\":[]},\"stashId\":\"5GNJqTPyNqANBkUVMN1LPPrxXnFouWXoe2wNSmmEoLctxiZY\",\"validatorPrefs\":{\"unstakeThreshold\":3,\"validatorPayment\":0}}\r\n\r\n...\r\n\r\n *** 8 something slightly different\r\n\r\n```\r\n\r\n**Actual:**\r\n\r\n```\r\n    *** 7 {\"accountId\":\"5GNJqTPyNqANBkUVMN1LPPrxXnFouWXoe2wNSmmEoLctxiZY\",\"controllerId\":\"5GrwvaEF5zXb26Fz9rcQpDWS57CtERHpNehXCPcNoHGKutQY\",\"nextSessionId\":\"5FA9nQDVg267DEd8m1ZypXLBnvN7SFxYwV7ndqSYGiN9TTpu\",\"nominators\":[],\"redeemable\":\"0\",\"rewardDestination\":1,\"stakers\":{\"total\":\"0x0000000000000000002386f26fc10000\",\"own\":\"0x0000000000000000002386f26fc10000\",\"others\":[]},\"stakingLedger\":{\"stash\":\"5GNJqTPyNqANBkUVMN1LPPrxXnFouWXoe2wNSmmEoLctxiZY\",\"total\":\"0x0000000000000000002386f26fc10000\",\"active\":\"0x0000000000000000002386f26fc10000\",\"unlocking\":[]},\"stashId\":\"5GNJqTPyNqANBkUVMN1LPPrxXnFouWXoe2wNSmmEoLctxiZY\",\"validatorPrefs\":{\"unstakeThreshold\":3,\"validatorPayment\":0}}\r\n\r\n...\r\n\r\n    *** 8 {\"accountId\":\"5GNJqTPyNqANBkUVMN1LPPrxXnFouWXoe2wNSmmEoLctxiZY\",\"controllerId\":\"5GrwvaEF5zXb26Fz9rcQpDWS57CtERHpNehXCPcNoHGKutQY\",\"nextSessionId\":\"5FA9nQDVg267DEd8m1ZypXLBnvN7SFxYwV7ndqSYGiN9TTpu\",\"nominators\":[],\"redeemable\":\"0\",\"rewardDestination\":1,\"stakers\":{\"total\":\"0x0000000000000000002386f26fc10000\",\"own\":\"0x0000000000000000002386f26fc10000\",\"others\":[]},\"stakingLedger\":{\"stash\":\"5GNJqTPyNqANBkUVMN1LPPrxXnFouWXoe2wNSmmEoLctxiZY\",\"total\":\"0x0000000000000000002386f26fc10000\",\"active\":\"0x0000000000000000002386f26fc10000\",\"unlocking\":[]},\"stashId\":\"5GNJqTPyNqANBkUVMN1LPPrxXnFouWXoe2wNSmmEoLctxiZY\",\"validatorPrefs\":{\"unstakeThreshold\":3,\"validatorPayment\":0}}\r\n```\r\n\r\nNotes:\r\n- I added a distinctUntilChanged in drr in api-derive, but right now it's a bit useless, because it only checks on === for different values, should check at least on `Codec` and `Codec[]`\r\n- The 2nd thing is I'm not sure distinctUntilChanged on api-derive is useful, it should probably take place lower down the level, so that repeated values don't happen on api.query or api.rpc.state.subscribeStorage"},
{"text": "```javascript\r\napi.queryMulti([\r\n  [api.query.session.nextKeyFor, controllerId],\r\n  [api.query.staking.ledger, controllerId],\r\n], callback)\r\n```\r\n\r\nFirst result: [something1, something2],\r\n\r\n**Expected:** \r\n\r\nsecond result: [something1, something3]\r\n\r\n**Actual:**\r\n\r\nsecond result: [null, something3]\r\n\r\n"},
{"text": "I removed the following test from `@polkadot/api/test/e2e/promise-queries.spec.ts` in https://github.com/polkadot-js/api/pull/1066, because the test used `existentialDeposit` to test the storage with a well-known value. However, `existentialDeposit` has since been moved to `consts`. The test needs to be rewritten to use another storage.\r\n\r\n```js\r\ndescribe('with plain type', () => {\r\n    const EXISTENTIALDEPOSIT = 500;\r\n    it('queries correct value', async () => {\r\n      const existentialDeposit = await api.query.balances.existentialDeposit() as Balance;\r\n\r\n      expect(existentialDeposit.toNumber()).toEqual(EXISTENTIALDEPOSIT);\r\n    });\r\n\r\n    it('queries correct value at a specified block', async () => {\r\n      const header = await api.rpc.chain.getHeader() as Header;\r\n      const existentialDepositAt = await api.query.balances.existentialDeposit.at(header.hash) as Balance;\r\n\r\n      expect(existentialDepositAt.toNumber()).toEqual(EXISTENTIALDEPOSIT);\r\n    });\r\n\r\n    it('subscribes to query and get correct result', (done) => {\r\n      return api.query.balances.existentialDeposit((existentialDeposit: Balance) => {\r\n        expect(existentialDeposit.toNumber()).toEqual(EXISTENTIALDEPOSIT);\r\n        done();\r\n      });\r\n    });\r\n\r\n    it('queries correct hash', async () => {\r\n      const hash = await api.query.balances.existentialDeposit.hash();\r\n\r\n      expect(hash).toBeDefined();\r\n    });\r\n\r\n    it('gets correct key', async () => {\r\n      const key = api.query.balances.existentialDeposit.key();\r\n      const existentialDepositData = await api.rpc.state.getStorage(key) as Option<any>;\r\n      const existentialDepositRPC = new Balance(existentialDepositData.unwrapOr(undefined));\r\n\r\n      expect(existentialDepositRPC.toNumber()).toEqual(EXISTENTIALDEPOSIT);\r\n    });\r\n\r\n    it('queries correct size', async () => {\r\n      const size = await api.query.balances.existentialDeposit.size();\r\n\r\n      expect(size.toNumber()).not.toEqual(0);\r\n    });\r\n  });\r\n```"},
{"text": "In decorateStorageEntry:\r\n\r\nhttps://github.com/polkadot-js/api/blob/aed73e2bb3d395d4210e193f996b19bcfab0ee91/packages/api/src/Base.ts#L585\r\n\r\nso right now:\r\n```javascript\r\nconst api = new ApiPromise();\r\nawait api.query.system.accountNonce(addr1); // uses subscribeStorage, with immediate unsubscribe after resolve\r\n```\r\n\r\nExpected: uses `stategetStorage`.\r\n\r\nEdit: same for multi"},
{"text": "Same thing as in #987, for `api.rpc.*.*`\r\n\r\nThis is different from #714, since these can be inferred in-editor."},
{"text": "process:\r\n  - construct & sign tx offline (could be external signer or creator)\r\n  - send tx via the api\r\n\r\n```js\r\nconst nonce = await api.query.system.accountNonce(keyring.dave.address());\r\nconst hex = api.tx.balances\r\n  .transfer(keyring.eve.address(), 12345)\r\n  .sign(keyring.dave, { nonce })\r\n  .toHex(); // hex UncheckedMortalExtrinsic\r\n\r\nreturn api.tx(hex).send(({ events, status }) => { ... });\r\n```"},
{"text": "`Option<T>`, `Result<T,E>` and `Vec<T>` (`Vec<T>` not listed below, but has the same form as `Option<T>`)\r\n\r\nExample ABI: (@jacogr & @robbepop has the WASM for this)\r\n\r\n```js\r\n{\r\n    \"name\": \"SharedVec\",\r\n    \"deploy\": {\r\n        \"args\": []\r\n    },\r\n    \"messages\": [\r\n        {\r\n            \"name\": \"push\",\r\n            \"selector\": 865577567,\r\n            \"mutates\": true,\r\n            \"args\": [\r\n                {\r\n                    \"name\": \"value\",\r\n                    \"type\": \"i32\"\r\n                }\r\n            ],\r\n            \"returntype\": {\r\n                \"Result<T,E>\": {\r\n                    \"T\": [],\r\n                    \"E\": \"u32\"\r\n                }\r\n            }\r\n        },\r\n        {\r\n            \"name\": \"register\",\r\n            \"selector\": 572030971,\r\n            \"mutates\": true,\r\n            \"args\": [\r\n                {\r\n                    \"name\": \"mutator\",\r\n                    \"type\": \"AccountId\"\r\n                },\r\n                {\r\n                    \"name\": \"begin\",\r\n                    \"type\": {\r\n                        \"Option<T>\": {\r\n                            \"T\": \"u32\"\r\n                        }\r\n                    }\r\n                },\r\n                {\r\n                    \"name\": \"end\",\r\n                    \"type\": {\r\n                        \"Option<T>\": {\r\n                            \"T\": \"u32\"\r\n                        }\r\n                    }\r\n                }\r\n            ],\r\n            \"returntype\": {\r\n                \"Result<T,E>\": {\r\n                    \"T\": [],\r\n                    \"E\": \"u32\"\r\n                }\r\n            }\r\n        },\r\n        {\r\n            \"name\": \"set\",\r\n            \"selector\": 2028185770,\r\n            \"mutates\": true,\r\n            \"args\": [\r\n                {\r\n                    \"name\": \"at\",\r\n                    \"type\": \"u32\"\r\n                },\r\n                {\r\n                    \"name\": \"to\",\r\n                    \"type\": \"i32\"\r\n                }\r\n            ],\r\n            \"returntype\": {\r\n                \"Result<T,E>\": {\r\n                    \"T\": \"i32\",\r\n                    \"E\": \"u32\"\r\n                }\r\n            }\r\n        },\r\n        {\r\n            \"name\": \"get\",\r\n            \"selector\": 4266279973,\r\n            \"mutates\": false,\r\n            \"args\": [\r\n                {\r\n                    \"name\": \"at\",\r\n                    \"type\": \"u32\"\r\n                }\r\n            ],\r\n            \"returntype\": {\r\n                \"Option<T>\": {\r\n                    \"T\": \"i32\"\r\n                }\r\n            }\r\n        },\r\n        {\r\n            \"name\": \"len\",\r\n            \"selector\": 1403873684,\r\n            \"mutates\": false,\r\n            \"args\": [],\r\n            \"returntype\": \"u32\"\r\n        }\r\n    ]\r\n}\r\n```"},
{"text": "This happens for both Substrate and Alexander and only on stash accounts AFAICS.\r\n\r\n`Mismatch decoding '15', computed as '7' with TransactionPayment,Transfer,Reserve`\r\n\r\nTo reproduce:\r\nIn extrinsics: balances > locks on a stash account e.g `Alicestash` in substrate\r\n\r\nor in the JS console:\r\n```js\r\nconst [balancesLocksSubstrate, balancesLocksAlexander ] = await Promise.all([\r\n  api.query.balances.locks('5GNJqTPyNqANBkUVMN1LPPrxXnFouWXoe2wNSmmEoLctxiZY'),\r\n  api.query.balances.locks('5DWrJzdCLLEXFndG6qjCNaMFU74sMEdNwg8TuLLwRiGJcYsn')\r\n]);\r\n\r\nconsole.log('locks: ' + balancesLocksSubstrate);\r\nconsole.log('locks: ' + balancesLocksAlexander);\r\n```\r\n![image](https://user-images.githubusercontent.com/33178835/57103328-bcc8bb00-6d25-11e9-92f8-8792cff16457.png)\r\n"},
{"text": "(Marking as question since it is not really confirmed and may just be due to me not quite grasping some basics)\r\n\r\nLet's start at the top, I believe this is needed: https://github.com/polkadot-js/api/blob/master/packages/api/src/Base.ts#L554 - as new entries get added, the head is updated, so it nicely triggers the reload of all/\r\n\r\nHowever, not convinced about this - https://github.com/polkadot-js/api/blob/master/packages/api/src/Base.ts#L505\r\n\r\nThe problem is that as the entry changes (say an entry was removed in the middle), I'm not sure how this actually caters for refreshing that part of the list and/or the whole list. Since at on subsequent loads we are basically done, I am not sure how the list gets refreshed. \r\n\r\nTL;DR - Can see how adding a new entry causes a refresh of the list (and can visibly see this with the apps UI), however for stuff that gets removed from the list, cannot quite wrap around the refresh thereof.\r\n\r\nThis could be related to https://github.com/polkadot-js/apps/issues/857 (however that could very well be a UI bug, things are still WIP and not 100% clean there)\r\n\r\ncc @xlc @amaurymartiny  - you may be able to help guide me along the right track. This looks correct, but not sure how/if it works in practice since with these refreshes can be problematic"},
{"text": "I just want to mention something I found strange when working with the @polkadot/api and registering custom types. For some reason `await ApiPromise.create({ types})` doesn\u2019t work for me instead I need to use `getTypeRegistry().register(types);`\r\n\r\n`await ApiPromise.create({ types})` creates the following errors in the chrome console:\r\n`2019-03-13 16:39:17        RPC-CORE: getMetadata (block: Hash): Customtype:: Number can only safely store up to 53 bits\r\n2019-03-13 16:39:17   API/DECORATOR: loadMeta a: getMetadata (block: Hash): Customtype:: Number can only safely store up to 53 bits`"},
{"text": "- Requires https://github.com/polkadot-js/common/pull/297\r\n- From https://github.com/polkadot-js/common/issues/298"},
{"text": "It looks like trackStatus inside send() is being called twice. "},
{"text": "> nodeJs console.log(api); : \r\n```\r\napi:---- ApiPromise {\r\n  eventemitter: EventEmitter { events: { error: [EE] }, eventsCount: 1 },\r\n  extrinsics:\r\n   { timestamp: { set: [Function] },\r\n     consensus:\r\n      { reportMisbehavior: [Function],\r\n        noteOffline: [Function],\r\n        remark: [Function],\r\n        setHeapPages: [Function],\r\n        setCode: [Function],\r\n        setStorage: [Function] },\r\n     balances: { transfer: [Function], setBalance: [Function] },\r\n     session:\r\n      { setKey: [Function],\r\n        setLength: [Function],\r\n        forceNewSession: [Function] },\r\n     staking:\r\n      { stake: [Function],\r\n        unstake: [Function],\r\n        nominate: [Function],\r\n        unnominate: [Function],\r\n        registerPreferences: [Function],\r\n        setSessionsPerEra: [Function],\r\n        setBondingDuration: [Function],\r\n        setValidatorCount: [Function],\r\n        forceNewEra: [Function],\r\n        setOfflineSlashGrace: [Function] },\r\n     democracy:\r\n      { propose: [Function],\r\n        second: [Function],\r\n        vote: [Function],\r\n        startReferendum: [Function],\r\n        cancelReferendum: [Function],\r\n        cancelQueued: [Function] },\r\n     council:\r\n      { setApprovals: [Function],\r\n        reapInactiveVoter: [Function],\r\n        retractVoter: [Function],\r\n        submitCandidacy: [Function],\r\n        presentWinner: [Function],\r\n        setDesiredSeats: [Function],\r\n        removeMember: [Function],\r\n        setPresentationDuration: [Function],\r\n        setTermDuration: [Function] },\r\n     councilVoting:\r\n      { propose: [Function],\r\n        vote: [Function],\r\n        veto: [Function],\r\n        setCooloffPeriod: [Function],\r\n        setVotingPeriod: [Function] },\r\n     councilMotions: { propose: [Function], vote: [Function] },\r\n     grandpa: { reportMisbehavior: [Function] },\r\n     treasury:\r\n      { proposeSpend: [Function],\r\n        setPot: [Function],\r\n        configure: [Function],\r\n        rejectProposal: [Function],\r\n        approveProposal: [Function] },\r\n     contract: { call: [Function], create: [Function] },\r\n     upgradeKey: { upgrade: [Function], setKey: [Function] },\r\n     sudo: { sudo: [Function], setKey: [Function] } },\r\n  genesisHash:\r\n ... ...\r\n```\r\n**It's complete.**\r\n------\r\n\r\n> But the RN console.log(api); :\r\n\r\n```\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS: 'api:-------', { eventemitter: \r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:    { events: { error: { fn: [Function], context: [Circular], once: true } },\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:      eventsCount: 1 },\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:   extrinsics: {},\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:   genesisHash: {},\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:   query: \r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:    { substrate: \r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:       { code: \r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:          { [Function: decorated]\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:            at: [Function],\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:            meta: \r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:             { documentation: \r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                [ { '0': 'W',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '1': 'a',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '2': 's',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '3': 'm',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '4': ' ',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '5': 'c',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '6': 'o',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '7': 'd',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '8': 'e',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '9': ' ',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '10': 'o',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '11': 'f',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '12': ' ',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '13': 't',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '14': 'h',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '15': 'e',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '16': ' ',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '17': 'r',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '18': 'u',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '19': 'n',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '20': 't',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '21': 'i',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '22': 'm',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '23': 'e',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '24': '.' },\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                  Type: [Function: Text] ],\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:               modifier: { raw: 0, enum: [ 'None', 'Default', 'Required' ] },\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:               type: \r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                { raw: \r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                   { '0': 'B',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                     '1': 'y',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                     '2': 't',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                     '3': 'e',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                     '4': 's',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                     originalLength: 6 },\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                  def: \r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                   { Type: [Function: Type],\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                     'StorageFunctionType$Map': [Function: StorageFunctionType$Map] },\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                  index: 0,\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                  indexes: [ 0, 1 ] },\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:               toJSON: [Function: toJSON] },\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:            method: 'code',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:            section: 'substrate',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:            toJSON: [Function] },\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:         heapPages: \r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:          { [Function: decorated]\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:            at: [Function],\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:            meta: \r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:             { documentation: \r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                [ { '0': 'N',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '1': 'u',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '2': 'm',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '3': 'b',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '4': 'e',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '5': 'r',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '6': ' ',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '7': 'o',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '8': 'f',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '9': ' ',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '10': 'w',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '11': 'a',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '12': 's',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '13': 'm',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '14': ' ',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '15': 'l',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '16': 'i',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '17': 'n',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '18': 'e',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '19': 'a',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '20': 'r',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '21': ' ',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '22': 'm',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '23': 'e',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '24': 'm',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '25': 'o',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '26': 'r',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '27': 'y',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '28': ' ',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '29': 'p',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '30': 'a',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '31': 'g',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '32': 'e',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '33': 's',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '34': ' ',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '35': 'r',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '36': 'e',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '37': 'q',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '38': 'u',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '39': 'i',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '40': 'r',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '41': 'e',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '42': 'd',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '43': ' ',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '44': 'f',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '45': 'o',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '46': 'r',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '47': ' ',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '48': 'e',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '49': 'x',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '50': 'e',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '51': 'c',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '52': 'u',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '53': 't',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '54': 'i',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '55': 'o',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '56': 'n',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '57': ' ',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '58': 'o',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '59': 'f',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '60': ' ',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '61': 't',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '62': 'h',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '63': 'e',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '64': ' ',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '65': 'r',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '66': 'u',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '67': 'n',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '68': 't',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '69': 'i',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '70': 'm',\r\n01-01 16:48:57.505  3704  3735 I ReactNativeJS:                    '7\r\n```\r\nIt\u2018s incomplete, so.. such as api.query.xxxx,  api.extrinsics, api.tx, and more, can't to be working.\r\n![ 20181222002106](https://user-images.githubusercontent.com/34789555/50574587-4626ba00-0e26-11e9-855f-62d8bf4c0569.png)\r\n\r\n"},
{"text": "  **polkadot Api version** : \r\n```\r\n    \"@polkadot/api\": \"^0.33.17\",\r\n    \"@polkadot/rpc-provider\": \"^0.33.17\"\r\n```\r\n**This React-Native project create way is** :\r\n `react-native init Project`\r\n```\r\ncd Project\r\nreact-native run-android\r\n```\r\n\r\n**packages**:\r\n```\r\n\"dependencies\": {\r\n    \"axios\": \"0.18.0\",\r\n    \"ethers\": \"3.0.27\",\r\n    \"identicon.js\": \"2.3.2\",\r\n    \"mobx\": \"^4.3.1\",\r\n    \"mobx-react\": \"5.2.5\",\r\n    \"moment\": \"2.22.2\",\r\n    \"react\": \"16.4.2\",\r\n    \"react-native\": \"0.56.0\",\r\n    \"react-native-camera\": \"1.2.0\",\r\n    \"react-native-modal\": \"6.5.0\",\r\n    \"react-native-permissions\": \"1.1.1\",\r\n    \"react-native-qrcode-svg\": \"5.1.0\",\r\n    \"react-native-sensitive-info\": \"5.2.4\",\r\n    \"react-native-snackbar\": \"0.5.0\",\r\n    \"react-native-svg\": \"6.5.2\",\r\n    \"react-native-vector-icons\": \"5.0.0\",\r\n    \"react-navigation\": \"2.12.1\",\r\n    \"@polkadot/api\": \"^0.33.17\",\r\n    \"@polkadot/rpc-provider\": \"^0.33.17\"\r\n  },\r\n  \"devDependencies\": {\r\n    \"@babel/core\": \"7.0.0-beta.47\",\r\n    \"@babel/plugin-proposal-decorators\": \"7.0.0-beta.47\",\r\n    \"@babel/plugin-transform-runtime\": \"7.0.0-beta.47\",\r\n    \"@babel/runtime\": \"7.0.0-beta.47\",\r\n    \"babel-core\": \"7.0.0-bridge.0\",\r\n    \"babel-jest\": \"23.4.2\",\r\n    \"babel-plugin-module-resolver\": \"3.1.1\",\r\n    \"babel-preset-react-native\": \"5.0.2\",\r\n    \"enzyme\": \"3.5.0\",\r\n    \"enzyme-adapter-react-16\": \"1.3.0\",\r\n    \"eslint-config-rallycoding\": \"3.2.0\",\r\n    \"jest\": \"23.5.0\",\r\n    \"jsdom\": \"12.0.0\",\r\n    \"react-native-mock-render\": \"0.1.1\",\r\n    \"react-test-renderer\": \"16.4.2\",\r\n    \"rimraf\": \"^2.6.2\"\r\n  },\r\n```\r\n\r\n**When I import the @polkadot/api to **React Native** project. get the error**:\r\n```\r\nerror: bundling failed: Error: Unable to resolve module `core-js/modules/es6.regexp.to-string` from `/media/threebody/DATA/Desktop/github/ethereum-wallet/nodemodules/@polkadot/util/logger.js`: Module `core-js/modules/es6.regexp.to-string` does not exist in the Haste module map\r\n\r\nThis might be related to https://github.com/facebook/react-native/issues/4968\r\nTo resolve try the following:\r\n  1. Clear watchman watches: `watchman watch-del-all`.\r\n  2. Delete the `nodemodules` folder: `rm -rf nodemodules && npm install`.\r\n  3. Reset Metro Bundler cache: `rm -rf /tmp/metro-bundler-cache-*` or `npm start -- --reset-cache`.  4. Remove haste cache: `rm -rf /tmp/haste-map-react-native-packager-*`.\r\n\r\n```\r\n![ 20181217193346](https://user-images.githubusercontent.com/34789555/50085161-373fe500-0234-11e9-8c66-caabe7751988.png)\r\n\r\n```\r\nThe development server returned response error code: 500\r\n\r\nURL: http://10.0.2.2:8081/index.delta?platform=android&dev=true&minify=false\r\n\r\nBody:\r\n{\"originModulePath\":\"/media/threebody/DATA/Desktop/github/ethereum-wallet/nodemodules/@polkadot/util/logger.js\",\"targetModuleName\":\"core-js/modules/es6.regexp.to-string\",\"message\":\"Unable to resolve module `core-js/modules/es6.regexp.to-string` from `/media/threebody/DATA/Desktop/github/ethereum-wallet/nodemodules/@polkadot/util/logger.js`: Module `core-js/modules/es6.regexp.to-string` does not exist in the Haste module map\\n\\nThis might be related to https://github.com/facebook/react-native/issues/4968\\nTo resolve try the following:\\n  1. Clear watchman watches: `watchman watch-del-all`.\\n  2. Delete the `nodemodules` folder: `rm -rf nodemodules && npm install`.\\n  3. Reset Metro Bundler cache: `rm -rf /tmp/metro-bundler-cache-*` or `npm start -- --reset-cache`.  4. Remove haste cache: `rm -rf /tmp/haste-map-react-native-packager-*`.\",\"errors\":[{\"description\":\"Unable to resolve module `core-js/modules/es6.regexp.to-string` from `/media/threebody/DATA/Desktop/github/ethereum-wallet/nodemodules/@polkadot/util/logger.js`: Module `core-js/modules/es6.regexp.to-string` does not exist in the Haste module map\\n\\nThis might be related to https://github.com/facebook/react-native/issues/4968\\nTo resolve try the following:\\n  1. Clear watchman watches: `watchman watch-del-all`.\\n  2. Delete the `nodemodules` folder: `rm -rf nodemodules && npm install`.\\n  3. Reset Metro Bundler cache: `rm -rf /tmp/metro-bundler-cache-*` or `npm start -- --reset-cache`.  4. Remove haste cache: `rm -rf /tmp/haste-map-react-native-packager-*`.\"}],\"name\":\"Error\",\"stack\":\"Error: Unable to resolve module `core-js/modules/es6.regexp.to-string` from `/media/threebody/DATA/Desktop/github/ethereum-wallet/nodemodules/@polkadot/util/logger.js`: Module `core-js/modules/es6.regexp.to-string` does not exist in the Haste module map\\n\\nThis might be related to https://github.com/facebook/react-native/issues/4968\\nTo resolve try the following:\\n  1. Clear watchman watches: `watchman watch-del-all`.\\n  2. Delete the `nodemodules` folder: `rm -rf nodemodules && npm install`.\\n  3. Reset Metro Bundler cache: `rm -rf /tmp/metro-bundler-cache-*` or `npm start -- --reset-cache`.  4. Remove haste cache: `rm -rf /tmp/haste-map-react-native-packager-*`.\\n    at ModuleResolver.resolveDependency (/media/threebody/DATA/Desktop/github/ethereum-wallet/nodemodules/metro/src/node-haste/DependencyGraph/ModuleResolution.js:167:1306)\\n    at ResolutionRequest.resolveDependency (/media/threebody/DATA/Desktop/github/ethereum-wallet/nodemodules/metro/src/node-haste/DependencyGraph/ResolutionRequest.js:80:16)\\n    at DependencyGraph.resolveDependency (/media/threebody/DATA/Desktop/github/ethereum-wallet/nodemodules/metro/src/node-haste/DependencyGraph.js:237:485)\\n    at Object.resolve (/media/threebody/DATA/Desktop/github/ethereum-wallet/nodemodules/metro/src/lib/transformHelpers.js:116:25)\\n    at dependencies.map.result (/media/threebody/DATA/Desktop/github/ethereum-wallet/nodemodules/metro/src/DeltaBundler/traverseDependencies.js:298:29)\\n    at Array.map (<anonymous>)\\n    at resolveDependencies (/media/threebody/DATA/Desktop/github/ethereum-wallet/nodemodules/metro/src/DeltaBundler/traverseDependencies.js:294:16)\\n    at /media/threebody/DATA/Desktop/github/ethereum-wallet/nodemodules/metro/src/DeltaBundler/traverseDependencies.js:159:33\\n    at Generator.next (<anonymous>)\\n    at step (/media/threebody/DATA/Desktop/github/ethereum-wallet/nodemodules/metro/src/DeltaBundler/traverseDependencies.js:239:307)\"}\r\nprocessBundleResult\r\n    BundleDownloader.java:285\r\naccess$200\r\n    BundleDownloader.java:37\r\nonResponse\r\n    BundleDownloader.java:163\r\nexecute\r\n    RealCall.java:153\r\nrun\r\n    NamedRunnable.java:32\r\nrunWorker\r\n    ThreadPoolExecutor.java:1162\r\nrun\r\n    ThreadPoolExecutor.java:636\r\nrun\r\n    Thread.java:764\r\n\r\n```\r\n"},
{"text": "(Needs https://github.com/polkadot-js/api/issues/475)\r\n\r\n- submitAndWatch\r\n- track status events\r\n- upon completion (non-Finalization), end\r\n- upon Finalization, track events in next steps\r\n- get block, check for extrinsic inclusion (against data)\r\n- if found, pull system.events for that block\r\n- return events as part of the subscription, i.e. callback becomes `(status: ExtsinsicStatus, events?: Events)` as opposed to the current `(status: ExtinsicStatus)`\r\n\r\nPromise here is easy, I'm not convinced about the RxJS version, i.e. don't want to change the signature to `[ExtrinsicStatus, Vector]` there - not 100% sure how to deal with allowing `.subscribe((status: ExtsinsicStatus, events?: Events) => {...})` there"},
{"text": "- Description and tracking issue https://github.com/paritytech/substrate/issues/1256\r\n- Implementation in https://github.com/paritytech/substrate/pull/1264\r\n\r\n(Assigning @amaurymartiny since he has been looking at it and playing with it already)"},
{"text": "Hi Polkadot and Substrate team, we're having a small issue with testing where transactions are being returned as finalised but the nodes have not updated their block status. I've followed the example transaction code and I've pasted what I've done below. It's entirely possible that I'm not running the transaction code correctly. \r\n\r\nHere is the code that I've been using to run the sample transaction code: \r\n\r\n```\r\nimport {ApiPromise} from '@polkadot/api';\r\nimport {Keyring} from '@polkadot/keyring';\r\nimport WsProvider from '@polkadot/rpc-provider/ws';\r\nimport {stringToU8a} from '@polkadot/util';\r\n\r\nimport additionalTypes from './types';\r\n\r\nasync function main() {\r\n  const ws = 'ws://localhost:9944';\r\n  const keyring = new Keyring();\r\n  let seed = 'Alice';\r\n  if (seed && seed.length < 32) {\r\n    seed = seed.padEnd(32, ' ');\r\n  }\r\n\r\n  const sender = keyring.addFromSeed(stringToU8a(seed));\r\n  const provider = new WsProvider(ws);\r\n  const api = await ApiPromise.create({\r\n    provider,\r\n    types: additionalTypes\r\n  });\r\n  try {\r\n    const nonce: any = await api.query.system.accountNonce(sender.address());\r\n    console.log('Nonce before transaction', String(nonce));\r\n    const block = await api.rpc.chain.getHeader();\r\n\r\n    console.log('Block status before transaction', String(block));\r\n\r\n    const tx = await api.tx.balances.transfer(\r\n      '5Gw3s7q4QLkSWwknsiPtjujPv3XM4Trxi5d4PgKMMk3gfGTE',\r\n      123\r\n    );\r\n    tx.sign(sender, nonce);\r\n    await tx\r\n      .send(status => console.log(`Status type is: ${status.type}`))\r\n      .then(hash => {\r\n        console.log(`submitted with hash ${hash}`);\r\n      });\r\n\r\n    const blockafter = await api.rpc.chain.getHeader();\r\n\r\n    console.log('Block status after transaction', String(blockafter));\r\n    const nonceafter: any = await api.query.system.accountNonce(\r\n      sender.address()\r\n    );\r\n    console.log('Nonce after transaction', String(nonceafter));\r\n  } catch (e) {\r\n    console.log(e);\r\n  }\r\n  process.exit(1);\r\n}\r\n\r\nmain();\r\n```\r\n\r\nHere is the result of the console.logs \r\n\r\n```\r\nNonce before transaction 40\r\nBlock status before transaction {\"parentHash\":\"0x57e79da1292a9680c153b00bb1581a980caa804948c4aa245bb149a8b97c9e93\",\"number\":4357,\"stateRoot\":\"0xfa1286e210d3be2401de6a5a0d80d5e3a000652f594b6d2c01b958bc5b0fc4e3\",\"extrinsicsRoot\":\"0x93123d7542541f55630064c216b523e890552f6ea06daa85215ee810441602c5\",\"digest\":{\"logs\":[[257442668,\"0xdd344f5bbd65bdaa3bbf0fc623a7358565510f2b61e4b9f74dfda105e36eed3a257b12ecc06301dde48b6877c0e7f122162e68802b03c953e452ab1d4437ee07\"]]}}\r\nsubmitted with hash 16\r\nStatus type is: Finalised\r\nBlock status after transaction {\"parentHash\":\"0x57e79da1292a9680c153b00bb1581a980caa804948c4aa245bb149a8b97c9e93\",\"number\":4357,\"stateRoot\":\"0xfa1286e210d3be2401de6a5a0d80d5e3a000652f594b6d2c01b958bc5b0fc4e3\",\"extrinsicsRoot\":\"0x93123d7542541f55630064c216b523e890552f6ea06daa85215ee810441602c5\",\"digest\":{\"logs\":[[257442668,\"0xdd344f5bbd65bdaa3bbf0fc623a7358565510f2b61e4b9f74dfda105e36eed3a257b12ecc06301dde48b6877c0e7f122162e68802b03c953e452ab1d4437ee07\"]]}}\r\nNonce after transaction 40\r\n```\r\n\r\nIs there something I am doing wrong with respect to the transaction? Because the Status type is telling me that the transaction has been Finalised but neither the block states nor the nodes have updated to reflect this transaction. \r\n\r\nI'm running a single node network on my local machine (Macbook Pro 2017, Mac OS High Sierra) with respect to substrate, and here are the logs for the substrate instance from a few seconds before I send the transaction to a few seconds after.\r\n\r\n```\r\n2018-12-13 12:10:11 Idle (0 peers), best: #4376 (0xe03d\u20260faa)\r\n2018-12-13 12:10:13 Proposing block [number: 4377; hash: 0x955e\u202693cc; parenthash: 0xe03d\u20260faa; extrinsics: [0xc877\u202644ca, 0x7b4e\u20262d59]]\r\n2018-12-13 12:10:16 Idle (0 peers), best: #4376 (0xe03d\u20260faa)\r\n2018-12-13 12:10:17 Imported #4377 (0x1f84\u2026d8db)\r\n2018-12-13 12:10:18 Starting consensus session on top of parent 0x1f8407cab28e54041f0051e57f8c91291f347025532f9bb1418a7024440fd8db\r\n2018-12-13 12:10:21 Idle (0 peers), best: #4377 (0x1f84\u2026d8db)\r\n2018-12-13 12:10:22 Proposing block [number: 4378; hash: 0xfa44\u2026d392; parenthash: 0x1f84\u2026d8db; extrinsics: [0x2f9a\u2026d775, 0x7b4e\u20262d59]]\r\n2018-12-13 12:10:26 Idle (0 peers), best: #4377 (0x1f84\u2026d8db)\r\n2018-12-13 12:10:27 Imported #4378 (0x9d8f\u2026606a)\r\n2018-12-13 12:10:28 Starting consensus session on top of parent 0x9d8f83ec8c14a6c1513745c67515d69b4db517b8d6042b4cf674a82d5dee606a\r\n2018-12-13 12:10:31 Idle (0 peers), best: #4378 (0x9d8f\u2026606a)\r\n2018-12-13 12:10:32 Proposing block [number: 4379; hash: 0xca2d\u2026683a; parenthash: 0x9d8f\u2026606a; extrinsics: [0xdbef\u2026f3f4, 0x7b4e\u20262d59]]\r\n2018-12-13 12:10:36 Imported #4379 (0x8ce2\u2026b0b7)\r\n2018-12-13 12:10:36 Idle (0 peers), best: #4379 (0x8ce2\u2026b0b7)\r\n2018-12-13 12:10:37 Starting consensus session on top of parent 0x8ce22997f8bc0a4ac3524dae23ab0ab4c2b48fb641777ff3377cdf27c90eb0b7\r\n2018-12-13 12:10:41 Proposing block [number: 4380; hash: 0x2f84\u2026a06d; parenthash: 0x8ce2\u2026b0b7; extrinsics: [0xb107\u20266296, 0x7b4e\u20262d59]]\r\n2018-12-13 12:10:41 Idle (0 peers), best: #4379 (0x8ce2\u2026b0b7)\r\n2018-12-13 12:10:46 Imported #4380 (0x85d2\u2026b01f)\r\n2018-12-13 12:10:46 Idle (0 peers), best: #4380 (0x85d2\u2026b01f)\r\n2018-12-13 12:10:47 Starting consensus session on top of parent 0x85d2b8898b230dd7e0b0bd74ef2d7d3f06e66d306187ed725097d3300882b01f\r\n2018-12-13 12:10:47 Random Kademlia request has yielded empty results\r\n2018-12-13 12:10:51 Proposing block [number: 4381; hash: 0xb33f\u202680fd; parenthash: 0x85d2\u2026b01f; extrinsics: [0x856c\u20265260, 0x7b4e\u20262d59]]\r\n2018-12-13 12:10:51 Idle (0 peers), best: #4380 (0x85d2\u2026b01f)\r\n2018-12-13 12:10:55 Imported #4381 (0x8cb8\u20267be8)\r\n2018-12-13 12:10:56 Idle (0 peers), best: #4381 (0x8cb8\u20267be8)\r\n2018-12-13 12:10:56 Starting consensus session on top of parent 0x8cb8bb0379ec184e1cdb3e64cc2e20225560f4319db4b70725160cce9e5c7be8\r\n2018-12-13 12:11:00 Proposing block [number: 4382; hash: 0x66f0\u2026c6b8; parenthash: 0x8cb8\u20267be8; extrinsics: [0x12d2\u2026c431, 0x7b4e\u20262d59]]\r\n2018-12-13 12:11:01 Idle (0 peers), best: #4381 (0x8cb8\u20267be8)\r\n2018-12-13 12:11:05 Imported #4382 (0x4a1d\u20268bc2)\r\n2018-12-13 12:11:06 Starting consensus session on top of parent 0x4a1da9855119a288aaf16ae27039f6981c99606c98b35afcae3172e071578bc2\r\n2018-12-13 12:11:06 Idle (0 peers), best: #4382 (0x4a1d\u20268bc2)\r\n2018-12-13 12:11:10 Proposing block [number: 4383; hash: 0xbb25\u2026018b; parenthash: 0x4a1d\u20268bc2; extrinsics: [0x0ca5\u2026feda, 0x7b4e\u20262d59]]\r\n2018-12-13 12:11:11 Idle (0 peers), best: #4382 (0x4a1d\u20268bc2)\r\n2018-12-13 12:11:14 Imported #4383 (0xd890\u20264ffa)\r\n2018-12-13 12:11:15 Starting consensus session on top of parent 0xd8905527e88ff36bdc3de9d077d7df51d9f946066b9e7c7f1022ffd68e6c4ffa\r\n2018-12-13 12:11:16 Idle (0 peers), best: #4383 (0xd890\u20264ffa)\r\n2018-12-13 12:11:19 Proposing block [number: 4384; hash: 0x137d\u20260966; parenthash: 0xd890\u20264ffa; extrinsics: [0x9fa1\u20267889, 0x7b4e\u20262d59]]\r\n2018-12-13 12:11:21 Idle (0 peers), best: #4383 (0xd890\u20264ffa)\r\n2018-12-13 12:11:23 Imported #4384 (0x449d\u20260b20)\r\n2018-12-13 12:11:25 Starting consensus session on top of parent 0x449d661b3dd41078966a29e277de7d2ccdd7b81b54fdbf9e0b2e4d1dffbf0b20\r\n2018-12-13 12:11:26 Idle (0 peers), best: #4384 (0x449d\u20260b20)\r\n2018-12-13 12:11:28 Proposing block [number: 4385; hash: 0x61f6\u20268fd6; parenthash: 0x449d\u20260b20; extrinsics: [0x6e53\u2026855c, 0x7b4e\u20262d59]]\r\n2018-12-13 12:11:31 Idle (0 peers), best: #4384 (0x449d\u20260b20)\r\n2018-12-13 12:11:32 Random Kademlia request has yielded empty results\r\n2018-12-13 12:11:33 Imported #4385 (0x9962\u202671cc)\r\n2018-12-13 12:11:34 Starting consensus session on top of parent 0x9962d8493ead4209ec7637d60fe7c1c0635e69c97158ddc6fb7aa5f4544471cc\r\n2018-12-13 12:11:36 Idle (0 peers), best: #4385 (0x9962\u202671cc)\r\n2018-12-13 12:11:38 Proposing block [number: 4386; hash: 0x83a3\u2026c3f9; parenthash: 0x9962\u202671cc; extrinsics: [0xe03b\u2026fadd, 0x7b4e\u20262d59]]\r\n2018-12-13 12:11:41 Idle (0 peers), best: #4385 (0x9962\u202671cc)\r\n2018-12-13 12:11:44 Imported #4386 (0x5d86\u202666b3)\r\n2018-12-13 12:11:46 Starting consensus session on top of parent 0x5d863e6a26c2d1b9b1cf31f885908c07ed6afffdcd7150b740bcb72db14b66b3\r\n2018-12-13 12:11:46 Idle (0 peers), best: #4386 (0x5d86\u202666b3)\r\n2018-12-13 12:11:50 Proposing block [number: 4387; hash: 0x6d02\u20263489; parenthash: 0x5d86\u202666b3; extrinsics: [0x3e36\u202666cd, 0x7b4e\u20262d59, 0x7052\u2026e172]]\r\n2018-12-13 12:11:51 Idle (0 peers), best: #4386 (0x5d86\u202666b3)\r\n2018-12-13 12:11:56 Imported #4387 (0x6474\u20261edf)\r\n2018-12-13 12:11:56 Idle (0 peers), best: #4387 (0x6474\u20261edf)\r\n2018-12-13 12:11:58 Starting consensus session on top of parent 0x64749d8dd5ba7705807692da32cd7a46adc1d9e099934528554b9073d1ed1edf\r\n2018-12-13 12:12:01 Idle (0 peers), best: #4387 (0x6474\u20261edf)\r\n2018-12-13 12:12:02 Proposing block [number: 4388; hash: 0x5156\u20265dcd; parenthash: 0x6474\u20261edf; extrinsics: [0x8e24\u20263ec0, 0x7b4e\u20262d59]]\r\n2018-12-13 12:12:06 Imported #4388 (0x8bdb\u202627ca)\r\n2018-12-13 12:12:06 Idle (0 peers), best: #4388 (0x8bdb\u202627ca)\r\n2018-12-13 12:12:07 Starting consensus session on top of parent 0x8bdb90e6f8f8c54f345668bae134e8df434bf0e114af80ebcfb148d9496d27ca\r\n2018-12-13 12:12:11 Proposing block [number: 4389; hash: 0x703c\u202679a2; parenthash: 0x8bdb\u202627ca; extrinsics: [0xee2a\u2026767a, 0x7b4e\u20262d59]]\r\n2018-12-13 12:12:11 Idle (0 peers), best: #4388 (0x8bdb\u202627ca)\r\n2018-12-13 12:12:15 Imported #4389 (0x73ce\u20263d13)\r\n```\r\n\r\nThanks"},
{"text": "Process -\r\n\r\n- API subscribes to runtimeVersion\r\n- When the runtime version changes, retrieve metadata via `stategetMetadata`\r\n- Inject\r\n\r\nBasically we want the initialization that happens in https://github.com/polkadot-js/api/blob/master/packages/api/src/Base.ts#L456-L462 to happen on version updates\r\n\r\nThis is the one area where oo7 does it really well, i.e. `tie` to version, update on changes - https://github.com/paritytech/oo7/blob/master/packages/oo7-substrate/src/bonds.js#L207-L211"},
{"text": "Basically, have an api endpoint, which takes multiple storage values and runs it through a derivation function, returning a result. And example may be of votingBalance, we could do (pseudo-ish code) -\r\n\r\n```\r\n{\r\n  section: 'balance',\r\n  method: 'votingBalance',\r\n  inputs: ['balances.freeBalanceOf', 'balances.reservedBalanceOf`],\r\n  derive: (free, reserved) => free.add(reserved)\r\n}\r\n```\r\n\r\nand then\r\n\r\n```\r\napi.derive.balances.votingBalance(ALICE).toString();\r\n```\r\n\r\nBasically the API will add these and attach them to the derive endpoints. We def. need something to this effect, either we write code or have it more templated. (And needs to support both API types)\r\n\r\nEDIT: The above example is already hairy, how to we cater for params passed in?"},
{"text": "If we create a new instance of the `Method` class, it is understood based on discussion with @amaurymartiny that the current functionality of the `args` getter is ok, and the FIXME as shown [here](https://github.com/polkadot-js/api/blob/master/packages/types/src/Method.ts#L170) is no longer required.\r\n\r\nFor example, when you go to http://localhost:3000/#/extrinsics and click Submit Transaction, and you want to obtain the recipientId (dest) and amount (value) from the prop `this.props.value.extrinsic` that passed down to polkadot-js/apps/packages/ui-signer/src/Extrinsic.tsx, then \r\n\r\n```\r\nconst methodInstance = new Method(extrinsic, extrinsic.meta);\r\n\r\n// WRONG - do not use `.raw`. \r\n// See https://github.com/polkadot-js/apps/pull/389#discussionr230735365\r\n// const recipientId = methodInstance.args[0].raw.toString();\r\n// const amount = methodInstance.args[1].raw.toString();\r\n\r\n// WRONG - suggested in the FIXME, but not preferred approach\r\n// const recipientId = methodInstance.args.get('dest').toString();\r\n// const amount = methodInstance.args.get('value').toString();\r\n\r\n// RIGHT\r\nconst recipientId = methodInstance.get('args').get('dest').toString();\r\nconst amount = methodInstance.get('args').get('value').toString();  // or .toBn().toString()\r\n```\r\n\r\nProposed action is to remove the following [FIXME](https://github.com/polkadot-js/api/blob/master/packages/types/src/Method.ts#L170)\r\n```\r\nget args (): Array<Base> {\r\n    // FIXME This should return a Struct instead of an Array\r\n    return [...(this.get('args') as Struct).values()];\r\n  }\r\n```\r\n\r\n"},
{"text": "Right now they are in `.spec.js`, for historical reasons."},
{"text": "Some of the examples listed in the below \"Usage\" section:\r\n\r\n<img width=\"737\" alt=\"screen shot 2018-10-15 at 18 03 25\" src=\"https://user-images.githubusercontent.com/6226175/46962960-c568e500-d0a4-11e8-844f-f5457c16ad4d.png\">\r\n\r\nAre duplicated to an extent in the examples in the \"Examples\" section at links shown below. Note however that often the version in the \"Usage\" section (such as \"Submitting a transaction\") is often more concise and makes more use of chaining:\r\n\r\n<img width=\"227\" alt=\"screen shot 2018-10-15 at 18 03 37\" src=\"https://user-images.githubusercontent.com/6226175/46963018-e8939480-d0a4-11e8-9cc1-aa4739e2fbdd.png\">\r\n "},
{"text": "This should be `statusCb` for extrinsic submission to work, right?\r\n\r\nhttps://github.com/polkadot-js/api/blob/67f625b096e8cc3f0a091105061a5f52e01bedef/packages/api/src/promise/SubmittableExtrinsic.ts#L21"},
{"text": "- Updates automatically with rpc loads (trigerred on connect)\r\n- Export api-observable whenReady (promise)\r\n- Rename extrinsics/storage `testing` to `static` (expose upon API load)"},
{"text": "I cannot put it more succinctly :)\r\n\r\n- Remote extrinsics & storage (the latter will still contain some, e.g. `:code`, basically all these https://github.com/paritytech/substrate/pull/764)\r\n- Pull storage, extrinsics and events (this is new) from stategetMeta\r\n- Fixup encoders and do it properly - currently they are all-over, some in primitives, some in params\r\n- Make everything work....\r\n- ... I missed some stuff\r\n\r\ncc @amaurymartiny :)\r\n"},
{"text": "\"@polkadot/api\": \"^0.28.24\",\r\n\r\nI did not see this issue yesterday at all but this is showing up today."},
{"text": "when i use it in my vueJs project ,it occurs this error once i  compile code.\r\n\r\n```\r\nCannot destructure property `strings` of 'undefined' or 'null'.\r\n    at new MetadataRegistryLookup (MetaRegistry.js?1408:44)\r\n    at new MetaRegistry (MetaRegistry.js?1408:117)\r\n    at new ContractRegistry (ContractRegistry.js?25d1:56)\r\n    at new ContractAbi (Abi.js?14ba:22)\r\n```\r\n\r\npackage.json:\r\n\r\n```\r\n  \"dependencies\": {\r\n    \"@polkadot/api\": \"0.96.1\",\r\n    \"@polkadot/keyring\": \"^1.6.1\",\r\n    \"@polkadot/util\": \"^1.6.1\",\r\n    \"@polkadot/util-crypto\": \"^1.6.1\",\r\n    \"@polkadot/api-contract\": \"0.96.1\",\r\n    \"@polkadot/types\": \"0.96.1\",\r\n    \"@polkadot/app-contracts\": \"^0.36.1\",\r\n    \"core-js\": \"^2.6.9\",\r\n    \"vue\": \"^2.6.10\",\r\n    \"vue-class-component\": \"^7.1.0\",\r\n    \"vue-i18n\": \"^8.14.0\",\r\n    \"vue-property-decorator\": \"^8.2.2\",\r\n    \"vue-router\": \"^3.1.3\",\r\n    \"vuex\": \"^3.1.1\"\r\n  },\r\n  \"devDependencies\": {\r\n    \"@types/pdfjs-dist\": \"^2.1.0\",\r\n    \"@types/qrcode\": \"^1.3.4\",\r\n    \"@vue/cli-plugin-babel\": \"^3.11.0\",\r\n    \"@vue/cli-plugin-typescript\": \"^3.11.0\",\r\n    \"@vue/cli-service\": \"^3.11.0\",\r\n    \"ts-import-plugin\": \"^1.6.1\",\r\n    \"typescript\": \"^3.6.2\",\r\n    \"vue-template-compiler\": \"^2.6.10\",\r\n    \"vuetable-2\": \"^1.7.5\",\r\n    \"webpack\": \"^4.39.3\"\r\n  }\r\n```\r\n\r\ntsconfig.json:\r\n\r\n```\r\n{\r\n  \"compilerOptions\": {\r\n    \"target\": \"esnext\",\r\n    \"module\": \"esnext\",\r\n    \"strict\": true,\r\n    \"jsx\": \"preserve\",\r\n    \"importHelpers\": true,\r\n    \"moduleResolution\": \"node\",\r\n    \"experimentalDecorators\": true,\r\n    \"esModuleInterop\": true,\r\n    \"allowSyntheticDefaultImports\": true,\r\n    \"sourceMap\": true,\r\n    \"baseUrl\": \".\",\r\n    \"allowJs\": true,\r\n    \"resolveJsonModule\": true,\r\n    \"types\": [\r\n      \"webpack-env\"\r\n    ],\r\n    \"paths\": {\r\n      \"@/*\": [\r\n        \"src/*\"\r\n      ]\r\n    },\r\n    \"lib\": [\r\n      \"esnext\",\r\n      \"dom\",\r\n      \"dom.iterable\",\r\n      \"scripthost\"\r\n    ]\r\n  },\r\n  \"include\": [\r\n    \"src/**/*.ts\",\r\n    \"src/**/*.tsx\",\r\n    \"src/**/*.vue\",\r\n    \"tests/**/*.ts\",\r\n    \"tests/**/*.tsx\"\r\n  ],\r\n  \"exclude\": [\r\n    \"nodemodules\"\r\n  ]\r\n}\r\n```"},
{"text": " I used the latest available [apps](https://github.com/polkadot-js/apps) `7048a65c3dc0bea2061a653a7f63baf8b192ddb4` and [substate node](https://github.com/paritytech/substrate) `7874be8668ba6ff43c107c5da26105f934654cc2` to `deploy` an [erc20 contract]()  and found that the value set in `ondeploy` is not the same as the value returned by the `totalsupply` method. I recently found this bug with the new ABI, but I am not sure if it is caused by [api](https://github.com/polkadot-js/api) or `substrate node`.This is the [abi file ](https://github.com/polkadot-js/api/files/3823230/abi.txt) I am using.This problem exists with all method calls in the contract instance.\r\n"},
{"text": "When I tested the contract rpc call method, the main code is as follows:\r\n```\r\nimport { Abi, PromiseContract as ApiContract } from '@polkadot/api-contract';\r\nimport { ContractCallOutcome } from '@polkadot/api-contract/types';\r\nimport { ApiPromise } from '@polkadot/api';\r\nimport { stringToU8a,hexToU8a,hexToString,u8aToHex } from'@polkadot/util';\r\nimport * as getmethodtest from \"../contracttest.json\";\r\n\r\nconst abistr = (<any>getmethodtest);\r\nconst abi = getAbiObj(abistr);\r\n\r\nnew ApiPromise().isReady.then((api) => {\r\n \r\n    const contractApi = new ApiContract(api, abi, \"5EUE4FAE9wGyxhKdFkhNsm9T8x55VRACzzpPpMDyWEE6h1is\");\r\n    const {fn,def} = contractApi.getMessage(\"getoriginalnonce\");\r\n    let data = fn();\r\n    console.log(\"message data:\"+u8aToHex(data)); \r\n    const contractmethod = contractApi.call('rpc',def.name,0,500000);\r\n     contractmethod.send(\"5GrwvaEF5zXb26Fz9rcQpDWS57CtERHpNehXCPcNoHGKutQY\").then(\r\n        (outcome:ContractCallOutcome):void =>{\r\n            console.log(\"isSuccess:\"+outcome.isSuccess+\",value:\"+outcome.output.toString());\r\n        }\r\n    );\r\n});\r\n```\r\nAn error message appears when I run:\r\n```\r\n(node:26072) UnhandledPromiseRejectionWarning: ReferenceError: name is not defined\r\n    at PromiseContract.getMessage (/home/jeremy/work/demo/typescript/substrate-ts-api-test/nodemodules/@polkadot/api-contract/base/util.js:38:100)\r\n    at /home/jeremy/work/demo/typescript/substrate-ts-api-test/src/index.ts:13:11\r\n```\r\nAccording to the prompt, I find the corresponding file and modify the field corresponding to the line `31,38`: After the `name` is changed to `def.name`, the program can run normally.But seeing that your [apps](https://polkadot.js.org/apps/#/explorer) is working fine, I don't know if I am calling the wrong way.\r\nI use `@polkadot/api-contract,@polkadot/api` version is `0.96.0-beta.34`,test using [ABI](https://github.com/polkadot-js/api/files/3818526/contracttest.txt)\r\n"},
{"text": " I get an error `main.749f3709.js:21450 Uncaught Error: createType({ \"elems\": \"Vec\" }):: Unable to find plain type for {\"info\":6,\"type\":\"Vec\"}`, when I call deploy at https://polkadot.js.org/apps/#/contracts/code.\r\n![sALNPfuHKHgwCxEqXIRgdfDM](https://user-images.githubusercontent.com/13585788/68310368-d985e700-00ea-11ea-8d9e-c8783e277fb4.png)\r\n When I remove Vec<u8> in deploy, the contract can be instantiated normally."},
{"text": "Looks like the UI is not showing the accurate reward amount for validators with a commission greater than 0.\r\n\r\nFor instance, the message for this tx https://polkascan.io/pre/kusama/transaction/0x342d516e1f99a7ce92bc5f98aa95ef4566b4f40b70d11367deb75cc9d5d2d8de was `Payout rewards (0.000 KSM)`, the validator has set a 100% commission."},
{"text": "Using api beta30 - getting derived session info returns wrong value on current kusama node.\r\nChain height currently at BN:826889 while value for last session(epoch?) change is showing value of 262453039\r\n\r\nIt looks like other data is also wrong - if we look at polkascan and look into events on kusamacc2 - session and era starts do not correspond to data shown in session info.\r\n\r\nAccording to session info, there should have been session starts at blocks  824870, 822470, 820070 which is calculated from \r\n`await api.rpc.chain.getHeader()).number.toNumber() - sessionProgress`\r\n which doesn't look like it's right because \r\n`await api.query.system.events.at(await api.rpc.chain.getBlockHash(824870))` \r\ndoesn't return events that should be emitted on new nession start. Whereas\r\n`await api.query.system.events.at(await api.rpc.chain.getBlockHash(824956))` \r\ndoes return these events\r\n\r\nit looks like eraProgress returns same value as sessionProgress which is also wrong.\r\n\r\nhttps://polkascan.io/pre/kusama-cc2/event \r\n![Screen Shot 2019-11-26 at 01 57 40](https://user-images.githubusercontent.com/3409250/69590640-663c0a80-0ff0-11ea-940c-966209cb5aa7.png)\r\n\r\nhttps://github.com/polkadot-js/api/blob/4cea617b13efa9db9addb17f6c4e31e1df025246/packages/api-derive/src/session/info.ts#L63\r\n"},
{"text": "Currently we ignore these, however some locks can still be used to pay for transfer fees"},
{"text": "`subscribeNewHeads` only works when the node runtime provides the session module. If this is not the case (when using Aura consensus for example) the method throws an error that `api.query.session` is undefined. "},
{"text": "https://github.com/paritytech/substrate/pull/3816\r\n\r\nSpecifically these moved from the balances module -\r\n\r\nhttps://github.com/paritytech/substrate/pull/3816/files#diff-32c053d1675d55642287f44823979cb4R243-R254"},
{"text": "https://github.com/polkadot-js/api/blob/master/packages/api-derive/src/imOnline/receivedHeartbeats.ts#L24\r\n\r\nHowever the `imOnline` query takes the . index, not the addres \r\n\r\n![image](https://user-images.githubusercontent.com/1424473/66158720-bddc7c00-e626-11e9-9277-9a1e6d41245b.png)\r\n\r\n- retrieve session index & keys\r\n- lookup keys in the array\r\n- then do the query based on index (not address)"},
{"text": "Current master, effectively block don't show up in the apps UI atm"},
{"text": "E.g. here: https://github.com/polkadot-js/api/blob/master/packages/api-derive/src/contracts/fees.ts#L47\r\n\r\nIt should not be BN, but the actual Codec type. derive is one of the rare places where we have typings, so let's make them correct.\r\n\r\ntests should also be updated (e.g expect.any(BN) -> expect.any(BalanceOf))"},
{"text": "An issue appeared in `apps` and is related to `derive.staking.info`. Updates are not pushed through the props, so that the info don't update unless the page is reloaded.\r\n\r\nI've tracked down the issue and it happens since v0.82 https://github.com/polkadot-js/api/pull/987\r\n\r\nHow to reproduce:\r\n- navigate to staking>actions\r\n- change the reward destination\r\n- once the tx succeeds, the reward destination isn't updated\r\n- refresh the page or change tab and get back -> the destination is updated."},
{"text": "As part of HeaderExtended in derive - atm we only look at Seal, and since these are not being produced anymore, we are missing the block author indicator."},
{"text": "Issue as title, \r\nTried to call `api.derive.staking.intentionsBalances()`, and got rejected.\r\nThe func works with `Alexander (Polkadot, hosted by Parity) Node`, \r\nAnd doesnt get the balance when with `Dried Danta (Substrate, hosted by Parity)`.\r\n\r\nGot the err as below when tried to call the api:\r\n\r\n```\r\nPromise\u00a0{<pending>}proto: Promisecatch: \u0192 catch()constructor: \u0192 Promise()finally: \u0192 finally()then: \u0192 then()Symbol(Symbol.toStringTag): \"Promise\"proto: Object[[PromiseStatus]]: \"rejected\"[[PromiseValue]]: TypeError: api.query.balances.freeBalance is not a function\r\n    at SwitchMapSubscriber.pipe [as project]\r\n\r\n@polkadot/api-derive/balances/votingBalance.js:33 Uncaught (in promise) TypeError: api.query.balances.freeBalance is not a function\r\n    at SwitchMapSubscriber.pipe [as project] (.../nodemodules/@polkadot/api-derive/balances/votingBalance.js:33)\r\n    at SwitchMapSubscriber.next (switchMap.ts:106)\r\n    at SwitchMapSubscriber.Subscriber.next (Subscriber.ts:99)\r\n    at RefCountSubscriber.Subscriber.next (Subscriber.ts:139)\r\n    at RefCountSubscriber.Subscriber.next (Subscriber.ts:99)\r\n    at ReplaySubject.Subject.next (Subject.ts:70)\r\n    at ReplaySubject.nextInfiniteTimeWindow (ReplaySubject.ts:46)\r\n    at ConnectableSubscriber.Subscriber.next (Subscriber.ts:139)\r\n    at ConnectableSubscriber.Subscriber.next (Subscriber.ts:99)\r\n    at DistinctUntilChangedSubscriber.next (distinctUntilChanged.ts:121)\r\n```\r\n"},
{"text": "Currently the query interfaces allows for a `null` return, i.e. https://github.com/polkadot-js/api/blob/master/packages/api/src/promise/types.ts#L33 & https://github.com/polkadot-js/api/blob/master/packages/api/src/rx/types.ts#L16 - where the return is `Codec | null | undefined`\r\n\r\nHowever, since the introduction of defaults, `null` and `undefined` are never returned anymore, see https://github.com/polkadot-js/api/blob/master/packages/rpc-core/src/index.ts#L213\r\n\r\nCleanups required -\r\n\r\n- interfaces as detailed above\r\n- api-derive has all the `value || new Something(...)` overrides"},
{"text": "Needs https://github.com/polkadot-js/api/issues/559 (to allow derive on api/promise)"},
{"text": "- [x] I have checked that this issue has not already been reported.\r\n\r\n- [x] I have confirmed this bug exists on the latest version of pandas.\r\n\r\n- [ ] (optional) I have confirmed this bug exists on the master branch of pandas.\r\n\r\n---\r\n\r\n#### Code Sample:\r\n\r\n```python\r\nimport pandas as pd\r\n\r\n\r\ndf = pd.DataFrame({\"date\": [\"2019-02-10\", \"2019-02-10\", \"2019-02-11\"]})\r\ndf[\"date\"] = pd.todatetime(df[\"date\"])\r\n\r\nprint(\"Type before the for cycle:\")\r\nprint(type(df[\"date\"][0]))  # pandas.libs.tslibs.timestamps.Timestamp\r\n\r\nfor day in df[\"date\"].unique(): \r\n    print(\"Type in the loop:\")\r\n    print(type(day))  # here is a numpy.datetime64\r\n```\r\n\r\nwhich returns:\r\n\r\n```\r\nType before the for cycle:\r\n<class 'pandas.libs.tslibs.timestamps.Timestamp'>\r\nType in the loop:\r\n<class 'numpy.datetime64'>\r\nType in the loop:\r\n<class 'numpy.datetime64'>\r\n```\r\n\r\n#### Problem description\r\n\r\nThe function `unique()` should not cast the data type.\r\n\r\n#### Expected Output\r\n\r\ntypes of `dftarget[\"date\"].unique()` should be the same as in ` set(dftarget[\"date\"].tolist())`. E.g.\r\n\r\n\r\n```python\r\nimport pandas as pd\r\n\r\n\r\ndf = pd.DataFrame({\"date\": [\"2019-02-10\", \"2019-02-10\", \"2019-02-11\"]})\r\ndf[\"date\"] = pd.todatetime(df[\"date\"])\r\n\r\nprint(\"Type before the for cycle:\")\r\nprint(type(df[\"date\"][0])) \r\n\r\nfor day in set(df[\"date\"].tolist()): \r\n    print(\"Type in the loop:\")\r\n    print(type(day))\r\n```\r\n\r\nReturning:\r\n```\r\nType before the for cycle:\r\n<class 'pandas.libs.tslibs.timestamps.Timestamp'>\r\nType in the loop:\r\n<class 'pandas.libs.tslibs.timestamps.Timestamp'>\r\nType in the loop:\r\n<class 'pandas.libs.tslibs.timestamps.Timestamp'>\r\n```\r\n\r\n#### Output of ``pd.showversions()``\r\n\r\n```\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit           : None\r\npython           : 3.7.7.final.0\r\npython-bits      : 64\r\nOS               : Darwin\r\nOS-release       : 19.5.0\r\nmachine          : x8664\r\nprocessor        : i386\r\nbyteorder        : little\r\nLCALL           : None\r\nLANG             : enGB.UTF-8\r\nLOCALE           : enGB.UTF-8\r\n\r\npandas           : 1.0.5\r\nnumpy            : 1.19.0\r\npytz             : 2020.1\r\ndateutil         : 2.8.1\r\npip              : 20.1.1\r\nsetuptools       : 47.3.1\r\nCython           : None\r\npytest           : 5.4.1\r\nhypothesis       : None\r\nsphinx           : None\r\nblosc            : None\r\nfeather          : None\r\nxlsxwriter       : None\r\nlxml.etree       : None\r\nhtml5lib         : None\r\npymysql          : None\r\npsycopg2         : None\r\njinja2           : 2.11.2\r\nIPython          : 7.16.1\r\npandasdatareader: None\r\nbs4              : None\r\nbottleneck       : None\r\nfastparquet      : None\r\ngcsfs            : None\r\nlxml.etree       : None\r\nmatplotlib       : 3.2.2\r\nnumexpr          : None\r\nodfpy            : None\r\nopenpyxl         : None\r\npandasgbq       : None\r\npyarrow          : None\r\npytables         : None\r\npytest           : 5.4.1\r\npyxlsb           : None\r\ns3fs             : None\r\nscipy            : 1.5.2\r\nsqlalchemy       : None\r\ntables           : None\r\ntabulate         : None\r\nxarray           : None\r\nxlrd             : None\r\nxlwt             : None\r\nxlsxwriter       : None\r\nnumba            : None\r\n```\r\n\r\n</details>\r\n"},
{"text": "- [x] I have checked that this issue has not already been reported.\r\n\r\n- [x] I have confirmed this bug exists on the latest version of pandas.\r\n\r\n---\r\n#### Code snippet\r\n```\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\ndf = pd.DataFrame(data={'a': np.arange(100), 'b': np.arange(100),})\r\n\r\ndf = df.quantile([0.2, 0.5, 0.8], axis=1)\r\n\r\n```\r\n#### Problem description\r\n\r\nUsing  `DataFrame.quantile` over axis=1 with multiple values for q transposes the dataframe. I would expect the quantiles to appear over the specified axis, so along the columns axis when axis = 1, and along rows when axis = 0. Ofcourse, an easy fix is a call to `DataFrame.transpose`. Ideally this should not be necessary in my opinion.\r\n\r\n#### Expected Output\r\nQuantile values over the specified axis without transposing the dataframe.\r\n\r\n#### Output of ``pd.showversions()``\r\n\r\n<details>\r\n\r\nC:\\Anaconda64\\lib\\site-packages\\setuptools\\distutilspatch.py:26: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\r\n  \"Distutils was imported before Setuptools. This usage is discouraged \"\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit           : None\r\npython           : 3.7.6.final.0\r\npython-bits      : 64\r\nOS               : Windows\r\nOS-release       : 10\r\nmachine          : AMD64\r\nprocessor        : Intel64 Family 6 Model 158 Stepping 10, GenuineIntel\r\nbyteorder        : little\r\nLCALL           : None\r\nLANG             : nlNL.UTF-8\r\nLOCALE           : None.None\r\n\r\npandas           : 1.0.5\r\nnumpy            : 1.18.5\r\npytz             : 2020.1\r\ndateutil         : 2.8.1\r\npip              : 20.1.1\r\nsetuptools       : 49.2.0.post20200712\r\nCython           : 0.29.21\r\npytest           : 5.4.3\r\nhypothesis       : 5.19.3\r\nsphinx           : 3.1.2\r\nblosc            : None\r\nfeather          : None\r\nxlsxwriter       : 1.2.9\r\nlxml.etree       : 4.5.2\r\nhtml5lib         : 1.1\r\npymysql          : None\r\npsycopg2         : None\r\njinja2           : 2.11.2\r\nIPython          : 7.16.1\r\npandasdatareader: None\r\nbs4              : 4.9.1\r\nbottleneck       : 1.3.2\r\nfastparquet      : None\r\ngcsfs            : None\r\nlxml.etree       : 4.5.2\r\nmatplotlib       : 3.2.2\r\nnumexpr          : 2.7.1\r\nodfpy            : None\r\nopenpyxl         : 3.0.4\r\npyarrow          : None\r\npytables         : None\r\npytest           : 5.4.3\r\npyxlsb           : None\r\ns3fs             : None\r\nscipy            : 1.3.1\r\nsqlalchemy       : 1.3.18\r\ntables           : 3.6.1\r\ntabulate         : None\r\nxarray           : None\r\nxlrd             : 1.2.0\r\nxlwt             : 1.3.0\r\nxlsxwriter       : 1.2.9\r\nnumba            : 0.50.1\r\n\r\n</details>\r\n"},
{"text": "On master PeriodDtype has a `.dtypecode` attribute.\r\n\r\n```python\r\nIn [5]: pd.PeriodDtype('D').dtypecode\r\nOut[5]: 6000\r\n```\r\n\r\nThat wasn't there in 1.0.x. I think we want it to be private."},
{"text": "This was inspired by #33888 and #34584\r\n\r\n#### Problem description\r\nThe behavior of `copy` argument in `df.reindex` is confusing. Current docstring does it explain it sufficiently clear. It also seems to me `copy` is unnecessary.\r\n\r\nCurrently the docstring says\r\n```\r\n...\r\n\r\nA new object is produced unless the new index is equivalent to the current one and ``copy=False``.\r\n\r\n...\r\n\r\ncopy : bool, default True\r\n       Return a new object, even if the passed indexes are the same.\r\n```\r\n\r\nIt is hard to clarify what is considered an \"equivalent\" index. See below for more details.\r\n\r\nFurther, I believe users rarely purposefully tries to `reindex` with an \"equivalent\" index. It happens only if the user does not yet know the current index or the index to conform to, in which case a consistent behavior (e.g. always return new object) is probably preferred.\r\n\r\n```python\r\n# On current master\r\n>>> pd.version\r\n'1.1.0.dev0+1802.g942beba1e'\r\n\r\n>>> df = pd.DataFrame(range(3))\r\n>>> df\r\n   0\r\n0  0\r\n1  1\r\n2  2\r\n>>> df.index\r\nRangeIndex(start=0, stop=3, step=1)\r\n\r\n# not equivalent\r\n>>> df is df.reindex(range(3), copy=False)\r\nFalse\r\n\r\n# not equivalent\r\n>>> df is df.reindex(list(range(3)), copy=False)\r\nFalse\r\n\r\n# equivalent\r\n>>> df is df.reindex(pd.RangeIndex(start=0, stop=3, step=1), copy=False)\r\nTrue\r\n\r\n>>> df = pd.DataFrame(range(3), index=list(range(3)))\r\n>>> df\r\n   0\r\n0  0\r\n1  1\r\n2  2\r\n>>> df.index\r\nInt64Index([0, 1, 2], dtype='int64')\r\n\r\n# not equivalent\r\n>>> df is df.reindex(range(3), copy=False)\r\nFalse\r\n\r\n# even this is considered not equivalent\r\n>>> df is df.reindex(list(range(3)), copy=False)\r\nFalse\r\n\r\n>>> df is df.reindex(pd.Int64Index([0, 1, 2]), copy=False)\r\nTrue\r\n\r\n```\r\n\r\nYou can see it is actually pretty strict to be \"equivalent\".  I feel it does really make sense to have this `copy` parameter because `reindex` will return a new object in most cases anyway even when `copy=False`.\r\n\r\nSo the question is, can we deprecate `copy`? "},
{"text": "I discovered this while trying to tackle issue #32344, where @ryankarlos mentioned `groupby.transform('tshift', ...)` seems to behave incorrectly.\r\n\r\nHowever, before we can address #32344, we probably need to address this.\r\n```python\r\n# on current master\r\n>>> import pandas as pd\r\n>>> import numpy as np\r\n\r\n>>> pd.version\r\n'1.1.0.dev0+1708.g043b60920'\r\n\r\n>>> df = pd.DataFrame(\r\n...     {\r\n...     \"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"bar\", \"bar\", \"baz\"],\r\n...     \"B\": [1, 2, np.nan, 3, 3, np.nan, 4],\r\n...     },\r\n...     index=pd.daterange('2020-01-01', '2020-01-07')\r\n... )\r\n>>> df\r\n              A    B\r\n2020-01-01  foo  1.0\r\n2020-01-02  foo  2.0\r\n2020-01-03  foo  NaN\r\n2020-01-04  foo  3.0\r\n2020-01-05  bar  3.0\r\n2020-01-06  bar  NaN\r\n2020-01-07  baz  4.0\r\n\r\n>>> df.groupby(\"A\").tshift(1, \"D\")\r\n                  B\r\nA\r\nbar 2020-01-06  3.0\r\n    2020-01-07  NaN\r\nbaz 2020-01-08  4.0\r\nfoo 2020-01-02  1.0\r\n    2020-01-03  2.0\r\n    2020-01-04  NaN\r\n    2020-01-05  3.0\r\n\r\n>>> df.groupby(\"A\").ffill()\r\n              B\r\n2020-01-01  1.0\r\n2020-01-02  2.0\r\n2020-01-03  2.0\r\n2020-01-04  3.0\r\n2020-01-05  3.0\r\n2020-01-06  3.0\r\n2020-01-07  4.0\r\n\r\n>>> df.groupby(\"A\").cumsum()\r\n              B\r\n2020-01-01  1.0\r\n2020-01-02  3.0\r\n2020-01-03  NaN\r\n2020-01-04  6.0\r\n2020-01-05  3.0\r\n2020-01-06  NaN\r\n2020-01-07  4.0\r\n```\r\n\r\nWe can see that `groupby.tshift` is inconsistent with other groupby transformations. It retains the groupby column, and more importantly reordered the data.\r\n\r\nSince 0.25 we have had deliberate effort to make all groupby transformations consistent, see https://pandas.pydata.org/pandas-docs/stable/whatsnew/v0.25.0.html#dataframe-groupby-ffill-bfill-no-longer-return-group-labels\r\n\r\nFollowing this thinking I would expect the returned data to behave more like \r\n```python\r\n>>> df.groupby(\"A\").tshift(1, \"D\")  # this is actually the result of df.tshift(1, \"D\").drop(columns='A')\r\n              B\r\n2020-01-02  1.0\r\n2020-01-03  2.0\r\n2020-01-04  NaN\r\n2020-01-05  3.0\r\n2020-01-06  3.0\r\n2020-01-07  NaN\r\n2020-01-08  4.0\r\n```\r\n\r\nHowever, if we are to make `groupby.tshift` consistent with other groupby transformation like the above, this makes it no different from `df.tshift(1, \"D\").drop(columns='A')', and `groupby` has lost its meaning here.\r\n\r\nPerhaps we should just deprecate `groupby.tshift` entirely? I know #11631 discussed about deprecating `tshift`, but that has been stalled for a long time."},
{"text": "- [X] I have checked that this issue has not already been reported.\r\n\r\n- [X] I have confirmed this bug exists on the latest version of pandas.\r\n\r\n- [ ] (optional) I have confirmed this bug exists on the master branch of pandas.\r\n\r\n---\r\n**Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug.\r\n\r\n#### Code Sample, a copy-pastable example\r\n\r\n```python\r\nimport pandas as pd\r\nfrom datetime import datetime\r\ndata=pd.DataFrame([[430., 630.],\r\n                         [540., 660.],\r\n                         [610., 720.]],\r\n                        columns=[1, 2],\r\n                        index=pd.daterange(datetime(2019, 1, 1, 12),\r\n                                            datetime(2019, 1, 1, 12, 30),\r\n                                            freq='15min'))\r\npd.tseries.frequencies.tooffset(pd.inferfreq(data.index))\r\n>> <15 * Minutes>\r\npd.tseries.frequencies.tooffset(pd.inferfreq(data.index)) / 2\r\n>> <450 * Secondes>\r\npd.tseries.offsets.DateOffset(minutes=15)\r\n>> <DateOffset: minutes=15>\r\npd.tseries.offsets.DateOffset(minutes=15) / 2\r\n>> TypeError: unsupported operand type(s) for /: 'DateOffset' and 'int'\r\n\r\n```\r\n#### Problem description\r\nThe function `pd.tseries.frequencies.tooffset` does not really provide a `DateOffset`object. As I understand the code right there are several types of DateOffsets e.g. Minutes, Seconds that are not compareable with the DateOffset object because they are having different properties.\r\n\r\n\r\n\r\n#### Expected Output\r\nOne Unified pd.DateOffset Object with same properties for all inherit Objects like Minutes and Seconds\r\n#### Output of ``pd.showversions()``\r\n\r\n<details>\r\n\r\n[INSTALLED VERSIONS\r\n------------------\r\ncommit           : None\r\npython           : 3.6.9.final.0\r\npython-bits      : 64\r\nOS               : Linux\r\nOS-release       : 4.15.0-99-generic\r\nmachine          : x8664\r\nprocessor        : x8664\r\nbyteorder        : little\r\nLCALL           : None\r\nLANG             : deDE.UTF-8\r\nLOCALE           : deDE.UTF-8\r\n\r\npandas           : 1.0.3\r\nnumpy            : 1.16.0\r\npytz             : 2018.9\r\ndateutil         : 2.8.1\r\npip              : 20.0.2\r\nsetuptools       : 44.0.0\r\nCython           : 0.28.3\r\npytest           : 4.3.0\r\nhypothesis       : None\r\nsphinx           : None\r\nblosc            : None\r\nfeather          : None\r\nxlsxwriter       : None\r\nlxml.etree       : 4.2.1\r\nhtml5lib         : 0.999999999\r\npymysql          : 0.9.3\r\npsycopg2         : 2.8.4 (dt dec pq3 ext lo64)\r\njinja2           : 2.10\r\nIPython          : 7.11.1\r\npandasdatareader: None\r\nbs4              : 4.6.0\r\nbottleneck       : 1.3.0\r\nfastparquet      : None\r\ngcsfs            : None\r\nlxml.etree       : 4.2.1\r\nmatplotlib       : 2.2.2\r\nnumexpr          : 2.6.4\r\nodfpy            : None\r\nopenpyxl         : None\r\npandasgbq       : None\r\npyarrow          : 0.13.0\r\npytables         : None\r\npytest           : 4.3.0\r\npyxlsb           : None\r\ns3fs             : None\r\nscipy            : 1.4.1\r\nsqlalchemy       : 1.3.16\r\ntables           : 3.4.2\r\ntabulate         : 0.8.5\r\nxarray           : 0.10.9\r\nxlrd             : 1.1.0\r\nxlwt             : None\r\nxlsxwriter       : None\r\nnumba            : 0.42.0\r\n]\r\n\r\n</details>\r\n"},
{"text": "From [SO](https://stackoverflow.com/a/61891863/2901002):\r\n\r\n    df1 = (df.setindex(['Animal', df.groupby('Animal').cumcount().add(1)])\r\n             .unstack()\r\n             .sortindex(axis=1, level=1))\r\n    df1.columns = [f'{a}{b}' for a, b in df1.columns]\r\n    df1 = df1.resetindex()\r\n    print (df1)\r\n      Animal  Age1 Color1 Length1  Age2 Color2 Length2  Age3 Color3  \\\r\n    0    Cat      1   Brown     50cm      2   White     60cm      3   Brown   \r\n    1    Dog      1   White     99cm      2   White    129cm      3   White   \r\n    \r\n      Length3  \r\n    0     55cm  \r\n    1    105cm  \r\n\r\nIf I want chain flatten `MultIindex` for one line solution, is it possible? Now `f-string`s cannot chain with `sortindex` and `resetindex` (or not idea how).\r\n\r\nIs possible implemented [`MultiIndex.toflatindex`](http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.MultiIndex.toflatindex.html) for `DataFrame` ?\r\n\r\n\r\n    df1 = (df.setindex(['Animal', df.groupby('Animal').cumcount().add(1)])\r\n             .unstack()\r\n             .sortindex(axis=1, level=1)\r\n             .toflatindex(axis=1)\r\n             .resetindex())\r\n"},
{"text": "- [x] I have checked that this issue has not already been reported.\r\n\r\n- [x] I have confirmed this bug exists on the latest version of pandas.\r\n\r\n- [ ] (optional) I have confirmed this bug exists on the master branch of pandas.\r\n\r\n---\r\n\r\n**Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug.\r\n\r\n#### Code Sample, a copy-pastable example\r\n\r\n<img width=\"1143\" alt=\"image\" src=\"https://user-images.githubusercontent.com/33289453/81488715-0c2db980-929f-11ea-9960-61d24d1ab44f.png\">\r\n\r\n```python\r\n\r\n#%%\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\n#%%\r\ndf = pd.DataFrame(np.arange(16).reshape(4,4), index=pd.MultiIndex.fromarrays([list(\"AABB\"), list(\"XYXY\")]), columns=list(\"abcd\"))\r\ndf\r\n\r\n#%%\r\ndf.index, df.index.levels\r\n\r\n#%%\r\ndfnew = df.drop(index=\"A\")\r\ndfnew\r\n\r\n#%%\r\ndfnew.index, dfnew.index.levels\r\n\r\n```\r\n\r\n#### Problem description\r\n\r\n[this should explain **why** the current behaviour is a problem and why the expected output is a better solution]\r\nThe levels of MultiIndex of DataFrame never change when creating a new DataFrame by dropping a row. When creating a new DataFrame, the levels should match the new MultiIndex.\r\n\r\n#### Expected Output\r\ndfnew.index.levels \r\n    should be \r\nFrozenList([['B'], ['X', 'Y']]))\r\n\r\n#### Output of ``pd.showversions()``\r\n\r\n<details>\r\n\r\n[paste the output of ``pd.showversions()`` here leaving a blank line after the details tag]\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit           : None\r\npython           : 3.7.7.final.0\r\npython-bits      : 64\r\nOS               : Darwin\r\nOS-release       : 19.4.0\r\nmachine          : x8664\r\nprocessor        : i386\r\nbyteorder        : little\r\nLCALL           : None\r\nLANG             : None\r\nLOCALE           : None.UTF-8\r\n\r\npandas           : 1.0.3\r\nnumpy            : 1.18.1\r\npytz             : 2019.3\r\ndateutil         : 2.8.1\r\npip              : 20.0.2\r\nsetuptools       : 46.1.3.post20200330\r\nCython           : None\r\npytest           : None\r\nhypothesis       : None\r\nsphinx           : 2.4.4\r\nblosc            : None\r\nfeather          : None\r\nxlsxwriter       : None\r\nlxml.etree       : None\r\nhtml5lib         : None\r\npymysql          : None\r\npsycopg2         : None\r\njinja2           : 2.11.1\r\nIPython          : 7.13.0\r\npandasdatareader: None\r\nbs4              : None\r\nbottleneck       : None\r\nfastparquet      : None\r\ngcsfs            : None\r\nlxml.etree       : None\r\nmatplotlib       : 3.1.3\r\nnumexpr          : None\r\nodfpy            : None\r\nopenpyxl         : 3.0.3\r\npandasgbq       : None\r\npyarrow          : None\r\npytables         : None\r\npytest           : None\r\npyxlsb           : None\r\ns3fs             : None\r\nscipy            : None\r\nsqlalchemy       : None\r\ntables           : None\r\ntabulate         : None\r\nxarray           : None\r\nxlrd             : 1.2.0\r\nxlwt             : 1.3.0\r\nxlsxwriter       : None\r\nnumba            : None\r\n\r\n</details>\r\n"},
{"text": "Now we are adding ExtensionArray.argmin/argmax (#24382 / #27801), we also need to decide on its behaviour for nullable / masked arrays. \r\nFor the default of `skipna=True`, I think the behaviour is clear (we skip those values, and calculate the argmin/argmax of the remaining values), but we need to decide on the behaviour in case of `skipna=False` in presence of missing values.\r\n\r\nI don't think it makes much sense to follow the current behaviour for Series with NaNs:\r\n\r\n```\r\nIn [25]: pd.Series([1, 2, 3, np.nan]).argmin() \r\nOut[25]: 0\r\n\r\nIn [26]: pd.Series([1, 2, 3, np.nan]).argmin(skipna=False)  \r\nOut[26]: -1\r\n```\r\n\r\n(the -1 is discussed separately in https://github.com/pandas-dev/pandas/issues/33941 as well)\r\n\r\nWe also can't really compare with numpy, as there NaNs are regarded as the largest values (which follows somewhat from the sorting behaviour with NaNs).\r\n\r\nFor other reductions, the logic is: once there is an NA present, the result is also an NA with `skipna=False` (with the logic here that the with NAs, the min/max is not known, and thus also not the location). \r\n\r\nSo something like:\r\n\r\n```python\r\n>>> pd.Series([1, 2, 3, pd.NA], dtype=\"Int64\").argmin(skipna=False)  \r\n<NA>\r\n```\r\n\r\nHowever, this also means that `argmin`/`argmax` return something that is not an integer, and since those methods are typically used to get a value that can be used to index, that might also be annoying. \r\nAn alternative could also be to raise an error (similar as for empty arrays).\r\n\r\n"},
{"text": "This is as good a time as any to revisit the \"experimental\" EA interface.\r\n\r\nMy read of the Issues and recollection of threads suggests there are three main groups of topics:\r\n\r\nClarification of the Interface\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n1) valuesforargsort and valuesforfactorize\r\n    - Do we need both?  The docs both say they should be order-preserving.\r\n    - Is it safe to return a view?  (Categorical.valuesforargsort makes a copy for no obvious reason)\r\n    - What else can they be used for internally?  e.g. in #32467 valuesforargsort is used for ExtensionIndex joinnonunique and joinmonotonic\r\n2) <s>What characteristics should ndarrayvalues have?  Is it needed?  (#32412)</s> ndarrayvalues has been removed\r\n3) What should fromsequence accept?\r\n    - Should it only be sequences that are unambiguously this dtype?\r\n    - In particular, should DTA/TDA/PA not accept i8 values?\r\n4) What should fillna accept? (#22954, #32414)\r\n4.5) Require that `iter` return native types?  #29738\r\n\r\nNdarray Compat\r\n^^^^^^^^^^^^^^^^^\r\n5) Headaches have been caused by trivial ndarray methods not being on EA\r\n    - #31199 size\r\n    - #32342 \"T\" (just the most recent; this has come up a lot)\r\n    - #24583 ravel\r\n6) For arithmetic we're going to need something like either `tile` or `broadcastto`\r\n\r\nMethods Needed/Wanted For Index/Series/DataFrame/Block\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n7) Suggested Methods (partial list)\r\n    - #27264 duplicated\r\n    - #23437 empty\r\n    - #28955 apply\r\n    - #23179 map\r\n    - #22680 hasnas\r\n    - #27081 equals\r\n    - #24144 where\r\n    - putmask would be helpful for ExtensionIndex\r\n\r\nI suggest we discuss these in order.  Before jumping in, is there anything vital missing from this list?  (this is only a small subset of the issues on the tracker)\r\n\r\ncc @pandas-dev/pandas-core @xhochy "},
{"text": "Currently when you align columns and create a new column, align will create a new float64 column filled with NaNs.\r\n\r\n```python\r\nIn [1]: import pandas as pd\r\n\r\nIn [2]: a = pd.DataFrame({\"A\": [1, 2], \"B\": [pd.Timestamp('2000'), pd.NaT]})\r\n\r\nIn [3]: b = pd.DataFrame({\"A\": [1, 2]})\r\n\r\nIn [4]: a.align(b)[1].dtypes\r\nOut[4]:\r\nA      int64\r\nB    float64\r\ndtype: object\r\n```\r\n\r\nI think it'd be more useful for the dtypes of new columns to be the same as the dtype from the other.\r\n\r\n```python\r\n# proposed behavior\r\nIn [4]: a.align(b)[1].dtypes\r\nOut[4]:\r\nA             int64\r\nB    datetime64[ns]\r\ndtype: object\r\n```\r\n\r\nThe newly created `B` column has dtype `datetime64[ns]`, the same as `a.B`.\r\n\r\nThis proposal would make the `fillvalue` keyword a bit more complex.\r\n\r\n1. The default of `np.nan` would change to `None`, which means \"the right NA value for the dtype\". \r\n2. We would maybe need to accept a Mapping so users could specify specific fill values per column.\r\n\r\nI think this would make the workaround in https://github.com/pandas-dev/pandas/pull/31679 unnecessary, as we'd have the correct dtype going into the operation.\r\n\r\n---\r\n\r\nIf we think this is a good idea, it's probably an API breaking change. We *might* be able to deprecate this cleanly by (ab)using `fillvalue`. We would warn when creating new columns.\r\n\r\n```python\r\nif newcolumns and fillvalue is nodefault:\r\n    warnings.warn(\"Creating new float64 columns filled with NaN. In the future... \"\r\n                             \"Specify fillvalue=None to accept the future behavior now.\")\r\n    fillvalue = np.nan  # \r\n```\r\n\r\nUnfortunately, that'll happen in the background during binops. Not sure how to get around that, aside from instructing users to explicitly align first."},
{"text": "#### Code Sample\r\n\r\nCreate a dataframe with nullable integer, string, and float data types.\r\n\r\n```python\r\n>>> df = df = pd.DataFrame({'a': [1, 3, np.nan], 'b': ['rain', 'shine', None], \r\n                                                    'afloat': [1.1, 3.3, np.nan]})\r\n>>> df = df.convertdtypes()\r\n>>> df\r\n```\r\n\r\n|    | a    | b     |   afloat |\r\n|---:|:-----|:------|----------:|\r\n|  0 | 1    | rain  |       1.1 |\r\n|  1 | 3    | shine |       3.3 |\r\n|  2 | `<NA>` | `<NA>`  |     nan   |\r\n\r\nVerify data types and attempt to use `query`\r\n\r\n```python\r\n>>> df.dtypes\r\na            Int64\r\nb            string\r\nafloat      float64\r\n\r\n>>> df.query('a > 2') # same as df[df['a'] > 2]\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n~/Documents/Code Practice/pandas-dev/pandas/pandas/core/frame.py in query(self, expr, inplace, **kwargs)\r\n   3227         try:\r\n-> 3228             newdata = self.loc[res]\r\n   3229         except ValueError:\r\n\r\n~/Documents/Code Practice/pandas-dev/pandas/pandas/core/indexing.py in getitem(self, key)\r\n   1683             maybecallable = com.applyifcallable(key, self.obj)\r\n-> 1684             return self.getitemaxis(maybecallable, axis=axis)\r\n   1685 \r\n\r\n~/Documents/Code Practice/pandas-dev/pandas/pandas/core/indexing.py in getitemaxis(self, key, axis)\r\n   1798             return self.getsliceaxis(key, axis=axis)\r\n-> 1799         elif com.isboolindexer(key):\r\n   1800             return self.getboolaxis(key, axis=axis)\r\n\r\n~/Documents/Code Practice/pandas-dev/pandas/pandas/core/common.py in isboolindexer(key)\r\n    133                 if np.any(key.isna()):\r\n--> 134                     raise ValueError(namsg)\r\n    135             return True\r\n\r\nValueError: cannot mask with array containing NA / NaN values\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-52-e5d239635d7b> in <module>\r\n----> 1 df.query('a > 2')\r\n\r\n~/Documents/Code Practice/pandas-dev/pandas/pandas/core/frame.py in query(self, expr, inplace, **kwargs)\r\n   3230             # when res is multi-dimensional loc raises, but this is sometimes a\r\n   3231             # valid query\r\n-> 3232             newdata = self[res]\r\n   3233 \r\n   3234         if inplace:\r\n\r\n~/Documents/Code Practice/pandas-dev/pandas/pandas/core/frame.py in getitem(self, key)\r\n   2784 \r\n   2785         # Do we have a (boolean) 1d indexer?\r\n-> 2786         if com.isboolindexer(key):\r\n   2787             return self.getitemboolarray(key)\r\n   2788 \r\n\r\n~/Documents/Code Practice/pandas-dev/pandas/pandas/core/common.py in isboolindexer(key)\r\n    132             if isextensionarraydtype(key.dtype):\r\n    133                 if np.any(key.isna()):\r\n--> 134                     raise ValueError(namsg)\r\n    135             return True\r\n    136     elif isinstance(key, list):\r\n\r\nValueError: cannot mask with array containing NA / NaN values\r\n\r\n>>> df.query('afloat > 2')\r\n```\r\n|    |   a | b     |   afloat |\r\n|---:|----:|:------|----------:|\r\n|  1 |   3 | shine |       3.3 |\r\n\r\nUsing `query` with strings works...\r\n\r\n```python\r\n>>> df.query('b == \"rain\"')\r\n```\r\n|    |   a | b    |   afloat |\r\n|---:|----:|:-----|----------:|\r\n|  0 |   1 | rain |       1.1 |\r\n\r\n\r\n...but fails for boolean selection\r\n```python\r\n>>> df[df['b'] == 'rain']\r\nValueError: cannot mask with array containing NA / NaN values\r\n```\r\n\r\nstrings also fail for inequalities\r\n```\r\n>>> df.query('b >= \"rain\"') # also df.query('b > \"rain\"')\r\nValueError: cannot mask with array containing NA / NaN values\r\n```\r\n\r\n#### Problem description\r\n\r\nThe `query` method  behaves differently for nullable integers, strings, and floats. Here's my summary of how I think they work with the `query method` assuming there are missing values in the columns.\r\n\r\n* nullable integers - fails\r\n* strings - works with equality, fails with inequality\r\n* float - works for all\r\n\r\nI find it extremely difficult to use if the behavior for all of these types are different for query and boolean selection.\r\n\r\n#### Expected Output\r\n\r\nI think I would prefer to have both query and boolean selection working like they do with floats, where missing values evaluate as False in a condition. And even if there are missing values in the boolen mask itself, treat those as False. This would harmonize the behavior for all data types. \r\n\r\nThis would leave it up to the user to check for missing values. I believe SQL where clauses work in such a manner (missing values in conditions evaluate as False).\r\n\r\n#### Output of ``pd.showversions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit           : None\r\npython           : 3.8.1.final.0\r\npython-bits      : 64\r\nOS               : Darwin\r\nOS-release       : 19.2.0\r\nmachine          : x8664\r\nprocessor        : i386\r\nbyteorder        : little\r\nLCALL           : None\r\nLANG             : enUS.UTF-8\r\nLOCALE           : enUS.UTF-8\r\n\r\npandas           : 0+untagged.1.gce8af21.dirty\r\nnumpy            : 1.18.1\r\npytz             : 2019.3\r\ndateutil         : 2.8.1\r\npip              : 20.0.2\r\nsetuptools       : 45.1.0.post20200127\r\nCython           : 0.29.14\r\npytest           : None\r\nhypothesis       : None\r\nsphinx           : None\r\nblosc            : None\r\nfeather          : None\r\nxlsxwriter       : None\r\nlxml.etree       : 4.5.0\r\nhtml5lib         : None\r\npymysql          : None\r\npsycopg2         : None\r\njinja2           : 2.10.3\r\nIPython          : 7.11.1\r\npandasdatareader: None\r\nbs4              : None\r\nbottleneck       : None\r\nfastparquet      : None\r\ngcsfs            : None\r\nlxml.etree       : 4.5.0\r\nmatplotlib       : 3.1.1\r\nnumexpr          : None\r\nodfpy            : None\r\nopenpyxl         : None\r\npandasgbq       : None\r\npyarrow          : None\r\npytables         : None\r\npytest           : None\r\npyxlsb           : None\r\ns3fs             : None\r\nscipy            : 1.3.1\r\nsqlalchemy       : 1.3.13\r\ntables           : None\r\ntabulate         : 0.8.3\r\nxarray           : None\r\nxlrd             : None\r\nxlwt             : None\r\nxlsxwriter       : None\r\nnumba            : None\r\n\r\n</details>\r\n"},
{"text": "#### Summary\r\n\r\nThanks for making Pandas I have used it in a lot of projects! But now I have a problem.\r\n\r\nI have spent nearly 3 days trying to figure out how to **resample / upsample a Pandas MultiIndex** elegantly and correctly. I have read and tried numerous posts on StackOverflow and GitHub. My conclusion is that **I don't think this is supported very well in Pandas**. Let me explain what I want to do.\r\n\r\n#### Background\r\n\r\nI am currently building a Python API in collaboration with www.simfin.com that makes it very easy to download and use financial data (share-prices, fundamentals, etc.) for free. This will enable people to conduct and share financial research very easily. It works by downloading bulk-data in CSV files from the SimFin server and loading them in Pandas. The fundamental data such as Income Statements and Balance Sheets is usually indexed by the Ticker and Report Date which creates a Pandas DataFrame with a MultiIndex.\r\n\r\n#### Data Example\r\n\r\nLet us say we have a Pandas DataFrame `df` with this data:\r\n\r\n                             Revenue  Net Income (Common)\r\n    Ticker Report Date                                   \r\n    AAPL   2007-09-30    24578000000           3495000000\r\n           2008-09-30    37491000000           6119000000\r\n           2009-09-30    42905000000           8235000000\r\n           2010-09-30    65225000000          14013000000\r\n           2011-09-30   108249000000          25922000000\r\n           2012-09-30   156508000000          41733000000\r\n           2013-09-30   170910000000          37037000000\r\n           2014-09-30   182795000000          39510000000\r\n           2015-09-30   233715000000          53394000000\r\n           2016-09-30   215639000000          45687000000\r\n           2017-09-30   229234000000          48351000000\r\n           2018-09-30   265595000000          59531000000\r\n    AMZN   2007-12-31    14835000000            476000000\r\n           2008-12-31    19166000000            645000000\r\n           2009-12-31    24509000000            902000000\r\n           2010-12-31    34204000000           1152000000\r\n           2011-12-31    48077000000            631000000\r\n           2012-12-31    61093000000            -39000000\r\n           2013-12-31    74452000000            274000000\r\n           2014-12-31    88988000000           -241000000\r\n           2015-12-31   107006000000            596000000\r\n           2016-12-31   135987000000           2371000000\r\n           2017-12-31   177866000000           3033000000\r\n           2018-12-31   232887000000          10073000000\r\n    MSFT   2008-06-30    60420000000          17681000000\r\n           2009-06-30    58437000000          14569000000\r\n           2010-06-30    62484000000          18760000000\r\n           2011-06-30    69943000000          23150000000\r\n           2012-06-30    73723000000          16978000000\r\n           2013-06-30    77849000000          21863000000\r\n           2014-06-30    86833000000          22074000000\r\n           2015-06-30    93580000000          12193000000\r\n           2016-06-30    91154000000          20539000000\r\n           2017-06-30    96571000000          25489000000\r\n           2018-06-30   110360000000          16571000000\r\n\r\n#### Resample a single Ticker (DatetimeIndex)\r\n\r\nLet us first resample for a single ticker:\r\n\r\n    df.loc['MSFT'].resample('D').pad()\r\n\r\nThis works and the result is:\r\n\r\n                     Revenue  Net Income (Common)\r\n    Report Date                                  \r\n    2008-06-30   60420000000          17681000000\r\n    2008-07-01   60420000000          17681000000\r\n    2008-07-02   60420000000          17681000000\r\n    2008-07-03   60420000000          17681000000\r\n    2008-07-04   60420000000          17681000000\r\n\r\n#### Resample multiple Tickers (MultiIndex)\r\n\r\nLet us now try and resample for all tickers in the DataFrame. The `resample()` function takes an argument `level` which is supposed to work with a MultiIndex DataFrame:\r\n\r\n    df.resample('D', level='Report Date').pad()\r\n\r\nBut this apparently doesn't work for upsampling e.g. annual data to daily data, because we get this error message:\r\n\r\n    ValueError: Upsampling from level= or on= selection is not supported, use .setindex(...) to explicitly set index to datetime-like\r\n\r\nOne solution is to use `groupby()` (adapted from e.g. #13699):\r\n\r\n    df.resetindex('Ticker').groupby('Ticker').resample('D').pad()\r\n\r\nThis works, but it now has duplicated the Ticker both as an index and as a column:\r\n\r\n                       Ticker      Revenue  Net Income (Common)\r\n    Ticker Report Date                                         \r\n    AAPL   2007-09-30    AAPL  24578000000           3495000000\r\n           2007-10-01    AAPL  24578000000           3495000000\r\n           2007-10-02    AAPL  24578000000           3495000000\r\n           2007-10-03    AAPL  24578000000           3495000000\r\n           2007-10-04    AAPL  24578000000           3495000000\r\n\r\nWe can avoid one of them by adding the arg `groupkeys=False`:\r\n\r\n    df.resetindex('Ticker').groupby('Ticker', groupkeys=False).resample('D').pad()\r\n\r\nThis works, but now the Ticker is a data-column instead of an index:\r\n\r\n                Ticker      Revenue  Net Income (Common)\r\n    Report Date                                         \r\n    2007-09-30    AAPL  24578000000           3495000000\r\n    2007-10-01    AAPL  24578000000           3495000000\r\n    2007-10-02    AAPL  24578000000           3495000000\r\n    2007-10-03    AAPL  24578000000           3495000000\r\n    2007-10-04    AAPL  24578000000           3495000000\r\n\r\nTo get the original MultiIndex back with both Ticker and Report Date, we need to do:\r\n\r\n    df.resetindex('Ticker').groupby('Ticker', groupkeys=False).resample('D').pad().resetindex().setindex(['Ticker', 'Report Date'])\r\n\r\nWhich produces the desired result:\r\n\r\n                            Revenue  Net Income (Common)\r\n    Ticker Report Date                                  \r\n    AAPL   2007-09-30   24578000000           3495000000\r\n           2007-10-01   24578000000           3495000000\r\n           2007-10-02   24578000000           3495000000\r\n           2007-10-03   24578000000           3495000000\r\n           2007-10-04   24578000000           3495000000\r\n\r\nBut this is so complicated that nobody can be expected to remember how to do it. So I would have to make a small helper-function that does all of this. But because the resampling method (pad, interpolate, etc.) is invoked through a function call on the groupby-object, my helper-function would get big and awkward if I want to allow different methods of resampling.\r\n\r\n#### Conclusion\r\n\r\nIt appears that upsampling a MultiIndex is not supported very well in Pandas, unless I have misunderstood how it is supposed to work.\r\n\r\nI think that by far the most elegant solution would be if the `resample()` function supported the `level` argument for upsampling, because the syntax and semantics would be very similar for upsampling DatetimeIndex and MultiIndex:\r\n\r\n    # DatetimeIndex\r\n    df.loc['MSFT'].resample('D').pad()\r\n\r\n    # MultiIndex\r\n    df.resample('D', level='Report Date').pad()\r\n\r\nI have taken a look at the Pandas source-code, but it is complicated and so sparsely documented, that it would take me forever to figure out how everything is connected and how it works, so I don't think I will be able to fix this myself. Is this something you could fix, because it would make it so much easier to upsample DataFrames with a MultiIndex?\r\n\r\nThanks!\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit           : None\r\npython           : 3.6.8.final.0\r\npython-bits      : 64\r\nOS               : Linux\r\nOS-release       : 4.15.0-60-generic\r\nmachine          : x8664\r\nprocessor        : x8664\r\nbyteorder        : little\r\nLCALL           : None\r\nLANG             : enUS.UTF-8\r\nLOCALE           : enUS.UTF-8\r\n\r\npandas           : 0.25.1\r\nnumpy            : 1.16.4\r\npytz             : 2019.2\r\ndateutil         : 2.8.0\r\npip              : 19.1.1\r\nsetuptools       : 41.0.1\r\nCython           : None\r\npytest           : None\r\nhypothesis       : None\r\nsphinx           : None\r\nblosc            : None\r\nfeather          : None\r\nxlsxwriter       : None\r\nlxml.etree       : None\r\nhtml5lib         : None\r\npymysql          : None\r\npsycopg2         : None\r\njinja2           : 2.10.1\r\nIPython          : 7.5.0\r\npandasdatareader: None\r\nbs4              : None\r\nbottleneck       : None\r\nfastparquet      : None\r\ngcsfs            : None\r\nlxml.etree       : None\r\nmatplotlib       : 3.1.0\r\nnumexpr          : None\r\nodfpy            : None\r\nopenpyxl         : None\r\npandasgbq       : None\r\npyarrow          : None\r\npytables         : None\r\ns3fs             : None\r\nscipy            : 1.3.1\r\nsqlalchemy       : None\r\ntables           : None\r\nxarray           : None\r\nxlrd             : None\r\nxlwt             : None\r\nxlsxwriter       : None\r\n\r\n</details>"},
{"text": "Currently, to extend pandas `Series`, `DataFrame` and `Index` with user-defined methods, we use accessors in the next way:\r\n\r\n```python\r\n@pandas.api.extensions.registerseriesaccessor('emoji')\r\nclass Emoji:\r\n    def init(self, data):\r\n        self.data = data\r\n\r\n    def ismonkey(self):\r\n        \"\"\"\r\n        This would create `Series().emoji.ismonkey`\r\n        \"\"\"\r\n        return self.data.isin(['\ud83d\ude48', '\ud83d\ude49', '\ud83d\ude4a'])\r\n```\r\n\r\nWhile this works well, I think there are two problems with this approach:\r\n- The API looks somehow intimidating, and it's not well known. I think because `pandas.api.extensions.registerseriesaccessor` is too long and lives in `pandas.api`, separate of functionality most users know.\r\n- It's not possible to register methods directly (`Series().ismonkey` instead of `Series().emoji.ismonkey`)\r\n\r\nI think all the projects extending pandas I've seen, simply \"inject\" the methods (except the ones implemented by pandas maintainers). For example:\r\n- https://github.com/PatrikHlobil/Pandas-Bokeh/blob/master/pandasbokeh/init.py#L20\r\n- https://github.com/nalepae/pandarallel/blob/master/pandarallel/pandarallel.py#L52\r\n\r\nWhat I propose is to have a easier/simpler API for the user. To be specific, this is the syntax I'd like when extending `Series`...\r\n\r\n```python\r\nimport pandas\r\n\r\n@pandas.Series.extend('emoji')\r\nclass Emoji:\r\n    def init(self, data):\r\n        self.data = data\r\n\r\n    def ismonkey(self):\r\n        \"\"\"\r\n        This would create `Series().emoji.ismonkey`\r\n        \"\"\"\r\n        return self.data.isin(['\ud83d\ude48', '\ud83d\ude49', '\ud83d\ude4a'])\r\n\r\n@pandas.Series.extend(namespace='emoji')\r\ndef ismonkey(data):\r\n    \"\"\"\r\n    This would also create `Series().emoji.ismonkey`\r\n    \"\"\"\r\n    return data.isin(['\ud83d\ude48', '\ud83d\ude49', '\ud83d\ude4a'])\r\n\r\n@pandas.Series.extend\r\nclass Emoji:\r\n    def init(self, data):\r\n        self.data = data\r\n\r\n    def ismonkey(self):\r\n        \"\"\"\r\n        This would directly create `Series().ismonkey`\r\n        \"\"\"\r\n        return self.data.isin(['\ud83d\ude48', '\ud83d\ude49', '\ud83d\ude4a'])\r\n\r\n@pandas.Series.extend\r\ndef ismonkey(data):\r\n    \"\"\"\r\n    This would create `Series().emoji.ismonkey`\r\n    \"\"\"\r\n    return data.isin(['\ud83d\ude48', '\ud83d\ude49', '\ud83d\ude4a'])\r\n```\r\n\r\nThis would make things much easier for the user, because:\r\n- The name `pandas.Series.extend` is much easier to remember\r\n- A single function can be used (without creating a class)\r\n- A direct method of `Series`... can be created\r\n\r\nCC: @pandas-dev/pandas-core "},
{"text": "This has confused me for a while, but we apparently (sometimes?) allow a `fillvalue` whose dtype is not the same as `spvalues.dtype`\r\n\r\n```python\r\nIn [20]: a = pd.SparseArray([1, 2, 3], fillvalue=1.0)\r\n\r\nIn [21]: a\r\nOut[21]:\r\n[1.0, 2, 3]\r\nFill: 1.0\r\nIntIndex\r\nIndices: array([1, 2], dtype=int32)\r\n\r\nIn [22]: a.spvalues.dtype\r\nOut[22]: dtype('int64')\r\n```\r\n\r\nThis can lead to confusing behavior when doing operations.\r\n\r\nI suspect a primary motivation was supporting sparse integer values with `NaN` for a fill value. We should investigate what's tested, part of the API, and useful to users."},
{"text": "I'm very often working with `df.groupby.apply()`, and there are many confusing (sometimes wrong) aspects about the behaviour of the output, particularly regarding what happens with the index of the output. `v.0.23` cleaned up big parts of the `apply` API, but there's still a lot left...\r\n\r\nIdeally, I wish there'd be a sort of matrix (not necessarily in the following form) in the documentation - and implemented by the API - along the following lines\r\n\r\nFor `asindex=True`:\r\n```\r\nfunction output   |  result type  |  (multi-)index levels |  groupby-cols  |  columns\r\n--------------------------------------------------------------------------------------------\r\nscalar            |    Series     |    groupby-columns    |      n/a       |  none\r\nSeries            |   DataFrame   |    groupby-columns    |     dropped    |  index (union) of Series\r\nDataFrame         |   DataFrame   |   gb-cols + df.index  |     dropped    |  columns (union) of DFs\r\nnp.ndarray 1-dim  |   DataFrame   |  to dicuss / raise ?  |      n/a       |  to dicuss / raise ?\r\nnp.ndarray 2-dim  |   DataFrame   |  to dicuss / raise ?  |      n/a       |  to dicuss / raise ?\r\nIndex             |  MultiIndex?  |   gb-cols + output    |      n/a       |  n/a\r\n```\r\nFor `asindex=False`:\r\n```\r\nfunction output   |  result type  |  (multi-)index levels |  groupby-cols  |  columns\r\n--------------------------------------------------------------------------------------------\r\nscalar            |   DataFrame?  |      RangeIndex       |      n/a       |  gb-cols + output?\r\nSeries            |   DataFrame   |      RangeIndex       |      kept      |  gb-cols + index of Series?\r\nDataFrame         |   DataFrame   |  to dicuss / raise ?  |      kept      |  gb-cols + columns of DFs\r\nnp.ndarray 1-dim  |   DataFrame   |  to dicuss / raise ?  |      n/a       |  to dicuss / raise ?\r\nnp.ndarray 2-dim  |   DataFrame   |  to dicuss / raise ?  |      n/a       |  to dicuss / raise ?\r\nIndex             |    Series?    |  to dicuss / raise ?  |      n/a       |  n/a\r\n```\r\n\r\nCurrently, the behaviour is much, much more complicated / inconsistent / wrong. I'm trying to fill corresponding tables with the current behaviour and some issue xrefs, but it's by far not complete yet:\r\n\r\nFor `asindex=True`:\r\n```\r\nfunction output   |  result type  |  (multi-)index levels |  groupby-cols  |  columns\r\n--------------------------------------------------------------------------------------------\r\nscalar            |    Series     |    groupby-columns    |      n/a       |  none\r\nSeries (same idx) |   DataFrame   |    groupby-columns    |     kept?!     |  index of Series\r\nSeries (diff idx) |    Series?!   |  gb-cols + output.idx |      n/a       |  none?!\r\ngroup as-is       |   DataFrame   |    original index?!   |     kept?!     |  original columns\r\ngroup selection   |   DataFrame   |  gb-cols + output.idx |     kept?!     |  original columns\r\nDataFrame         |   DataFrame   |  gb-cols + output.idx |      n/a       |  columns (union) of DFs\r\nnp.ndarray 1-dim  |    Series?!   |   groupby-columns     |      n/a       |  none\r\nnp.ndarray 2-dim  |    Series?!   |   groupby-columns     |      n/a       |  none\r\nIndex             |    Series?!   |   groupby-columns     |      n/a       |  none #22541\r\n```\r\nFor `asindex=False`:\r\n```\r\nfunction output   |  result type  |  (multi-)index levels |  groupby-cols  |  columns\r\n--------------------------------------------------------------------------------------------\r\nscalar            |    Series     |      RangeIndex       |      n/a       |  none\r\nSeries (same idx) |   DataFrame   |      RangeIndex       |     kept       |  index of Series\r\nSeries (diff idx) |    Series?!   | RngIdx + output.idx?! |      n/a       |  none?!\r\ngroup as-is       |   DataFrame   |    original index?!   |     kept       |  original columns\r\ngroup selection   |   DataFrame   | RngIdx + output.idx?! |     kept       |  original columns\r\nDataFrame         |   DataFrame   | RngIdx + output.idx?! |      n/a       |  columns (union) of DFs\r\nnp.ndarray 1-dim  |    Series?!   |      RangeIndex       |      n/a       |  none\r\nnp.ndarray 2-dim  |    Series?!   |      RangeIndex       |      n/a       |  none\r\nIndex             |    Series?!   |      RangeIndex       |      n/a       |  none #22541\r\n```\r\n\r\nSome xrefs: #20420, #22541, #22542, #22546"},
{"text": "For clarification, by \"interval-point\" joins I mean joining an `IntervalIndex`/`IntervalArray` against the point values contained in the intervals, e.g. joining a numeric `IntervalIndex` against a `Float64Index`.  I want to keep this discussion separate from interval-interval merges for the time being.\r\n\r\nFor example, the following `join` does not currently work (and likewise `merge` with column data):  \r\n```python\r\nIn [2]: df1 = pd.DataFrame({'A': [10, 20, 30]}, index=pd.intervalrange(0, 3))\r\n\r\nIn [3]: df2 = pd.DataFrame({'B': ['foo', 'bar', 'baz', 'qux']},\r\n   ...:                    index=[0.5, 1, 2.71828, 3.14159])\r\n\r\nIn [4]: df1\r\nOut[4]: \r\n         A\r\n(0, 1]  10\r\n(1, 2]  20\r\n(2, 3]  30\r\n\r\nIn [5]: df2\r\nOut[5]: \r\n           B\r\n0.50000  foo\r\n1.00000  bar\r\n2.71828  baz\r\n3.14159  qux\r\n\r\nIn [6]: df1.join(df2)\r\nOut[6]: \r\n         A    B\r\n(0, 1]  10  NaN\r\n(1, 2]  20  NaN\r\n(2, 3]  30  NaN\r\n```\r\n\r\nI think the behavior of such a `join`/`merge` is straight forward for left/right joins, but is a little bit less clear for inner/outer joins.  For inner (outer) joins one takes the intersection (union) of both indexes as the resulting index values.  This makes sense when both indexes contain the same type of objects, but this is not the case for interval-point joins.  I can't think of a consistent way to handle inner/outer joins, and not entirely if they even make sense.  A few options:\r\n\r\n- Do not support inner/outer interval-point joins\r\n- For inner joins:\r\n  - always keep the intervals and filter any non-matches?\r\n  - default to the left index and filter any non-matches?\r\n- For outer joins:\r\n  - union any non-matching point values for an `object` dtype?\r\n     - obviously non-performant and a bit weird\r\n  - coerce non-matching points to degenerate intervals (left == right) and union for an interval dtype?\r\n- Use a new API for non-exact interval joins?\r\n\r\nI'm leaning towards just using the existing API not supporting inner/outer for the time being, but would appreciate any thoughts."},
{"text": "Under #18262 a `FutureWarning` was added suggesting that existing code like this:\r\n\r\n    pd.DataFrame.fromitems(x)\r\n\r\nShould be changed to this:\r\n\r\n    import collections\r\n    pd.DataFrame.fromdict(collections.OrderedDict(x))\r\n\r\nThe fact that `fromitems()` appeared only 6 times (now 8 times) in a Stack Overflow search was used as partial justification for removing it.  But if you search on GitHub, [`pd.DataFrame.fromitems()`](https://github.com/search?q=pd.DataFrame.fromitems&type=Code) appears more than 15,000 times in Python--almost half as many as `fromrecords()`!\r\n\r\nWe should celebrate the fact that this function doesn't cause enough confusion to appear often on Stack Overflow.  But it does occur (a lot!) in real code, and deprecating it is a mistake.\r\n\r\nIf constructing a temporary `OrderedDict` around items is the best way to construct a DataFrame, Pandas should implement that as a short function called `DataFrame.fromitems()`, rather than asking thousands of people to busy themselves to accommodate this unnecessary API change.\r\n\r\nI recommend removing the FutureWarning, and retaining this widely-used, longstanding function.\r\n\r\nFor reference, the `FutureWarning` starts in 0.23 and looks like this:\r\n\r\n> FutureWarning: fromitems is deprecated. Please use DataFrame.fromdict(dict(items), ...) instead. DataFrame.fromdict(OrderedDict(items)) may be used to preserve the key order.\r\n\r\n"},
{"text": "Currently, ``Categorical.unique`` and ``CategoricalIndex.unique`` drop unused categories:\r\n\r\n```python\r\n>>> categories = ['very good', 'good', 'neutral', 'bad', 'very bad']\r\n>>> cat = pd.Categorical(['good','good', 'bad', 'bad'], categories=categories, ordered=True)\r\n>>> cat\r\n[good, good, bad, bad]\r\nCategories (5, object): [very good < good < neutral < bad < very bad]\r\n>>> cat.unique()\r\n[good, bad]\r\nCategories (2, object): [good < bad]  # unused categories dropped\r\n```\r\n\r\nSo, ``.unique()`` both uniquefies and drops unused categories (does two things in one operation)\r\n\r\nOften, even if you want to uniquefy values, you still want to control whether to drop unused categories or not. So ``Categorical/CategoricalIndex.unique`` should IMO keep all categories, and categories should be dropped in a seperate action. So, this would be a better API:\r\n\r\n```python\r\n>>> cat.unique()\r\n[good, bad]\r\nCategories (5, object): [very good < good < neutral < bad < very bad]    # unused not dropped\r\n```\r\n\r\nIf you want to drop unused categories, you should do it explicitly like so: ``cat.unique().removeunusedcategories()``.\r\n\r\nThe proposed API is also faster, as dropping unused categories requires recoding the categories/codes, which is potentially expensive.\r\n"},
{"text": "Many thanks for the excellent software. This report is about behavior I did not expect. Not sure if it is a bug or not.\r\n\r\n```python\r\n>>> import pandas as pd\r\n>>> s = pd.Series([10, 20, 30, 'a', 'a', 'b', 'a'])\r\n>>> print(s)\r\n0    10\r\n1    20\r\n2    30\r\n3     a\r\n4     a\r\n5     b\r\n6     a\r\ndtype: object\r\n>>> print(s.replace('a', None))\r\n0    10\r\n1    20\r\n2    30\r\n3    30\r\n4    30\r\n5     b\r\n6     b\r\ndtype: object\r\n>>> print(s.replace({'a': None}))\r\n0      10\r\n1      20\r\n2      30\r\n3    None\r\n4    None\r\n5       b\r\n6    None\r\ndtype: object\r\n```\r\n#### Problem description\r\n\r\nThis behavior was unexpected for me. I would have assumed that these two lines would produce the same output:\r\n```python\r\ns.replace('a', None)\r\ns.replace({'a': None})\r\n```\r\n\r\nIn my particular use case, I was actually looking to just replace `'a'`with `None` and therefore did `s.replace('a', None)`. I did not check output carefully and therefore ended up with some very strange behavior down the line in my data analysis.\r\n\r\nNot sure if this is to be considered a bug or not. Docs are not entirely clear on what is intended behavior. Possible solutions could include\r\n\r\n* Describe behavior in docs (the filling behavior is barely described at all).\r\n* Hint that something like `s.replace('a', numpy.nan)` might be a better option.\r\n* Change API to require a more explicit opt-in for filling.\r\n\r\n#### Output of ``pd.showversions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.6.4.final.0\r\npython-bits: 64\r\nOS: Linux\r\nOS-release: 4.4.0-116-generic\r\nmachine: x8664\r\nprocessor: x8664\r\nbyteorder: little\r\nLCALL: None\r\nLANG: enUS.UTF-8\r\nLOCALE: enUS.UTF-8\r\n\r\npandas: 0.22.0\r\npytest: None\r\npip: 9.0.1\r\nsetuptools: 38.5.1\r\nCython: None\r\nnumpy: 1.14.0\r\nscipy: None\r\npyarrow: None\r\nxarray: None\r\nIPython: None\r\nsphinx: None\r\npatsy: None\r\ndateutil: 2.6.1\r\npytz: 2018.3\r\nblosc: None\r\nbottleneck: None\r\ntables: None\r\nnumexpr: None\r\nfeather: None\r\nmatplotlib: None\r\nopenpyxl: None\r\nxlrd: None\r\nxlwt: None\r\nxlsxwriter: None\r\nlxml: None\r\nbs4: None\r\nhtml5lib: None\r\nsqlalchemy: None\r\npymysql: None\r\npsycopg2: None\r\njinja2: None\r\ns3fs: None\r\nfastparquet: None\r\npandasgbq: None\r\npandasdatareader: None\r\n\r\n</details>\r\n"},
{"text": "Discussed briefly on the call today, but we should go through things formally.\r\n\r\nWhat should the return type of `Series[extensionarray].values` and `Index[extensionarray].values` be? I believe the two options are\r\n\r\n1. Return the ExtensionArray backing it (e.g. like what Categorical does)\r\n2. Return an ndarray with some information loss / performance cost\r\n   - e.g. like Series[datetimeTZ].values -> datetime64ns at UTC\r\n   - e.g. Series[period].values -> ndarray[Period objects]\r\n\r\n## Current State\r\n\r\nNot sure how much weight we should put on the current behavior, but for reference:\r\n\r\ntype        | Series.values           | Index.values\r\n----------- | ----------------------- | ------------\r\ndatetime    | datetime64ns            | datetime64ns\r\ndatetime-tz | datetine64ns(UTC&naive) | datetime64ns(UTC&naive)\r\ncategorical | Categorical             | Categorical\r\nperiod      | NA                      | ndarray[Period objects]\r\ninterval    | NA                      | ndarray[Interval objects]\r\n\r\n<details>\r\n\r\n```python\r\nIn [5]: pd.Series(pd.daterange('2017', periods=1)).values\r\nOut[5]: array(['2017-01-01T00:00:00.000000000'], dtype='datetime64[ns]')\r\n\r\nIn [6]: pd.Series(pd.daterange('2017', periods=1, tz='US/Eastern')).values\r\nOut[6]: array(['2017-01-01T05:00:00.000000000'], dtype='datetime64[ns]')\r\n\r\nIn [7]: pd.Series(pd.Categorical([1])).values\r\nOut[7]:\r\n[1]\r\nCategories (1, int64): [1]\r\n\r\nIn [8]: pd.Series(pd.SparseArray([1])).values\r\nOut[8]:\r\n[1]\r\nFill: 0\r\nIntIndex\r\nIndices: array([0], dtype=int32)\r\n\r\nIn [9]: pd.daterange('2017', periods=1).values\r\nOut[9]: array(['2017-01-01T00:00:00.000000000'], dtype='datetime64[ns]')\r\n\r\nIn [10]: pd.daterange('2017', periods=1, tz='US/Central').values\r\nOut[10]: array(['2017-01-01T06:00:00.000000000'], dtype='datetime64[ns]')\r\n\r\nIn [11]: pd.periodrange('2017', periods=1, freq='D').values\r\nOut[11]: array([Period('2017-01-01', 'D')], dtype=object)\r\n\r\nIn [12]: pd.intervalrange(start=0, periods=1).values\r\nOut[12]: array([Interval(0, 1, closed='right')], dtype=object)\r\n\r\nIn [13]: pd.CategoricalIndex([1]).values\r\nOut[13]:\r\n[1]\r\nCategories (1, int64): [1]\r\n```\r\n\r\n</details>\r\n\r\nIf we decide to have the return values be ExtensionArrays, we'll need to discuss\r\nto what extent they're part of the public API.\r\n\r\nRegardless of the choice for `.values`, we'll probably want to support the other\r\nuse case (maybe just by documenting \"call `np.asarray` on it). Internally, we\r\nhave `.values` (\"best\" array, ndarray or EA) and `.ndarrayvalues` (always an\r\nndarray).\r\n\r\n\r\ncc @jreback @jorisvandenbossche @jschendel @jbrockmendel @shoyer @chris-b1 "},
{"text": "#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\nIn [2]: s = pd.Series(dtype='object')\r\n\r\nIn [3]: s.loc['myint'] = 1\r\n\r\nIn [4]: s.loc['myfloat'] = 2.\r\n\r\nIn [5]: s\r\nOut[5]: \r\nmyint      1.0\r\nmyfloat    2.0\r\ndtype: float64\r\n```\r\n#### Problem description\r\n\r\nWhen an empty Series is added the first object, it does inference on it and sets its dtype ( https://github.com/pandas-dev/pandas/issues/19576#issuecomment-363875752 ). This can be nice... except if the user had passed a specific dtype on construction.\r\n\r\nEmpty objects should (by default) have no dtype set (or have an [\"Any\" dtype](https://github.com/pandas-dev/pandas/issues/19576#issuecomment-364680239)), and inference should be done only in this case.\r\n\r\n#### Expected Output\r\n\r\n#### Output of ``pd.showversions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.5.3.final.0\r\npython-bits: 64\r\nOS: Linux\r\nOS-release: 4.9.0-5-amd64\r\nmachine: x8664\r\nprocessor: \r\nbyteorder: little\r\nLCALL: None\r\nLANG: itIT.UTF-8\r\nLOCALE: itIT.UTF-8\r\n\r\npandas: 0.19.2\r\nnose: 1.3.7\r\npip: 9.0.1\r\nsetuptools: 33.1.1\r\nCython: 0.25.2\r\nnumpy: 1.13.3\r\nscipy: 0.18.1\r\nstatsmodels: None\r\nxarray: None\r\nIPython: 5.1.0\r\nsphinx: 1.4.9\r\npatsy: 0.4.1+dev\r\ndateutil: 2.5.3\r\npytz: 2016.7\r\nblosc: None\r\nbottleneck: 1.2.0\r\ntables: 3.3.0\r\nnumexpr: 2.6.1\r\nmatplotlib: 2.0.0\r\nopenpyxl: 2.3.0\r\nxlrd: 1.0.0\r\nxlwt: None\r\nxlsxwriter: 0.9.6\r\nlxml: 3.7.1\r\nbs4: 4.5.3\r\nhtml5lib: 0.999999999\r\nhttplib2: 0.9.2\r\napiclient: None\r\nsqlalchemy: 1.0.15\r\npymysql: None\r\npsycopg2: None\r\njinja2: 2.8\r\nboto: None\r\npandasdatareader: None\r\n\r\n\r\n</details>\r\n"},
{"text": "#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\n>>> ndt = np.dtype(object)\r\n>>> pdt = pd.api.types.CategoricalDtype(categories=['German', 'English', 'French'])\r\n>>> pdt == ndt\r\nFalse  # ok\r\n>>> ndt == pdt\r\nTypeError: data type not understood\r\n```\r\n#### Problem description\r\n\r\nThe dtypes are not always comparable, The same issue is with IntervalDtype and if the numpy types are oher kinds (int, float, dates etc.).\r\n\r\nThe issue may be a numpy issue and not a pandas issue, but I raise it here for discussion first, and can later file an issue at the numpy repository.\r\n\r\n#### Expected Output\r\n\r\nExpected was ``False``.\r\n\r\n#### Output of ``pd.showversions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: 78d4e5db4f04086f2006796840bf6f1882de2afb\r\npython: 3.6.3.final.0\r\npython-bits: 32\r\nOS: Windows\r\nOS-release: 10\r\nmachine: AMD64\r\nprocessor: Intel64 Family 6 Model 78 Stepping 3, GenuineIntel\r\nbyteorder: little\r\nLCALL: None\r\nLANG: None\r\nLOCALE: None.None\r\n\r\npandas: 0.22.0.dev0+561.g78d4e5d\r\npytest: 3.3.1\r\npip: 9.0.1\r\nsetuptools: 38.2.5\r\nCython: 0.26.1\r\nnumpy: 1.13.3\r\nscipy: 1.0.0\r\npyarrow: None\r\nxarray: None\r\nIPython: 6.2.1\r\nsphinx: 1.6.3\r\npatsy: 0.4.1\r\ndateutil: 2.6.1\r\npytz: 2017.3\r\nblosc: None\r\nbottleneck: None\r\ntables: None\r\nnumexpr: None\r\nfeather: None\r\nmatplotlib: 2.1.0\r\nopenpyxl: 2.4.9\r\nxlrd: 1.1.0\r\nxlwt: 1.3.0\r\nxlsxwriter: None\r\nlxml: None\r\nbs4: None\r\nhtml5lib: 1.0b10\r\nsqlalchemy: None\r\npymysql: None\r\npsycopg2: None\r\njinja2: 2.9.6\r\ns3fs: None\r\nfastparquet: None\r\npandasgbq: None\r\npandasdatareader: None\r\n\r\n</details>\r\n"},
{"text": "#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\nIn [2]: mi = pd.MultiIndex.fromproduct([['i'], ['ii'], ['iii']])\r\n\r\nIn [3]: mi.rename([1,5,6]).getlevelvalues(1) # Interpreted as label\r\nOut[3]: Index(['i'], dtype='object', name=1)\r\n\r\nIn [4]: mi.rename([1,5,1]).getlevelvalues(1) # Interpreted as index\r\nOut[4]: Index(['ii'], dtype='object', name=5)\r\n\r\nIn [5]: mi.rename(['a',5,'a']).getlevelvalues('a') # ValueError is OK, KeyError is not\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n/home/nobackup/repo/pandas/pandas/core/indexes/multi.py in getlevelnumber(self, level)\r\n    670                 raise ValueError('The name %s occurs multiple times, use a '\r\n--> 671                                  'level number' % level)\r\n    672             level = self.names.index(level)\r\n\r\nValueError: The name a occurs multiple times, use a level number\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nKeyError                                  Traceback (most recent call last)\r\n<ipython-input-5-e8a616f9610f> in <module>()\r\n----> 1 mi.rename(['a',5,'a']).getlevelvalues('a')\r\n\r\n/home/nobackup/repo/pandas/pandas/core/indexes/multi.py in getlevelvalues(self, level)\r\n    975         Index(['d', 'e', 'f'], dtype='object', name='level2')\r\n    976         \"\"\"\r\n--> 977         level = self.getlevelnumber(level)\r\n    978         values = self.getlevelvalues(level)\r\n    979         return values\r\n\r\n/home/nobackup/repo/pandas/pandas/core/indexes/multi.py in getlevelnumber(self, level)\r\n    673         except ValueError:\r\n    674             if not isinstance(level, int):\r\n--> 675                 raise KeyError('Level %s not found' % str(level))\r\n    676             elif level < 0:\r\n    677                 level += self.nlevels\r\n\r\nKeyError: 'Level a not found'\r\n\r\nIn [6]: mi.rename([1, 'a', 'a']).getlevelvalues(1) # How am I going to access the second level?!\r\nOut[6]: Index(['i'], dtype='object', name=1)\r\n\r\n```\r\n\r\n#### Problem description\r\n\r\nThere are different problems, but the root cause is (I think) the same:\r\n1. the first is trivial: the ``KeyError`` in ``In [5]:`` should not appear\r\n2. the second is that the interpretation of an integer changes when there is a duplicate name (difference between ``Out[3]`` and ``Out[4]``)\r\n3. the third is that in a situation like ``In [6]``, I have no way whatsoever to access the second column, since it is denoted by a duplicated name and its index is also the name of another column (sure, this is a perverse example, but I suspect it can bite in some cases in which users use duplicate labels and pandas internal code adds integer labels)\r\n\r\n\r\n#### Expected Output\r\n\r\nIf we were to design this from scratch, the solution would be simple: prioritize the \"index\" interpretation of an integer over the \"label\" interpretation, so that the former is always unambiguous. Is this a too strong API change?\r\n\r\nIf the answer is \"no\", I will be happy to implement it, possibly with a temporary warning in those cases where the behaviour will change (that is: requested label is integer and is present in the names).\r\n\r\nIf the answer is \"yes\", I would like to at least suppress the ``KeyError`` in ``In [5]:`` and have ``In [4]:`` raise an error rather than return a result inconsistent with ``In [3]:``.\r\n\r\n#### Output of ``pd.showversions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: 04db779d4c93d286bb0ab87780a85d50ec490266\r\npython: 3.5.3.final.0\r\npython-bits: 64\r\nOS: Linux\r\nOS-release: 4.9.0-4-amd64\r\nmachine: x8664\r\nprocessor: \r\nbyteorder: little\r\nLCALL: None\r\nLANG: itIT.UTF-8\r\nLOCALE: itIT.UTF-8\r\n\r\npandas: 0.22.0.dev0+388.g04db779d4\r\npytest: 3.2.3\r\npip: 9.0.1\r\nsetuptools: 36.7.0\r\nCython: 0.25.2\r\nnumpy: 1.12.1\r\nscipy: 0.19.0\r\npyarrow: None\r\nxarray: None\r\nIPython: 6.2.1\r\nsphinx: 1.5.6\r\npatsy: 0.4.1\r\ndateutil: 2.6.1\r\npytz: 2017.2\r\nblosc: None\r\nbottleneck: 1.2.0dev\r\ntables: 3.3.0\r\nnumexpr: 2.6.1\r\nfeather: 0.3.1\r\nmatplotlib: 2.0.0\r\nopenpyxl: 2.3.0\r\nxlrd: 1.0.0\r\nxlwt: 1.3.0\r\nxlsxwriter: 0.9.6\r\nlxml: 4.1.1\r\nbs4: 4.5.3\r\nhtml5lib: 0.999999999\r\nsqlalchemy: 1.0.15\r\npymysql: None\r\npsycopg2: None\r\njinja2: 2.10\r\ns3fs: None\r\nfastparquet: None\r\npandasgbq: None\r\npandasdatareader: 0.2.1\r\n\r\n\r\n</details>\r\n"},
{"text": "#### Code Sample, a copy-pastable example if possible\r\n\r\n```\r\nIn [1]: import pandas\r\n\r\nIn [2]: idx = pandas.Index(['a', 'b', 'c'])\r\n\r\nIn [3]: idx\r\nOut[3]: Index(['a', 'b', 'c'], dtype='object')\r\n\r\nIn [4]: idx.astype('category')\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-4-b8d97d97d03f> in <module>()\r\n----> 1 idx.astype('category')\r\n\r\nC:\\...\\pandas\\indexes\\base.py in astype(self, dtype, copy)\r\n    889     @Appender(indexshareddocs['astype'])\r\n    890     def astype(self, dtype, copy=True):\r\n--> 891         return Index(self.values.astype(dtype, copy=copy), name=self.name,\r\n    892                      dtype=dtype)\r\n    893\r\n\r\nTypeError: data type \"category\" not understood\r\n```\r\n\r\n#### Problem description\r\n\r\nThe documentation for this method reads:\r\n\r\n> Create an Index with values cast to dtypes. The class of a new Index is determined by dtype.\r\n\r\nSince there is a CategoricalIndex type, it is reasonable for a user to expect that `.astype('category')` would return a CategoricalIndex object.\r\n\r\nAs a workaround for the issue, users can construct a CategoricalIndex directly:\r\n\r\n```\r\nIn [7]: pandas.CategoricalIndex(idx)\r\nOut[7]: CategoricalIndex(['a', 'b', 'c'], categories=['a', 'b', 'c'], ordered=False, dtype='category')\r\n```\r\n\r\n#### Expected Output\r\n\r\nThe method should return a CategoricalIndex equal to the following:\r\n```\r\nIn [5]: pandas.CategoricalIndex(['a', 'b', 'c'])\r\nOut[5]: CategoricalIndex(['a', 'b', 'c'], categories=['a', 'b', 'c'], ordered=False, dtype='category')\r\n```\r\n\r\n#### Output of ``pd.showversions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.4.5.final.0\r\npython-bits: 64\r\nOS: Windows\r\nOS-release: 7\r\nmachine: AMD64\r\nprocessor: Intel64 Family 6 Model 79 Stepping 1, GenuineIntel\r\nbyteorder: little\r\nLCALL: None\r\nLANG: enUS.UTF-8\r\nLOCALE: None.None\r\n\r\npandas: 0.19.1\r\nnose: 1.3.7\r\npip: 9.0.1\r\nsetuptools: 27.2.0\r\nCython: 0.24.1\r\nnumpy: 1.11.2\r\nscipy: 0.18.1\r\nstatsmodels: 0.6.1\r\nxarray: 0.8.2\r\nIPython: 5.1.0\r\nsphinx: 1.4.8\r\npatsy: 0.4.1\r\ndateutil: 2.6.0\r\npytz: 2016.7\r\nblosc: 1.5.0\r\nbottleneck: 1.2.0\r\ntables: 3.2.2\r\nnumexpr: 2.6.1\r\nmatplotlib: 2.0.0\r\nopenpyxl: 2.4.0\r\nxlrd: 1.0.0\r\nxlwt: 1.1.2\r\nxlsxwriter: 0.9.3\r\nlxml: 3.6.4\r\nbs4: 4.5.3\r\nhtml5lib: 0.999\r\nhttplib2: 0.9.2\r\napiclient: None\r\nsqlalchemy: 1.1.3\r\npymysql: None\r\npsycopg2: 2.6.2 (dt dec pq3 ext lo64)\r\njinja2: 2.8\r\nboto: 2.43.0\r\npandasdatareader: None\r\n\r\n</details>\r\n"},
{"text": "Possible API breakage for dask in https://github.com/pandas-dev/pandas/pull/16821\r\n\r\n```python\r\nimport dask.dataframe as dd\r\nimport pandas as pd\r\n\r\nfrom dask.dataframe.utils import asserteq\r\n\r\n\r\ns = dd.core.Scalar({('s', 0): 10}, 's', 'i8')\r\npdf = pd.DataFrame({'a': [1, 2, 3, 4, 5, 6, 7],\r\n                    'b': [7, 6, 5, 4, 3, 2, 1]})\r\nresult = (pdf + s).dtypes  # This now casts to object, used to retain int64\r\nexpected = pdf.dtypes\r\nasserteq(result, expected)\r\n```\r\n\r\nIn master, `result` is now `(object, object)`. Before it was `(int64, int64)`.\r\n\r\nI'm looking into #16821 to see if this was unintentional, and can be avoided."},
{"text": "#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\nreader = pd.readhdf(filename, 'foo', chunksize=1000)\r\nnext(reader)\r\n```\r\n```python\r\nTypeError: 'TableIterator' object is not an iterator\r\n```\r\n#### Problem description\r\n\r\nUnless I'm missing something, I would expect something called `TableIterator` to be (itself) an iterator. Since this is an analog of `df.readcsv()`, I would expect it to behave along the same lines (which is `TextFileReader` and works with `next()`). \r\n\r\n`reader.iter()` is defined, so `for chunk in reader` works. It's just slightly surprising that `TextFileReader` defines `next()`, but TableIterator does not. \r\n\r\n#### Expected Output\r\n`next(reader)` should give the dataframe corresponding to that chunk.\r\n\r\n(yes I know Iterators and Iterables are slightly different, but in this case I would expect both to be supported)\r\n\r\n#### Output of ``pd.showversions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.5.2.final.0\r\npython-bits: 64\r\nOS: Linux\r\nOS-release: 4.4.0-79-generic\r\nmachine: x8664\r\nprocessor: x8664\r\nbyteorder: little\r\nLCALL: None\r\nLANG: enUS.UTF-8\r\nLOCALE: enUS.UTF-8\r\n\r\npandas: 0.19.2\r\nnose: None\r\npip: 9.0.1\r\nsetuptools: 36.0.1\r\nCython: None\r\nnumpy: 1.12.1\r\nscipy: 0.19.0\r\nstatsmodels: None\r\nxarray: None\r\nIPython: 6.1.0\r\nsphinx: None\r\npatsy: None\r\ndateutil: 2.6.0\r\npytz: 2016.10\r\nblosc: None\r\nbottleneck: None\r\ntables: 3.4.2\r\nnumexpr: 2.6.2\r\nmatplotlib: 2.0.0\r\nopenpyxl: None\r\nxlrd: None\r\nxlwt: None\r\nxlsxwriter: None\r\nlxml: None\r\nbs4: 4.5.3\r\nhtml5lib: 0.999999999\r\nhttplib2: None\r\napiclient: None\r\nsqlalchemy: None\r\npymysql: None\r\npsycopg2: None\r\njinja2: 2.9.6\r\nboto: None\r\npandasdatareader: None\r\n\r\n</details>\r\n"},
{"text": "```python\r\nIn [3]: df1 = pd.DataFrame(np.random.randint(0,10,(4,3)), columns=['a','b','c'])\r\n\r\nIn [4]: df1\r\nOut[4]: \r\n   a  b  c\r\n0  9  3  2\r\n1  9  0  2\r\n2  7  7  6\r\n3  3  4  2\r\n\r\nIn [5]: df2 = df1.reindex(columns=['c','a','d'])\r\n\r\nIn [6]: df2\r\nOut[6]: \r\n   c  a   d\r\n0  2  9 NaN\r\n1  2  9 NaN\r\n2  6  7 NaN\r\n3  2  3 NaN\r\n\r\nIn [7]: df2.columns\r\nOut[7]: Index([u'c', u'a', u'd'], dtype='object')\r\n\r\nIn [8]: ci = pd.MultiIndex.fromproduct([['x','y'],['a','b','c']])\r\n\r\nIn [10]: df3 = pd.DataFrame(np.random.randint(0,10,(4,6)), columns=ci)\r\n\r\nIn [11]: df3\r\nOut[11]: \r\n   x        y      \r\n   a  b  c  a  b  c\r\n0  3  1  5  3  8  7\r\n1  2  7  6  8  7  4\r\n2  8  3  5  7  1  1\r\n3  7  5  8  7  8  7\r\n\r\nIn [12]: df4 = df3.reindex(columns=['c','a','d'], level=1)\r\n\r\nIn [13]: df4\r\nOut[13]: \r\n   x     y   \r\n   c  a  c  a\r\n0  5  3  7  3\r\n1  6  2  4  8\r\n2  5  8  1  7\r\n3  8  7  7  7\r\n\r\nIn [14]: df4.columns\r\nOut[14]: \r\nMultiIndex(levels=[[u'x', u'y'], [u'c', u'a', u'd']],\r\n           labels=[[0, 0, 1, 1], [0, 1, 0, 1]])\r\n```\r\n\r\nWhen passing a nonexistent column name to `reindex` on a dataframe without multiindex columns, the result is:\r\n- a `NaN` column with the \"new\" column name\r\n- the `columns` attribute matches the columns in the dataframe\r\n\r\nThe same action on a multiindex dataframe produces different results:\r\n- there are no `NaN` columns (this may not be a problem)\r\n- the `columns` attribute of the resulting dataframe does not match the dateframe column names  (this appears to be a bug)\r\n\r\n<details>\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 2.7.12.final.0\r\npython-bits: 64\r\nOS: Darwin\r\nOS-release: 16.3.0\r\nmachine: x8664\r\nprocessor: i386\r\nbyteorder: little\r\nLCALL: None\r\nLANG: enUS.UTF-8\r\nLOCALE: None.None\r\n\r\npandas: 0.19.1\r\nnose: 1.3.7\r\npip: 9.0.1\r\nsetuptools: 27.2.0\r\nCython: 0.25.1\r\nnumpy: 1.11.2\r\nscipy: 0.18.1\r\nstatsmodels: 0.6.1\r\nxarray: None\r\nIPython: 5.1.0\r\nsphinx: 1.4.8\r\npatsy: 0.4.1\r\ndateutil: 2.6.0\r\npytz: 2016.7\r\nblosc: None\r\nbottleneck: 1.1.0\r\ntables: 3.3.0\r\nnumexpr: 2.6.1\r\nmatplotlib: 1.5.3\r\nopenpyxl: 2.4.0\r\nxlrd: 1.0.0\r\nxlwt: 1.1.2\r\nxlsxwriter: 0.9.3\r\nlxml: 3.6.4\r\nbs4: 4.5.1\r\nhtml5lib: None\r\nhttplib2: None\r\napiclient: None\r\nsqlalchemy: 1.1.4\r\npymysql: None\r\npsycopg2: 2.6.2 (dt dec pq3 ext lo64)\r\njinja2: 2.8\r\nboto: 2.43.0\r\npandasdatareader: None\r\n\r\n</details>\r\n"},
{"text": "xref #14145  (reviving this PR and superceding)\r\nxref #15533\r\n \r\nSo when we fill (either via fillna, where, or using setitem) we are inconsistent in handling what we do when we have a non-compat type (note have not exhaustively tested other methods, I suspect these pretty much coerce to ``object``, except for ``.where``). The classic example is trying to fill with a tz-aware in tz-naive.\r\n\r\nFor current pandas (ex-pandas2), we generally upcast to ``object``. This is the case for setitem and fillna, but NOT for ``.where``, where we raise. We DO have a parameter to control this ``raiseonerror=True``, and it works for ``.where`` (though not for ``.fillna``).\r\n\r\n```\r\nIn [1]: s = Series([Timestamp('20130101'), pd.NaT])\r\n\r\nIn [2]: s\r\nOut[2]: \r\n0   2013-01-01\r\n1          NaT\r\ndtype: datetime64[ns]\r\n\r\n# this is wrong\r\nIn [3]: s.fillna(Timestamp('20130101', tz='US/Eastern'))\r\nOut[3]: \r\n0   2012-12-31 19:00:00-05:00\r\n1   2013-01-01 00:00:00-05:00\r\ndtype: datetime64[ns, US/Eastern]\r\n\r\n# current behavior\r\nIn [4]: s.fillna('foo')\r\nOut[4]: \r\n0    2013-01-01 00:00:00\r\n1                    foo\r\ndtype: object\r\n\r\nIn [5]: s[1] = 'bar'\r\n\r\nIn [6]: s\r\nOut[6]: \r\n0    2013-01-01 00:00:00\r\n1                    bar\r\ndtype: object\r\n\r\nIn [8]: s = Series([Timestamp('20130101'), pd.NaT])\r\n\r\n# this is inconsistent with fillna\r\nIn [9]: s.where([True, False], Timestamp('20130101',tz='US/Eastern'), raiseonerror=False)\r\nOut[9]: \r\n0          2013-01-01 00:00:00\r\n1    2013-01-01 00:00:00-05:00\r\ndtype: object\r\n\r\nIn [10]: s.where([True, False], Timestamp('20130101',tz='US/Eastern'), raiseonerror=True)\r\nTypeError: Could not operate [Timestamp('2013-01-01 00:00:00-0500', tz='US/Eastern')] with block values [cannot coerce a Timestamp with a tz on a naive Block]\r\n```\r\n\r\nSo I think its reasonable to make these *all* raise, though that would be a pretty big API change. We are going to do this for pandas2 anyhow. Would be beneficial to not be so strict like this.\r\n\r\nAlternatively we can fix ``.where`` to by default upcast to ``object``.\r\n\r\nthoughts?\r\n\r\ncc @wesm @shoyer @TomAugspurger @jorisvandenbossche @sinhrks @cpcloud \r\n@ResidentMario "},
{"text": "#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\ndfMain = pd.DataFrame({\r\n    'a': [0, 1, np.NAN, 3, 4],\r\n    'b': [np.NaN, np.NaN, np.NaN, 3, 4],\r\n    'c': [0 , 1, 2, 3, np.NaN]})\r\n\r\nfor col in dfMain:\r\n    start = dfMain[col].firstvalidindex()\r\n    end = dfMain[col].lastvalidindex()\r\n    dfMain.loc[start:end, col] = dfMain.loc[start:end, col].interpolate()\r\n\r\nprint(dfMain)\r\n```\r\n\r\n#### Problem description\r\nIt would be very nice to have a limitdirection='inside' that would make interpolate only fill values that are surrounded (both in front and behind) with valid values.\r\n\r\nThis would allow an interpolate to only fill missing values in a series and **not extend** the series beyond its original limits.  The key here is that it is sometimes important to maintain the original range of a series, but still fill in the gaps.\r\n\r\nThe example shows a simple DataFrame with an 'inside' interpolation.\r\n\r\n#### Expected Output\r\n\r\n```python\r\n     a    b    c\r\n0  0.0  NaN  0.0\r\n1  1.0  NaN  1.0\r\n2  2.0  NaN  2.0\r\n3  3.0  3.0  3.0\r\n4  4.0  4.0  NaN\r\n```\r\n#### Output of ``pd.showversions()``\r\n\r\n<details>\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.6.0.final.0\r\npython-bits: 64\r\nOS: Linux\r\nOS-release: 4.4.0-75-generic\r\nmachine: x8664\r\nprocessor: x8664\r\nbyteorder: little\r\nLCALL: None\r\nLANG: enUS.UTF-8\r\nLOCALE: enUS.UTF-8\r\n\r\npandas: 0.19.2\r\nnose: 1.3.7\r\npip: 9.0.1\r\nsetuptools: 34.4.1\r\nCython: 0.25.2\r\nnumpy: 1.12.1\r\nscipy: 0.18.1\r\nstatsmodels: 0.6.1\r\nxarray: None\r\nIPython: 5.1.0\r\nsphinx: 1.5.1\r\npatsy: 0.4.1\r\ndateutil: 2.6.0\r\npytz: 2016.10\r\nblosc: None\r\nbottleneck: 1.2.0\r\ntables: 3.3.0\r\nnumexpr: 2.6.1\r\nmatplotlib: 2.0.0\r\nopenpyxl: 2.4.1\r\nxlrd: 1.0.0\r\nxlwt: 1.2.0\r\nxlsxwriter: 0.9.6\r\nlxml: 3.7.2\r\nbs4: 4.5.3\r\nhtml5lib: None\r\nhttplib2: None\r\napiclient: None\r\nsqlalchemy: 1.1.5\r\npymysql: None\r\npsycopg2: None\r\njinja2: 2.9.4\r\nboto: 2.45.0\r\npandasdatareader: 0.2.1\r\nNone\r\n\r\n\r\n</details>\r\n"},
{"text": "```\r\nIn [1]: pd.api.types.inferdtype([2*63, -1])\r\nOut[1]: 'integer'\r\n\r\nIn [3]: pd.api.types.inferdtype([2*63])\r\nOut[3]: 'integer'\r\n```\r\n[1] should be 'mixed' (inference which means object)\r\n[2] should be 'uinteger'\r\n\r\nnote this will probably break some things in other parts of the suite as we sometimes infer to figure out the dtype and act on it, so 'uinteger' would then be unhandled.\r\n\r\ne.g. in Index creation and https://github.com/pandas-dev/pandas/pull/16108/files\r\nxref https://github.com/pandas-dev/pandas/pull/16295/files"},
{"text": "\r\n```python\r\nSeries(['a', 'b', 'c']).str.cat(['A', np.NaN, 'C'], sep=',')\r\n\r\n0    a,A\r\n1    NaN\r\n2    c,C\r\ndtype: object\r\n\r\n```\r\n#### Problem description\r\n\r\nI was expecting NaN to be skipped and just get \"b\" in the second line. \r\n\r\nWhen using narep it does something like this.\r\n\r\n```python\r\nSeries(['a', 'b', 'c']).str.cat(['A', np.NaN, 'C'], sep=',', narep='X')\r\n\r\n0    a,A\r\n1    b,X\r\n2    c,C\r\ndtype: object\r\n```\r\n\r\nI feel this behavior is inconsistent. \r\n\r\nI can see that if you are expecting to get output that could be used like a record/csv current behavior would help. Perhaps this could work as a parameter.\r\n\r\n#### Expected Output\r\n\r\n```python\r\n0    a,A\r\n1    b\r\n2    c,C\r\ndtype: object\r\n```\r\n\r\n#### Output of ``pd.showversions()``\r\n\r\n<details>\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.4.3.final.0\r\npython-bits: 64\r\nOS: Linux\r\nOS-release: 4.4.0-59-generic\r\nmachine: x8664\r\nprocessor: x8664\r\nbyteorder: little\r\nLCALL: None\r\nLANG: enUS.UTF-8\r\nLOCALE: enUS.UTF-8\r\n\r\npandas: 0.19.2\r\nnose: None\r\npip: 8.1.2\r\nsetuptools: 28.2.0\r\nCython: None\r\nnumpy: 1.11.1\r\nscipy: None\r\nstatsmodels: None\r\nxarray: None\r\nIPython: 4.2.0\r\nsphinx: 1.3.1\r\npatsy: None\r\ndateutil: 2.4.2\r\npytz: 2016.4\r\nblosc: None\r\nbottleneck: None\r\ntables: None\r\nnumexpr: None\r\nmatplotlib: None\r\nopenpyxl: None\r\nxlrd: 1.0.0\r\nxlwt: 1.1.1\r\nxlsxwriter: 0.9.6\r\nlxml: None\r\nbs4: None\r\nhtml5lib: 0.999999999\r\nhttplib2: None\r\napiclient: None\r\nsqlalchemy: 1.0.13\r\npymysql: None\r\npsycopg2: 2.6.2 (dt dec pq3 ext lo64)\r\njinja2: 2.9.6\r\nboto: None\r\npandasdatareader: None\r\n\r\n</details>\r\n"},
{"text": "#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\ndf = pd.DataFrame({'a':np.random.random(10),'b':np.random.random(10)})\r\ndf\r\ndf.renameaxis('numbers', inplace=True)\r\ndf\r\n```\r\n#### Problem description\r\n\r\ndf.renameaxis with the inplace=True should return None and make the named axis change the index name in the original object.  However, up listing df again, no index name is present.\r\n\r\n#### Expected Output\r\ndf.index.name should return 'numbers'\r\n#### Output of ``pd.showversions()``\r\n\r\n\r\n<details>\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.5.2.final.0\r\npython-bits: 64\r\nOS: Linux\r\nOS-release: 4.4.0-66-generic\r\nmachine: x8664\r\nprocessor: x8664\r\nbyteorder: little\r\nLCALL: None\r\nLANG: enUS.UTF-8\r\n\r\npandas: 0.18.1\r\nnose: 1.3.7\r\npip: 9.0.1\r\nsetuptools: 27.2.0\r\nCython: 0.24.1\r\nnumpy: 1.11.1\r\nscipy: 0.18.1\r\nstatsmodels: 0.6.1\r\nxarray: None\r\nIPython: 5.1.0\r\nsphinx: 1.4.6\r\npatsy: 0.4.1\r\ndateutil: 2.5.3\r\npytz: 2016.6.1\r\nblosc: None\r\nbottleneck: 1.1.0\r\ntables: 3.2.3.1\r\nnumexpr: 2.6.1\r\nmatplotlib: 1.5.3\r\nopenpyxl: 2.3.2\r\nxlrd: 1.0.0\r\nxlwt: 1.1.2\r\nxlsxwriter: 0.9.3\r\nlxml: 3.6.4\r\nbs4: 4.5.1\r\nhtml5lib: 0.999999999\r\nhttplib2: None\r\napiclient: None\r\nsqlalchemy: 1.0.13\r\npymysql: None\r\npsycopg2: None\r\njinja2: 2.8\r\nboto: 2.42.0\r\npandasdatareader: 0.3.0.post\r\n\r\n</details>\r\n"},
{"text": "\r\n```python\r\n# Your code here\r\n\r\ntdf.rolling( '10D' ).mean()\r\n```\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-49-707b0ff61efc> in <module>()\r\n     10 tdf = df.groupby(level=1).getgroup( 64413 )\r\n     11 \r\n---> 12 tdf.rolling( '10D' ).mean()\r\n     13 \r\n     14 tdf.resetindex().setindex('time').rolling( '10D' ).mean()\r\n\r\n/home/firdaus/.conda/envs/tsconda/lib/python3.5/site-packages/pandas/core/generic.py in rolling(self, window, minperiods, freq, center, wintype, on, axis)\r\n   5502                                    minperiods=minperiods, freq=freq,\r\n   5503                                    center=center, wintype=wintype,\r\n-> 5504                                    on=on, axis=axis)\r\n   5505 \r\n   5506         cls.rolling = rolling\r\n\r\n/home/firdaus/.conda/envs/tsconda/lib/python3.5/site-packages/pandas/core/window.py in rolling(obj, wintype, **kwds)\r\n   1797         return Window(obj, wintype=wintype, **kwds)\r\n   1798 \r\n-> 1799     return Rolling(obj, **kwds)\r\n   1800 \r\n   1801 \r\n\r\n/home/firdaus/.conda/envs/tsconda/lib/python3.5/site-packages/pandas/core/window.py in init(self, obj, window, minperiods, freq, center, wintype, axis, on, **kwargs)\r\n     76         self.wintype = wintype\r\n     77         self.axis = obj.getaxisnumber(axis) if axis is not None else None\r\n---> 78         self.validate()\r\n     79 \r\n     80     @property\r\n\r\n/home/firdaus/.conda/envs/tsconda/lib/python3.5/site-packages/pandas/core/window.py in validate(self)\r\n   1055 \r\n   1056         elif not isinteger(self.window):\r\n-> 1057             raise ValueError(\"window must be an integer\")\r\n   1058         elif self.window < 0:\r\n   1059             raise ValueError(\"window must be non-negative\")\r\n\r\nValueError: window must be an integer\r\n```\r\n\r\n\r\n#### Problem description\r\n\r\nThe offset feature of specifying timelike windows in 'rolling' doesn't work if the dataframe has multindex with level0 = 'time' and level1 = something else.\r\n\r\n\r\n#### Expected Output\r\n``` python\r\ntdf.resetindex().setindex('time').rolling( '10D' ).mean()\r\n```\r\nWorks correctly.\r\n\r\n#### Output of ``pd.showversions()``\r\n\r\n<details>\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.5.2.final.0\r\npython-bits: 64\r\nOS: Linux\r\nOS-release: 3.16.0-0.bpo.4-amd64\r\nmachine: x8664\r\nprocessor: \r\nbyteorder: little\r\nLCALL: None\r\nLANG: enUS.UTF-8\r\nLOCALE: enUS.UTF-8\r\n\r\npandas: 0.19.2.post+ts3\r\nnose: None\r\npip: 9.0.1\r\nsetuptools: 27.2.0\r\nCython: 0.25.2\r\nnumpy: 1.11.3\r\nscipy: 0.18.1\r\nstatsmodels: 0.6.1\r\nxarray: None\r\nIPython: 5.1.0\r\nsphinx: 1.5.1\r\npatsy: 0.4.1\r\ndateutil: 2.6.0\r\npytz: 2016.10\r\nblosc: None\r\nbottleneck: 1.2.0\r\ntables: 3.3.0\r\nnumexpr: 2.6.1\r\nmatplotlib: 1.5.3\r\nopenpyxl: 2.4.0\r\nxlrd: 1.0.0\r\nxlwt: None\r\nxlsxwriter: 0.9.6\r\nlxml: None\r\nbs4: 4.5.3\r\nhtml5lib: None\r\nhttplib2: None\r\napiclient: None\r\nsqlalchemy: 1.1.4\r\npymysql: None\r\npsycopg2: None\r\njinja2: 2.9.4\r\nboto: None\r\npandasdatareader: None\r\n</details>\r\n"},
{"text": "#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\n# Your code here\r\ndf1 = pd.DataFrame({'a': [0, 10, 20]})\r\ndf2 = pd.DataFrame({'b': [200, 100]}, index=[2,1])\r\n\r\nprint(df1.join(df2, how='inner'))\r\nprint(df2.join(df1, how='inner'))\r\n\r\nprint(df1.join(df2, how='inner', sort=True))\r\n```\r\n#### Problem description\r\n\r\nContrary to what is stated in the documentation of DataFrame.join(), when using the default sort=False, the return DataFrame preserves the index order of the other (right) DataFrame, instead of the index order of the calling (left) DataFrame.\r\n\r\nBesides, the sort=True argument does not work.\r\n\r\n#### Expected Output\r\nThe expected output is that the return DataFrame should preserve the index order of the calling (left) DataFrame.\r\n\r\n#### Output of ``pd.showversions()``\r\n\r\n<details>\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.5.2.final.0\r\npython-bits: 64\r\nOS: Linux\r\nOS-release: 3.13.0-108-generic\r\nmachine: x8664\r\nprocessor: x8664\r\nbyteorder: little\r\nLCALL: None\r\nLANG: caES.UTF-8\r\nLOCALE: caES.UTF-8\r\n\r\npandas: 0.19.2\r\nnose: 1.3.7\r\npip: 8.1.2\r\nsetuptools: 27.2.0.post20161106\r\nCython: 0.24.1\r\nnumpy: 1.11.1\r\nscipy: 0.18.1\r\nstatsmodels: 0.6.1\r\nxarray: None\r\nIPython: 5.1.0\r\nsphinx: 1.4.6\r\npatsy: 0.4.1\r\ndateutil: 2.5.3\r\npytz: 2016.6.1\r\nblosc: None\r\nbottleneck: 1.1.0\r\ntables: 3.2.3.1\r\nnumexpr: 2.6.1\r\nmatplotlib: 1.5.3\r\nopenpyxl: 2.3.2\r\nxlrd: 1.0.0\r\nxlwt: 1.1.2\r\nxlsxwriter: 0.9.3\r\nlxml: 3.6.4\r\nbs4: 4.5.1\r\nhtml5lib: None\r\nhttplib2: None\r\napiclient: None\r\nsqlalchemy: 1.0.13\r\npymysql: None\r\npsycopg2: None\r\njinja2: 2.8\r\nboto: 2.42.0\r\npandasdatareader: 0.2.1\r\n</details>\r\n"},
{"text": "### Preconditions\r\nmagento 2.4-develop\r\n\r\nThe devdocs clearly state that authenticated admin users can access the rest api.\r\n\r\nhttp://devdocs.magento.com/guides/v2.0/get-started/authentication/gs-authentication.html\r\n\r\n> Resources for which administrators or integrators are authorized. For example, if administrators are authorized for the MagentoCustomer::group resource, they can make a GET /V1/customerGroups/:id call.\r\n\r\nBut this does not work. \r\n\r\n\r\n### Steps to reproduce\r\n1.  Install magento 2.1.5 from composer archive\r\n2. Log into you new admin account\r\n3. Open domain.com/rest/V1/customers/1 in the same browser in a new tab.\r\n\r\n### Expected result\r\nA response saying that this customer does not exist.\r\n\r\n### Actual result\r\nA response saying me I have no acccess rights.\r\n\r\n`<response>\r\n   <message>Consumer is not authorized to access %resources</message>\r\n    <parameters>\r\n      <resources>MagentoCustomer::customer</resources>\r\n    </parameters>\r\n</response>`\r\n"},
{"text": "### Preconditions\r\n1. Magento 2.2.2 CE, php 7.1.\r\n\r\n### Steps to reproduce\r\n1. `GET` to API `/customers/search` with parameters.\r\n```json\r\n\"searchcriteria\": {\r\n    \"filtergroups\": [\r\n        {\r\n            \"filters\": [\r\n                {\r\n                    \"field\": \"company\",\r\n                    \"value\": \"%%\",\r\n                    \"conditiontype\": \"like\"\r\n                },\r\n                {\r\n                    \"field\": \"companyname\",\r\n                    \"value\": \"%%\",\r\n                    \"conditiontype\": \"like\"\r\n                }\r\n            ]\r\n        }\r\n    ]\r\n}\r\n```\r\n\r\n`company` is default magento attribute in customer address,` companyname` I created for customer entity.\r\n\r\nUsing the m2 [documentation](http://devdocs.magento.com/guides/v2.2/rest/performing-searches.html)\r\n### Expected result\r\nSearch where `company` like `%%` OR `companyname` like `%%`.\r\n\r\n### Actual result\r\nEmpty result. I noticed magento require filled `companyname` in customers. If I add any string in my custom field, magento returns this row without a problems even if the condition is not correct for this part of rule (expected result)."},
{"text": "### Preconditions\r\n1. Magento Version 2.4\r\n2. Set up and activated API Integration with full access\r\n\r\n### Steps to reproduce\r\n1. Create integrations\r\n2. Make POST call to `/oauth/token/request`\r\n\r\n### Expected result\r\n1. Get request token\r\n\r\n### Actual result\r\n1. oauthproblem=Consumer+key+has+expired\r\n\r\n![image](https://user-images.githubusercontent.com/15145911/36991851-fd4c4cb6-2076-11e8-8263-2a50d0fa1922.png)\r\n\r\nI tried it with two different integrations, both are activated, and both return the same response of \"consumer key has expired\""},
{"text": "### Preconditions\r\n1. Magento 2.2.3\r\n\r\n### Steps to reproduce\r\nI am following the [API documentation](http://devdocs.magento.com/swagger/index.html) to create guest cart and add item to it:\r\n1.  `POST https://yourdomain/rest/default/V1/guest-carts` (with empty body) creates cart for you and return **cartId** in body\r\n2.  `GET https://yourdomain/rest/default/V1/guest-carts/`**`:cartId`** to check you cart is created\r\n3. `POST https://yourdomain/rest/default/V1/guest-carts/`**`:cartId`**`/items` with body\r\n\r\n```\r\n{\r\n  \"cartItem\": {\r\n    \"sku\": \"WS12-M-Orange\",\r\n    \"qty\": 3\r\n  }\r\n}\r\n```\r\nto add item to your cart, but error is returned instead of adding cart to item\r\n\r\n### Expected result\r\nIn step 3, I was expecting the added item to be returned. Instead of that, error is returned.\r\n\r\n### Actual result\r\n```\r\n{\r\n    \"message\": \"No such entity with %fieldName = %fieldValue\",\r\n    \"parameters\": {\r\n        \"fieldName\": \"cartId\",\r\n        \"fieldValue\": null\r\n    },\r\n    \"trace\": \"...\"\r\n}\r\n```\r\n\r\n### Further research\r\nI discovered: If you send the **cartId** in `quoteid` field in body at step 3, the method would work. So the body would be:\r\n```\r\n{\r\n  \"cartItem\": {\r\n    \"sku\": \"WS12-M-Orange\",\r\n    \"qty\": 3,\r\n    \"quoteid\": \":cartId\"\r\n  }\r\n}\r\n```\r\nAnd the results is cart item, no error. The **cartId** in url is completly ignored. If you use send request with some dummy string instead of cartId in URL (with the body with quoteid field), it actually works.\r\n\r\nSo request like\r\n`POST https://yourdomain/rest/default/V1/guest-carts/somedummystringinseteadofcartId/items`\r\nworks. But it should not! And the mandatory quoteid in body is also wrong I think. The only cartId needed to add the item to the cart should be the one from URL (which is not used at all at the moment).\r\n\r\n**The same problem is present on other methods in guest-cart.**"},
{"text": "### Preconditions\r\n1. Tested in CE 2.3\r\n\r\n### Steps to reproduce\r\nFresh install\r\nCreate product (of any type) with SKU containing /, e.g. \"0RJ9548SN-212/W0-54\"\r\n\r\nsearching for the product with\r\nGET : /rest/v1/products?searchCriteria[filtergroups][0][filters][0][field]=sku&searchCriteria[filtergroups][0][filters][0][value]=0RJ9548SN-212%2FW0-54\r\nreturns results as expected\r\n\r\nbut when getting the stockItems with the following\r\nGET : /rest/V1/stockItems/0RJ9548SN-212%2FW0-54\r\nresult 404 status - BUT the actual data is returned?\r\n\r\nwhen trying to update the stockItem\r\nPUT : /rest/V1/products/0RJ9548SN-212%2FW0-54/stockItems/100\r\nresult : 404 status - message=Request does not match any route.\r\n\r\n### Expected result\r\nexpect\r\n/rest/V1/stockItems/[sku containing / to also work]\r\n/rest/V1/products/[sku containing / to also work]/stockItems/[stockItemID]\r\n\r\nboth to work in the same manner as sku without '/'\r\n\r\n### Actual result\r\nGET : /rest/V1/stockItems/0RJ9548SN-212%2FW0-54\r\nresult 404 status - BUT the actual data is returned?\r\n\r\nPUT : /rest/V1/products/0RJ9548SN-212%2FW0-54/stockItems/100\r\nresult : 404 status - message=Request does not match any route.\r\n\r\nsame issue -> https://github.com/magento/magento2/issues/13343\r\n"},
{"text": "<!---\r\n    Thank you for contributing to Magento.\r\n    To help us process this issue we recommend that you add the following information:\r\n     - Summary of the issue,\r\n     - Information on your environment,\r\n     - Steps to reproduce,\r\n     - Expected and actual results,\r\n    Fields marked with (*) are required. Please don't remove the template.\r\n\r\n    Please also have a look at our guidelines article before adding a new issue https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\n-->\r\n\r\n### Preconditions (*)\r\n<!---\r\n    Please provide as detailed information about your environment as possible.\r\n    For example Magento version, tag, HEAD, PHP & MySQL version, etc..\r\n-->\r\n1. Created a custom one page checkout.\r\n2. Placing order for guest users using Rest API Magento 2\r\n3. Magento -v 2.1.3\r\n4. php -v 7.0.4\r\n5. Apache 2.4\r\n6. MySQL 5.7, AWS RDS 16G RAM, 4 core CPU with 1000 IOPS\r\n7. AWS EC2 Ubuntu 16.4 4G RAM 4 core CPU 100G SSD\r\n8. Redis for session and cache\r\n9. Opcache enabled\r\n\r\n\r\n### Steps to reproduce (*)\r\n<!---\r\n    It is important to provide a set of clear steps to reproduce this bug.\r\n    If relevant please include code samples\r\n-->\r\n1. Placing an order using Cash  On Delivery Method.\r\n\r\n### Expected result (*)\r\n<!--- Tell us what should happen -->\r\n1. Since all the optimizations and cache are already done. The Rest API time should be less.\r\n\r\n### Actual result (*)\r\n<!--- Tell us what happens instead -->\r\n1. Place order API taking too much time around 30 sec. to complete. On the other hand, I'm using one more server having the same configurations, But the Place Order API responding less than 3 seconds on that server.\r\n\r\nCan you please help me out to figure out the solution.\r\n\r\n"},
{"text": "<!---\r\nPlease review our guidelines before adding a new issue: https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\nFields marked with (*) are required. Please don't remove the template.\r\n-->\r\n\r\n### Preconditions (*)\r\n<!---\r\nProvide the exact Magento version (example: 2.2.5) and any important information on the environment where bug is reproducible.\r\n-->\r\n1. Magento 2.2.8 CE\r\n\r\n### Steps to reproduce (*)\r\n<!---\r\nImportant: Provide a set of clear steps to reproduce this bug. We can not provide support without clear instructions on how to reproduce.\r\n-->\r\n1. Create Configurable item\r\n2. Create order using the configurable item\r\n3. get order JSON using order API\r\n\r\n### Expected result (*)\r\n<!--- Tell us what do you expect to happen. -->\r\n1. Items node for child item should not show the price ., It should show price 0 as same as 2.2.7 and before.\r\n\r\n### Actual result (*)\r\n<!--- Tell us what happened instead. Include error messages and issues. -->\r\n1. items node for child item showing the only price in \"price\" node. not in \"originalprice\", \"baseprice\", \"baseoriginalprice\", etc.\r\n"},
{"text": "<!---\r\nPlease review our guidelines before adding a new issue: https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\nFields marked with (*) are required. Please don't remove the template.\r\n-->\r\n\r\n### Preconditions (*)\r\n<!---\r\nProvide the exact Magento version (example: 2.2.5) and any important information on the environment where bug is reproducible.\r\n-->\r\n1.Magento 2.3.0\r\n\r\n### Steps to reproduce (*)\r\n<!---\r\nImportant: Provide a set of clear steps to reproduce this bug. We can not provide support without clear instructions on how to reproduce.\r\n-->\r\n1.Create an order without $0 shipping cost\r\n2.Invoice the order\r\n3.Try to refund the invoice using the invoice/{invoiceId}/refund API call with all items at quantity 0 and just a positive adjustment. For example:\r\n{\"items\": [{\"qty\": 0, \"orderItemId\": 6, \"extensionAttributes\": {}}], \"appendComment\": false, \"notify\": true, \"isOnline\": true, \"arguments\": {\"adjustmentnegative\": 0.0, \"adjustmentpositive\": 0.99, \"shippingamount\": 0}}\r\n\r\n### Expected result (*)\r\n<!--- Tell us what do you expect to happen. -->\r\n1. It should refund the invoice just like you can refund it in the admin interface (you can set all quantities to 0 and refund the invoice in the admin interface).\r\n\r\n### Actual result (*)\r\n<!--- Tell us what happened instead. Include error messages and issues. -->\r\n1. The API responds with error \"You can't create a creditmemo without products.\" from the QuantityValidator.\r\n"},
{"text": "I am using magento 2.3 instance. I am developing android app with magento 2 default APIs but I am facing issue with checkout.\r\nAccording to magento 2 default , we don't required billing and shipping information for virtual and downloadable products but when I placing order using magento 2 default API I am getting billing and shipping information required.\r\n\r\nStep to reproduce( Using Magento 2 Rest API)\r\n1. Add downloadable product to cart\r\n2. After add product to cart set payment method\r\n3. Place order \r\n\r\nAfter call place order API getting error Billing information is required with downloadable products.\r\n\r\n\r\nPlease help me to find any solution for this. "},
{"text": "### Preconditions (*)\r\n - Magento CE 2.3.1\r\n\r\n### Steps to reproduce (*)\r\n1. Add a product to Magento using the API:\r\n```\r\n{\r\n\"product\": {\r\n\"sku\": \"test555\",\r\n\"name\": \"test product for video111\",\r\n\"attributesetid\": 9,\r\n\"price\": 342,\r\n\"status\": 1,\r\n\"visibility\": 1,\r\n\"typeid\": \"simple\",\r\n\"weight\": \"0.5\",\r\n\"mediagalleryentries\": [\r\n{\r\n\"mediatype\": \"external-video\",\r\n\"disabled\": false,\r\n\"label\": \"Test Video\",\r\n\"types\": [],\r\n\"content\": {\r\n\"type\": \"image/png\",\r\n\"name\": \"thumbnail.png\",\r\n\"base64encodeddata\": \"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\"\r\n},\r\n\"extensionattributes\": {\r\n\"videocontent\": {\r\n\"mediatype\": \"external-video\",\r\n\"videoprovider\":\"youtube\",\r\n\"videourl\": \"https://www.youtube.com/watch?v=FVFPRstvlvk\",\r\n\"videotitle\": \"Video title\",\r\n\"videodescription\": \"Video description\",\r\n\"videometadata\": \"Video meta\"\r\n}\r\n}\r\n}\r\n]\r\n},\r\n\"saveOptions\": true\r\n}\r\n```\r\n\r\n2. Send Product Video update using PUT to rest/V1/products/{SKU}:\r\n```\r\n{\r\n\"product\": {\r\n\"sku\": \"test555\",\r\n\"name\": \"test product for video111\",\r\n\"attributesetid\": 9,\r\n\"price\": 342,\r\n\"status\": 1,\r\n\"visibility\": 1,\r\n\"typeid\": \"simple\",\r\n\"weight\": \"0.5\",\r\n\"mediagalleryentries\": [\r\n{\r\n\"mediatype\": \"external-video\",\r\n\"disabled\": false,\r\n\"label\": \"Test Video\",\r\n\"types\": [],\r\n\"content\": {\r\n\"type\": \"image/png\",\r\n\"name\": \"thumbnail.png\",\r\n\"base64encodeddata\": \"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\"\r\n},\r\n\"extensionattributes\": {\r\n\"videocontent\": {\r\n\"mediatype\": \"external-video\",\r\n\"videoprovider\":\"youtube\",\r\n\"videourl\": \"https://www.youtube.com/watch?v=FVFPRstvlvk\",\r\n\"videotitle\": \"Video title\",\r\n\"videodescription\": \"Video description\",\r\n\"videometadata\": \"Video meta\"\r\n}\r\n}\r\n}\r\n]\r\n},\r\n\"saveOptions\": true\r\n}\r\n```\r\n\r\n### Expected result (*)\r\n<!--- Tell us what do you expect to happen. -->\r\n1.  Video appears on product view page/In the magento admin\r\n![image](https://user-images.githubusercontent.com/51627977/59190271-313c1880-8b74-11e9-922a-6d186b17999e.png)\r\n\r\n### Actual result (*)\r\n<!--- Tell us what happened instead. Include error messages and issues. -->\r\n1. Thumbnail appears, but video player does not load when play button is clicked.\r\n![image](https://user-images.githubusercontent.com/51627977/59190331-59c41280-8b74-11e9-9398-8978fb768afd.png)\r\n\r\n2. Fields show as empty in Magento admin:\r\n![image](https://user-images.githubusercontent.com/51627977/59190386-81b37600-8b74-11e9-8aae-59a35c7aceb5.png)\r\n\r\n"},
{"text": "<!---\r\nPlease review our guidelines before adding a new issue: https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\nFields marked with (*) are required. Please don't remove the template.\r\n-->\r\n\r\n### Preconditions (*)\r\n<!---\r\nProvide the exact Magento version (example: 2.2.5) and any important information on the environment where bug is reproducible.\r\n-->\r\n1. Magento 2.3.1\r\n\r\n### Steps to reproduce (*)\r\n<!---\r\nImportant: Provide a set of clear steps to reproduce this bug. We can not provide support without clear instructions on how to reproduce.\r\n-->\r\n1. Create a simple code of REST API with `curl` to fetch orders with `updatedat` **searchCriteria** parameter and **fields** parameter.\r\n2. Code as below\r\n\r\n```\r\n$webSiteUrl = 'mydomain.com'\r\n$last1DayUpdated = date('Y-m-d',(strtotime ('-1 day', strtotime(date('Y-m-d')))));\r\n$ch = curlinit(\"{$webSiteUrl}/rest/V1/orders?searchCriteria[filtergroups][0][filters][0][field]=updatedat&searchCriteria[filtergroups][0][filters][0][value]={$last1DayUpdated}&searchCriteria[filtergroups][0][filters][0][conditiontype]=gteq&fields=billingaddress,customerfirstname,customerlastname\");\r\n```\r\n\r\n### Expected result (*)\r\n<!--- Tell us what do you expect to happen. -->\r\n1. Output should json of orders with mentioned fields\r\n\r\n### Actual result (*)\r\n<!--- Tell us what happened instead. Include error messages and issues. -->\r\n1. Output is blank array\r\n"},
{"text": "<!---\r\nPlease review our guidelines before adding a new issue: https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\nFields marked with (*) are required. Please don't remove the template.\r\n-->\r\n\r\n### Preconditions (*)\r\n<!---\r\nProvide the exact Magento version (example: 2.2.5) and any important information on the environment where bug is reproducible.\r\n-->\r\n1. I tried on magento 2.3.1.\r\n2. Fresh and developer instances.\r\n\r\n### Steps to reproduce (*)\r\n<!---\r\nImportant: Provide a set of clear steps to reproduce this bug. We can not provide support without clear instructions on how to reproduce.\r\n-->\r\n1. The problem is that you cannot update the order of a group in an attribute set by repository. It does not have support for it.\r\n\r\nBasically, I am trying to update the groups of some attribute set via rest api.\r\nThe code asks for a specific format\r\n\r\n>     {\r\n>       \"group\": {\r\n>         \"attributegroupid\": \"string\",\r\n>         \"attributegroupname\": \"string\",\r\n>         \"attributesetid\": 0,\r\n>         \"extensionattributes\": {\r\n>           \"attributegroupcode\": \"string\",\r\n>           \"sortorder\": \"string\"\r\n>         }\r\n>       }\r\n>     }\r\n\r\nBut it does not work. When I debugged what was being received by the site, it returned:\r\n\r\n>    (vendor/magento/module-eav/Model/Attribute/GroupRepository.php::save())\r\n>    \r\n>    \r\n>    2019-07-09T09:06:01+00:00 INFO (6): Array\r\n>    \r\n>     (\r\n>         [attributegroupname] => Product Details\r\n>         [attributegroupid] => 336\r\n>         [attributesetid] => 39\r\n>     )\r\n\r\nWhile my posted data was:\r\n\r\n>    2019-07-09T08:46:02+00:00 INFO (6): Array\r\n>    \r\n>     (\r\n>         [group] => Array\r\n>             (\r\n>                 [attributegroupname] => Product Details\r\n>                 [extensionattributes] => Array\r\n>                     (\r\n>                         [sortorder] => 1\r\n>                         [attributegroupcode] => product-details\r\n>                     )\r\n>     \r\n>                 [attributegroupid] => 336\r\n>                 [attributesetid] => 39\r\n>            )\r\n>     \r\n>     )\r\n\r\nAfter the repository saves the group (calls resource->save()), it returns: \r\n\r\n>     2019-07-09T09:06:01+00:00 INFO (6): Array\r\n>     (\r\n>         [attributegroupname] => Product Details\r\n>         [attributegroupid] => 336\r\n>         [attributesetid] => 39\r\n>         [attributegroupcode] => product-details\r\n>         [sortorder] => 83\r\n>     )\r\n\r\nWhich is normal, because in the group model, in beforeSave, there is \r\n\r\n>    (vendor/magento/module-eav/Model/ResourceModel/Entity/Attribute/Group.php::beforeSave())\r\n>    \r\n>     if (!$object->getSortOrder()) {\r\n>             $object->setSortOrder($this->getMaxSortOrder($object) + 1);\r\n>      }\r\n\r\n### Expected result (*)\r\n<!--- Tell us what do you expect to happen. -->\r\n1. To be able to set the order of some attribute groups\r\n\r\n### Actual result (*)\r\n<!--- Tell us what happened instead. Include error messages and issues. -->\r\n1. Saving an attribute group by its repository auto-increments its old order.\r\n"},
{"text": "### Preconditions (*)\r\n### Preconditions\r\n1. magento 2.3.1 CE\r\n2. PHP 7.1.29\r\n3. elasticsearch 5\r\n\r\n### Steps to reproduce (*)\r\nupdate multiple products via REST API with a PUT request. Every time I get this error: **The stock item was unable to be saved. Please try again.**. This issue persist with elasticsearch 5 as indexer, and with MariaDB as indexer\r\n\r\nTo reproduce this issue try to perform a PUT request with this body\r\n\r\n`{\r\n\t\"product\": {\r\n\t\t\"sku\": \"productcode\",\r\n\t\t\"attributesetid\": 4,\r\n\t\t\"status\": 1,\r\n\t\t\"typeid\": \"simple\",\r\n\t\t\"visibility\": 4,\r\n\t\t\"extensionattributes\": {\r\n\t\t\t\"stockitem\": {\r\n\t\t\t\t\"qty\": 132,\r\n\t\t\t\t\"isinstock\": true,\r\n\t\t\t\t\"isqtydecimal\": false,\r\n\t\t\t\t\"minqty\": 1,\r\n\t\t\t\t\"qtyincrements\": 1\r\n\t\t\t}\r\n\t\t},\r\n\t\t\"customattributes\": [{\r\n\t\t\t\"attributecode\": \"newstodate\",\r\n\t\t\t\"value\": \"1546905600\"\r\n\t\t}, {\r\n\t\t\t\"attributecode\": \"newsfromdate\",\r\n\t\t\t\"value\": \"1546300800\"\r\n\t\t}]\r\n\t}\r\n}`\r\n\r\n### Expected result (*)\r\nUpdating of stock item related to product sku via PUT request\r\n\r\n### Actual result (*)\r\nerror in console:  **The stock item was unable to be saved. Please try again.**\r\n"},
{"text": "### Preconditions\r\nMagento 2.3-develop\r\nUse Postman, or any other application that communicates via REST API with that Magento installation.\r\n### Steps to reproduce\r\n\r\n1. Create a new product image via REST API (POST to /rest/V1/products/{sku}/media). The API returns the id of this new image. \r\n2. Now update that same image via REST API (PUT to /rest/V1/products/{sku}/media/{id}), and give it a new file and content (new base64encodeddata). \r\n\r\n### Expected result\r\nThe new id (integer) that was produced with the update. When updating the file & content, Magento actually deletes the existing image, and creates a new one. When you just update a property like position or disabled, this does not happen.\r\nYou can use the same REST API (GET to /rest/V1/products/{sku}/media/) to verify what just happened, and to see that the image was really deleted and a new entry, with a new id, was created. \r\n### Actual result\r\nThe update/PUT only returns a message: \"No image with the provided ID was found. Verify the ID and try again.\". Now you have lost control over the image. The last known id has just been deleted, and you didn't get a new id which you could store and use for future updates.  "},
{"text": "### Preconditions (*)\r\n1. Magento 2.3.1 & 2.3-develop\r\n2. Created and enabled custom module 'DreamVendor\\DreamModule'.\r\n\r\n### Steps to reproduce (*)\r\n1. Create php interface which will be used for the endpoint. E.g.\r\n```\r\nnamespace DreamVendor\\DreamModule\\Api;\r\n\r\nuse Magento\\Framework\\Api\\Search\\SearchResultInterface;\r\n\r\n/**\r\n * My Custom Endpoint API.\r\n */\r\ninterface MyCustomEndpointInterface\r\n{\r\n    /**\r\n     * Get some awesome stuff!\r\n     *\r\n     * @param \\DreamVendor\\DreamModule\\Api\\Data\\SearchRequestInterface $searchRequest\r\n     *\r\n     * @return \\Magento\\Framework\\Api\\Search\\SearchResultInterface\r\n     */\r\n    public function execute(\\DreamVendor\\DreamModule\\Api\\Data\\SearchRequestInterface $searchRequest): SearchResultInterface;\r\n}\r\n```\r\n2. Create SearchRequestInterface. Make it extensible with extension attributes.\r\n```\r\nnamespace DreamVendor\\DreamModule\\Api\\Data;\r\n\r\nuse Magento\\Framework\\Api\\ExtensibleDataInterface;\r\n\r\n/**\r\n * Search Request Data Object.\r\n */\r\ninterface SearchRequestInterface extends ExtensibleDataInterface\r\n{\r\n    /**\r\n     * Get Extension Attributes.\r\n     *\r\n     * @return \\DreamVendor\\DreamModule\\Api\\Data\\SearchRequestExtensionInterface|null\r\n     */\r\n    public function getExtensionAttributes(): ?\\DreamVendor\\DreamModule\\Api\\Data\\SearchRequestExtensionInterface;\r\n\r\n    /**\r\n     * Set Extension Attributes.\r\n     *\r\n     * @param \\DreamVendor\\DreamModule\\Api\\Data\\SearchRequestExtensionInterface|null $extension\r\n     */\r\n    public function setExtensionAttributes(?\\DreamVendor\\DreamModule\\Api\\Data\\SearchRequestExtensionInterface $extension): void;\r\n\r\n```\r\n3. Declare your endpoint via `webapi.xml` in `etc` folder of your module.\r\n```\r\n<routes xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:noNamespaceSchemaLocation=\"urn:magento:module:MagentoWebapi:etc/webapi.xsd\">\r\n    <route url=\"/V1/my-custom-endpoint\" method=\"GET\">\r\n        <service class=\"DreamVendor\\DreamModule\\Api\\MyCustomEndpointInterface\" method=\"execute\"/>\r\n        <resources>\r\n            <resource ref=\"anonymous\" />\r\n        </resources>\r\n    </route>\r\n</routes>\r\n\r\n```\r\n4. Flush caches.\r\n5. Try to generate schema. Go to `your.website.com/swagger/`.\r\n\r\n### Expected result (*)\r\n1. The page has been opened.\r\n2. You can see your new endpoint.\r\n\r\n### Actual result (*)\r\n1. You can see message like `Failed to load API definition. Internal Server Error http://magento2.local/rest/all/schema?services=all`\r\n2. Error message Notice: Undefined index: parameters in Magento/Webapi/Model/Rest/Swagger/Generator.php on line 741\r\n"},
{"text": "If you try to get a shipment list from the /shipments endpoints using search criteria you will get an empty extensionattributes field.\r\n\r\n**Preconditions**\r\nMagento 2.3.1 & 2.3-develop\r\nPHP 7\r\n\r\n**Steps to reproduce**\r\n1.Perform a curl to YOURMAGENTOHOST/rest/V1/shipments?searchCriteria[pageSize]=X&searchCriteria[currentPage]=Y with an authorization header\r\n2.Check the returned JSON\r\n\r\n**Expected result**\r\nAs API reference and Swagger [say](https://devdocs.magento.com/redoc/2.3/admin-rest-api.html#operation/salesShipmentRepositoryV1GetListGet) extensionattributes should be not empty and containing some information like sourcecode, like the following part of JSON taken from API reference\r\n\r\n\r\n**Actual result**\r\nextensionattributes is always not presented:\r\n```\r\n{\r\n    \"items\": [\r\n        {\r\n            \"billingaddressid\": 32,\r\n            \"createdat\": \"2019-08-14 14:06:06\",\r\n            \"entityid\": 9,\r\n            \"incrementid\": \"000000005\",\r\n            \"orderid\": 16,\r\n            \"packages\": [],\r\n            \"shippingaddressid\": 31,\r\n            \"storeid\": 1,\r\n            \"totalqty\": 1,\r\n            \"updatedat\": \"2019-08-14 14:06:06\",\r\n            \"items\": [\r\n                ...\r\n            ],\r\n            \"tracks\": [\r\n                ...\r\n            ],\r\n            \"comments\": []\r\n        }\r\n    ],\r\n    \"searchcriteria\": {\r\n        \"filtergroups\": [\r\n            {\r\n                \"filters\": [\r\n                    {\r\n                        \"field\": \"orderid\",\r\n                        \"value\": \"16\",\r\n                        \"conditiontype\": \"eq\"\r\n                    }\r\n                ]\r\n            }\r\n        ],\r\n        \"pagesize\": 0,\r\n        \"currentpage\": 1\r\n    },\r\n    \"totalcount\": 1\r\n}\r\n```\r\n\r\nAnyway if you use the /shipment/id API endpoint you can see that the product extensionattributes field is populated.\r\n\r\n```\r\n{\r\n    \"billingaddressid\": 32,\r\n    \"createdat\": \"2019-08-14 14:06:06\",\r\n    \"entityid\": 9,\r\n    \"incrementid\": \"000000005\",\r\n    \"orderid\": 16,\r\n    \"packages\": [],\r\n    \"shippingaddressid\": 31,\r\n    \"storeid\": 1,\r\n    \"totalqty\": 1,\r\n    \"updatedat\": \"2019-08-14 14:06:06\",\r\n    \"items\": [\r\n        ...\r\n    ],\r\n    \"tracks\": [\r\n       ...\r\n    ],\r\n    \"comments\": [],\r\n    \"extensionattributes\": {\r\n        \"sourcecode\": \"second\"\r\n    }\r\n}\r\n```\r\n\r\nI found a similar issue with /products here https://github.com/magento/magento2/issues/8700"},
{"text": "<!---\r\nPlease review our guidelines before adding a new issue: https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\nFields marked with (*) are required. Please don't remove the template.\r\n-->\r\nThe REST API endpoint for validating a password reset token will always fail unless a valid customer id is provided.\r\n\r\nIn the documentation (https://devdocs.magento.com/redoc/2.3/customer-rest-api.html#operation/customerAccountManagementV1ValidateResetPasswordLinkTokenGet) the customerId parameter description outlines \r\n> If null is given then a customer will be matched by the RP token\r\n\r\nIt is impossible to provide null for this GET request. The default password reset link that contains the reset token does not contain the customer ID. \r\n\r\n### Preconditions (*)\r\n<!---\r\nProvide the exact Magento version (example: 2.2.5) and any important information on the environment where bug is reproducible.\r\n-->\r\n1. Magento 2.3.1. & 2.3-develop\r\n2. At least one customer must exist.\r\n\r\n### Steps to reproduce (*)\r\n<!---\r\nImportant: Provide a set of clear steps to reproduce this bug. We can not provide support without clear instructions on how to reproduce.\r\n-->\r\n1. Issue a password reset email for an existing customer.\r\n2. Attempt to validate the password reset token via the REST API without customer ID since it is unavailable.\r\n\r\n\r\n### Expected result (*)\r\n<!--- Tell us what do you expect to happen. -->\r\n1. The password reset token is used to match the customer account.\r\n2. The reset password token is compared.\r\n\r\n### Actual result (*)\r\n<!--- Tell us what happened instead. Include error messages and issues. -->\r\n1. Without the customer ID (which is unavailable) this API call will always fail.\r\n\r\n### Examples\r\nThe link sent to the customer email address does not contain the customer ID. `{{basesecureurl}}/customer/account/createPassword/?token={resetPasswordLinkToken}` \r\n\r\nThe documentation example shows the following:\r\n`/V1/customers/{customerId}/password/resetLinkToken/{resetPasswordLinkToken}`\r\n\r\nThis REST API endpoint resolves to the validateResetPasswordLinkToken method of class Magento\\Customer\\Model\\AccountManagement.\r\n\r\nInternally, the following snippet is used, and so customer ID is not required as the token can identify the customer on its own:\r\n`$this->accountManagement->validateResetPasswordLinkToken(null, $resetPasswordToken);`\r\n\r\nHowever, it is not possible to pass a null value via the REST API without impacting the routing of this request.\r\n\r\nRemoving the customer id portion entirely routes differently and results in a no route response.\r\n`/V1/customers/password/resetLinkToken/{resetPasswordLinkToken}`\r\n`{\"message\":\"Request does not match any route.\",\"trace\":null}`\r\n\r\nProviding a URL encoded null value fails with a 404 html response:\r\n`/V1/customers/%00/password/resetLinkToken/{resetPasswordLinkToken}`\r\n> <!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\r\n> <html><head>\r\n> <title>404 Not Found</title>\r\n> </head><body>\r\n> <h1>Not Found</h1>\r\n> <p>The requested URL /rest/V1/customers/ was not found on this server.</p>\r\n> </body></html>\r\n\r\nPassing the phrase null, or any other non-integer value responds with a type error:\r\n`/V1/customers/null/password/resetLinkToken/{resetPasswordLinkToken}`\r\n`{\"message\":\"The \\\"null\\\" value's type is invalid. The \\\"int\\\" type was expected. Verify and try again.\",\"trace\":null}`\r\n\r\nPassing a zero value also fails:\r\n`/V1/customers/0/password/resetLinkToken/{resetPasswordLinkToken}`\r\n`{\"message\":\"Invalid value of \\\"%value\\\" provided for the %fieldName field.\",\"parameters\":{\"value\":0,\"fieldName\":\"customerId\"}`\r\n"},
{"text": "\r\n<!---\r\nPlease review our guidelines before adding a new issue: https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\nFields marked with (*) are required. Please don't remove the template.\r\n-->\r\n\r\n### Preconditions (*)\r\n1. Magento version: 2.3.2 \r\n\r\n### Steps to reproduce (*)\r\n<!---\r\nImportant: Provide a set of clear steps to reproduce this bug. We can not provide support without clear instructions on how to reproduce.\r\n-->\r\n1. Create a product in Magento using the API with POST (`/rest/V1/products`) with base64 encoded image to the mediagalleryentries attribute\r\n[request.txt](https://github.com/magento/magento2/files/3551238/request.txt)\r\n### Expected result (*)\r\n<!--- Tell us what do you expect to happen. -->\r\n1. Product being created with an image\r\n\r\n### Actual result (*)\r\n<!--- Tell us what happened instead. Include error messages and issues. -->\r\n1. Exception thrown, \"The product that was requested doesn't exist. Verify the product and try again.\", this is caused by /vendor/magento/module-catalog/Model/ProductRepository/MediaGalleryProcessor.php:141\r\n2. This exception is thrown because the \"mediagallery\" attribute does not exist on the product, maybe because it isn't saved to the database yet?\r\n"},
{"text": "<!---\r\nPlease review our guidelines before adding a new issue: https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\nFields marked with (*) are required. Please don't remove the template.\r\n-->\r\n\r\nThe call to catalogProductTierPriceManagementV1GetListGet fails when querying a configurable product. It should handle the request gracefully but instead dies.\r\n\r\nThe offending file is\r\n  ```/app/code/Magento/Catalog/Model/Product/TierPriceManagement.php```\r\nThis function is wrong:\r\n\r\n```php\r\n public function getList($sku, $customerGroupId)\r\n {\r\n   $product = $this->productRepository->get($sku, ['editmode' => true]);\r\n\r\n   $priceKey = 'websiteprice';\r\n   $value = $this->config->getValue('catalog/price/scope', \\Magento\\Store\\Model\\ScopeInterface::SCOPEWEBSITE);\r\n   if ($value == 0) {\r\n     $priceKey = 'price';\r\n   }\r\n\r\n   $cgi = ($customerGroupId === 'all'\r\n           ? $this->groupManagement->getAllCustomersGroup()->getId()\r\n           : $customerGroupId);\r\n\r\n   $prices = [];\r\n   foreach ($product->getData('tierprice') as $price) {\r\n     if ((isnumeric($customerGroupId) && (int) $price['custgroup'] === (int) $customerGroupId)\r\n         || ($customerGroupId === 'all' && $price['allgroups'])\r\n         ) {\r\n       /** @var \\Magento\\Catalog\\Api\\Data\\ProductTierPriceInterface $tierPrice */\r\n       $tierPrice = $this->priceFactory->create();\r\n       $tierPrice->setValue($price[$priceKey])\r\n       ->setQty($price['priceqty'])\r\n       ->setCustomerGroupId($cgi);\r\n       $prices[] = $tierPrice;\r\n     }\r\n   }\r\n   return $prices;\r\n }\r\n```\r\n\r\nThe line\r\n```php\r\n   foreach ($product->getData('tierprice') as $price) {\r\n```\r\nmight return a null.\r\n\r\nIt should be\r\n```php\r\n$prices = $product->getData('tierprice');\r\nif ($prices != null) {\r\n  foreach ($prices as $price) {\r\n```\r\n\r\n  If you ask for the product info (even a parent configurable product), it'll return data in JSON including\r\n  ```json\r\n    \"tierprices\": [] \r\n  ```\r\n...which correctly indicates that this (configurable) product has no tier prices.\r\nBut if you ask the configurable product DIRECTLY for prices using group-prices/all/tiers (eg rest/V1/products/myConfigurableProduct/group-prices/all/tiers) it will error and die as detailed below.\r\n\r\n### Preconditions (*)\r\n<!---\r\nProvide the exact Magento version (example: 2.2.5) and any important information on the environment where bug is reproducible.\r\n-->\r\n1. Magento 2.3.2\r\n2. A configurable product with options\r\n3. A child product of the configurable product mentioned in (2)\r\n*Optional:*\r\n4. A tax group so that you can add tiered prices\r\n5. Tiered price for the child product mentioned in (3), for the group mentioned in (4)\r\n\r\n### Steps to reproduce (*)\r\n<!---\r\nImportant: Provide a set of clear steps to reproduce this bug. We can not provide support without clear instructions on how to reproduce.\r\n-->\r\n1. Make a GET request to catalogProductTierPriceManagementV1GetListGet http://t213.vg/rest/default/V1/products/{sku}/group-prices/{customerGroupId}/tiers, eg. http://t213.vg/rest/default/V1/products/parentSKU/group-prices/1/tiers\r\n\r\n### Expected result (*)\r\n<!--- Tell us what do you expect to happen. -->\r\n1. The page should return an empty tiers array, eg.\r\n```json\r\n\"tierprices\": []\r\n```\r\n2. OR the page should fail with HTTP 400, or HTTP 405 as technically the request is wrong (tier prices are not valid for configurable products)\r\n\r\n### Actual result (*)\r\n<!--- Tell us what happened instead. Include error messages and issues. -->\r\n1. The page dies horribly with an internal error and generates a log file. The page returns something like:\r\n{\"message\":\"Internal Error. Details are available in Magento log file. Report ID: webapi-5d36f243413e9\"}\r\n2. The generated log file contains:\r\n```\r\nmain.CRITICAL:\r\n  Report ID: webapi-5d36f243413e9; Message: Warning: Invalid argument supplied for foreach() in /usr/local/var/www/vendor/magento/module-catalog/Model/Product/TierPriceManagement.php on line 185 {\"exception\":\"[object] (Exception(code: 0): Report ID: webapi-5d36f243413e9; Message: Warning: Invalid argument supplied for foreach() in /usr/local/var/www/vendor/magento/module-catalog/Model/Product/TierPriceManagement.php on line 185 at /usr/local/var/www/vendor/magento/framework/Webapi/ErrorProcessor.php:206, Exception(code: 0): Warning: Invalid argument supplied for foreach() in /usr/local/var/www/vendor/magento/module-catalog/Model/Product/TierPriceManagement.php on line 185 at /usr/local/var/www/vendor/magento/framework/App/ErrorHandler.php:61)\"} [\r\n   ]\r\n```\r\n"},
{"text": "As a merchant, I want to have seperate images with type thumbnail, small and image. \r\nThis can be set using the admin backend, but it is not working from the rest api.\r\n\r\n### Preconditions (*)\r\n<!---\r\nProvide the exact Magento version (example: 2.2.5) and any important information on the environment where bug is reproducible.\r\n-->\r\n1. Magento Commerce/OpenSource 2.3.2\r\n2.\r\n\r\n### Steps to reproduce (*)\r\n<!---\r\nImportant: Provide a set of clear steps to reproduce this bug. We can not provide support without clear instructions on how to reproduce.\r\n-->\r\n1. Create an Simple Product\r\n2. Upload 2 image using the rest bulk api like this\r\n\r\n```javascript\r\nURL: {{baseurl}}/rest/all/async/bulk/V1/products/bySku/media\r\nBody:\r\n[\r\n  {\r\n    \"entry\": {\r\n      \"mediatype\": \"image\",\r\n      \"label\": \"Image\",\r\n      \"disabled\": false,\r\n      \"position\": 1,\r\n        \"types\": [\r\n            \"image\",\r\n            \"smallimage\"\r\n        ],\r\n      \"content\": {\r\n        \"base64EncodedData\": \"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\",\r\n        \"type\": \"image/png\",\r\n        \"name\": \"20750.jpg\"\r\n      }\r\n    },\r\n    \"sku\": \"49128\"\r\n  },\r\n  {\r\n    \"entry\": {\r\n      \"mediatype\": \"image\",\r\n      \"label\": \"Image\",\r\n      \"disabled\": false,\r\n      \"position\": 8,\r\n      \"types\": [\"thumbnail\"],\r\n      \"content\": {\r\n        \"base64EncodedData\": \"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\",\r\n        \"type\": \"image/png\",\r\n        \"name\": \"20750back.jpg\"\r\n      }\r\n    },\r\n    \"sku\": \"49128\"\r\n  }\r\n]\r\n```\r\n### Expected result (*)\r\n<!--- Tell us what do you expect to happen. -->\r\n1. In the backend there should be 2 images both with types.\r\n2. The first image should be marked aus base,small and the secound should be thumbnail.\r\n\r\n### Actual result (*)\r\n<!--- Tell us what happened instead. Include error messages and issues. -->\r\n1. Depending which image will be processed last only this types will be set, as you can see in the screenshot below.\r\n![grafik](https://user-images.githubusercontent.com/19548641/64334264-7687af00-cfd8-11e9-8188-4d6fad8c7763.png)\r\n\r\n"},
{"text": "<!---\r\nPlease review our guidelines before adding a new issue: https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\nFields marked with (*) are required. Please don't remove the template.\r\n-->\r\nMagento 2.3.0 rest API can't able to update `customer` throws the error.\r\nAPI  `/V1/customers/:customerId`\r\n`Method: PUT`\r\n`URL: http://localhost/magentosample230/rest/V1/customers/2`\r\n\r\n### Preconditions (*)\r\n<!---\r\nProvide the exact Magento version (example: 2.2.5) and any important information on the environment where bug is reproducible.\r\n-->\r\n1. Magento 2.3.0 & 2.3-develop\r\n\r\n\r\n### Steps to reproduce (*)\r\n<!---\r\nImportant: Provide a set of clear steps to reproduce this bug. We can not provide support without clear instructions on how to reproduce.\r\n-->\r\n1. Run the customer update API.\r\n2. Method: PUT\r\n3. Headers: `Authorization:Bearer yfhwg1j458dw086qelbqkkkmp6f0tj89`\r\n                    `Content-Type:application/json`\r\n4. Body: \r\n```\r\n{\r\n      \"customer\": {\r\n      \"email\": \"john@gmail.com\",\r\n      \"firstname\": \"firstname new\",\r\n      \"lastname\": \"lastname new\",\r\n      \"websiteid\": 1\r\n   }\r\n}\r\n```\r\n\r\n\r\n5. URL: http://localhost/magentosample230/rest/V1/customers/2\r\n\r\n\r\n### Expected result (*)\r\n<!--- Tell us what do you expect to happen. -->\r\n1. Customer should be updated and reponse will return success message. \r\n\r\n\r\n### Actual result (*)\r\n<!--- Tell us what happened instead. Include error messages and issues. -->\r\n1. Throw the error in response.\r\n`Error: `\r\n```\r\n{\r\n    \"message\": \"A customer with the same email address already exists in an associated website.\",\r\n    \"trace\": \"#0 /var/www/html/magentosample230/vendor/magento/module-eav/Model/Entity/VersionControl/AbstractEntity.php(90): Magento\\\\Customer\\\\Model\\\\ResourceModel\\\\Customer->beforeSave(Object(Magento\\\\Customer\\\\Model\\\\Customer\\\\Interceptor))\\n#1 /var/www/html/magentosample230/vendor/magento/framework/Interception/Interceptor.php(58): Magento\\\\Eav\\\\Model\\\\Entity\\\\VersionControl\\\\AbstractEntity->save(Object(Magento\\\\Customer\\\\Model\\\\Customer\\\\Interceptor))\\n#2 /var/www/html/magentosample230/vendor/magento/framework/Interception/Interceptor.php(138): Magento\\\\Customer\\\\Model\\\\ResourceModel\\\\Customer\\\\Interceptor->callParent('save', Array)\\n#3 /var/www/html/magentosample230/vendor/magento/framework/App/Cache/FlushCacheByTags.php(68): Magento\\\\Customer\\\\Model\\\\ResourceModel\\\\Customer\\\\Interceptor->Magento\\\\Framework\\\\Interception\\\\{closure}(Object(Magento\\\\Customer\\\\Model\\\\Customer\\\\Interceptor))\\n#4 /var/www/html/magentosample230/vendor/magento/framework/Interception/Interceptor.php(135): Magento\\\\Framework\\\\App\\\\Cache\\\\FlushCacheByTags->aroundSave(Object(Magento\\\\Customer\\\\Model\\\\ResourceModel\\\\Customer\\\\Interceptor), Object(Closure), Object(Magento\\\\Customer\\\\Model\\\\Customer\\\\Interceptor))\\n#5 /var/www/html/magentosample230/vendor/magento/framework/Interception/Interceptor.php(153): Magento\\\\Customer\\\\Model\\\\ResourceModel\\\\Customer\\\\Interceptor->Magento\\\\Framework\\\\Interception\\\\{closure}(Object(Magento\\\\Customer\\\\Model\\\\Customer\\\\Interceptor))\\n#6 /var/www/html/magentosample230/generated/code/Magento/Customer/Model/ResourceModel/Customer/Interceptor.php(117): Magento\\\\Customer\\\\Model\\\\ResourceModel\\\\Customer\\\\Interceptor->callPlugins('save', Array, NULL)\\n#7 /var/www/html/magentosample230/vendor/magento/framework/Model/AbstractModel.php(648): Magento\\\\Customer\\\\Model\\\\ResourceModel\\\\Customer\\\\Interceptor->save(Object(Magento\\\\Customer\\\\Model\\\\Customer\\\\Interceptor))\\n#8 /var/www/html/magentosample230/vendor/magento/framework/Interception/Interceptor.php(58): Magento\\\\Framework\\\\Model\\\\AbstractModel->save()\\n#9 /var/www/html/magentosample230/vendor/magento/framework/Interception/Interceptor.php(138): Magento\\\\Customer\\\\Model\\\\Customer\\\\Interceptor->callParent('save', Array)\\n#10 /var/www/html/magentosample230/vendor/magento/framework/Interception/Interceptor.php(153): Magento\\\\Customer\\\\Model\\\\Customer\\\\Interceptor->Magento\\\\Framework\\\\Interception\\\\{closure}()\\n#11 /var/www/html/magentosample230/generated/code/Magento/Customer/Model/Customer/Interceptor.php(1118): Magento\\\\Customer\\\\Model\\\\Customer\\\\Interceptor->callPlugins('save', Array, Array)\\n#12 /var/www/html/magentosample230/vendor/magento/module-customer/Model/ResourceModel/CustomerRepository.php(219): Magento\\\\Customer\\\\Model\\\\Customer\\\\Interceptor->save()\\n#13 /var/www/html/magentosample230/vendor/magento/framework/Interception/Interceptor.php(58): Magento\\\\Customer\\\\Model\\\\ResourceModel\\\\CustomerRepository->save(Object(Magento\\\\Customer\\\\Model\\\\Data\\\\Customer), NULL)\\n#14 /var/www/html/magentosample230/vendor/magento/framework/Interception/Interceptor.php(138): Magento\\\\Customer\\\\Model\\\\ResourceModel\\\\CustomerRepository\\\\Interceptor->callParent('save', Array)\\n#15 /var/www/html/magentosample230/vendor/vertex/module-tax/Model/Plugin/CustomerRepositoryPlugin.php(179): Magento\\\\Customer\\\\Model\\\\ResourceModel\\\\CustomerRepository\\\\Interceptor->Magento\\\\Framework\\\\Interception\\\\{closure}(Object(Magento\\\\Customer\\\\Model\\\\Data\\\\Customer), NULL)\\n#16 /var/www/html/magentosample230/vendor/magento/framework/Interception/Interceptor.php(135): Vertex\\\\Tax\\\\Model\\\\Plugin\\\\CustomerRepositoryPlugin->aroundSave(Object(Magento\\\\Customer\\\\Model\\\\ResourceModel\\\\CustomerRepository\\\\Interceptor), Object(Closure), Object(Magento\\\\Customer\\\\Model\\\\Data\\\\Customer), NULL)\\n#17 /var/www/html/magentosample230/vendor/magento/module-customer/Model/Plugin/CustomerRepository/TransactionWrapper.php(44): Magento\\\\Customer\\\\Model\\\\ResourceModel\\\\CustomerRepository\\\\Interceptor->Magento\\\\Framework\\\\Interception\\\\{closure}(Object(Magento\\\\Customer\\\\Model\\\\Data\\\\Customer), NULL)\\n#18 /var/www/html/magentosample230/vendor/magento/framework/Interception/Interceptor.php(135): Magento\\\\Customer\\\\Model\\\\Plugin\\\\CustomerRepository\\\\TransactionWrapper->aroundSave(Object(Magento\\\\Customer\\\\Model\\\\ResourceModel\\\\CustomerRepository\\\\Interceptor), Object(Closure), Object(Magento\\\\Customer\\\\Model\\\\Data\\\\Customer), NULL)\\n#19 /var/www/html/magentosample230/vendor/magento/framework/Interception/Interceptor.php(153): Magento\\\\Customer\\\\Model\\\\ResourceModel\\\\CustomerRepository\\\\Interceptor->Magento\\\\Framework\\\\Interception\\\\{closure}(Object(Magento\\\\Customer\\\\Model\\\\Data\\\\Customer), NULL)\\n#20 /var/www/html/magentosample230/generated/code/Magento/Customer/Model/ResourceModel/CustomerRepository/Interceptor.php(26): Magento\\\\Customer\\\\Model\\\\ResourceModel\\\\CustomerRepository\\\\Interceptor->callPlugins('save', Array, NULL)\\n#21 [internal function]: Magento\\\\Customer\\\\Model\\\\ResourceModel\\\\CustomerRepository\\\\Interceptor->save(Object(Magento\\\\Customer\\\\Model\\\\Data\\\\Customer), NULL)\\n#22 /var/www/html/magentosample230/vendor/magento/module-webapi/Controller/Rest/SynchronousRequestProcessor.php(95): calluserfuncarray(Array, Array)\\n#23 /var/www/html/magentosample230/vendor/magento/module-webapi/Controller/Rest.php(188): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\SynchronousRequestProcessor->process(Object(Magento\\\\Framework\\\\Webapi\\\\Rest\\\\Request\\\\Proxy))\\n#24 /var/www/html/magentosample230/vendor/magento/framework/Interception/Interceptor.php(58): Magento\\\\Webapi\\\\Controller\\\\Rest->dispatch(Object(Magento\\\\Framework\\\\App\\\\Request\\\\Http))\\n#25 /var/www/html/magentosample230/vendor/magento/framework/Interception/Interceptor.php(138): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\Interceptor->callParent('dispatch', Array)\\n#26 /var/www/html/magentosample230/vendor/magento/framework/Interception/Interceptor.php(153): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\Interceptor->Magento\\\\Framework\\\\Interception\\\\{closure}(Object(Magento\\\\Framework\\\\App\\\\Request\\\\Http))\\n#27 /var/www/html/magentosample230/generated/code/Magento/Webapi/Controller/Rest/Interceptor.php(26): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\Interceptor->callPlugins('dispatch', Array, Array)\\n#28 /var/www/html/magentosample230/vendor/magento/framework/App/Http.php(135): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\Interceptor->dispatch(Object(Magento\\\\Framework\\\\App\\\\Request\\\\Http))\\n#29 /var/www/html/magentosample230/generated/code/Magento/Framework/App/Http/Interceptor.php(24): Magento\\\\Framework\\\\App\\\\Http->launch()\\n#30 /var/www/html/magentosample230/vendor/magento/framework/App/Bootstrap.php(258): Magento\\\\Framework\\\\App\\\\Http\\\\Interceptor->launch()\\n#31 /var/www/html/magentosample230/index.php(39): Magento\\\\Framework\\\\App\\\\Bootstrap->run(Object(Magento\\\\Framework\\\\App\\\\Http\\\\Interceptor))\\n#32 {main}\"\r\n}\r\n```\r\n\r\n\r\n\r\n\r\n"},
{"text": "After refactoring which was done in 735024aef05ccf39412b343439b074129a8dfdaa, the issue https://github.com/magento/magento2/issues/24116 is come back.\r\nOriginal report: [tap](https://testing-service.magento-community.engineering/reports/magento/inventory/pull/2509/c596c0daf17e77fc8ca757ec38e7d757/Integration/allure-report-ce/index.html#categories/f48e7d3623b476c0129b7c130cbc68bf/db7fff094b014ee3/)\r\n\r\n### Preconditions (*)\r\n1. Magento 2.3.1 & 2.3-develop\r\n2. Created and enabled custom module 'DreamVendor\\DreamModule'.\r\n\r\n### Steps to reproduce (*)\r\n1. Create php interface which will be used for the endpoint. E.g.\r\n```\r\nnamespace DreamVendor\\DreamModule\\Api;\r\n\r\nuse Magento\\Framework\\Api\\Search\\SearchResultInterface;\r\n\r\n/**\r\n * My Custom Endpoint API.\r\n */\r\ninterface MyCustomEndpointInterface\r\n{\r\n    /**\r\n     * Get some awesome stuff!\r\n     *\r\n     * @param \\DreamVendor\\DreamModule\\Api\\Data\\SearchRequestInterface $searchRequest\r\n     *\r\n     * @return \\Magento\\Framework\\Api\\Search\\SearchResultInterface\r\n     */\r\n    public function execute(\\DreamVendor\\DreamModule\\Api\\Data\\SearchRequestInterface $searchRequest): SearchResultInterface;\r\n}\r\n```\r\n2. Create SearchRequestInterface. Make it extensible with extension attributes.\r\n```\r\nnamespace DreamVendor\\DreamModule\\Api\\Data;\r\n\r\nuse Magento\\Framework\\Api\\ExtensibleDataInterface;\r\n\r\n/**\r\n * Search Request Data Object.\r\n */\r\ninterface SearchRequestInterface extends ExtensibleDataInterface\r\n{\r\n    /**\r\n     * Get Extension Attributes.\r\n     *\r\n     * @return \\DreamVendor\\DreamModule\\Api\\Data\\SearchRequestExtensionInterface|null\r\n     */\r\n    public function getExtensionAttributes(): ?\\DreamVendor\\DreamModule\\Api\\Data\\SearchRequestExtensionInterface;\r\n\r\n    /**\r\n     * Set Extension Attributes.\r\n     *\r\n     * @param \\DreamVendor\\DreamModule\\Api\\Data\\SearchRequestExtensionInterface|null $extension\r\n     */\r\n    public function setExtensionAttributes(?\\DreamVendor\\DreamModule\\Api\\Data\\SearchRequestExtensionInterface $extension): void;\r\n\r\n```\r\n3. Declare your endpoint via `webapi.xml` in `etc` folder of your module.\r\n```\r\n<routes xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:noNamespaceSchemaLocation=\"urn:magento:module:MagentoWebapi:etc/webapi.xsd\">\r\n    <route url=\"/V1/my-custom-endpoint\" method=\"GET\">\r\n        <service class=\"DreamVendor\\DreamModule\\Api\\MyCustomEndpointInterface\" method=\"execute\"/>\r\n        <resources>\r\n            <resource ref=\"anonymous\" />\r\n        </resources>\r\n    </route>\r\n</routes>\r\n\r\n```\r\n4. Flush caches.\r\n5. Try to generate schema. Go to `your.website.com/swagger/`.\r\n\r\n### Expected result (*)\r\n1. The page has been opened.\r\n2. You can see your new endpoint.\r\n\r\n### Actual result (*)\r\n1. You can see message like `Failed to load API definition. Internal Server Error http://magento2.local/rest/all/schema?services=all`\r\n2. Error message `Warning: arraymerge() expects at least 1 parameter, 0 given in \\/var\\/www\\/html\\/app\\/code\\/Magento\\/Webapi\\/Model\\/Rest\\/Swagger\\/Generator.php:762`"},
{"text": "### Preconditions (*)\r\n1. Magento 2.3.2 & 2.3-develop\r\n2. Change locale of main store to german\r\n3. Create an integration\r\n\r\n### Steps to reproduce (*)\r\nUnfortunately I have no idea how to trigger a 500 error via REST API. It usually happens by chance when there are database issues or something similar. However, the following steps could help to reproduce it.\r\n\r\n1. Enforce an exception by calling the REST API, for example too many concurrent product updates will cause a \"Database deadlock found when trying to get lock\" exception\r\n2. Until 2.3.1 exception thrown by the REST API were always in english, irrespective of the actual store language. This made it easy to catch errors and for example retry on deadlocks. Since 2.3.2 exceptions are localized even via REST API. \r\n\r\n### Expected result (*)\r\n1. \"Database deadlock found when trying to get lock\" exception message in english\r\n\r\n### Actual result (*)\r\n1. \"Database deadlock gedetecteerd tijdens het verkrijgen van een lock\" for a dutch store or any other language for a store in this language\r\n"},
{"text": "<!---\r\nPlease review our guidelines before adding a new issue: https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\nFields marked with (*) are required. Please don't remove the template.\r\n-->\r\nI am not sure if this is a bug or feature. I am trying to update the CMS Page title from POSTMAN. It updates title but also makes content and other fields empty.\r\n\r\n### Preconditions (*)\r\n<!---\r\nProvide the exact Magento version (example: 2.2.5) and any important information on the environment where the bug is reproducible.\r\n-->\r\n1. At least 1 CMS page\r\n2. Web API auth key\r\n\r\n### Steps to reproduce (*)\r\n<!---\r\nImportant: Provide a set of clear steps to reproduce this bug. We can not provide support without clear instructions on how to reproduce.\r\n-->\r\n1. Go to the [postman](https://www.getpostman.com/) and use this URL and body content with PUT method\r\nURL: `http://www.example.com/rest/all/V1/cmsPage/ID` (replace ID with your id (integer)\r\nBody: \r\n```\r\n{\"page\":\r\n\t{\r\n\t\t\"title\": \"My Title\"\r\n\t}\r\n}\r\n```\r\n\r\n### Expected result (*)\r\n<!--- Tell us what do you expect to happen. -->\r\n1. Update TITLE and keep all other fields same/unchanged\r\n2. OR only update the field provided.\r\n\r\n### Actual result (*)\r\n<!--- Tell us what happened instead. Include error messages and issues. -->\r\n1. Updates title and makes all other fields (not provided in the body) null.\r\n\r\n**How do I update title only or content only? I want to update one field only (title at this stage).** "},
{"text": "#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\nIn [2]: s = pd.Series(range(4), index=pd.MultiIndex.fromproduct([[1,2], ['a', 'b']]))\r\n\r\nIn [3]: s.loc[['not', 'found']]\r\nOut[3]: Series([], dtype: int64)\r\n```\r\n#### Problem description\r\n\r\nWith regular ``Index``es, looking for a list of labels of which none is present will raise ``KeyError`` (see below). We should be coherent (and while I would prefer the empty result to the exception, this was already discussed in #7999).\r\n\r\n#### Expected Output\r\n\r\nCompare to\r\n\r\n``` python\r\nIn [4]: s.resetindex().loc[['not', 'found']]\r\n---------------------------------------------------------------------------\r\nKeyError                                  Traceback (most recent call last)\r\n<ipython-input-4-e13655430320> in <module>()\r\n----> 1 s.resetindex().loc[['not', 'found']]\r\n\r\n/home/nobackup/repo/pandas/pandas/core/indexing.py in getitem(self, key)\r\n   1339         else:\r\n   1340             key = com.applyifcallable(key, self.obj)\r\n-> 1341             return self.getitemaxis(key, axis=0)\r\n   1342 \r\n   1343     def isscalaraccess(self, key):\r\n\r\n/home/nobackup/repo/pandas/pandas/core/indexing.py in getitemaxis(self, key, axis)\r\n   1539                     raise ValueError('Cannot index with multidimensional key')\r\n   1540 \r\n-> 1541                 return self.getitemiterable(key, axis=axis)\r\n   1542 \r\n   1543             # nested tuple slicing\r\n\r\n/home/nobackup/repo/pandas/pandas/core/indexing.py in getitemiterable(self, key, axis)\r\n   1049     def getitemiterable(self, key, axis=0):\r\n   1050         if self.shouldvalidateiterable(axis):\r\n-> 1051             self.hasvalidtype(key, axis)\r\n   1052 \r\n   1053         labels = self.obj.getaxis(axis)\r\n\r\n/home/nobackup/repo/pandas/pandas/core/indexing.py in hasvalidtype(self, key, axis)\r\n   1429 \r\n   1430                 raise KeyError(\"None of [%s] are in the [%s]\" %\r\n-> 1431                                (key, self.obj.getaxisname(axis)))\r\n   1432 \r\n   1433             return True\r\n\r\nKeyError: \"None of [['not', 'found']] are in the [index]\"\r\n\r\n```\r\n\r\n#### Output of ``pd.showversions()``\r\n\r\n<details>\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: f65a6415f15d438432cc6954ead61b052c5d4d60\r\npython: 3.5.2.final.0\r\npython-bits: 64\r\nOS: Linux\r\nOS-release: 4.7.0-1-amd64\r\nmachine: x8664\r\nprocessor: \r\nbyteorder: little\r\nLCALL: None\r\nLANG: itIT.utf8\r\nLOCALE: itIT.UTF-8\r\n\r\npandas: 0.19.0+473.gf65a641\r\npytest: 3.0.6\r\npip: 8.1.2\r\nsetuptools: 28.0.0\r\nCython: 0.23.4\r\nnumpy: 1.12.0\r\nscipy: 0.18.1\r\nxarray: None\r\nIPython: 5.1.0.dev\r\nsphinx: 1.4.8\r\npatsy: 0.3.0-dev\r\ndateutil: 2.5.3\r\npytz: 2015.7\r\nblosc: None\r\nbottleneck: 1.2.0\r\ntables: 3.2.2\r\nnumexpr: 2.6.0\r\nfeather: None\r\nmatplotlib: 2.0.0rc2\r\nopenpyxl: 2.3.0\r\nxlrd: 1.0.0\r\nxlwt: 1.1.2\r\nxlsxwriter: 0.9.3\r\nlxml: 3.6.4\r\nbs4: 4.5.1\r\nhtml5lib: 0.999\r\nhttplib2: 0.9.1\r\napiclient: 1.5.2\r\nsqlalchemy: 1.0.15\r\npymysql: None\r\npsycopg2: None\r\njinja2: 2.8\r\ns3fs: None\r\npandasdatareader: 0.2.1\r\n\r\n\r\n</details>\r\n"},
{"text": "#### Problem description\r\nThis is a feature request for usecols to accept integer value and string.  If integer/string is provided, flag `squeeze` is to be turned on, thus producing a Series.\r\n\r\n#### Rationale\r\n+ consistency with `indexcol` which accepts both integer/string and lists\r\n+ shortcut\r\n\r\n#### Expected Output\r\n\r\n```python\r\n# test\r\ntestfile = \"pandas/tests/io/data/tips.csv\"\r\ndf = pd.readtable(testfile, sep=\",\", usecols=\"tip\")\r\nassert isinstance(df, pd.Series)\r\n\r\ndf = pd.readtable(testfile, sep=\",\", usecols=2)\r\nassert isinstance(df, pd.Series)\r\n\r\ndf = pd.readtable(testfile, sep=\",\", usecols=[2])\r\nassert isinstance(df, pd.DataFrame)\r\n```\r\n#### Output of ``pd.showversions()``\r\n\r\n<details>\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.3.2.final.0\r\npython-bits: 64\r\nOS: Linux\r\nOS-release: 2.6.32-642.13.1.el6.x8664\r\nmachine: x8664\r\nprocessor: x8664\r\nbyteorder: little\r\nLCALL: None\r\nLANG: enUS.UTF-8\r\nLOCALE: enUS.UTF-8\r\n\r\npandas: 0.19.0\r\nnose: 1.3.0\r\npip: 8.1.2\r\nsetuptools: 20.9.0\r\nCython: 0.25.1\r\nnumpy: 1.11.2\r\nscipy: 0.18.0\r\nstatsmodels: 0.6.1\r\nxarray: None\r\nIPython: 5.0.0.dev\r\nsphinx: None\r\npatsy: 0.4.1\r\ndateutil: 2.5.3\r\npytz: 2016.6.1\r\nblosc: None\r\nbottleneck: None\r\ntables: 3.3.1-dev0\r\nnumexpr: 2.6.1\r\nmatplotlib: 1.5.1\r\nopenpyxl: None\r\nxlrd: None\r\nxlwt: None\r\nxlsxwriter: None\r\nlxml: None\r\nbs4: 4.4.1\r\nhtml5lib: None\r\nhttplib2: 0.9.2\r\napiclient: None\r\nsqlalchemy: None\r\npymysql: None\r\npsycopg2: None\r\njinja2: 2.8\r\nboto: None\r\npandasdatareader: None\r\n</details>\r\n"},
{"text": "#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\n# It's pretty simple but it doesn't work.\r\n# Here stocks is inside a class which type is pd.Series.\r\n# I tried to print money / price * (1-r) and found it was not zero.\r\n# However, self.stocks[ticker] is never changed which confuses me\r\nself.stocks[ticker] += money / price * (1 - r)\r\n\r\n```\r\n#### Problem description\r\nSee the comments above. It only happens when I tried to use a certain set of data but works for other situations. I've tried to change the value of self.stocks[name] and something more strange happened.\r\n``` python\r\n# this works\r\nself.stocks[ticker] = 6\r\nself.stocks[ticker] += money / price * (1 - r)\r\n# I was able to see the different value printed after the line\r\n# but if I change it to\r\nif self.stocks[ticker] == 0:\r\n    self.stocks[ticker] = 0\r\nself.stocks[ticker] += money / price* (1 - r)\r\n# it repeated the unchanged result which drove me mad\r\n```\r\n\r\n#### Expected Output\r\nself.stocks[ticker] should be changed\r\n#### Output of ``pd.showversions()``\r\n<details>\r\n# Paste the output here pd.showversions() here\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.6.0.final.0\r\npython-bits: 64\r\nOS: Darwin\r\nOS-release: 16.3.0\r\nmachine: x8664\r\nprocessor: i386\r\nbyteorder: little\r\nLCALL: None\r\nLANG: zhCN.UTF-8\r\nLOCALE: zhCN.UTF-8\r\n\r\npandas: 0.19.2\r\nnose: None\r\npip: 9.0.1\r\nsetuptools: 32.2.0\r\nCython: None\r\nnumpy: 1.12.0\r\nscipy: 0.18.1\r\nstatsmodels: None\r\nxarray: None\r\nIPython: 5.1.0\r\nsphinx: None\r\npatsy: None\r\ndateutil: 2.6.0\r\npytz: 2016.10\r\nblosc: None\r\nbottleneck: None\r\ntables: None\r\nnumexpr: 2.6.2\r\nmatplotlib: 2.0.0\r\nopenpyxl: 2.4.2\r\nxlrd: 1.0.0\r\nxlwt: None\r\nxlsxwriter: None\r\nlxml: 3.7.2\r\nbs4: None\r\nhtml5lib: None\r\nhttplib2: None\r\napiclient: None\r\nsqlalchemy: None\r\npymysql: None\r\npsycopg2: None\r\njinja2: 2.9.5\r\nboto: None\r\npandasdatareader: None\r\n</details>\r\n"},
{"text": "#### Code Sample\r\n\r\n```pycon\r\n>>> import pandas as pd\r\n\r\n>>> df = pd.DataFrame({'A': [1, 2], 'B': [3, 4], 'C': [5, 6], 'D': [7, 8]})\r\n>>> pd.melt(df, idvars=('A', 'B'), valuevars=('C', 'D'))\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-14-ef146f73874a> in <module>()\r\n----> 1 pd.melt(df, idvars=('A', 'B'), valuevars=('C', 'D'))\r\n\r\n/Users/josh/env/analysis/lib/python3.5/site-packages/pandas/core/reshape.py in melt(frame, idvars, valuevars, varname, valuename, collevel)\r\n    766         if not isinstance(valuevars, (tuple, list, np.ndarray)):\r\n    767             valuevars = [valuevars]\r\n--> 768         frame = frame.ix[:, idvars + valuevars]\r\n    769     else:\r\n    770         frame = frame.copy()\r\n\r\nTypeError: can only concatenate list (not \"tuple\") to list\r\n\r\n```\r\n#### Problem description\r\n\r\nThe [documentation](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.melt.html) says that `idvars` and `valuevars` can be tuples, lists, or ndarrays, but it doesn't work if `valuevars` is a tuple. The function works as expected if `valuevars` is given as a list.\r\n\r\n#### Output of ``pd.showversions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.5.1.final.0\r\npython-bits: 64\r\nOS: Darwin\r\nOS-release: 16.4.0\r\nmachine: x8664\r\nprocessor: i386\r\nbyteorder: little\r\nLCALL: None\r\nLANG: None\r\nLOCALE: None.None\r\n\r\npandas: 0.19.2\r\nnose: None\r\npip: 9.0.1\r\nsetuptools: 26.1.1\r\nCython: 0.24.1\r\nnumpy: 1.12.0\r\nscipy: 0.18.0\r\nstatsmodels: 0.6.1\r\nxarray: None\r\nIPython: 5.1.0\r\nsphinx: None\r\npatsy: 0.4.1\r\ndateutil: 2.6.0\r\npytz: 2016.10\r\nblosc: None\r\nbottleneck: None\r\ntables: 3.2.3.1\r\nnumexpr: 2.6.1\r\nmatplotlib: 2.0.0\r\nopenpyxl: None\r\nxlrd: None\r\nxlwt: None\r\nxlsxwriter: None\r\nlxml: None\r\nbs4: None\r\nhtml5lib: None\r\nhttplib2: None\r\napiclient: None\r\nsqlalchemy: 1.0.15\r\npymysql: None\r\npsycopg2: None\r\njinja2: 2.8\r\nboto: None\r\npandasdatareader: None\r\n\r\n</details>\r\n"},
{"text": "#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\nfor i, k in df.resample('W-MON'):\r\n    print(i, k)\r\n```\r\n```sh\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-60-5ca9218261db> in <module>()\r\n----> 1 for i, k in df.resample('W-MON'):\r\n      2     print(i, k)\r\n      3     break\r\n\r\n/xxx/lib/python3.5/site-packages/pandas/core/groupby.py in iter(self)\r\n    629         for each group\r\n    630         \"\"\"\r\n--> 631         return self.grouper.getiterator(self.obj, axis=self.axis)\r\n    632\r\n    633     @Substitution(name='groupby')\r\n\r\nAttributeError: 'NoneType' object has no attribute 'getiterator'\r\n```\r\n#### Problem description\r\ncan't iterate the resampler's key and grouped dataframe\r\n\r\n#### Expected Output\r\niterate the resampler's key and the grouped dataframe, now workaround\r\n```python\r\nfor key in df.resample('W-MON').groups.keys():\r\n  try:\r\n    print(key, df.resample('W-MON').getgroup(key))\r\n  except KeyError:\r\n    continue\r\n```\r\n\r\n#### Output of ``pd.showversions()``\r\n\r\n<details>\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.5.2.final.0\r\npython-bits: 64\r\nOS: Darwin\r\nOS-release: 15.6.0\r\nmachine: x8664\r\nprocessor: i386\r\nbyteorder: little\r\nLCALL: enGB.UTF-8\r\nLANG: enGB.UTF-8\r\nLOCALE: enGB.UTF-8\r\n\r\npandas: 0.19.2\r\nnose: None\r\npip: 9.0.1\r\nsetuptools: 30.2.0\r\nCython: 0.25.2\r\nnumpy: 1.12.0\r\nscipy: 0.18.1\r\nstatsmodels: None\r\nxarray: None\r\nIPython: 5.1.0\r\nsphinx: 1.5.1\r\npatsy: 0.4.1\r\ndateutil: 2.6.0\r\npytz: 2016.10\r\nblosc: None\r\nbottleneck: None\r\ntables: None\r\nnumexpr: None\r\nmatplotlib: 1.5.3\r\nopenpyxl: 2.4.1\r\nxlrd: None\r\nxlwt: None\r\nxlsxwriter: None\r\nlxml: None\r\nbs4: None\r\nhtml5lib: 0.9999999\r\nhttplib2: None\r\napiclient: None\r\nsqlalchemy: None\r\npymysql: None\r\npsycopg2: 2.6.2 (dt dec pq3 ext lo64)\r\njinja2: 2.8\r\nboto: None\r\npandasdatareader: None\r\n</details>\r\n\r\n----\r\nupdate the workaround a bit"},
{"text": "#### Code Sample, a copy-pastable example if possible\r\n\r\n```ipython\r\nIn [1]: import pandas as pd\r\nIn [2]: pd.Timestamp(\"2016-01-01\", tz=\"Europe/Berlin\") - pd.Timestamp(\"now\", tz=\"UTC\")\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-3-691a8df26ecd> in <module>()\r\n----> 1 pd.Timestamp(\"2016-01-01\", tz=\"Europe/Berlin\") - pd.Timestamp(\"now\", tz=\"UTC\")\r\n\r\npandas\\tslib.pyx in pandas.tslib.Timestamp.sub (pandas\\tslib.c:23697)()\r\n\r\nTypeError: Timestamp subtraction must have the same timezones or no timezones\r\n\r\n```\r\n#### Problem description\r\n\r\nIf *both* timestamps have a timezone specified, the result of this operation is perfectly well-defined. It's quite surprising that I have to riddle my code with `lhs.tzconvert(\"UTC\") - rhs.tzconvert(\"UTC\")` lines to get the difference of timestamps.\r\n\r\n#### Expected Output\r\n\r\n    Timedelta('-393 days +06:29:07.057926')\r\n\r\n#### Output of ``pd.showversions()``\r\n\r\n<details>\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.5.2.final.0\r\npython-bits: 64\r\nOS: Windows\r\nOS-release: 7\r\nmachine: AMD64\r\nprocessor: Intel64 Family 6 Model 58 Stepping 9, GenuineIntel\r\nbyteorder: little\r\nLCALL: None\r\nLANG: None\r\nLOCALE: None.None\r\n\r\npandas: 0.19.2\r\nnose: 1.3.7\r\npip: 9.0.1\r\nsetuptools: 27.2.0\r\nCython: 0.25.1\r\nnumpy: 1.11.2\r\nscipy: None\r\nstatsmodels: None\r\nxarray: None\r\nIPython: 5.1.0\r\nsphinx: 1.5.1\r\npatsy: None\r\ndateutil: 2.6.0\r\npytz: 2016.10\r\nblosc: None\r\nbottleneck: None\r\ntables: None\r\nnumexpr: None\r\nmatplotlib: None\r\nopenpyxl: 2.4.0\r\nxlrd: None\r\nxlwt: None\r\nxlsxwriter: 0.9.6\r\nlxml: None\r\nbs4: None\r\nhtml5lib: None\r\nhttplib2: None\r\napiclient: None\r\nsqlalchemy: None\r\npymysql: None\r\npsycopg2: None\r\njinja2: 2.8.1\r\nboto: None\r\npandasdatareader: None\r\n</details>\r\n"},
{"text": "#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\n# Your code here\r\nIn [135]: df = pd.DataFrame({'a': range(10), 'b': range(10)}, \r\n                            index=pd.daterange('2014-01-01', periods=10))\r\n\r\nIn [136]: df.asof('2014-01-15')\r\nOut[136]: \r\na    9\r\nb    9\r\nName: 2014-01-10 00:00:00, dtype: int32\r\n\r\nIn [137]: df.asof('2013-01-15')\r\nOut[137]: nan\r\n```\r\n#### Problem description\r\n\r\nI got tripped up by `[137]` returning a scalar - it makes sense for a `Series`, but not sure it does with a  `DataFrame` lookup?  So maybe it should instead return an empty Series, e.g.\r\n```\r\nIn [138]: df.asof('2013-01-15')\r\nOut[138]: \r\na  NaN\r\nb  NaN\r\ndtype: float64\r\n```\r\n\r\n\r\n#### Output of ``pd.showversions()``\r\n<details>\r\n# Paste the output here pd.showversions() here\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.5.2.final.0\r\npython-bits: 64\r\nOS: Windows\r\nOS-release: 7\r\nmachine: AMD64\r\nprocessor: Intel64 Family 6 Model 78 Stepping 3, GenuineIntel\r\nbyteorder: little\r\nLCALL: None\r\nLANG: None\r\nLOCALE: None.None\r\n\r\npandas: 0.19.0\r\nnose: 1.3.7\r\npip: 8.1.2\r\nsetuptools: 23.0.0\r\nCython: 0.24.1\r\nnumpy: 1.11.2\r\nscipy: 0.18.1\r\nstatsmodels: 0.6.1\r\nxarray: 0.8.2\r\nIPython: 5.1.0\r\nsphinx: 1.3.1\r\npatsy: 0.4.1\r\ndateutil: 2.5.3\r\npytz: 2016.4\r\nblosc: None\r\nbottleneck: 1.1.0\r\ntables: 3.2.2\r\nnumexpr: 2.6.1\r\nmatplotlib: 1.5.3\r\nopenpyxl: 2.3.2\r\nxlrd: 1.0.0\r\nxlwt: 1.1.2\r\nxlsxwriter: 0.9.2\r\nlxml: 3.6.0\r\nbs4: 4.4.1\r\nhtml5lib: 0.999\r\nhttplib2: 0.9.2\r\napiclient: 1.5.3\r\nsqlalchemy: 1.0.13\r\npymysql: None\r\npsycopg2: None\r\njinja2: 2.8\r\nboto: 2.40.0\r\npandasdatareader: 0.2.1\r\n</details>\r\n"},
{"text": "In https://github.com/pandas-dev/pandas/pull/11603#issuecomment-162113949 (the main PR implementing the deferred API for rolling / expanding / ewm), we discussed how to specify table-wise `apply`s. `Groupby.apply(f)` feeds the entire group (all columns) to `f`. For backwards-compatibility, `.rolling(n).apply(f)` needed to be column-wise.\r\n\r\nhttps://github.com/pandas-dev/pandas/pull/11603#issuecomment-162116556 mentions a possible API like what I added for `.style`\r\n\r\n- `axis=0`: apply to each column independently\r\n- `axis=1`: apply to each row independently\r\n- `axis=None`: apply the supplied function to the entire table\r\n\r\nSo it'd be `df.rolling(n).apply(f, axis=None)`.\r\nDo people like the axis=0 / 1 / None idiom? Is it obvious enough?\r\n\r\nThis is prompted by @josef-pkt's [post on the mailinglist](https://groups.google.com/forum/#!topic/pydata/FcAT8LBPmlg). Needing a rolling OLS.\r\n\r\nAn example:\r\n\r\n```python\r\nIn [2]: import numpy as np\r\n   ...: import pandas as pd\r\n   ...:\r\n   ...: np.random.seed(0)\r\n   ...: df = pd.DataFrame(np.random.randint(0, 10, size=(10, 2)), columns=[\"A\", \"B\"])\r\n   ...: df\r\n   ...:\r\nOut[2]:\r\n   A  B\r\n0  5  0\r\n1  3  3\r\n2  7  9\r\n3  3  5\r\n4  2  4\r\n5  7  6\r\n6  8  8\r\n7  1  6\r\n8  7  7\r\n9  8  1\r\n```\r\n\r\nFor a concrete example, get the table-wise max (this is equivalent to `df.rolling(4).max().max(1)`)\r\n\r\n```python\r\nIn [10]: df.rolling(4).apply(np.max, axis=None)\r\nOut[10]:\r\n0    NaN\r\n1    NaN\r\n2    NaN\r\n3    9.0\r\n4    9.0\r\n5    9.0\r\n6    8.0\r\n7    8.0\r\n8    8.0\r\n9    8.0\r\ndtype: float64\r\n```\r\n\r\nA real example is something like a rolling OLS:\r\n\r\n```python\r\nimport statsmodels.api as sm\r\nf = lambda x: sm.OLS.fromformula('A ~ B', data=x).fit()  # wrong, but w/e\r\n\r\ndf.rolling(5).apply(f, axis=None)\r\n```"},
{"text": "It's not an issue in py3.5, but in older versions this is annoying - because a decorator is used in the definition, the function signature on `todatetime` is lost.  This is the big one I've run into, but there may be some other places in the API it comes up.\n![image](https://cloud.githubusercontent.com/assets/1924092/17310153/49ca6d18-5808-11e6-91aa-483ab3458efd.png)\n\nI saw this blog today - could use one of the strategies there.  It may make sense to vendor rather than adding another dependency?\nhttps://hynek.me/articles/decorators/\n"},
{"text": "Currently, the parameter for values that one needs to insert into an array-like object such as `DataFrame` or `Series` is inconsistent across implementations.  For example, `base.py` surfaces it as `key`, whereas `series.py` surfaces it as `v`.\r\n\r\nThis issue was identified while fixing an issue for `v0.18.1` (xref #12413), but in the interests of maintaining backwards compatibility for a minor release, this change should be made as early as `v0.19.0` with the following API comment:\r\n\r\n\"The signature for `searchsorted` has changed. It is now `searchsorted(self, value, side='left', sorter=None)`.\"\r\n\r\nList of functions with signature inconsistencies:\r\n`searchsorted`\r\n`repeat`\r\n\r\n@jreback \r\n@jorisvandenbossche \r\n"},
{"text": "While using master a bit, I discovered some more cases where the new resample API breaks things:\n- Plotting. `.plot` is a dedicated groupby/resample method (which adds each group individually to the plot), while I think it is a very common idiom to quickly resample your timeseries and plot it with (old API) eg `s.resample('D').plot()`. \n  Example with master:\n  \n  ```\n  In [1]: s = pd.Series(np.random.randn(60), index=daterange('2016-01-01', periods=60, freq='1min'))\n  \n  In [3]: s.resample('15min').plot()\n  Out[3]:\n  2016-01-01 00:00:00    Axes(0.125,0.1;0.775x0.8)\n  2016-01-01 00:15:00    Axes(0.125,0.1;0.775x0.8)\n  2016-01-01 00:30:00    Axes(0.125,0.1;0.775x0.8)\n  2016-01-01 00:45:00    Axes(0.125,0.1;0.775x0.8)\n  Freq: 15T, dtype: object\n  ```\n  \n  ![figure1](https://cloud.githubusercontent.com/assets/1020496/13317218/79e8937e-dbb4-11e5-80ad-87e663ef5de8.png)\n  \n  while previously it would just have given you one continuous line. \n  This one can be solved I think by special casing `plot` for `resample` (not have it a special groupby-like method, but let it warn and pass the the `resample().mean()` result to `Series.plot()` like the 'deprecatedvalids')\n- When you previously called a method on the `resample` result that is also a valid Resampler method now. Eg `s.resample(freq).min()` would previously have given you the \"minimum daily average\" while now it will give you the \"minimum per day\". \n  This one is more difficult/impossible to solve I think? As you could detect that case if you know it is old code, but cannot distinguish it from perfectly valid code with the new API. If we can't solve it, I think it deserves some mention in the whatsnew explanation.\n- Using `resample` on a `groupby` object (xref #12202). Using the example of that issue, with 0.17.1 you get:\n  \n  ```\n  In [1]: df = pd.DataFrame({'date': pd.daterange(start='2016-01-01', periods=4,\n  freq='W'),\n  ...:                'group': [1, 1, 2, 2],\n  ...:                'val': [5, 6, 7, 8]})\n  \n  In [2]: df.setindex('date', inplace=True)\n  \n  In [3]: df\n  Out[3]:\n        group  val\n  date\n  2016-01-03      1    5\n  2016-01-10      1    6\n  2016-01-17      2    7\n  2016-01-24      2    8\n  \n  In [4]: df.groupby('group').resample('1D', fillmethod='ffill')\n  Out[4]:\n                  val\n  group date\n  1     2016-01-03    5\n    2016-01-04    5\n    2016-01-05    5\n    2016-01-06    5\n    2016-01-07    5\n    2016-01-08    5\n    2016-01-09    5\n    2016-01-10    6\n  2     2016-01-17    7\n    2016-01-18    7\n    2016-01-19    7\n    2016-01-20    7\n    2016-01-21    7\n    2016-01-22    7\n    2016-01-23    7\n    2016-01-24    8\n  \n  In [5]: pd.version\n  Out[5]: u'0.17.1'\n  ```\n  \n  while with master you get:\n  \n  ```\n  In [29]: df.groupby('group').resample('1D', fillmethod='ffill')\n  Out[29]: <pandas.core.groupby.DataFrameGroupBy object at 0x0000000009BA73C8>\n  ```\n  \n  which will give you different results/error with further operations on that. Also, this case does not raise any FutureWarning (which should, as the user should adapt the code to `groupby().resample('D').ffill()`)\n"},
{"text": "xref #11892 (see changes and discussion)\n\nRangeIndex, a new Int64Index subclass that will be used as the new default index (currently) has the following signature: `RangeIndex(start=None, stop=None, step=None, name=None...)`\n\nFor converting an `xrange`/`range` object into a RangeIndex, we have the constructor `RangeIndex.fromrange`.\n\nAlthough it isn't documented, the current constructor supports accepting a `RangeIndex` instances as the `start` argument, in which case a copy of the original index is produced, e.g., `RangeIndex(RangeIndex(0, 10, 1)) -> RangeIndex(0, 10, 1)`.\n\nI think this is a mistake: it is reusing the `start` parameter for a different type of argument, at odds with the documented behavior and predictable function signatures. If a user wants to create another RangeIndex from a RangeIndex, they can simply use the Index construtor, e.g., `Index(RangeIndex(...))`.\n\n@jreback argues that not accepting a `RangeIndex` as the first argument to `RangeIndex` would be an API break, because it would create an Index constructor that is not idempotent. It would be \"a major break with the current Index design\".\n\nThoughts from anyone else?\n"},
{"text": "From #11497. Found inconsistencyr regarding `fillna` downcasting.\n\nI understand `fillna(downcast=None)` should downcast values appropriately. It doesn't work on `float` dtype.\n\n```\n# NG\npd.Series([1, 2, np.nan, 4]).fillna(3)\n#0    1\n#1    2\n#2    3\n#3    4\n# dtype: float64\n\n# OK\npd.Series([1, 2, np.nan, 4], dtype=object).fillna(3)\n#0    1\n#1    2\n#2    3\n#3    4\n# dtype: int64\n```\n\nBased on the internal logic, `downcast` can accept dtype. It works on `float`, but not on `object`.\n- https://github.com/pydata/pandas/blob/master/pandas/core/internals.py#L366\n\n```\n# OK\npd.Series([1, 2, np.nan, 4]).fillna(3, downcast='int')\n#0    1\n#1    2\n#2    3\n#3    4\n# dtype: int64\n\n# NG\npd.Series([1, 2, np.nan, 4], dtype=object).fillna(3, downcast='int')\n#0    1\n#1    2\n#2    3\n#3    4\n# dtype: object\n```\n\nI understood the expected behavior as below:\n- all dtypes should be downcast by default (downcast=None)\n- if any dtype is passed via `downcast` kw, downcast to the specified dtype if possible. \n- `downcast=False` will not perform downcast. \n- [ ] Add `Index.fillna` to API (follow-up of #11343)\n"},
{"text": "I am currently writing a script to take data from an API and save it to an Excel file for non-technical users who need to access the data. One of the requirements is to have separate date and time column, rather than a single datetime column. \n\nI am using pandas 0.17.0. \n\n``` python\nimport pandas as pd\n\n# creating datetime series\ndates = pd.daterange('2015-01-01 00:00', '2015-01-01 03:00', freq='H')\ndates = pd.Series(dates)\n# setting one record to NaT\ndates.iloc[0] = pd.NaT\n# converting to date \ndates.apply(lambda x: x.date()) # ignores the NaT\n# converting to time\ndates.apply(lambda x: x.time()) # fails with error \"NaTType does not support time\"\n```\n\nI expected NaTType to behave in the same way for converting into a time as it did for a date i.e. returning NaT. \n\nThe full error is: \n\n``` python\n\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n<ipython-input-98-b34fccfc4c06> in <module>()\n      9 dates.apply(lambda x: x.date()) # ignores the NaT\n     10 # converting to time\n---> 11 dates.apply(lambda x: x.time()) # fails with error \"NaTType does not support time\"\n\nC:\\Users\\Nathan\\Anaconda\\lib\\site-packages\\pandas\\core\\series.pyc in apply(self, func, convertdtype, args, **kwds)\n   2158             values = lib.mapinfer(values, lib.Timestamp)\n   2159 \n-> 2160         mapped = lib.mapinfer(values, f, convert=convertdtype)\n   2161         if len(mapped) and isinstance(mapped[0], Series):\n   2162             from pandas.core.frame import DataFrame\n\npandas\\src\\inference.pyx in pandas.lib.mapinfer (pandas\\lib.c:62187)()\n\n```\n"},
{"text": "I find this surprising as the rest of the pandas `Series.str.*` API ignores NaN values.\n\n``` python\nIn [1]: import pandas as pd\n\nIn [2]: import numpy as np\n\nIn [3]: pd.version\nOut[3]: u'0.17.0'\n\nIn [4]: s = pd.Series(['asdf','sdfg',np.nan,'qwer','wert'])\n\nIn [5]: s.str.cat(sep=' ')\nOut[5]: nan\n```\n\nI think this should return\n\n``` python\nIn [5]: s.str.cat(sep=' ')\nOut[5]:'asdf sdfg qwer wert'\n```\n"},
{"text": "The head of my Pandas dataframe , `df`, is shown below:\n\n```\n      count1  count2  totalcount  season\n    0       3      13          16       1\n    1       8      32          40       1\n    2       5      27          32       1\n    3       3      10          13       1\n    4       0       1           1       1\n```\n\nI'd like to make boxplots of `count1`, `count2`, and `totalcount`, grouped by `season` (there are 4 seasons) and have each set of box plots show up on their own subplot in a single figure.\n\nWhen I do this with only two of the columns, say `count1` and `count2`, everything looks great.\n\n```\ndf.boxplot(['count1', 'count2'], by='season')\n```\n\n![enter image description here](http://i.stack.imgur.com/1Jbav.png)\n\nBut when I add `totalcount` to the mix, the axis limits go haywire.\n\n```\ndf.boxplot(['count1', 'count2', 'totalcount'], by='season')\n```\n\n![enter image description here](http://i.stack.imgur.com/Yv74U.png)\n\nThis happens irregardless of the order of the columns. I realize there are several ways around this problem, but it would be much more convenient if this worked properly. I believe this worked as expected in Pandas 0.13.1.\n\nOutput from `pd.showversions()`\n\n```\nINSTALLED VERSIONS\n------------------\ncommit: None\npython: 2.7.7.final.0\npython-bits: 64\nOS: Darwin\nOS-release: 13.2.0\nmachine: x8664\nprocessor: i386\nbyteorder: little\nLCALL: None\nLANG: enUS.UTF-8\n\npandas: 0.14.0\nnose: 1.3.3\nCython: 0.20.1\nnumpy: 1.8.1\nscipy: 0.14.0\nstatsmodels: 0.5.0\nIPython: 2.1.0\nsphinx: None\npatsy: 0.2.1\nscikits.timeseries: None\ndateutil: 2.2\npytz: 2014.4\nbottleneck: None\ntables: 3.1.1\nnumexpr: 2.4\nmatplotlib: 1.3.1\nopenpyxl: None\nxlrd: 0.9.3\nxlwt: None\nxlsxwriter: None\nlxml: None\nbs4: 4.3.2\nhtml5lib: None\nbq: None\napiclient: None\nrpy2: None\nsqlalchemy: 0.9.4\npymysql: None\npsycopg2: 2.5.3 (dt dec pq3 ext)\n```\n"},
{"text": "xref: #7356\n\nAPI like:\n\n``` python\ndf.nlargest('columnname', 3)\n```\n\nimpl like:\n\n``` python\ndef nlargest(self, col, n):\n    return self.loc[self[col].nlargest(n).index]\n```\n\ncc @hayd \n"},
{"text": "``` python\n\nIn [12]: pd.readjson(\"No Such File\")\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n<ipython-input-12-f479cae2f65a> in <module>()\n----> 1 pd.readjson(\"No Such File\")\n\n/home/user1/src/pandas/pandas/io/json.pyc in readjson(pathorbuf, orient, typ, dtype, convertaxes, convertdates, keepdefaultdates, numpy, precisefloat, dateunit)\n    188         obj = FrameParser(json, orient, dtype, convertaxes, convertdates,\n    189                           keepdefaultdates, numpy, precisefloat,\n--> 190                           dateunit).parse()\n    191 \n    192     if typ == 'series' or obj is None:\n\n/home/user1/src/pandas/pandas/io/json.pyc in parse(self)\n    256 \n    257         else:\n--> 258             self.parsenonumpy()\n    259 \n    260         if self.obj is None:\n\n/home/user1/src/pandas/pandas/io/json.pyc in parsenonumpy(self)\n    473         if orient == \"columns\":\n    474             self.obj = DataFrame(\n--> 475                 loads(json, precisefloat=self.precisefloat), dtype=None)\n    476         elif orient == \"split\":\n    477             decoded = dict((str(k), v)\n\nValueError: Expected object or value\n```\n\nreadjson interprets strings which are not filenames as json data, then fails to parse them\nif the filename names a path that doesn't exist (due to typo, or being in wrong directory for example).\n\nThat overloading makes it <del>impossible</del> nasty to distinguish two distinct error cases, e.g. \nmissing file and malformed json. Dubious API choice to my tastes.\n\nin any case, catch both errors and return a saner message \"missing file or malformed input\" etc.\n"},
{"text": "Trying to print a data frame as plain, strict tsv (i.e., no quoting and no escaping, because I know none the fields will contain tabs), I wanted to use the \"quoting\" option, which is documented in pandas and is passed through to csv, as well as the \"quotechar\" option, not documented in pandas but also a csv option. But it doesn't work:\n\n``` python\nIn [1]: import sys, csv\n\nIn [2]: from pandas import DataFrame\n\nIn [3]: data = {'col1': ['contents of col1 row1', 'contents \" of col1 row2'], 'col2': ['contents of col2 row1', 'contents \" of col2 row2'] }\n\nIn [4]: df = DataFrame(data)\n\nIn [5]: df.tocsv(sys.stdout, sep='\\t', quoting=csv.QUOTENONE, quotechar=None)\n\u00a0 \u00a0 \u00a0 \u00a0 col1 \u00a0 \u00a0col2\n0 \u00a0 \u00a0 \u00a0 contents of col1 row1 \u00a0 contents of col2 row1\n---------------------------------------------------------------------------\nError \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Traceback (most recent call last)\n<ipython-input-5-a30d32266fb4> in <module>()\n----> 1 df.tocsv(sys.stdout, sep='\\t', quoting=csv.QUOTENONE, quotechar=None)\n\n/home/brechea/.local/lib/python2.6/site-packages/pandas-0.12.0-py2.6-linux-x8664.egg/pandas/core/frame.pyc in tocsv(self, pathorbuf, sep, narep, floatformat, cols, header, index, indexlabel, mode, nanRep, encoding, quoting, lineterminator, chunksize, tupleizecols, **kwds)\n\u00a0 \u00a01409 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0tupleizecols=tupleizecols,\n\u00a0 \u00a01410 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0)\n-> 1411 \u00a0 \u00a0 \u00a0 \u00a0 formatter.save()\n\u00a0 \u00a01412\n\u00a0 \u00a01413 \u00a0 \u00a0 def toexcel(self, excelwriter, sheetname='sheet1', narep='',\n\n/home/brechea/.local/lib/python2.6/site-packages/pandas-0.12.0-py2.6-linux-x8664.egg/pandas/core/format.pyc in save(self)\n\u00a0 \u00a0 974\n\u00a0 \u00a0 975 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 else:\n--> 976 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 self.save()\n\u00a0 \u00a0 977\n\u00a0 \u00a0 978\n\n/home/brechea/.local/lib/python2.6/site-packages/pandas-0.12.0-py2.6-linux-x8664.egg/pandas/core/format.pyc in save(self)\n\u00a0 \u00a01080 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 break\n\u00a0 \u00a01081\n-> 1082 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 self.savechunk(starti, endi)\n\u00a0 \u00a01083\n\u00a0 \u00a01084 \u00a0 \u00a0 def savechunk(self, starti, endi):\n\n/home/brechea/.local/lib/python2.6/site-packages/pandas-0.12.0-py2.6-linux-x8664.egg/pandas/core/format.pyc in savechunk(self, starti, endi)\n\u00a0 \u00a01098 \u00a0 \u00a0 \u00a0 \u00a0 ix = dataindex.tonativetypes(slicer=slicer, narep=self.narep, floatformat=self.floatformat)\n\u00a0 \u00a01099\n-> 1100 \u00a0 \u00a0 \u00a0 \u00a0 lib.writecsvrows(self.data, ix, self.nlevels, self.cols, self.writer)\n\u00a0 \u00a01101\n\u00a0 \u00a01102 # from collections import namedtuple\n\n/home/brechea/.local/lib/python2.6/site-packages/pandas-0.12.0-py2.6-linux-x8664.egg/pandas/lib.so in pandas.lib.writecsvrows (pandas/lib.c:13871)()\n\nError: need to escape, but no escapechar set\n```\n\nAdding the parameter\n\nquotechar=kwds.get(\"quotechar\")\n\nto the\n\nformatter = fmt.CSVFormatter(...\n\ncall in tocsv(), and doing corresponding changes to format.CSVFormatter()'s **init**() and save(), produces the expected output:\n\n``` python\nIn [1]: import sys, csv\n\nIn [2]: from pandas import DataFrame\n\nIn [3]: data = {'col1': ['contents of col1 row1', 'contents \" of col1 row2'], 'col2': ['contents of col2 row1', 'contents \" of col2 row2'] }\n\nIn [4]: df = DataFrame(data)\n\nIn [5]: df.tocsv(sys.stdout, sep='\\t', quoting=csv.QUOTENONE, quotechar=None)\n        col1    col2\n0       contents of col1 row1   contents of col2 row1\n1       contents \" of col1 row2 contents \" of col2 row2\n```\n\ni.e., unescaped, unquoted tsv.\n\nMore generally, there could be many reasons to want more control of the underlying csv writer, so a generic mechanism (as opposed to adding each param one by one) might be called for (e.g., allowign for a csv dialect object or at least a dictionary holding dialect attributes).\n"},
{"text": "This is and API change in  numpy >= 1.7, but need to work around. Numpy now\nlooks at the structure for a p`rod` method (if the function is not operating on a numpy array), if it has one, then it passes the arguments\n`axis,dtype,out`, currently these types of methods only aceept `axis`, need to accept `dtype,out` as dummy arguments for compat\n\naffects `mean,sum,prod,std`...prob others\n\n```\nIn [1]: df = DataFrame(randn(10,2))\n\nIn [2]: np.prod(df)\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n<ipython-input-2-99feb18ea783> in <module>()\n----> 1 np.prod(df)\n\n/usr/local/lib/python2.7/site-packages/numpy/core/fromnumeric.pyc in prod(a, axis, dtype, out, keepdims)\n   2111             return methods.prod(a, axis=axis, dtype=dtype,\n   2112                                 out=out, keepdims=keepdims)\n-> 2113         return prod(axis=axis, dtype=dtype, out=out)\n   2114     else:\n   2115         return methods.prod(a, axis=axis, dtype=dtype,\n\nTypeError: prod() got an unexpected keyword argument 'dtype'\n\nIn [3]: np.prod(df.values)\nOut[3]: -2.2566177751865827e-07\n\nIn [4]: np.prod(df.values,axis=1)\nOut[4]: \narray([-0.00912739,  0.00569453,  0.58508784,  0.87462665, -0.32556754,\n        0.12015118,  1.01860104, -0.15380337, -0.54518287, -2.5393832 ])\n```\n"},
{"text": "After #3482 is merged, some additional methods to fixup\n- [x] Series.replace (use generic/replace) via f4fe5fd03816deab1dc71e958ebbb4d9c1b9d35d\n- [x] Series align (use generic/align), PR #4800\n- [x] Move Arithmetic/Comparison methods to generic, #4051, #5034\n- [ ] Fillna column wise, #4514\n- [x] Verify Copy for Series (deep=True), #2721, PR #4627\n- [x] Verify that `deep=True` is implemented in `core/internals/copy`, related to #4039, PR #4627\n- [ ] consolidate tests as appropriate to `tests/testgeneric.py` (ones that should have a conforming API, e.g. `replace,filter`) see #4118, (testgeneric is created via #4627)\n- [x] add `AXISLEN` check in `filter`, PR #4855\n- [x] rename consistency between series/frame, see #4605, PR #4627\n- [x] clean up reindex / fix method= issues #4604, PR is #4610\n- [x] interpolation, consolidate `Series/DataFrame` interpolation to \n    `internals.Block.interpolatte`,  #4434, cc @TomAugspurger \n- [x] change setitemwithindexer to use `Block.setitem` (core/indexing), PR #4624\n- [x] move getnumericdata/getbooldata to generic.py PR #4675\n- [x] fix tools/plotting for series sub of NDFrame PR #4675\n- [x] ~~remove use of common/maybeupcastputmask and possiblycastitem~~\n- [x] clip ( see #2747), need to move from frame.py to generic.py (series is ok), PR #4798\n- [x] take ( PR #4757 )\n- [ ] update, #3025\n"},
{"text": "Numpy 1.8 API change in mean?\n\n```\n/home/data/flashsupression/yarik/scripts/utils.pyc in pairedtanal(d, value, testcol, rows, cols, printpt, plots, aggfunc)\n    162     pvalues = np.array(pvalues, ndmin=1)\n    163 \n--> 164     ptpairedt = DataFrame(np.array([np.mean(v0, axis=0),\n    165                                       np.mean(v1, axis=0),\n    166                                       np.mean(v10, axis=0),\n\n/usr/lib/pymodules/python2.7/numpy/core/fromnumeric.pyc in mean(a, axis, dtype, out, keepdims)\n   2481         try:\n   2482             mean = a.mean\n-> 2483             return mean(axis=axis, dtype=dtype, out=out)\n   2484         except AttributeError:\n   2485             pass\n\nTypeError: mean() got an unexpected keyword argument 'dtype'\n```\n\ncomplete \"line\" calling this is\n\n```\n    ptpairedt = DataFrame(np.array([np.mean(v0, axis=0),\n                                      np.mean(v1, axis=0),\n                                      np.mean(v10, axis=0),\n                                      tvalues, pvalues]),\n                            index=Index(['mean(%s)' % lvalues[0],\n                                         'mean(%s)' % lvalues[1],\n                                         'mean effect',\n                                         't-score', 'p-value'],\n                                        name=contrasts),\n                            columns = columns)\n\n```\n\nit used to work before ... did not check for sure yet though if it is pandas or recent numpy upgrade (if I did any)\n\nmore information:\n\n```\nipdb> print a.mean\n<bound method DataFrame.mean of cond                full   profile\nsubject                           \n01jul10sc.dat   1.572131  1.569658\n01oct10cs.dat   1.491370  1.678300\n...\n```\n\nand if to provide ndarray compatibility here then interface should match numpy's where dtype is a valid argument to mean\n"},
{"text": "Creating a pivot table from a DataFrame is easy.\n\n``` python\nIn [17]: df\nOut[17]: \n                 date variable     value\n0 2000-01-03 00:00:00        A  0.528219\n1 2000-01-04 00:00:00        A -0.135071\n2 2000-01-05 00:00:00        A -0.343018\n3 2000-01-03 00:00:00        B -0.097701\n4 2000-01-04 00:00:00        B -1.383248\n\nIn [18]: df.pivot('date', 'variable', 'value')\nOut[18]: \nvariable           A         B\ndate                          \n2000-01-03  0.528219 -0.097701\n2000-01-04 -0.135071 -1.383248\n2000-01-05 -0.343018       NaN\n```\n\nHowever if the index has been set, and there is no column to be set as index, pivot fails. From api point of view, the `index` argument is optional, but in fact it is not.\n\n``` python\nIn [19]: df.setindex('date', inplace=True)\n\nIn [20]: df\nOut[20]: \n           variable     value\ndate                         \n2000-01-03        A  0.528219\n2000-01-04        A -0.135071\n2000-01-05        A -0.343018\n2000-01-03        B -0.097701\n2000-01-04        B -1.383248\n\nIn [21]: df.pivot(columns='variable', values='value')\n---------------------------------------------------------------------------\nKeyError                                  Traceback (most recent call last)\n...\nKeyError: u'no item named None'\n```\n\nOf course one can reset the index before using pivot.\n\n``` python\nIn [22]: df.resetindex().pivot('date', 'variable', 'value')\nOut[22]: \nvariable           A         B\ndate                          \n2000-01-03  0.528219 -0.097701\n2000-01-04 -0.135071 -1.383248\n2000-01-05 -0.343018       NaN\n```\n"},
{"text": "API docs say it is `PUT /contacts/:id/career`\r\n\r\nhttps://www.monicahq.com/api/contacts#update-a-contact-career\r\n\r\nbut it is actually `PUT /contacts/:id/work`\r\n\r\nhttps://github.com/monicahq/monica/blob/47ef3d75a72267098f2e5463bba6dacaf707bc2b/tests/Api/Contact/ApiContactControllerTest.php#L1438\r\n\r\n\r\n\r\n\r\n\r\n"},
{"text": "**Describe the bug**\r\nI tried to use the API endpoint `/api/contacts/:id/contactfields` in parallel (since it's a bit slow...) and I got an error:\r\n\r\n```\r\n500 Internal Server Error\r\n\r\nSQLSTATE[40001]: Serialization failure: 1213 Deadlock found when trying to get lock; try restarting transaction (SQL: delete from `cache` where `key` = laravelcachea67d557b4725645ae52533f2330b47c3e249d758)\r\n```\r\n\r\nWell, when I try again, it usually works, but it's annoying to handle that in a script. Could you please property handle serialization failures in Monica?\r\n\r\nI'm running a local Monica instance (version 2.14.0). So you can be calm that I'm not DOSing your servers :)\r\n"},
{"text": "I'd like to sync the Monica contacts through the JSON API, but I don't see a way to upload a new avatar to Monica.\r\n"},
{"text": "Since #2251 it's not possible to create or update these information with an API call:\r\n| job | string | The job title of the contact. Max 255 characters. |\r\n| company | string | The company which employs the contact. Max 255 characters. |\r\n| foodpreferencies | string | The food preferencies of the contact. Max 100000 characters. |\r\n| firstmetinformation | string | The information (ie where and how) the user has met the contact. Max 1000000 characters. |\r\n| firstmetdate | string | The date you first met the contact. Format: 'YYYY-MM-DD'. |\r\n| firstmetdateisagebased | boolean | Indicates whether the firstmetdate is age based or not. |\r\n| firstmetdateisyearunknown | boolean | Indicates whether we know the year or not. |\r\n| firstmetdateage | integer | The number of years between the firstmetdate and the current year. |\r\n| firstmetthroughcontactid | integer | The contact whose made the introduction to this person. |\r\n| avatarurl | string | The URL of an external image that would serve as the avatar of the contact. Max 400 characters. |\r\n"},
{"text": "Getting reminders via. API has an error in date formatting. \r\nAPI endpoint responds as below,\r\n\r\n```json\r\n{\r\n    \"message\": \"Unexpected data found.\\nUnexpected data found.\\nUnexpected data found.\\nData missing\"\r\n}\r\n```\r\n\r\n##### Important\r\n- Initially, I thought, the error is in my hosted version but tested on https://app.monicahq.com and it occurs there too.\r\n\r\n##### Steps to reproduce\r\n- Create `PersoalAccessToken` from https://app.monicahq.com/settings/api (or make sure you are able to access the API with other methods)\r\n- I am using **PersonalAccessToken**\r\n- Visit `api/reminders` endpoint with your accessToken.\r\n- You should get above error(If you have at least 1 reminder in future) I have just 1 reminder.\r\n- Try to access other resources e.g. `api/contacts`, that works perfectly.\r\n- A stack trace is attached to this issue. \r\n\r\n**Which version are you using:**\r\n - Hosting version 2.12.1 (app.monicahq.com)\r\n - My server-hosted version 2.12.0\r\n\r\n**Additional context**\r\n[monica-api-stacktrace.log](https://github.com/monicahq/monica/files/3028901/monica-api-stacktrace.log)\r\n\r\n"},
{"text": "I've written an API importer for my tags from a previous CRM, and noticed a strange behavior when getting ready to run it on my data.\r\n\r\nIn the API docs for Tags, it says setTags should not affect existing tags, simply add new ones if needed.\r\n\r\n<img width=\"434\" alt=\"personal crm - monica api documentation 2018-11-29 20-29-03\" src=\"https://user-images.githubusercontent.com/1626189/49268655-9240a200-f415-11e8-8b17-3a3463adf83f.png\">\r\n\r\nHowever, when calling setTags from the API, I observed different behavior. Here's an example before:\r\n\r\n![image](https://user-images.githubusercontent.com/1626189/49268684-be5c2300-f415-11e8-826f-ac1e9ee567b3.png)\r\n\r\nand after\r\n\r\n<img width=\"353\" alt=\"aftersettags\" src=\"https://user-images.githubusercontent.com/1626189/49268690-c4520400-f415-11e8-8e13-5e6e72742a54.png\">\r\n\r\nNote that the latter two tags have disappeared.\r\n\r\nAdditionally, [in the relevant controller](https://github.com/monicahq/monica/blob/1f65b18a3c47b962fbc5b31eca93031ffeb85821/app/Http/Controllers/Api/ApiContactTagController.php), a comment in line 28 explicitly refers to detaching existing tags.\r\n\r\nPlease let me know when you have a chance to correct this behavior, so that I can run my importer nondestructively. Thanks for making such a great tool - I'm excited to have my full data in there!"},
{"text": "I'm trying to create a contact via the API on the hosted version at app.monicahq.com, following the documentation here: https://www.monicahq.com/api/contacts\r\n\r\nAccording to the docs, I can send `\"gender\" : \"male\"` to POST /contacts but the API expects a genderid instead. Since there's no API to retrieve available gender IDs I don't know any valid value for this, so I cannot create a contact through the API.\r\n\r\nAlso, the API expects isstarred, which is not documented.\r\n\r\nAlso, the error messages for missing genderid and isstarred are in Arabic."},
{"text": "I cannot connect to the API when running Monica locally through Docker. All requests are being redirect to `/login` (see below). I installed the key files with `php artisan passport:install` and was also able to generate a personal access token through the web gui.\r\n\r\nAll is working fine with the app.monicahq.com hosted version. (I realize there is a cookie being set in the hosted version also for api calls, in contrast to the local one. But I think the cookie is unrelated to this issue, since I can also connect to the hosted version without sending the cookie back.)\r\n\r\nResponse:\r\n```\r\nHTTP/1.1 302 Found\r\nDate: Sun, 31 Dec 2017 18:28:35 GMT\r\nServer: Apache/2.4.27 (Unix)\r\nX-Powered-By: PHP/7.1.9\r\nCache-Control: no-cache, private\r\nLocation: http://monica.xyz.com/login\r\nContent-Length: 376\r\nConnection: close\r\nContent-Type: text/html; charset=UTF-8\r\n\r\n<!DOCTYPE html>\r\n<html>\r\n    <head>\r\n        <meta charset=\"UTF-8\" />\r\n        <meta http-equiv=\"refresh\" content=\"0;url=http://monica.xyz.com/login\" />\r\n\r\n        <title>Redirecting to http://monica.xyz.com/login</title>\r\n    </head>\r\n    <body>\r\n        Redirecting to <a href=\"http://monica.xyz.com/login\">http://monica.xyz.com/login</a>.\r\n    </body>\r\n</html>\r\n```\r\n\r\nRequest:\r\n```\r\ncurl \"http://monica.xyz.com/api/contacts\" \\\r\n     -H 'Authorization: Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImp0aSI6IjU5ZTA3NjBlM2FiNGZlMjNhYThlMGU3Yjg3NjA4MDc5MmM3MjJkMWRkZGMxNTQ0MDVkMjE2ZTI4YTBlODk4ZTYxNzdmNWY4MjhiNTI4MDM0In0.eyJhdWQiOiIxIiwianRpIjoiNTllMDc2MGUzYWI0ZmUyM2FhOGUwZTdiODc2MDgwNzkyYzcyMmQxZGRkYzE1NDQwNWQyMTZlMjhhMGU4OThlNjE3N2Y1ZjgyOGI1MjgwMzQrLCJpYXQiOjE1MTQ3MzMwMDYsIm5iZiI6MTUxNDczMzAwNiwiZXhwIjoxNTQ2MjY5MDA2LCJzdWIiOiIxIiwic2NvcGVzIjpbXX0.NZK397HKORi1lTAGjS2oV6AjPqgE2mrTbb6xwhj38EAs0rXa-ZEYEQS3ptAEelNXXt6hf5ts7ZWnh5UqfoAsESqwHZzVddIksMzgXN1BgDdKQGmWGAfkhSCKMYsBtyqkpH8vrkpK0iIlNXmQ9-vuMjKGlEW8ynXec2DNQQyIJF1Wjlx3bipamIIrJC1s2CKOVFfjvYjiIKklETaMUctO-F37OgM5UTyl4wp1eDvwtdHVyXXUj0HrMQzm00NLt0b19YSg9rQJeElvokAcg1mdvCtOh6lO230cpeWKJITZ0UbGyzkL-q6jhBDTWvXVVNTVaoEQg7Sw0CaxBJwEQL4NcxgZ0bChX01LD4WfcIduYtEzHE3M4m1KaJaDo3RJlDUaFoPneckS41MASCilv1pYY1aCLQb6lWlfuNdF72qaF17ajRiVAq2RmYExW1YrPbZ-F5ZeGfiteLA5HUZ2QCVSFXlemGDlx-0acBtLZBISXLrxlLA6eQV-3EPbtf45izpW8UZmS3NyOMfAO7uxue7IQSCd9nJ3oP3BpDM64uh-3Ld8BBRt038WiPe4kON3f7yy2VW-LgvDl3B0ew3AmyJ5qPeps2yKAwIGjuzZYOpFIJgDAZhjRqhMJosdR9SswQhCamN1qrZs8VNpPL39ktXEhf3kPBHpX7EQ'\r\n```"},
{"text": "We've recently added the pets management. We don't have an API for that yet."},
{"text": "In 1.4 we've added the journal entries table. But we have no API methods for it."},
{"text": "### Operating system\r\n\r\n<!-- Please only leave those relevant to your request -->\r\n\r\n- macOS\r\n\r\n### Application\r\n\r\n<!-- Please only leave those relevant to your request -->\r\n\r\n- Desktop\r\n\r\n---\r\n\r\nI've just noticed that the API command to delete resources does not delete the resources from the sync target. Only the meta data files are deleted from the sync target.\r\n\r\nThis is the command I used:\r\n\r\n```\r\ncurl -X DELETE http://localhost:41184/resources/ecfef68586324b6a88149f651af58068?token=TOKEN\r\n```\r\n\r\nAfter syncing `ecfef68586324b6a88149f651af58068.md` is removed from the sync target, but `.resources/ecfef68586324b6a88149f651af58068` still remains."},
{"text": "https://discourse.joplin.cozic.net/t/api-error-500/1480"},
{"text": "Hi, the API isn't working as expected.\r\n\r\nI'm assuming the status query should be int as that's what is being returned.\r\n\r\nPlease help!\r\n\r\n```\r\n$ http -v https://demo.cachethq.io/api/v1/incidents componentId==1 X-Cachet-Token:\"9yMHsdioQosnyVK4iCVR\" status==1\r\nGET /api/v1/incidents?componentId=1&status=1 HTTP/1.1\r\nAccept: */*\r\nAccept-Encoding: gzip, deflate\r\nConnection: keep-alive\r\nHost: demo.cachethq.io\r\nUser-Agent: HTTPie/0.9.9\r\nX-Cachet-Token: 9yMHsdioQosnyVK4iCVR\r\n\r\n\r\n\r\nHTTP/1.1 500 Internal Server Error\r\nCF-RAY: 4fd020501d23a9d0-SIN\r\nCache-Control: no-cache, private\r\nConnection: keep-alive\r\nContent-Type: application/json\r\nDate: Sat, 27 Jul 2019 16:52:52 GMT\r\nExpect-CT: max-age=604800, report-uri=\"https://report-uri.cloudflare.com/cdn-cgi/beacon/expect-ct\"\r\nServer: cloudflare\r\nSet-Cookie: cfduid=d09ee393ca2c4ea7448ced3192077c2fc1564246371; expires=Sun, 26-Jul-20 16:52:51 GMT; path=/; domain=.cachethq.io; HttpOnly\r\nTransfer-Encoding: chunked\r\n\r\n{\r\n    \"errors\": [\r\n        {\r\n            \"detail\": \"An error has occurred and this resource cannot be displayed.\",\r\n            \"id\": \"7d810996-8320-457b-844e-554d5e80e799\",\r\n            \"status\": 500,\r\n            \"title\": \"Internal Server Error\"\r\n        }\r\n    ]\r\n}\r\n```"},
{"text": "Developing a POC for my office to make use of cachet and we're testing the API functionality.\r\n\r\nI'm getting a 404 response when trying to create an update:\r\n\r\nGET incident snippet:\r\n```        \r\n{\r\n            \"id\": 5,\r\n            \"componentid\": 0,\r\n            \"name\": \"API Test Incident 3\",\r\n            \"status\": 2,\r\n            \"message\": \"API Test Incident 3\",\r\n            \"createdat\": \"2019-01-22 14:00:00\",\r\n            \"updatedat\": \"2019-01-22 14:00:00\",\r\n            \"deletedat\": null,\r\n            \"scheduledat\": \"2019-01-22 13:41:50\",\r\n            \"visible\": 1,\r\n            \"humanstatus\": \"Identified\"\r\n        } \r\n```\r\n\r\nPOST Incident update creation\r\n``` \r\nhttp://localhost/api/v1/incidents/5/updates\r\n```\r\n``` \r\nContent-Type:application/json\r\nX-Cachet-Token:<REMOVED> \r\n```\r\n``` \r\n{\r\n    \"status\": 2,\r\n    \"message\": \"update test\"\r\n} \r\n```\r\n\r\nAnd the response:\r\n``` \r\n{\r\n    \"errors\": [\r\n        {\r\n            \"id\": \"c352ccfe-a7e7-4a1f-b7bd-05fb8ca5106e\",\r\n            \"status\": 404,\r\n            \"title\": \"Not Found\",\r\n            \"detail\": \"The requested resource could not be found but may be available again in the future.\"\r\n        }\r\n    ]\r\n} \r\n```"},
{"text": "I am trying to utilise the still undocumented Maintenances API. I tried to infer the correct parameters, but I nearly always get the bad HTTP request error with a description of trailing data.\r\n\r\nCan someone provide me with the needed parameters and their format in order to make a successful API call?"},
{"text": "Hi.\r\nIs there Swagger / OpenAPI json file available? Or endpoint with it? I found discussion about generating docs only but no json file with API description. \r\n\r\nThanks "},
{"text": "I have to create a new issue for this problem since issue #2947 is being automatically closed without the author input. For me this seems pretty simple to reproduce: Call OPTIONS https://demo.cachethq.io//api/v1/components from Postman with Access-Control-Request-Method set to GET and Origin set to a web site url. Observe that there is no Access-Control-Allow-Origin header, thereby effectively making it impossible to use from an external web site.\r\n\r\nOriginally posted by @palktonderAtpowelno in https://github.com/CachetHQ/Cachet/issues/2947#issuecomment-452217255"},
{"text": "Hi,\r\n\r\nWhen using the API to create an incident I'm getting an error 500 and the following error message in the log:\r\n\r\nNext Illuminate\\Database\\QueryException: SQLSTATE[42S22]: Column not found: 1054 Unknown column 'notify' in 'where clause' (SQL: select count(*) as aggregate from `incidents` where `visible` >= 1 and (`name` = test incident and `message` = This is a test incident created via API calls and `status` = 1 and `visible` = 1 and `notify` = 1) and `incidents`.`deletedat` is null)\r\n\r\nI'm running 2.4.0-dev\r\nany suggestions?\r\n\r\nJay"},
{"text": "When I make an API call to a component the updatedat field only updates to the current time if the status actually changes - i.e. If I send a request to update a component from Operational to Operational the updateat timestamp does not change.\r\n\r\nI have automated monitoring setup to update the components status regularly, and I want the timestamp to reflect the most recent time the component was checked.\r\n\r\nThe other option would be to send a PUT request to manually change the updatedat field with the current time, however when I do this it causes the status to be set to 'cachet.components.status.0' and doesn't even update the time field.\r\n\r\nExample:\r\nCall: `[2018-12-13 13:22.54] curl -X PUT http://status.domain.com/api/v1/components/4 -H \"Content-type: application/json\" -H \"X-Cachet-Token: <token omitted>\" -d \"{\\\"updatedat\\\":date +%s}\"`\r\nResult:\r\n`{\"data\":{\"id\":4,\"name\":\"Component Four\",\"description\":\"\",\"link\":\"https:\\/\\/www.component-four.com\",\"status\":0,\"order\":0,\"groupid\":1,\"createdat\":\"2018-12-12 15:13:15\",\"updatedat\":\"2018-12-13 13:22:42\",\"deletedat\":null,\"enabled\":true,\"statusname\":\"cachet.components.status.0\",\"tags\":[]}} `\r\n\r\nEDIT: Already reached out on slack and was told to raise an issue, also I see there was a similar issue raised on here but it was closed with no resolution"},
{"text": "**Description**\r\n\r\nThe OpenAPI allows to generate automatically clients for various languages. There are however some unresolved problems with some of the constructs in the Open API - for example oneOf with single schema produces uncompilable code  despite being correct specification. Another example is \"key\" generic name of parameter, which in Java code might cause compilation problems in some cases as \"key\" variable name is used internally in generated methods.\r\n\r\nWe would like to make sure that our OpenAPI specification produces compilable and usable clients when auto-client generation is used.  This can be easily setup as a CI step.\r\n\r\n**Use case / motivation**\r\n\r\nWe want our customers to have very easy path in using the API. Being able to use pre-generated client API in their favorite language can save many days of work for integration.\r\n\r\nCI building the API clients + API clients published as artifacts are great way to achieve that consistently.\r\n\r\n**Related Issues**\r\n#7549 \r\n\r\n"},
{"text": "**Description**\r\n\r\nThere is no endpoint to check if the instance is in good condition\r\n\r\nWe need to prepare the change to the API specification and then implement this change.\r\n\r\nMore information about API Endpoints:\r\nhttps://github.com/apache/airflow/issues/8118\r\n\r\n**Use case / motivation**\r\n\r\nN/A\r\n\r\n**Related Issues**\r\n\r\nN/a"},
{"text": "The following POST-only routes return an empty body when requested with GET. Instead they should return an error message:\r\n\r\n* https://chat.zulip.org/accounts/logout/\r\n* https://chat.zulip.org/accounts/register/\r\n* https://chat.zulip.org/json/subscriptions/exists\r\n* https://zulip.com/json/remotes/server/register\r\n* https://chat.zulip.org/api/v1/devfetchapikey\r\n\r\nAll of these seem to be caused by using the `@requirepost` decorator, without restricting the route to `POST` in `zerver/urls.py`.\r\n\r\nAn example of where a body is returned as expected is:\r\n\r\n* https://chat.zulip.org/json/fetchapikey"},
{"text": "While working on #15899, we discovered that a few internal fields in the message event handling system are incorrectly being leaked to clients.  The details on the fields are here: dbde901684ae67eeed67de14ac699fb430082479.\r\n\r\nWhat's going on is that we're somewhat sloppily attaching values to event objects in order to pass data around internal to `zerver/tornado/eventqueue.py` logic -- but then not removing those values before\r\n\r\nThere's no security issue here, because the values are mostly data the client could know.  And arguably for the `pushnotified` bundle of fields, it'd arguably be reasonable to expose them to clients as a useful hint -- except for the fact that we have no guarantee of a value of False correct since push notifications could be triggered later on via `missedmessagehook`.  For that reason, we should just remove them from the API.\r\n\r\nSpecifically, the fields are:\r\n* `handlerid`: An internal tracking value for an open HTTP connection.\r\n* pushnotified`: Internal booleans used to keep track of whether a push notification has been sent for the purposes of sending additional ones.  \r\n\r\nI'm not sure what the best way to handle these is; @showell might have ideas.  One option would be to make `contents()` return a copied data structure with these fields explicitly excluded (or a whitelist of included fields).\r\n"},
{"text": "Similar to https://github.com/zulip/zulip/issues/14481, when a user clicks the \"mark stream as read\" option in the left sidebar, we don't presently provide any feedback that we're working on it.  As a result, if there are many thousands of matching messages, the user is likely to think it didn't work, retry, and then that second HTTP request will probably fail after a deadlock with the first, spamming our server-side error logs.\r\n\r\nWe can prevent this through showing a loading indicator over the unread count for the stream until the HTTP request finishes (Well, that might be super ugly, but we should do something visible).\r\n\r\nAnd then there's probably a backend change to make such a fast duplicate request not deadlock/500 as well, though I'm not sure what that needs to be.\r\n\r\nThe exception we get is this mess: \r\n\r\n```\r\n  File \"./zerver/decorator.py\", line 589, in wrappedfuncarguments\r\n    raise err\r\n  File \"./zerver/decorator.py\", line 574, in wrappedfuncarguments\r\n    return targetviewfunc(request, profile, *args, **kwargs)\r\n  File \"./zerver/decorator.py\", line 789, in wrappedfunc\r\n    return func(request, *args, **kwargs)\r\n  File \"./zerver/lib/request.py\", line 368, in wrappedviewfunc\r\n    return viewfunc(request, *args, **kwargs)\r\n  File \"./zerver/views/messages.py\", line 1156, in markstreamasread\r\n    count = domarkstreammessagesasread(userprofile, request.client, stream)\r\n  File \"./zerver/lib/actions.py\", line 4251, in domarkstreammessagesasread\r\n    flags=F('flags').bitor(UserMessage.flags.read)\r\n  File \"/srv/zulip-venv-cache/5f67b9220527f4792938295885923757cc6301b9/zulip-py3-venv/lib/python3.6/site-packages/django/db/models/query.py\", line 741, in update\r\n    rows = query.getcompiler(self.db).executesql(CURSOR)\r\n  File \"/srv/zulip-venv-cache/5f67b9220527f4792938295885923757cc6301b9/zulip-py3-venv/lib/python3.6/site-packages/django/db/models/sql/compiler.py\", line 1462, in executesql\r\n    cursor = super().executesql(resulttype)\r\n  File \"/srv/zulip-venv-cache/5f67b9220527f4792938295885923757cc6301b9/zulip-py3-venv/lib/python3.6/site-packages/django/db/models/sql/compiler.py\", line 1133, in executesql\r\n    cursor.execute(sql, params)\r\n  File \"/srv/zulip-venv-cache/5f67b9220527f4792938295885923757cc6301b9/zulip-py3-venv/lib/python3.6/site-packages/django/db/backends/utils.py\", line 67, in execute\r\n    return self.executewithwrappers(sql, params, many=False, executor=self.execute)\r\n  File \"/srv/zulip-venv-cache/5f67b9220527f4792938295885923757cc6301b9/zulip-py3-venv/lib/python3.6/site-packages/django/db/backends/utils.py\", line 76, in executewithwrappers\r\n    return executor(sql, params, many, context)\r\n  File \"/srv/zulip-venv-cache/5f67b9220527f4792938295885923757cc6301b9/zulip-py3-venv/lib/python3.6/site-packages/django/db/backends/utils.py\", line 84, in execute\r\n    return self.cursor.execute(sql, params)\r\n  File \"/srv/zulip-venv-cache/5f67b9220527f4792938295885923757cc6301b9/zulip-py3-venv/lib/python3.6/site-packages/django/db/utils.py\", line 89, in exit\r\n    raise djexcvalue.withtraceback(traceback) from excvalue\r\n  File \"/srv/zulip-venv-cache/5f67b9220527f4792938295885923757cc6301b9/zulip-py3-venv/lib/python3.6/site-packages/django/db/backends/utils.py\", line 84, in execute\r\n    return self.cursor.execute(sql, params)\r\n  File \"./zerver/lib/db.py\", line 31, in execute\r\n    return wrapperexecute(self, super().execute, query, vars)\r\n  File \"./zerver/lib/db.py\", line 18, in wrapperexecute\r\n    return action(sql, params)\r\ndjango.db.utils.OperationalError: deadlock detected\r\nDETAIL:  Process 19245 waits for ShareLock on transaction 1337553386; blocked by process 19483.\r\nProcess 19483 waits for ShareLock on transaction 1337553388; blocked by process 19245.\r\nHINT:  See server log for query details.\r\nCONTEXT:  while updating tuple (5452156,93) in relation \"zerverusermessage\"\r\n```"},
{"text": "- Zulip version: 2.1.0-5-g49ff894d6a\r\n- OS version: Ubuntu 18.04.3 LTS (bionic)\r\n\r\nWe currently have some seemingly strange problems by using Zulip API with message IDs (e.g. with message deletion).\r\n\r\nInitially we created a new (generic) bot in Zulip and enabled message deletion as described (https://zulipchat.com/help/configure-message-editing-and-deletion). On this way we are able to successfully send messages (which also then are shown up correctly in Zulip web/desktop/mobile client):\r\n\r\n```\r\ncurl -X POST https://zulip.domain.com/api/v1/messages \\\r\n    -u alert-bot@zulip.domain.com:APIKEY \\\r\n    -d \"type=stream\" \\\r\n    -d \"to=Alert\" \\\r\n    -d \"subject=Test\" \\\r\n    -d $\"content=TEST - Event ID #5000\"\r\n\r\n{\"result\":\"success\",\"msg\":\"\",\"id\":78539}\r\n```\r\n\r\nBut strangely it is not possible to get the message or to delete it via API by using the (correct) message ID:\r\n\r\n```\r\ncurl -sSX GET -G https://zulip.domain.com/api/v1/messages/78539 \\\r\n    -u alert-bot@zulip.domain.com:APIKEY\r\n\r\n{\"result\":\"error\",\"msg\":\"Invalid message(s)\",\"code\":\"BADREQUEST\"}\r\n```\r\n```\r\ncurl -sSX DELETE https://zulip.domain.com/api/v1/messages/78539 \\\r\n    -u alert-bot@zulip.domain.com:APIKEY\r\n\r\n{\"result\":\"error\",\"msg\":\"Invalid message(s)\",\"code\":\"BADREQUEST\"}\r\n```\r\n\r\nWe get then a BADREQUEST (400) error - which seem to related to a user indicated \"invalid/unknown\" message id (https://zulipchat.com/api/rest-error-handling).\r\n\r\nSo it seems that the message ID does not exist - but it is possible to query for the correct message (with narrow: https://zulipchat.com/api/construct-narrow) and this shows that the message ID actually exists indeed:\r\n\r\n```\r\ncurl -sSX GET -G https://zulip.domain.com/api/v1/messages \\\r\n    -u alert-bot@zulip.domain.com:APIKEY \\\r\n    -d 'usefirstunreadanchor=true' \\\r\n    -d 'numbefore=1000' \\\r\n    -d 'numafter=1000' \\\r\n    --data-urlencode narrow='[{\"operator\": \"stream\", \"operand\": \"Alert\"}, {\"operator\": \"sender\", \"operand\": \"alert-bot@zulip.domain.com\", \"negated\": false}, {\"operator\": \"search\", \"operand\": \"#5000\"}]'\r\n\r\n{\"result\":\"success\",\"msg\":\"\",\"messages\":[{\"id\":78539,\"senderid\":49,\"content\":\"<p>TEST - Event ID #5000<\\/p>\",\"recipientid\":152,\"timestamp\":1578002626,\"client\":\"curl\",\"subject\":\"Test\",\"subjectlinks\":[],\"ismemessage\":false,\"reactions\":[],\"submessages\":[],\"flags\":[\"read\",\"historical\"],\"matchcontent\":\"<p>TEST - Event ID #<span class=\\\"highlight\\\">5000<\\/span><\\/p>\",\"matchsubject\":\"Test\",\"senderfullname\":\"Alert\",\"sendershortname\":\"alert-bot\",\"senderemail\":\"alert-bot@zulip.domain.com\",\"senderrealmstr\":\"\",\"displayrecipient\":\"Test\",\"type\":\"stream\",\"streamid\":105,\"avatarurl\":\"https:\\/\\/secure.gravatar.com\\/avatar\\/0ebefs3b5d3581f24cf8d3fad67ac760?d=identicon&version=1\",\"contenttype\":\"text\\/html\"}],\"foundanchor\":false,\"foundoldest\":true,\"foundnewest\":true,\"historylimited\":false,\"anchor\":10000000000000000}\r\n```\r\n\r\nIn the Zulip logs we didn't found any helpful information in this context. For us it is currently not understandable where exactly the problem source lies - and we would be grateful for every hint..."},
{"text": "as I'm diving a bit deeper in using the API, I realised when testing against `chat.zulip.org`, that the request to get my stream subscriptions is ~10x slower than getting all streams.\r\n\r\nfor comparison: \r\n`https://chat.zulip.org/api/v1/streams`    **0.28s**\r\n`https://chat.zulip.org/api/v1/users/me/subscriptions`    **2.18s**\r\n\r\nis such a large performance difference expected?\r\n"},
{"text": "the REST API is not usable from within a browser without CORS allowed...\r\n\r\nare there reasons to not allow it ?"},
{"text": "While developing zulip-terminal, we noticed two different forms of reactions data being sent:\r\n* events have a `user` dict with a `userid` entry (and others)\r\n* messages have a `user` dict with an `id` entry\r\n\r\nThis was reported as issue zulip/zulip-terminal#334.\r\n\r\nI initially suggested simply migrating to add `id` in the event. However, to satisfy a long-term goal of reducing user info and bandwidth @showell suggested we could move to a `userid` entry in both places, instead of a fuller `user` dict.\r\n\r\nThe relevant discussion is below:\r\nhttps://chat.zulip.org/#narrow/stream/49-development-help/topic/reactions.3A.20id.20.26.20userid.20keys/near/662711\r\n\r\nNo decision was made in the discussion, but as it stands it's a bit of an unexpected issue for those using the messages and reaction-event APIs, where the keys don't match."},
{"text": "The mobile app's PMs screen shows the PM conversations we've been in recently, but \"recently\" may be as few as the last 100 PM messages. For a user that heavily uses PMs, this can leave out conversations even from a day or two ago.  One user reported an example as a typical experience: they're looking for a specific conversation, and the last message in it was 3pm yesterday. It's 3:30pm at the time they look, just over 24hr later. It doesn't show up on the PMs screen, though 6 other conversations do.\r\n\r\nThis is a data issue -- the mobile app doesn't have a convenient way to query these data.\r\n\r\nWith in part this issue in mind, the Zulip backend as of Zulip 1.9 added a nice database index for PMs that a given user has received; so we can very quickly do queries on that data.\r\n\r\nThe really dumb version that could be done with the API today would be to do a GET /messages is:private narrow query, but that would be a lot of data over the network. Probably what we should actually do is write a function similar to the \"more topics\" function that takes advantage of this index to get you e.g. the (PM recipient User ID list, lastmessageid) tuples covering e.g. the last 1K PMs you've had, which probably is a <10ms query on the database end, and either include the data in /register or a separate endpoint (depending what's better for mobile's architecture); I expect it'd be <1hr work for me to add backend support for this if we had confirmation of what format the mobile app wanted. And the app should be able to maintain that data set after /register as new messages come in, since it's basically just \"look up the useridlist, and bump the lastmessageid\".\r\n\r\n(Until the database index work in 1.9, this would have been prohibitively expensive, since we'd need to scan all messages to find enough PMs, which for low-PM users in an organization with a lot of streams traffic could have easily involved the database needing to look at 50K+ messages of history and thus adding 100sms of latency).\r\n\r\nI don't think this data set would need unreads data, since the client should have that and be able to splice it in directly and it's probably cleaner to have one source of truth there, but it wouldn't be hard to include.\r\n\r\nDiscussion in https://github.com/zulip/zulip-mobile/issues/3133 suggests we should use a dict data structure, not a tuple, e.g.\r\n```\r\n[{\r\n    userids: [1, 2, 3],\r\n    lastmessageid: 23451,\r\n    ...\r\n}]\r\n```\r\n\r\nI think the query we'll want is roughly UserMessage.objects.filter(userprofile=userprofile, flags=UserMessage.flags.isprivate).orderby(\"-id\")[0:1000] will get the conversations we want, and then we just need to format the data.\r\n\r\nWe also need a name for the data structure; maybe `recentconversations` is good enough.\r\n\r\nThe super optimized version of the key database query is this:\r\n```\r\nzulip=> select sub.recipientid, max(sub.messageid) from (select um.messageid as messageid, m.recipientid as recipientid from zerverusermessage um join zervermessage m on um.messageid = m.id where um.userprofileid=8683 and um.flags & 2048 <> 0 order by messageid desc limit 1000) as sub group by sub.recipientid;\r\n\r\n-----------\r\nor spelled in Python:\r\n\r\nquery = '''\r\nSELECT                                             \r\n    subquery.recipientid, max(subquery.messageid)\r\nFROM (                                             \r\n    SELECT                                         \r\n        um.messageid as message.id                \r\n        m.recipientid as recipientid             \r\n    FROM                                           \r\n        zerverusermessage um                      \r\n    JOIN                                           \r\n        zervermessage m                           \r\n    ON                                             \r\n        um.messageid = m.id                       \r\n    WHERE                                          \r\n        um.userprofileid=%d AND                  \r\n        um.flags & 2048 <> 0                       \r\n    ORDER BY messageid DESC                       \r\n    LIMIT %d                                       \r\n) AS subquery                                      \r\nGROUP BY subquery.recipientid                     \r\n''' % (userprofile.id, RECENTCONVERSATIONSCOUNT)\r\n```\r\n\r\nhowever, that has a bug, namely that it misses 1:1 PMs sent directly to the current user."},
{"text": "Currently, most API users will have to do that manually to ensure that they don't have to download extra payload, which means, people have to be aware of such in the first place. If the default is `True`, then the \"error\" encountered by GUI-based API users will be explicit and can be mitigated early on.\r\n\r\nThe only complication with the migration is that legacy clients are not aware of `clientgravatar` in the first place.\r\n\r\nSpawned from https://github.com/zulip/zulip-terminal/issues/219."},
{"text": "@borisyankov helped me discover a subtle bug where `usefirstunreadanchor` and `includehistory` don't interact correctly in a situation where the only messages on a topic were before the current user subscribed to that stream.  Basically if you set things up like this:\r\n* Send a single message to a new topic \"test\" to a public stream Hamlet is not subscribed to (\"Denmark\" in this example).\r\n* Subscribe hamlet to that stream\r\n* Do the API query the mobile app does to try to view topic \"test\". (e.g. stream Denmark, topic \"test\", usefirstunreadanchor=True, anchor=0, numbefore=25, numafter=25).  Then the API query will return 0 messages (!).  So effectively one sees messages in the webapp, but none appear on mobile.\r\n\r\nHere's how this happens:\r\n* Because `usefirstunreadanchor` is True, we end up going down the non-`includehistory` code path in `getmessagesbackend` and thus joining with UserMessage.  The user has 0 rows for that topic in UserMessage (since they weren't subscribed when the message was sent), so everything from there on returns no messages.\r\n\r\nWhat we should actually be doing is in `getmessagesbackend`:\r\n* The main query should just be on `Message` (i.e. we should get rid of the `and not usefirstunreadanchor` part of the `includehistory` line)\r\n* In the `usefirstunreadanchor` code block, we should check `includehistory`, and if True, we do the join against UserMessage in constructing `firstunreadquery`, since we do need that join for getting the first unread message ID (just not for fetching the messages themselves, i.e. no changes to the main query).  This should require a moderately sized refactor.\r\n* The rest of the code path correctly splits the logic based on whether `includehistory` is True (i.e. does a UserMessage query to splice in the `flags` data as needed).\r\n\r\n@showell since you were just in this code, would you be up for tackling this in the next day or so?  Ideally we'd have a fix in before the 1.8 release (aka Monday).\r\n"},
{"text": "We just moved our documentation for writing bots into /api in #7392; this lists some CSS bugs \r\n\r\n* [ ] The multi-line bold section here is oddly not wrapped automatically:\r\n![image](https://user-images.githubusercontent.com/2746074/32851853-0b1664fe-c9eb-11e7-8a4d-b7f47eaa2270.png)\r\n* [ ] The pagedown key on /api/writing-bots moves much less than one would expect.\r\n* [ ] This multi-line code block looks wrong:\r\n![image](https://user-images.githubusercontent.com/2746074/32851837-fc989118-c9ea-11e7-889b-6790e5700c8d.png)\r\n* [x] Including a code block in the heading looks wrongs: \r\n![image](https://user-images.githubusercontent.com/2746074/32851917-446dc10c-c9eb-11e7-95e3-9e63ceb8e520.png)\r\n(This one we might want to just fix by changing the text to \"Zulip bots package\".\r\n\r\n"},
{"text": "Right now, if the server 500s on a JSON request from a client in a way that doesn't return valid JSON, we get this sort of JS exception sent back to the server.  \r\n\r\n```\r\nMessage:\r\nUnexpected token < in JSON at position 0\r\n\r\nStacktrace:\r\nSyntaxError: Unexpected token < in JSON at position 0\r\n    at JSON.parse (<anonymous>)\r\n\r\n    at Object.a.xhrerrormessage (static/min/app.f993cb5274ab.js:1331:372)\r\n       = static/js/channel.js line 110 column 27\r\n\r\n    at error (static/min/app.f993cb5274ab.js:2062:742)\r\n       = static/js/reactions.js line 25 column 28\r\n```\r\n\r\nI think we should fix this in 2 ways;\r\n* Make it ~impossible for an invalid-JSON response to come back from `channel.js` (e.g. have a set of 500 error pages for API URLs that are in JSON format), and mostly not change this code.  This probably involves changes to both our `nginx` configuration (for \"unexpected errors\" where Django isn't even running).  And then there's a probably simpler piece of changing `zerver/middleware.py` to handle unexpected exceptions in JSON style API routes at the Django level.\r\n* Make `channel.js` catch this exception and provide a more clear error message for what's happening (perhaps including the invalid JSON it received) in the report, via `blueslip.error` or something.\r\n\r\n\r\n"},
{"text": "We have a few places where we're using a `PUT` HTTP method where the endpoint isn't actually idempotent.  This causes exceptions when things are automatically retransmitted by the browser incorrectly.   The main ones are:\r\n\r\n```\r\n    url(r'^realm/icon$', restdispatch,                                                              \r\n        {'PUT': 'zerver.views.realmicon.uploadicon',                                               \r\n```\r\n\r\n```\r\n    url(r'^realm/emoji/(?P<emojiname>.*)$', restdispatch,                                          \r\n        {'PUT': 'zerver.views.realmemoji.uploademoji',                                             \r\n```\r\n\r\n```\r\n    url(r'^users/me/avatar$', restdispatch,                                                         \r\n        {'PUT': 'zerver.views.usersettings.setavatarbackend',                                     \r\n```\r\n\r\n```\r\n    url(r'^users/me/alertwords$', restdispatch,                                                    \r\n        {'GET': 'zerver.views.alertwords.listalertwords',                                         \r\n         'POST': 'zerver.views.alertwords.setalertwords',                                         \r\n         'PUT': 'zerver.views.alertwords.addalertwords',                                          \r\n```\r\n\r\n3/4 of these are because we're uploading a file and we should just change to `POST`; the alertwords one is more interesting (but also hasn't been a source of problems yet).  Ideally we'd change them all. \r\n\r\nThe uploads part of this, at least, we should fix soon, since it's easy to do and I don't believe those APIs are in use in any apps (and we'd like to fix this before that changes)."},
{"text": "### Preconditions\r\n1. Magento 2.2.2 CE, php 7.1.\r\n\r\n### Steps to reproduce\r\n1. `GET` to API `/customers/search` with parameters.\r\n```json\r\n\"searchcriteria\": {\r\n    \"filtergroups\": [\r\n        {\r\n            \"filters\": [\r\n                {\r\n                    \"field\": \"company\",\r\n                    \"value\": \"%%\",\r\n                    \"conditiontype\": \"like\"\r\n                },\r\n                {\r\n                    \"field\": \"companyname\",\r\n                    \"value\": \"%%\",\r\n                    \"conditiontype\": \"like\"\r\n                }\r\n            ]\r\n        }\r\n    ]\r\n}\r\n```\r\n\r\n`company` is default magento attribute in customer address,` companyname` I created for customer entity.\r\n\r\nUsing the m2 [documentation](http://devdocs.magento.com/guides/v2.2/rest/performing-searches.html)\r\n### Expected result\r\nSearch where `company` like `%%` OR `companyname` like `%%`.\r\n\r\n### Actual result\r\nEmpty result. I noticed magento require filled `companyname` in customers. If I add any string in my custom field, magento returns this row without a problems even if the condition is not correct for this part of rule (expected result)."},
{"text": "### Summary (*)\r\nNot Able to set Rest API oAuth token expire in minutes or seconds in admin. Currently it's showing hours and it will not accept like 0.5(for 30 minute etc) \r\n### Preconditions (*)\r\n1. Magento 2.3-develop\r\n\r\n### Steps to reproduce (*)\r\n\r\n1. Login to Admin\r\n2. Go to the Stores-->Configuration-->Services-->OAuth\r\n3. Change values in Customer Token Lifetime (hours) & in Admin Token Lifetime (hours) to '0.5'\r\n ![image](https://user-images.githubusercontent.com/51680850/65674090-ad3f6b00-e054-11e9-829d-a31728c45f47.png)\r\n4. Get the admin token (POST `<yourlocal>/rest/V1/integration/admin/token`)\r\n ![image](https://user-images.githubusercontent.com/51680850/65684590-a7ec1b80-e068-11e9-937e-cf1d425cf46b.png)\r\n5. Notice the time when you sent the request\r\n ![image](https://user-images.githubusercontent.com/51680850/65684887-60b25a80-e069-11e9-9785-1d6d63e53677.png)\r\n6. Wait 30+ minutes\r\n7. Send any request with admin token ( GET `<yourlocal>/rest/V1/products/<sku>` in my case)\r\n \r\n\r\n### Expected result (*)\r\n1. We get an error\r\n![image](https://user-images.githubusercontent.com/51680850/65685409-93108780-e06a-11e9-86c6-9b9f8f69c91d.png)\r\n\r\n### Actual result (*)\r\n200 OK\r\n![image](https://user-images.githubusercontent.com/51680850/65685669-3366ac00-e06b-11e9-9a3d-218d9018d464.png)\r\n\r\n\r\n"},
{"text": "### Preconditions (*)\r\nMagento 2.3-develop\r\nIf any one is add products in cart by guest and after that login then how it will merge guest cart to customer login cart items by Rest API.\r\n\r\n### Steps to reproduce (*)\r\n1. Create a customer \r\n2. Log out from customer account \r\n3. Add any product to cart \r\n4. Try to merge quotes via API\r\n```\r\nAuthorization -\"Bearer {user-token}\"\r\nPUT {URL}/rest/V1/guest-carts/{guest-card-id}\r\nBody: \r\n{\r\n  \"customerId\": {customer id},\r\n  \"storeId\": {store id}\r\n}\r\n```\r\n### Expected result (*)\r\n200 OK\r\n`true`\r\n### Actual result (*)\r\ngetting error : \"The customer can't be assigned to the cart because the customer already has an active cart.\"\r\n![Screenshot from 2019-10-02 13-18-36](https://user-images.githubusercontent.com/51680850/66039969-f6912e00-e51e-11e9-8c66-3f045c2544f8.png)\r\n"},
{"text": "It looks like internal bug MAGETWO-71829 was not fully solved. It made the \"issubscribed\" field available in the API.\r\nHowever this was not done for results of the search?searchCriteria API method.\r\n\r\nMore information: https://github.com/magento/devdocs/issues/1384\r\n### Preconditions (*)\r\n1. Magento is at version 2.3.2 & 2.3-develop\r\n\r\n### Steps to reproduce (*)\r\n1. Install Magento \r\n2. Add one or more customers\r\n3. Request a list of customers through the  /V1/customers/search?searchCriteria API method\r\n4. Notice there are no extension attributes\r\n\r\n### Expected result (*)\r\n1. Expected behavior: have a extensionattribute section that includes \"issubscribed\" field. Just like when /V1/customers/:id: is requested.\r\n![image](https://user-images.githubusercontent.com/51680850/68113623-e218ca80-fefc-11e9-99ca-fdb412e02635.png)\r\n\r\n\r\n### Actual result (*)\r\n1. no extensionattribute is present, no \"issubscribed\" field is present.\r\n![image](https://user-images.githubusercontent.com/51680850/68113658-f066e680-fefc-11e9-8eeb-d1ee41ed6a3e.png)\r\n\r\n"},
{"text": "<!---\r\nPlease review our guidelines before adding a new issue: https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\nFields marked with (*) are required. Please don't remove the template.\r\n-->\r\n\r\n### Preconditions (*)\r\n<!---\r\nProvide the exact Magento version (example: 2.3.2) and any important information on the environment where bug is reproducible.\r\n-->\r\n1. Customer should be created through API or programmatically.\r\n\r\n### Steps to reproduce (*)\r\n<!---\r\nImportant: Provide a set of clear steps to reproduce this bug. We can not provide support without clear instructions on how to reproduce.\r\n-->\r\n1. Try to create a customer through API\r\n\r\nURL: https://Magentoinstancepath/rest/V1/customers \r\n\r\nData:\r\n```\r\n{\r\n  \"customer\": {\r\n    \"email\": \"manna@gmail.com1\",\r\n    \"firstname\": \"Manna\",\r\n    \"lastname\": \"Test\",\r\n    \"gender\": 0\r\n}\r\n} \r\n```\r\nmethod type: post\r\n\r\n### Expected result (*)\r\n<!--- Tell us what do you expect to happen. -->\r\n1. Validation should behave in the same way as in Magento UI\r\n2. Validation of .com1 should happen through API as well \r\n\r\n### Actual result (*)\r\n<!--- Tell us what happened instead. Include error messages and issues. -->\r\n1. Validation is not happening similar for Magento UI and API\r\n2. Magento should not allow creating a customer with Email having .comXXX through API\r\n"},
{"text": "### Preconditions (*)\r\nMagento Version 2.3.3 & 2.3-develop\r\nPHP version 7.3\r\nApache 2.4\r\nMagento Default Theme\r\n\r\n### Steps to reproduce (*)\r\n1. Do an API product paginated search query with `/V1/products/searchCriteria[currentPage]=0&searchCriteria[pageSize]=20`\r\n2. Look at returned JSON content.\r\n3. Do an API product GET with `/V1/products/searchCriteria[currentPage]=1&searchCriteria[pageSize]=20`\r\n4. Look at returned JSON content\r\n5. Do an API product paginated search query with \r\n`/V1/search/?searchCriteria[requestName]=quicksearchcontainer&searchCriteria[filtergroups][0][filters][0][field]=searchterm&searchCriteria[filtergroups][0][filters][0][value]=sample&searchCriteria[pagesize]=20&searchCriteria[currentpage]=0`\r\n6. Look at returned JSON content.\r\n7. Do an API product GET with \r\n`/V1/search/?searchCriteria[requestName]=quicksearchcontainer&searchCriteria[filtergroups][0][filters][0][field]=searchterm&searchCriteria[filtergroups][0][filters][0][value]=sample&searchCriteria[pagesize]=20&searchCriteria[currentpage]=1`\r\n8. Look at returned JSON content\r\n\r\n\r\n### Expected result (*)\r\nThe parameter `searchCriteria[currentpage]` should start from the same index, so the result with the parameters `searchCriteria[currentpage]=0` or `searchCriteria[currentpage]=1` should be the same for every call to each endpoints of the API.\r\n\r\n### Actual result (*)\r\n1. The result in step 2 and 4 are the same.\r\n2. The result in step 6 and 8 are different\r\n"},
{"text": "### Preconditions\r\n\r\n1. Magento 2.3.2 & 2.3-develop\r\n\r\n### Steps to reproduce\r\n\r\nCreate an interface with a nullable getter. In our scenario it was a method that could return an array of instances of another object, or `null`:\r\n\r\n```php\r\n/**\r\n * @return null|\\Vendor\\Module\\Api\\Data\\CompanyAddressInterface[]\r\n */\r\npublic function getAddresses(): ?array;\r\n```\r\n\r\n### Expected result\r\n\r\nWhen properly configured and used as a web API, the object should be serialized using Reflection and it's nested objects as well.\r\n\r\n### Actual result\r\n\r\nThe following error is thrown:\r\n\r\n![image](https://user-images.githubusercontent.com/51680850/69247499-2968b180-0bb3-11ea-9f73-7be2c423c988.png)\r\n\r\n\r\n### Possible cause\r\n\r\nMy guess is that when determinating the type of return class, something goes wrong when a return type can be nullable. See also the workaround:\r\n\r\n### Workaround\r\n\r\nThe current woraround that will not trigger this error and make the web API work as expected is to flip the arguments, so instead of:\r\n\r\n```php\r\n/**\r\n * @return null|\\Vendor\\Module\\Api\\Data\\CompanyAddressInterface[]\r\n */\r\npublic function getAddresses(): ?array;\r\n```\r\n\r\nI use:\r\n\r\n```php\r\n/**\r\n * @return \\Vendor\\Module\\Api\\Data\\CompanyAddressInterface[]|null\r\n */\r\npublic function getAddresses(): ?array;\r\n```\r\n\r\nNow everything works as expected, but it seems to me that this should be considered a bug."},
{"text": "<!---\r\nPlease review our guidelines before adding a new issue: https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\nFields marked with (*) are required. Please don't remove the template.\r\n-->\r\n\r\n### Preconditions (*)\r\n<!---\r\nProvide the exact Magento version (example: 2.3.2) and any important information on the environment where bug is reproducible.\r\n-->\r\n1. Magento 2.2.8\r\nM 2.3.3\r\n\r\n### Steps to reproduce (*)\r\n<!---\r\nImportant: Provide a set of clear steps to reproduce this bug. We can not provide support without clear instructions on how to reproduce.\r\n-->\r\n1. Create multiple websites\r\n2. Set Catalog Price Scope to Website\r\n3. Create special price for a product on one of the websites (or both)\r\n4. Call `V1/products/special-price-delete` API specifying one of the storeid's\r\n![price2](https://user-images.githubusercontent.com/51681435/70235811-551b9800-176c-11ea-97df-8560e52ce457.png)\r\n\r\n### Expected result (*)\r\n<!--- Tell us what do you expect to happen. -->\r\n1. Expect only the price with the storeid specified to be removed\r\n\r\n### Actual result (*)\r\n<!--- Tell us what happened instead. Include error messages and issues. -->\r\n1. All special prices for that sku are removed from all stores\r\n![s-price](https://user-images.githubusercontent.com/51681435/70235557-da527d00-176b-11ea-8ad0-665b3f8e3fe2.png)\r\n\r\n"},
{"text": "<!---\r\nPlease review our guidelines before adding a new issue: https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\nFields marked with (*) are required. Please don't remove the template.\r\n-->\r\n\r\n### Preconditions (*)\r\n<!---\r\nProvide the exact Magento version (example: 2.3.2) and any important information on the environment where bug is reproducible.\r\n-->\r\n1. Magento 2.2.x / Magento 2.3.x both CE / EE & 2.4-develop\r\n\r\n### Steps to reproduce (*)\r\n<!---\r\nImportant: Provide a set of clear steps to reproduce this bug. We can not provide support without clear instructions on how to reproduce.\r\n-->\r\n1. Create a new module which will add new webapi route\r\n2. Create a new deserializer using `di.xml` in your module\r\n\r\n<config xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:noNamespaceSchemaLocation=\"urn:magento:framework:ObjectManager/etc/config.xsd\">\r\n    <!-- interface for API -->\r\n    <preference for=\"Coinpayments\\Withdrawals\\Api\\IpnInterface\"\r\n                type=\"Coinpayments\\Withdrawals\\Model\\Ipn\" />\r\n\r\n    <type name=\"Magento\\Framework\\Webapi\\Rest\\Request\\DeserializerFactory\">\r\n        <arguments>\r\n            <argument name=\"deserializers\" xsi:type=\"array\">\r\n                <item name=\"textplain\" xsi:type=\"array\">\r\n                    <item name=\"type\" xsi:type=\"string\">text/plain</item>\r\n                    <item name=\"model\" xsi:type=\"string\">Custom\\Module\\Webapi\\Rest\\Request\\Deserializer\\Plain</item>\r\n                </item>\r\n            </argument>\r\n        </arguments>\r\n    </type>\r\n\r\n### Expected result (*)\r\n<!--- Tell us what do you expect to happen. -->\r\n1. New content type accepted by REST API \r\n\r\n### Actual result (*)\r\n<!--- Tell us what happened instead. Include error messages and issues. -->\r\n1. All CORE defined content types for API are no longer working and return 400 error\r\n![image](https://user-images.githubusercontent.com/51681618/72727558-dd76c080-3b93-11ea-8f70-efd16bb1c039.png)\r\n\r\n2. Only new defined content type is accepted\r\n\r\nIt was my understanding that **DI.XML** is used to extend **CORE** features, not **OVERWRITE** them."},
{"text": "<!---\r\nPlease review our guidelines before adding a new issue: https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\nFields marked with (*) are required. Please don't remove the template.\r\n-->\r\n\r\n### Preconditions (*)\r\n<!---\r\nProvide the exact Magento version (example: 2.3.2) and any important information on the environment where bug is reproducible.\r\n-->\r\n1. Have magento2.2.2 installed \r\n2. Keep all default payments config  etc... such as `Check / Money order`\r\n\r\n### Steps to reproduce (*)\r\n<!---\r\nImportant: Provide a set of clear steps to reproduce this bug. We can not provide support without clear instructions on how to reproduce.\r\n-->\r\n1. Add a configurable and at least 1 simple to `configurations`\r\n2. Go to frontend add at least one product to cart and checkout finalise purchase.\r\n3. Go to backend and Invoice + Ship the item and the status will be set to `Complete`.\r\n4. Now using your favourite API tool use `salesRefundOrderV1` from documentation found here: https://devdocs.magento.com/swagger/#/salesRefundOrderV1 . Request order refund input necessary details from the order like so E.G:\r\n\r\n`POST http://dev.test/rest/V1/order/1/refund`\r\n\r\n**Body:**\r\n`{\r\n  \"items\": [\r\n    {\r\n      \"extensionattributes\": {},\r\n      \"orderitemid\": 1,\r\n      \"qty\": 1\r\n    }\r\n  ],\r\n  \"notify\": true,\r\n  \"appendComment\": true,\r\n  \"comment\": {\r\n    \"extensionattributes\": {},\r\n    \"comment\": \"string\",\r\n    \"isvisibleonfront\": 0\r\n  },\r\n  \"arguments\": {\r\n    \"shippingamount\": 0,\r\n    \"adjustmentpositive\": 0,\r\n    \"adjustmentnegative\": 0,\r\n    \"extensionattributes\": {\r\n      \"returntostockitems\": [\r\n        0\r\n      ]\r\n    }\r\n  }\r\n}`\r\n\r\n5. If success you should receive refund ID E.G: `\"1\"`\r\n6. Go to backend->Sales->Order check the order you've just refunded in `information`  Order Status still says: `Complete`\r\n\r\n### Expected result (*)\r\n<!--- Tell us what do you expect to happen. -->\r\n1. Order Status should be `Closed`\r\n\r\n### Actual result (*)\r\n<!--- Tell us what happened instead. Include error messages and issues. -->\r\n1. Order Status still be `Complete`.\r\n"},
{"text": "When you update a product. For example adding an image using the API. Which is totally unrelated to anything else, such as editing price.\r\n\r\nThe checkbox \"Use Default Value\" becomes unchecked on a bunch of attributes, such as price.\r\n\r\nThis turns into a problem when you want to edit the product later, update the price, or the description etc. and nothing happens. So you have to change store view scope to that particular store, check the box \"Use Default Value\" and save to be able to change the price.\r\n\r\nThis should not happen in the first place.\r\n\r\n\r\n### Preconditions (*)\r\n<!---\r\nProvide the exact Magento version (example: 2.3.2) and any important information on the environment where bug is reproducible.\r\n-->\r\n1. Magento 2.3.3\r\n2. 2 store views\r\n\r\n### Steps to reproduce (*)\r\n<!---\r\nImportant: Provide a set of clear steps to reproduce this bug. We can not provide support without clear instructions on how to reproduce.\r\n-->\r\n1. Create 2 store views\r\n2. Add a new product with a price\r\n3. Change store view on the product. You can see \"Use Default Value\" for price is checked.\r\n4. Update the product using the API, for example uploading an image\r\n5. View the product again and change store scope\r\n6. Notice the \"Use Default Value\" on price is now unchecked (amongst other attributes)\r\n\r\n### Expected result (*)\r\n\r\nCheckbox \"Use Default Value\" should remain checked until a user actually unchecks it.\r\n\r\n### Actual result (*)\r\n\r\nCheckbox \"Use Default Value\" unchecks itself when you update the product using the API for all store views.\r\n\r\n### Additional info \r\nI just re-produced it on 2.4-dev.\r\n\r\nSeems to be a problem with scopes.\r\n\r\nIn addition to the steps above, do the following:\r\n\r\n1. Stores > All Stores. Click \"Main Website Store\" and change \"Default Store View\" to the second store view\r\n\r\n![image](https://user-images.githubusercontent.com/1741593/73576575-0b54e280-447b-11ea-863e-c8f466999a25.png)\r\n\r\n\r\n2. Open \"Default Store View\" and change to status to disabled\r\n3. Go into product, select scope \"Default store view\" (first store) Click \"Use Default Value\" on everything. Save.\r\n4. Change store scope to second store view. Click \"Use Default Value\" on everything. Save.\r\n5. Change scope to second store view again. A bunch of \"Use Default Value\" are unchecked.\r\n\r\n\r\n![image](https://user-images.githubusercontent.com/1741593/73576115-0b081780-447a-11ea-8e07-3af9ec72d1f6.png)"},
{"text": "Hello,\r\n when doing GET to /V1/categories?rootCategoryId=1 I've null fields in **isactive** (but the structure is correct)\r\n\r\n```\r\n{\r\n  \"id\": 1,\r\n  \"parentid\": 0,\r\n  \"name\": \"Root Catalog\",   \r\n  \"isactive\": null,     #<---\r\n  \"position\": 0,\r\n  \"level\": 0,\r\n  \"productcount\": 0,    \r\n  \"childrendata\": [\r\n    {\r\n      \"id\": 2,\r\n      \"parentid\": 1,\r\n      \"name\": \"Default Category\",\r\n      \"isactive\": true,\r\n      \"position\": 1,\r\n      \"level\": 1,\r\n      \"productcount\": 1,\r\n      \"childrendata\": [\r\n        {\r\n          \"id\": 3,\r\n          \"parentid\": 2,\r\n          \"name\": \"Category\",\r\n          \"isactive\": true,\r\n          \"position\": 1,\r\n          \"level\": 2,\r\n          \"productcount\": 2,\r\n          \"childrendata\": []\r\n        }\r\n      ]\r\n    },\r\n```\r\n   \r\nThis problems happens only with search filter \"rootCategoryId=1\" that I use to get ALL the category trees. If I use \"CategoryId=2\" it works, But I need a way to get all category trees across all websites with one call. \r\n\r\n### Preconditions (*)\r\nmagento 2.3.2 and magento 2.3.3\r\n\r\n### Steps to reproduce (*)\r\nSimply make a GET to\r\nhttps://<SHOPHOSTNAME>/index.php/rest/V1/categories?rootCategoryId=1\r\n\r\n### Expected result (*)\r\nno null values\r\n\r\n### Actual result (*)\r\nThe **isactive: null**\r\n![catresponsebody1](https://user-images.githubusercontent.com/51680745/74158299-80b27700-4c22-11ea-9470-8915c320381b.png)"},
{"text": "<!---\r\nPlease review our guidelines before adding a new issue: https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\nFields marked with (*) are required. Please don't remove the template.\r\n-->\r\n\r\nUpdating or adding a new image to a product will not create a thumbnail in the admin products grid. The admin products grid will have a placeholder.\r\n\r\n### Preconditions (*)\r\n<!---\r\nProvide the exact Magento version (example: 2.3.2) and any important information on the environment where bug is reproducible.\r\n-->\r\n1. Magento 2.3.3\r\n\r\n### Steps to reproduce (*)\r\n<!---\r\nImportant: Provide a set of clear steps to reproduce this bug. We can not provide support without clear instructions on how to reproduce.\r\n-->\r\n1. Create product\r\n2. Upload image to product using the rest API\r\n3. Visit the products grid in backend\r\n\r\n### Expected result (*)\r\n<!--- Tell us what do you expect to happen. -->\r\n\r\nA thumbnail for the product should be rendered in the products grid.\r\n\r\n### Actual result (*)\r\n<!--- Tell us what happened instead. Include error messages and issues. -->\r\n\r\nA placeholder for the product is rendered in the products grid.\r\n\r\n### Additional information\r\nWhen the product image is added from Admin, the **Image Roles** are displayed. Base, Small, Thumbnail, Swatch\r\n![basesmall](https://user-images.githubusercontent.com/51680745/74345584-fa7b6980-4db6-11ea-8d51-8bf9b15b9354.png)\r\n\r\n![imagedetail](https://user-images.githubusercontent.com/51680745/74345830-5a721000-4db7-11ea-8d47-45e8777a5e26.png)\r\n\r\nIf the product image is added using API, there are no image roles. \r\n![imagedetailsno](https://user-images.githubusercontent.com/51680745/74346247-f439bd00-4db7-11ea-852a-891b4d48b41f.png)\r\n\r\nAnd as a result - no thumbnails \r\n![nothumbnails](https://user-images.githubusercontent.com/51680745/74346576-71fdc880-4db8-11ea-9050-8fa4a79d8d17.png)\r\n"},
{"text": "The Magento CHANGELOG.md reports every issue link as one for magento/magento2, when in fact we have multiple repositories each tracking their own set of changes (eg magento/graphql-ce)\r\n\r\n### Preconditions (*)\r\nView **CHANGELOG.md** - https://github.com/magento/magento2/blob/2.3/CHANGELOG.md\r\n\r\n### Steps to reproduce (*)\r\nLook in the 2.3.4 changelog for the following:\r\n```md\r\n    * [#167](https://github.com/magento/magento2/issues/167) -- Fatal error: Class 'Mage' not found (fixed in [magento/graphql-ce#800](https://github.com/magento/graphql-ce/pull/800))\r\n\r\n```\r\n\r\n### Expected result (*)\r\nIt should link to https://github.com/magento/graphql-ce/issues/167 (it's a GraphQL issue, not a Magento one) and have the issue title **Add support for '@magentoConfigFixture' annotation on API-functional tests** (or potentially link to https://github.com/magento/graphql-ce/issues/794 based off of the PR text?)\r\n\r\n### Actual result (*)\r\nIt links to https://github.com/magento/magento2/issues/167 with the (very amusing) incorrect issue title."},
{"text": "### Preconditions:\r\n\r\n- Magento 2.4-develop\r\n- Swagger/Postman https scheme integrationCustomerTokenServiceV1\r\n- Customer is created\r\n\r\n### Steps to reproduce\r\n\r\n1) Open the default magento Swagger http schemes or use this same api in postman.\r\n2) Open integrationCustomerTokenServiceV1 interface to generate token for customers.\r\n3) Enter the integrationCustomerTokenServiceV1CreateCustomerAccessTokenPostBody as registered customer acess details  to generate token for customer.\r\n4) Verify the response the valid respose token should be generated for the valid registered customer acess details as entered.\r\n\r\n### Expected result :\r\nWhen in swagger/postman interface to generate customer acess details is entered the valid respose code should be generated for the valid customer details as entered.\r\n\r\n### Actual result :\r\nWhen in swagger/postman interface to generate customer acess details is entered the valid respose code was not getting  generated for the valid customer details as entered and the respose was as: \"The account sign-in was incorrect or your account is disabled temporarily. Please wait and try again later\"\r\n\r\n![swagger issue](https://user-images.githubusercontent.com/38529140/75606488-54986080-5b13-11ea-9b37-2c64b51791e1.png)\r\n\r\n"},
{"text": "<!---\r\nPlease review our guidelines before adding a new issue: https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\nFields marked with (*) are required. Please don't remove the template.\r\n-->\r\n\r\n### Preconditions (*)\r\n<!---\r\nProvide the exact Magento version (example: 2.3.2) and any important information on the environment where bug is reproducible.\r\n-->\r\n1. Magento version 2.3.3\r\n2. Using REST API calls\r\n\r\n### Steps to reproduce (*)\r\n<!---\r\nImportant: Provide a set of clear steps to reproduce this bug. We can not provide support without clear instructions on how to reproduce.\r\n-->\r\n1. Create a quote for a user if they do not have one. \r\n2. Add a few items item to the shopping cart using POST `carts/{quoteId}/items`\r\n3. Delete all items in quick succession using DELETE `carts/{quoteId}/items`\r\n4. Get the cart using GET `carts/{quoteId}`\r\n\r\n### Expected result (*)\r\n<!--- Tell us what do you expect to happen. -->\r\n1. The cart should be empty and itemsqty should be 0\r\n1. The cart should be empty and itemscount should be 0\r\n\r\n### Actual result (*)\r\n<!--- Tell us what happened instead. Include error messages and issues. -->\r\n1. ![image](https://user-images.githubusercontent.com/13006588/75776744-e17e2c80-5d54-11ea-8cb6-bec91aa838cf.png)\r\n2. items is an empty array but itemsqty is 2.\r\n3. items is an empty array but itemscount is 2."},
{"text": "<!---\r\nPlease review our guidelines before adding a new issue: https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\nFields marked with (*) are required. Please don't remove the template.\r\n-->\r\n\r\n### Preconditions (*)\r\n<!---\r\nProvide the exact Magento version (example: 2.3.2) and any important information on the environment where bug is reproducible.\r\n-->\r\n1.  Magento 2.4 with sample data\r\n<!---\r\nPlease review our guidelines before adding a new issue: https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\nFields marked with (*) are required. Please don't remove the template.\r\n-->\r\n\r\n### Steps to reproduce (*)\r\n<!---\r\nImportant: Provide a set of clear steps to reproduce this bug. We can not provide support without clear instructions on how to reproduce.\r\n-->\r\n1. Adding Configurable product with api to website\r\n2. Using [this](https://devdocs.magento.com/guides/v2.4/rest/tutorials/configurable-product/plan-product.html) documentation\r\n3. First create the new Attribute Set \"Test\" based on Default\r\n4. Add the \"attributeset3attribute1\" attribute to this Attribute Set \r\nHere is Api requests [Configurable.zip](https://github.com/magento/magento2/files/4937433/Configurable.zip)\r\n5. On the Luma storefront page, search for TS.\r\n![Peek 2020-07-17 13-26](https://user-images.githubusercontent.com/60198022/87781529-80ee1880-c839-11ea-9d65-490d72a517ec.gif)\r\n6. Status of the product in backend \"Out of Stock\"\r\n7. Change the status to \"In Stock\"  -> Save\r\n8. Try to search it again.\r\nResult is the same as on 6 step\r\n### Expected result (*)\r\n<!--- Tell us what do you expect to happen. -->\r\n1. The product should be added successfully to website and shows/display on front.  \r\n\r\n### Actual result (*)\r\n<!--- Tell us what happened instead. Include error messages and issues. -->\r\n1. The product is added successfully in backend, but in front its not displayed. \r\n3.if open the product page(edit product) on backend, and just save it without any change, its shows/display on front! (on 2.3.4 version)\r\n4. video : https://www.loom.com/share/0afc407bebb44c6ba45ee2e701b3f35c\r\n5.this problem is just for configurable product, for simple product no issue.\r\n"},
{"text": "<!---\r\nPlease review our guidelines before adding a new issue: https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\nFields marked with (*) are required. Please don't remove the template.\r\n-->\r\n\r\n### Preconditions (*)\r\n<!---\r\nProvide the exact Magento version (example: 2.3.2) and any important information on the environment where bug is reproducible.\r\n-->\r\n1. Magento 2.3.3 CE\r\n2. Apache + AWS\r\n\r\n### Steps to reproduce (*)\r\n<!---\r\nImportant: Provide a set of clear steps to reproduce this bug. We can not provide support without clear instructions on how to reproduce.\r\n-->\r\n1. Create customer password reset token\r\n2. `$resetPasswordToken = $this->userData->generateResetPasswordLinkToken();` \r\n    `New \\Magento\\User\\Helper\\Data;`\r\n2. Invoke  /V1/customers/resetPassword to set new password\r\n\r\n### Expected result (*)\r\n<!--- Tell us what do you expect to happen. -->\r\n1. It should update customer password with given in \"newPassword\" key\r\n2.\r\n\r\n### Actual result (*)\r\n<!--- Tell us what happened instead. Include error messages and issues. -->\r\n1. The password token is mismatched. Reset and try again.\r\n2. `{\"message\":\"The password token is mismatched. Reset and try again.\",\"trace\":\"#0 \\/var\\/www\\/html\\/magento\\/vendor\\/magento\\/module-customer\\/Model\\/AccountManagement.php(685): Magento\\\\Customer\\\\Model\\\\AccountManagement->validateResetPasswordToken('32', '5SEwugR9l6tgtvs...')\\n#1 \\/var\\/www\\/html\\/magento\\/generated\\/code\\/Magento\\/Customer\\/Model\\/AccountManagement\\/Interceptor.php(102): Magento\\\\Customer\\\\Model\\\\AccountManagement->resetPassword('zerocool@gm...', '5SEwugR9l6tgtvs...', 'admin1234')\\n#2 [internal function]: Magento\\\\Customer\\\\Model\\\\AccountManagement\\\\Interceptor->resetPassword('zerocool@gm...', '5SEwugR9l6tgtvs...', 'admin1234')\\n#3 \\/var\\/www\\/html\\/magento\\/vendor\\/magento\\/module-webapi\\/Controller\\/Rest\\/SynchronousRequestProcessor.php(95): calluserfuncarray(Array, Array)\\n#4 \\/var\\/www\\/html\\/magento\\/vendor\\/magento\\/module-webapi\\/Controller\\/Rest.php(188): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\SynchronousRequestProcessor->process(Object(Magento\\\\Framework\\\\Webapi\\\\Rest\\\\Request\\\\Proxy))\\n#5 \\/var\\/www\\/html\\/magento\\/vendor\\/magento\\/framework\\/Interception\\/Interceptor.php(58): Magento\\\\Webapi\\\\Controller\\\\Rest->dispatch(Object(Magento\\\\Framework\\\\App\\\\Request\\\\Http))\\n#6 \\/var\\/www\\/html\\/magento\\/vendor\\/magento\\/framework\\/Interception\\/Interceptor.php(138): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\Interceptor->callParent('dispatch', Array)\\n#7 \\/var\\/www\\/html\\/magento\\/vendor\\/magento\\/framework\\/Interception\\/Interceptor.php(153): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\Interceptor->Magento\\\\Framework\\\\Interception\\\\{closure}(Object(Magento\\\\Framework\\\\App\\\\Request\\\\Http))\\n#8 \\/var\\/www\\/html\\/magento\\/generated\\/code\\/Magento\\/Webapi\\/Controller\\/Rest\\/Interceptor.php(26): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\Interceptor->callPlugins('dispatch', Array, Array)\\n#9 \\/var\\/www\\/html\\/magento\\/vendor\\/magento\\/framework\\/App\\/Http.php(137): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\Interceptor->dispatch(Object(Magento\\\\Framework\\\\App\\\\Request\\\\Http))\\n#10 \\/var\\/www\\/html\\/magento\\/generated\\/code\\/Magento\\/Framework\\/App\\/Http\\/Interceptor.php(24): Magento\\\\Framework\\\\App\\\\Http->launch()\\n#11 \\/var\\/www\\/html\\/magento\\/vendor\\/magento\\/framework\\/App\\/Bootstrap.php(261): Magento\\\\Framework\\\\App\\\\Http\\\\Interceptor->launch()\\n#12 \\/var\\/www\\/html\\/magento\\/index.php(39): Magento\\\\Framework\\\\App\\\\Bootstrap->run(Object(Magento\\\\Framework\\\\App\\\\Http\\\\Interceptor))\\n#13 {main}\"}` \r\n\r\n\r\n**UPDATE**\r\n\r\nAfter generating token with `$resetPasswordToken = $this->userData->generateResetPasswordLinkToken();` \r\n    `New \\Magento\\User\\Helper\\Data;`\r\n\r\nI'm verifying token with `/V1/customers/{customerId}/password/resetLinkToken/{resetPasswordLinkToken}`\r\n\r\nIn response getting **true** but still /V1/customers/resetPassword showing same error as above.  \r\n"},
{"text": "<!---\r\nPlease review our guidelines before adding a new issue: https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\nFields marked with (*) are required. Please don't remove the template.\r\n-->\r\n\r\n### Preconditions (*)\r\n<!---\r\nProvide the exact Magento version (example: 2.4.0) and any important information on the environment where bug is reproducible.\r\n-->\r\n1. Magento version 2.3.5 \r\n\r\n### Steps to reproduce (*)\r\n<!---\r\nImportant: Provide a set of clear steps to reproduce this bug. We can not provide support without clear instructions on how to reproduce.\r\n-->\r\n1. Configure the postman\r\n2. Make an API call using the below details\r\nAPI : rest/V1/products/cost\r\nRequest : {\"prices\":[{\"cost\":100.0,\"storeid\":0,\"sku\":\"Test Prdouct-104\"}]}\r\n\r\n### Expected result (*)\r\n<!--- Tell us what do you expect to happen. -->\r\n1. Expected Result\r\n [\r\n    {\r\n        \"message\": \"string\",\r\n        \"parameters\": [\r\n                                \"string\"\r\n                               ],\r\n         \"extensionattributes\": {}\r\n     }\r\n]\r\n\r\n### Actual result (*)\r\n<!--- Tell us what happened instead. Include error messages and issues. -->\r\n1. Actual result is empty braces \r\n[]\r\n\r\n\r\n---\r\nPlease provide [Severity](https://devdocs.magento.com/guides/v2.3/contributor-guide/contributing.html#backlog) assessment for the Issue as Reporter. This information will help during Confirmation and Issue triage processes.\r\n\r\n- [ ] Severity: **S0** - Affects critical data or functionality and leaves users without workaround.\r\n- [ ] Severity: **S1** - Affects critical data or functionality and forces users to employ a workaround.\r\n- [ ] Severity: **S2** - Affects non-critical data or functionality and forces users to employ a workaround.\r\n- [ ] Severity: **S3** - Affects non-critical data or functionality and does not force users to employ a workaround.\r\n- [ ] Severity: **S4** - Affects aesthetics, professional look and feel, \"quality\" or \"usability\".\r\n"},
{"text": "### Description\r\nBundle products have a price in the store and admin interface, but not in the Products Details REST API. \r\n\r\n### Preconditions\r\n1. Magento 2.3.3\r\n\r\n### Steps to reproduce\r\n1. Create a bundle product and assign simple products to it.\r\n![image](https://user-images.githubusercontent.com/11089409/83320211-f63e6380-a262-11ea-972a-220b9e91635b.png)\r\n\r\n2. Enable 'Allow Anonymous Guest Access'  from Store -> Configuration -> Services -> Magento Web API\r\n\r\n3. GET /rest/V1/products/{sku} to get a details of bundle product.\r\n\r\n### Expected result\r\n1. Children products must have price in response \r\n\r\n### Actual result\r\n1. Price is 'null' of children products.\r\n```\r\n{\r\n  \"id\": 1203,\r\n  \"sku\": \"Bundle Product\",\r\n  \"name\": \"Bundle Product\",\r\n  \"attributesetid\": 4,\r\n  \"price\": 0,\r\n  \"status\": 1,\r\n  \"visibility\": 4,\r\n  \"typeid\": \"bundle\",\r\n  \"createdat\": \"2020-05-27 11:02:38\",\r\n  \"updatedat\": \"2020-05-27 11:02:38\",\r\n  \"weight\": 0,\r\n  \"extensionattributes\": {\r\n    \"websiteids\": [\r\n      1\r\n    ],\r\n    \"bundleproductoptions\": [\r\n      {\r\n        \"optionid\": 1,\r\n        \"title\": \"option 1\",\r\n        \"required\": true,\r\n        \"type\": \"select\",\r\n        \"position\": 1,\r\n        \"sku\": \"Bundle Product\",\r\n        \"productlinks\": [\r\n          {\r\n            \"id\": \"1\",\r\n            \"sku\": \"productdynamic3\",\r\n            \"optionid\": 1,\r\n            \"qty\": 1,\r\n            \"position\": 1,\r\n            \"isdefault\": false,\r\n            \"price\": null, // Price is null\r\n            \"pricetype\": null,\r\n            \"canchangequantity\": 0\r\n          },\r\n          {\r\n            \"id\": \"2\",\r\n            \"sku\": \"productdynamic4\",\r\n            \"optionid\": 1,\r\n            \"qty\": 1,\r\n            \"position\": 2,\r\n            \"isdefault\": false,\r\n            \"price\": null, // Price is null\r\n            \"pricetype\": null,\r\n            \"canchangequantity\": 0\r\n          }\r\n        ]\r\n      }\r\n    ]\r\n  },\r\n  \"productlinks\": [],\r\n  \"options\": [],\r\n  \"mediagalleryentries\": [],\r\n  \"tierprices\": [],\r\n  ....\r\n}\r\n```\r\n\r\n---\r\n\r\n- [X] Severity: **S0**\r\n"},
{"text": "<!---\r\nPlease review our guidelines before adding a new issue: https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\nFields marked with (*) are required. Please don't remove the template.\r\n-->\r\n\r\n### Preconditions (*)\r\n<!---\r\nProvide the exact Magento version (example: 2.4.0) and any important information on the environment where bug is reproducible.\r\n-->\r\n1. Magento 2.3.4\r\n\r\n### Steps to reproduce (*)\r\n<!---\r\nImportant: Provide a set of clear steps to reproduce this bug. We can not provide support without clear instructions on how to reproduce.\r\n-->\r\n1. Go to admin\r\n2. Stores > Settings > Configuration\r\n3. In the left panel, expand Advanced and choose Developer\r\n4. Expand selector the Translate Inline section\r\n5. Set Enabled for Storefront to Yes\r\n6. Click on save config\r\n7. Try to login to admin as a user using API-\r\nPOST -  {Baseurl}/rest/V1/integration/admin/token\r\nBody-{\r\n\"username\": \"\",\r\n\"password\": \"\"\r\n}\r\n\r\n### Expected result (*)\r\n<!--- Tell us what do you expect to happen. -->\r\n1. Translation inline should be effected to frontend side only.\r\n2. Message from REST API should work well while translation inline is enabled.\r\n\r\n### Actual result (*)\r\n<!--- Tell us what happened instead. Include error messages and issues. -->\r\n1.  Result from rest API:\r\n`{\r\n    \"message\": \"<span data-translate=\\\"[&#x7B;&quot;shown&quot;&#x3A;&quot;Invalid&#x20;login&#x20;or&#x20;password.&quot;,&quot;translated&quot;&#x3A;&quot;Invalid&#x20;login&#x20;or&#x20;password.&quot;,&quot;original&quot;&#x3A;&quot;Invalid&#x20;login&#x20;or&#x20;password.&quot;,&quot;location&quot;&#x3A;&quot;Text&quot;,&quot;scope&quot;&#x3A;&quot;Invalid&#x20;login&#x20;or&#x20;password.&#x7D;&#x7D;&#x7B;&#x7B;theme&quot;&#x7D;]\\\">Invalid login or password.</span>\"\r\n}`\r\n\r\n### Additional information\r\n- more detailed steps to reproduce with screens https://github.com/magento/magento2/issues/28656#issuecomment-644551601\r\n\r\n---\r\nPlease provide [Severity](https://devdocs.magento.com/guides/v2.3/contributor-guide/contributing.html#backlog) assessment for the Issue as Reporter. This information will help during Confirmation and Issue triage processes.\r\n\r\n- [x] Severity: **S1** - Affects critical data or functionality and forces users to employ a workaround.\r\n"},
{"text": "### Description\r\nSearchCriteria filters not working on a Product Attribute which is used while creating a Configurable Product.\r\nVisibility filter applied to show only Visible products in product list.\r\n\r\n### Preconditions (*)\r\n1. Magento 2.4\r\n2. Enable 'Allow Anonymous Guest Access' from Store -> Configuration -> Services -> Magento Web API\r\n\r\n### Steps to reproduce (*)\r\n1. **Create a Configurable Product**\r\n\r\n![Screenshot from 2020-07-14 15-44-06](https://user-images.githubusercontent.com/11089409/87414185-029b3780-c5e9-11ea-8dc2-cc3b4ae4e0ff.png)\r\n\r\n2. **GET** :  /rest/V1/products?searchCriteria[filterGroups][0][filters][0][field]=categoryid&searchCriteria[filterGroups][0][filters][0][value]=33&searchCriteria[filterGroups][1][filters][0][field]=visibility&searchCriteria[filterGroups][1][filters][0][value]=2&searchCriteria[filterGroups][1][filters][0][conditionType]=eq&searchCriteria[filterGroups][1][filters][1][field]=visibility&searchCriteria[filterGroups][1][filters][1][value]=4&searchCriteria[filterGroups][1][filters][1][conditionType]=eq&searchCriteria[filterGroups][2][filters][1][field]=mycolor&searchCriteria[filterGroups][2][filters][1][value]=5431\r\n\r\n![image](https://user-images.githubusercontent.com/11089409/87422667-ab9c5f00-c5f6-11ea-9fd4-d9ee2da50b6b.png)\r\n\r\n\r\n### Expected result (*)\r\n1.  **Must Return Parent Product with attribute \"mycolor\" is set** \r\n\r\n![image](https://user-images.githubusercontent.com/11089409/87416082-cd441900-c5eb-11ea-8acc-166c26798bd9.png)\r\n\r\n### Actual result (*)\r\n1. **No Items in the response**\r\n\r\n![image](https://user-images.githubusercontent.com/11089409/87422835-f74f0880-c5f6-11ea-87e1-7043a0ed2efc.png)\r\n\r\n\r\n![Screenshot from 2020-07-14 17-45-41-1](https://user-images.githubusercontent.com/16210367/87427661-c2df4a80-c5fe-11ea-8d39-d34cec29a4e1.png)\r\n![Screenshot from 2020-07-14 17-45-54](https://user-images.githubusercontent.com/16210367/87427664-c4a90e00-c5fe-11ea-8edd-63409e17fe12.png)\r\n![Screenshot from 2020-07-14 17-42-54-1](https://user-images.githubusercontent.com/16210367/87427668-c541a480-c5fe-11ea-81bb-6c7521ae4b35.png)\r\n---\r\n\r\n- [x] Severity: **S0** - Affects critical data or functionality and leaves users without workaround.\r\n"},
{"text": "This issue is automatically created based on existing pull request: magento/magento2#28828: Fix for empty category field values in REST calls\r\n\r\n---------\r\n<!---\r\n    Thank you for contributing to Magento.\r\n    To help us process this pull request we recommend that you add the following information:\r\n     - Summary of the pull request,\r\n     - Issue(s) related to the changes made,\r\n     - Manual testing scenarios\r\n    Fields marked with (*) are required. Please don't remove the template.\r\n-->\r\n\r\n<!--- Please provide a general summary of the Pull Request in the Title above -->\r\n\r\n### Description (*)\r\nWhen using either rest/all/V1/categories or rest/all/V1/categories?rootCategoryId=2 the name and productcount fields are empty for all categories in the tree. This does not happen when using a store code like default without a rootCategoryId as GET param, like this: rest/default/V1/categories\r\n\r\n### Related Pull Requests\r\nThis is a resubmit of #23587\r\n\r\n### Manual testing scenarios (*)\r\nUse Magento installatie with a category tree and place a REST API call to 'rest/all/V1/categories'.\r\nThis will result in empty field values for name and productcount.\r\nWhen using a storecode like default instead of all in the endpoint call, the fields will be filled in the data that we get back from the API endpoint.\r\n\r\n### Preconditions:\r\n1. Magento 2.4-develop\r\n2. Two categories created\r\n3. 1 product created for each category\r\n\r\n### Steps to reproduce:\r\nMake API call GET rest/all/V1/categories  \r\n\r\n### Expected result:\r\n![image](https://user-images.githubusercontent.com/60198413/90520747-6c6fa980-e172-11ea-8912-56f75a72d469.png)\r\n\r\n### Actual result:\r\nResponse is empty for all categories in the tree\r\n\r\n- Repro on 2.4-develop - YES\r\n\r\n\r\n\r\n### Contribution checklist (*)\r\n - [x] Pull request has a meaningful description of its purpose\r\n - [x] All commits are accompanied by meaningful commit messages\r\n - [ ] All new or changed code is covered with unit/integration tests (if applicable)\r\n - [ ] All automated tests passed successfully (all builds are green)\r\n"},
{"text": "### Preconditions (*)\r\n1. Magento version 2.4.0\r\n\r\n### Steps to reproduce (*)\r\n1. Create user by execute API call on: \"/index.php/rest/all/V1/customers\"  with json body: \r\n`\r\n{\r\n  \"customer\": {\r\n    \"id\": 0,\r\n    \"groupid\": 0,\r\n    \"email\": \"marcinwarzybok@outlook.com\",\r\n    \"firstname\": \"Marcin\",\r\n    \"lastname\": \"Warzybok\"\r\n  },\r\n  \"password\": \"Abcdef123\"\r\n}\r\n`\r\nReturns result:\r\n`\r\n{\r\n    \"id\": 2,\r\n    \"groupid\": 0,\r\n    \"createdat\": \"2020-09-08 11:58:13\",\r\n    \"updatedat\": \"2020-09-08 11:58:13\",\r\n    \"createdin\": \"Default Store View\",\r\n    \"email\": \"marcinwarzybok@outlook.com\",\r\n    \"firstname\": \"Marcin\",\r\n    \"lastname\": \"Warzybok\",\r\n    \"storeid\": 1,\r\n    \"websiteid\": 1,\r\n    \"addresses\": [],\r\n    \"disableautogroupchange\": 0,\r\n    \"extensionattributes\": {\r\n        \"issubscribed\": false\r\n    }\r\n}\r\n`\r\nWhich means i have a new user registered.\r\n\r\n2.Execute API call on: \"/rest/all/V1/integration/customer/token\" with json body:\r\n`\r\n{\r\n    \"username\":\"marcinwarzybok@outlook.com\",\r\n    \"password\":\"Abcdef123\"\r\n}\r\n`\r\nReturns error:\r\n`\r\n{\r\n    \"message\": \"The account sign-in was incorrect or your account is disabled temporarily. Please wait and try again later.\",\r\n    \"trace\": \"#0 [internal function]: Magento\\\\Integration\\\\Model\\\\CustomerTokenService->createCustomerAccessToken('marcinwarzybok@...', 'Abcdef123')\\n#1 /bitnami/magento/htdocs/vendor/magento/module-webapi/Controller/Rest/SynchronousRequestProcessor.php(95): calluserfuncarray(Array, Array)\\n#2 /bitnami/magento/htdocs/vendor/magento/module-webapi/Controller/Rest.php(188): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\SynchronousRequestProcessor->process(Object(Magento\\\\Framework\\\\Webapi\\\\Rest\\\\Request\\\\Proxy))\\n#3 /bitnami/magento/htdocs/vendor/magento/framework/Interception/Interceptor.php(58): Magento\\\\Webapi\\\\Controller\\\\Rest->dispatch(Object(Magento\\\\Framework\\\\App\\\\Request\\\\Http))\\n#4 /bitnami/magento/htdocs/vendor/magento/framework/Interception/Interceptor.php(138): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\Interceptor->callParent('dispatch', Array)\\n#5 /bitnami/magento/htdocs/vendor/magento/framework/Interception/Interceptor.php(153): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\Interceptor->Magento\\\\Framework\\\\Interception\\\\{closure}(Object(Magento\\\\Framework\\\\App\\\\Request\\\\Http))\\n#6 /bitnami/magento/htdocs/generated/code/Magento/Webapi/Controller/Rest/Interceptor.php(26): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\Interceptor->callPlugins('dispatch', Array, Array)\\n#7 /bitnami/magento/htdocs/vendor/magento/framework/App/Http.php(116): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\Interceptor->dispatch(Object(Magento\\\\Framework\\\\App\\\\Request\\\\Http))\\n#8 /bitnami/magento/htdocs/generated/code/Magento/Framework/App/Http/Interceptor.php(24): Magento\\\\Framework\\\\App\\\\Http->launch()\\n#9 /bitnami/magento/htdocs/vendor/magento/framework/App/Bootstrap.php(263): Magento\\\\Framework\\\\App\\\\Http\\\\Interceptor->launch()\\n#10 /bitnami/magento/htdocs/index.php(39): Magento\\\\Framework\\\\App\\\\Bootstrap->run(Object(Magento\\\\Framework\\\\App\\\\Http\\\\Interceptor))\\n#11 {main}\"\r\n}\r\n`\r\n\r\n\r\n### Expected result (*)\r\n1. Execute API call on: \"/rest/all/V1/integration/customer/token\" with json body:\r\n`\r\n{\r\n    \"username\":\"marcinwarzybok@outlook.com\",\r\n    \"password\":\"Abcdef123\"\r\n}\r\n`\r\nShould return token, according to this documentation: https://devdocs.magento.com/guides/v2.3/get-started/authentication/gs-authentication-token.html like this: \"asdf3hjklp5iuytre\"\r\n\r\n### Actual result (*)\r\n1. Execute API call on: \"/rest/all/V1/integration/customer/token\" with json body:\r\n`\r\n{\r\n    \"username\":\"marcinwarzybok@outlook.com\",\r\n    \"password\":\"Abcdef123\"\r\n}\r\n`\r\nReturns error:\r\n`\r\n{\r\n    \"message\": \"The account sign-in was incorrect or your account is disabled temporarily. Please wait and try again later.\",\r\n    \"trace\": \"#0 [internal function]: Magento\\\\Integration\\\\Model\\\\CustomerTokenService->createCustomerAccessToken('marcinwarzybok@...', 'Abcdef123')\\n#1 /bitnami/magento/htdocs/vendor/magento/module-webapi/Controller/Rest/SynchronousRequestProcessor.php(95): calluserfuncarray(Array, Array)\\n#2 /bitnami/magento/htdocs/vendor/magento/module-webapi/Controller/Rest.php(188): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\SynchronousRequestProcessor->process(Object(Magento\\\\Framework\\\\Webapi\\\\Rest\\\\Request\\\\Proxy))\\n#3 /bitnami/magento/htdocs/vendor/magento/framework/Interception/Interceptor.php(58): Magento\\\\Webapi\\\\Controller\\\\Rest->dispatch(Object(Magento\\\\Framework\\\\App\\\\Request\\\\Http))\\n#4 /bitnami/magento/htdocs/vendor/magento/framework/Interception/Interceptor.php(138): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\Interceptor->callParent('dispatch', Array)\\n#5 /bitnami/magento/htdocs/vendor/magento/framework/Interception/Interceptor.php(153): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\Interceptor->Magento\\\\Framework\\\\Interception\\\\{closure}(Object(Magento\\\\Framework\\\\App\\\\Request\\\\Http))\\n#6 /bitnami/magento/htdocs/generated/code/Magento/Webapi/Controller/Rest/Interceptor.php(26): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\Interceptor->callPlugins('dispatch', Array, Array)\\n#7 /bitnami/magento/htdocs/vendor/magento/framework/App/Http.php(116): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\Interceptor->dispatch(Object(Magento\\\\Framework\\\\App\\\\Request\\\\Http))\\n#8 /bitnami/magento/htdocs/generated/code/Magento/Framework/App/Http/Interceptor.php(24): Magento\\\\Framework\\\\App\\\\Http->launch()\\n#9 /bitnami/magento/htdocs/vendor/magento/framework/App/Bootstrap.php(263): Magento\\\\Framework\\\\App\\\\Http\\\\Interceptor->launch()\\n#10 /bitnami/magento/htdocs/index.php(39): Magento\\\\Framework\\\\App\\\\Bootstrap->run(Object(Magento\\\\Framework\\\\App\\\\Http\\\\Interceptor))\\n#11 {main}\"\r\n}\r\n\r\n---\r\n- [ ] Severity: **S2** - Affects non-critical data or functionality and forces users to employ a workaround.\r\n"},
{"text": "### Preconditions (*)\r\n1. Magento ver. 2.3.1\r\n\r\n### Steps to reproduce (*)\r\n1. Configure the postman\r\n2. Make an API call using the below details\r\nAPI : rest /V1/orders\r\nRequest : {\"entity\": {\"entityid\": 89,\"status\": \"canceled\",\"incrementid\": \"000000074\"}}\r\nMethod : POST\r\n\r\n\r\n### Expected result (*)\r\n<!--- Tell us what do you expect to happen. -->\r\n1.  The order MUST be cancelled and the cancel status should be shown on orders page and  order details details \r\n\r\n\r\n### Actual result (*)\r\n<!--- Tell us what happened instead. Include error messages and issues. -->\r\n1. On orders page status is shown cancelled \r\n![image-20200902-214307](https://user-images.githubusercontent.com/54639289/92573794-e8599f00-f2a3-11ea-9b9a-5f3c20e4b35c.png)\r\n\r\n**2. The order status is showing Pending Status instead of cancelled.** \r\n![image-20200902-214503](https://user-images.githubusercontent.com/54639289/92574008-2bb40d80-f2a4-11ea-9967-5b40a18f278d.png)\r\n\r\n\r\n\r\n---\r\nPlease provide [Severity](https://devdocs.magento.com/guides/v2.3/contributor-guide/contributing.html#backlog) assessment for the Issue as Reporter. This information will help during Confirmation and Issue triage processes.\r\n\r\n- [ ] Severity: **S0** - Affects critical data or functionality and leaves users without workaround.\r\n- [ ] Severity: **S1** - Affects critical data or functionality and forces users to employ a workaround.\r\n- [ ] Severity: **S2** - Affects non-critical data or functionality and forces users to employ a workaround.\r\n- [ ] Severity: **S3** - Affects non-critical data or functionality and does not force users to employ a workaround.\r\n- [ ] Severity: **S4** - Affects aesthetics, professional look and feel, \"quality\" or \"usability\".\r\n"},
{"text": "The current auth.json approach uses your main Magento.com account credentials to authenticate, given that these accounts are used to manage publishing and payment for Magento Connect extensions, this presents a serious security concern. At the very least the authentication should be done using separate accounts created inside your main Magento account that can be revoked as and when necessary.\n\nFurthermore, you're explicitly forcing any developer in a shared development environment (i.e. most development companies) to breach your own [terms of service](http://magento.com/legal/terms/website).\n\n> You agree to treat as strictly private and confidential any user ID and related password which you may have received required for entry to any tool or service that we provide and all information to which you have access through password-protected areas and will not cause or permit any such information to be communicated, copied or otherwise divulged to any other person whatsoever. You are solely responsible for the security of your password. Any loss that you sustain due to a lack of security on your part regarding your codes or passwords is your sole loss to sustain.\n\nWhile I'm sure nobody would actually be pursued over this breach of terms, that's simply not good enough.\n"},
{"text": "We send the following POST request to /oauth/token/request with in the header Autorization \n\n> > OAuth \n> > oauthnonce=\"5A4856755A5868495330706F5A554E4759564E31\", oauthcallback=\"oob\", oauthsignaturemethod=\"HMAC-SHA1\", oauthtimestamp=\"1448631572\", oauthconsumerkey=\"l7vs6fqtilnsmcpjn9rpqnmi4qgcdu93\", oauthsignature=\"kCmZlP6mRwfI3aRPap0mmFB0Eds%3D\", oauthversion=\"1.0\" \n\nBut we get back the following error\n\n> > Cannot+create+request+token+because+consumer+token+is+not+a+verifier+token\n\nWhat does this mean? How to fix this?\n"},
{"text": "I am trying to create custom api using webapi and we need output in custom XML.\nWhen we are trying to return some XML and  hit the rest API url then XML shown as plain text in the <response> .... </response> tags. It is not creating XML in response.\n\nit shows like this : \n![image](https://cloud.githubusercontent.com/assets/6079017/12744480/82112a22-c9ba-11e5-8e11-d491f5edf39d.png)\n\nIs there any way to modify the response tag to get custom XML response.\n"},
{"text": "details here\n\nhttps://community.magento.com/t5/Programming-Questions/C-magento-2-0-2-error-deserialsing-SOAP-call/m-p/30859\n\nRelease: 2.0.2 Community Version.\n\nwriting a service by adding the magento soap url as a service reference,\nwhen calling the salesInvoiceRepositoryV1GetList i get an error with the framework tries to deserialise the data\n\nError in deserializing body of reply message for operation 'salesInvoiceRepositoryV1GetList'.\n\nfiddler returns the data correctly, but unable to deserialize\n"},
{"text": "## Steps to reproduce\n1. Install Magento from `develop` branch.\n2. Call /V1/customers/me rest api with (valid auth token) and body:\n   {\n   \"email\": \"test@test.com\",\n   \"firstname\": \"dsfsdf\",\n   \"lastname\": \"sdsdf\",\n   \"addresses\": [\n       {\n       \"firstname\": \"string\",\n       \"lastname\": \"string\"\n       }\n   ]\n   }\n## Expected result\n1. The customer gets created and 200 is returned\n## Actual result\n1. 400 bad request\n   {\n   \"message\": \"One or more input exceptions have occurred.\",\n   \"errors\": [\n     {\n       \"message\": \"%fieldName is a required field.\",\n       \"parameters\": {\n         \"fieldName\": \"firstname\"\n       }\n     },\n     {\n       \"message\": \"%fieldName is a required field.\",\n       \"parameters\": {\n         \"fieldName\": \"lastname\"\n       }\n     },\n     {\n       \"message\": \"Invalid value of \\\"%value\\\" provided for the %fieldName field.\",\n       \"parameters\": {\n         \"fieldName\": \"email\",\n         \"value\": null\n       }\n     }\n   ]\n   }\n"},
{"text": "## Steps to reproduce\n1. using Magento 2.0.4\n2. Call the api at POST /rest/V1/shipment with data\n\n`\n{\n    \"entity\": {\n        \"orderId\": 1,\n        \"comments\": [{\n            \"comment\": \"test\"\n        }]\n    }\n}`\n## Expected result\n1. Shipment created\n## Actual result\n\n`{\n\"message\": \"Could not save shipment\"\n}`\n\nand in the magneto logs\n\n[2016-03-06 18:07:10] main.CRITICAL: ZendDbStatementException: Report ID: webapi-56dc71ced11ac; Message: SQLSTATE[42S22]: Column not found: 1054 Unknown column 'price' in 'where clause', query was: SELECT `maintable`.\\* FROM `salesorder` AS `maintable` WHERE (`price` < '10') in /var/www/html/lib/internal/Magento/Framework/Webapi/ErrorProcessor.php:194\nStack trace:\n#0 /var/www/html/lib/internal/Magento/Framework/Webapi/ErrorProcessor.php(139): Magento\\Framework\\Webapi\\ErrorProcessor->critical(Object(ZendDbStatementException))\n#1 /var/www/html/app/code/Magento/Webapi/Controller/Rest.php(163): Magento\\Framework\\Webapi\\ErrorProcessor->maskException(Object(ZendDbStatementException))\n#2 /var/www/html/var/generation/Magento/Webapi/Controller/Rest/Interceptor.php(24): Magento\\Webapi\\Controller\\Rest->dispatch(Object(Magento\\Framework\\App\\Request\\Http))\n#3 /var/www/html/lib/internal/Magento/Framework/App/Http.php(115): Magento\\Webapi\\Controller\\Rest\\Interceptor->dispatch(Object(Magento\\Framework\\App\\Request\\Http))\n#4 /var/www/html/lib/internal/Magento/Framework/App/Bootstrap.php(258): Magento\\Framework\\App\\Http->launch()\n#5 /var/www/html/index.php(39): Magento\\Framework\\App\\Bootstrap->run(Object(Magento\\Framework\\App\\Http))\n#6 {main} [] []\n\nexception.logmain.CRITICAL: ZendDbStatementException: Report ID: webapi-56dc71ced11ac; Message: SQLSTATE[42S22]: Column not found: 1054 Unknown column 'price' in 'where clause', query was: SELECT `maintable`.\\* FROM `salesorder` AS `maintable` WHERE (`price` < '10') in /var/www/html/lib/internal/Magento/Framework/Webapi/ErrorProcessor.php:194\n"},
{"text": "Similar questions have been posted here, but none provided the solution that worked for me.\n## Summary\n\nI authenticated with `/admin/token`, and was able to access `/products/:sku`. However, when I tried to do `/products?searchCriteria...`, I encountered an access error:\n\n> { \"message\": \"Consumer is not authorized to access %resources\", \"parameters\": { \"resources\": \"MagentoCatalog::products\" } }\n\nI checked the user roles in my admin site, and I belong to a user role with access to all resources. Can you tell me why I'm seeing this error?\n## Steps I took\n1. Got an admin token\n   `curl -X POST \"http://magento2.stores.klaviyo.com/index.php/rest/V1/integration/admin/token\" \\\n    -H \"Content-Type:application/json\" \\\n    -d '{\"username\":<admin>, \"password\":<Minsanity1234}'`\n2. Did a test Web API call using the searchCriteria example given in Magento's official doc.\n   `http GET http://magento2.stores.klaviyo.com/index.php/rest/V1/products? \\\n   searchCriteria[filtergroups][0][filters][0][field]=size& \\\n   searchCriteria[filtergroups][0][filters][0][value]=Large& \\\n   searchCriteria[filtergroups][0][filters][0][conditiontype]=eq& \\\n   searchCriteria[filtergroups][0][filters][1][field]=color& \\\n   searchCriteria[filtergroups][0][filters][1][value]=Red& \\\n   searchCriteria[filtergroups][0][filters][1][conditiontype]=eq \\\n   Authorization:'Bearer oly9bh07dljyo2sj7n8ck1bd9iwn7ee9'`\n\nThank you!\n"},
{"text": "I am trying to create a Credit Memo for a billed unshipped sales order in Magento (version 2.0.4) of a Simple item via API. Here are the list of issues with while using REST API POST: /v1/creditmemo\nOrder Details\n1. contains single simple item price $20, no tax and no discount.\n2. Shipping cost of $5 fixed.\n3. paid by credit card.\n\n![image](https://cloud.githubusercontent.com/assets/12096540/14853775/85928ff0-0caa-11e6-838a-cdc1d7ebfba1.png)\n\nIssues\n1. Order Status doesn't change to closed even though the credit memo is created successfully.\n2. Can create multiple Credit memos for same orders as Order is not reflect that item is refunded ending up in refunding more than what was sold for.\n3. row total, Subtotal and Grand Total fields are not auto calculated as a result I can set those fields values to any higher value without any rational logic and still successfully creating the credit memo record. (i think payment gateway takes care of failing this transaction from refund but still these two values shouldn't be editable)\n4. When orderId field is not provided in the request to the api it throws 500 Internal Server error.\n\"Fatal Error: 'Call to a member function getId() on a non-object' in '<magento root folder>/vendor/magento/module-sales/Model/ResourceModel/Order/Creditmemo.php' on line 50\"\n\nHere is the request which was successfully creating the credit memo\n    {\n      \"entity\": {\n        \"orderId\": 7,\n        \"subtotal\": 100,\n        \"grandtotal\": 2000,\n        \"items\": [\n          {\n            \"orderItemId\": 7,\n            \"qty\": 1,\n            \"price\": 20,\n            \"rowtotal\": 20\n          }\n        ],\n        \"comments\": [\n         ],\n        \"extensionAttributes\": {}\n      }\n    }\nHere is the screenshot of the credit memo created.\n![image](https://cloud.githubusercontent.com/assets/12096540/14853790/9b6de716-0caa-11e6-96eb-dae8e3a39e0d.png)\n\nAfter credit memo for that item is created it is still as order status is not reflected that change.\n![image](https://cloud.githubusercontent.com/assets/12096540/14853854/de2439f2-0caa-11e6-9f6a-21c41707ea1c.png)\n\nHere is the request of credit memo for which it was failing with error.\n{\n      \"entity\": {\n        \"subtotal\": 100,\n        \"grandtotal\": 2000,\n        \"items\": [\n          {\n            \"orderItemId\": 7,\n            \"qty\": 1,\n            \"price\": 20,\n            \"rowtotal\": 20\n          }\n        ],\n        \"comments\": [\n         ],\n        \"extensionAttributes\": {}\n      }\n    }\n\nCan you please take a look and help on what I am doing wrong?\n"},
{"text": "## Steps to reproduce\n1. curl to magento 2.0.5 installation to get customer token\n2. curl -X POST \"http://youdomain/index.php/rest/V1/integration/customer/token\" \\\n    -H \"Content-Type:application/json\" \\\n    -d '{\"username\":\"xxx@yahoo.com\", \"password\":\"xxxxxxxx1\"}'\n## Expected result\n1. a token return\n## Actual result\n1. get the following msg: {\"message\":\"You did not sign in correctly or your account is temporarily disabled.\"}\n"},
{"text": "If we send an XML message like this:\n\n`<?xml` version=\"1.0\" encoding=\"utf-8\"?>\n`<soap:Envelope xmlns:soap=\"http://www.w3.org/2003/05/soap-envelope\" xmlns:def=\"http://localhost/magento205/soap/default?services=catalogProductLinkRepositoryV1\">\n`  soap:Body\n`<def:catalogProductLinkRepositoryV1SaveRequest>\n`     <entity>\n `<sku>1120</sku>\n`       <linkedProductSku>1001</linkedProductSku>\n `<linkedProductType>simple</linkedProductType>\n`       <position>3</position>\n `<linkType>associated</linkType>\n`       <extensionAttributes>\n `<qty>1</qty>\n`        </extensionAttributes>\n `</entity>\n`   /def:catalogProductLinkRepositoryV1SaveRequest\n `</soap:Body>\n`/soap:Envelope\n\nWe receive a true as response, but in the backend the item is not linked, reason is that the linked item is out of stock. if we set the item to instcok the item will be proper linked \n"},
{"text": "Hi there, \nAs per observation on Magento2.0 on back-end there is no \"Cancel\" option for the order which is invoiced completely, which goes as per logic. But If I make cancel call via api \"/V1/orders/{orderid}/cancel\"  in response I am getting \"true\" ,which is not correct. According to my understanding we should not be allowed to make cancel call for such orders.  Also , On making cancel call for already \"cancelled\" orders , we get \"true\" in response, instead of some error message.\n"},
{"text": "## Steps to reproduce\n1. Install Magento from `develop` branch.\n2. Create multiple categories and sub-categories for products.\n3. Make a REST api call GET /V1/categories, with or without search Criteria.\n## Expected result\n1.  The GET call should return json response with all the categories created from UI.\n## Actual result\n1. Only 1 category and it's sub-categories are returned in the json response.\n2. Sample response : \n   `{\n   \"id\": 2,\n   \"parentid\": 1,\n   \"name\": \"Default Category\",\n   \"isactive\": true,\n   \"position\": 1,\n   \"level\": 1,\n   \"productcount\": 28,\n   \"childrendata\": [\n     {\n       \"id\": 3,\n       \"parentid\": 2,\n       \"name\": \"Bike\",\n       \"isactive\": true,\n       \"position\": 1,\n       \"level\": 2,\n       \"productcount\": 29,\n       \"childrendata\": [\n         {\n           \"id\": 6,\n           \"parentid\": 3,\n           \"name\": \"Helmets\",\n           \"isactive\": true,\n           \"position\": 1,\n           \"level\": 3,\n           \"productcount\": 25,\n           \"childrendata\": []\n         }\n       ]\n     },\n     {\n       \"id\": 4,\n       \"parentid\": 2,\n       \"name\": \"Petrol components\",\n       \"isactive\": true,\n       \"position\": 2,\n       \"level\": 2,\n       \"productcount\": 8,\n       \"childrendata\": []\n     },\n     {\n       \"id\": 5,\n       \"parentid\": 2,\n       \"name\": \"Services\",\n       \"isactive\": true,\n       \"position\": 3,\n       \"level\": 2,\n       \"productcount\": 13,\n       \"childrendata\": []\n     }\n   ]\n   }`\n\n![categorybug](https://cloud.githubusercontent.com/assets/14216430/15291635/9582c352-1b9c-11e6-8c59-6c10ea8e2789.JPG)\n"},
{"text": "## Steps to reproduce\n1. Install Magento from `develop` branch.\n2. Create multiple attribute-sets with a lot of attributes assigned to them\n3. Make a GET call on /V1/products/attribute-sets/sets/list to get the list of all attribute-sets and their IDs.\n4. Make subsequent GET calls on /V1/products/attribute-sets/:ID/attributes for all attribute-sets.\n## Expected result\n1. It should return proper response for all the GET calls on /V1/products/attribute-sets/:ID/attributes\n## Actual result\n1. It gives proper response for some of the attribute-set IDs:\n2. It gives 500 response code and following error for some attribute-set IDs :\n   `{\n   \"messages\": {\n     \"error\": [\n       {\n         \"code\": 500,\n         \"message\": \"Server internal error. See details in report api/501949553088\"\n       }\n     ]\n   }\n   }`\n## Actual calls and responses\n\n1) /V1/products/attribute-sets/sets/list?searchCriteria[filtergroups][2][filters][0][field]=createdat&searchCriteria[filtergroups][2][filters][0][value]=2015-05-02T18:30:00.000Z&searchCriteria[filtergroups][2][filters][0][conditionType]=gt\n\nResponse : \n`{\n  \"items\": [\n    {\n      \"attributesetid\": 4,\n      \"attributesetname\": \"Default\",\n      \"sortorder\": 1,\n      \"entitytypeid\": 4\n    },\n    {\n      \"attributesetid\": 9,\n      \"attributesetname\": \"Helmet\",\n      \"sortorder\": 0,\n      \"entitytypeid\": 4\n    },\n    {\n      \"attributesetid\": 10,\n      \"attributesetname\": \"Ulti attributes\",\n      \"sortorder\": 0,\n      \"entitytypeid\": 4\n    },\n    {\n      \"attributesetid\": 11,\n      \"attributesetname\": \"Clothes - T shirts\",\n      \"sortorder\": 0,\n      \"entitytypeid\": 4\n    }\n  ],\n  \"searchcriteria\": {\n    \"filtergroups\": [\n      {\n        \"filters\": [\n          {\n            \"field\": \"entitytypecode\",\n            \"value\": \"catalogproduct\",\n            \"conditiontype\": \"eq\"\n          }\n        ]\n      }\n    ]\n  },\n  \"totalcount\": 4\n}`\n\n2) /V1/products/attribute-sets/4/attributes\n\nResponse : 200 OK \n`[\n  {\n    \"attributeid\": 73,\n    \"attributecode\": \"shortdescription\",\n    \"frontendinput\": \"textarea\",\n    \"entitytypeid\": \"4\",\n    \"isrequired\": false,\n    \"options\": [],\n    \"isuserdefined\": false,\n    \"defaultfrontendlabel\": \"Short Description\",\n    \"frontendlabels\": null,\n    \"backendtype\": \"text\",\n    \"isunique\": \"0\",\n    \"validationrules\": []\n  },...\n]`\n\n3) /V1/products/attribute-sets/9/attributes\n  `{\n  \"messages\": {\n    \"error\": [\n      {\n        \"code\": 500,\n        \"message\": \"Server internal error. See details in report api/501949553088\"\n      }\n    ]\n  }\n}` \n"},
{"text": "## Steps to reproduce\n1. Installed Magento 2.0.4\n2. Created 6 sample orders\n3. Implemented the following SOAP call\n\n```\n<x:Envelope xmlns:x=\"http://schemas.xmlsoap.org/soap/envelope/\" xmlns:def=\"http://localhost/magento2/soap/default?services=salesShipmentRepositoryV1\">\n    <x:Header/>\n    <x:Body>\n        <def:salesShipmentRepositoryV1GetListRequest>\n            <def:searchCriteria>\n                <def:pageSize>0</def:pageSize>\n                <def:currentPage>0</def:currentPage>\n            </def:searchCriteria>\n        </def:salesShipmentRepositoryV1GetListRequest>\n    </x:Body>\n</x:Envelope>\n```\n## Expected result\n\nIt should list all the 6 orders. It used to work with 3 orders then I shipped order#000000001 and everything ceased to function\n## Actual result\n\nIt lists only order 000000001\n\nIf I try to get order#000000006 explicitly like \n\n```\n<x:Envelope xmlns:x=\"http://schemas.xmlsoap.org/soap/envelope/\" xmlns:def=\"http://localhost/magento2/soap/default?services=salesShipmentRepositoryV1\">\n    <x:Header/>\n    <x:Body>\n        <def:salesShipmentRepositoryV1GetRequest>\n            <def:id>000000006</def:id>\n        </def:salesShipmentRepositoryV1GetRequest>\n    </x:Body>\n</x:Envelope>\n```\n\nit returns \n\"Requested entity doesn't exist\" error\n\nIn phpmyadmin SELECT `incrementid` FROM `salesorder` shows all my orders, so they are definitely there\n\n000000006\n000000005\n000000004\n000000003\n000000002\n000000001\n"},
{"text": "Hello,\n\nI try to use Magento 2.0.5 SOAP API. I am not able to retrieve attribute options. Attribute with code dm1 exists in the shop.\n\nRequest\n\n``` XML\n<soap:Envelope xmlns:soap=\"http://www.w3.org/2003/05/soap-envelope\" xmlns:def=\"XXX/soap/default?services=catalogProductAttributeOptionManagementV1%2CintegrationAdminTokenServiceV1\">\n   <soap:Header/>\n   <soap:Body>\n      <def:catalogProductAttributeOptionManagementV1GetItemsRequest>\n         <attributeCode>dm1</attributeCode>\n      </def:catalogProductAttributeOptionManagementV1GetItemsRequest>\n   </soap:Body>\n</soap:Envelope>\n```\n\nResponse\n\n``` XML\n<env:Envelope xmlns:env=\"http://www.w3.org/2003/05/soap-envelope\">\n   <env:Body>\n      <env:Fault>\n         <env:Code>\n            <env:Value>env:Receiver</env:Value>\n         </env:Code>\n         <env:Reason>\n            <env:Text>SOAP-ERROR: Encoding: object has no 'label' property</env:Text>\n         </env:Reason>\n      </env:Fault>\n   </env:Body>\n</env:Envelope>\n```\n"},
{"text": "### Preconditions\r\nMagento 2.0.7\r\n\r\n## Steps to reproduce\r\n1. Complete oAuth connection and acquire access token and secret\r\n## Expected result\r\n1. Access token and secret last indefinitely \r\n## Actual result\r\n1. If the Access token has not been used in Approx 1-2 hours, Magento2 deletes the Access token and Access Token Secret under the Integration Details so API calls no longer work.\r\n\r\nWhat could be causing this? Magento2 docs says this access token should last indefinitely.\r\n\r\nI know it's the actual Access token that's disappearing (and not the Request token) because the one I have matches the one listed in Magento (until it disappears), and it's the token I get after making the following calls (using the same oAuth library Magento uses):\r\n\r\n```\r\n    $credentials = new \\OAuth\\Common\\Consumer\\Credentials($consumerKey, $consumerSecret, $url);\r\n    $client = new OauthClient($credentials, $url);\r\n    $requestToken = $client->requestRequestToken();\r\n\r\n    $accessToken = $client->requestAccessToken(\r\n        $requestToken->getRequestToken(),\r\n        $oauthVerifier,\r\n        $requestToken->getRequestTokenSecret()\r\n    );\r\n```\r\n"},
{"text": "Hello,\n\nMe and my company are developing an Angular site for a client that communicates with Magento2 over Magento's build in REST api.\n\nOne of the requirements of the site is that there are multiple locals, that have slightly different catalogs of products. In this case we have a US store and EU store that have very similar but different products.\n\nI'm using the API endpoint\n`{{APIURL}}/rest/{{STOREVIEWCODE}}/V1/products`\nWith some extra searchCriteria\n\nThe problem is when I change the \"{{STOREVIEWCODE}}\" from one store view code to another, I see absolutely no difference in the payloads even though based on my configuration I should see different results. I've even confirmed that my store view changes are indeed applying by using the Luma front-end on my Magento2 install.\n\nThis is slightly hard to explain so here's a a gif of the behaviour.\n\nhttp://i.imgur.com/gBUObKX.gifv\n\nAs you can see from the GIF the \"Websites\" configuration of the product seems to have NO effect on the returning catalog call.\n\n I would expect to see that turning off the product in specific store views would remove the product from the REST api call.\n"},
{"text": "## Preconditions\r\n1. Install Magento from `2.1` branch.\r\n\r\n## Steps to reproduce\r\n1. Install Magento from `2.1` branch.\r\n2. Call http://magentohost/soap/default?wsdllist=1\r\n\r\n## Expected result\r\n\r\n...\r\n\r\n``` xml\r\n<item>\r\n    <wsdlendpoint>http://magentohost/soap/default?wsdl&amp;services=0</wsdlendpoint>\r\n  </item>\r\n```\r\n\r\n...\r\n\r\n## Actual result\r\n\r\nthe '&' is double escaped\r\n...\r\n\r\n``` xml\r\n<item>\r\n    <wsdlendpoint>http://magentohost/soap/default?wsdl&amp;amp;services=0</wsdlendpoint>\r\n  </item>\r\n```\r\n\r\n...\r\n\r\nmight be a duplicate of https://github.com/magento/magento2/issues/2206 \r\nif so, will this be fixed in the next 2.1 release?\r\n"},
{"text": "## Steps to reproduce\n1. Install Magento.\n2. Login to Magento frontend.\n3. Go to My Account and in the Address section update your address.\n4. Pull that customer using REST Api.\n## Expected result\n1. updatedat time should change.\n## Actual result\n1. updatedat time not changing.\n"},
{"text": "Reproducable steps:\n\n1) Successful POST to search for abandoned carts with a simple 1 filter group (updatedat greater than equal 2016-06-14):\n## https://devsvr.mydomain.com/index.php/rest/V1/carts/search?searchCriteria[filtergroups][0][filters][0][field]=updatedat&searchCriteria[filtergroups][0][filters][0][value]=2016-06-14&searchCriteria[filtergroups][0][filters][0][conditiontype]=gteq\n\nResult of Step 1:\nAssumed result is correct, it fetched 6 carts (3 Active, 3 InActive).  Actual result response data is in attached file 1FilterGroupResult.txt.\n## [1FilterGroup-Result.txt](https://github.com/magento/magento2/files/314665/1FilterGroup-Result.txt)\n\n2) Now perform a second query, adding an additional filter to narrow down the result (+ isactive equals true)\n## https://devsvr.mydomain.com/index.php/rest/V1/carts/search?searchCriteria[filtergroups][0][filters][0][field]=updatedat&searchCriteria[filtergroups][0][filters][0][value]=2016-06-14&searchCriteria[filtergroups][0][filters][0][conditiontype]=gteq&searchCriteria[filtergroups][1][filters][0][field]=isactive&searchCriteria[filtergroups][1][filters][0][value]=true&searchCriteria[filtergroups][1][filters][0][conditiontype]=eq\n\nResult of Step 2:\nAlthough POST transaction was successful, it fetched the exact opposite of what's expeted, it returned the 3 carts whose isactive flags are false.  Actual result response data is in attached file 2FilterGroups-Result-isActiveTRUE.txt.\n## [2FilterGroups-Result-isActiveTRUE.txt](https://github.com/magento/magento2/files/314664/2FilterGroups-Result-isActiveTRUE.txt)\n\n3) Changing the isactive filter value from true to false yielded the same 3 records whose isactive flags are FALSE (presumably generating a set of correct results).  Actual result response data is in attached file 2FilterGroups-Result-isActiveFALSE.txt.\n\n[2FilterGroups-Result-isActiveFALSE.txt](https://github.com/magento/magento2/files/314666/2FilterGroups-Result-isActiveFALSE.txt)\n\n---\n\nWhy did the the filter condition isactive eq true generate the wrong set of results?\n"},
{"text": "For Magento ver. 2.0.5 I am having following issue,\n\nI am using following endpoint to list the customers,\nFor this I am using Postman - REST Client 0.8.4.17 of crome using OAuth 1.0 Authorization\nhttp://< magentohost >/rest/V1/customers/search?searchCriteria[pagesize]=100\n\nAlong with the above request I am providing,\n1. Consumer Key\n2. Consumer Secret\n3. Token\n4. Token Secret\nThese I get from Integrations Extensions of System in Admin Panel of Magento.\n\nThe problem I come across is I am able to get the list of customers for some time (~= 2 hrs) & after this I am continuously getting following,\n{\n    \"message\": \"Consumer is not authorized to access %resources\",\n    \"parameters\": {\n        \"resources\": \"MagentoCustomer::customer\"\n    }\n}\n"},
{"text": "We receive message like procedure is not present when sending data by API, these are the default now, a lot of them are missing, which were available in previous versions, all functions regadring to catalog are missing, this is a serious bug. This is very critical! A lot of our customers are starting on Magento 2.1\n\n![image](https://cloud.githubusercontent.com/assets/15381778/16444892/976c67c0-3de0-11e6-9ccf-fd7623e55428.png)\n\n![image](https://cloud.githubusercontent.com/assets/15381778/16445149/9fc0ad54-3de1-11e6-9179-dca6f7acd811.png)\n\n![image](https://cloud.githubusercontent.com/assets/15381778/16445117/7b854ff8-3de1-11e6-9ca6-9fb5af77ba8b.png)\n\nThese should be part of the servcies;\n![image](https://cloud.githubusercontent.com/assets/15381778/16445232/f82ab156-3de1-11e6-8dd5-2d052c589547.png)\n\n[2016-06-29 07:58:03] main.CRITICAL: exception 'RuntimeException' with message 'Requested service is not available: \"customerV1\"' in C:\\wamp64\\www\\magento21\\vendor\\magento\\module-webapi\\Model\\ServiceMetadata.php:167\nStack trace:\n#0 C:\\wamp64\\www\\magento21\\vendor\\magento\\module-webapi\\Model\\Soap\\Wsdl\\Generator.php(366): Magento\\Webapi\\Model\\ServiceMetadata->getServiceMetadata('customerV1')\n#1 C:\\wamp64\\www\\magento21\\vendor\\magento\\module-webapi\\Model\\AbstractSchemaGenerator.php(169): Magento\\Webapi\\Model\\Soap\\Wsdl\\Generator->getServiceMetadata('customerV1')\n#2 C:\\wamp64\\www\\magento21\\vendor\\magento\\module-webapi\\Model\\Soap\\Wsdl\\Generator.php(374): Magento\\Webapi\\Model\\AbstractSchemaGenerator->getAllowedServicesMetadata(Array)\n#3 C:\\wamp64\\www\\magento21\\vendor\\magento\\module-webapi\\Model\\AbstractSchemaGenerator.php(104): Magento\\Webapi\\Model\\Soap\\Wsdl\\Generator->getAllowedServicesMetadata(Array)\n#4 C:\\wamp64\\www\\magento21\\vendor\\magento\\module-webapi\\Controller\\Soap.php(132): Magento\\Webapi\\Model\\AbstractSchemaGenerator->generate(Array, 'http', 'localhost', 'http://localhos...')\n#5 C:\\wamp64\\www\\magento21\\var\\generation\\Magento\\Webapi\\Controller\\Soap\\Interceptor.php(24): Magento\\Webapi\\Controller\\Soap->dispatch(Object(Magento\\Framework\\App\\Request\\Http))\n#6 C:\\wamp64\\www\\magento21\\vendor\\magento\\framework\\App\\Http.php(135): Magento\\Webapi\\Controller\\Soap\\Interceptor->dispatch(Object(Magento\\Framework\\App\\Request\\Http))\n#7 C:\\wamp64\\www\\magento21\\vendor\\magento\\framework\\App\\Bootstrap.php(258): Magento\\Framework\\App\\Http->launch()\n#8 C:\\wamp64\\www\\magento21\\index.php(39): Magento\\Framework\\App\\Bootstrap->run(Object(Magento\\Framework\\App\\Http))\n#9 {main}\n"},
{"text": "## Steps to reproduce\n1. Install Magento from `develop` branch.\n2. Create custom module with API and respond associative array like below\n   $response=[];\n   $response[\"priceformat''] =[\n   \"pattern\"=> \"$%s\",\n   \"precision\"=> \"2\",\n   \"requiredPrecision\"=> \"2\",\n   \"decimalSymbol\"=> \".\",\n   \"groupSymbol\"=> \",\",\n   \"groupLength\"=> \"3\",\n   \"integerRequired\"=> \"1\"\n   ];\n\nExpected result\n\n\"priceformat\": {\n    \"pattern\": \"$%s\",\n    \"precision\": \"2\",\n    \"requiredPrecision\": \"2\",\n    \"decimalSymbol\": \".\",\n    \"groupSymbol\": \",\",\n    \"groupLength\": \"3\",\n    \"integerRequired\": \"1\"\n  }\n## Actual result\n\n\"priceformat\": [\n    \"$%s\",\n    \"2\",\n    \"2\",\n    \".\",\n    \",\",\n    \"3\",\n    \"1\"\n  ]\n\nIt can be possible by making small change in class Magento\\Framework\\Reflection\\DataObjectProcessor as below, but unsure if it affect to other API SOAP or in core methods etc.\n\npublic function buildOutputDataArray($dataObject, $dataObjectType)\n{\n.\n.\n.\n.\n      foreach ($value as $elmKey =>$singleValue) {\n             if (isobject($singleValue) && !($singleValue instanceof Phrase)) {\n                   $singleValue = $this->buildOutputDataArray($singleValue, $arrayElementType);\n             }\n            $valueResult[$elmKey] = $this->typeCaster->castValueToType($singleValue, $arrayElementType)\n      }\n.\n.\n}\n"},
{"text": "## Steps to reproduce\n1. Magento 2.1.0\n2. Multistore\n3. rest/storecode/V1/categories - giving categories which are in defined storecode\n4. rest/<storecode>/V1/products - giving all products without filtering it by storecode\n5. rest/<store code which not exists>/V1/products - giving error. So storecode is checked but with changing storecode still receiving all products\n## Expected result\n1. Products which are turned on in defined storecode\n## Actual result\n1. all products from all stores\n"},
{"text": "Hi! I am develop integration with ERP. But have many problem with import large product catalog to Magento (2.1 from composer metapackage.)\nREST API Product create very slow - import one thousand products more 15 min.\n(post request to /rest/V1/products).\nInternal csv import work fast, but I can't start him remote. Also this way, there is no way to create the attributes and attributesets.\n\nSolve the problem with the speed REST API, please\n"},
{"text": "The issue does not occur in a fresh setup of CE 2.0.8, and does occur in a fresh setup of CE 2.1.0.\n\nTo reproduce:\nSet Stores > Configuration > Services > Web API > Web API Security > Allow Anonymous Guest Access = Yes\n\nVisit {store url}/swagger\nIn CE 2.0.8, catalogProductRepositoryV1 would have several verb types shown (post, put, delete). In CE 2.1.0, only two GET methods are available. The same items are missing when viewing all wsdl services as well.\n\nCreate and activate a new Integration with permission to access All resources.\nCreate a category and simple product with enough info to show up as a product page on the storefront.\n\nTest the integration with an authorized call to {store url}/rest/V1/products/{sku}\nNow try to change the visibility value to a 1 with a POST call. The response will be \"OK\", but the value will not be updated, and the entries for the product in the table urlrewrite will be missing!\n\nThe product delete REST call works despite not showing up in /swagger.\n\nThese issues are only a problem in 2.1.0.\n\nMy two main questions are:\n1) Does anyone with a CE 2.1.0 build see the POST, PUT, DELETE items on the /swagger page for catalogProductRepositoryV1?\n2) Is anyone else seeing their urlrewrite entries disappear when making product updates in REST?\n"},
{"text": "### Preconditions\n1. Magento CE 2.1.0 with sample data is installed.\n2. Integration successfully configured.\n### Steps to reproduce\n1. Create a cart (id = 3).\n2. Add items.\n3. Add shipping information `[POST] /rest/V1/carts/3/shipping-information`.\n4. Send request for `[PUT] /rest/V1/carts/3/order` with billingAddress and without paymentMethod parameter.\n### Expected result\n\n<!--- Tell us what should happen -->\n\n``` json\n\"message\": \"Payment method is required.\"\n```\n### Actual result\n\n``` json\n{\n    \"message\": \"Please check the billing address information. %1\",\n    \"parameters\": [\n        \"Please enter the first name. Please enter the last name. Please enter the street. Please enter the city. Please enter the phone number. Please enter the zip/postal code. Please enter the country.\"\n    ],\n    \"trace\": \"...\"\n}\n```\n\n<!--- (This may be platform independent comment) -->\n"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\n\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\n### Preconditions\n\n<!--- Provide a more detailed information of environment you use -->\n\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\n1. Magento version 2.1\n### Steps to reproduce\n\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\n1. Install magento\n2. Create a product with sku: test-sku\n3. Add a custom option by POST: rest/V1/products/option with body:\n\n> { \n>  \"option\": {\n>     \"productsku\" : \"test-sku\",\n>     \"title\" : \"Option title\",\n>     \"type\" : \"area\",\n>     \"pricetype\" : \"fixed\"\n>   }\n> }\n\nTry to update the option by PUT: rest/V1/products/option/(optionid created from POST) with body\n\n> { \n>  \"option\": {\n>     \"productsku\" : \"test-sku\",\n>     \"optionid\" : (optionid created from POST),\n>     \"title\" : \"Option title changed\",\n>     \"type\" : \"area\",\n>     \"pricetype\" : \"fixed\"\n>   }\n> }\n### Expected result\n\n<!--- Tell us what should happen -->\n1. The title should have been updated.\n### Actual result\n\n<!--- Tell us what happens instead -->\n1. New options get added instead of updating old. This happens in all store view so it's not possible to add translated titles to different store views.\n\nMaybe related to #5885 and #5931 \n\n<!--- (This may be platform independent comment) -->\n"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\n\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\n### Preconditions\n\n<!--- Provide a more detailed information of environment you use -->\n\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\n1.  Add Option to simple product in REST\n### Steps to reproduce\n\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\n1. Create Simple Product using REST or any another way.\n2. If i want to add new option to the product using (REST) with POST method  i have this message [Unable to save product]. the same if i want to update the product using PUT method with new options\n3. I tried to make some debug , then i have this error [Call to a member function getId() on a non-object] in this file [vendor/magento/module-catalog-inventory/Model/Plugin/AroundProductRepositorySave.php' on line 58\"].\n4. For example : i have two simple product (sku = simple1, sku = simple2).\n5. I want to add option to product (sku = simple1), with this json using PUT method in REST\n   {\n   \"option\": {\n     \"productsku\": \"simple1\",\n     \"title\": \"Option Title\",\n     \"type\": \"dropdown\",\n     \"sortorder\": 0,\n     \"isrequire\": true,\n     \"values\": [\n       {\n         \"title\": \"Value Title\",\n         \"sortorder\": 0,\n         \"price\": null,\n         \"pricetype\": null,\n         \"sku\": \"simple2\",\n         \"optiontypeid\": 2\n       }\n     ]\n   }\n   }\n6. End point [/V1/products/options] , method = POST\n### Expected result\n\n<!--- Tell us what should happen -->\n1. \n### Actual result\n\n<!--- Tell us what happens instead -->\n1. [Screenshot, logs]\n\n<!--- (This may be platform independent comment) -->\n"},
{"text": "Magento version is 2.1.0.\n\nWhen using REST for creating a new attribute, this works: \n\nURL: `post /rest/V1/products/attributes`\nBody:\n`{'attribute': {'attributeid': 0, 'frontendlabels': [{'storeid': 1, 'label': 'azmun'}], 'ishtmlallowedonfront': True, 'attributecode': 'azmun', 'position': 0, 'isuserdefined': True, 'isrequired': True, 'usedforsortby': True, 'isfilterable': True, 'frontendinput': 'multiselect', 'defaultfrontendlabel': 'azmun', 'isfilterableinsearch': True, 'isvisible': True, 'iswysiwygenabled': True}}`\n\nBut adding any of the following fields will make Magento throw an exception and return the index html page instead: **isusedingrid, isfilterableingrid, isvisibleingrid**\n\nLooking into the logs this will be shown:\n`Next exception 'Exception' with message 'Report ID: webapi-57b506762d4ff; Message: Property \"IsVisibleInGrid\" does not have corresponding setter in class \"Magento\\Catalog\\Api\\Data\\ProductAttributeInterface\".' in /home/pcpal/publichtml/vendor/magento/framework/Webapi/ErrorProcessor.php:195\n`\n"},
{"text": "I have a Dutch website. My REST user's language is set to English, but the responses of the REST interface are in Dutch :( \n\nIf I set a users language to x I would also expect the response to be in that language.\n\nTested on 2.1.0 and 2.2.0-dev\n### Steps to reproduce\n1.  Install a language pack\n2. Set admin user to use that language\n3. Deploy everything\n4. Create user with password for REST set language to english\n5. f.e. check non-existing product via REST wether it exists,\n### Expected result\n1. English language result\n### Actual result\n1. Non-English result\n"},
{"text": "I have a multi store website. I use the REST interface to add and maintain the products. When you add the product via the REST interface the URL rewrite is created for the product for the first website. When you add the product to another website via REST, the URL rewrite for the \"extra\" website/storefront is not created.\n\nTested on 2.1.0 and 2.2.0-dev\n### Steps to reproduce\n1. Create product via REST\n2. Add product to extra website via REST. f.e. In PHP add product with $sku to website with id 6:\n   \n   ```\n    $productData = array(\n       'sku'               => $sku ,\n       'websiteid'       => 6\n    );\n   \n    $setHaders = array('Content-Type:application/json','Authorization:Bearer '.$token);\n    $productData = jsonencode(array('productWebsiteLink' => $productData));\n    $requestURL = \"http://shop.domain.tld/rest/V1/products/\".$sku.\"/websites\";\n    echo $productData.\"\\n\\n\";\n    $ch = curlinit();\n    curlsetopt($ch,CURLOPTURL, $requestURL);\n    curlsetopt($ch,CURLOPTPOSTFIELDS, $productData);\n    curlsetopt($ch, CURLOPTCUSTOMREQUEST, \"POST\");\n    curlsetopt($ch, CURLOPTHTTPHEADER, $setHaders);\n    curlsetopt($ch, CURLOPTSSLVERIFYPEER, false);\n    curlsetopt($ch, CURLOPTRETURNTRANSFER, true);\n    if (curlexec($ch)===false) {\n      echo \"Curl error: \" . curlerror($ch).\"\\n\";\n    } else {\n      $response = curlexec($ch) ?: \"\";\n    }\n    curlclose($ch);\n   ```\n### Expected result\n1.  Product added to website\n2. URL Rewrites for all storefronts in website created\n### Actual result\n1.  Product added to website\n2. URL Rewrites not created\n"},
{"text": "On a completely fresh Magento 2.2.0 (HEAD) install with an empty database I created a product and associated an image with it using the REST API. Then I logged into the admin, edited the product and clicked Save. I then get this message:\n\n```\nItem (Magento\\Framework\\DataObject) with the same ID \"1\" already exists.\n```\n### Preconditions / Environment / Setup:\n- Ubuntu 16.04 LAMP stack: apt-get install -y apache2 mysql-server php-mysql php-mcrypt libapache2-mod-php unzip composer php-gd php-dom php-simplexml php-curl php-intl php-xsl php-mbstring php-zip git)\n- Clone the repostory: git clone https://github.com/magento/magento2.git\n- Install Magneto: bin/magento setup:install --base-url=http://example.com/ --backend-frontname=admin --db-host=localhost --db-name=magento --db-user=magento --db-password=magento --admin-firstname=Magento --admin-lastname=User --admin-email=user@example.com --admin-user=admin --admin-password=magento123 --language=enAU --currency=AUD --timezone=Australia/Sydney --use-rewrites=1\n- Deploy the static content: bin/magento setup:static-content:deploy\n- Reindex: bin/magento indexer:reindex\n### Steps to reproduce\n\n\\1. Use the REST API to create a product\n\n```\n    $api->post('products', ['json' => ['product' => [\n        'typeid' => 'simple',\n        'visibility' => 2,\n        'attributesetid' => 4,\n        'sku' => 'test',\n        'name' => 'Test Product',\n        'price' => 123.45,\n    ]]]);\n```\n\n\\2. Use the REST API to associate an image with the product.\n\n```\n    $api->post('products/test/media', ['json' => [\n        'entry' => [\n            'position' => 1,\n            'types' => ['image', 'smallimage', 'base', 'small', 'thumbnail', 'swatch'],\n            'mediatype' => 'image',\n            'label' => 'test',\n            'disabled' => false,\n            'file' => './',\n            'content' => [\n                'base64encodeddata' => base64encode(filegetcontents('http://lorempixel.com/output/abstract-q-c-640-480-3.jpg')),\n                'type' => 'image/jpeg',\n                'name' => 'test.jpg'\n            ]\n        ]\n    ]]);\n```\n\n\\3. Locate the product in the admin, edit it and click Save.\n\nNote: The API post code above is a simple wrapper around GuzzleHttp that will send the request along with the token provided by authenticating to the endpoint.\n### Expected result\n\nThe product should save.\n### Actual result\n\nThe product does not save with the message \n\n```\nItem (Magento\\Framework\\DataObject) with the same ID \"1\" already exists.\n```\n\nAdditionally the following stack trace is emitted into the exception.log:\n\n```\n[2016-08-22 21:54:00] main.CRITICAL: Exception: Item (Magento\\Framework\\DataObject) with the same ID \"1\" already exists. in /sites/magento/lib/internal/Magento/Framework/Data/Collection.php:406\nStack trace:\n#0 /sites/magento/app/code/Magento/Catalog/Model/Product.php(1477): Magento\\Framework\\Data\\Collection->addItem(Object(Magento\\Framework\\DataObject))\n#1 /sites/magento/var/generation/Magento/Catalog/Model/Product/Interceptor.php(869): Magento\\Catalog\\Model\\Product->getMediaGalleryImages()\n#2 /sites/magento/app/code/Magento/Catalog/Model/Product/Image/Cache.php(84): Magento\\Catalog\\Model\\Product\\Interceptor->getMediaGalleryImages()\n#3 /sites/magento/app/code/Magento/Catalog/Model/Product.php(931): Magento\\Catalog\\Model\\Product\\Image\\Cache->generate(Object(Magento\\Catalog\\Model\\Product\\Interceptor))\n#4 /sites/magento/var/generation/Magento/Catalog/Model/Product/Interceptor.php(362): Magento\\Catalog\\Model\\Product->afterSave()\n#5 /sites/magento/lib/internal/Magento/Framework/EntityManager/Observer/AfterEntitySave.php(34): Magento\\Catalog\\Model\\Product\\Interceptor->afterSave()\n#6 /sites/magento/lib/internal/Magento/Framework/Event/Invoker/InvokerDefault.php(73): Magento\\Framework\\EntityManager\\Observer\\AfterEntitySave->execute(Object(Magento\\Framework\\Event\\Observer))\n#7 /sites/magento/lib/internal/Magento/Framework/Event/Invoker/InvokerDefault.php(61): Magento\\Framework\\Event\\Invoker\\InvokerDefault->callObserverMethod(Object(Magento\\Framework\\EntityManager\\Observer\\AfterEntitySave), Object(Magento\\Framework\\Event\\Observer))\n#8 /sites/magento/lib/internal/Magento/Framework/Event/Manager.php(66): Magento\\Framework\\Event\\Invoker\\InvokerDefault->dispatch(Array, Object(Magento\\Framework\\Event\\Observer))\n#9 /sites/magento/var/generation/Magento/Framework/Event/Manager/Proxy.php(95): Magento\\Framework\\Event\\Manager->dispatch('magentocatalog...', Array)\n#10 /sites/magento/lib/internal/Magento/Framework/EntityManager/EventManager.php(51): Magento\\Framework\\Event\\Manager\\Proxy->dispatch('magentocatalog...', Array)\n#11 /sites/magento/lib/internal/Magento/Framework/EntityManager/Operation/Update.php(108): Magento\\Framework\\EntityManager\\EventManager->dispatchEntityEvent('Magento\\\\Catalog...', 'saveafter', Array)\n#12 /sites/magento/lib/internal/Magento/Framework/EntityManager/EntityManager.php(87): Magento\\Framework\\EntityManager\\Operation\\Update->execute(Object(Magento\\Catalog\\Model\\Product\\Interceptor), Array)\n#13 /sites/magento/app/code/Magento/Catalog/Model/ResourceModel/Product.php(611): Magento\\Framework\\EntityManager\\EntityManager->save(Object(Magento\\Catalog\\Model\\Product\\Interceptor))\n#14 /sites/magento/lib/internal/Magento/Framework/Interception/Interceptor.php(58): Magento\\Catalog\\Model\\ResourceModel\\Product->save(Object(Magento\\Catalog\\Model\\Product\\Interceptor))\n#15 /sites/magento/lib/internal/Magento/Framework/Interception/Interceptor.php(138): Magento\\Catalog\\Model\\ResourceModel\\Product\\Interceptor->callParent('save', Array)\n#16 /sites/magento/app/code/Magento/CatalogSearch/Model/Indexer/Fulltext/Plugin/Product.php(51): Magento\\Catalog\\Model\\ResourceModel\\Product\\Interceptor->Magento\\Framework\\Interception\\{closure}(Object(Magento\\Catalog\\Model\\Product\\Interceptor))\n#17 /sites/magento/app/code/Magento/CatalogSearch/Model/Indexer/Fulltext/Plugin/Product.php(24): Magento\\CatalogSearch\\Model\\Indexer\\Fulltext\\Plugin\\Product->addCommitCallback(Object(Magento\\Catalog\\Model\\ResourceModel\\Product\\Interceptor), Object(Closure), Object(Magento\\Catalog\\Model\\Product\\Interceptor))\n#18 /sites/magento/lib/internal/Magento/Framework/Interception/Interceptor.php(135): Magento\\CatalogSearch\\Model\\Indexer\\Fulltext\\Plugin\\Product->aroundSave(Object(Magento\\Catalog\\Model\\ResourceModel\\Product\\Interceptor), Object(Closure), Object(Magento\\Catalog\\Model\\Product\\Interceptor))\n#19 /sites/magento/lib/internal/Magento/Framework/App/Cache/FlushCacheByTags.php(60): Magento\\Catalog\\Model\\ResourceModel\\Product\\Interceptor->Magento\\Framework\\Interception\\{closure}(Object(Magento\\Catalog\\Model\\Product\\Interceptor))\n#20 /sites/magento/lib/internal/Magento/Framework/Interception/Interceptor.php(135): Magento\\Framework\\App\\Cache\\FlushCacheByTags->aroundSave(Object(Magento\\Catalog\\Model\\ResourceModel\\Product\\Interceptor), Object(Closure), Object(Magento\\Catalog\\Model\\Product\\Interceptor))\n#21 /sites/magento/lib/internal/Magento/Framework/Interception/Interceptor.php(153): Magento\\Catalog\\Model\\ResourceModel\\Product\\Interceptor->Magento\\Framework\\Interception\\{closure}(Object(Magento\\Catalog\\Model\\Product\\Interceptor))\n#22 /sites/magento/var/generation/Magento/Catalog/Model/ResourceModel/Product/Interceptor.php(273): Magento\\Catalog\\Model\\ResourceModel\\Product\\Interceptor->callPlugins('save', Array, Array)\n#23 /sites/magento/lib/internal/Magento/Framework/Model/AbstractModel.php(631): Magento\\Catalog\\Model\\ResourceModel\\Product\\Interceptor->save(Object(Magento\\Catalog\\Model\\Product\\Interceptor))\n#24 /sites/magento/var/generation/Magento/Catalog/Model/Product/Interceptor.php(2351): Magento\\Framework\\Model\\AbstractModel->save()\n#25 /sites/magento/app/code/Magento/Catalog/Controller/Adminhtml/Product/Save.php(111): Magento\\Catalog\\Model\\Product\\Interceptor->save()\n#26 /sites/magento/var/generation/Magento/Catalog/Controller/Adminhtml/Product/Save/Interceptor.php(24): Magento\\Catalog\\Controller\\Adminhtml\\Product\\Save->execute()\n#27 /sites/magento/lib/internal/Magento/Framework/App/Action/Action.php(102): Magento\\Catalog\\Controller\\Adminhtml\\Product\\Save\\Interceptor->execute()\n#28 /sites/magento/app/code/Magento/Backend/App/AbstractAction.php(227): Magento\\Framework\\App\\Action\\Action->dispatch(Object(Magento\\Framework\\App\\Request\\Http))\n#29 /sites/magento/lib/internal/Magento/Framework/Interception/Interceptor.php(58): Magento\\Backend\\App\\AbstractAction->dispatch(Object(Magento\\Framework\\App\\Request\\Http))\n#30 /sites/magento/lib/internal/Magento/Framework/Interception/Interceptor.php(138): Magento\\Catalog\\Controller\\Adminhtml\\Product\\Save\\Interceptor->callParent('dispatch', Array)\n#31 /sites/magento/app/code/Magento/Backend/App/Action/Plugin/Authentication.php(143): Magento\\Catalog\\Controller\\Adminhtml\\Product\\Save\\Interceptor->Magento\\Framework\\Interception\\{closure}(Object(Magento\\Framework\\App\\Request\\Http))\n#32 /sites/magento/lib/internal/Magento/Framework/Interception/Interceptor.php(135): Magento\\Backend\\App\\Action\\Plugin\\Authentication->aroundDispatch(Object(Magento\\Catalog\\Controller\\Adminhtml\\Product\\Save\\Interceptor), Object(Closure), Object(Magento\\Framework\\App\\Request\\Http))\n#33 /sites/magento/lib/internal/Magento/Framework/Interception/Interceptor.php(153): Magento\\Catalog\\Controller\\Adminhtml\\Product\\Save\\Interceptor->Magento\\Framework\\Interception\\{closure}(Object(Magento\\Framework\\App\\Request\\Http))\n#34 /sites/magento/var/generation/Magento/Catalog/Controller/Adminhtml/Product/Save/Interceptor.php(39): Magento\\Catalog\\Controller\\Adminhtml\\Product\\Save\\Interceptor->callPlugins('dispatch', Array, NULL)\n#35 /sites/magento/lib/internal/Magento/Framework/App/FrontController.php(55): Magento\\Catalog\\Controller\\Adminhtml\\Product\\Save\\Interceptor->dispatch(Object(Magento\\Framework\\App\\Request\\Http))\n#36 /sites/magento/lib/internal/Magento/Framework/Interception/Interceptor.php(58): Magento\\Framework\\App\\FrontController->dispatch(Object(Magento\\Framework\\App\\Request\\Http))\n#37 /sites/magento/lib/internal/Magento/Framework/Interception/Interceptor.php(138): Magento\\Framework\\App\\FrontController\\Interceptor->callParent('dispatch', Array)\n#38 /sites/magento/lib/internal/Magento/Framework/Module/Plugin/DbStatusValidator.php(69): Magento\\Framework\\App\\FrontController\\Interceptor->Magento\\Framework\\Interception\\{closure}(Object(Magento\\Framework\\App\\Request\\Http))\n#39 /sites/magento/lib/internal/Magento/Framework/Interception/Interceptor.php(135): Magento\\Framework\\Module\\Plugin\\DbStatusValidator->aroundDispatch(Object(Magento\\Framework\\App\\FrontController\\Interceptor), Object(Closure), Object(Magento\\Framework\\App\\Request\\Http))\n#40 /sites/magento/lib/internal/Magento/Framework/Interception/Interceptor.php(153): Magento\\Framework\\App\\FrontController\\Interceptor->Magento\\Framework\\Interception\\{closure}(Object(Magento\\Framework\\App\\Request\\Http))\n#41 /sites/magento/var/generation/Magento/Framework/App/FrontController/Interceptor.php(26): Magento\\Framework\\App\\FrontController\\Interceptor->callPlugins('dispatch', Array, NULL)\n#42 /sites/magento/lib/internal/Magento/Framework/App/Http.php(135): Magento\\Framework\\App\\FrontController\\Interceptor->dispatch(Object(Magento\\Framework\\App\\Request\\Http))\n#43 /sites/magento/lib/internal/Magento/Framework/App/Bootstrap.php(258): Magento\\Framework\\App\\Http->launch()\n#44 /sites/magento/pub/index.php(37): Magento\\Framework\\App\\Bootstrap->run(Object(Magento\\Framework\\App\\Http))\n#45 {main} [] []\n```\n\nHappy to provide more information if required.\n"},
{"text": "I was about to install 2.1.1 but read your statement.  We use Shipstation which sends us tracking numbers once per day.  This updates our order status to complete which then tells authorize.net to capture funds.  Will this process not work anymore?  If so, any idea how long it will take to fix this known issue?\n\nKnown issue\n\nThe Sales API does not currently support all the update operations on objects that you can execute from the Admin. (Objects in this context include orders, invoices, shipments, credit memos, and return merchandise authorizations.) The Sales API\n\nsupports create, read, delete, and search operations on objects\n\ndoes not support updates to order status or payment status. (Order status includes changes to processing, shipped, processed, and hold, while payment status includes authorized, charged, reject, and refund.)\n\nYou can run these operations from the Admin.\n"},
{"text": "I have deployed magento 2.0.7 on XAMP server. I want to add configurable product through rest API.\nFor that I used  http://host:port/Magento/index.php/rest/default/V1/products API. And post below data\n\"product\": {\n                            \"sku\": \"productname\",\n                            \"name\": \"productname\",\n                            \"status\": 1,\n                            \"typeid\": \"configurable\",\n                            \"price\": 500000,\n                            \"attributesetid\":4,\n                            \"weight\": 1\n                        }\n\nThis product is added to magento catalog,but Price for this product is not set.\n\nPlease suggest me on it.\n\n![image](https://cloud.githubusercontent.com/assets/21389647/18156804/9edbaa88-7036-11e6-9084-7bab69d59167.png)\n"},
{"text": "JSON Reference: http://devdocs.magento.com/swagger/index.html#/ \n\nSteps followed\nStep 1 --> http://<magentohost>/rest/default/V1/guest-carts  -- 200 OK\nStep 2 --> http://<magentohost>/rest/default/V1/guest-carts/{cart id}/items  -- 200 OK\nStep 3 --> http://<magentohost>/rest/default/V1/guest-carts/{cart id}/shipping-information \u2013 200 OK\nStep 4 --> http://<magentohost>/rest/default/V1/guest-carts/{cart id}/set-payment-information  -- 400 Bad Request and the response JSON as\n{\n  \"message\": \"Shipping address is not set\"\n}\n\nRequest JSON details:\n{\n  \"email\": \"happy5648@gmal.com\",\n  \"paymentMethod\": {\n    \"ponumber\": \"123\",\n    \"method\": \"purchaseorder\",\n    \"additionaldata\": [\n      \"\"\n    ],\n    \"extensionattributes\": {\n     \"agreementids\": [\n        \"\"\n      ]\n    }\n  },\n  \"billingAddress\": {\n      \"id\": 1,\n    \"region\": \"Virginia\",\n    \"regionid\": \"Virginia\",\n    \"regioncode\": \"VA\",\n    \"countryid\": \"US\",\n    \"street\": [\n      \"Symbiosis College\"\n    ],\n    \"company\": \"Happiest\",\n    \"telephone\": \"9090909090\",\n    \"fax\": \"13232212589\",\n    \"postcode\": \"51\",\n    \"city\": \"Bangalore\",\n    \"firstname\": \"Name\",\n    \"lastname\": \"lastName\",\n    \"middlename\": \"Middle\",\n    \"prefix\": \"Mr\",\n    \"suffix\": \"\",\n    \"vatid\": null,\n    \"customerid\": 1,\n    \"email\": \"abc.xyz@gmail.com\",\n    \"sameasbilling\": 0,\n    \"customeraddressid\": 0,\n    \"saveinaddressbook\": 0,\n    \"extensionattributes\": {},\n    \"customattributes\": [\n      {\n        \"attributecode\": \"\",\n        \"value\": \"\"\n      }\n    ]\n  }\n}\n\nPlease help resolve this issue.\n"},
{"text": "steps to reproduce: \n**Make API call with this body:**\n\n```\n<soap:Envelope xmlns:soap=\"http://www.w3.org/2003/05/soap-envelope\" xmlns:def=\"http://hereshouldbeyourmagentostoreurl.com/soap/default?services=salesOrderRepositoryV1\"><soap:Header/>\n   <soap:Body>\n      <def:salesOrderRepositoryV1GetListRequest>\n         <searchCriteria>\n            <filterGroups>\n               <!--Zero or more repetitions:-->\n\n            </filterGroups>\n            <!--Optional:-->\n\n            <!--Optional:-->\n\n            <!--Optional:-->\n            <sortOrders><item><field>createdAt</field><direction>DESC</direction></item></sortOrders><pageSize>100</pageSize><currentPage>1</currentPage>\n         </searchCriteria>\n      </def:salesOrderRepositoryV1GetListRequest>\n   </soap:Body>\n</soap:Envelope>\n```\n\n**Th answer is:**\n\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<env:Envelope xmlns:env=\"http://www.w3.org/2003/05/soap-envelope\" >\n   <env:Body>\n      <env:Fault>\n         <env:Code>\n            <env:Value>env:Receiver</env:Value>\n         </env:Code>\n         <env:Reason>\n            <env:Text xml:lang=\"en\">Internal Error. Details are available in Magento log file. Report ID: webapi-57c80c791008f</env:Text>\n         </env:Reason>\n\n      </env:Fault>\n   </env:Body>\n</env:Envelope>\n```\n\n**The problem is in sorting since when i removed this field:**\n\n```\n<soap:Envelope xmlns:soap=\"http://www.w3.org/2003/05/soap-envelope\" xmlns:def=\"http://hereshouldbeyourmagentostoreurl.com/soap/default?services=salesOrderRepositoryV1\">\n   <soap:Header/>\n   <soap:Body>\n      <def:salesOrderRepositoryV1GetListRequest>\n         <searchCriteria>\n            <filterGroups>\n               <!--Zero or more repetitions:-->\n\n            <item><filters><item><field>updatedAt</field><value>2016-03-10 20:24:00</value><conditionType>gt</conditionType></item><item><field>updatedAt</field><value>2016-09-10 20:24:00</value><conditionType>lt</conditionType></item></filters></item></filterGroups>\n            <!--Optional:-->\n\n            <!--Optional:-->\n\n            <!--Optional:-->\n            <pageSize>100</pageSize><currentPage>1</currentPage>\n         </searchCriteria>\n      </def:salesOrderRepositoryV1GetListRequest>\n   </soap:Body>\n</soap:Envelope>\n```\n\n**I received correct answer:**\n\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<env:Envelope xmlns:env=\"http://www.w3.org/2003/05/soap-envelope\" xmlns:ns1=\"http://hereshouldbeyourmagentostoreurl.com/soap/default?services=salesOrderRepositoryV1\">\n    <env:Body>\n        <ns1:salesOrderRepositoryV1GetListResponse>\n            <result>\n                <items>\n                    <item>\n                        <baseCurrencyCode>USD</baseCurrencyCode>\n                        <baseDiscountAmount>0</baseDiscountAmount>\n                        <baseGrandTotal>16</baseGrandTotal>\n...\n\n```\n"},
{"text": "Hello, \n\nI've followed all instructions given in \nhttp://devdocs.magento.com/guides/v2.0/howdoi/webapi/integration.html\n### File Tree\n\nthis is my module under **app/code/**\n\n```\nanar\n\u2514\u2500\u2500 module-testapi\n    \"\u2500\u2500 Setup\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 InstallData.php\n    \"\u2500\u2500 composer.json\n    \"\u2500\u2500 etc\n    \u2502\u00a0\u00a0 \"\u2500\u2500 integration\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \"\u2500\u2500 api.xml\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 config.xml\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 module.xml\n    \u2514\u2500\u2500 registration.php\n```\n### registration.php\n\n```\n<?php\n       \\Magento\\Framework\\Component\\ComponentRegistrar::register(\n     \\Magento\\Framework\\Component\\ComponentRegistrar::MODULE,\n     'AnarTestapi',\n     DIR\n     );\n```\n### composer.json\n\n```\n {\n      \"name\": \"AnarTestapi\",\n      \"description\": \"create integration from config\",\n      \"require\": {\n         \"php\": \"~5.5.0|~5.6.0|~7.0.0\",\n         \"magento/framework\": \"2.0.0\",\n         \"magento/module-integration\": \"2.0.0\"\n      },\n      \"type\": \"magento2-module\",\n      \"version\": \"1.0\",\n      \"autoload\": {\n         \"files\": [ \"registration.php\" ],\n         \"psr-4\": {\n            \"Anar\\\\Testapi\\\\\": \"\"\n         }\n      }\n   }\n```\n### module.xml\n\n```\n<config xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:noNamespaceSchemaLocation=\"urn:magento:framework:Module/etc/module.xsd\">\n       <module name=\"AnarTestapi\" setupversion=\"2.0.0\">\n            <sequence>\n                <module name=\"MagentoIntegration\"/>\n            </sequence>\n       </module>\n     </config>\n```\n### api.xml\n\n```\n<integrations>\n    <integration name=\"testIntegration\">\n        <resources>\n            <!-- To grant permission to MagentoLog::online, its parent MagentoCustomer::customer needs to be declared as well-->\n            <resource name=\"MagentoCustomer::customer\" />\n            <resource name=\"MagentoLog::online\" />\n            <!-- To grant permission to MagentoSales::reorder, all its parent resources need to be declared-->\n            <resource name=\"MagentoSales::sales\" />\n            <resource name=\"MagentoSales::salesoperation\" />\n            <resource name=\"MagentoSales::salesorder\" />\n            <resource name=\"MagentoSales::actions\" />\n            <resource name=\"MagentoSales::reorder\" />\n        </resources>\n    </integration>\n</integrations>\n```\n### config.xml\n\n```\n<integrations>\n   <integration name=\"TestIntegration\">\n       <email>anar@anar.com</email>\n       <endpointurl>http://anar.com</endpointurl>\n       <identitylinkurl>http://anar.com/identity</identitylinkurl>\n   </integration>\n</integrations>\n```\n## Installation\n\nI installed module like \n\n**bin/magento module:enable AnarTestapi**\n**bin/magento setup:upgrade**\n**bin/magento setup:di:compile**\n\nSeleted modulesetup after multiple tries.\nAlso tried everything mentioned in; \n\nhttps://github.com/magento/magento2/issues/4023 \nand \nhttps://github.com/magento/magento2/issues/4824\n\nbut still I dont see my integration.\n\nThank you \n"},
{"text": "### Preconditions\n\n<!--- Provide a more detailed information of environment you use -->\n\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\n1. Magento 2.1.1\n### Steps to reproduce\n\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\n1. Create a product via the Rest API, including a price and weight\n### Expected result\n\n<!--- Tell us what should happen -->\n1. The product is saved with the price and weight\n### Actual result\n\n<!--- Tell us what happens instead -->\n1. The price and weight are not saved and are not returned in the result of the POST request.\n\n<!--- (This may be platform independent comment) -->\n\nI traced this down to the BeforeEntitySave observer, where the price seems to be stripped off the product when $entity->beforeSave() is called. I did not continue research after that.\n\nWorkaround is to execute the post request again. During the update of the product, the price seems the be saved correctly.\n"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\n\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\n### Preconditions\n\nMagento Version 2.1\nPHP 7.0\n\nI'm, trying to get all products with the `ProductRepository`, but I only get an empty array.\n\nWhen accessing the `/rest/V1/products?searchCriteria=` REST endpoint, I get the a non-empty array.\n\nFor test reasons I added `$product = $this->productRepository->getById(1);` and this returns me the correct product with the id `1`.\n### Steps to reproduce\n\n``` php\nnamespace StackOverflow\\Lib;\n\nuse Magento\\Catalog\\Api\\ProductRepositoryInterface;\nuse Magento\\Framework\\Api\\SearchCriteriaBuilder;\n\nclass Demo {\n    public function construct(\n        ProductRepositoryInterface $productRepository,\n        SearchCriteriaBuilder $searchCriteriaBuilder\n    ) {\n        $this->productRepository = $productRepository;\n        $this->searchCriteriaBuilder = $searchCriteriaBuilder;\n    }\n\n    public function execute() {\n        $searchCriteria = $this->searchCriteriaBuilder\n            ->create();\n        $products = $this->productRepository->getList($searchCriteria)\n            ->getItems();\n        $product = $this->productRepository->getById(1); // This returns the correct product\n\n        vardump($products);\n    }\n}\n```\n### Expected result\n\nWhat I expected is an array of Products.\n\n``` php\n[ProductInterface]\n```\n### Actual result\n\nWhat I got is an empty array\n\n``` php\n[]\n```\n"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\n\nWe are getting this error \"Shipping address is not set\" when we are posting to /rest/V1/carts/mine/payment-information\n\n<!--- Before adding new issues, please, check this article \nhttps://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\n### Preconditions\n\n<!--- Provide a more detailed information of environment you use -->\n\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\n1. Magento 2.0.5\n2. PHP 5.6.19\n3. MySql 5\n### Steps to reproduce\n\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\n1. First post data to the following rest api url   /rest/V1/carts/mine/shipping-information\n\nREQUEST -\n\n{\"addressInformation\":{\"shippingAddress\":{\"id\":54,\"customerid\":4,\"region\":\"MH\",\"regionid\":0,\"countryid\":\"IN\",\"street\":[\"Chakala,Kalyan (e)\"],\"company\":\"abc\",\"telephone\":\"1111111\",\"postcode\":\"12223\",\"city\":\"Mumbai\",\"firstname\":\"Sameer\",\"lastname\":\"Sawant\",\"prefix\":\"address\",\"regioncode\":\"MH\",\"sameAsBilling\":1},\"billingAddress\":{\"id\":54,\"customerid\":4,\"region\":\"MH\",\"regionid\":0,\"countryid\":\"IN\",\"street\":[\"Chakala,Kalyan (e)\"],\"company\":\"abc\",\"telephone\":\"1111111\",\"postcode\":\"12223\",\"city\":\"Mumbai\",\"firstname\":\"Sameer\",\"lastname\":\"Sawant\",\"prefix\":\"address\",\"regioncode\":\"MH\"},\"shippingmethodcode\":\"flatrate\",\"shippingcarriercode\":\"flatrate\"}}\n\n**Response -** \n\n{\n \"paymentmethods\": [\n   {\n     \"code\": \"cashondelivery\",\n     \"title\": \"Cash On Delivery\"\n   },\n   {\n     \"code\": \"checkmo\",\n     \"title\": \"Check / Money order\"\n   },\n   {\n     \"code\": \"free\",\n     \"title\": \"No Payment Information Required\"\n   }\n ],\n \"totals\": {\n   \"grandtotal\": 14.55,\n   \"basegrandtotal\": 14.55,\n   \"subtotal\": 14.55,\n   \"basesubtotal\": 14.55,\n   \"discountamount\": 0,\n   \"basediscountamount\": 0,\n   \"subtotalwithdiscount\": 14.55,\n   \"basesubtotalwithdiscount\": 14.55,\n   \"shippingamount\": 0,\n   \"baseshippingamount\": 0,\n   \"shippingdiscountamount\": 0,\n   \"baseshippingdiscountamount\": 0,\n   \"taxamount\": 0,\n   \"basetaxamount\": 0,\n   \"weeetaxappliedamount\": null,\n   \"shippingtaxamount\": 0,\n   \"baseshippingtaxamount\": 0,\n   \"subtotalincltax\": 14.55,\n   \"shippingincltax\": 0,\n   \"baseshippingincltax\": 0,\n   \"basecurrencycode\": \"AED\",\n   \"quotecurrencycode\": \"AED\",\n   \"itemsqty\": 1,\n   \"items\": [\n     {\n       \"itemid\": 82,\n       \"price\": 14.55,\n       \"baseprice\": 14.55,\n       \"qty\": 1,\n       \"rowtotal\": 14.55,\n       \"baserowtotal\": 14.55,\n       \"rowtotalwithdiscount\": 0,\n       \"taxamount\": 0,\n       \"basetaxamount\": 0,\n       \"taxpercent\": 0,\n       \"discountamount\": 0,\n       \"basediscountamount\": 0,\n       \"discountpercent\": 0,\n       \"priceincltax\": 14.55,\n       \"basepriceincltax\": 14.55,\n       \"rowtotalincltax\": 14.55,\n       \"baserowtotalincltax\": 14.55,\n       \"options\": \"[]\",\n       \"weeetaxappliedamount\": null,\n       \"weeetaxapplied\": null,\n       \"name\": \"Keratin\"\n     }\n   ],\n   \"totalsegments\": [\n     {\n       \"code\": \"subtotal\",\n       \"title\": \"Subtotal\",\n       \"value\": 14.55\n     },\n     {\n       \"code\": \"shipping\",\n       \"title\": \"Shipping & Handling\",\n       \"value\": 0\n     },\n     {\n       \"code\": \"tax\",\n       \"title\": \"Tax\",\n       \"value\": 0,\n       \"extensionattributes\": {\n         \"taxgrandtotaldetails\": []\n       }\n     },\n     {\n       \"code\": \"grandtotal\",\n       \"title\": \"Grand Total\",\n       \"value\": 14.55,\n       \"area\": \"footer\"\n     }\n   ]\n }\n}\n1.  Afterwards POST data to /rest/V1/carts/mine/set-payment-information\n\nREQUEST -\n\n{\"paymentMethod\":{\"ponumber\":32,\"method\":\"cashondelivery\"},\"billingAddress\":{\"id\":54,\"customerid\":4,\"region\":\"MH\",\"regionid\":0,\"countryid\":\"IN\",\"street\":[\"Chakala,Kalyan (e)\"],\"company\":\"abc\",\"telephone\":\"1111111\",\"postcode\":\"400059\",\"city\":\"Mumbai\",\"firstname\":\"Sameer\",\"lastname\":\"Sawant\",\"prefix\":\"address\",\"regioncode\":\"MH\"}}\n\nRESPONSE - \n\n{\n \"message\": \"Shipping address is not set\"\n}\n\nPlease let us know where are we going wrong.\n\nCan you kindly tell us the rest api checkout process steps. It might be we must be missing something due to which we are getting the above error.\n### Expected result\n\n<!--- Tell us what should happen -->\n1. Order must be created from cart and get ID in response\n### Actual result\n\n<!--- Tell us what happens instead -->\n1. [Screenshot, logs]\n\n{\n \"message\": \"Shipping address is not set\"\n}\n\n<!--- (This may be platform independent comment) -->\n"},
{"text": "### Steps to reproduce\n1. Add items to cart, go to checkout and select \"Purchase Order\".\n   ![111](https://cloud.githubusercontent.com/assets/18581994/18447920/a94edfa8-78f6-11e6-83a1-4c271454fb81.PNG)\n2. Use REST API `[POST] /V1/carts/mine/payment-information`\n\n``` json\n{\n  \"paymentMethod\": {\n      \"method\": \"purchaseorder\"\n   }\n}\n```\n### Expected result\n\nError: PO number is required.\n### Actual result\n\n``` json\n\"90\"\n```\n\n(number of new order)\n### Additional info\n\n[API documentation](http://devdocs.magento.com/swagger/index.html) checkoutPaymentInformationManagementV1\n\n```\nquote-data-payment-interface {\n  ponumber (string, optional): Purchase order number ,\n  ...\n}\n```\n\n| Q | A |\n| --- | --- |\n| Magento version | 2.1.0 with sample data |\n| PHP version | 7 x64 |\n| Operating system | Windows 10 x64 |\n"},
{"text": "### Preconditions\n1. Magento 2.1 CE on PHP 7\n2. In section configuration /general / state options\n3. State is required for : Unselect all country. No one should be slected\n4. Allow to choose state if it is optional for country : NO\n\nWe use this configuration cause we do not need to have region field in our store. We do not need it and it's one more field in form and that cool for the UX and conversion rate.\n### Steps to reproduce\n1. We had to remove manually the field cause the setup in configuration did not work properly (the field was still mandatory in back office) \n2. Try to confirm an order with an adress without region and you should have this message in front office. It will disapear depending on the order. Sometime if you create a new adress it won't appear. (appear in log files)\n### Expected result\n1. Be able to confirme order without the bug\n### Actual result\n\n`Next Exception: Report ID: webapi-57d7bf41422a0; Message: Recoverable Error: Object of class Magento\\Customer\\Model\\Data\\Region could not be converted to string in /var/www/ourNameSpace/rec/src/releases/2016-09-13-08-25/vendor/magento/framework/DB/Adapter/Pdo/Mysql.php on line 2915 in /var/www/ourNameSpace/rec/src/releases/2016-09-13-08-25/vendor/magento/framework/Webapi/ErrorProcessor.php:...\nStack trace:\n#0 /var/www/ourNameSpace/rec/src/releases/2016-09-13-08-25/vendor/magento/framework/Webapi/ErrorProcessor.php(...: Magento\\Framework\\Webapi\\ErrorProcessor->critical(Object(Exception))\n#1 /var/www/ourNameSpace/rec/src/releases/2016-09-13-08-25/vendor/magento/module-webapi/Controller/Rest.php(21...: Magento\\Framework\\Webapi\\ErrorProcessor->maskException(Object(Exception))\n#2 /var/www/ourNameSpace/rec/src/releases/2016-09-13-08-25/var/generation/Magento/Webapi/Controller/Rest/Inter...: Magento\\Webapi\\Controller\\Rest->dispatch(Object(Magento\\Framework\\App\\Request\\Http))\n#3 /var/www/ourNameSpace/rec/src/releases/2016-09-13-08-25/vendor/magento/framework/App/Http.php(135): Magento\\Webapi\\Controller\\Rest\\Interceptor->dispatch(Object(Magento\\Framework\\App\\Request\\Http))\n#4 /var/www/ourNameSpace/rec/src/releases/2016-09-13-08-25/vendor/magento/framework/App/Bootstrap.php(258): Magento\\Framework\\App\\Http->launch()\n#5 /var/www/ourNameSpace/rec/src/releases/2016-09-13-08-25/index.php(39): Magento\\Framework\\App\\Bootstrap->run(Object(Magento\\Framework\\App\\Http))\n#6 {main} [] []`\n"},
{"text": "### Steps to reproduce\n1. Send `[POST] /V1/orders`\n\n``` json\n{\n  \"entity\": {\n      \"entityid\": 103,\n      \"payment\": {\n          \"ponumber\":\"si-103\",\n          \"method\":\"purchaseorder\",\n          \"entityid\":104\n      }\n  }\n}\n```\n\nAnd if you send\n\n``` json\n{\n  \"entity\": {\n      \"payment\": {\n          \"ponumber\":\"si-103\",\n          \"method\":\"purchaseorder\",\n          \"entityid\":104\n      }\n  }\n}\n```\n\nYou have\n\n``` html\n<br />\n<b>Fatal error</b>:  Uncaught Error: Call to a member function getMethodInstance() on null in \\vendor\\magento\\module-payment\\Observer\\SalesOrderBeforeSaveObserver.php:24\nStack trace:\n...\n```\n\nThis is bad.\n### Expected result\n\nPO number is `si-103`.\n### Actual result\n\nPO number is `NULL`.\n### Additional info\n\n[API documentation](http://devdocs.magento.com/swagger/index.html) salesOrderRepositoryV1\n\n| Q | A |\n| --- | --- |\n| Magento version | 2.1.0 with sample data |\n| PHP version | 7 x64 |\n| Operating system | Windows 10 x64 |\n"},
{"text": "### Preconditions\n\nMagento 2.1.1\n1. Braintree payment method is configured and enabled Vault\n2. Placed order with saved card \n### Steps to reproduce\n1. rest call on /rest/V1/orders/{$orderId} endpoint\n### Expected result\n1. Order information is returned\n### Actual result\n1. Exception: Internal Error. Details are available in Magento log file. Report ID: webapi-***\\* is returned\n\nDetails from log file:\nmain.CRITICAL: exception 'Exception' with message 'Notice: Array to string conversion in /lib/internal/Magento/Framework/Reflection/TypeCaster.php on line 34' in /lib/internal/Magento/Framework/App/ErrorHandler.php:61\n"},
{"text": "Shipment retrieval via REST API results in error during jsonencode returning a blank result. This happens because of the data stored in the shippinglabel BLOB.\n### Preconditions\n1. Magento 2.1.1\n2. PHP 5.6.22\n3. MySQL 5.6.28\n### Steps to reproduce\n1. Create a test order and generate a shipment with a shipping label.\n2. Attempt to retrieve the shipment via REST API with the following endpoint:\n\n/rest/V1/shipments?searchCriteria[filtergroups][0][filters][0][field]=orderid&searchCriteria[filtergroups][0][filters][0][value]=orderidvaluetosearch&searchCriteria[filtergroups][0][filters][0][conditiontype]=eq\n### Expected result\n1. Should return a JSON array of the shipment data\n### Actual result\n1. No response is returned because of an error thrown during jsonencode. It fails to encode the data in the shippinglabel field.\n\nThe error returned by jsonlasterrormsg() is \"Malformed UTF-8 characters, possibly incorrectly encoded\".\n\nPlease note, this endpoint works fine with the following two scenarios:\n1. If there is no shipment associated with an order, the API returns an error.\n2. If there is no shippinglabel associated with the shipment, the API returns the shipment information.\n"},
{"text": "Magento 2.1.1\n\nREST API\n\n**REQUEST**\nPOST /V1/integration/customer/token\n{\n  \"username\": \"EMAIL\",\n  \"password\": \"PASSWORD\"\n}\n\n**RESPONSE** - 200 OK, \nHEADER: Content-Type **application/json; charset=utf-8**\n\nbut response body is not valid JSON but just \"token\". \n\nThis is serious bug. \n"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\n\nI add magento 2.1.0 SOAP api service reference to C# project. I use \nPOST https://www.xxx.com/soap/default?services=salesOrderRepositoryV1 trying to get orded by id. If orders exists respons is SOAP 12 but if there is no order response is SOAP11\n\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\n### Preconditions\n\n<!--- Provide a more detailed information of environment you use -->\n\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\n1. Magento 2.1.0.\n2. C#, WebService reference generated by Visual Studio\n### Steps to reproduce\n\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\n1. request:\n\n```\nPOST https://www.mymagento.com/soap/default?services=salesOrderRepositoryV1 \n\n\n<s:Envelope xmlns:s=\"http://schemas.xmlsoap.org/soap/envelope/\"><s:Body><salesOrderRepositoryV1GetRequest xmlns=\"https://www.mymagento.com/soap/default?services=salesOrderRepositoryV1\"><id xmlns=\"\">432</id></salesOrderRepositoryV1GetRequest></s:Body></s:Envelope>\n```\n1. \n2. \n### Expected result\n\n<!--- Tell us what should happen -->\n1. this is an example of response where magento order exists. Response is SOAP 12. Response body starts from\n\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<SOAP-ENV:Envelope xmlns:SOAP-ENV=\"http://schemas.xmlsoap.org/soap/envelope/\" xmlns:ns1=\"https://www.mymagento.com/soap/default?services=salesOrderRepositoryV1\"><\n```\n### Actual result\n\n<!--- Tell us what happens instead -->\n1. Response is SOAP 11. Response body\n\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<env:Envelope xmlns:env=\"http://www.w3.org/2003/05/soap-envelope\" >\n   <env:Body>\n      <env:Fault>\n         <env:Code>\n            <env:Value>env:Sender</env:Value>\n         </env:Code>\n         <env:Reason>\n            <env:Text xml:lang=\"en\">Requested entity doesn't exist</env:Text>\n         </env:Reason>\n\n      </env:Fault>\n   </env:Body>\n</env:Envelope>\n\n```\n\n<!--- (This may be platform independent comment) -->\n\nUPDATE:\n\nAnother strange thing - is that really this order exists. I received this order `432` from GetList API function\n"},
{"text": "We pulled the latest code from Magento2 and install the Magento2 instance\nProblem -1\n### Preconditions\n\n<!--- Provide a more detailed information of environment you use -->\n\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\n1. Magento develop branch\n2. php-fpm version 5.6 MySQL 5.6\n### Steps to reproduce\n\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\n1.  create a configurable Product using api using POST: /V1/products using the following JSON body\n   {\n   \"product\" : {\n       \"sku\" : \"Test-Product-Parent\",\n       \"name\" : \"Test-Product-Parent\",\n       \"attributesetid\" : 4,\n       \"price\" : 50,\n       \"status\" : 1,\n       \"visibility\" : 4,\n       \"typeid\" : \"configurable\",\n       \"weight\" : 2,\n       \"extensionattributes\" : {\n   \n   ```\n   }\n   ```\n   \n   }\n   }\n2.  Then make a call to links SKU using POST: /V1/configurable-products/Test-Product-Parent/child using the following JSON body\n   {\n   \"childSku\":\"TestProduct-Red\" \n   }\n3.  It links this item but later if you try to link another item it doesn't link another item. I am trying for new item to link\n   Then make a call to links Child SKU using POST: /V1/configurable-products/Test-Product-Parent/child using the following JSON body\n   {\n   \"childSku\":\"Test-Product-Blue\" \n   }\n\nIt gives me 200 as status code and response as true.\n### Expected result\n\n<!--- Tell us what should happen -->\n1.  I should be seeing two ChildSkus linked to Parent product.\n### Actual result\n\n<!--- Tell us what happens instead -->\n1. Only first item is linked to parent item. We can see this by making the following api call GET: /V1/configurable-products/Test-Product-Parent/children and here is the response\n   [\n   {\n     \"sku\": \"TestProduct-Red\",\n     \"name\": \"TestProduct-Red\",\n     \"attributesetid\": 4,\n     \"price\": 24,\n     \"status\": 1,\n     \"typeid\": \"simple\",\n     \"createdat\": \"2016-09-26 12:30:40\",\n     \"updatedat\": \"2016-09-26 12:30:40\",\n     \"weight\": 2,\n     \"extensionattributes\": [],\n     \"productlinks\": [],\n     \"tierprices\": [],\n     \"customattributes\": [\n       {\n         \"attributecode\": \"taxclassid\",\n         \"value\": \"2\"\n       },\n       {\n         \"attributecode\": \"categoryids\",\n         \"value\": [\n           \"2\"\n         ]\n       },\n       {\n         \"attributecode\": \"requiredoptions\",\n         \"value\": \"0\"\n       },\n       {\n         \"attributecode\": \"hasoptions\",\n         \"value\": \"0\"\n       },\n       {\n         \"attributecode\": \"urlkey\",\n         \"value\": \"testproduct-red\"\n       }\n     ]\n   }\n   ]\n\nI cannot attach more than one SKU using the api to configurable item created via API. \nI have all details of attributes set same in all three records and also configurable attribute is same.\n"},
{"text": "The task at hand is to synchronize the Magento products qty with data from a POS. A simple code sample provided at http://devdocs.magento.com/guides/v2.1/howdoi/webapi/filter-response.html is not working as expected. The API does return product information, but the extensionattributes always returns null.\n### Preconditions\n1. Magento 2.1.0\n2. PHP 5.6\n### Steps to reproduce\n\nPerformed a curl with \"http://myhost.dev/rest/default/V1/products/12345/?fields=name,sku,extensionattributes[categorylinks,stockitem[itemid,qty]]\"\nNote: From ?fields onward this came directly from the documentation source listed above\n### Expected result\n\nAccording to the documentation, the result should be similar to:\n\n{\n  \"sku\": \"12345\"\n  \"name\": \"Product Name\"\n  \"extensionattributes\": {\n    \"categorylinks\": {\n      \"position\": 1\n      \"categoryid\": \"123\"\n    }\n    \"stockitem\": {\n      \"itemid\": 321\n      \"qty\": 1\n      }\n  }\n}\n### Actual result\n\nA vardump of the response I get from the API is as follows:\n\n\"{\"sku\":\"12345\",\"name\":\"Product Name\",\"extensionattributes\":null}\"\n\nI have altered the product sku and name in my example as they are irrelevant. The NULL response for the extensionattributes is concerning me, as I reproduced the example I saw in the documentation after many other attempts to receive this data. Always a NULL response. Either I'm doing something wrong, the documentation is inaccurate, or the software is faulty.\n"},
{"text": "I try to assign a customer to a quote using the REST API. I do this according to the manual:\n\nhttp://devdocs.magento.com/swagger/index.html#!/quoteGuestCartManagementV1/quoteGuestCartManagementV1AssignCustomerPut\n\nThis is a guest-endpoint so it should not require authentication. However, when I try to use it, the API tells me I am not allowed to do so\n### Preconditions\n1. Magento 2.1.1\n### Steps to reproduce\n1. Setup a quote as a guest and get it's masked ID (in this example it's `17ce47dfff93f4f07a2deec97dd5c3ab`.\n2. Create a customer and get it's ID (in this example it's `10`)\n3. Create the API call. For example:\n\n```\ncurl -X PUT -H \"Content-Type: application/json\" \\\n    -d '{\"customerId\":10}' \\\n    \"http://www.domain.com/rest/V1/guest-carts/17ce47dfff93f4f07a2deec97dd5c3ab/\"\n```\n### Expected result\n1. A logic response from the API and the customer saved to the quote (as documented)\n### Actual result\n1. 401 response with the following message:\n\n```\n{\n  \"message\": \"Consumer is not authorized to access %resources\",\n  \"parameters\": {\n    \"resources\": \"self\"\n  },\n  \"trace\": \"\n#0 /var/www/public/vendor/magento/module-webapi/Controller/Rest/RequestValidator.php(70): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\RequestValidator->checkPermissions()\\n\n#1 /var/www/public/vendor/magento/module-webapi/Controller/Rest/InputParamsResolver.php(80): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\RequestValidator->validate()\\n\n#2 /var/www/public/vendor/magento/module-webapi/Controller/Rest.php(299): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\InputParamsResolver->resolve()\\n\n#3 /var/www/public/vendor/magento/module-webapi/Controller/Rest.php(216): Magento\\\\Webapi\\\\Controller\\\\Rest->processApiRequest()\\n\n#4 /var/www/public/var/generation/Magento/Webapi/Controller/Rest/Interceptor.php(37): Magento\\\\Webapi\\\\Controller\\\\Rest->dispatch(Object(Magento\\\\Framework\\\\App\\\\Request\\\\Http))\\n\n#5 /var/www/public/vendor/magento/framework/App/Http.php(135): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\Interceptor->dispatch(Object(Magento\\\\Framework\\\\App\\\\Request\\\\Http))\\n\n#6 /var/www/public/vendor/magento/framework/App/Bootstrap.php(258): Magento\\\\Framework\\\\App\\\\Http->launch()\\n\n#7 /var/www/public/pub/index.php(37): Magento\\\\Framework\\\\App\\\\Bootstrap->run(Object(Magento\\\\Framework\\\\App\\\\Http))\\n\n#8 {main}\"\n}\n\n```\n"},
{"text": "The protected SOAP endpoints prevent Visual Studio from generating the necessary intermediate files to write software against\r\n### Preconditions\r\n1. Mage 2.1.1\r\n2. PHP 7.0.11\r\n3. Visual Studio 2015 CE\r\n### Steps to reproduce\r\n1.  Enable \"Allow Anonymous Guest Access\" against the store\r\n2.  Create an Integration account with \"Resource Access: All\"\r\n3.  Open Visual Studio -> Add Service Reference.\r\n4.  Use url http://[mystore]/soap/default?wsdl=1&services=salesOrderRepositoryV1\r\n### Expected result\r\n1. The same as using an allowed URL IE http://[mystore]/soap/default?wsdl=1&services=catalogProductAttributeGroupRepositoryV1\r\n### Actual result\r\n\r\nThere was an error downloading 'http://[mystore]/soap/default?wsdl=1&services=salesOrderRepositoryV1/$metadata'.\r\nThe request failed with HTTP status 400: Bad Request.\r\nMetadata contains a reference that cannot be resolved: 'http://[mystore]/soap/default?wsdl=1&services=salesOrderRepositoryV1'.\r\nThe HTTP request is unauthorized with client authentication scheme 'Anonymous'. The authentication header received from the server was ''.\r\nThe remote server returned an error: (401) Unauthorized.\r\nIf the service is defined in the current solution, try building the solution and adding the service reference again.\r\n### Other Things I have tried\r\n1. Using the WSDL.exe tool directly and supplying a the username and AccessToken for the Integration user account and it returns a 401 error\r\n2. Adding a Web Reference instead of a Service Reference and supplying the login credentials in the url IE\r\n   http://[ServiceUserAccount]:[AccessToken]@[mystore]/soap/default?wsdl=1&services=catalogProductAttributeTypesListV1    returns a 401\r\n3. Doing the above in a web browser returns a 401 with no access to %resource page\r\n"},
{"text": "### Issue\n\nI am trying to create a script which will update product tier prices for all Magento product types using the Magento SOAP API. Using the add method on the catalogProductTierPriceManagementV1 endpoint I am able to update tiered pricing for simple products, so for example I can set different prices for 20-40, 40-60 products etc. However, when I update simple products associated with a configurable product, the simple products lose their relationship with the configurable product which of course breaks the product on the site. It could be that I am going about this in the wrong way or that there is a bug. I've not been able to find much in the way of examples. \n### Development environment\n\nMy development environment is set up as detailed here:\nhttps://github.com/paliarush/magento2-vagrant-for-developers#what-you-get\n### Steps to reproduce\n\nIn my script, to update the main price for each simple product I am calling:\n\n`$soapClient->catalogProductRepositoryV1Save(['product' => ['sku' => 'EPFG', 'price' => 7.00]]);`\n\nTo update the simple product tiered pricing, I am using this script:\n\n```\n$row = 1;\n$handle = fopen('tier-prices-configurable.csv', 'r');\nwhile (($data = fgetcsv($handle, ',')) !== false) {\n    if ($row != 1) {\n        $requestData = '';\n        $sku = $data[0];\n        $customerGroupId = $data[1];\n        $qty = $data[2];\n        $price = $data[3];\n\n        $requestData = [\n            'sku' => $sku,\n            'customerGroupId' => $customerGroupId,\n            'qty' => $qty,\n            'price' => $price,\n        ];\n\n        try {\n            // Update tiered prices\n            if (!empty($sku)) {\n                $soapClient->catalogProductTierPriceManagementV1Add($requestData);\n            }\n\n        } catch (Exception $e) {\n            $errors .= 'Error for SKU ' . $sku . ': ' . $e->getMessage() . \"\\n\";\n        }\n    }\n\n    $row++;\n}\n```\n### Expected result\n\n<!--- Tell us what should happen -->\n1. The main price and tiered pricing for each of the simple products to be updated.\n2. When the simple products associated with a configurable product are updated they maintain their relation as child products to the configurable product.\n### Actual result\n1. The simple products are updated, but those associated with a configurable product are no longer associated with that configurable product as child products.\n\n<!--- (This may be platform independent comment) -->\n"},
{"text": "### Preconditions\r\nMagento 2.1.1\r\n\r\nI want to be able to change the `<resource ref=\"self\" />` to `<resource ref=\"anonymous\" />` in a non-obstructive way, but there's currently no way of doing this. Take the following snippet from `quote/etc/webapi.xml`:\r\n\r\n```\r\n<route url=\"/V1/guest-carts/:cartId\" method=\"PUT\">\r\n    <service class=\"Magento\\Quote\\Api\\GuestCartManagementInterface\" method=\"assignCustomer\"/>\r\n    <resources>\r\n        <resource ref=\"self\" />\r\n    </resources>\r\n</route>\r\n```\r\n\r\nI want to be able to make this endpoint accessible anonymously. I thought I'd simply add a `webapi.xml` to my own module and add the following line:\r\n\r\n```\r\n<route url=\"/V1/guest-carts/:cartId\" method=\"PUT\">\r\n    <resources>\r\n        <resource ref=\"anonymous\" />\r\n    </resources>\r\n</route>\r\n```\r\n\r\nSince Magento flattens all it's configuration, I assumed that `self` would be replaced with `anonymous`.\r\n\r\nHowever... the addition of an extra node to `<resources>` causes an `AND`-condition. So now my API response (error) tells me:\r\n\r\n```\r\n\"message\": \"Consumer is not authorized to access %resources\",\r\n  \"parameters\": {\r\n    \"resources\": \"self, anonymous\"\r\n  }\r\n```\r\n\r\nSo instead of changing the permissions, it adds it.\r\n\r\n\r\n### Expected result\r\n1. I expect that I can change the access permissions.\r\n### Actual result\r\n1. It adds the access permissions.\r\n### Workaround\r\n\r\nAs a temporary workaround, I now added a new endpoint, pointing to the same methods:\r\n\r\n```\r\n<route url=\"/V1/guest-carts-anonymous/:cartId\" method=\"PUT\">\r\n    <service class=\"Magento\\Quote\\Api\\GuestCartManagementInterface\" method=\"assignCustomer\"/>\r\n    <resources>\r\n        <resource ref=\"anonymous\" />\r\n    </resources>\r\n</route>\r\n```\r\n"},
{"text": "I'm making a call to REST API configurableProductLinkManagementV1. The first simple product is associated correctly. Any simple product after that is not. The error I receive states \"option values are not specified\".  I'm passing in the following JSON:\n\n'{\"childSKU\": \"my SKU here\"}'\n\nI'm running Magento 2.1.0, PHP version 5.6.25-1+deb.sury.org~trusty+1, Apache/2.4.7, Ubuntu Linux 14.04, MySQL 5.6.33-0ubuntu0.14.04.1. \n### Steps to reproduce\n1.  I create all of the simple products using  catalogProductRepositoryV1.\n2.  I then create the configurable product using the same REST API.\n3.  Next I add the configurable product options using configurableProductOptionRepositoryV1.\n4.  Finally I associate all of the simple products to the configurable product using configurableProductLinkManagementV1.\n### Expected result\n1.  I'm expecting for the configurable product to have its associated simple products. \n### Actual result\n1. Only the first simple product has been added to the configurable product.  No other simple products are added to the configurable product.\n\nWhat are the correct steps when creating simple/configurable products and associating the products to one another?  And is there any where that I can find what the different JSON objects represent?  The REST API documentation doesn't give enough detailed information.\n"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\n\nI am trying to get product details via rest api via following criteria  /V1/products?searchCriteria[pageSize]=12  it return json but json data is invalid  after \"customattributes\": [{\n                            \"attributecode\": \"description\",\n\nhere is some json response i got\n\n``` json\n\n{\n    \"items\": [{\n                \"id\": 2,\n                \"sku\": \"98329487\",\n                \"name\": \"Corey Test Gas Range\",\n                \"attributesetid\": 9,\n                \"price\": 2799,\n                \"status\": 1,\n                \"visibility\": 4,\n                \"typeid\": \"simple\",\n                \"createdat\": \"2016-01-21 23:20:25\",\n                \"updatedat\": \"2016-07-09 00:04:22\",\n                \"weight\": 450,\n                \"extensionattributes\": [],\n                \"productlinks\": [],\n                \"tierprices\": [{\n                    \"customergroupid\": 2,\n                    \"qty\": 2,\n                    \"value\": 1750\n                }, {\n                    \"customergroupid\": 2,\n                    \"qty\": 4,\n                    \"value\": 1450\n                }],\n                \"customattributes\": [{\n                    \"attributecode\": \"specialprice\",\n                    \"value\": \"1500.0000\"\n                }, {\n                    \"attributecode\": \"specialfromdate\",\n                    \"value\": \"2016-01-21 00:00:00\"\n                }, {\n                    \"attributecode\": \"specialtodate\",\n                    \"value\": \"2016-01-24 00:00:00\"\n                }, {\n                    \"attributecode\": \"metatitle\",\n                    \"value\": \"Corey Test Gas Range\"\n                }, {\n                    \"attributecode\": \"metakeyword\",\n                    \"value\": \"Corey Test Gas Range\"\n                }, {\n                    \"attributecode\": \"metadescription\",\n                    \"value\": \"Corey Test Gas Range \"\n                }, {\n                    \"attributecode\": \"color\",\n                    \"value\": \"190\"\n                }, {\n                    \"attributecode\": \"newsfromdate\",\n                    \"value\": \"2016-01-21 00:00:00\"\n                }, {\n                    \"attributecode\": \"customdesignfrom\",\n                    \"value\": \"2016-01-21 00:00:00\"\n                }, {\n                    \"attributecode\": \"optionscontainer\",\n                    \"value\": \"container2\"\n                }, {\n                    \"attributecode\": \"requiredoptions\",\n                    \"value\": \"0\"\n                }, {\n                    \"attributecode\": \"hasoptions\",\n                    \"value\": \"0\"\n                }, {\n                    \"attributecode\": \"urlkey\",\n                    \"value\": \"corey-test-gas-range\"\n                }, {\n                    \"attributecode\": \"taxclassid\",\n                    \"value\": \"2\"\n                }, {\n                    \"attributecode\": \"manufacturer\",\n                    \"value\": \"516\"\n                }, {\n                    \"attributecode\": \"reffreezercompressor\",\n                    \"value\": \"650\"\n                }, {\n                    \"attributecode\": \"reffreezersections\",\n                    \"value\": \"652\"\n                }, {\n                    \"attributecode\": \"reffreezerdoortype\",\n                    \"value\": \"655\"\n                }]\n            }, {\n                \"id\": 3,\n                \"sku\": \"2938573\",\n                \"name\": \"Test Deep Fryer\",\n                \"attributesetid\": 4,\n                \"price\": 1315.25,\n                \"status\": 2,\n                \"visibility\": 4,\n                \"typeid\": \"simple\",\n                \"createdat\": \"2016-03-22 21:29:42\",\n                \"updatedat\": \"2016-07-11 20:11:35\",\n                \"weight\": 14,\n                \"extensionattributes\": [],\n                \"productlinks\": [],\n                \"tierprices\": [{\n                    \"customergroupid\": 5,\n                    \"qty\": 1,\n                    \"value\": 979.99\n                }, {\n                    \"customergroupid\": 10,\n                    \"qty\": 1,\n                    \"value\": 999.99\n                }, {\n                    \"customergroupid\": 11,\n                    \"qty\": 1,\n                    \"value\": 979.99\n                }, {\n                    \"customergroupid\": 17,\n                    \"qty\": 1,\n                    \"value\": 989.99\n                }, {\n                    \"customergroupid\": 34,\n                    \"qty\": 1,\n                    \"value\": 1200\n                }],\n                \"customattributes\": [{\n                            \"attributecode\": \"description\",\n                            \"value\": \"\n                            Lorem ipsum dolor sit amet,\n                            consectetur adipiscing elit.In volutpat ligula augue,\n                            ut tempor arcu dignissim non.Nunc et sapien mauris.Lorem ipsum dolor sit amet,\n                            consectetur adipiscing elit.Vivamus et mi ut odio accumsan dignissim vel sed lectus.Pellentesque varius volutpat nunc,\n                            sed auctor quam ullamcorper at.Mauris condimentum ullamcorper gravida.Vestibulum fermentum augue vel ligula facilisis,\n                            tincidunt porta metus blandit.Pellentesque imperdiet ipsum diam. < \\/span><\\/p>\\r\\n\n\n\n                            <\n                            \\/span><\\/p>\\r\\n\n\n                            Pellentesque metus eros,\n                            commodo in feugiat quis,\n                            lacinia in quam.Sed quis ligula elit.Praesent sit amet sem quam.Mauris auctor sapien vitae auctor vehicula.Sed ut ornare leo.Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas.Praesent tincidunt vel lacus eget pharetra. < \\/span><\\/p>\"},{\"attributecode\":\"metatitle\",\"value\":\"Test Deep Fryer\"},{\"attributecode\":\"metakeyword\",\"value\":\"Test Deep Fryer\"},{\"attributecode\":\"metadescription\",\"value\":\"Test Deep Fryer\n\n                            Lorem ipsum dolor sit amet,\n                            consectetur adipiscing elit.In volutpat ligula augue,\n                            ut tempor arcu dignissim non.Nunc et sapien mauris.Lorem ipsum dolor sit amet,\n                            consectetur adipiscing elit.Vivamus et mi ut odio accumsan dignis \"},{\"\n                            attributecode \":\"\n                            image \",\"\n                            value \":\"\\ / s\\ / o\\ / socalrestshow.jpg \"},{\"\n                            attributecode \":\"\n                            smallimage \",\"\n                            value \":\"\\ / s\\ / o\\ / socalrestshow.jpg \"},{\"\n                            attributecode \":\"\n                            thumbnail \",\"\n                            value \":\"\\ / s\\ / o\\ / socalrestshow.jpg \"},{\"\n                            attributecode \":\"\n                            optionscontainer \",\"\n                            value \":\"\n                            container2 \"},{\"\n                            attributecode \":\"\n                            requiredoptions \",\"\n                            value \":\"\n                            0 \"},{\"\n                            attributecode \":\"\n                            hasoptions \",\"\n                            value \":\"\n                            0 \"},{\"\n                            attributecode \":\"\n                            urlkey \",\"\n                            value \":\"\n                            test - deep - fryer \"},{\"\n                            attributecode \":\"\n                            swatchimage \",\"\n                            value \":\"\\ / s\\ / o\\ / socalrestshow.jpg \"},{\"\n                            attributecode \":\"\n                            taxclassid \",\"\n                            value \":\"\n                            2 \"},{\"\n                            attributecode \":\"\n                            mpn \",\"\n                            value \":\"\n                            TEST \"},{\"\n                            attributecode \":\"\n                            upc \",\"\n                            value \":\"\n                            TEST \"},{\"\n                            attributecode \":\"\n                            searchaliases \",\"\n                            value \":\"\n                            wonton soup \"}]}],\"\n                            searchcriteria \":{\"\n                            filtergroups \":[],\"\n                            pagesize \":2},\"\n                            totalcount \":2460}\n\n\n```\n\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\n### Preconditions\n\n<!--- Provide a more detailed information of environment you use -->\n\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\n1.  Magento ver. 2.1.0\n2. Rest Api\n### Steps to reproduce\n\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\n1. /V1/products?searchCriteria[pageSize]=12   with customattributes description (with html mixed content) \n2. \n3. \n### Expected result\n\n<!--- Tell us what should happen -->\n1. valid json\n### Actual result\n\n<!--- Tell us what happens instead -->\n1. [Screenshot, logs]\n   invalid json\n   json \n   Error: Parse error on line 117:\n   ...n\",                          \"value\": \"                          Lorem ipsum\n   ----------------------^\n   Expecting 'STRING', 'NUMBER', 'NULL', 'TRUE', 'FALSE', '{', '[', got 'undefined'\n   <!--- (This may be platform independent comment) -->\n"},
{"text": "### Preconditions\n1. Have Magento 2.1.1 installed\n### Steps to reproduce\n1. Add products to different stores\n2. Place products in the category.\n3. Call /rest/V1/categories/:categoryID/products?storeId= + STOREID\n### Expected result\n1. List of products in this category and this storeid will be returned.\n### Actual result\n1. Return was empty array, [].\n\nI have altered the code in the module-catalog/Model/CategoryLinkManagement.php. I changed the getAssignedProducts functions first lines to:\n        ```\n$sId = isset($GET['storeId']) ? $GET['storeId'] : null;\n        $category = $this->categoryRepository->get($categoryId, $sId);\n\n```\n\nNow it does return a list with the appropriate products.\n```\n"},
{"text": "We are trying to create invoice for bundle product used in order by using \n/V1/order/:orderId/invoice : POST method API.\n### Preconditions\n1. Magento Development ver. 2.2.0-dev \n2. Magento Released ver. 2.1.2 CE\n### Steps to reproduce\n1. Create an Order using Bundle item\n2. try to create invoice using /V1/order/:orderId/invoice : POST method API with bundle product order item id.\n3. try to create invoice using /V1/order/:orderId/invoice : POST method API with child simple product order item id.\n### Expected result\n1. It should be able to create invoice either using parent order item id or child product order item id.\n### Actual result\n1. In Magento Development latest ver. 2.2.0-dev instance : Invoice created properly if we use child product order item id. If we use parent product order item id then empty invoice will be created.\n2. In Magento Released ver. 2.1.2 CE instance : Invoice created properly if we use parent product order item id. If we use child product order item id then empty invoice will be created.\n\nBoth development and released version magento2 are working opposite for creation of invoice.\n"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\n\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\n### Preconditions\n\n<!--- Provide a more detailed information of environment you use -->\n\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\n1. Magento version 2.1\n2. \n### Steps to reproduce\n\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\n1. Create a 'product' using /V1/products API with name and sku.\n2. It should throw an error.\n3. \n   ![image](https://cloud.githubusercontent.com/assets/17979940/19347900/dc7fc358-9168-11e6-8940-e48d0f0c0d10.png)\n### Expected result\n\n<!--- Tell us what should happen -->\n1. As per the swagger JSON, only sku is mandatory field. So it should have created a product with sku and name.\n### Actual result\n\n<!--- Tell us what happens instead -->\n1. It throws an error\n   ![image](https://cloud.githubusercontent.com/assets/17979940/19347916/f9115e78-9168-11e6-8a5e-e0565da97c0a.png)\n\n<!--- (This may be platform independent comment) -->\n\nDoes Magento have comprehensive API documentation or swagger JSON returned should be considered as the API doc?\n"},
{"text": "### Preconditions\n\nMagento 2.1.2 CE\n### Steps to reproduce\n1. POST /V1/carts/mine/ with {\"customerid\": 10} , returns \"76\"\n2.  PUT /V1/carts/mine/ with \n   {\n   \"customerid\":10,\n   \"quote\": \n   {\n       \"id\":76, <---- cartid\n       \"items\":[\n           {\n               \"sku\":\"Toast MP3-3\",\n               \"qty\":1\n           }\n       ]\n   }\n   }\n   OK, SKU added to the cart.\n3.  now we need to have the cart empty as per docs \n   http://devdocs.magento.com/swagger/index.html#!/quoteCartManagementV1\n\nImplementation Notes\n\nCreates an empty cart and quote for a specified customer.\n\n**POST /V1/carts/mine/ with {\"customerid\": 10}**\n### Expected result\n\nEmpty cart is created (as per docs - \"Creates an empty cart and quote for a specified customer.\").\n### Actual result\n\nLast created cart ID returned - \"76\".\n"},
{"text": "Hi \nthere are 3rd party developers who are trying to set up API account and they got this error. They need to feed product data from their NutriLoader software so they need to set up API account.\n\nThey went to below path to set up API account.\nSystem > Extension (Integrations)\n\nSystem config details are as below:\nPHP 5.6.20 and OS Linux\n### Expected result\n\n<!--- Tell us what should happen -->\n1.  Without error\n### Actual result\n\n<!--- Tell us what happens instead -->\n\n![f42f1c14-92f9-11e6-9e79-5f9e0736a941](https://cloud.githubusercontent.com/assets/16436069/19506443/43784e20-95e9-11e6-8067-f13eca711df1.png)\n\n<!--- (This may be platform independent comment) -->\n"},
{"text": "1. Magento 2.1.2\n### Steps to reproduce\n1. Customer login\n2. Create cart (carts/mine)\n3. Add product to cart\n4. Create address (via put customers/me)\n5. Now I have address ID 109115\n6. I checked available shipping for my address (V1/carts/mine/estimate-shipping-methods-by-address-id) and in response I get that flatrate is available.\n### Expected result\n1. One simple call with which I can add shipping address ID to cart. \n### Actual result\n1. You need to use POST V1/carts/mine/shipping-information where you cant use just ID\n\n{\n  \"addressInformation\": {\n    \"shippingAddress\": {\n      \"id\": 109115,\n      \"customerAddressId\": 109115\n    },\n    \"shippingMethodCode\": \"flatrate\",\n    \"shippingCarrierCode\": \"flatrate\"\n  }\n}\n\nresult: Error 400 Shipping address is not set\n\nor when\n{\n  \"addressInformation\": {\n    \"shippingAddress\": {\n      \"customerAddressId\": 109115\n    },\n    \"shippingMethodCode\": \"flatrate\",\n    \"shippingCarrierCode\": \"flatrate\"\n  }\n}\n\nresult: Error 400 Shipping address is not set\n\nor when\n{\n  \"addressInformation\": {\n    \"shippingAddress\": {\n      \"id\": 109115\n    },\n    \"shippingMethodCode\": \"flatrate\",\n    \"shippingCarrierCode\": \"flatrate\"\n  }\n}\n\nresult: Error 400 Shipping address is not set\n\nOK lets to add address. Here is another funny part. You cant use address ID because it is not working (and we are just starting)\n\n{\n  \"addressInformation\": {\n    \"shippingAddress\": {\n      \"id\": 109115,\n      \"region\": \"\",\n      \"regionId\": 0,\n      \"regionCode\": \"\",\n      \"countryId\": \"SK\",\n      \"street\": [\n        \"string\"\n      ],\n      \"telephone\": \"0902222\",\n      \"postcode\": \"82100\",\n      \"city\": \"Bratislava\",\n      \"firstname\": \"My name\",\n      \"lastname\": \"My last name\",\n      \"customerAddressId\": 109115,\n      \"customerId\": 124252\n    },\n    \"shippingMethodCode\": \"flatrate\",\n    \"shippingCarrierCode\": \"flatrate\"\n  }\n}\n\nresponse\nError 400: Unable to save shipping information. Please check input data.\n\n**Here we can look on another weird thing** - why right now we are using another address attribute name asi it is on customers/me calls? For example on customers/me call\nregion is array, customerid vs customerId, regionid vs regionId, countryid vs countryId... The right hand does not know what makes left... \n\n**So how we can set saved address to cart?** We cant... What we need to do is to get address from customers/me, then rewrite it to different structure in shipping-information call AND delete address ID. So call should look like\n\n{\n  \"addressInformation\": {\n    \"shippingAddress\": {\n      \"region\": \"\",\n      \"regionId\": 0,\n      \"regionCode\": \"\",\n      \"countryId\": \"SK\",\n      \"street\": [\n        \"string\"\n      ],\n      \"telephone\": \"0902222\",\n      \"postcode\": \"82100\",\n      \"city\": \"Bratislava\",\n      \"firstname\": \"My name\",\n      \"lastname\": \"My last name\"\n    },\n    \"shippingMethodCode\": \"flatrate\",\n    \"shippingCarrierCode\": \"flatrate\"\n  }\n}\n\nVuala - this is working - but is this good? I think that this is bug and it should be done more simple.\n\nThanks guys\n"},
{"text": "According to the documentation, `\\Magento\\Cms\\Api\\Data\\PageSearchResultsInterface::getItems()` should return an array of `\\Magento\\Cms\\Api\\Data\\PageInterface` objects, while it currently returns an array of arrays.\n### Preconditions\n\nI am using Magento 2.1.\n### Steps to reproduce\n\n```\n$sortOrder      = $this->sortOrderBuilder->setField(\\Magento\\Cms\\Model\\Page::TITLE)\n                                         ->setAscendingDirection()\n                                         ->create();\n$searchCriteria = $this->searchCriteriaBuilder->addFilter('storeid', $storeId)\n                                              ->addSortOrder($sortOrder)\n                                              ->create();\n\n$pageList = $this->pageRepository->getList($searchCriteria);\n$pages    = $pageList->getItems();\n```\n### Expected result\n\nAccording to the documentation, I would expect `$pages` to be an array of `\\Magento\\Cms\\Api\\Data\\PageInterface` objects. \n### Actual result\n\n`$pages` is array of data arrays:\n\n```\nArray\n(\n    [0] => Array\n        (\n            [identifier] => [page identifier]\n            [title] => [page title]\n            [pagelayout] => [page title]\n            [metakeywords] => \n            [metadescription] => \n            [content] => [page content]\n            [creationtime] => 2016-10-06 14:22:20\n            [updatetime] => 2016-10-06 14:29:20\n            [sortorder] => 0\n            [layoutupdatexml] => \n            [customtheme] => \n            [customroottemplate] => \n            [customlayoutupdatexml] => \n            [customthemefrom] => 2016-10-06\n            [customthemeto] => 2016-10-06\n            [active] => 1\n        )\n)\n```\n\n<!--- (This may be platform independent comment) -->\n"},
{"text": "### Preconditions\n1. Magento 2.1.2\n2. PHP7\n### Steps to reproduce\n\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\n1. Go to swagger or call rest API through script\n2. Try updating or creating a product with a videourl, videotitle etc. with media type \"external-video\".\n3. I used the following JSON:\n\n```\n{\n  \"product\": {\n    \"sku\": \"SKU\",\n    \"mediagalleryentries\": [\n        {\n            \"mediatype\": \"external-video\",\n            \"disabled\": false,\n            \"label\": \"\",\n            \"types\": [],\n            \"content\": {\n                \"type\": \"image/jpeg\",\n                \"name\": \"FyL6smNEMiU.jpg\",\n                \"base64encodeddata\": \"encodedimage\"\n            },\n            \"extensionattributes\": {\n                \"videocontent\": {\n                    \"mediatype\": \"external-video\",\n                    \"videourl\": \"https://youtu.be/FyL6smNEMiU\",\n                    \"videotitle\": \"Video title\",\n                    \"videodescription\": \"Video description\"\n                }\n            }\n        }\n    ]\n  },\n  \"saveOptions\": true\n}\n```\n\nOfcourse I used a valid base64 encoded image as thumbnail and used a correct SKU.\n### Expected result\n\nProduct should be created or updated with a valid video gallery item, which should have all necessary attributes filled like videourl and videotitle.\n### Actual result\n\nThe product is updated, however there is only a thumbnail image and no video attributes. If you will load the product through API you will get the item back with the right mediatype but without attributes.\n### Comment\n\nI think it has something to do with the fact that the productRepository is handling the gallery entries by itself and is not yet processing any of the extensionattributes for gallery items.\n"},
{"text": "Magento 2.1.2\n\nIf we send a XML request (see attachment) with store code 'all', the product is assigned to all available websites. This is a bug. We set the store to 'all' beacuse the description and attributes should be global available. If we use a specific storecode this is not happening.\n\nWith the webservice method 'catalogProductWebsiteLinkRepositoryV1SaveRequest' the assignment for a product to websites will be done. This is working ok.\n\n[productsaverequest.zip](https://github.com/magento/magento2/files/555194/productsaverequest.zip)\n"},
{"text": "### Preconditions\n\nMagento 2.1.1 \n### Steps to reproduce\n1. Add tax rate & rule (10%)\n2. Change some settings in Stores > Configuration > Sales > Tax:\n   ![price incl tax](https://cloud.githubusercontent.com/assets/18303554/19761430/1dedd2d8-9c60-11e6-8df8-d3cbc33ba6a3.PNG)\n3. Add a new product (for testing):\n   Price: $10\n4. Save then indexer:reindex and clear cache or even disable cache.\n### Expected result\n1. The price in frontend included tax. The test product's price is $11.\n2. The price when calling rest api ( /V1/products/SKU + /V1/carts/mine + /V1/carts/mine/items ) included tax. The test product's price is $11.\n### Actual result\n1. On website, it's great.\n2. On the response, the price is always excluded tax.\n\nIs that missing something in my steps to set up the product's price included tax? Or is that an issue?\n"},
{"text": "Although REST API should be stateless for anonymous calls, PHP session is always created. This is caused by the fact that sessionstart() is called implicitly from '\\Magento\\Framework\\Session\\SessionManager' constructor.\r\n\r\nThere are 2 issues with this: Spammed PHP session which will never be used, if remote address validation is enabled for sessions, clients with dynamic IP address will get 302 redirect instead of REST API result, and this is undesirable.\r\n\r\n### Preconditions\r\n1. Magento 2.4-develop\r\n\r\n### Steps to reproduce\r\n1. Make a REST request, for example from Swagger UI, but it can be a request from any client. For example, call /V1/directory/countries\r\n \r\n### Expected result\r\n1. Received JSON response with countries;\r\n2. No PHP session is started;\r\n3. No PHPSESSID in the response cookies.\r\n\r\n### Actual result\r\n1. PHP session is started and is perhaps never used (because the request is anonymous)\r\n\r\n### Why?\r\n\r\nThe reason for this is that in di.xml `\\Magento\\Authorization\\Model\\CompositeUserContext` is fed with `userContexts` argument, and at least 2 of them will start PHP session: `customerSessionUserContext` and `adminSessionUserContext`.\r\n\r\n### How to fix\r\n\r\nMy PoC solution was to modify `vendor/magento/module-customer/etc/webapirest/di.xml` and `vendor/magento/module-user/etc/webapirest/di.xml` so that types for `userContext` would be Proxies, and they would be created on-demand.\r\n\r\n``` xml\r\n\r\n<config xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:noNamespaceSchemaLocation=\"urn:magento:framework:ObjectManager/etc/config.xsd\">\r\n     <type name=\"Magento\\Framework\\Authorization\">\r\n        <plugin name=\"customerAuthorization\" type=\"Magento\\Customer\\Model\\Plugin\\CustomerAuthorization\" />\r\n    </type>\r\n    <type name=\"Magento\\Authorization\\Model\\CompositeUserContext\">\r\n        <arguments>\r\n            <argument name=\"userContexts\" xsi:type=\"array\">\r\n                <item name=\"customerSessionUserContext\" xsi:type=\"array\">\r\n <!-- *********************** LET IT BE A PROXY ************************** -->\r\n                    <item name=\"type\" xsi:type=\"object\">Magento\\Customer\\Model\\Authorization\\CustomerSessionUserContext\\Proxy</item>\r\n                    <item name=\"sortOrder\" xsi:type=\"string\">20</item>\r\n                </item>\r\n                <item name=\"adminSessionUserContext\" xsi:type=\"array\">\r\n <!-- *********************** LET IT BE A PROXY ************************** -->\r\n                    <item name=\"type\" xsi:type=\"object\">Magento\\User\\Model\\Authorization\\AdminSessionUserContext\\Proxy</item>\r\n                    <item name=\"sortOrder\" xsi:type=\"string\">30</item>\r\n                </item>\r\n            </argument>\r\n        </arguments>\r\n    </type>\r\n</config>\r\n\r\n```\r\n\r\n``` xml\r\n<config xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:noNamespaceSchemaLocation=\"urn:magento:framework:ObjectManager/etc/config.xsd\">\r\n    <type name=\"Magento\\Authorization\\Model\\CompositeUserContext\">\r\n        <arguments>\r\n            <argument name=\"userContexts\" xsi:type=\"array\">\r\n                <item name=\"adminSessionUserContext\" xsi:type=\"array\">\r\n <!-- *********************** LET IT BE A PROXY ************************** -->\r\n                    <item name=\"type\" xsi:type=\"object\">Magento\\User\\Model\\Authorization\\AdminSessionUserContext\\Proxy</item>\r\n                    <item name=\"sortOrder\" xsi:type=\"string\">30</item>\r\n                </item>\r\n            </argument>\r\n        </arguments>\r\n    </type>\r\n</config>\r\n\r\n```\r\n\r\nI do not know which one of the changes fixed the issue, but I achieved the expected result.\r\n"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\n\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\n### Preconditions\n\n<!--- Provide a more detailed information of environment you use -->\n\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\n1.  Magento 2.0.7\n### Steps to reproduce\n\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\n1. Using Chrome extension ARC \n2. Using endpoint /V1/categories/{id}\n3. Set method to PUT\n4. Used: 'Content-Type: application/json'\n5. Trying to change description to a category that already exist with Raw Payload as:\n   {\n   \"category\": {\n     \"name\": \"Tenzin\",\n     \"customAttributes\": [{\n     \"attributeCode\":\"description\",\n     \"value\":\"<p>This is a test description<\\/p>\"\n   }]\n   }\n   }\n### Expected result\n\n<!--- Tell us what should happen -->\n1. The description will update/change to the value I set in the Raw Payload\n### Actual result\n\n<!--- Tell us what happens instead -->\n1. Recieved a \"501: Not Implemented\"\n   ![image](https://cloud.githubusercontent.com/assets/13293090/19784883/3f82e866-9c4c-11e6-8c96-5a6b4421abca.png)\n\n<!--- (This may be platform independent comment) -->\n"},
{"text": "It is not possible to authenticate using the REST API if a store is set up with a different front-end and backend domain - as many international retailers do. e.g. \r\nwww.mystore.com - frontend (mage run code default)\r\nadmin.mystore.com/admin - backend (mage run code admin)\r\n\r\n### Preconditions\r\n1. Magento ver. 2.0.8\r\n2. PHP 7.0.12 (cli) (built: Oct 15 2016 19:03:00)\r\n3. nginx version: nginx/1.9.15\r\n4. mysql server version: 5.6.32-78.1-56-log Percona XtraDB Cluster\r\n\r\n### Steps to reproduce\r\n1. Use POSTMAN to attempt a login to https://admin.mysite.co.uk/rest/V1/integration/admin/token\r\n\r\n### Expected result\r\n1. Authentication token should be returned\r\n\r\n### Actual result\r\n1. SQLSTATE[42S02]: Base table or view not found: 1146 Table '.catalogcategoryflat' doesn't exist, query was: SELECT `maintable`.`entityid`, `maintable`.`level`, `maintable`.`path`, `maintable`.`position`, `maintable`.`isactive`, `maintable`.`isanchor`, `maintable`.`urlkey`, `maintable`.`name`, `maintable`.`isanchor` FROM `catalogcategoryflat` AS `maintable` WHERE (`entityid` IN('1')) AND (`isactive` = '1') ORDER BY name ASC"},
{"text": "1. Magento v2.1.2\r\n2. php 7\r\n\r\n### Steps to reproduce\r\n1. Create configurable product\r\n2. Assign options (simple products) via configurableProductOptionRepositoryV1 \r\n```\r\n\r\n{\r\n    \"option\": {\r\n    \"attributeid\": \"162\",\r\n    \"label\": \"Collection\",\r\n    \"position\": 0,\r\n    \"isusedefault\": true,\r\n    \"values\": [\r\n      {\r\n        \"valueindex\": 25,\r\n        \"extensionattributes\": {}\r\n      }\r\n    ],\r\n    \"extensionattributes\": {},\r\n    \"productid\": 102\r\n  },\r\n  \r\n  \"option\": {  \r\n    \"attributeid\": \"144\",\r\n    \"label\": \"Size\",\r\n    \"position\": 0,\r\n    \"values\": [\r\n      {\r\n        \"valueindex\": 45\r\n      }\r\n    ],\r\n    \"productid\": 102\r\n   }\r\n}\r\n\r\n```\r\n### Expected result\r\n```\r\n. [\r\n  {\r\n    \"id\": 46,\r\n    \"attributeid\": \"144\",\r\n    \"label\": \"Size\",\r\n    \"position\": 0,\r\n    \"values\": [\r\n      {\r\n        \"valueindex\": 45\r\n      }\r\n    \"productid\": 102\r\n  },\r\n  {\r\n    \"id\": 45,\r\n    \"attributeid\": \"162\",\r\n    \"label\": \"Collection\",\r\n    \"position\": 0,\r\n    \"values\": [\r\n      {\r\n        \"valueindex\": 25\r\n      }\r\n    \"productid\": 102\r\n  }\r\n]\r\n```\r\n\r\n### Actual result\r\nThere is no   \"valueindex\" attribute in values\r\n\r\n```\r\n. [\r\n  {\r\n    \"id\": 46,\r\n    \"attributeid\": \"144\",\r\n    \"label\": \"Size\",\r\n    \"position\": 0,\r\n     \"values\": [],\r\n    \"productid\": 102\r\n  },\r\n  {\r\n    \"id\": 45,\r\n    \"attributeid\": \"162\",\r\n    \"label\": \"Collection\",\r\n    \"position\": 0,\r\n    \"values\": [],\r\n    \"productid\": 102\r\n  }\r\n]\r\n```\r\n\r\n"},
{"text": "### Preconditions\r\nMagento 2.1\r\nA customer with a default billing adres set\r\n\r\n### Steps to reproduce\r\n1. Update firstname and lastname via the API.\r\nPUT /rest/v1/customers/1\r\n`{\"customer\":{\"id\":1,\"email\":\"ronicost@example.com\",\"firstname\":\"Paul\",\"lastname\":\"Boss\",\"middlename\":null,\"gender\":0}}\r\n`\r\n### Expected result\r\n1. Customer with id 1 has firstname \"Paul\" and lastname \"Boss\". Other data is left intact\r\n\r\n### Actual result\r\n1. Default billing address option is reset. The address is stil available, but the \"default billing address\" option is now false."},
{"text": "PRECONDITIONS:\r\nINSTALL MAGENTO 2.0.10\r\nUSE THE REST API\r\nADD A PRODUCT TO YOUR CATALOG, USE ITS ID AS AN ITEM ID\r\nCREATE A CART, GET ITS ID, USE AS PARAMETER IN FOLLOWING REQUESTS AS EITHER CARTID or QUOTEID\r\n\r\nSTEPS TO REPRODUCE\r\nsend an http POST request (https://www.w3.org/Protocols/rfc2616/rfc2616-sec9.html)\r\nwith json body:\r\n```\r\n{\r\n    \"cartItem\": {\r\n        \"itemId\":1,\r\n        \"qty\": 1\r\n    }\r\n}\r\n```\r\nto\r\n\r\n`/rest/V1/carts/{cartId}/items` where cartId is the id of your cart\r\nTHE REAL, ACTUAL RESULT\r\n```\r\n{\r\n  \"message\": \"No such entity with %fieldName = %fieldValue\",\r\n  \"parameters\": {\r\n    \"fieldName\": \"cartId\",\r\n    \"fieldValue\": null\r\n  }\r\n}\r\n```\r\nAdditionally, sending the same request with the following json body:\r\n```\r\n{\r\n    \"cartItem\": {\r\n        \"itemId\":1,\r\n        \"cartId\":1,\r\n        \"qty\": 1\r\n    }\r\n}\r\n```\r\nACTUAL RESULT\r\n```\r\n{\r\n  \"message\": \"Internal Error. Details are available in Magento log file. Report ID: webapi-5678ac6216cf5\"\r\n}\r\n```\r\n\r\nEXPECTED RESULTS:\r\nI EXPECT THE \"ADD ITEM TO CART\" ENDPOINT TO ADD AN ITEM TO THE CART, instead of erroring\r\n\r\n\r\nlog excerpt\r\n\r\n```\r\n[2015-12-22 01:50:26] main.CRITICAL: exception 'LogicException' with message 'Report ID: webapi-5678ac6216cf5; Message: Property \"CartId\" does not have corresponding setter in class \"Magento\\Quote\\Api\\Data\\CartItemInterface\".' in /var/www/magento2/lib/internal/Magento/Framework/Webapi/ErrorProcessor.php:194\r\nStack trace:\r\n#0 /var/www/magento2/lib/internal/Magento/Framework/Webapi/ErrorProcessor.php(139): Magento\\Framework\\Webapi\\ErrorProcessor->critical(Object(LogicException))\r\n#1 /var/www/magento2/app/code/Magento/Webapi/Controller/Rest.php(163): Magento\\Framework\\Webapi\\ErrorProcessor->maskException(Object(LogicException))\r\n#2 /var/www/magento2/var/generation/Magento/Webapi/Controller/Rest/Interceptor.php(24): Magento\\Webapi\\Controller\\Rest->dispatch(Object(Magento\\Framework\\App\\Request\\Http))\r\n#3 /var/www/magento2/lib/internal/Magento/Framework/App/Http.php(115): Magento\\Webapi\\Controller\\Rest\\Interceptor->dispatch(Object(Magento\\Framework\\App\\Request\\Http))\r\n#4 /var/www/magento2/lib/internal/Magento/Framework/App/Bootstrap.php(258): Magento\\Framework\\App\\Http->launch()\r\n#5 /var/www/magento2/index.php(39): Magento\\Framework\\App\\Bootstrap->run(Object(Magento\\Framework\\App\\Http))\r\n#6 {main} [] []\r\n```\r\n\r\nFuther INFO\r\nSending the following works as expected, adding an item to cart successfully\r\n```\r\n{\r\n    \"cartItem\": {\r\n        \"itemId\":1,\r\n        \"quoteId\":1,\r\n        \"qty\": 1\r\n    }\r\n}\r\n```"},
{"text": "**Preconditions**\r\n1. Magento CE 2.1.2 without sample data is installed.\r\n2. Test Category is created, ID:5\r\n3. Test Sub category is created, ID:112\r\n4. Test Product is created, assigned to the test sub category only, ID:112\r\n\r\n**Steps to reproduce**\r\n\r\n1. Run request: /index.php/rest/V1/products?searchCriteria[filtergroups][0][filters][0][field]=categoryid&searchCriteria[filtergroups][0][filters][0][value]=5,112&searchCriteria[filtergroups][0][filters][0][conditiontype]=in\r\n\r\n**Actual and Expected result**\r\nExpected result:\r\nGetting JSON with totalproducts:1\r\nActual result:\r\nGetting JSON with totalproducts:0\r\n\r\n**Additional information**\r\n\r\nThis is related to this issue https://github.com/magento/magento2/issues/2892 \r\n\r\nThis seems, it is still an issue with REST API on Magento 2.1.2\r\nIm using the following endpoint\r\nhttp://bikebiz.local:4575/index.php/rest/V1/products?searchCriteria[filtergroups][0][filters][0][field]=categoryid&searchCriteria[filtergroups][0][filters][0][value]=5,112&searchCriteria[filtergroups][0][filters][0][conditiontype]=in\r\n\r\nAnd this looks like Magento ignores conditiontype in, and uses something like this categoryid=5\r\nas a result returns 0 products.\r\n\r\nHowever, if I change order of values, e.g. [value]=112,5 it will use categoryid=112 as a result it will return a bunch of products from category 112.\r\n\r\nThis shows that conditiontype in completely does not work. Could you advice on file name where I can fix this please?"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\r\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\r\n\r\n### Preconditions\r\n1. We are using GA released version of Magento ver CE 2.1.2 setup.\r\n2. We created some simple items and used that items to create orders.\r\n\r\n### Steps to reproduce\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1. Create a simple item itemToBeDelete and place an order using this only this simple item.\r\n2. Now create some more items and place order using items excluding the itemToBeDelete.\r\n3. When you make a REST API Call GET: /V1/orders?searchCriteria[currentPage]=1 and you will get all orders details\r\n4. Now delete that item itemToBeDelete and then make a REST API Call GET: /V1/orders?searchCriteria[currentPage]=1 \r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. It should only throw/give error for in one particular order related object and other order details should be made available in response or fail entire order API with proper status code. If status code is 200 then we expecting it to be successful and more over we don't even know fetching which order it failed.\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. It is given status code 200 when request body   \r\n{\r\n\"message\": \"Requested product doesn't exist\"\r\n}\r\n\r\nThis is failing entire API call without explicit error or what is the cause of this issue we need to debug a lot to find that one item was deleted and it has failed entire order API result.\r\n\r\n<!--- (This may be platform independent comment) -->\r\n"},
{"text": "I have a list of customers that I am trying to pull data for all at once. I build a search filter with the contiontype=\"in\", field=\"id\", and value=my list of customers. I get an error that the field id does not exist.\r\n\r\n### Preconditions\r\n1. Magento 2.1.2\r\n2. REST API\r\n\r\n### Steps to reproduce\r\n0. Acquire token for token-based REST authorization\r\n1. Make GET request to /rest/V1/customers/search?searchCriteria[filtergroups][0][filters][0][field]=id&searchCriteria[filtergroups][0][filters][0][value]=1,2&searchCriteria[filtergroups][0][filters][0][conditiontype]=in\r\n\r\n### Expected result\r\n1. This should return a list of customers with an id in {1,2}\r\n\r\n### Actual result\r\n{\r\n    \"message\": \"Invalid attribute name: %1\",\r\n    \"parameters\": [\r\n        \"id\"\r\n    ]\r\n}\r\n\r\nI have tried other terms for id, such as customerid, customerID, custID, etc. with no change.\r\n"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\r\nWhen i call catalogInventoryStockRegistryV1GetLowStockItems for magento 2.1.1\r\nand use scope=1 i receive empty list. But when i used scope=0 i receive the list of items with stockId=1;\r\n\r\nWhen i call catalogInventoryStockRegistryV1GetLowStockItems for magento 2.0.2\r\nand use scope=0 i receive empty list. But when i used scope=1 i receive the list of items with stockId=1;\r\n\r\nDb and config for both stores are the same but soap response is different. Which scopeId should i use to receive all inventory for the root scope?\r\n\r\nthe problem is actual not only for these 2 versions but for all 2.0.x versions and 2.1.x\r\n\r\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\r\n\r\n### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1. SOAP, Magento 2-1-1\r\n2. SOAP, Magento 2-0-2\r\n3. `coreconfigdata`.`scopeid`  contains 0 for all records for both stores.\r\n`coreconfigdata`.`scope`  contains default for all records for both stores.\r\n4. ![chrome2016-11-2913-34-40](https://cloud.githubusercontent.com/assets/4807486/20706555/e98bd268-b638-11e6-9ba0-60bfb2c99a7a.png)\r\n![chrome2016-11-2913-35-31](https://cloud.githubusercontent.com/assets/4807486/20706554/e98b1616-b638-11e6-989e-dcc6d6215500.png)\r\n\r\n### Steps to reproduce\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1. Request :`<s:Envelope xmlns:s=\"http://schemas.xmlsoap.org/soap/envelope/\">\r\n\t<s:Body>\r\n\t\t<catalogInventoryStockRegistryV1GetLowStockItemsRequest xmlns=\"http://youmagentohost/magento-2-1-1-0-ce/soap/default?services=catalogInventoryStockRegistryV1\">\r\n\t\t\t<scopeId xmlns=\"\">1</scopeId>\r\n\t\t\t<qty xmlns=\"\">1E+12</qty>\r\n\t\t\t<currentPage xmlns=\"\">1</currentPage>\r\n\t\t\t<pageSize xmlns=\"\">500</pageSize>\r\n\t\t</catalogInventoryStockRegistryV1GetLowStockItemsRequest>\r\n\t</s:Body>\r\n</s:Envelope>\r\n`\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. `<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<SOAP-ENV:Envelope xmlns:SOAP-ENV=\"http://schemas.xmlsoap.org/soap/envelope/\" xmlns:ns1=\"http://youmagentohost/magento-2-1-1-0-ce/soap/default?services=catalogInventoryStockRegistryV1\">\r\n\t<SOAP-ENV:Body>\r\n\t\t<ns1:catalogInventoryStockRegistryV1GetLowStockItemsResponse>\r\n\t\t\t<result>\r\n\t\t\t\t<items>\r\n\t\t\t\t\t<item>\r\n\t\t\t\t\t\t<productId>1</productId>\r\n\t\t\t\t\t\t<stockId>1</stockId>\r\n\t\t\t\t\t\t<qty>402</qty>\r\n\t\t\t\t\t\t<stockStatus/>\r\n\t\t\t\t\t\t<stockItem/>\r\n\t\t\t\t\t</item>\r\n\t\t\t\t\t<item>\r\n\t\t\t\t\t\t<productId>2</productId>\r\n\t\t\t\t\t\t<stockId>1</stockId>\r\n\t\t\t\t\t\t<qty>0</qty>\r\n\t\t\t\t\t\t<stockStatus/>\r\n\t\t\t\t\t\t<stockItem/>\r\n\t\t\t\t\t</item>\r\n\t\t\t\t\t<item>\r\n\t\t\t\t\t\t<productId>3</productId>\r\n\t\t\t\t\t\t<stockId>1</stockId>\r\n\t\t\t\t\t\t<qty>438</qty>\r\n\t\t\t\t\t\t<stockStatus/>\r\n\t\t\t\t\t\t<stockItem/>\r\n\t\t\t\t\t</item>\r\n\t\t\t\t</items>\r\n\t\t\t\t<searchCriteria>\r\n\t\t\t\t\t<mapperInterfaceName>Magento\\CatalogInventory\\Model\\ResourceModel\\Stock\\Item\\StockItemCriteriaMapper</mapperInterfaceName>\r\n\t\t\t\t\t<criteriaList/>\r\n\t\t\t\t\t<filters/>\r\n\t\t\t\t\t<orders/>\r\n\t\t\t\t\t<limit>\r\n\t\t\t\t\t\t<item>1</item>\r\n\t\t\t\t\t\t<item>500</item>\r\n\t\t\t\t\t</limit>\r\n\t\t\t\t</searchCriteria>\r\n\t\t\t\t<totalCount>3</totalCount>\r\n\t\t\t</result>\r\n\t\t</ns1:catalogInventoryStockRegistryV1GetLowStockItemsResponse>\r\n\t</SOAP-ENV:Body>\r\n</SOAP-ENV:Envelope>\r\n`\r\n\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1.  `<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<SOAP-ENV:Envelope xmlns:SOAP-ENV=\"http://schemas.xmlsoap.org/soap/envelope/\" xmlns:ns1=\"http://youmagentohost/magento-2-1-1-0-ce/soap/default?services=catalogInventoryStockRegistryV1\">\r\n\t<SOAP-ENV:Body>\r\n\t\t<ns1:catalogInventoryStockRegistryV1GetLowStockItemsResponse>\r\n\t\t\t<result>\r\n\t\t\t\t<items/>\r\n\t\t\t\t<searchCriteria>\r\n\t\t\t\t\t<mapperInterfaceName>Magento\\CatalogInventory\\Model\\ResourceModel\\Stock\\Item\\StockItemCriteriaMapper</mapperInterfaceName>\r\n\t\t\t\t\t<criteriaList/>\r\n\t\t\t\t\t<filters/>\r\n\t\t\t\t\t<orders/>\r\n\t\t\t\t\t<limit>\r\n\t\t\t\t\t\t<item>1</item>\r\n\t\t\t\t\t\t<item>500</item>\r\n\t\t\t\t\t</limit>\r\n\t\t\t\t</searchCriteria>\r\n\t\t\t\t<totalCount>0</totalCount>\r\n\t\t\t</result>\r\n\t\t</ns1:catalogInventoryStockRegistryV1GetLowStockItemsResponse>\r\n\t</SOAP-ENV:Body>\r\n</SOAP-ENV:Envelope>\r\n`\r\n<!--- (This may be platform independent comment) -->\r\n"},
{"text": "### Preconditions\r\n1. Magento 2.1.2 out of the box installation\r\n2. An application that communicates via REST API with that Magento installation\r\n\r\n### Steps to reproduce\r\n1. Create a new simple item via REST API (POST to `/rest/V1/products`) with descriptions and META information.\r\n2. Verify in shop bakend that the item was created correctly.\r\n3. Verify in database (table `catalogproductentitytext`) that the attributes are inserted with `storeid` 0\r\n4. Update the long description for that same item via REST API (PUT to `/rest/V1/products/{sku}`).\r\n5. Check the shop backend: the long description appears to be unchanged\r\n6. Check the database (same table): A new attribute is inserted with `storeid` 1 instead of updating the previously created attribute.\r\n\r\n### Expected result\r\n1. The description that was created when creating the item should be changed when updating the item instead of creating a new attribute with the wrong `storeid`.\r\n\r\n### Actual result\r\n1. The description that was created when creating the item still exists, but a new description is added with a wrong `storeid` 1.\r\n\r\n\r\nThis is for Magento version 2.1.2 and was not an issue in pre-2.1 versions.\r\n"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\r\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\r\n\r\n### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1. Mage 2.1.2\r\n2. PHP 7\r\n3. some Payment Gateway Module (in our case https://www.sellxed.com/shop/en/magento-payment-extension-postfinance.html)\r\n\r\n### Steps to reproduce\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1. Create an order with online creditcard payment (via backend or frontend)\r\n2. Create an invoice for that order (via api or backend)\r\n3. Create a credit memo via API, with offlineRequested : false\r\n[creditmemo-api-request.txt](https://github.com/magento/magento2/files/624410/creditmemo-api-request.txt)\r\n\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. Refunded Online\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. Refunded Offline\r\n\r\n<!--- (This may be platform independent comment) -->\r\nThe problem is, that despite the invoiceid being set, the invoice instance is never loaded and set, and thus the credit memo is always created offline.\r\n"},
{"text": "### Preconditions\r\n1. Magento 2.1.2 - PHP7\r\n\r\n### Steps to reproduce\r\n1. Login in with existing customer\r\n2. Add products to cart\r\n3. Progress to cart\r\n\r\n### Expected result\r\n1. Cart should successfully complete\r\n\r\n### Actual result\r\n1. At the 'Reviews and Payments' step the cart throws an error when pressing 'Place Order':\r\n\r\n'An error occurred on the server, please try to order again.'\r\n\r\nOn inspection its showing:\r\n\r\n'Failed to load resource: the server responded with a status of 400 (Bad Request)'\r\n\r\nhttp://www.mywebsite.com/rest/glg/V1/carts/mine/payment-information\r\n\r\nI have my suspsiosns that this is something to do with address formatsd for old account. Maybe the 'street' attribute?\r\n\r\nDebugging has given me this:\r\n\r\n{message: \"An error occurred on the server. Please try to place the order again.\",\u2026}\r\nmessage\r\n:\r\n\"An error occurred on the server. Please try to place the order again.\"\r\ntrace\r\n:\r\n\"#0 /var/www/html/magento/vendor/magento/framework/Interception/Interceptor.php(146): Magento\\Checkout\\Model\\PaymentInformationManagement->savePaymentInformationAndPlaceOrder(9, Object(Magento\\Quote\\Model\\Quote\\Payment), Object(Magento\\Quote\\Model\\Quote\\Address))\u21b5#1 /var/www/html/magento/var/generation/Magento/Checkout/Model/PaymentInformationManagement/Interceptor.php(26): Magento\\Checkout\\Model\\PaymentInformationManagement\\Interceptor->callPlugins('savePaymentInfo...', Array, Array)\u21b5#2 [internal function]: Magento\\Checkout\\Model\\PaymentInformationManagement\\Interceptor->savePaymentInformationAndPlaceOrder(9, Object(Magento\\Quote\\Model\\Quote\\Payment), Object(Magento\\Quote\\Model\\Quote\\Address))\u21b5#3 /var/www/html/magento/vendor/magento/module-webapi/Controller/Rest.php(307): calluserfuncarray(Array, Array)\u21b5#4 /var/www/html/magento/vendor/magento/module-webapi/Controller/Rest.php(216): Magento\\Webapi\\Controller\\Rest->processApiRequest()\u21b5#5 /var/www/html/magento/var/generation/Magento/Webapi/Controller/Rest/Interceptor.php(37): Magento\\Webapi\\Controller\\Rest->dispatch(Object(Magento\\Framework\\App\\Request\\Http))\u21b5#6 /var/www/html/magento/vendor/magento/framework/App/Http.php(135): Magento\\Webapi\\Controller\\Rest\\Interceptor->dispatch(Object(Magento\\Framework\\App\\Request\\Http))\u21b5#7 /var/www/html/magento/vendor/magento/framework/App/Bootstrap.php(258): Magento\\Framework\\App\\Http->launch()\u21b5#8 /var/www/html/magento/index.php(39): Magento\\Framework\\App\\Bootstrap->run(Object(Magento\\Framework\\App\\Http))\u21b5#9 {main}\"\r\nName\r\n\r\n\r\nI'm seriously lost, have tried everything and cannot get this issue sorted. Please help \r\n"},
{"text": "### Preconditions\r\n1. Magento 2.1.3 \r\n\r\n### Steps to reproduce\r\n1. REST POST a new category  (receive 200 ok with category id 43)\r\n2. REST PUT to rename the category (receive 200 ok with new category name in response)\r\n3. REST GET to get the new name (receive 200 ok with new category name)\r\n4. Check category name in administration console\r\n\r\n### Expected result\r\n1. The category name to change \r\n\r\n### Actual result\r\n1. Category name does not change in console\r\n2. In the db the new name is added as an additional attribute set.\r\n\r\nPayload in REST PUT:\r\n\r\n```\r\n{\r\n  \"category\": {\r\n    \"name\": \"Test Category Rename\"\r\n  }\r\n}\r\n```"},
{"text": "When creating a track via the API the response message is incorrect.\r\n\r\n### Preconditions\r\n1. Magento 2.1.2\r\n\r\n### Steps to reproduce\r\n1. Create order in Magento\r\n2. Add shipment via API\r\n3. Add incorrect track (missing number) to shipment via API\r\n\r\n### Expected result\r\n1. Response as described on [Magento REST API documentation](http://devdocs.magento.com/swagger/#!/salesShipmentTrackRepositoryV1)\r\n```\r\n{\r\n  \"message\": \"string\",\r\n  \"errors\": [\r\n    {\r\n      \"message\": \"string\",\r\n      \"parameters\": [\r\n        {\r\n          \"resources\": \"string\",\r\n          \"fieldName\": \"string\",\r\n          \"fieldValue\": \"string\"\r\n        }\r\n      ]\r\n    }\r\n  ],\r\n  \"code\": 0,\r\n  \"parameters\": [\r\n    {\r\n      \"resources\": \"string\",\r\n      \"fieldName\": \"string\",\r\n      \"fieldValue\": \"string\"\r\n    }\r\n  ],\r\n  \"trace\": \"string\"\r\n}\r\n```\r\n\r\n### Actual result\r\n1. \r\n```\r\n{\"message\":\"Cannot save track:\\n%1\",\"parameters\":[\"Number can not be empty\"]}\r\n```"},
{"text": "### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1. Magento 2.1.3\r\n2. PHP7\r\n\r\n### Steps to reproduce\r\n1. Create a product with custom options via the API: /V1/products/\r\n2. The options will apear successfully\r\n3. Now update the product options while specifying the optionid aswell.\r\n\r\n### Expected result\r\n1. The option id should stay the same and the options should be updated rather than being replaced.\r\n\r\n### Actual result\r\n1. The option is updated, however the option id changed.\r\n\r\n### Comment\r\nThe reason this can be a problem is because if you have a cart with items inside of it with the custom options specified and you update the product options the current options will be entirely removed because the ID does not exist anymore. Which results in the customer being able to order a product without options. So we would prefer to just update the existing options so this problem won't occur.\r\n"},
{"text": "### Preconditions\r\n1. Magento 2.1.3 - possibly earlier\r\n2. Available order data with no extension attributes for the payment method\r\n\r\n### Steps to reproduce\r\n1. Place an order without using Braintree to get order data with no extension attributes for payment info\r\n2. Use the REST api to pull order data\r\n\r\n### Expected result\r\n1. The empty extensionattributes under the payment model should be output as an empty object\r\n\r\n### Actual result\r\n1. The empty extensionattributes is output as an empty array\r\n\r\nThis is an issue mainly for API connectors. If you try to map the response data directly onto the expected data model, you will get an error because of the data type mismatch.\r\n"},
{"text": "### Steps to reproduce\r\n1. Create a configurable item in Magento(manually or by API)\r\n2. Add some variations to the item\r\n3. Send an update by WEBAPI with the method: catalogProductRepositoryV1SaveRequest, don't include any info related to the attached simples\r\n\r\n\r\n### Expected result\r\n1. Do just a save for the product with the info in the XML request, leave the variations untouched\r\n\r\n### Actual result\r\n\r\n1. All existing variations / simple items are removed for the configurable\r\n\r\n\r\n"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\r\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\r\n\r\n### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1. I am using Magento 2.1.3 CE Version\r\n\r\n\r\n### Steps to reproduce\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1. Request for WSDL http://domain-name/soap/default/default?wsdl&services=quoteShippingAddressManagementV1\r\n\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. The response should be the correct WSDL XML schema\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. Actual result is:\r\n<env:Envelope xmlns:env=\"http://www.w3.org/2003/05/soap-envelope\">\r\n<env:Body>\r\n<env:Fault>\r\n<env:Code>\r\n<env:Value>env:Receiver</env:Value>\r\n</env:Code>\r\n<env:Reason>\r\n<env:Text xml:lang=\"it\">\r\nInternal Error. Details are available in Magento log file. Report ID: webapi-585b94eb49b5f\r\n</env:Text>\r\n</env:Reason>\r\n</env:Fault>\r\n</env:Body>\r\n</env:Envelope>\r\n\r\nIn the log error:\r\n\r\nMessage: The required service is not available: \"quoteShippingAddressManagementV1\" in /vendor/magento/framework/Webapi/ErrorProcessor.php:195\r\n<!--- (This may be platform independent comment) -->\r\n"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\r\nReceiving an unrecognized document type when trying to process the magento2 soap wsdl with Visual Studio 2015 \r\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\r\n\r\n### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1. Magento v2.1.1 installed and running\r\n2. Visual Studio 2015 \r\n\r\n\r\n### Steps to reproduce\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1. Add a service reference of soap wsdl to visual studio 2015 (http://<magentohost>/soap/default?wsdllist=1)\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. Parse wsdl xml response\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. Unrecognised document type \r\nLog from C#\r\nThe document at the url http://[removed]/soap/default?wsdllist=1 was not recognized as a known document type.\r\nThe error message from each known type may help you fix the problem:\r\n- Report from 'XML Schema' is 'Data at the root level is invalid. Line 1, position 1.'.\r\n- Report from 'DISCO Document' is 'Data at the root level is invalid. Line 1, position 1.'.\r\n- Report from 'WSDL Document' is 'There is an error in XML document (1, 1).'.\r\n  - Data at the root level is invalid. Line 1, position 1.\r\nMetadata contains a reference that cannot be resolved: 'http://[removed]/soap/default?wsdllist=1'.\r\nThe content type application/json; charset=UTF-8 of the response message does not match the content type of the binding (application/soap+xml; charset=utf-8). If using a custom encoder, be sure that the IsContentTypeSupported method is implemented properly. The first 1024 bytes of the response were: '{\"directoryCurrencyInformationAcquirerV1\":{\"wsdlendpoint\":\"http:\\/\\/[removed]\\/soap\\/hdjenglishview?wsdl&services=directoryCurrencyInformationAcquirerV1\"},\"directoryCountryInformationAcquirerV1\":{\"wsdlendpoint\":\"http:\\/\\/[removed]\\/soap\\/hdjenglishview?wsdl&services=directoryCountryInformationAcquirerV1\"},\"customerAccountManagementV1\":{\"wsdlendpoint\":\"http:\\/\\/[removed]\\/soap\\/hdjenglishview?wsdl&services=customerAccountManagementV1\"},\"quoteGuestCartRepositoryV1\":{\"wsdlendpoint\":\"http:\\/\\/[removed]\\/soap\\/hdjenglishview?wsdl&services=quoteGuestCartRepositoryV1\"},\"quoteGuestCartManagementV1\":{\"wsdlendpoint\":\"http:\\/\\/[removed]\\/soap\\/hdjenglishview?wsdl&services=quoteGuestCartManagementV1\"},\"quoteGuestShippingMethodManagementV1\":{\"wsdlendpoint\":\"http:\\/\\/[removed]\\/soap\\/hdjenglishview?wsdl&services=quoteGuestShippingMethodManagementV1\"},\"quoteGuestShipmentEstimationV1\":{\"wsdlendpoint\":\"http:\\/\\/[removed]\\/soap\\/hdjenglis'.\r\nIf the service is defined in the current solution, try building the solution and adding the service reference again.\r\n\r\n\r\n<!--- (This may be platform independent comment) -->\r\n"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\r\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\r\n\r\n### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1.  Instance is setup using Magento 2.1.2 CE release and shipping tables are setup with handling fee\r\n\r\n### Steps to reproduce\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1.  Placed an order with shipping method to have handling fee.\r\n2.  Make a API call GET:/V1/orders/:id or GET:/V1/orders?searchCriteria[filtergroups][0][filters][0][field]=incrementid&searchCriteria[filtergroups][0][filters][0][value]={{incrementid}}&searchCriteria[filtergroups][0][filters][0][conditiontype]=eq\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1.  Response json should be to give handling fee amount.\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. \r\n![image](https://cloud.githubusercontent.com/assets/12096540/21449552/513a4afa-c914-11e6-845a-216f4363e2c2.png)\r\n\r\nResponse for this order\r\n\r\n[1091.txt](https://github.com/magento/magento2/files/670451/1091.txt)\r\n\r\n\r\n\r\n\r\n<!--- (This may be platform independent comment) -->\r\n"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\r\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\r\n\r\n### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1. Release: 2.1.3 CE\r\n2. Using Visual studio 2015 to write service reference SOAP API Call \r\n\r\n### Steps to reproduce\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1. Call web method catalogProductRepositoryV1Get for bundle product\r\n2. Fiddler returns the data correctly but the data aren't  deserializable in Visual Studio \r\n3. The issue  is only in the bundle type products\r\n\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. The Fiddler XML response is:\r\n```\r\n\r\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<SOAP-ENV:Envelope xmlns:SOAP-ENV=\"http://schemas.xmlsoap.org/soap/envelope/\" xmlns:ns1=\"http://test.jonathan.it/soap/default?services=catalogProductRepositoryV1%2CcatalogInventoryStockRegistryV1\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\">\r\n   <SOAP-ENV:Body>\r\n      <ns1:catalogProductRepositoryV1GetResponse>\r\n         <result>\r\n            <id>16</id>\r\n            <sku>B001</sku>\r\n            <name>Bundle prova</name>\r\n            <attributeSetId>9</attributeSetId>\r\n            <price>0</price>\r\n            <status>1</status>\r\n            <visibility>4</visibility>\r\n            <typeId>bundle</typeId>\r\n            <createdAt>2016-12-27 17:02:25</createdAt>\r\n            <updatedAt>2016-12-27 17:02:25</updatedAt>\r\n            <weight>0</weight>\r\n            <extensionAttributes>\r\n               <bundleProductOptions>\r\n                  <item>\r\n                     <optionId>19</optionId>\r\n                     <title>Modello</title>\r\n                     <required>false</required>\r\n                     <type>checkbox</type>\r\n                     <position>1</position>\r\n                     <sku>B001</sku>\r\n                     <productLinks>\r\n                        <item>\r\n                           <id>37</id>\r\n                           <sku>224045</sku>\r\n                           <optionId>19</optionId>\r\n                           <qty>1</qty>\r\n                           <position>1</position>\r\n                           <isDefault>true</isDefault>\r\n                           <price />\r\n                           <priceType />\r\n                           <canChangeQuantity>0</canChangeQuantity>\r\n                        </item>\r\n                     </productLinks>\r\n                  </item>\r\n                  <item>\r\n                     <optionId>20</optionId>\r\n                     <title>Radiocomandi</title>\r\n                     <required>false</required>\r\n                     <type>checkbox</type>\r\n                     <position>2</position>\r\n                     <sku>B001</sku>\r\n                     <productLinks>\r\n                        <item>\r\n                           <id>38</id>\r\n                           <sku>444534</sku>\r\n                           <optionId>20</optionId>\r\n                           <qty>1</qty>\r\n                           <position>1</position>\r\n                           <isDefault>false</isDefault>\r\n                           <price />\r\n                           <priceType />\r\n                           <canChangeQuantity>1</canChangeQuantity>\r\n                        </item>\r\n                        <item>\r\n                           <id>39</id>\r\n                           <sku>444555</sku>\r\n                           <optionId>20</optionId>\r\n                           <qty>1</qty>\r\n                           <position>2</position>\r\n                           <isDefault>false</isDefault>\r\n                           <price />\r\n                           <priceType />\r\n                           <canChangeQuantity>1</canChangeQuantity>\r\n                        </item>\r\n                        <item>\r\n                           <id>40</id>\r\n                           <sku>444298</sku>\r\n                           <optionId>20</optionId>\r\n                           <qty>1</qty>\r\n                           <position>3</position>\r\n                           <isDefault>false</isDefault>\r\n                           <price />\r\n                           <priceType />\r\n                           <canChangeQuantity>1</canChangeQuantity>\r\n                        </item>\r\n                     </productLinks>\r\n                  </item>\r\n                  <item>\r\n                     <optionId>21</optionId>\r\n                     <title>Motori</title>\r\n                     <required>false</required>\r\n                     <type>checkbox</type>\r\n                     <position>3</position>\r\n                     <sku>B001</sku>\r\n                     <productLinks>\r\n                        <item>\r\n                           <id>41</id>\r\n                           <sku>356019</sku>\r\n                           <optionId>21</optionId>\r\n                           <qty>1</qty>\r\n                           <position>1</position>\r\n                           <isDefault>false</isDefault>\r\n                           <price />\r\n                           <priceType />\r\n                           <canChangeQuantity>1</canChangeQuantity>\r\n                        </item>\r\n                        <item>\r\n                           <id>42</id>\r\n                           <sku>356824</sku>\r\n                           <optionId>21</optionId>\r\n                           <qty>1</qty>\r\n                           <position>2</position>\r\n                           <isDefault>false</isDefault>\r\n                           <price />\r\n                           <priceType />\r\n                           <canChangeQuantity>1</canChangeQuantity>\r\n                        </item>\r\n                     </productLinks>\r\n                  </item>\r\n               </bundleProductOptions>\r\n               <stockItem>\r\n                  <itemId>15</itemId>\r\n                  <productId>16</productId>\r\n                  <stockId>1</stockId>\r\n                  <qty>0</qty>\r\n                  <isInStock>true</isInStock>\r\n                  <isQtyDecimal>false</isQtyDecimal>\r\n                  <showDefaultNotificationMessage>false</showDefaultNotificationMessage>\r\n                  <useConfigMinQty>true</useConfigMinQty>\r\n                  <minQty>0</minQty>\r\n                  <useConfigMinSaleQty>1</useConfigMinSaleQty>\r\n                  <minSaleQty>1</minSaleQty>\r\n                  <useConfigMaxSaleQty>true</useConfigMaxSaleQty>\r\n                  <maxSaleQty>10000</maxSaleQty>\r\n                  <useConfigBackorders>true</useConfigBackorders>\r\n                  <backorders>0</backorders>\r\n                  <useConfigNotifyStockQty>true</useConfigNotifyStockQty>\r\n                  <notifyStockQty>1</notifyStockQty>\r\n                  <useConfigQtyIncrements>true</useConfigQtyIncrements>\r\n                  <qtyIncrements>0</qtyIncrements>\r\n                  <useConfigEnableQtyInc>true</useConfigEnableQtyInc>\r\n                  <enableQtyIncrements>false</enableQtyIncrements>\r\n                  <useConfigManageStock>true</useConfigManageStock>\r\n                  <manageStock>true</manageStock>\r\n                  <lowStockDate />\r\n                  <isDecimalDivided>false</isDecimalDivided>\r\n                  <stockStatusChangedAuto>0</stockStatusChangedAuto>\r\n               </stockItem>\r\n            </extensionAttributes>\r\n            <productLinks />\r\n            <options />\r\n            <mediaGalleryEntries />\r\n            <tierPrices />\r\n            <customAttributes>\r\n               <item>\r\n                  <attributeCode>description</attributeCode>\r\n                  <value>&amp;lt;p&amp;gt;&amp;lt;span style=\"font-family: Verdana, Arial; helvetica; font-size: 12px; color: #000000;\"&amp;gt;L&amp;rsquo;UMX Yak 54 3D BNF realizza&amp;lt;strong&amp;gt; il sogno di molti modellista&amp;lt;/strong&amp;gt; di volare con un modello 3D in &amp;lt;strong&amp;gt;uno spazio ridottissimo&amp;lt;/strong&amp;gt; come una grande sala da pranzo o una sala conferenze.&amp;lt;br /&amp;gt; L&amp;rsquo;UMX Yak 54 &amp;egrave; un &amp;lt;strong&amp;gt;micro aeromodello elettrico 3D&amp;lt;/strong&amp;gt;, con un peso di soli&amp;lt;strong&amp;gt; 36 grammi.&amp;lt;/strong&amp;gt;&amp;lt;br /&amp;gt; La struttura &amp;egrave; realizzata in &amp;lt;strong&amp;gt;materiale espanso ultra alleggerito&amp;lt;/strong&amp;gt; e coperto con una pellicola sottilissima. La cellula &amp;egrave; &amp;lt;strong&amp;gt;rinforzata con barre in fibra di carbonio&amp;lt;/strong&amp;gt; che riducono la flessione e torsione per effettuare le pi&amp;ugrave; spinte manovre 3D con assoluta precisione.&amp;lt;br /&amp;gt; Lo Yak 54 viene fornito &amp;lt;strong&amp;gt;completamente assemblato&amp;lt;/strong&amp;gt;, completo di un potente motore coreless.&amp;lt;br /&amp;gt; L&amp;rsquo;elettronica comprende il&amp;lt;strong&amp;gt; sistema di stabilizzazione&amp;lt;/strong&amp;gt; &amp;lt;strong&amp;gt;AS3X&amp;lt;/strong&amp;gt; per offrirvi un controllo di volo ancora superiore. &amp;lt;br /&amp;gt; Il sistema AS3X integrato nella ricevente, garantisce una enorme stabilit&amp;agrave; al volo pur conservando il massimo controllo sia per i voli sport che 3D, aiutando in modo invisibile con correzioni complesse.&amp;lt;br /&amp;gt; Per il funzionamento &amp;lt;strong&amp;gt;&amp;egrave; richiesto un radiocomando con trasmissione Spektrum DSM2/DSMX&amp;lt;/strong&amp;gt;, almeno 4 canali e funzione di riduzione di corsa ed esponenziali.&amp;lt;strong&amp;gt;&amp;lt;/strong&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;/p&amp;gt;&amp;#13;\r\n&amp;lt;p&amp;gt;&amp;lt;span style=\"font-family: Verdana, Arial; helvetica; font-size: 12px; color: #000000;\"&amp;gt;&amp;lt;strong&amp;gt;Contenuto del kit:&amp;lt;br /&amp;gt; &amp;lt;/strong&amp;gt;- Modello BNF&amp;lt;br /&amp;gt; - Servocomandi installati&amp;lt;br /&amp;gt; - Motore e regolatore con tecnologia AS3X&amp;lt;/span&amp;gt;&amp;lt;/p&amp;gt;</value>\r\n               </item>\r\n               <item>\r\n                  <attributeCode>shortdescription</attributeCode>\r\n                  <value>&amp;lt;p&amp;gt;&amp;lt;span style=\"font-family: Verdana, Arial; helvetica; font-size: 12px; color: #ff0000;\"&amp;gt;Questo&amp;lt;strong&amp;gt; &amp;lt;/strong&amp;gt;articolo non &amp;egrave; disponibile e non conosciamo la data di arrivo. &amp;lt;br /&amp;gt; Se preordini ora, effettueremo la consegna non appena arriver&amp;agrave;, se il prezzo dovesse diminuire prima della data di spedizione, pagherai il prezzo pi&amp;ugrave; basso.&amp;lt;/span&amp;gt;&amp;lt;/p&amp;gt;&amp;#13;\r\n&amp;lt;p&amp;gt;&amp;lt;span style=\"font-family: Verdana, Arial; helvetica; font-size: 12px; color: #000000;\"&amp;gt;L&amp;rsquo;UMX Yak 54 3D BNF realizza&amp;lt;strong&amp;gt; il sogno di molti modellista&amp;lt;/strong&amp;gt; di volare con un modello 3D in &amp;lt;strong&amp;gt;uno spazio ridottissimo&amp;lt;/strong&amp;gt; come una grande sala da pranzo o una sala conferenze.&amp;lt;br /&amp;gt; L&amp;rsquo;UMX Yak 54 &amp;egrave; un &amp;lt;strong&amp;gt;micro aeromodel&amp;lt;/strong&amp;gt;...&amp;lt;/span&amp;gt;&amp;lt;/p&amp;gt;</value>\r\n               </item>\r\n               <item>\r\n                  <attributeCode>metatitle</attributeCode>\r\n                  <value>Bundle prova</value>\r\n               </item>\r\n               <item>\r\n                  <attributeCode>metakeyword</attributeCode>\r\n                  <value>Bundle prova</value>\r\n               </item>\r\n               <item>\r\n                  <attributeCode>metadescription</attributeCode>\r\n                  <value>Bundle prova L\u2019UMX Yak 54 3D BNF realizza il sogno di molti modellista di volare con un modello 3D in uno spazio ridottissimo come una grande sala da pranzo o una sala conferenze. L\u2019UMX Yak 54 \u00e8 un micro aeromodello elettrico 3D, con un peso di soli 36 gr</value>\r\n               </item>\r\n               <item>\r\n                  <attributeCode>categoryids</attributeCode>\r\n                  <value>\r\n                     <xsd:string>3</xsd:string>\r\n                  </value>\r\n               </item>\r\n               <item>\r\n                  <attributeCode>optionscontainer</attributeCode>\r\n                  <value>container2</value>\r\n               </item>\r\n               <item>\r\n                  <attributeCode>requiredoptions</attributeCode>\r\n                  <value>0</value>\r\n               </item>\r\n               <item>\r\n                  <attributeCode>hasoptions</attributeCode>\r\n                  <value>1</value>\r\n               </item>\r\n               <item>\r\n                  <attributeCode>urlkey</attributeCode>\r\n                  <value>bundle-prova</value>\r\n               </item>\r\n               <item>\r\n                  <attributeCode>pricetype</attributeCode>\r\n                  <value>0</value>\r\n               </item>\r\n               <item>\r\n                  <attributeCode>skutype</attributeCode>\r\n                  <value>1</value>\r\n               </item>\r\n               <item>\r\n                  <attributeCode>weighttype</attributeCode>\r\n                  <value>0</value>\r\n               </item>\r\n               <item>\r\n                  <attributeCode>priceview</attributeCode>\r\n                  <value>0</value>\r\n               </item>\r\n               <item>\r\n                  <attributeCode>shipmenttype</attributeCode>\r\n                  <value>1</value>\r\n               </item>\r\n               <item>\r\n                  <attributeCode>taxclassid</attributeCode>\r\n                  <value>5</value>\r\n               </item>\r\n               <item>\r\n                  <attributeCode>giftmessageavailable</attributeCode>\r\n                  <value>2</value>\r\n               </item>\r\n               <item>\r\n                  <attributeCode>featured</attributeCode>\r\n                  <value>0</value>\r\n               </item>\r\n            </customAttributes>\r\n         </result>\r\n      </ns1:catalogProductRepositoryV1GetResponse>\r\n   </SOAP-ENV:Body>\r\n</SOAP-ENV:Envelope>\r\n```\r\n\r\nThe error is likely caused by null fields `<price/>` and `<priceType />` in productLinks\r\n\r\n<!--- (This may be platform independent comment) -->\r\n\r\n### Expected result\r\nno deserialsing error\r\n"},
{"text": "**Problem description:**\r\nWhen use PUT API calls for change \"types\" field on one image of product, thera are problems.\r\nFor exampe, If we want assing Types=\"Thumbnail\" to image with ID 15 and there is other image in the same product that have alrady assigned \"thumbnail\" and this last image have higher ID, for example ID 19, then PUT action will not update Types field. In the opossite case, if we try assign \"Thumbnail\" to image with id 19 and image with ID 15 have assigned this type, PUT action will update them successful.\r\nIn resume, PUT media API Call apply change at types values only when ID of image is lower than ID image that have \"Types\" values assigned before.\r\n\r\n\r\n### Preconditions\r\nMagento 2\r\nVersion: 2.1.x (tested on 2.1.1 and 2.1.3)\r\nEC2 Instance of AWS Amazon with CentOS\r\nPHP v7.0.10\r\nMysql 5.6\r\nAlso was tested on local environment with Vagrant with CentOS.\r\n\r\n\r\n### Steps to reproduce\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1. Create with API new product with sku SUN001\r\n2. Add 3 different images with API Call POST /V1/products/SUN001/media\r\n3. Assing with PUT the Types value \"images\",\"smallimage\",\"thumbnail\". Example:\r\nPUT\r\n{{baseurl}}/rest/V1/products/sun-001/media/19\r\n{\r\n  \"entry\": {\r\n    \"id\" : \"19\"\r\n    \"mediatype\": \"image\",\r\n    \"label\": \"image 3\",\r\n    \"disabled\": false,\r\n    \"position\" : 0,\r\n    \"types\": [\r\n      \"images\",\r\n      \"smallimages\",\r\n      \"thumbnail\"\r\n    ]\r\n    \r\n  }\r\n}\r\n4. Try now assign types values to image with lower id in the same product, for example:\r\nPUT\r\n{{baseurl}}/rest/V1/products/sun-001/media/15\r\n{\r\n  \"entry\": {\r\n    \"id\" : \"15\"\r\n    \"mediatype\": \"image\",\r\n    \"label\": \"image 3\",\r\n    \"disabled\": false,\r\n    \"position\" : 0,\r\n    \"types\": [\r\n      \"images\",\r\n      \"smallimages\",\r\n      \"thumbnail\"\r\n    ]\r\n    \r\n  }\r\n}\r\n5. When you check images at backend or with GET of product data at API call, you can see that image with ID 19 and ID 15 is not updated correctly. Image ID 19 keep types value without update.\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. We wait that image with lower ID get the types values assigned and image with higher ID be emtpy at Types field.\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. When you check images at backend or with GET of product data at API call, you can see that image with ID 19 and ID 15 is not updated correctly. Image ID 19 keep types value without update.\r\n\r\n\r\n"},
{"text": "Hi all,\r\n\r\nWhen using the Magento 2.1.1 SOAP API to update the sales order state, the displayed ID (incrementid) is changed with the order state.\r\n\r\n### Preconditions\r\nWe use a JAVA client for the magento 2.1.1 SOAP API to handle sales order in an external application.\r\n\r\n### Steps to reproduce\r\n1. Create a sales order from the magento shop. Assume that the displayed order ID (incrementid) is 0000001 and the internal order ID (entityid) is 1. The order is created and its state is complete.\r\n2. Use the salesOrderRepository SOAP API to fetch the order and treat it in our external application.\r\n3. Assume the the order is completely treated in our application, we want to close it. So we use the salesOrderRepository SOAP API save operation to update the order state from complete to closed.\r\n\r\n### Expected result\r\nWhat we expected is that the order state is changed but its visible ID remains the same since it is the ID sent to the customer as a reference and if something wrong happens we will not find a reference to the customer order.\r\n\r\n### Actual result\r\nThe order state is updated correctly but the visible ID is increment to 0000002. The internal order ID is not touched and we are still able to fetch it using the SOAP API with the same internal ID. Finally we have sent an email to the customer telling him that his order (ID = 0000001) is created and when the order is treated, its visible ID is changed to 0000002. Our problem here is when the customer will complain about an error occurred in his order, he will tell us that his order ID is 0000001 which does not exist anymore in the magento store since it is transformed to 0000002 after the SOAP API save call.  \r\n\r\nBest Regards"},
{"text": "### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1. Magento 2.1.3 \r\n2. PHP 7.0.8-0ubuntu0.16.04.3 \r\n\r\n### Steps to reproduce\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1. Define a Extension attribute for the OrderInterface with a join table:\r\n```\r\n    <extensionattributes for=\"Magento\\Sales\\Api\\Data\\OrderInterface\">\r\n        <attribute code=\"someid\" type=\"string\">\r\n            <join referencetable=\"SOMETABLE\" joinonfield=\"quoteid\" referencefield=\"quoteid\">\r\n                <field>someid</field>\r\n            </join>\r\n        </attribute>\r\n    </extensionattributes>\r\n```\r\n2. Make sure there's matching data in the SOMETABLE table and the salesorder table\r\n3. Request orders via REST\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. I expected to see someid in the resulting json response (this does work for Quote extension attributes).\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. No someid in the extension attributes property of the json response\r\n\r\n<!--- (This may be platform independent comment) -->\r\n"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\r\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\r\n\r\n### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1. Magento 2.0.0 - 2.1.3 (Community or Enterprise) with Sample Data installed\r\n2. Environment using [magento2-docker-compose](https://github.com/mageinferno/magento2-docker-compose/)\r\n\r\n### Steps to reproduce\r\n\r\nThis issue appears to affect at least /products/ and /categories/ requests. I have added below an example for products. \r\n\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1. Make API request for products specifying page size as 1, current page as 99999, eg:\r\n\r\n```\r\nGET /rest/default/V1/products/?searchCriteria[pageSize]=1&searchCriteria[currentPage]=9999 \r\nHTTP/1.1\r\nHost: m2.localhost:8000\r\nAuthorization: OAuth oauthconsumerkey=\"sitoq7tu4b1aj7kikj4irkog8tggh1ch\",oauthtoken=\"kr3bly2kbbnrr9flyws9r4mxdaagxngo\",oauthsignaturemethod=\"HMAC-SHA1\",oauthtimestamp=\"1484095699\",oauthnonce=\"TivkWr\",oauthversion=\"1.0\",oauthsignature=\"Q02C2wk4AgkDPkYAbACUoLMoXa4%3D\"\r\nCache-Control: no-cache\r\n```\r\n\r\nNote: Page size of '1' above is a nominal value to make examples given below more concise. \r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. No items returned in response if (current page * page size) > total products, eg:\r\n\r\n```json\r\n{\r\n  \"items\": [],\r\n  \"searchcriteria\": {\r\n    \"filtergroups\": [],\r\n    \"pagesize\": 1,\r\n    \"currentpage\": 99999\r\n  },\r\n  \"totalcount\": 2048\r\n}\r\n```\r\n\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. The product with highest id is returned, eg:\r\n\r\n```json\r\n{\r\n  \"items\": [\r\n    {\r\n      \"id\": 2048,\r\n      \"sku\": \"24-WG085Group\",\r\n      \"name\": \"Set of Sprite Yoga Straps\",\r\n      \"attributesetid\": 12,\r\n      \"status\": 1,\r\n      \"visibility\": 4,\r\n      \"typeid\": \"grouped\",\r\n      \"createdat\": \"2016-11-13 21:24:31\",\r\n      \"updatedat\": \"2016-11-13 21:24:31\",\r\n      \"extensionattributes\": [],\r\n      \"productlinks\": [\r\n        {\r\n          \"sku\": \"24-WG085Group\",\r\n          \"linktype\": \"associated\",\r\n          \"linkedproductsku\": \"24-WG085\",\r\n          \"linkedproducttype\": \"simple\",\r\n          \"position\": 0,\r\n          \"extensionattributes\": {\r\n            \"qty\": 0\r\n          }\r\n        },\r\n        {\r\n          \"sku\": \"24-WG085Group\",\r\n          \"linktype\": \"associated\",\r\n          \"linkedproductsku\": \"24-WG086\",\r\n          \"linkedproducttype\": \"simple\",\r\n          \"position\": 1,\r\n          \"extensionattributes\": {\r\n            \"qty\": 0\r\n          }\r\n        },\r\n        {\r\n          \"sku\": \"24-WG085Group\",\r\n          \"linktype\": \"associated\",\r\n          \"linkedproductsku\": \"24-WG087\",\r\n          \"linkedproducttype\": \"simple\",\r\n          \"position\": 2,\r\n          \"extensionattributes\": {\r\n            \"qty\": 0\r\n          }\r\n        }\r\n      ],\r\n      \"tierprices\": [],\r\n      \"customattributes\": [\r\n        {\r\n          \"attributecode\": \"description\",\r\n          \"value\": \"<p>Great set of Sprite Yoga Straps for every stretch and hold you need. There are three straps in this set: 6', 8' and 10'.</p>\\n<ul>\\n<li> 100% soft and durable cotton.\\n<li> Plastic cinch buckle is easy to use.\\n<li> Choice of three natural colors made from phthalate and heavy metal free dyes.\\n</ul>\"\r\n        },\r\n        {\r\n          \"attributecode\": \"image\",\r\n          \"value\": \"/l/u/luma-yoga-strap-set.jpg\"\r\n        },\r\n        {\r\n          \"attributecode\": \"smallimage\",\r\n          \"value\": \"/l/u/luma-yoga-strap-set.jpg\"\r\n        },\r\n        {\r\n          \"attributecode\": \"thumbnail\",\r\n          \"value\": \"/l/u/luma-yoga-strap-set.jpg\"\r\n        },\r\n        {\r\n          \"attributecode\": \"optionscontainer\",\r\n          \"value\": \"container2\"\r\n        },\r\n        {\r\n          \"attributecode\": \"requiredoptions\",\r\n          \"value\": \"0\"\r\n        },\r\n        {\r\n          \"attributecode\": \"hasoptions\",\r\n          \"value\": \"0\"\r\n        },\r\n        {\r\n          \"attributecode\": \"urlkey\",\r\n          \"value\": \"set-of-sprite-yoga-straps\"\r\n        },\r\n        {\r\n          \"attributecode\": \"isreturnable\",\r\n          \"value\": \"2\"\r\n        },\r\n        {\r\n          \"attributecode\": \"activity\",\r\n          \"value\": \"17\"\r\n        },\r\n        {\r\n          \"attributecode\": \"material\",\r\n          \"value\": \"41,53\"\r\n        },\r\n        {\r\n          \"attributecode\": \"gender\",\r\n          \"value\": \"89,90,93\"\r\n        },\r\n        {\r\n          \"attributecode\": \"categorygear\",\r\n          \"value\": \"96\"\r\n        },\r\n        {\r\n          \"attributecode\": \"size\",\r\n          \"value\": \"100\"\r\n        }\r\n      ]\r\n    }\r\n  ],\r\n  \"searchcriteria\": {\r\n    \"filtergroups\": [],\r\n    \"pagesize\": 1,\r\n    \"currentpage\": 99999\r\n  },\r\n  \"totalcount\": 2048\r\n}\r\n```\r\n\r\n<!--- (This may be platform independent comment) -->\r\n"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\r\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\r\n\r\n### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1. Magento 2.1.3, using Sample Data\r\n2. Environment using [magento2-docker-compose](https://github.com/mageinferno/magento2-docker-compose)\r\n\r\n### Steps to reproduce\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1. Create new integration\r\n2. Create a new website with code \"test\"\r\n3. Create a new store, assign to the \"test\" website\r\n4. Create a new store view with code \"test\", assign to the new store\r\n5. (Optional) - Don't assign any products to the website to make test easier to verify\r\n6. Perform REST API GET request using the store code in the URL, eg:\r\n\r\n```\r\nGET /rest/test/V1/products/?searchCriteria[pageSize]=1&searchCriteria[currentPage]=50 \r\nHTTP/1.1\r\nHost: m2.localhost:8000\r\nAuthorization: OAuth oauthconsumerkey=\"sitoq7tu4b1aj7kikj4irkog8tggh1ch\",oauthtoken=\"kr3bly2kbbnrr9flyws9r4mxdaagxngo\",oauthsignaturemethod=\"HMAC-SHA1\",oauthtimestamp=\"1484095699\",oauthnonce=\"TivkWr\",oauthversion=\"1.0\",oauthsignature=\"Q02C2wk4AgkDPkYAbACUoLMoXa4%3D\"\r\nCache-Control: no-cache\r\n```\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. Only products assigned to the test website are returned (or no products if none assigned)\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. All products in the Magento instance are returned  \r\n\r\n<!--- (This may be platform independent comment) -->\r\n\r\n---\r\n\r\n### Comments \r\n\r\nIs it intended that using a non-\"default\" store code exposes a global product repository? Reading the [documentation](http://devdocs.magento.com/guides/v2.0/rest/restendpoints.html) it sounds like the request should be limited to the store that's specified:\r\n\r\n> The value of `storecode` can be one of the following:\r\n> - default\r\n> - The assigned store code\r\n>  - all. This value only applies to the CMS and Product modules. If this value is specified, the API call affects all the merchant's stores. GEToperations cannot be performed when you specify all.\r\n\r\nI have also attempted a search criteria filter against the following fields: store, storeid, storecode, website, websiteid, websitecode, all of which return `\"Invalid attribute name: %1\"`. \r\n\r\nI'm unable to find any other alternatives in the documentation. Is there currently no multistore support in the product API, or have I missed something obvious? "},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\r\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\r\n\r\n### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1. Magento 2.0.0 - 2.1.3\r\n\r\n### Steps to reproduce\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1. Create OAuth integration\r\n2. Make API request having `Authorization` header beginning with non \"OAuth\" value:\r\n\r\n```\r\nGET /rest/default/V1/products?searchCriteria[pageSize]=5&amp;searchCriteria[currentPage]=1 HTTP/1.1\r\nHost: host.example.com\r\nAuthorization: Basic d2luZHcm0yOlxxdpTxxzb1JTbWlUSdsMTss=, OAuth oauthconsumerkey=\"ror07fth0ctjq16xddlrnkbg9qd5t29j\",oauthtoken=\"edkoyum5qmuokayjho7dvc5jbf9186ii\",oauthsignaturemethod=\"HMAC-SHA1\",oauthtimestamp=\"1484543150\",oauthnonce=\"vO6XiU\",oauthsignature=\"IB9F87TZM%2Btk1VK9aT%2FXnZ7VZFI%3D\"\r\nCache-Control: no-cache\r\n```\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. API request processed\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. OAuth authorization validation fails due to parsing of `Authorization` header value\r\n\r\n```json\r\n{\"message\":\"Consumer is not authorized to access %resources\",\"parameters\":{\"resources\":\"MagentoCatalog::products\"},\"trace\":\"#0 \\/var\\/www\\/releases\\/20170105100948\\/src\\/vendor\\/magento\\/module-webapi\\/Controller\\/Rest\\/RequestValidator.php(70): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\RequestValidator->checkPermissions()\\n#1 \\/var\\/www\\/releases\\/20170105100948\\/src\\/vendor\\/magento\\/module-webapi\\/Controller\\/Rest\\/InputParamsResolver.php(80): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\RequestValidator->validate()\\n#2 \\/var\\/www\\/releases\\/20170105100948\\/src\\/vendor\\/magento\\/module-webapi\\/Controller\\/Rest.php(299): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\InputParamsResolver->resolve()\\n#3 \\/var\\/www\\/releases\\/20170105100948\\/src\\/vendor\\/magento\\/module-webapi\\/Controller\\/Rest.php(216): Magento\\\\Webapi\\\\Controller\\\\Rest->processApiRequest()\\n#4 \\/var\\/www\\/releases\\/20170105100948\\/src\\/vendor\\/magento\\/framework\\/Interception\\/Interceptor.php(146): Magento\\\\Webapi\\\\Controller\\\\Rest->dispatch(Object(Magento\\\\Framework\\\\App\\\\Request\\\\Http))\\n#5 \\/var\\/www\\/releases\\/20170105100948\\/src\\/var\\/generation\\/Magento\\/Webapi\\/Controller\\/Rest\\/Interceptor.php(26): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\Interceptor->callPlugins('dispatch', Array, Array)\\n#6 \\/var\\/www\\/releases\\/20170105100948\\/src\\/vendor\\/magento\\/framework\\/App\\/Http.php(135): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\Interceptor->dispatch(Object(Magento\\\\Framework\\\\App\\\\Request\\\\Http))\\n#7 \\/var\\/www\\/releases\\/20170105100948\\/src\\/vendor\\/magento\\/framework\\/App\\/Bootstrap.php(258): Magento\\\\Framework\\\\App\\\\Http->launch()\\n#8 \\/var\\/www\\/releases\\/20170105100948\\/src\\/pub\\/index.php(37): Magento\\\\Framework\\\\App\\\\Bootstrap->run(Object(Magento\\\\Framework\\\\App\\\\Http))\\n#9 {main}\"}```\r\n"},
{"text": "I use following calls to quote api to set product quantity: \r\n```\r\n'guest': '/guest-carts/:cartId/items'\r\n'customer': '/carts/mine/items'\r\n```\r\nUsing those api calls quantity can be changed regardless of admin configurations.\r\n\r\n### Preconditions\r\n1. Magento 2.1.3 with sample data\r\n2. Enable `Stores > Configuration > SALES > Sales > Minimum Order Amount`\r\n3. Set `Maximum Qty Allowed in Shopping Cart`, `Minimum Qty Allowed in Shopping Cart` and `Qty Increments` in `Stores > Configuration > CATALOG > Inventory > Product Stock Options`\r\n\r\n### Steps to reproduce\r\n1. Make call to api setting item quantity: \r\n```\r\n{\r\n    cartItem: {\r\n        itemid: itemId,\r\n        qty: qty,\r\n        quoteid: quoteId\r\n    }\r\n}\r\n```\r\n\r\n### Expected result\r\n1. Error message if quantity change conflicts with one of described configurations.\r\n\r\n### Actual result\r\n1. Quantity is changed regardless of quantity and totals configurations."},
{"text": "### Preconditions\r\nphp 7\r\nPercona\r\nMagento 2.1.3\r\n(mageinferno docker image)\r\n\r\n### Steps to reproduce\r\nPUT /rest/V1/products/SOMESKU\r\n\r\n### Expected result\r\nThe product should be visible in the website.\r\n\r\n### Actual result\r\nIt is not. \r\n\r\nWhen investigation, I found that the products created via REST were assigned to the website 0, while products created via the admin GUI are assigned to website 1. (In table `catalogproductwebsite`.)"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\r\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\r\n\r\n### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1. Magento 2.1.3 with Sample Data\r\n\r\n### Steps to reproduce\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1. Create two products via API with same name, eg:\r\n\r\n**Request 1**\r\n```\r\nPOST /rest/default/V1/products/ HTTP/1.1\r\nHost: example.com\r\nAuthorization: OAuth oauthconsumerkey=\"sitoq7tu4b1aj7kikj4irkog8tggh1ch\",oauthtoken=\"kr3bly2kbbnrr9flyws9r4mxdaagxngo\",oauthsignaturemethod=\"HMAC-SHA1\",oauthtimestamp=\"1484796895\",oauthnonce=\"ah5BdS\",oauthsignature=\"kNaSGRy%2FNg5SYBf%2BI1AJuozM1hs%3D\"\r\nContent-Type: application/json\r\nCache-Control: no-cache\r\n\r\n{\r\n\t\"product\": {\r\n\t\t\"attributesetid\": 4,\r\n\t\t\"name\": \"Test API 1\",\r\n\t\t\"price\": 254.13,\r\n\t\t\"sku\": \"1234\"\r\n\t}\r\n}\r\n```\r\n\r\n**Request 2**\r\n```\r\nPOST /rest/default/V1/products/ HTTP/1.1\r\nHost: example.com\r\nAuthorization: OAuth oauthconsumerkey=\"sitoq7tu4b1aj7kikj4irkog8tggh1ch\",oauthtoken=\"kr3bly2kbbnrr9flyws9r4mxdaagxngo\",oauthsignaturemethod=\"HMAC-SHA1\",oauthtimestamp=\"1484796895\",oauthnonce=\"ah5BdS\",oauthsignature=\"kNaSGRy%2FNg5SYBf%2BI1AJuozM1hs%3D\"\r\nContent-Type: application/json\r\nCache-Control: no-cache\r\n\r\n{\r\n\t\"product\": {\r\n\t\t\"attributesetid\": 4,\r\n\t\t\"name\": \"Test API 1\",\r\n\t\t\"price\": 254.13,\r\n\t\t\"sku\": \"1235\"\r\n\t}\r\n}\r\n```\r\n\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. Both products created successfully\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. Error \"URL key for specified store already exists.\"\r\n\r\n```\r\n{\"message\":\"URL key for specified store already exists.\",\"trace\":\"#0 \\/var\\/www\\/html\\/vendor\\/magento\\/framework\\/Interception\\/Interceptor.php(74): Magento\\\\UrlRewrite\\\\Model\\\\Storage\\\\AbstractStorage->replace(Array)\\n#1 \\/var\\/www\\/html\\/vendor\\/magento\\/framework\\/Interception\\/Chain\\/Chain.php(70): Magento\\\\UrlRewrite\\\\Model\\\\Storage\\\\DbStorage\\\\Interceptor->callParent('replace', Array)\\n#2 \\/var\\/www\\/html\\/vendor\\/magento\\/framework\\/Interception\\/Interceptor.php(138): Magento\\\\Framework\\\\Interception\\\\Chain\\\\Chain->invokeNext('Magento\\\\\\\\UrlRewr...', 'replace', Object(Magento\\\\UrlRewrite\\\\Model\\\\Storage\\\\DbStorage\\\\Interceptor), Array, 'storageplugin')\\n#3 \\/var\\/www\\/html\\/vendor\\/magento\\/module-catalog-url-rewrite\\/Model\\/Category\\/Plugin\\/Storage.php(43): Magento\\\\UrlRewrite\\\\Model\\\\Storage\\\\DbStorage\\\\Interceptor->Magento\\\\Framework\\\\Interception\\\\{closure}(Array)\\n#4 \\/var\\/www\\/html\\/vendor\\/magento\\/framework\\/Interception\\/Interceptor.php(142): Magento\\\\CatalogUrlRewrite\\\\Model\\\\Category\\\\Plugin\\\\Storage->aroundReplace(Object(Magento\\\\UrlRewrite\\\\Model\\\\Storage\\\\DbStorage\\\\Interceptor), Object(Closure), Array)\\n#5 \\/var\\/www\\/html\\/var\\/generation\\/Magento\\/UrlRewrite\\/Model\\/Storage\\/DbStorage\\/Interceptor.php(65): Magento\\\\UrlRewrite\\\\Model\\\\Storage\\\\DbStorage\\\\Interceptor->callPlugins('replace', Array, Array)\\n#6 \\/var\\/www\\/html\\/vendor\\/magento\\/module-catalog-staging\\/Model\\/Url\\/Storage.php(56): Magento\\\\UrlRewrite\\\\Model\\\\Storage\\\\DbStorage\\\\Interceptor->replace(Array)\\n#7 \\/var\\/www\\/html\\/vendor\\/magento\\/module-catalog-url-rewrite\\/Observer\\/ProductProcessUrlRewriteSavingObserver.php(61): Magento\\\\CatalogStaging\\\\Model\\\\Url\\\\Storage->replace(Array)\\n#8 \\/var\\/www\\/html\\/vendor\\/magento\\/framework\\/Event\\/Invoker\\/InvokerDefault.php(73): Magento\\\\CatalogUrlRewrite\\\\Observer\\\\ProductProcessUrlRewriteSavingObserver->execute(Object(Magento\\\\Framework\\\\Event\\\\Observer))\\n#9 \\/var\\/www\\/html\\/vendor\\/magento\\/framework\\/Event\\/Invoker\\/InvokerDefault.php(61): Magento\\\\Framework\\\\Event\\\\Invoker\\\\InvokerDefault->callObserverMethod(Object(Magento\\\\CatalogUrlRewrite\\\\Observer\\\\ProductProcessUrlRewriteSavingObserver), Object(Magento\\\\Framework\\\\Event\\\\Observer))\\n#10 \\/var\\/www\\/html\\/vendor\\/magento\\/module-staging\\/Model\\/Event\\/Manager.php(97): Magento\\\\Framework\\\\Event\\\\Invoker\\\\InvokerDefault->dispatch(Array, Object(Magento\\\\Framework\\\\Event\\\\Observer))\\n#11 \\/var\\/www\\/html\\/var\\/generation\\/Magento\\/Staging\\/Model\\/Event\\/Manager\\/Proxy.php(95): Magento\\\\Staging\\\\Model\\\\Event\\\\Manager->dispatch('catalogproduct...', Array)\\n#12 \\/var\\/www\\/html\\/vendor\\/magento\\/framework\\/Model\\/AbstractModel.php(802): Magento\\\\Staging\\\\Model\\\\Event\\\\Manager\\\\Proxy->dispatch('catalogproduct...', Array)\\n#13 \\/var\\/www\\/html\\/vendor\\/magento\\/module-catalog\\/Model\\/Product.php(921): Magento\\\\Framework\\\\Model\\\\AbstractModel->afterSave()\\n#14 \\/var\\/www\\/html\\/var\\/generation\\/Magento\\/Catalog\\/Model\\/Product\\/Interceptor.php(362): Magento\\\\Catalog\\\\Model\\\\Product->afterSave()\\n#15 \\/var\\/www\\/html\\/vendor\\/magento\\/framework\\/EntityManager\\/Observer\\/AfterEntitySave.php(34): Magento\\\\Catalog\\\\Model\\\\Product\\\\Interceptor->afterSave()\\n#16 \\/var\\/www\\/html\\/vendor\\/magento\\/framework\\/Event\\/Invoker\\/InvokerDefault.php(73): Magento\\\\Framework\\\\EntityManager\\\\Observer\\\\AfterEntitySave->execute(Object(Magento\\\\Framework\\\\Event\\\\Observer))\\n#17 \\/var\\/www\\/html\\/vendor\\/magento\\/framework\\/Event\\/Invoker\\/InvokerDefault.php(61): Magento\\\\Framework\\\\Event\\\\Invoker\\\\InvokerDefault->callObserverMethod(Object(Magento\\\\Framework\\\\EntityManager\\\\Observer\\\\AfterEntitySave), Object(Magento\\\\Framework\\\\Event\\\\Observer))\\n#18 \\/var\\/www\\/html\\/vendor\\/magento\\/module-staging\\/Model\\/Event\\/Manager.php(97): Magento\\\\Framework\\\\Event\\\\Invoker\\\\InvokerDefault->dispatch(Array, Object(Magento\\\\Framework\\\\Event\\\\Observer))\\n#19 \\/var\\/www\\/html\\/var\\/generation\\/Magento\\/Staging\\/Model\\/Event\\/Manager\\/Proxy.php(95): Magento\\\\Staging\\\\Model\\\\Event\\\\Manager->dispatch('magentocatalog...', Array)\\n#20 \\/var\\/www\\/html\\/vendor\\/magento\\/framework\\/EntityManager\\/EventManager.php(51): Magento\\\\Staging\\\\Model\\\\Event\\\\Manager\\\\Proxy->dispatch('magentocatalog...', Array)\\n#21 \\/var\\/www\\/html\\/vendor\\/magento\\/module-staging\\/Model\\/Operation\\/Create.php(138): Magento\\\\Framework\\\\EntityManager\\\\EventManager->dispatchEntityEvent('Magento\\\\\\\\Catalog...', 'saveafter', Array)\\n#22 \\/var\\/www\\/html\\/vendor\\/magento\\/framework\\/EntityManager\\/EntityManager.php(87): Magento\\\\Staging\\\\Model\\\\Operation\\\\Create->execute(Object(Magento\\\\Catalog\\\\Model\\\\Product\\\\Interceptor), Array)\\n#23 \\/var\\/www\\/html\\/vendor\\/magento\\/module-catalog\\/Model\\/ResourceModel\\/Product.php(695): Magento\\\\Framework\\\\EntityManager\\\\EntityManager->save(Object(Magento\\\\Catalog\\\\Model\\\\Product\\\\Interceptor))\\n#24 \\/var\\/www\\/html\\/vendor\\/magento\\/framework\\/Interception\\/Interceptor.php(74): Magento\\\\Catalog\\\\Model\\\\ResourceModel\\\\Product->save(Object(Magento\\\\Catalog\\\\Model\\\\Product\\\\Interceptor))\\n#25 \\/var\\/www\\/html\\/vendor\\/magento\\/framework\\/Interception\\/Chain\\/Chain.php(70): Magento\\\\Catalog\\\\Model\\\\ResourceModel\\\\Product\\\\Interceptor->callParent('save', Array)\\n#26 \\/var\\/www\\/html\\/vendor\\/magento\\/framework\\/Interception\\/Chain\\/Chain.php(63): Magento\\\\Framework\\\\Interception\\\\Chain\\\\Chain->invokeNext('Magento\\\\\\\\Catalog...', 'save', Object(Magento\\\\Catalog\\\\Model\\\\ResourceModel\\\\Product\\\\Interceptor), Array, 'catalogsearchFu...')\\n#27 \\/var\\/www\\/html\\/vendor\\/magento\\/module-catalog-search\\/Model\\/Indexer\\/Fulltext\\/Plugin\\/Product.php(51): Magento\\\\Framework\\\\Interception\\\\Chain\\\\Chain->Magento\\\\Framework\\\\Interception\\\\Chain\\\\{closure}(Object(Magento\\\\Catalog\\\\Model\\\\Product\\\\Interceptor))\\n#28 \\/var\\/www\\/html\\/vendor\\/magento\\/module-catalog-search\\/Model\\/Indexer\\/Fulltext\\/Plugin\\/Product.php(24): Magento\\\\CatalogSearch\\\\Model\\\\Indexer\\\\Fulltext\\\\Plugin\\\\Product->addCommitCallback(Object(Magento\\\\Catalog\\\\Model\\\\ResourceModel\\\\Product\\\\Interceptor), Object(Closure), Object(Magento\\\\Catalog\\\\Model\\\\Product\\\\Interceptor))\\n#29 \\/var\\/www\\/html\\/vendor\\/magento\\/framework\\/Interception\\/Chain\\/Chain.php(67): Magento\\\\CatalogSearch\\\\Model\\\\Indexer\\\\Fulltext\\\\Plugin\\\\Product->aroundSave(Object(Magento\\\\Catalog\\\\Model\\\\ResourceModel\\\\Product\\\\Interceptor), Object(Closure), Object(Magento\\\\Catalog\\\\Model\\\\Product\\\\Interceptor))\\n#30 \\/var\\/www\\/html\\/vendor\\/magento\\/framework\\/Interception\\/Interceptor.php(138): Magento\\\\Framework\\\\Interception\\\\Chain\\\\Chain->invokeNext('Magento\\\\\\\\Catalog...', 'save', Object(Magento\\\\Catalog\\\\Model\\\\ResourceModel\\\\Product\\\\Interceptor), Array, 'cleancache')\\n#31 \\/var\\/www\\/html\\/vendor\\/magento\\/framework\\/App\\/Cache\\/FlushCacheByTags.php(71): Magento\\\\Catalog\\\\Model\\\\ResourceModel\\\\Product\\\\Interceptor->Magento\\\\Framework\\\\Interception\\\\{closure}(Object(Magento\\\\Catalog\\\\Model\\\\Product\\\\Interceptor))\\n#32 \\/var\\/www\\/html\\/vendor\\/magento\\/framework\\/Interception\\/Interceptor.php(142): Magento\\\\Framework\\\\App\\\\Cache\\\\FlushCacheByTags->aroundSave(Object(Magento\\\\Catalog\\\\Model\\\\ResourceModel\\\\Product\\\\Interceptor), Object(Closure), Object(Magento\\\\Catalog\\\\Model\\\\Product\\\\Interceptor))\\n#33 \\/var\\/www\\/html\\/var\\/generation\\/Magento\\/Catalog\\/Model\\/ResourceModel\\/Product\\/Interceptor.php(273): Magento\\\\Catalog\\\\Model\\\\ResourceModel\\\\Product\\\\Interceptor->callPlugins('save', Array, Array)\\n#34 \\/var\\/www\\/html\\/vendor\\/magento\\/module-catalog\\/Model\\/ProductRepository.php(538): Magento\\\\Catalog\\\\Model\\\\ResourceModel\\\\Product\\\\Interceptor->save(Object(Magento\\\\Catalog\\\\Model\\\\Product\\\\Interceptor))\\n#35 \\/var\\/www\\/html\\/vendor\\/magento\\/framework\\/Interception\\/Interceptor.php(74): Magento\\\\Catalog\\\\Model\\\\ProductRepository->save(Object(Magento\\\\Catalog\\\\Model\\\\Product\\\\Interceptor), false)\\n#36 \\/var\\/www\\/html\\/vendor\\/magento\\/framework\\/Interception\\/Chain\\/Chain.php(70): Magento\\\\Catalog\\\\Model\\\\ProductRepository\\\\Interceptor->callParent('save', Array)\\n#37 \\/var\\/www\\/html\\/vendor\\/magento\\/framework\\/Interception\\/Chain\\/Chain.php(63): Magento\\\\Framework\\\\Interception\\\\Chain\\\\Chain->invokeNext('Magento\\\\\\\\Catalog...', 'save', Object(Magento\\\\Catalog\\\\Model\\\\ProductRepository\\\\Interceptor), Array, 'configurablePro...')\\n#38 \\/var\\/www\\/html\\/vendor\\/magento\\/module-configurable-product\\/Model\\/Plugin\\/AroundProductRepositorySave.php(62): Magento\\\\Framework\\\\Interception\\\\Chain\\\\Chain->Magento\\\\Framework\\\\Interception\\\\Chain\\\\{closure}(Object(Magento\\\\Catalog\\\\Model\\\\Product\\\\Interceptor), false)\\n#39 \\/var\\/www\\/html\\/vendor\\/magento\\/framework\\/Interception\\/Chain\\/Chain.php(67): Magento\\\\ConfigurableProduct\\\\Model\\\\Plugin\\\\AroundProductRepositorySave->aroundSave(Object(Magento\\\\Catalog\\\\Model\\\\ProductRepository\\\\Interceptor), Object(Closure), Object(Magento\\\\Catalog\\\\Model\\\\Product\\\\Interceptor), false)\\n#40 \\/var\\/www\\/html\\/vendor\\/magento\\/framework\\/Interception\\/Interceptor.php(138): Magento\\\\Framework\\\\Interception\\\\Chain\\\\Chain->invokeNext('Magento\\\\\\\\Catalog...', 'save', Object(Magento\\\\Catalog\\\\Model\\\\ProductRepository\\\\Interceptor), Array, 'catalogInventor...')\\n#41 \\/var\\/www\\/html\\/vendor\\/magento\\/module-catalog-inventory\\/Model\\/Plugin\\/AroundProductRepositorySave.php(74): Magento\\\\Catalog\\\\Model\\\\ProductRepository\\\\Interceptor->Magento\\\\Framework\\\\Interception\\\\{closure}(Object(Magento\\\\Catalog\\\\Model\\\\Product\\\\Interceptor), false)\\n#42 \\/var\\/www\\/html\\/vendor\\/magento\\/framework\\/Interception\\/Interceptor.php(142): Magento\\\\CatalogInventory\\\\Model\\\\Plugin\\\\AroundProductRepositorySave->aroundSave(Object(Magento\\\\Catalog\\\\Model\\\\ProductRepository\\\\Interceptor), Object(Closure), Object(Magento\\\\Catalog\\\\Model\\\\Product\\\\Interceptor), false)\\n#43 \\/var\\/www\\/html\\/var\\/generation\\/Magento\\/Catalog\\/Model\\/ProductRepository\\/Interceptor.php(52): Magento\\\\Catalog\\\\Model\\\\ProductRepository\\\\Interceptor->callPlugins('save', Array, Array)\\n#44 [internal function]: Magento\\\\Catalog\\\\Model\\\\ProductRepository\\\\Interceptor->save(Object(Magento\\\\Catalog\\\\Model\\\\Product\\\\Interceptor), false)\\n#45 \\/var\\/www\\/html\\/vendor\\/magento\\/module-webapi\\/Controller\\/Rest.php(307): calluserfuncarray(Array, Array)\\n#46 \\/var\\/www\\/html\\/vendor\\/magento\\/module-webapi\\/Controller\\/Rest.php(216): Magento\\\\Webapi\\\\Controller\\\\Rest->processApiRequest()\\n#47 \\/var\\/www\\/html\\/vendor\\/magento\\/framework\\/Interception\\/Interceptor.php(146): Magento\\\\Webapi\\\\Controller\\\\Rest->dispatch(Object(Magento\\\\Framework\\\\App\\\\Request\\\\Http))\\n#48 \\/var\\/www\\/html\\/var\\/generation\\/Magento\\/Webapi\\/Controller\\/Rest\\/Interceptor.php(39): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\Interceptor->callPlugins('dispatch', Array, Array)\\n#49 \\/var\\/www\\/html\\/vendor\\/magento\\/framework\\/App\\/Http.php(135): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\Interceptor->dispatch(Object(Magento\\\\Framework\\\\App\\\\Request\\\\Http))\\n#50 \\/var\\/www\\/html\\/vendor\\/magento\\/framework\\/App\\/Bootstrap.php(258): Magento\\\\Framework\\\\App\\\\Http->launch()\\n#51 \\/var\\/www\\/html\\/pub\\/index.php(37): Magento\\\\Framework\\\\App\\\\Bootstrap->run(Object(Magento\\\\Framework\\\\App\\\\Http))\\n#52 {main}\"}\r\n```\r\n\r\n<!--- (This may be platform independent comment) -->\r\n"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\r\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\r\n\r\n### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1.  Install Magento 2.1.3 with sample data.\r\n2. Set up Rest integration.\r\n\r\n### Steps to reproduce\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1. Try to update an attribute set from /V1/products/attribute-sets/{attributeSetId} with a PUT request, inserting in the body ONLY the not-optional parameters (as explained in the documentation).\r\n```\r\n{\r\n\"attributeset\": {\r\n\"attributesetname\":\"Updated Name\",\r\n\"sortorder\":0 }\r\n}\r\n```\r\nand with an existing attribute set id as url parameter\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. The attribute set with given attribute set id gets updated with the new name\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. It doesn't get updated and magento answer with \r\n`{\"message\":\"Provided Attribute set non product Attribute set.\"}`\r\n\r\n### Why\r\n1. Field entitytypeid is NOT optional in the PUT request, differently from what the documentation says.\r\n2. If field attributesetid is only in the url parameter and NOT in the body, instead of updating the attribute set, a new attribute set with the given fields is created.\r\n3. Only if both fields attributesetid and entitytypeid are given in the body, the request is succesful and the attribute set with the given id in the url parameter is updated.\r\n\r\n<!--- (This may be platform independent comment) -->\r\n"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\r\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\r\n\r\n### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1. Install Magento 2.1.3 with sample data.\r\n2. Set up Rest integration.\r\n\r\n### Steps to reproduce\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1. Try to create a product custom option, sending a REST request to post /V1/products/options with Method POST correctly, adding a custom option to a product. As store view, tried to both use all and default.\r\nLike this:\r\n```\r\n{\r\n\"option\": {\r\n   productsku = \"producttestsku\",\r\n   isrequire = true,\r\n   title = \"Option just to test\",\r\n   type = \"area\",\r\n   sortorder = 0,\r\n   price = 100,\r\n   pricetype = \"fixed\",\r\n   sku = \"testsku\"\r\n   }\r\n}\r\n```\r\n2. Receive the correct answer, meaning that the option is created in the product. Check on the web interface from the admin view that the option is there with all the correct values and everything seems correct, the option was correctly created and added to the right product.\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. The new custom option should be visible on frontend when searching the product, available to be used.\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. The new custom option doesn't appear on the frontend, even if it's visible on the the web backend. It doesn't appear on web frontend UNTIL the product is saved from the web interface. Saving the product on web interface as admin immediately make the not-visible option appear on frontend, exactly as it was saved by the rest api.\r\n\r\n### Notes\r\nIt's probably a problem of indexing on custom options with Rest api, doesn't automatically reindex when they modify or delete or create custom options?\r\nBecause Products are automatically modified when updated from rest api, so I expected the same behaviour for custom options also.\r\n<!--- (This may be platform independent comment) -->\r\n"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\r\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\r\n\r\n### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1. Install Magento 2.1.3 with sample data.\r\n2. Set up Rest integration.\r\n\r\n### Steps to reproduce\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1. Retrieve stockitem list of low stock items sending a Rest request to /V1/stockItems/lowStock/ with method GET, query parameters scopeid and qty as specified in the documentation. Rest request like this: `rest/default/V1/stockItems/lowStock/?scopeId=0&qty=10`.\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. As for all other Rest methods available that returns a list taking filter parameters and as the documentation specify, if no pagesize is given, all results of the query should be returned.\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. Only one stock item is returned, in addition, searchcriteria has a different structure from other methods, with a limit field that is automatically set like this:\r\n```\r\n\"limit\": [\r\n      \"1\",\r\n      \"0\"\r\n    ]\r\n```\r\n\r\n### Notes\r\nEither changing the documentation (fast solution) or even better, uniforming this method with all the other available methods, making it accept a filter and not only page filter parameters (pagesize and currentpage).\r\n\r\n<!--- (This may be platform independent comment) -->\r\n### Additional info\r\n- Reproducible on Magento 2.4-develop\r\n- The way it can be reproduced via Swagger \r\n1. In your web browser open http://{magento2 instanse}/swagger#/integrationAdminTokenServiceV1/integrationAdminTokenServiceV1CreateAdminAccessTokenPost click **Try it out**\r\n![tryitout](https://user-images.githubusercontent.com/51680745/71408582-6eb34f80-2647-11ea-96ab-7b60f58cd983.png)\r\n2. Set admin User name and Passwod and click Execute \r\n3. Copy the token from the Response body \r\n![token](https://user-images.githubusercontent.com/51680745/71408693-c6ea5180-2647-11ea-8cbc-11c279d23c31.png)\r\nand Paste it into apikey field in the top right corner. Click Apply\r\n![apikey](https://user-images.githubusercontent.com/51680745/71408814-25afcb00-2648-11ea-8b20-f038b3d60e7f.png)\r\n4. Open catalogInventoryStockRegistryV1  - GET /V1/stockItemslowStock clcik Try in out\r\n![low stockcatalog](https://user-images.githubusercontent.com/51680745/71409005-bc7c8780-2648-11ea-85e1-d0cbe96ca65c.png)\r\n5. Set scopeId to **0** qty to **10**. Click Execute\r\n![scopeqty](https://user-images.githubusercontent.com/51680745/71409143-2bf27700-2649-11ea-8bdf-f91a1a766056.png)\r\n\r\nActual Result: \r\n![limit](https://user-images.githubusercontent.com/51680745/71409257-96a3b280-2649-11ea-9d33-f1f04d0f2aad.png)\r\n\r\n"},
{"text": "### Preconditions\r\n1. Mag CE 2.1.3\r\n2. MySQL 5.7.11\r\n3. PHP 5.6.19\r\n\r\n### Steps to reproduce\r\n1. VS2015 C#. \r\n2. Use WSDL to add service reference for salesOrderManagementV1.\r\n3. Use WSDL to add service reference for salesOrderRepositoryV1.\r\n4. Get sales order for an incrementid with salesOrderRepositoryV1GetList() into SalesOrderRepositoryV1GetListResponse.\r\n5. Get sales order comments for an order using salesOrderManagementV1GetCommentsList.items[0].entityId passed to salesOrderManagementV1GetCommentsList() into SalesOrderManagementV1GetCommentsListResponse.\r\n6. Create new SalesOrderManagementV1AddCommentRequest.\r\n7. Create new SalesOrderManagementV1AddCommentRequest.SalesDataOrderStatusHistoryInterface.\r\n8. set statusHistory.comment = \"new comment from api\".\r\n9. set statusHistory.parentId = SalesOrderRepositoryV1GetListResponse.result.items[0].incremented.\r\n10. set statusHistory.isVisibleOnFront = 1.\r\n11. statusHistory.status = SalesOrderRepositoryV1GetListResponse.result.items[0].status.\r\n12. set SalesOrderManagementV1AddCommentRequest.id=0 or SalesOrderManagementV1AddCommentRequest.id=-1.\r\n13. call salesOrderManagementV1AddComment(SalesOrderManagementV1AddCommentRequest).\r\nGet error id required. Should get new comment added to sales order.\r\n14. set SalesOrderManagementV1AddCommentRequest.id=SalesOrderManagementV1GetCommentsListResponse.result.items[0].entityID.\r\n15) call salesOrderManagementV1AddComment(SalesOrderManagementV1AddCommentRequest).\r\nGet SalesOrderManagementV1AddCommentResponse.result true. But existing comment has not been set to \"new comment from api\".\r\n### Expected result\r\n1. When passing an existing SalesDataOrderStatusHistoryInterface.entityId to SalesOrderManagementV1AddCommentRequest.id we should see that order comment changed to SalesDataOrderStatusHistoryInterface.comment value.\r\n2. When passing zero or -1 to SalesDataOrderStatusHistoryInterface.entityId we should see a new comment added to the order.\r\n\r\n### Actual result\r\n1. Nothing happens, order comments remain unaltered.\r\n\r\n### C# code:\r\n        private void SaveV2SoapOrderComment()\r\n        {\r\n            MagV2SoapService.MagV2SoapsalesOrderManagementV1.SalesOrderManagementV1AddCommentResponse Res = new MagV2SoapService.MagV2SoapsalesOrderManagementV1.SalesOrderManagementV1AddCommentResponse();\r\n            try\r\n            {\r\n                System.Diagnostics.Stopwatch sw1 = new System.Diagnostics.Stopwatch();\r\n                sw1.Start();\r\n                MagV2SoapService.MagV2SoapsalesOrderRepositoryV1.SalesOrderRepositoryV1GetListResponse orderRes=GetV2SoapOrders(\"000000019\");   //(\"000000020\")\r\n                MagV2SoapService.MagV2SoapsalesOrderManagementV1.SalesOrderManagementV1GetCommentsListRequest ReqList = new MagV2SoapService.MagV2SoapsalesOrderManagementV1.SalesOrderManagementV1GetCommentsListRequest();\r\n                MagV2SoapService.MagV2SoapsalesOrderManagementV1.SalesOrderManagementV1GetCommentsListResponse ResList = new MagV2SoapService.MagV2SoapsalesOrderManagementV1.SalesOrderManagementV1GetCommentsListResponse();\r\n                ReqList.id = orderRes.result.items[0].entityId;    \r\n                ResList = MagV2SoapService.MagentoSOAP.OrderManagement.salesOrderManagementV1GetCommentsList(ReqList);\r\n\r\n                MagV2SoapService.MagV2SoapsalesOrderManagementV1.SalesOrderManagementV1AddCommentRequest Req = new MagV2SoapService.MagV2SoapsalesOrderManagementV1.SalesOrderManagementV1AddCommentRequest();\r\n                Req.statusHistory = new MagV2SoapService.MagV2SoapsalesOrderManagementV1.SalesDataOrderStatusHistoryInterface();\r\n                Req.statusHistory.comment = \"new comment from magtest\";\r\n                Req.statusHistory.parentId = Convert.ToInt32(orderRes.result.items[0].incrementId);\r\n                //Req.statusHistory.entityId = Convert.ToInt32(orderRes.result.items[0].entityId);\r\n                //Req.statusHistory.entityIdSpecified = true;\r\n                Req.statusHistory.isVisibleOnFront = 1;\r\n                Req.statusHistory.status = orderRes.result.items[0].status;\r\n                //Req.id = 0;  \r\n                Req.id = ResList.result.items[ResList.result.items.Length-1].entityId;\r\n                Res = MagV2SoapService.MagentoSOAP.OrderManagement.salesOrderManagementV1AddComment(Req);\r\n                \r\n                sw1.Stop();\r\n                \r\n                lblResult.Text += String.Format(\"V2 Soap saved order comment result {0} in {1} hours {2} minutes {3} seconds\\r\\n\", Res.result, sw1.Elapsed.Hours, sw1.Elapsed.Minutes, sw1.Elapsed.Seconds);\r\n            }\r\n            catch (Exception ex)\r\n            {\r\n                ShowError(\"V2 Soap save saved order comment\", ex);\r\n            }\r\n        }\r\n\r\n"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\r\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\r\nCalling GET on catalogProductAttributeRepository does not return frontend-labels\r\n\r\n### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1. Magento EE 2.1.2\r\n2. PHP 7.0.14 (dotdeb: 7.0.14-1~dotdeb+8.1)\r\n3. Mysql 5.6.30 (Debian-Jessie-backports: 5.6.30-1~bpo8+1)\r\n\r\n### Steps to reproduce\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1. I have a product-attribute with the code \"testapi\", with frontend-labels, see backend-screenshot\r\n2. `curl -X GET --header \"Accept: application/json\" --header \"Authorization: Bearer <API-Token>\" \"https://<myserver>/rest/V1/products/attributes/testapi\"`\r\n![image](https://cloud.githubusercontent.com/assets/24474289/22207049/ec22a22a-e17d-11e6-98b8-e16aa26956a0.png)\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\nreturn json with `\"frontendlabels\": [{\"storeid\": 1, \"label\": \"Test 3 \u00fcber API\"},{\"storeid\":2,\"label\":\"testing with API\"}]`\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n```json\r\n{\"iswysiwygenabled\":false,\"ishtmlallowedonfront\":false,\"usedforsortby\":false,\"isfilterable\":false,\"isfilterableinsearch\":false,\"isusedingrid\":false,\"isvisibleingrid\":false,\"isfilterableingrid\":false,\"position\":0,\"applyto\":[],\"issearchable\":\"0\",\"isvisibleinadvancedsearch\":\"0\",\"iscomparable\":\"0\",\"isusedforpromorules\":\"0\",\"isvisibleonfront\":\"0\",\"usedinproductlisting\":\"0\",\"isvisible\":true,\"scope\":\"global\",\"attributeid\":179,\"attributecode\":\"testapi\",\"frontendinput\":\"text\",\"entitytypeid\":\"4\",\"isrequired\":false,\"options\":[],\"isuserdefined\":true,\"defaultfrontendlabel\":\"Test \\u00fcber API\",\"frontendlabels\":null,\"backendtype\":\"varchar\",\"isunique\":\"0\",\"validationrules\":[]}\r\n```\r\n(note the `\"frontendlabels\":null,`)\r\n\r\n<!--- (This may be platform independent comment) -->\r\n"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\r\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\r\n\r\n### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1. Magento 2.1.3, PHP 5.6\r\n2. \r\n\r\n### Steps to reproduce\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1. Generate JAVA libs with swagger CLI\r\n2. Get product by sku (using generated client with method: \"catalogProductRepositoryV1GetGet\")\r\n3. \r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. \r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. [Screenshot, logs]\r\njava.lang.IllegalStateException: Expected a string but was BEGINARRAY at line 1 column 2614 path $.customattributes[8].value\r\n\tat com.google.gson.internal.bind.ReflectiveTypeAdapterFactory\r\n\r\n<!--- (This may be platform independent comment) -->\r\nI've temporary solved changing originaly created classes with:\r\ninstead using \"CatalogDataProductExtensionInterface\", used \"Object\" and\r\n\r\nSame issue was with class:\r\nFrameworkAttributeInterface\r\nso i've changed:\r\nfield \"value\" (String) to \"value\" Object. \r\nProblem is, when I've retreive data expected result is not the same like generated classes:\r\nResult give Array instead of Object of CatalogDataProductExtensionInterface.\r\nI understand it can be some differences with client but NOT data types\r\n\r\n\r\n"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\r\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\r\n\r\n### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1. Magento 2.1.3 PHP 5.6\r\n2. \r\n\r\n### Steps to reproduce\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1. put attribute value {\"saleprice\", \"\"}\r\n2. retreive product data\r\n3. result : {\"saleprice\", \"0.0000\"}\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. I need empty value\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. [Screenshot, logs]\r\n\r\n<!--- (This may be platform independent comment) -->\r\nI've solved temporary using \"saleendtime\" to day before today\r\nIMPORTANT! If value of \"saleprice\" is \"0\", price on fronted is \"0\" - very bad"},
{"text": "### Preconditions\r\n1.  Magento 2.1.3\r\n2. PHP 7.0.15\r\n\r\n### Steps to reproduce\r\n1. Add a product through the API including a specialprice (via customattributes)\r\n2. Try to empty the value by giving an empty string, the value null or 0\r\n3. None of the above methods work\r\n\r\n### Expected result\r\n1. The value should be emptied just like you can via the back-end\r\n\r\n### Actual result\r\n1. If you pass NULL allong the custom attribute processor will throw an error no value is set\r\n2. If you pass 0 the special price attribute will be set to 0 which will result in free products\r\n3. If you pass \"\" (an empty string) the value will be casted to a double or float and will also be 0 which will also result in free products\r\n\r\n### Comment\r\nI don't think this is only an issue with special price, since it can be a problem in every numeric type. \r\n\r\nI resolved the issue myself (temporary) via a plugin for \"Magento\\Framework\\Webapi\\ServiceInputProcessor\" on the \"convertValue\" method. Here I check if the type is Simple via the typeProcessor and if the value is an empty string, if it is I don't cast it to another type. This solved my issue with the special price.\r\n"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\r\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\r\n\r\n### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1. Any Magento2 version.\r\n2. Functional REST API.\r\n\r\n### Steps to reproduce\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1. Retrieve product via REST API, eg.: GET http://magento.dev:9080/rest/V1/products/MT07\r\n2. Check updatedat field.\r\n3. Delete, add or change an image (even just changing the base image)\r\n4. Retrieve the same product via REST API, eg.: GET http://magento.dev:9080/rest/V1/products/MT07\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. Database (and REST API) field updatedat should be set to the date of the change, as the product changed.\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. The change date is not stored with the product; an external API has no way to detect the image is different other than storing image urls and comparing them.\r\n\r\n<!--- (This may be platform independent comment) -->\r\n"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\r\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\r\n\r\n### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1. Install Magento 2.1.3 with sample data.\r\n2. Set up Rest integration.\r\n\r\n### Steps to reproduce\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1. Create a Product using Rest API POST request at `/V1/products`. The product has a custom option, correctly set and the custom attributes `requiredoptions` and `hasoptions` value set to `\"1\"`. Like this example:\r\n```\r\n{\r\n\"product\":{\r\n\"id\":0,\r\n\"sku\":\"testproduct\",\r\n\"visibility\":4,\r\n\"status\":1,\r\n\"name\":\"A test product for custom options\",\r\n\"price\":\"7.35\",\r\n\"typeid\":\"simple\",\r\n\"attributesetid\":4,\r\n\"extensionattributes\":{\r\n\"stockitem\":{\r\n\"qty\":\"1\",\r\n\"itemid\":null,\r\n\"productid\":null,\r\n\"stockid\":null,\r\n\"isinstock\":true,\r\n\"managestock\":false\r\n}\r\n},\r\n\"customattributes\":[\r\n{\"attributecode\":\"cost\",\r\n\"value\":\"7,3500\"},\r\n{\"attributecode\":\"categoryids\",\r\n\"value\":[\"6\",\"53\",\"6\"]},\r\n{\"attributecode\":\"optionscontainer\",\r\n\"value\":\"container2\"},\r\n{\"attributecode\":\"hasoptions\",\r\n\"value\":\"1\"},\r\n{\"attributecode\":\"requiredoptions\",\r\n\"value\":\"1\"}\r\n],\r\n\"options\":[\r\n{\r\n\"productsku\":\"testproduct\",\r\n\"optionid\":0,\r\n\"title\":\"Scelta\",\r\n\"type\":\"checkbox\",\r\n\"sortorder\":null,\r\n\"isrequire\":true,\r\n\"pricetype\":null,\r\n\"values\":[\r\n{\r\n\"title\":\"A3\",\r\n\"sortorder\":1,\r\n\"price\":7.35,\r\n\"pricetype\":\"fixed\",\r\n\"sku\":\"A3\"\r\n},\r\n{\r\n\"title\":\"A4\",\r\n\"sortorder\":1,\r\n\"price\":9.45,\r\n\"pricetype\":\"fixed\",\r\n\"sku\":\"A4\"\r\n}\r\n]}\r\n]\r\n},\r\n\"saveOptions\":true\r\n}\r\n```\r\n2. Get as response for the Rest method called a succesfull response, containing the product created. Checking the frontend or backend, the product is correctly created. The response, for the example could be like this:\r\n```\r\n{\r\n\"id\":87,\r\n\"sku\":\"testproduct\",\r\n\"name\":\"A test product for custom options\",\r\n\"attributesetid\":4,\r\n\"price\":7.35,\r\n\"status\":1,\r\n\"visibility\":4,\r\n\"typeid\":\"simple\",\r\n\"createdat\":\"2017-01-31 10:28:02\",\r\n\"updatedat\":\"2017-01-31 10:28:02\",\r\n\"extensionattributes\":{\r\n\"stockitem\":{\r\n\"itemid\":82,\r\n\"productid\":87,\r\n\"stockid\":1,\r\n\"qty\":1,\r\n\"isinstock\":true,\r\n\"isqtydecimal\":false,\r\n\"showdefaultnotificationmessage\":false,\r\n\"useconfigminqty\":true,\r\n\"minqty\":0,\r\n\"useconfigminsaleqty\":1,\r\n\"minsaleqty\":1,\r\n\"useconfigmaxsaleqty\":true,\r\n\"maxsaleqty\":10000,\r\n\"useconfigbackorders\":true,\r\n\"backorders\":0,\r\n\"useconfignotifystockqty\":true,\r\n\"notifystockqty\":1,\r\n\"useconfigqtyincrements\":true,\r\n\"qtyincrements\":0,\r\n\"useconfigenableqtyinc\":true,\r\n\"enableqtyincrements\":false,\r\n\"useconfigmanagestock\":true,\r\n\"managestock\":true,\r\n\"lowstockdate\":null,\r\n\"isdecimaldivided\":false,\r\n\"stockstatuschangedauto\":0\r\n}\r\n},\r\n\"productlinks\":[],\r\n\"options\":[\r\n{\r\n\"productsku\":\"testproduct\",\r\n\"optionid\":201,\r\n\"title\":\"Scelta\",\r\n\"type\":\"checkbox\",\r\n\"sortorder\":0,\r\n\"isrequire\":true,\r\n\"values\":[\r\n{\r\n\"title\":\"A3\",\r\n\"sortorder\":1,\r\n\"price\":7.35,\r\n\"pricetype\":\"fixed\",\r\n\"sku\":\"A3\",\r\n\"optiontypeid\":578\r\n},\r\n{\r\n\"title\":\"A4\",\r\n\"sortorder\":1,\r\n\"price\":9.45,\r\n\"pricetype\":\"fixed\",\r\n\"sku\":\"A4\",\r\n\"optiontypeid\":579\r\n}\r\n]\r\n}\r\n],\r\n\"mediagalleryentries\":[],\r\n\"tierprices\":[],\r\n\"customattributes\":[\r\n{\r\n\"attributecode\":\"cost\",\r\n\"value\":\"7.0000\"\r\n},\r\n{\r\n\"attributecode\":\"categoryids\",\r\n\"value\":[\"6\",\"53\"]\r\n},\r\n{\r\n\"attributecode\":\"optionscontainer\",\r\n\"value\":\"container2\"\r\n},\r\n{\r\n\"attributecode\":\"requiredoptions\",\r\n\"value\":\"1\"\r\n},\r\n{\r\n\"attributecode\":\"hasoptions\",\r\n\"value\":\"1\"\r\n},\r\n{\r\n\"attributecode\":\"urlkey\",\r\n\"value\":\"carta-fotocopie-disco\"\r\n},\r\n{\r\n\"attributecode\":\"taxclassid\",\r\n\"value\":\"2\"\r\n}\r\n]\r\n}\r\n```\r\n3. Ask the same product with a GET Rest API request at `/V1/products/{sku}`\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. The given product, I mean the answer of the POST request of which I gave an example, should be the product really created on Magento and should be the same answered from the GET request. Custom options should be visible on frontend.\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. Custom options aren't visible on frontend. Asking the product with a GET Rest API request to `/V1/products/{sku}` gives a different answer from the response of the POST method. For example, something like this:\r\n```\r\n{\r\n\"id\":87,\r\n\"sku\":\"testproduct\",\r\n\"name\":\"A test product for custom options\",\r\n\"attributesetid\":4,\r\n\"price\":7.35,\r\n\"status\":1,\r\n\"visibility\":4,\r\n\"typeid\":\"simple\",\r\n\"createdat\":\"2017-01-31 10:28:02\",\r\n\"updatedat\":\"2017-01-31 10:30:28\",\r\n\"extensionattributes\":{\r\n\"stockitem\":{\r\n\"itemid\":82,\r\n\"productid\":87,\r\n\"stockid\":1,\r\n\"qty\":1,\r\n\"isinstock\":true,\r\n\"isqtydecimal\":false,\r\n\"showdefaultnotificationmessage\":false,\r\n\"useconfigminqty\":true,\r\n\"minqty\":0,\r\n\"useconfigminsaleqty\":1,\r\n\"minsaleqty\":1,\r\n\"useconfigmaxsaleqty\":true,\r\n\"maxsaleqty\":10000,\r\n\"useconfigbackorders\":true,\r\n\"backorders\":0,\r\n\"useconfignotifystockqty\":true,\r\n\"notifystockqty\":1,\r\n\"useconfigqtyincrements\":true,\r\n\"qtyincrements\":0,\r\n\"useconfigenableqtyinc\":true,\r\n\"enableqtyincrements\":false,\r\n\"useconfigmanagestock\":true,\r\n\"managestock\":true,\r\n\"lowstockdate\":null,\r\n\"isdecimaldivided\":false,\r\n\"stockstatuschangedauto\":0\r\n}},\r\n\"productlinks\":[],\r\n\"options\":[\r\n{\r\n\"productsku\":\"testproduct\",\r\n\"optionid\":202,\r\n\"title\":\"Scelta\",\r\n\"type\":\"checkbox\",\r\n\"sortorder\":0,\r\n\"isrequire\":true,\r\n\"values\":[\r\n{\r\n\"title\":\"A3\",\r\n\"sortorder\":1,\r\n\"price\":7.35,\r\n\"pricetype\":\"fixed\",\r\n\"sku\":\"A3\",\r\n\"optiontypeid\":580\r\n},\r\n{\r\n\"title\":\"A4\",\r\n\"sortorder\":1,\r\n\"price\":9.45,\r\n\"pricetype\":\"fixed\",\r\n\"sku\":\"A4\",\r\n\"optiontypeid\":581\r\n}]\r\n}],\r\n\"mediagalleryentries\":[],\r\n\"tierprices\":[],\r\n\"customattributes\":[\r\n{\r\n\"attributecode\":\"cost\",\r\n\"value\":\"7.0000\"\r\n},\r\n{\r\n\"attributecode\":\"categoryids\",\r\n\"value\":[\"6\",\"53\"]\r\n},\r\n{\r\n\"attributecode\":\"optionscontainer\",\r\n\"value\":\"container2\"\r\n},\r\n{\r\n\"attributecode\":\"requiredoptions\",\r\n\"value\":\"0\"\r\n},\r\n{\r\n\"attributecode\":\"hasoptions\",\r\n\"value\":\"0\"\r\n},\r\n{\r\n\"attributecode\":\"urlkey\",\r\n\"value\":\"carta-fotocopie-disco\"\r\n},\r\n{\r\n\"attributecode\":\"taxclassid\",\r\n\"value\":\"2\"\r\n}]\r\n}\r\n```\r\nFirst of all, some optionsids are different from before, I read that option ids had an issue and the ids changed at every update of the product, but this seems like the ids change even on GET requests?\r\n\r\nSecond and most important, custom attributes of the product, `hasoptions` and `requiredoptions` both now are set at `\"0\"`, meaning that the custom options doesn't appear on frontend until this is changed. Interestingly enough, asking an update of the product with a PUT Rest API request at `/V1/products/{sku}` and sending exactly the same body of the POST request asked before, set the custom attributes correctly and the product custom options are finally visible on frontend.\r\nSaving the product from web interface as admin without changing anything has the same effect, probably setting correctly the custom attributes.\r\n\r\n<!--- (This may be platform independent comment) -->\r\n"},
{"text": "I am getting 500 internal server error when I am posting wrong parameter in API request. I was trying to create customer through API while posting customer data, I posted groupid instead of groupid and that shows me 500 internal server error.\r\n\r\n**Preconditions**\r\n    Magento 2.1.0 CE (or above)\r\n\r\n**Steps to reproduce**\r\n\r\n1. Open magentositeurl/swagger  documentation (http://demo.cedcommerce.com/magento2/marketplace/swagger)\r\n2. Open tab customerAccountManagementV1 ->Post /V1/customers to create account\r\n3. Post customer data to create customer account with all correct information, instead of passing groupid pass groupid (we can try with any other parameters too).\r\n4. Click on Try it Out! button\r\n\r\n **Result** \r\n{\r\n  \"message\": \"Internal Error. Details are available in Magento log file. Report ID: webapi-588f3c623a140\"\r\n}\r\n\r\n **Expected Result** \r\n\r\nYou had passed invalid parameters in your request, groupid doesn't exist in the request parameters. (Something like this)\r\n\r\n\r\nAs i had the access of server so i got my error but there is no process in magento to handle this error and show a correct/useful message, so that API user will be able to get what exact error they made in their API request. #\r\n![1](https://cloud.githubusercontent.com/assets/11978282/22454743/370eb306-e7ae-11e6-9b27-2cddc2d4025d.png)\r\n![2](https://cloud.githubusercontent.com/assets/11978282/22454746/3c9408ee-e7ae-11e6-8a62-8d32e5234a97.png)\r\n\r\n\r\n"},
{"text": "### Precondtions\r\n 1.  Mag CE 2.1.3\r\n 2. MySQL 5.7.11\r\n 3. PHP 5.6.19\r\n\r\n### Steps to reproduce\r\n1.VS2015 C#.\r\n2. Note for \"customers/me\" and all other API calls Swagger doc for BadRequest response has parameters as an array.\r\n3. Force an error by setting Request to \"....customers/me x...\" and call api.\r\n3. Response content for parameters returned is not an array.\r\n\r\n### Expected result\r\n1. Response content should be:\r\n\"{\"message\":\"%fieldName is a required field.\",\"parameters\":[{\"fieldName\":\"customer\"}],\"trace\":......}\"\r\n\r\n\r\n### Actual result\r\n1. Actual Response content is:\r\n\"{\"message\":\"%fieldName is a required field.\",\"parameters\":{\"fieldName\":\"customer\"},\"trace\":......}\"\r\n2. When deserialised into a c# class we therefore get an empty parameters array, unless we edit the response content.\r\n\r\n"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\r\nSummary:\r\nWorking with simple products and configurable products with API calls, we have detected that PUT method on simple products for update only one or some fields work (not sending all fields by json), this work good. But when try update with PUT method on configurable product, if we send only one of some fields, the return sometimes crash or lost data.  \r\nFor example: If we need only change name and update status, on simple product we can send only these two fields into json, but if we need update configurable product, have to send complete jason including all attribution options and product links, if not, we lost child products and attribute options.\r\n\r\n\r\n\r\n### Preconditions\r\nMagento 2\r\nVersion: 2.1.x (tested on 2.1.1 and 2.1.3)\r\nEC2 Instance of AWS Amazon with CentOS\r\nPHP v7.0.10\r\nMysql 5.6\r\nAlso was tested on local environment with Vagrant with CentOS.\r\n\r\n### Steps to reproduce\r\n1. Using the Luma demo with a T-shirt products, create on admin panel one configurable product, with combination of 2 colors and 3 sizes, then you will get a configurable product with 6 product childs.\r\n2. Make a PUT product API call where try update only status or name, for update only one or two fields into configurable product, for example:\r\n```\r\ncurl -X PUT -H \"Content-Type: application/json\" -H \"Authorization: Bearer cl6v1mlxnmr4b3mgvx6936lva7nme4pu\" -H \"Cache-Control: no-cache\" -d '{  \r\n   \"product\":{  \r\n      \"sku\":\"shirt0001\",\r\n      \"name\":\"T-shirt changed\",\r\n      \"price\":0,\r\n      \"status\":2,\r\n      \"customattributes\":[  \r\n         \r\n         {  \r\n            \"attributecode\":\"description\",\r\n            \"value\":\"<p>changed<\\/p>\"\r\n         }\r\n      ]\r\n   },\r\n   \"saveOptions\":true\r\n}' \"http://www.yourdomain.com/rest/V1/products/shirt0001\"\r\n```\r\n\r\n\r\n### Expected result\r\n\r\n1. We wait configurable product with name and status changed in this case, but with all attribute options and childs information on product links\r\n\r\n### Actual result\r\n\r\n1. We receive a Json with configurable product data updated, but los all information of produc links and attribute options. If we go to admin panel, then we see that product have no childs.\r\n\r\n<!--- (This may be platform independent comment) -->\r\nWe think that for reduce large times that take every api call to save products is really necessary that we can send PUT product calls with partial data."},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\r\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\r\nIf you try to get a products list from the /products endpoints using search criteria you won't get a non empty extensionattributes.\r\n\r\n### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1. Magento 2.1 (tested with 2.1.2 and 2.1.5)\r\n2. PHP 7\r\n\r\n### Steps to reproduce\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1. Perform a curl to YOURMAGENTOHOST/rest/V1/products?searchCriteria[pageSize]=X&searchCriteria[currentPage]=Y with an authorization header\r\n3. Check the returned JSON\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. As API reference and Swagger say extensionattributes should be not empty and containing some information like stock status and quantity, like the following part of JSON taken from API reference\r\n\r\n\"weight\": 0,\r\n      \"extensionattributes\": {\r\n        \"stockitem\": {\r\n          \"itemid\": 0,\r\n          \"productid\": 0,\r\n          \"stockid\": 0,\r\n          \"qty\": 0,\r\n          \"isinstock\": true,\r\n          \"isqtydecimal\": true,\r\n          \"showdefaultnotificationmessage\": true,\r\n          \"useconfigminqty\": true,\r\n          \"minqty\": 0,\r\n          \"useconfigminsaleqty\": 0,\r\n          \"minsaleqty\": 0,\r\n          \"useconfigmaxsaleqty\": true,\r\n          \"maxsaleqty\": 0,\r\n          \"useconfigbackorders\": true,\r\n          \"backorders\": 0,\r\n          \"useconfignotifystockqty\": true,\r\n          \"notifystockqty\": 0,\r\n          \"useconfigqtyincrements\": true,\r\n          \"qtyincrements\": 0,\r\n          \"useconfigenableqtyinc\": true,\r\n          \"enableqtyincrements\": true,\r\n          \"useconfigmanagestock\": true,\r\n          \"managestock\": true,\r\n          \"lowstockdate\": \"string\",\r\n          \"isdecimaldivided\": true,\r\n          \"stockstatuschangedauto\": 0,\r\n          \"extensionattributes\": {}\r\n        },\r\n\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. extensionattributes is always empty like the following part of the output I get:\r\n\r\n\"weight\":54,\r\n\"extensionattributes\":[],\r\n\"productlinks\":[],\r\n\"tierprices\":[],\r\n\r\nAnyway if you use the /products/SKU API endpoint you can see that the product extensionattributes field is populated.\r\n\r\n<!--- (This may be platform independent comment) -->\r\n"},
{"text": "Inside the REST API, it is impossible to access a resource that requires an SKU if the SKU contains a forward slash.\r\n\r\n### Preconditions\r\n1. Tested in CE 2.1.2 and CE 2.1.3. No indication of fix in 2.1.4 release notes\r\n\r\n### Steps to reproduce\r\n1. Fresh install\r\n2. Create product (of any type) with SKU containing /, e.g. \"CLE-056621/6\"\r\n3. Make REST request with encoded SKU (as Swagger does) e.g. \"V1/products/CLE-056621%2F6\", \"/V1/products/CLE-056621%2F6/media\"\r\n\r\n### Expected result\r\n1. Should be possible to make a request with encoded SKU, or by product ID\r\n\r\n### Actual result\r\n1. A request with a slash (\"CLE-056621/6\") returns \"Not found\" 404\r\n2. A request with encoded SKU (\"CLE-056621%2F6\") returns \r\n`{ \"message\": \"Requested product doesn't exist\" }`\r\n"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\r\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\r\n\r\n### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1. Magento 2.1.4\r\n\r\n### Steps to reproduce\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1. POST request to rest/V1/coupons with following JSON\r\n```\r\n{\r\n  \"coupon\": {\r\n    \"ruleid\":14,\r\n    \"code\":\"aaabbb\",\r\n    \"usagelimit\":10,\r\n    \"expirationdate\":\"2017-03-19\",\r\n    \"type\":\"1\"\r\n  }\r\n}\r\n```\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n<pre>\r\n{\r\n  \"couponid\": 11,\r\n  \"ruleid\": 14,\r\n  \"code\": \"aaabbb\",\r\n  <b>\"usagelimit\": 10</b>,\r\n  \"usagepercustomer\": 0,\r\n  \"timesused\": null,\r\n  <b>\"expirationdate\": \"2017-03-19\"</b>,\r\n  \"isprimary\": null,\r\n  \"type\": 1\r\n}\r\n</pre>\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n<pre>\r\n{\r\n  \"couponid\": 11,\r\n  \"ruleid\": 14,\r\n  \"code\": \"aaabbb\",\r\n  <b>\"usagelimit\": 2147483647</b>,\r\n  \"usagepercustomer\": 0,\r\n  \"timesused\": null,\r\n  <b>\"expirationdate\": \"2064-03-14\"</b>,\r\n  \"isprimary\": null,\r\n  \"type\": 1\r\n}\r\n</pre>\r\n\r\nThe parameters marked in bold are set to the same as that of the rule (id: 14) by Magento.\r\n<!--- (This may be platform independent comment) -->\r\n"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\r\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\r\n\r\n### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1. All versions. Tested on 2.1.4\r\n\r\n### Steps to reproduce\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1. Change default product link suffix in Stores -> Configuration -> SEO settings.\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. REST enpoint /V1/store/storeConfigs response should contain link suffix, among lots of other settings that can be done on a store. As an integrator, I want to be able to link to products obtained via the REST API.\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. It doesn't contain all the information needed to make a link.\r\n\r\n<!--- (This may be platform independent comment) -->\r\n"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\r\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\r\n\r\n### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1. Magento CE 2.1.4\r\n2. PHP 7.x\r\n3. MySQL 5.7\r\n\r\n### Steps to reproduce\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1. Send the same call to create an option ***twice***\r\nURL: /rest/V1/products/attributes/color/options\r\nPOST: \r\n```\r\n{\r\n    \"option\": {\r\n      \"label\": \"Black1\",\r\n      \"sortorder\": 9999,\r\n      \"isdefault\": false\r\n    }\r\n}\r\n```\r\n2. Get the attribute via API or check the backend\r\nResponse: \r\n```\r\n[\r\n  {\r\n    \"label\": \"offwhite/schwarz gestreift\",\r\n    \"value\": \"281\"\r\n  },\r\n  {\r\n    \"label\": \"red1\",\r\n    \"value\": \"286\"\r\n  },\r\n  {\r\n    \"label\": \"schwarz/mehrfarbig\",\r\n    \"value\": \"282\"\r\n  },\r\n  {\r\n    \"label\": \"Black1\",\r\n    \"value\": \"287\"\r\n  },\r\n  {\r\n    \"label\": \"Black1\",\r\n    \"value\": \"288\"\r\n  },\r\n  {\r\n    \"label\": \"Black1\",\r\n    \"value\": \"289\"\r\n  }\r\n]\r\n```\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. Only one option value is created\r\n2. Second call must fail with exception\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. Option values are created more than once.\r\n\r\n<!--- (This may be platform independent comment) -->\r\n"},
{"text": "When retrieving a credit memo via REST, an invalid `qtyrefunded` is given.\r\n\r\n### Preconditions\r\n1. A bundle (dynamic or static does not matter) with items that are in the bundle more than once (in my example the item is in the bundle 3 times)\r\n2. A credit memo on a order that ordered the bundle (again, in my example, it's ordered 2 times)\r\n\r\n### Steps to reproduce\r\n1. Request the credit memo via REST (`index.php/rest/V1/creditmemo/`)\r\n\r\n### Expected result\r\n1. On a **dynamic** bundle, the expected result is:\r\n```\r\n\"items\": [ {\r\n    ...\r\n    \"name\": \"MyDynamicBundle\", \r\n    \"orderItem\": {\r\n        ...\r\n        \"qtycanceled\": \"0.0000\",\r\n        \"qtyinvoiced\": \"2.0000\",\r\n        \"qtyordered\": \"2.0000\",\r\n        \"qtyrefunded\": \"2.0000\",\r\n        \"qtyshipped\": \"0.0000\",\r\n        ...\r\n    ...\r\n    \"name\": \"MySimpleProduct\", \r\n    \"orderItem\": {\r\n        ...\r\n        \"qtycanceled\": \"0.0000\",\r\n        \"qtyinvoiced\": \"6.0000\", // remember, the item is in the bundle 3 times, so 2x3 = 6)\r\n        \"qtyordered\": \"6.0000\",\r\n        \"qtyrefunded\": \"6.0000\",\r\n        \"qtyshipped\": \"0.0000\",\r\n        ...\r\n```\r\n2. On a **static** bundle (basically the same)\r\n```\r\n\"items\": [ {\r\n    ...\r\n    \"name\": \"MyStaticBundle\", \r\n    \"orderItem\": {\r\n        ...\r\n        \"qtycanceled\": \"0.0000\",\r\n        \"qtyinvoiced\": \"2.0000\",\r\n        \"qtyordered\": \"2.0000\",\r\n        \"qtyrefunded\": \"2.0000\",\r\n        \"qtyshipped\": \"0.0000\",\r\n        ...\r\n    ...\r\n    \"name\": \"MySimpleProduct\", \r\n    \"orderItem\": {\r\n        ...\r\n        \"qtycanceled\": \"0.0000\",\r\n        \"qtyinvoiced\": \"6.0000\", // remember, the item is in the bundle 3 times, so 2x3 = 6)\r\n        \"qtyordered\": \"6.0000\",\r\n        \"qtyrefunded\": \"6.0000\",\r\n        \"qtyshipped\": \"0.0000\",\r\n        ...\r\n```\r\n\r\n### Actual result\r\n1. On a **dynamic** bundle, the expected result is:\r\n```\r\n\"items\": [ {\r\n    ...\r\n    \"name\": \"MyDynamicBundle\", \r\n    \"orderItem\": {\r\n        ...\r\n        \"qtycanceled\": \"0.0000\",\r\n        \"qtyinvoiced\": \"2.0000\",\r\n        \"qtyordered\": \"2.0000\",\r\n        \"qtyrefunded\": \"1.0000\", // PLEASE NOTE, 1 INSTEAD OF 2\r\n        \"qtyshipped\": \"0.0000\",\r\n        ...\r\n    ...\r\n    \"name\": \"MySimpleProduct\", \r\n    \"orderItem\": {\r\n        ...\r\n        \"qtycanceled\": \"0.0000\",\r\n        \"qtyinvoiced\": \"6.0000\",\r\n        \"qtyordered\": \"6.0000\",\r\n        \"qtyrefunded\": \"6.0000\", // Correct\r\n        \"qtyshipped\": \"0.0000\",\r\n        ...\r\n```\r\n2. On a **static** bundle (basically the same)\r\n```\r\n\"items\": [ {\r\n    ...\r\n    \"name\": \"MyStaticBundle\", \r\n    \"orderItem\": {\r\n        ...\r\n        \"qtycanceled\": \"0.0000\",\r\n        \"qtyinvoiced\": \"2.0000\",\r\n        \"qtyordered\": \"2.0000\",\r\n        \"qtyrefunded\": \"2.0000\", // Correct\r\n        \"qtyshipped\": \"0.0000\",\r\n        ...\r\n    ...\r\n    \"name\": \"MySimpleProduct\", \r\n    \"orderItem\": {\r\n        ...\r\n        \"qtycanceled\": \"0.0000\",\r\n        \"qtyinvoiced\": \"6.0000\",\r\n        \"qtyordered\": \"6.0000\",\r\n        \"qtyrefunded\": \"1.0000\", // PLEASE NOTE, 1 INSTEAD OF 6\r\n        \"qtyshipped\": \"0.0000\",\r\n        ...\r\n```\r\n\r\nNote: When it's a dynamic bundle, the `baseprice` of the bundle is set and the `baseprice` of the items in the bundle are set to `0`, so it doesn't matter for the total costs (`6x0 = 0` and `1x0 = 0`). It does however matter when booking the credit: my stock isn't updated proper (I've gotten 6 items back, not just 1).\r\n"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\r\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\r\n\r\n### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1. Magento 2.1.5, PHP 7.0\r\n\r\n### Steps to reproduce\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1. Send Web API request as follows:\r\n\r\n```\r\nPUT /rest/default/V1/products/attributes/shortdescription/ HTTP/1.1\r\nHost: example.com\r\nAuthorization: OAuth oauthconsumerkey=\"xxxxx\",oauthtoken=\"xxxxx\",oauthsignaturemethod=\"HMAC-SHA1\",oauthtimestamp=\"xxxxx\",oauthnonce=\"xxxxx\",oauthsignature=\"xxxxx\"\r\nContent-Type: application/json\r\nCache-Control: no-cache\r\n\r\n{\r\n  \"attribute\": {\r\n    \"iswysiwygenabled\": true,\r\n    \"ishtmlallowedonfront\": true,\r\n    \"usedforsortby\": false,\r\n    \"isfilterable\": false,\r\n    \"isfilterableinsearch\": false,\r\n    \"isusedingrid\": true,\r\n    \"isvisibleingrid\": false,\r\n    \"isfilterableingrid\": false,\r\n    \"position\": 0,\r\n    \"applyto\": [],\r\n    \"issearchable\": \"1\",\r\n    \"isvisibleinadvancedsearch\": \"1\",\r\n    \"iscomparable\": \"1\",\r\n    \"isusedforpromorules\": \"0\",\r\n    \"isvisibleonfront\": \"0\",\r\n    \"usedinproductlisting\": \"1\",\r\n    \"isvisible\": true,\r\n    \"scope\": \"store\",\r\n    \"attributeid\": 76,\r\n    \"attributecode\": \"shortdescription\",\r\n    \"frontendinput\": \"textarea\",\r\n    \"entitytypeid\": \"4\",\r\n    \"isrequired\": false,\r\n    \"options\": [],\r\n    \"isuserdefined\": false,\r\n    \"defaultfrontendlabel\": \"Short Description\",\r\n    \"backendtype\": \"text\",\r\n    \"isunique\": \"0\",\r\n    \"validationrules\": []\r\n  }\r\n}\r\n```\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. Attribute updated successfully\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. Error returned via API:\r\n```\r\n{\r\n  \"message\": \"Internal Error. Details are available in Magento log file. Report ID: webapi-58c0d36765f2b\"\r\n}\r\n```\r\n\r\nContents of `webapi-58c0d36765f2b`:\r\n\r\n```\r\n[2017-03-09 04:00:39] report.CRITICAL: LogicException: Property \"IsUsedInGrid\" does not have corresponding setter in class \"Magento\\Catalog\\Api\\Data\\ProductAttributeInterface\". in /var/www/html/vendor/magento/framework/Reflection/NameFinder.php:100\r\nStack trace:\r\n#0 /var/www/html/vendor/magento/framework/Reflection/NameFinder.php(74): Magento\\Framework\\Reflection\\NameFinder->findAccessorMethodName(Object(Zend\\Code\\Reflection\\ClassReflection), 'IsUsedInGrid', 'setIsUsedInGrid', 'setIsIsUsedInGr...')\r\n#1 /var/www/html/vendor/magento/framework/Webapi/ServiceInputProcessor.php(163): Magento\\Framework\\Reflection\\NameFinder->getSetterMethodName(Object(Zend\\Code\\Reflection\\ClassReflection), 'IsUsedInGrid')\r\n#2 /var/www/html/vendor/magento/framework/Webapi/ServiceInputProcessor.php(322): Magento\\Framework\\Webapi\\ServiceInputProcessor->createFromArray('Magento\\\\Catalog...', Array)\r\n#3 /var/www/html/vendor/magento/framework/Webapi/ServiceInputProcessor.php(119): Magento\\Framework\\Webapi\\ServiceInputProcessor->convertValue(Array, 'Magento\\\\Catalog...')\r\n#4 /var/www/html/vendor/magento/module-webapi/Controller/Rest/InputParamsResolver.php(101): Magento\\Framework\\Webapi\\ServiceInputProcessor->process('Magento\\\\Catalog...', 'save', Array)\r\n#5 /var/www/html/vendor/magento/module-webapi/Controller/Rest.php(299): Magento\\Webapi\\Controller\\Rest\\InputParamsResolver->resolve()\r\n#6 /var/www/html/vendor/magento/module-webapi/Controller/Rest.php(216): Magento\\Webapi\\Controller\\Rest->processApiRequest()\r\n#7 /var/www/html/vendor/magento/framework/Interception/Interceptor.php(146): Magento\\Webapi\\Controller\\Rest->dispatch(Object(Magento\\Framework\\App\\Request\\Http))\r\n#8 /var/www/html/var/generation/Magento/Webapi/Controller/Rest/Interceptor.php(39): Magento\\Webapi\\Controller\\Rest\\Interceptor->callPlugins('dispatch', Array, Array)\r\n#9 /var/www/html/vendor/magento/framework/App/Http.php(135): Magento\\Webapi\\Controller\\Rest\\Interceptor->dispatch(Object(Magento\\Framework\\App\\Request\\Http))\r\n#10 /var/www/html/vendor/magento/framework/App/Bootstrap.php(258): Magento\\Framework\\App\\Http->launch()\r\n#11 /var/www/html/pub/index.php(37): Magento\\Framework\\App\\Bootstrap->run(Object(Magento\\Framework\\App\\Http))\r\n#12 {main}\r\n\r\nNext Exception: Report ID: webapi-58c0d36765f2b; Message: Property \"IsUsedInGrid\" does not have corresponding setter in class \"Magento\\Catalog\\Api\\Data\\ProductAttributeInterface\". in /var/www/html/vendor/magento/framework/Webapi/ErrorProcessor.php:195\r\nStack trace:\r\n#0 /var/www/html/vendor/magento/framework/Webapi/ErrorProcessor.php(139): Magento\\Framework\\Webapi\\ErrorProcessor->critical(Object(LogicException))\r\n#1 /var/www/html/vendor/magento/module-webapi/Controller/Rest.php(219): Magento\\Framework\\Webapi\\ErrorProcessor->maskException(Object(LogicException))\r\n#2 /var/www/html/vendor/magento/framework/Interception/Interceptor.php(146): Magento\\Webapi\\Controller\\Rest->dispatch(Object(Magento\\Framework\\App\\Request\\Http))\r\n#3 /var/www/html/var/generation/Magento/Webapi/Controller/Rest/Interceptor.php(39): Magento\\Webapi\\Controller\\Rest\\Interceptor->callPlugins('dispatch', Array, Array)\r\n#4 /var/www/html/vendor/magento/framework/App/Http.php(135): Magento\\Webapi\\Controller\\Rest\\Interceptor->dispatch(Object(Magento\\Framework\\App\\Request\\Http))\r\n#5 /var/www/html/vendor/magento/framework/App/Bootstrap.php(258): Magento\\Framework\\App\\Http->launch()\r\n#6 /var/www/html/pub/index.php(37): Magento\\Framework\\App\\Bootstrap->run(Object(Magento\\Framework\\App\\Http))\r\n#7 {main} [] []\r\n```\r\n<!--- (This may be platform independent comment) -->\r\n"},
{"text": "### Preconditions\r\nI have a Magento version 2.1.3 installation.  It has many orders wth different statuses.\r\n### Steps to reproduce\r\nIf I do a GET to this URL (replace BASEURL with magento 2 url, send token in header), I get a list of orders as expected (this is status=\"canceled\"):\r\n```\r\nBASEURL/rest/V1/orders/?searchCriteria[filtergroups][0][filters][0][field]=status&searchCriteria[filtergroups][0][filters][0][value]=canceled&searchCriteria[filtergroups][0][filters][0][conditiontype]=\"eq\"&searchCriteria[currentPage]=1&searchCriteria[pageSize]=10\r\n```\r\nIf I simply change this to status=\"pending\", I get an error.  This is the URL:\r\n```\r\nBASEURL/rest/V1/orders/?searchCriteria[filtergroups][0][filters][0][field]=status&searchCriteria[filtergroups][0][filters][0][value]=pending&searchCriteria[filtergroups][0][filters][0][conditiontype]=\"eq\"&searchCriteria[currentPage]=1&searchCriteria[pageSize]=10\r\n```\r\n### Expected result\r\nI expect to get pending orders when I GET to the second URL.  There are 8 of them on the Magento install I am working with. \r\n\r\n### Actual result\r\nWhen I do a GET with the second URL, I get this error:\r\n```\r\n{\r\n  \"message\": \"Notice: Array to string conversion in /srv/weldioc/html/vendor/magento/framework/Reflection/TypeCaster.php on line 34\",\r\n  \"trace\": \"#0 /srv/weldioc/html/vendor/magento/framework/Reflection/TypeCaster.php(34): Magento\\\\Framework\\\\App\\\\ErrorHandler->handler(8, 'Array to string...', '/srv/weldioc/ht...', 34, Array)\\n#1 /srv/weldioc/html/vendor/magento/framework/Reflection/DataObjectProcessor.php(139): Magento\\\\Framework\\\\Reflection\\\\TypeCaster->castValueToType(Array, 'string')\\n#2 /srv/weldioc/html/vendor/magento/framework/Reflection/DataObjectProcessor.php(120): Magento\\\\Framework\\\\Reflection\\\\DataObjectProcessor->buildOutputDataArray(Object(Magento\\\\Sales\\\\Model\\\\Order\\\\Payment\\\\Interceptor), '\\\\\\\\Magento\\\\\\\\Sales\\\\\\\\...')\\n#3 /srv/weldioc/html/vendor/magento/framework/Reflection/DataObjectProcessor.php(137): Magento\\\\Framework\\\\Reflection\\\\DataObjectProcessor->buildOutputDataArray(Object(Magento\\\\Sales\\\\Model\\\\Order), '\\\\\\\\Magento\\\\\\\\Sales\\\\\\\\...')\\n#4 /srv/weldioc/html/vendor/magento/framework/Webapi/ServiceOutputProcessor.php(109): Magento\\\\Framework\\\\Reflection\\\\DataObjectProcessor->buildOutputDataArray(Object(Magento\\\\Sales\\\\Model\\\\ResourceModel\\\\Order\\\\Collection), '\\\\\\\\Magento\\\\\\\\Sales\\\\\\\\...')\\n#5 /srv/weldioc/html/vendor/magento/framework/Webapi/ServiceOutputProcessor.php(60): Magento\\\\Framework\\\\Webapi\\\\ServiceOutputProcessor->convertValue(Object(Magento\\\\Sales\\\\Model\\\\ResourceModel\\\\Order\\\\Collection), '\\\\\\\\Magento\\\\\\\\Sales\\\\\\\\...')\\n#6 /srv/weldioc/html/vendor/magento/module-webapi/Controller/Rest.php(312): Magento\\\\Framework\\\\Webapi\\\\ServiceOutputProcessor->process(Object(Magento\\\\Sales\\\\Model\\\\ResourceModel\\\\Order\\\\Collection), 'Magento\\\\\\\\Sales\\\\\\\\A...', 'getList')\\n#7 /srv/weldioc/html/vendor/magento/module-webapi/Controller/Rest.php(216): Magento\\\\Webapi\\\\Controller\\\\Rest->processApiRequest()\\n#8 /srv/weldioc/html/var/generation/Magento/Webapi/Controller/Rest/Interceptor.php(24): Magento\\\\Webapi\\\\Controller\\\\Rest->dispatch(Object(Magento\\\\Framework\\\\App\\\\Request\\\\Http))\\n#9 /srv/weldioc/html/vendor/magento/framework/App/Http.php(135): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\Interceptor->dispatch(Object(Magento\\\\Framework\\\\App\\\\Request\\\\Http))\\n#10 /srv/weldioc/html/vendor/magento/framework/App/Bootstrap.php(258): Magento\\\\Framework\\\\App\\\\Http->launch()\\n#11 /srv/weldioc/html/pub/index.php(46): Magento\\\\Framework\\\\App\\\\Bootstrap->run(Object(Magento\\\\Framework\\\\App\\\\Http))\\n#12 {main}\"\r\n}\r\n```"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\r\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\r\n\r\n### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1. Magento 2.1.4\r\n2. PHP 7.0.15\r\n3. MySQL 5.6\r\n4. Website/store configuration:\r\n\r\nWebsite | Store | Store view\r\n------------ | ------------- | ------------- \r\nDanish (id: 2) | Danish Store (id: 2) | Store view (Danish)\r\nEnglish (id: 1) | English Store (id: 3) | Store View (English)\r\n\r\n### Steps to reproduce\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1. POST the following JSON to {domain.com}/rest/V1/products (catalogProductRepositoryV1)\r\n```\r\n{\r\n\t\"saveOptions\": true,\r\n\t\"product\": {\r\n\t\t\"attributesetid\": 4,\r\n\t\t\"visibility\": 4,\r\n\t\t\"price\": 100,\r\n\t\t\"typeid\": \"virtual\",\r\n\t\t\"name\": \"Test product\",\r\n\t\t\"extensionattributes\": {\r\n\t\t\t\"stockitem\": {\r\n\t\t\t\t\"managestock\": false,\r\n\t\t\t\t\"isinstock\": true,\r\n\t\t\t\t\"useconfigmanagestock\": false\r\n\t\t\t}\r\n\t\t},\r\n\t\t\"sku\": \"testproduct\",\r\n\t\t\"status\": 1\r\n\t}\r\n}\r\n```\r\n2. POST the following JSON to {domain.com}/rest/V1/products/testproduct/websites (catalogProductWebsiteLinkRepositoryV1)\r\n```\r\n{\r\n\t\"productWebsiteLink\": {\r\n\t\t\"sku\": \"testproduct\",\r\n\t\t\"websiteid\": 1\r\n\t}\r\n}\r\n```\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. New product should have url rewrites for both websites/stores\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. There is only created a url rewrite for the Danish website/store/store view\r\n\r\n<!--- (This may be platform independent comment) -->\r\n"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\r\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\r\n\r\n### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1. Magento ver. 2.1.4\r\n2. PHP ver. 7.0.15\r\n3. MySQL ver. 5.6.33\r\n\r\n\r\n### Steps to reproduce\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1. POST the following to domain.com/rest/V1/products/options:\r\n```\r\n{\r\n  \"option\": {\r\n    \"productsku\": \"mysku\",\r\n    \"title\": \"This is a gift\",\r\n    \"type\": \"checkbox\",\r\n    \"sortorder\": 0,\r\n    \"isrequire\": false,\r\n    \"maxcharacters\": 0,\r\n    \"imagesizex\": 0,\r\n    \"imagesizey\": 0,\r\n    \"values\": [\r\n      {\r\n        \"title\": \"Yes\",\r\n        \"sortorder\": 0,\r\n        \"price\": 0,\r\n        \"pricetype\": \"fixed\",\r\n        \"sku\": \"gift\"\r\n      }\r\n    ]\r\n  }\r\n}\r\n```\r\n2. Observe that the price field in the custom options in admin is empty and not 0.00.\r\n3. Programmatically change the status of the product in a cron job.\r\n4. Status not changed and cron message: \"Invalid option value\"\r\n5. Manually change price to 0.00 and save the product.\r\n6. Programmatically change the status of the product in a cron job.\r\n7. Status changed and no errors.\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. Observe that the price field in the custom options in admin is 0.00.\r\n2. Programmatically change the status of the product in a cron job.\r\n3. Status changed and no errors.\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. Programmatically changing the status of the product in a cron job does not work after creating the custom option through REST API. Status not changed and cron message: \"Invalid option value\"\r\n\r\n<!--- (This may be platform independent comment) -->\r\n"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\r\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\r\n\r\n### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1. Magento 2.1.2\r\n2. PHP 5.6\r\n3. MySQL 5.7\r\n\r\n### Steps to reproduce\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1. Create two attribute sets.\r\n2. Create a required attribute \r\n3. Assign the attribute to the first attribute set, but not the second.\r\n4. Create two products, one for each attribute set.\r\n5. Try to update the product on the attribute set without the required attribute with the REST API without that attribute.\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. The product is updated and nothing complains about the required attribute, since is not required for the attribute set of the product.\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. Magento doesn't check the attribute set of the product when using the API, so it throws an exception complaining about the missing attribute.\r\n`\"message\": \"The value of attribute \\\"foo\"\\ must be set\",`\r\n\r\n<!--- (This may be platform independent comment) -->\r\nThe process works normally when doing it on the backend, but on the API, it doesn't check the attribute set of the product, only the the entitytype.\r\n"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\r\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\r\n\r\n# Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1. Magento 2\r\n### Steps to reproduce\r\n\r\nThis demonstration is only with a single storeview, but can be reproduced with multiple storeviews or multiple websites like already mentioned by a bunch of other reporters above\r\n\r\n1. Setup a clean Magento installation using the 2.2-develop branch (I used commit eb84c5393da)\r\n2. Go into the backend\r\n3. Make a note of the default storeview code, it's `default` (we'll need this later when we create an API request)\r\n4. Create a new product:\r\n    - name: \"Base\"\r\n    - SKU: \"base\"\r\n    - price: 100\r\n    - description: \"Base\"\r\n    - short description: \"Base\"\r\n\r\n5. Look at the various `catalogproductentityint`, `catalogproductentitytext`, `catalogproductentityvarchar` tables in the database, they contain only values for storeid = 0, this is **good so far**!\r\n6. Still in the backend, go to System > Integrations and add a new integration with full access\r\n7. Activate the new integration and take a note of the 'access token' (example: `abc`)\r\n8. Execute the following curl command, which only updates the \"name\" attribute, using the storeview code from 3, and the access token from 7:\r\n```\r\ncurl -k -X PUT -H \"Accept: application/json\" -H \"Content-Type: application/json\" -H \"Authorization: Bearer abc\" -d \"{ \\\"product\\\": { \\\"name\\\": \\\"New name on storeview level\\\" }}\" https://domain/rest/default/V1/products/base\r\n```\r\n\r\n9. Go back in the backend and take a look at the product, but switch to the 'Default Store View' scope.\r\n10. It is expected that the \r\n\r\n11. Also take a look at the database again, to the `catalogproductentityint`, `catalogproductentitytext`, `catalogproductentityvarchar` tables, it is expected you'll only see one entry for storeid = 1, but there are like 10 entries, **not good**!\r\n\r\n# Expected result\r\n<!--- Tell us what should happen -->\r\nOnly attribute where the checkmark \"Use Default Value\" is unchecked is for the attribute \"name\"\r\n\r\n# Actual result\r\n<!--- Tell us what happens instead -->\r\nAll the following attributes now also have a value on storeview level, which is not what is expected:\r\n    - status\r\n    - tax class\r\n    - visibility\r\n    - description\r\n    - short description\r\n    - url key\r\n    - meta title\r\n    - meta keywords\r\n    - meta description\r\n    - display product options in\r\n"},
{"text": "### Preconditions\r\nMag CE 2.1.5\r\nPHP 5.6.19\r\nMySQL 5.7.11 \r\n\r\n### Steps to reproduce\r\nIn Mag Admin create new Bundle product, add Bundle Items to product, set  Ship Bundle Items option to Separately.\r\nIn Mag Admin create new Bundle product, add Bundle Items to product, set  Ship Bundle Items option to Together.\r\nCreate and Save a separate Sales Order for each newly added Bundle Product.\r\nUse Swagger or another development app to call salesOrderRepositoryV1 GET /V1/orders for each Sale Order and return the response body. Note that the response body model shows productoption with Order Items structure. But the REST response does not contain the productoption property and its values. The same missing content occurs with salesOrderItemRepositoryV1 GET /V1/orders/items/{id}.\r\nWhen catalogProductRepositoryV1 GET /V1/products/{sku} is called for the Bundle products the response body correctly shows customattributes{\"attributecode\": \"shipmenttype\",\"value\": \"0\"}\r\nWith Mag V1.9 SOAP API productoptions is populated and the critical value shipmenttype is shown. This value is critical for controlling how the sales order is to be handled in our receiving systems.\r\n\r\n### Expected result\r\nREST API response body property productoption should be populated with values that include shipmenttype.\r\n\r\n### Actual result\r\nREST API response body property productoption is not included in response body despite the modelschema showing it and the order containing bundle product with shipmenttype.\r\n\r\nIt is not possible to work around this by getting the product details during order item get because the Ship Bundle Items option may not be the same as when the order was created.\r\n\r\nThis is a show stopper for our integration project.\r\n"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\r\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\r\nThis issue was previously reported [here](https://github.com/magento/magento2/issues/9667). The reason for making a new issue is formatting a complaint according to the reporting guidelines. \r\n\r\n### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1. Magento 2.1.7\r\n2. PHP 7.0.18\r\n\r\n### Steps to reproduce\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1.  Having a test category of products:\r\n```\r\n\"id\": 20,\r\n\"parentid\": 2,\r\n\"name\": \"Clothes\"\r\n\"isactive\" => true\r\n```\r\n\r\n2. Send a Rest API request:\r\n\r\n> PUT /rest/V1/categories/20\r\n\r\nHeaders:\r\n\r\n```\r\ncontent-type: application/json\r\nAuthorization: Bearer <authorization token>\r\n```\r\n\r\nBody:\r\n```\r\n{\r\n    \"category\": {\r\n        \"id\": 20,\r\n        \"parentId\": 21,\r\n        \"name\": \"Test Category 1\",\r\n        \"isActive\": true\r\n    }\r\n}\r\n```\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n\r\n```\r\n\"id\": 20,\r\n\"parentid\": 21,\r\n\"name\": \"Test Category 1\",\r\n\"isactive\": true,\r\n```\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n\r\n```\r\n\"id\": 20,\r\n\"parentid\": 2,\r\n\"name\": \"Test Category 1\",\r\n\"isactive\": true,\r\n```\r\n\r\nResponse 200 OK.\r\n\r\nCategory name doesn't change, even if response shows that it is changed. \r\n![a829966e-4acd-11e7-83f6-9f3b488f0622](https://user-images.githubusercontent.com/13581265/27144782-de854766-513b-11e7-8f2e-39ebbd14ab5d.png)\r\n\r\n<!--- (This may be platform independent comment) -->\r\n"},
{"text": "### Preconditions\r\n\r\n1. Magento 2.1.7\r\n\r\n2. PHP 7.0.18\r\n\r\n### Steps to reproduce\r\n1. Having a test attribute group:\r\n```\r\n{\r\n  \"attributegroupid\": \"103\",\r\n  \"attributegroupname\": \"Test\",\r\n  \"attributesetid\": 4,\r\n  \"extensionattributes\": []\r\n}\r\n```\r\n2. Send a Rest API request:\r\n\r\n> PUT /rest/V1/products/attribute-sets/4/groups\r\n\r\nHeaders:\r\n\r\n    content-type: application/json\r\n    Authorization: Bearer <authorization token>\r\n\r\nBody:\r\n\r\n    {\r\n      \"group\": {\r\n        \"attributegroupid\": \"103\",\r\n        \"attributegroupname\": \"Test\",\r\n        \"attributesetid\": 13,\r\n        \"extensionattributes\": []\r\n      }\r\n    }\r\n\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n\r\n    {\r\n      \"attributegroupid\": \"103\",\r\n      \"attributegroupname\": \"Test\",\r\n      \"attributesetid\": 13,\r\n      \"extensionattributes\": []\r\n    }\r\n\r\n### Actual result\r\n\r\n    {\r\n      \"attributegroupid\": \"103\",\r\n      \"attributegroupname\": \"Test\",\r\n      \"attributesetid\": 4,\r\n      \"extensionattributes\": []\r\n    }\r\n\r\nResponse 200 OK.\r\n\r\nWorks if changing \"attributegroupname\"."},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\r\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\r\n\r\n### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1. Magento 2.1.3\r\n2. Setup Single store and that is default store. \r\n\r\n### Steps to reproduce\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1.  Use product rest api PUT:/V1/products/<productSKU> with request body {\"id\":2058,\"sku\":productSKU,\"name\":\"productSKU,\"attributesetid\":19,\"price\":29,\"status\":1,\"visibility\":4,\"typeid\":\"simple\",\"createdat\":\"2017-06-02 16:37:27\",\"updatedat\":\"2017-06-02 16:37:27\",\"weight\":0.08,\"extensionattributes\":[]}\r\n2. Response success 200 and changes are reflected on default store only.\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. This instance is having single store, so anything updated on default store store should be reflected on All store view in UI.\r\n2. As i wanted it to update data for all stores, I am not providing any store details in request. But if I provide the default store view then update only default store view for the item and not reflect on other stores\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. Default store view reflect the price and weight value in UI while All store view doesn't show any value.\r\n![image](https://user-images.githubusercontent.com/12096540/26917406-ce72bf2e-4c4b-11e7-8a8a-c576159e91e4.png)\r\n\r\n2. All store view doesn't show any price or weight.\r\n![image](https://user-images.githubusercontent.com/12096540/26917316-72cef174-4c4b-11e7-932e-472233202adf.png)\r\n\r\n\r\nI think it to be bug as this is single store and there is no way to get the price and weight show up in all store view. \r\n\r\n<!--- (This may be platform independent comment) -->\r\n"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\r\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\r\n\r\n### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1. Magento v2.1.4\r\n2. \r\n\r\n### Steps to reproduce\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1. Create an order containing a bundle of multiple simple products.\r\n2. Call the REST salesShipOrderV1 API (POST /V1/order/{orderId}/ship) and send a shipment for the individual items.  Example:\r\n```\r\n{\r\n        \"appendComment\": 1,\r\n        \"notify\": 1,\r\n        \"comment\": {\r\n            \"comment\": \"Your order has been shipped, login to view tracking information.\",\r\n            \"isvisibleonfront\": 1\r\n        },\r\n        \"items\": [\r\n            {\r\n                \"orderitemid\": 516,\r\n                \"qty\": 1\r\n            },\r\n            {\r\n                \"orderitemid\": 517,\r\n                \"qty\": 1\r\n            }\r\n        ],\r\n        \"tracks\": [\r\n            {\r\n                \"title\": \"Netherlands Post Ground Parcel\",\r\n                \"carriercode\": \"custom\",\r\n                \"tracknumber\": \"3SCEMW182389201\"\r\n            }\r\n        ]\r\n}\r\n```\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. Order gets mark completed\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. \r\n```\r\n{\r\n        \"status\": 400,\r\n        \"headers\": {},\r\n        \"body\": {\r\n            \"message\": \"Shipment Document Validation Error(s):\\nYou can't create a shipment without products.\"\r\n        }\r\n}\r\n```\r\n### Additional info \r\nReproduced it via Swagger. \r\nApplied admin token and used the POST/V1/order/{orderId}/ship\r\nUsed the following query body\r\n```\r\n{\r\n  \"items\": [\r\n    {\r\n      \"extensionattributes\": {},\r\n      \"orderitemid\": 6,\r\n      \"qty\": 1\r\n    }\r\n  ],\r\n  \"notify\": true,\r\n  \"appendComment\": true,\r\n  \"comment\": {\r\n    \"extensionattributes\": {},\r\n    \"comment\": \"Your order has been shipped, login to view tracking information.\",\r\n    \"isvisibleonfront\": 1\r\n  },\r\n  \"tracks\": [\r\n    {\r\n      \"extensionattributes\": {},\r\n      \"tracknumber\": \"3SCEMW182389201\",\r\n      \"title\": \"Netherlands Post Ground Parcel\",\r\n      \"carriercode\": \"fixed\"\r\n    }\r\n  ],\r\n  \"packages\": [\r\n    {\r\n      \"extensionattributes\": {}\r\n    }\r\n  ],\r\n  \"arguments\": {\r\n    \"extensionattributes\": {}\r\n  }\r\n}\r\n```\r\nWhere : \r\n- **orderId** can be found in Sales - Orders\r\n![salesorders](https://user-images.githubusercontent.com/51680745/72155345-9c282900-33bb-11ea-9418-c9a9b5fc7f62.png)\r\n- **tracknumber** is set while Shiping the order \r\n![ship](https://user-images.githubusercontent.com/51680745/72155637-2cff0480-33bc-11ea-8063-b6197052282e.png)\r\nAdd a tracking  number\r\n![tracknumber](https://user-images.githubusercontent.com/51680745/72155647-338d7c00-33bc-11ea-9d09-74c7a8879a66.png)\r\n- **orderitemid** I'm sure that there is an easier way, but I used GraphQL to verify the order item id \r\n![orderitemid](https://user-images.githubusercontent.com/51680745/72156067-39d02800-33bd-11ea-87f2-fe0341d318fe.png)\r\n\r\n"},
{"text": "When calling REST or SOAP the segments: appliedtaxes, itemappliedtaxes, convertingfromquote attributes are missing from the SOAP response.\r\n\r\nIn order to reproduce just call the REST API function \"{{host}}}/rest/V1/orders/{{orderid}}\"\r\n\r\n### Expected result\r\nIt should return the taxes details.\r\n\r\nThank you!"},
{"text": "When using REST API to insert entities the generated urlkey doesn't seem to keep track of the generated request path in urlrewrites. This, on long paths, will generate duplicate keys when, for example, doing a sub-category name change from Admin. Pretty sure the problem lies with products.\r\n\r\n### Preconditions\r\n1. Magento 2.1.6 \r\n2. REST API\r\n\r\n### Steps to reproduce\r\n1. POST to categories catalog a set categories building a reasonably large request path\r\n2. POST to products catalog product that exceeds the max length for request path\r\n\r\n### Expected result\r\n1. An error .\r\n\r\n### Actual result\r\n1. Nothing\r\n\r\nI imported via REST ~800 categories and ~16000 products. No errors/warning on generated path lengths.\r\n\r\nThen went through admin and changed a sub category name triggering a cascade of url rewrite entries to be processed. I got duplicate key errors due to the, now, truncated key being the same with existing product.\r\n\r\n**NOTE** It seems that the truncation is done on request path but the target path is not changed. At least in the urlrewrite table.\r\n"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\r\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\r\n\r\n### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1. Magento 2.1.6, PHP 5.6 and MySQL 5.6\r\n2. Hosted on cloudways\r\n\r\n### Steps to reproduce\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1. Create a simple product in the cart. Then try to update the quantity using the API (V1)\r\n2. \r\n3. \r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. Not a 500 error\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. [Screenshot, logs]\r\nLogs files are unavailable. Below are the responses from the two means of updating I tried.\r\n-----------------------------------------------------------------------------------------\r\nproduct update\r\n-----------------------------------------------------------------------------------------\r\nURL: http://magento-92293-260054.cloudwaysapps.com/index.php/rest/V1/products/TESTSKU2-1\r\nMethod: PUT\r\nData: {\"product\":{\"id\":\"6\",\"sku\":\"TESTSKU2-1\",\"name\":\"test names\",\"price\":99.0,\"weight\":\"0\",\"status\":\"1\",\"visibility\":\"4\",\"typeid\":\"simple\",\"attributesetid\":\"4\",\"stock\":{\"qty\":\"33\",\"isinstock\":true},\"customattributes\":[{\"attributecode\":\"shortdescription\",\"value\":\"prod desc\"},{\"attributecode\":\"requiredoptions\",\"value\":\"0\"},{\"attributecode\":\"taxclassid\",\"value\":\"2\"},{\"attributecode\":\"description\",\"value\":\"details2\"},{\"attributecode\":\"hasoptions\",\"value\":\"0\"},{\"attributecode\":\"giftmessageavailable\",\"value\":\"0\"},{\"attributecode\":\"optionscontainer\",\"value\":\"container2\"},{\"attributecode\":\"urlkey\",\"value\":\"test-names-1\"}],\"extensionattributes\":{\"stockitem\":{\"qty\":\"33\",\"isinstock\":true}}}}\r\nResponse code: 500\r\nRespnose message: {\"message\":\"Internal Error. Details are available in Magento log file. Report ID: webapi-591523cb7e6b1\"}\r\n\r\n-----------------------------------------------------------------------------------------\r\nstock update\r\n-----------------------------------------------------------------------------------------\r\nURL: http://magento-92293-260054.cloudwaysapps.com/index.php/rest/V1/products/TESTSKU2-1/stockItems/6\r\nMethod: PUT\r\nData {\"stockItem\":{\"itemid\":6,\"qty\":\"33\",\"isinstock\":true,\"isqtydecimal\":false,\"showdefaultnotificationmessage\":false,\"useconfigminqty\":false,\"useconfigmaxsaleqty\":false,\"useconfigbackorders\":false,\"useconfignotifystockqty\":false,\"useconfigqtyincrements\":false,\"useConfigEnableQtyInc\":false,\"enableqtyincrements\":false,\"useconfigmanagestock\":false,\"managestock\":true,\"isdecimaldivided\":false,\"productsku\":\"TESTSKU2-1\"}}\r\nResponse code: 500\r\nRespnose message: {\"message\":\"Internal Error. Details are available in Magento log file. Report ID: webapi-5915272c3e64a\"}\r\n<!--- (This may be platform independent comment) -->\r\n"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\r\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\r\n\r\n### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1. Magento 2.1.6\r\n2. Amazon Linux\r\n3. PHP 7.0.16\r\n4. Amazon RDS (MariaDB)\r\n\r\nThe server was completely installed using yum, with the packages available through the official Amazon repository\r\n\r\n### Steps to reproduce\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1. Create a new Amazon linux image on AWS\r\n2. Install php, nginx, the whole thing except the php soap extension\r\n3. Create a new vhost, copy over the 2.1.6 release\r\n4. Composer install\r\n5. Install magento through the command line ./bin/magento\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\nThe installation should not proceed as the soap extension, required for the magento soap api to work, is not present\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\nThe installation completes successfully, but the SOAP api is unusable\r\n\r\n<!--- (This may be platform independent comment) -->\r\nThis is probably platform independent."},
{"text": "### Preconditions\r\n1. Magento 2.1.6\r\n2. PHP 7.0.x\r\n\r\n### Steps to reproduce\r\n1. Try GET \"/rest/V1/products/attributes/:attributeCode\" using Postman; or ---.\r\n2. Try GET \"/rest/V1/products/products/attributes?searchCriteria[filterGroups][0][filters][0][field]=isvisible&searchCriteria[filterGroups][0][filters][0][value]=1&searchCriteria[filterGroups][0][filters][0][conditionType]=eq\" using Postman.\r\n\r\n### Expected result\r\n1. \"isvisible\" property should return correct value. \r\n2. Should not return attributes that does not visible.\r\n\r\n### Actual result\r\n1. Product Attribute in Magento admin :\r\n![selection306](https://cloud.githubusercontent.com/assets/345562/25735540/4c625082-3196-11e7-8935-0d28b0dbd41f.jpg)\r\n\r\n2. Product Attribute in REST API response :\r\n![selection305](https://cloud.githubusercontent.com/assets/345562/25735545/5274b7c6-3196-11e7-970c-4886a15cc92b.jpg)\r\n\r\n"},
{"text": "### Preconditions\r\n1. PHP 7.0\r\n2. Magento 2.1.6\r\n\r\n### Steps to reproduce\r\n1. Web API Security -> Allow Anonymous Guest Access: Yes\r\n2. Try GET \"/rest/V1/bundle-products/:sku/options/all\" using Postman\r\n\r\n### Expected result\r\n1. Never see a correct result\r\n\r\n### Actual result\r\n`{\r\n  \"message\": \"Consumer is not authorized to access %resources\",\r\n  \"parameters\": {\r\n    \"resources\": \"MagentoCatalog::products\"\r\n  }\r\n}`\r\n\r\n![selection299](https://cloud.githubusercontent.com/assets/345562/25602156/c3200e94-2f1b-11e7-8603-ddfe4f90d611.jpg)\r\n\r\n"},
{"text": "### Preconditions\r\nMagento 2.1.1\r\nPHP 5.6.30\r\n\r\n### Steps to reproduce\r\n1- Created a new configurable product. In my case I've created SKU '554864464' which has Id 46.\r\n2- Created attribute 'color' of type dropdown/select which has Id 170.\r\n3- Created an option 'White' for attribute color which has id/value 55.\r\n4- Verified the option 'White' by GETting /V1/products/attributes/color/options. White exists with value 55.\r\n5- POSTed this object to the configurableProductOptionRepositoryV1:\r\n(/V1/configurable-products/554864464/options)\r\n```\r\n{\r\n   \"option\":{\r\n      \"attributeid\":\"170\",\r\n      \"label\":\"Color\",\r\n      \"position\":0,\r\n      \"isusedefault\":true,\r\n      \"values\":[\r\n         {\r\n            \"valueindex\":55,\r\n            \"extensionattributes\":{}\r\n         }\r\n      ],\r\n      \"extensionattributes\":{},\r\n      \"productid\":46\r\n   }\r\n}\r\n```\r\n\r\n### Expected result\r\n1. Attribute color (170) has been assigned to configurable product 554864464 (46)\r\n\r\n### Actual result\r\n\"StatusCode: BadRequest, Content-Type: application/json; charset=utf-8, Content-Length: -1)\"\r\n{\"message\":\"**Something went wrong while saving option.**\"}\r\n\r\nI've also tried it with:\r\n- \"position\":1\r\n- \"isusedefault\":false\r\n- leaving out the \"extensionattributes\" properties\r\n\r\nIf I use the backend and manually assign color/white, it works just fine."},
{"text": "\"children\" field should not be included in documentation ( http://devdocs.magento.com/swagger/index21.html ) of possible body of POST /V1/categories in catalogCategoryRepositoryV1 or it should be ignored in webservice itself.\r\n\r\nThe same applies to documentation of body of PUT /V1/categories/{id} webservice.\r\n\r\n### Preconditions\r\n1. Magento 2.1.7\r\n\r\n### Steps to reproduce\r\n1. Create POST request to /rest/V1/categories endpoint with body:\r\n```\r\n{   \r\n\t\"category\": {\r\n\t\t\"isactive\": true, \r\n\t\t\"name\": \"Test\",     \r\n\t\t\"children\": \"1\"   \r\n\t} \r\n}\r\n```\r\n\r\n### Expected result\r\n1. Category is created\r\n\r\n### Actual result\r\n1. {\"message\":\"Internal Error. Details are available in Magento log file. Report ID: webapi-xxxxx\"}\r\n\r\nException log:\r\n\r\n```\r\nNext Exception: Report ID: webapi-5953d753666e8; Message: Property \"Children\" does not have corresponding setter in class \"Magento\\Catalog\\Api\\Data\\CategoryInterface\". in /var/www/vendor/magento/framework/Webapi/ErrorProcessor.php:195\r\nStack trace:\r\n#0 /var/www/vendor/magento/framework/Webapi/ErrorProcessor.php(139): Magento\\Framework\\Webapi\\ErrorProcessor->critical(Object(LogicException))\r\n#1 /var/www/vendor/magento/module-webapi/Controller/Rest.php(219): Magento\\Framework\\Webapi\\ErrorProcessor->maskException(Object(LogicException))\r\n#2 /var/www/vendor/magento/framework/Interception/Interceptor.php(146): Magento\\Webapi\\Controller\\Rest->dispatch(Object(Magento\\Framework\\App\\Request\\Http))\r\n#3 /var/www/var/generation/Magento/Webapi/Controller/Rest/Interceptor.php(39): Magento\\Webapi\\Controller\\Rest\\Interceptor->callPlugins('dispatch', Array, Array)\r\n#4 /var/www/vendor/magento/framework/App/Http.php(135): Magento\\Webapi\\Controller\\Rest\\Interceptor->dispatch(Object(Magento\\Framework\\App\\Request\\Http))\r\n#5 /var/www/vendor/magento/framework/App/Bootstrap.php(258): Magento\\Framework\\App\\Http->launch()\r\n#6 /var/www/pub/index.php(37): Magento\\Framework\\App\\Bootstrap->run(Object(Magento\\Framework\\App\\Http))\r\n#7 {main} [] []\r\n```"},
{"text": "Tested on Magento 2.1.7 with PHP7.\r\n\r\n1. Create a new product image via the REST API.\r\n2. The POST method return the ID of the created image.\r\n3. Update the image by SKU and ID, using the REST API.\r\n4. The PUT returns 'true' and the changes are visible on the front-end.\r\n5. Now do another update by SKU and ID, using the REST API.\r\n6. It throws the exception:\r\n\r\n> {\"message\":\"There is no image with provided ID.\",\"trace\":\"#0 [internal function]: Magento\\\\Catalog\\\\Model\\\\Product\\\\Gallery\\\\GalleryManagement->update('2192-S', Object(Magento\\\\Catalog\\\\Model\\\\Product\\\\Gallery\\\\Entry))\\n#1 \\/var\\/www\\/html\\/vendor\\/magento\\/module-webapi\\/Controller\\/Rest.php(307): calluserfuncarray(Array, Array)\\n#2 \\/var\\/www\\/html\\/vendor\\/magento\\/module-webapi\\/Controller\\/Rest.php(216): Magento\\\\Webapi\\\\Controller\\\\Rest->processApiRequest()\\n#3 \\/var\\/www\\/html\\/var\\/generation\\/Magento\\/Webapi\\/Controller\\/Rest\\/Interceptor.php(37): Magento\\\\Webapi\\\\Controller\\\\Rest->dispatch(Object(Magento\\\\Framework\\\\App\\\\Request\\\\Http))\\n#4 \\/var\\/www\\/html\\/vendor\\/magento\\/framework\\/App\\/Http.php(135): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\Interceptor->dispatch(Object(Magento\\\\Framework\\\\App\\\\Request\\\\Http))\\n#5 \\/var\\/www\\/html\\/vendor\\/magento\\/framework\\/App\\/Bootstrap.php(258): Magento\\\\Framework\\\\App\\\\Http->launch()\\n#6 \\/var\\/www\\/html\\/index.php(39): Magento\\\\Framework\\\\App\\\\Bootstrap->run(Object(Magento\\\\Framework\\\\App\\\\Http))\\n#7 {main}\"}\r\n\r\nI can reproduce this bug with every image, and I've tried multiple installations. Even a clean one without any 3rd party extensions installed.\r\n\r\nEdit: 2017-06-23:\r\nAfter trying to update an image twice, the image cannot be deleted anymore via the admin backend. So the image becomes permanent.\r\n"},
{"text": "With Magento 2.1.7 and the test dataset, I use the API \r\n\r\nhttp://localhost:8888/mage217/rest/V1/products/MS06-L-Blue\r\n\r\n(This is for product 541, named \"Zoltan Gym Tee-L-Blue\".  The SKU is \"MS06-L-Blue\" as shown in the API call.) \r\n\r\nI get back \r\n\r\n...\r\n            [10] => stdClass Object\r\n                (\r\n                    [attributecode] => urlkey\r\n                    [value] => zoltan-gym-tee-l-blue\r\n                )\r\n...\r\n\r\nI can't build a URL from this - the API key *should* be zoltan-gym-tee.  In other words,\r\n\r\nhttp://localhost:8888/mage217/index.php/zoltan-gym-tee.html  DOES work \r\n\r\nhttp://localhost:8888/mage217/index.php/zoltan-gym-tee-l-blue.html DOES NOT work\r\n\r\n### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1. Magento 2.1.7\r\n2. PHP 5.6.30\r\n3. MySQL 5.6.35\r\n4. MAMP\r\n\r\n### Steps to reproduce\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1. Use products API as shown above  http://localhost:8888/mage217/rest/V1/products/MS06-L-Blue\r\n\r\n2. Attempt to create a URL to this product using returned urlkey value\r\n\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. Actual product page is shown \r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. 404 page is shown. \r\n\r\n<!--- (This may be platform independent comment) -->\r\n"},
{"text": "### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1. XAMPP for MacOS 5.6.31 / PHP 5.6.31\r\n2. Magento 2.1.7\r\n3. I followed guideline in this article: http://devdocs.magento.com/guides/v2.0/get-started/authentication/gs-authentication-session.html\r\n\r\n### Steps to reproduce\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1. Create new customer at Magento 2 website\r\n2. Login customer with email/password\r\n3. On the same browser, open new tab\r\n4. Go to http://<magentohost>/rest/V1/customers/me\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. The information of customer should displayed (as xml because we are using browser)\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. Screenshot: http://prntscr.com/fwn2mu\r\n\r\n<!--- (This may be platform independent comment) -->\r\nI tried to create another GET endpoint with permission \"self\", and the result is the same \"Consumer is not authorized to access %resources\""},
{"text": "Using Magento 2.1.7 with the REST API - POST /V1/products/attributes - I can add a new attribute and configure it with settings such as isfilterable.\r\n\r\nThis is all fine but if I then want to change this setting I can't. I have tried with POST and with PUT /V1/products/attributes/{attributeCode}. The command works as in it will update, for instance, the frontend label in the eavattribute table, but it does not seem to have any effect on values in the catalogeavattribute table.\r\n\r\nSteps to reproduce -\r\n1. Add a new attribute using REST API - POST - /V1/products/attributes - with isfilterable set to false.\r\n2. Update the same attribute using either the same POST url or PUT - /V1/products/attributes/{attributeCode} and set the isfilterable field to true\r\n\r\nExpected result\r\nThe attribute is now set to be filterable\r\n\r\nActual result\r\nNo change\r\n"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\r\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\r\n\r\n### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1. Magento 2.1.7\r\n\r\n### Steps to reproduce\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1. Install magento \r\n2. create an admin user and obtain a token to be used for rest calls\r\n3. create one more store view (to have two store views in total. those ids would be used in the payload as values for 'storeid'\r\n4. create a product attribute by making a POST call to {{baseurl}}/rest/V1/products/attributes and using given json payload\r\n\r\n```\r\n{\r\n  \"attribute\": {\r\n    \"iswysiwygenabled\": false,\r\n    \"ishtmlallowedonfront\": false,\r\n    \"usedforsortby\": true,\r\n    \"isfilterable\": false,\r\n    \"isfilterableinsearch\": false,\r\n    \"position\": 0,\r\n    \"applyto\": [\"simple\",\"virtual\",\"configurable\"],\r\n    \"issearchable\": \"1\",\r\n    \"isvisibleinadvancedsearch\": \"1\",\r\n    \"iscomparable\": \"0\",\r\n    \"isusedforpromorules\": \"0\",\r\n    \"isvisibleonfront\": \"1\",\r\n    \"usedinproductlisting\": \"1\",\r\n    \"isvisible\": true,\r\n    \"scope\": \"store\",\r\n    \"extensionattributes\": {},\r\n    \"attributecode\": \"webattribute4\",\r\n    \"frontendinput\": \"multiselect\",\r\n    \"entitytypeid\": \"4\",\r\n    \"isrequired\": false,\r\n    \"isuserdefined\": true,\r\n    \"defaultfrontendlabel\": \"webattribute4deffrontendlabel\",\r\n    \"frontendlabels\": [\r\n      {\r\n        \"storeid\": 1,\r\n        \"label\": \"webattribute4labelen\"\r\n      }\r\n    ] ,    \r\n    \"options\": [\r\n        {\r\n            \"label\": \"label opt1\",\r\n            \"value\": \"valueopt1\",\r\n            \"isdefault\": true,\r\n            \"storelabels\": [\r\n          {\r\n            \"storeid\": 0,\r\n            \"label\": \"option1labladm\"\r\n          },\r\n          {\r\n            \"storeid\": 1,\r\n            \"label\": \"option1lablen\"\r\n          }\r\n         ]   \r\n        },\r\n        {\r\n            \"label\": \"label opt2\",\r\n            \"value\": \"valueopt2\",\r\n            \"storelabels\": [\r\n          {\r\n            \"storeid\": 0,\r\n            \"label\": \"option2labladm\"\r\n          },\r\n          {\r\n            \"storeid\": 1,\r\n            \"label\": \"option2lablen\"\r\n          }\r\n         ]   \r\n        }        \r\n    ],\r\n    \"note\": \"dummy note\",\r\n    \"backendtype\": \"varchar\",\r\n    \"defaultvalue\": \"0\",\r\n    \"isunique\": \"0\",\r\n    \"customattributes\": [\r\n      {\r\n        \"attributecode\": \"webattribute4\",\r\n        \"value\": \"webattribute4value\"\r\n      }\r\n    ]\r\n  }\r\n}\r\n```\r\n\r\n5. update an attribute using given json payload (**NOTE** replace YOURID with an actual attributeid from the previous step response )\r\n\r\n```\r\n{\r\n  \"attribute\": {\r\n    \"attributeid\": **YOURID**,\r\n    \"frontendlabels\": [\r\n      {\r\n        \"storeid\": 1,\r\n        \"label\": \"webattribute4labelennew2\"\r\n      }\r\n    ]    \r\n  }\r\n}\r\n\r\n```\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. Only frontend label should be updated and **NO changes in attribute options should be made** when no **option** element is given in the payload \r\n![image](https://user-images.githubusercontent.com/23319907/27876321-a951d286-6184-11e7-8050-4d471b8e2a79.png)\r\n![image](https://user-images.githubusercontent.com/23319907/27876354-c88d3622-6184-11e7-9220-86419ca08987.png)\r\n\r\n\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. Options have been changed - one empty option being inserted at the top of the list, two remained options lost their Admin values which are replaced with Default store view values , wheare Default store values became empty.\r\n\r\n![image](https://user-images.githubusercontent.com/23319907/27876498-53c9d0b0-6185-11e7-9d0d-559d6cf84440.png)\r\n\r\n![image](https://user-images.githubusercontent.com/23319907/27876542-7bd16884-6185-11e7-8404-87d6552faa94.png)\r\n\r\n\r\n### **PLEASE NOTE**\r\nSending an array of options within an update payload does not help either (example of the payload below)\r\n\r\n```\r\n{\r\n  \"attribute\": {\r\n  \t\"attributeid\": **YOURID**,\r\n    \"options\": [\r\n        {\r\n            \"label\": \"label opt1\",\r\n            \"value\": \"valueopt1\",\r\n            \"isdefault\": true,\r\n            \"storelabels\": [\r\n          {\r\n            \"storeid\": 0,\r\n            \"label\": \"option1labladm\"\r\n          },\r\n          {\r\n            \"storeid\": 1,\r\n            \"label\": \"option1lablen\"\r\n          }\r\n         ]   \r\n        },\r\n        {\r\n            \"label\": \"label opt2\",\r\n            \"value\": \"valueopt2\",\r\n            \"storelabels\": [\r\n          {\r\n            \"storeid\": 0,\r\n            \"label\": \"option2labladm\"\r\n          },\r\n          {\r\n            \"storeid\": 1,\r\n            \"label\": \"option2lablen\"\r\n          }\r\n         ]   \r\n        }        \r\n    ],  \t\r\n    \"frontendlabels\": [\r\n      {\r\n        \"storeid\": 1,\r\n        \"label\": \"webattribute4labelennew2\"\r\n      }\r\n    ]    \r\n  }\r\n}\r\n```\r\nThis way it causes options duplication\r\n\r\n![image](https://user-images.githubusercontent.com/23319907/27878278-abeb2d4c-618b-11e7-8429-59979cf8339a.png)\r\n\r\n \r\n<!--- (This may be platform independent comment) -->\r\n"},
{"text": "### Preconditions\r\n1. Magento 2.1.7 deployed from zip file then updated using composer\r\n2. Bog standard install\r\n\r\n### Steps to reproduce\r\n1. Create integration. It doesnt matter what values you use.\r\n2. Using an OAuth client, attempt to get access token\r\n\r\n### Expected result\r\n1. An access token is returned to the oauth client\r\n\r\n### Actual result\r\n1. Error \"Consumer key has expired\" is returned\r\n\r\nInvestigation shows that database table \"oauthconsumer\" field \"updatedat\" has the default value set to 0 and on update set to CURRENTTIMESTAMP\r\n\r\nWhen a new consumer is added, the \"updatedat\" field is set to 0. Since this field is used to validate the access token request, it fails stating that the consumer key has expired.\r\n\r\nThe \"updatedat\" field is only ever updated whenever the consumer is updated, not when it is added.\r\n\r\nSurely the correct behaviour should be that the default value of updatedat should be CURRENTTIMESTAMP so that on creation, \"createdat\" and \"updatedat\" are the same."},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\r\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\r\n\r\n### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1. Magento 2.1.9\r\n2. Multistore\r\n3. PHP 7.0.2\r\n\r\n### Steps to reproduce\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1. Magento 2.1.9\r\n2. Multistore\r\n3. POST rest/<storecode>/V1/categories \r\n4. I also tried giving the storeid, storeviewid, store and other parameters in the JSON Body but the api responds \"Property \"StoreId\" does not have corresponding setter in class \"Magento\\\\Catalog\\\\Api\\\\Data\\\\CategoryInterface\".\"\r\n\r\nI also tried to POST to rest/default/V1/categories but the result is the same, the category gets always listed in every single storeview of the store (not in storeviews of other stores, multiple stores are configured). \r\n\r\nI also printed out the Information of \"vendor/magento/module-webapi/Controller/PathProcessor.php\" to see if the API path is correctly extracted and got the following result: \r\npathInfo: /rest/english/V1/categories/37\r\nstoreCode: english\r\nOwn Message: Store exists and is set by code: english\r\nCurrentStore after $this->storeManager->getStore()->getId() is now: 4  <--- (which is the correct ID i want the category to be created under)\r\nreturn path: /V1/categories37\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. I would have expected a category in the specified storeView. I wanted to create the same category with different languages in different storeviews. \r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. Every category shows up in all storeviews. I wanted to create a category with multiple languages for the different storeviews (one is english, the other is german). \r\n\r\n<!--- (This may be platform independent comment) -->\r\n"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\r\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\r\n\r\n### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1. Magento 2.1.8 \r\n\r\n### Steps to reproduce\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1. Import Attribute Option of type visual swatch (Color for example) over http request (API)\r\n2. Code example:\r\n{\r\n        $option = $this->attrOptionFactory->create();\r\n        $optionLabel = $this->attrOptionLabelFactory->create();\r\n\r\n        $optionLabel->setStoreId(0);\r\n        $optionLabel->setLabel('newcolor');\r\n\r\n        $option->setLabel('newcolor');\r\n        $option->setStoreLabels(array($optionLabel));\r\n        \r\n        $this->productAttributeOptionManagement->add('color', $option);\r\n    }\r\n\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. New Attribute Option should be imported to backend \r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. New Atttribute Option does not get imported because there is no entry in eavattributeoptionswatch table\r\n\r\n### More info\r\nUntil Magento 2.1.7 the plugin did not trigger beforeSave function in swatches/Model/Plugin/EavAttribute and the Import data had not to match visual swatch data structure, it was imported\r\nSince Magento 2.1.8 the function is renamed to beforeBeforeSave and the plugin triggers it,\r\nso the Import data has to follow data structure of visual swatch, but since it is a API Import there is no entry in database and the new Option does not get imported\r\n \r\n<!--- (This may be platform independent comment) -->\r\n"},
{"text": "Every field of the `ProductFilterInput` input field in `MagentoCatagolGraphQl::etc/graphql.xml` has the type `FilterTypeInput`. The problem here is that `FilterTypeInput` requires most of its arguments to be strings.\r\n\r\nFor example, I might want to select products that do not have a special price set. This might be some query like:\r\n\r\n```graphql\r\n{\r\n  products(filter: { specialprice: { null: true } }) {\r\n    totalcount\r\n  }\r\n}\r\n```\r\n\r\nThe devdocs, and basic intuition seem to suggest this is okay. However, this doesn't work because `MagentoGraphQl::etc/graphql.xml` requires the `null` field in `FilterTypeInput` to be a string.\r\n\r\n### Preconditions\r\n\r\n1. This is GraphQL, so it's in `2.3-develop`, natch.\r\n\r\n### Steps to reproduce\r\n\r\n1. Try to submit the query written above.\r\n\r\n### Expected result\r\n\r\nBased on the documentation, I would expect this to be a legal query.\r\n\r\nReceive a response like this:\r\n\r\n```json\r\n{\r\n  \"data\": {\r\n    \"products\": {\r\n      \"totalcount\": 0\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n### Actual result\r\n\r\nResponse:\r\n\r\n```json\r\n{\r\n  \"errors\": [\r\n    {\r\n      \"message\": \"Argument \\\"filter\\\" has invalid value {specialprice: {null: true}}.\\nIn field \\\"specialprice\\\": In field \\\"null\\\": Expected type \\\"String\\\", found true.\",\r\n      \"category\": \"graphql\",\r\n      \"locations\": [\r\n        {\r\n          \"line\": 2,\r\n          \"column\": 20\r\n        }\r\n      ]\r\n    }\r\n  ]\r\n}\r\n```\r\n\r\nThis also applies to other fields. For example, I was unable to filter products by category ids."},
{"text": "### Preconditions\r\n1. I am using magento 2.1.10\r\n2. I am trying to place an order with multiple products in one cart\r\n\r\n### Steps to reproduce\r\n1. i am sending POST request and its not working, i am hitting url \"www.sample.com/index.php/rest/V1/guest-carts/c62700b7e525b82c0e96607e11ec0942/items\"\r\n2. i am send multiple products in body of post request\r\n{ \"cartItem\": [\r\n  { \"quoteid\": \"c62700b7e525b82c0e96607e11ec0942\",\"sku\": \"8246549-Black-40\", \"qty\":1 },\r\n  { \"quoteid\": \"c62700b7e525b82c0e96607e11ec0942\",\"sku\": \"8544501-Brown-43\", \"qty\":1 },\r\n  { \"quoteid\": \"c62700b7e525b82c0e96607e11ec0942\",\"sku\": \"8516031-Black-44\", \"qty\":1 }\r\n ]\r\n}\r\n\r\n\r\n### Expected result\r\n1. It should return cart's information with its all products\r\n\r\n### Actual result\r\n\r\n1. \"message\": \"Internal Error. Details are available in Magento log file. Report ID: webapi-5a4b216497333\"\r\n\r\n\r\n"},
{"text": "<!--- Provide a general summary of the issue in the Title above -->\r\n<!--- Before adding new issues, please, check this article https://github.com/magento/magento2/wiki/Issue-reporting-guidelines-->\r\nWith Asynchronous Grid Indexing status updates to an order via the Magento 2.2 APIs are not reflected in the order grid.\r\n\r\n### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. --> \r\nInstall Magento from 2.2.-develop branch\r\n\r\n### Steps to reproduce\r\n<!--- Provide a set of unambiguous steps to reproduce this bug include code, if relevant  -->\r\n1. Enable Asynchronous Indexing in Stores > Configuration > Advanced > Developer > Grid Settings\r\n2. Create a new order\r\n3. Add status update via API call, e.g., \r\n\r\n> /rest/V1/orders/{orderId}/comments\r\n {\r\n\"statusHistory\": {\r\n\"comment\": \"Updating status\",\r\n\"iscustomernotified\": 0,\r\n\"isvisibleonfront\": 0,\r\n\"status\": \"processing\"\r\n}\r\n}\r\n \r\n\r\n4. Go to Sales > Orders and search for the order from the grid - take note of the status\r\n5. Open the order and compare the status with the status from the grid\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\nOrder statuses in the grid and on its edit page are different.\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\nThe statuses should be the same."},
{"text": "### Preconditions\r\n<!--- Provide a more detailed information of environment you use -->\r\n<!--- Magento version, tag, HEAD, etc., PHP & MySQL version, etc.. -->\r\n1. Magento 2.2.3\r\n2. PHP 7.1\r\n3. MySQL 5.6\r\n4. OS - Ubuntu 16.04\r\n\r\n### Steps to reproduce\r\n1. Use **GET /V1/products-render-info** REST API call to get the list of products based on the search criteria, currency, store and the pagination settings (/rest/V1/products-render-info?searchCriteria=[]&storeId=1&currencyCode=1)\r\n2. It returns the list of products but not the filters section\r\n\r\n### Expected result\r\n1. Expecting the REST API to get the filters details\r\n\r\n### Actual result\r\n1. To build an Android application (for example), we are able to get the list of products but there is no provision to get the filters details\r\n"},
{"text": "### Preconditions (*)\r\n<!---\r\nProvide the exact Magento version (example: 2.3.2) and any important information on the environment where bug is reproducible.\r\n-->\r\n1. Magento 2.3.3\r\n2. Set TimeZone to something that isn't UTC (I.e. GMT Europe/London - currently UTC+1)\r\n\r\n### Steps to reproduce (*)\r\n1. Place test order\r\n2. Send GET request for order details to SalesOrderRepository\r\n3. createdat/updatedat will be in UTC\r\n\r\n### Expected result (*)\r\n<!--- Tell us what do you expect to happen. -->\r\n1. createdat/updatedat will use timezone set in Magento admin\r\n\r\n### Actual result (*)\r\n<!--- Tell us what happened instead. Include error messages and issues. -->\r\n1. createdat/updatedat uses UTC timezone\r\n"},
{"text": "<!---\r\nPlease review our guidelines before adding a new issue: https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\nFields marked with (*) are required. Please don't remove the template.\r\n-->\r\nThe server's response code is 500 in cases either success or failure when Show Prefix is set to be required. Customer is created by setting prefix in Address section\r\n\r\n### Preconditions (*)\r\n<!---\r\nProvide the exact Magento version (example: 2.2.5) and any important information on the environment where bug is reproducible.\r\n-->\r\n1. No preconditions\r\n\r\n### Steps to reproduce (*)\r\n<!---\r\nImportant: Provide a set of clear steps to reproduce this bug. We can not provide support without clear instructions on how to reproduce.\r\n-->\r\n1. Navigate to Stores -> Settings -> Configuration -> Customers -> Customers Configuration\r\n2. Set **Show Prefix** to be **Required**\r\n3. Reindex and Flush Cache\r\n4. Send request:\r\n```shell\r\n### Set your endpoint name, example: endpoint=\"http://gql-ce.io/rest\"\r\nendpoint=\"REPLACE\";\r\n\r\nadmintoken=$(curl -X POST \"$endpoint/V1/integration/admin/token\" \\\r\n -H \"Content-Type: application/json\" \\\r\n -d '{\"username\":\"admin\",\"password\":\"123123q\"}') && echo $admintoken && admintoken=$(echo $admintoken | tr -d '\"');\r\n\r\n curl -X POST $endpoint/V1/customers \\\r\n-H \"Content-Type: application/json\" \\\r\n-H \"Authorization: Bearer $admintoken\" \\\r\n-d '{\"customer\":{\"defaultbilling\":\"1\",\"defaultshipping\":\"1\",\"email\":\"yhitecwa12@gmail.com\",\"firstname\":\"Yokoshima\",\"lastname\":\"Hiteca\",\"gender\": \"3\",\"storeid\":1,\"websiteid\":1,\"addresses\":[{\"id\":1,\"region\":{\"regioncode\":\"CA\",\"region\":\"California\",\"regionid\":12},\"regionid\":12,\"countryid\":\"US\",\"street\":[\"6161 West Centinela Avenue\"],\"company\":\"Magento\",\"telephone\":\"555-55-555-55\",\"postcode\":\"90230\",\"city\":\"Culver City\",\"firstname\":\"Yokoshima\",\"lastname\":\"Hiteca\",\"defaultshipping\":true,\"defaultbilling\":true}],\"disableautogroupchange\":0,\"extensionattributes\":{\"issubscribed\":false}},\"password\":\"MetaFrame1\"}' | jsonpp\r\n```\r\nor\r\n```shell\r\n### Set your endpoint name, example: endpoint=\"http://gql-ce.io/rest\"\r\nendpoint=\"REPLACE\";\r\n\r\nadmintoken=$(curl -X POST \"$endpoint/V1/integration/admin/token\" \\\r\n -H \"Content-Type: application/json\" \\\r\n -d '{\"username\":\"admin\",\"password\":\"123123q\"}') && echo $admintoken && admintoken=$(echo $admintoken | tr -d '\"');\r\n\r\n curl -X POST $endpoint/V1/customers \\\r\n-H \"Content-Type: application/json\" \\\r\n-H \"Authorization: Bearer $admintoken\" \\\r\n-d '{\"customer\":{\"defaultbilling\":\"1\",\"defaultshipping\":\"1\",\"email\":\"yhitecwa12@gmail.com\",\"firstname\":\"Yokoshima\",\"lastname\":\"Hiteca\",\"gender\": \"3\",\"prefix\":\"Mr.\",\"storeid\":1,\"websiteid\":1,\"addresses\":[{\"id\":1,\"region\":{\"regioncode\":\"CA\",\"region\":\"California\",\"regionid\":12},\"regionid\":12,\"countryid\":\"US\",\"street\":[\"6161 West Centinela Avenue\"],\"company\":\"Magento\",\"telephone\":\"555-55-555-55\",\"postcode\":\"90230\",\"city\":\"Culver City\",\"firstname\":\"Yokoshima\",\"lastname\":\"Hiteca\",\"defaultshipping\":true,\"defaultbilling\":true}],\"disableautogroupchange\":0,\"extensionattributes\":{\"issubscribed\":false}},\"password\":\"MetaFrame1\"}' | jsonpp\r\n```\r\n\r\n### Expected result (*)\r\n<!--- Tell us what do you expect to happen. -->\r\n1. Validation\r\n2. Response code `200` in case of success (Customer was created after the second request, but got 500 in the console).\r\n\r\n### Actual result (*)\r\n<!--- Tell us what happened instead. Include error messages and issues. -->\r\n1. No validation. Code 500 on every request"},
{"text": "### Preconditions\r\nMagento 2.2.7\r\n\r\n### Steps to reproduce\r\nSearch Magento through the REST API endpoint:\r\n`/rest/V1/search?searchCriteria[requestName]=quicksearchcontainer&searchCriteria[filtergroups][0][filters][0][field]=searchterm&searchCriteria[filtergroups][0][filters][0][value]=brick`\r\n\r\n### Expected result\r\nThe search term `brick` should be added to the table `searchquery` and thus show up in the Search Terms Report.\r\n\r\n### Actual result\r\nNothing is added. This causes problems for headless websites, basically rendering those reports useless."},
{"text": "<!---\r\nPlease review our guidelines before adding a new issue: https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\n-->\r\nIf you use the API endpoint PUT /V1/guest-carts/{cartId}/collect-totals on an empty quote it all goes fine. But if you want to update the endpoint again to update the shippingMethod the old ShippingMethod is used for the totals.\r\n\r\n\r\n\r\n### Preconditions\r\n<!---\r\nProvide the exact Magento version (example: 2.2.5) and any important information on the environment where bug is reproducible.\r\n-->\r\n2.2.3\r\n\r\n### Steps to reproduce\r\n<!---\r\nImportant: Provide a set of clear steps to reproduce this bug. We can not provide support without clear instructions on how to reproduce.\r\n-->\r\n1. Call the PUT /V1/guest-carts/{cartId}/collect-totals endpoint with this data:\r\n```\r\n{\"shippingMethodCode\":\"flatrate\",\"shippingCarrierCode\":\"flatrate\",\"paymentMethod\":{\"method\":\"checkmo\"}}\r\n```\r\n2. Call the PUT /V1/guest-carts/{cartId}/collect-totals endpoint with this data:\r\n```\r\n{\"shippingMethodCode\":\"freeshipping\",\"shippingCarrierCode\":\"freeshipping\",\"paymentMethod\":{\"method\":\"checkmo\"}}\r\n```\r\n\r\n### Expected result\r\n<!--- Tell us what do you expect to happen. -->\r\n1. Totals are updated with the new shippingMethod\r\n\r\n### Actual result\r\n<!--- Tell us what happened instead. Include error messages and issues. -->\r\n1. Totals are from the old shippingMethod.\r\n\r\n\r\nIt looks like it has to do that on the second call the setShippingAssignments() is not updated and this causes that the totals are using the old shippingMethod."},
{"text": "Preconditions\r\n\r\n- Magento 2.2.5 installed with sample data , PHP 7.1 and MYSQL 5.6 With Ngnix\r\n- Create Customer token and a quote with items that would be used to add shipping and billing information\r\n- A saved customer address .\r\n\r\nSteps to reproduce\r\n\r\nHit the products REST api rest/V1/carts/mine/billing-address  with generated customer token in above state with a similar body as below\r\n```\r\n{\r\n\"address\": {\r\n      \"customerAddressId\":\"{{ saved customer address id }}\",\r\n      \"countryId\":\"MY\",\r\n      \"regionId\":\"572\",\r\n      \"regionCode\":\"MLK\",\r\n      \"region\":\"Melaka\",\r\n      \"street\":[  \r\n         \"My home Any Floor, any Tower ,\",\r\n         \"Unknown  Road\"\r\n      ],\r\n      \"telephone\":\"\",\r\n      \"postcode\":\"12345\",\r\n      \"city\":\"Melaka\",\r\n      \"firstname\":\"Vishwas\",\r\n      \"lastname\":\"Bhatnagar\"\r\n   }\r\n}\r\n```\r\nCheck the response of the Call\r\n\r\nExpected result\r\nSuccess and Returns quote address id\r\n\r\nActual result\r\n\r\n> \"message\": \"Unable to save address. Please check input data.\",\r\n>     \"trace\": \"#0 [internal function]: Magento\\\\Quote\\\\Model\\\\BillingAddressManagement->assign(26, Object(Magento\\\\Quote\\\\Model\\\\Quote\\\\Address\\\\Interceptor), false)\\n#1 /vagrant/digi-magento/vendor/magento/module-webapi/Controller/Rest.php(330): calluserfuncarray(Array, Array)\\n#2 /vagrant/digi-magento/vendor/magento/module-webapi/Controller/Rest.php(239): Magento\\\\Webapi\\\\Controller\\\\Rest->processApiRequest()\\n#3 /vagrant/digi-magento/vendor/magento/framework/Interception/Interceptor.php(58): Magento\\\\Webapi\\\\Controller\\\\Rest->dispatch(Object(Magento\\\\Framework\\\\App\\\\Request\\\\Http))\\n#4 /vagrant/digi-magento/vendor/magento/framework/Interception/Interceptor.php(138): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\Interceptor->callParent('dispatch', Array)\\n#5 /vagrant/digi-magento/vendor/magento/framework/Interception/Interceptor.php(153): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\Interceptor->Magento\\\\Framework\\\\Interception\\\\{closure}(Object(Magento\\\\Framework\\\\App\\\\Request\\\\Http))\\n#6 /vagrant/digi-magento/generated/code/Magento/Webapi/Controller/Rest/Interceptor.php(26): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\Interceptor->callPlugins('dispatch', Array, Array)\\n#7 /magento2/vendor/magento/framework/App/Http.php(135)\r\n\r\nand a exception is generated\r\n\r\n> [2018-08-10 07:32:12] report.CRITICAL: No such entity with customerId =  {\"exception\":\"[object] (Magento\\\\Framework\\\\Exception\\\\NoSuchEntityException(code: 0): No such entity with customerId =  at vendor/magento/framework/Exception/NoSuchEntityException.php:50)\"} []\r\n \r\nSame stands for \r\n\r\n- /V1/carts/mine/shipping-information\r\n\r\nAs it is a mine api the customer id should be populated from customer token "},
{"text": "I started seeing the following issue after upgrading to 2.2.5, after reverting back I found the issue was introduced in 2.2.4.\r\n\r\n### Preconditions\r\n1. Magento 2.2.4\r\n2. PHP 7.0\r\n3. MySQL 5.7\r\n4. Allow Anonymous Guest Access = Yes\r\n\r\n### Steps to reproduce\r\n1. Call the following rest API endpoint: `/rest/V1/products?searchCriteria[filtergroups][0][filters][0][field]=name&searchCriteria[filtergroups][0][filters][0][value]=%25name%25&searchCriteria[filtergroups][0][filters][0][conditiontype]=like` \r\nwith \"Accept: text/xml\" header.\r\n2. Change the name value to %25**ad**name%25 - or anything where the name begins with one of the values from this list: https://www.w3schools.com/tags/refurlencode.asp\r\n\r\n### Expected result\r\nYou should receive some response, even if there are no matching products.\r\n\r\n### Actual result\r\nThe following error is returned:\r\n\r\n`string is not in UTF-8 in /var/www/[path to magento]/vendor/magento/framework/Webapi/Rest/Response/Renderer/Xml.php on line 64`\r\n"},
{"text": "###  Background\r\nWe recently updated our system from 2.1.9 to 2.2.4.\r\nA following critical error was introduced, using the built in REST API's as described here: https://devdocs.magento.com/guides/v2.2/rest/performing-searches.html\r\n\r\n### Preconditions\r\n<!---\r\n    Please provide as detailed information about your environment as possible.\r\n    For example Magento version, tag, HEAD, PHP & MySQL version, etc..\r\n-->\r\n1. Magento 2.2.4\r\n2. PHP 7.0\r\n\r\n### Steps to reproduce\r\n<!---\r\n    It is important to provide a set of clear steps to reproduce this bug.\r\n    If relevant please include code samples\r\n-->\r\n1. Query products from `/rest/V1/products?searchCriteria[filtergroups][0][filters][0][field]=name&searchCriteria[filtergroups][0][filters][0][value]=%25car%25&searchCriteria[filtergroups][0][filters][0][conditiontype]=like`\r\n( Note the `%25car%25` in the query.)\r\n\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. Response should filter the string \"%car%\" in product name search criteria\r\n2. I.e `<value>%car%</value>`\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. Instead the string \"\u02b2%\" will end up being used as input.\r\n2. I.e `<value>\u02b2%</value> `\r\n\r\n### Analysis\r\nIt seems that when the `UrlDecoder::decodeParams` is called in `Magento\\Webapi\\Controller\\Rest\\InputParamsResolver::106`, the string is actually already been decoded, so the decoder will end up with `rawurldecode('%car%')` witch will return an unexpected result;"},
{"text": "### Preconditions\r\n\r\n- Magento 2.4-develop;\r\n- Integration created;\r\n\r\n### Steps to reproduce\r\n\r\n1. Create a website with code `wb2`.\r\n2. Create a store `st2` and assign it to the `wb2` website.\r\n3. Create a store view with code `sv2` and assign to the new store.\r\n![image](https://user-images.githubusercontent.com/51680850/82812137-fcb39080-9e9a-11ea-9c69-3538c625a511.png)\r\n\r\n4. Create product and assign only to `wb2` website.\r\n![image](https://user-images.githubusercontent.com/51680850/82813005-e0b0ee80-9e9c-11ea-9a53-f7cf10d56f8c.png)\r\n\r\n5. Perform REST API GET request using the store code in the URL, eg:\r\nGET /rest/`default`/V1/products/?searchCriteria[currentPage]=10\r\n\r\n### Expected result\r\nOnly products assigned to the test website are returned (or no products if none assigned).\r\n\r\n### Actual result\r\nAll products in the Magento instance are returned.\r\n![image](https://user-images.githubusercontent.com/51680850/82812215-2ff61f80-9e9b-11ea-84e5-d45b895c3942.png)\r\n\r\n"},
{"text": "Using SOAP API does not work when sending product updates to second Website.\r\n\r\nFor testing purpose I am using Postman: https://www.getpostman.com/apps   \r\n\r\n2 Website under the same installation.\r\nwebsite 1 url = test.com  (default)\r\nwebsite 2 url = test.co.uk (second website) \r\n### Preconditions\r\n1- Fresh Install Magento2.2.2.\r\n2- Create second Website, second wesbite store and second store view an save, you should have something similar:\r\n```\r\nDefault Config\r\n  Main Website\r\n    Main Website Store\r\n       Default Store View\r\n  Second Website\r\n    Second Website Store\r\n       Second Store View\r\n```\r\n3- go to store->configuration change store view to Second Website \r\n4- in store->configuration->web->baseUrls=> base Url Enter second website url and  base Link url  and do the same for baseUrls(secure).\r\n5- in store->configuration change store view to Second Store view repeat step 4  \r\n6- Create a simple product\r\n7- Goto Sytem->integration and Add New Integration\r\n8- Grab your Access Token.\r\n\r\n### Steps to reproduce\r\nGet Postman or any other soap testing platform and do the following:\r\n1-Choose in the drop down POST and enter the url= **http://test.com/soap/secondstoreviewcode?services=catalogProductRepositoryV1**\r\n2- Add Authorization type: Bearer Token and add Access token you just grabed.\r\n3- Add Body  Raw and Enter your XML REQUEST:\r\n\r\n\r\n`<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n     <soap:Envelope xmlns:def=\"http://test.com/soap/secondstoreviewcode? \r\n     services=catalogProductRepositoryV1\" xmlns:soap=\"http://www.w3.org/2003/05/soap-envelope\">\r\n        <soap:Body>\r\n           <def:catalogProductRepositoryV1SaveRequest> \r\n              <product>\r\n                 <sku>1234567890</sku> \r\n                 <price>99.99</price>\r\n              </product>\r\n          </def:catalogProductRepositoryV1SaveRequest>\r\n      </soap:Body>\r\n </soap:Envelope>`\r\n\r\n\r\n### Expected result\r\n```\r\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<env:Envelope xmlns:env=\"http://www.w3.org/2003/05/soap-envelope\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" \r\nxmlns:ns1=\"http://test.com/soap/secondstoreviewcode?services=catalogProductRepositoryV1\">\r\n    <env:Body>\r\n        <ns1:catalogProductRepositoryV1SaveResponse>\r\n            <result>\r\n                <id>1234</id>\r\n                <sku>1234567890</sku>\r\n                <name>Test-product</name>\r\n                <attributeSetId>2</attributeSetId>\r\n                <price>99.99</price>\r\n                <status>1</status>\r\n                <visibility>1</visibility>\r\n                <typeId>simple</typeId>\r\n                <createdAt>##########</createdAt>\r\n                <updatedAt>##########</updatedAt>\r\n                <extensionAttributes>\r\n                    <websiteIds>\r\n                        <item>1</item>\r\n                        <item>2</item>\r\n                    </websiteIds>\r\n                    <stockItem>\r\n                        <itemId>12345</itemId>\r\n                        <productId>123456</productId>\r\n                        <stockId>1</stockId>\r\n                        <qty/>\r\n                        <isInStock>false</isInStock>\r\n                        <isQtyDecimal>false</isQtyDecimal>\r\n                        <showDefaultNotificationMessage>false</showDefaultNotificationMessage>\r\n                        <useConfigMinQty>true</useConfigMinQty>\r\n                        <minQty>0</minQty>\r\n                        <useConfigMinSaleQty>1</useConfigMinSaleQty>\r\n                        <minSaleQty>1</minSaleQty>\r\n                        <useConfigMaxSaleQty>true</useConfigMaxSaleQty>\r\n                        <maxSaleQty>10000</maxSaleQty>\r\n                        <useConfigBackorders>true</useConfigBackorders>\r\n                        <backorders>0</backorders>\r\n                        <useConfigNotifyStockQty>true</useConfigNotifyStockQty>\r\n                        <notifyStockQty>1</notifyStockQty>\r\n                        <useConfigQtyIncrements>true</useConfigQtyIncrements>\r\n                        <qtyIncrements>0</qtyIncrements>\r\n                        <useConfigEnableQtyInc>true</useConfigEnableQtyInc>\r\n                        <enableQtyIncrements>false</enableQtyIncrements>\r\n                        <useConfigManageStock>true</useConfigManageStock>\r\n                        <manageStock>true</manageStock>\r\n                        <lowStockDate>2018-04-10 20:02:03</lowStockDate>\r\n                        <isDecimalDivided>false</isDecimalDivided>\r\n                        <stockStatusChangedAuto>1</stockStatusChangedAuto>\r\n                    </stockItem>\r\n                </extensionAttributes>\r\n                <productLinks/>\r\n                <options/>\r\n                <mediaGalleryEntries/>\r\n                <tierPrices/>\r\n                <customAttributes>\r\n                    <item>\r\n                        <attributeCode>categoryids</attributeCode>\r\n                        <value/>\r\n                    </item>\r\n                    <item>\r\n                        <attributeCode>optionscontainer</attributeCode>\r\n                        <value>container2</value>\r\n                    </item>\r\n                    <item>\r\n                        <attributeCode>requiredoptions</attributeCode>\r\n                        <value>0</value>\r\n                    </item>\r\n                    <item>\r\n                        <attributeCode>hasoptions</attributeCode>\r\n                        <value>0</value>\r\n                    </item>\r\n                    <item>\r\n                        <attributeCode>urlkey</attributeCode>\r\n                        <value>test-product</value>\r\n                    </item>\r\n                    <item>\r\n                        <attributeCode>taxclassid</attributeCode>\r\n                        <value>2</value>\r\n                    </item>\r\n                    <item>\r\n                        <attributeCode>size</attributeCode>\r\n                        <value>1036</value>\r\n                    </item>\r\n                    <item>\r\n                        <attributeCode>color</attributeCode>\r\n                        <value>1076</value>\r\n                    </item>\r\n                </customAttributes>\r\n            </result>\r\n        </ns1:catalogProductRepositoryV1SaveResponse>\r\n    </env:Body>\r\n</env:Envelope>\r\n```\r\n### Actual result\r\n```\r\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<env:Envelope xmlns:env=\"http://www.w3.org/2003/05/soap-envelope\">\r\n    <env:Body>\r\n        <env:Fault>\r\n            <env:Code>\r\n                <env:Value>rpc:ProcedureNotPresent</env:Value>\r\n            </env:Code>\r\n            <env:Reason>\r\n                <env:Text>Procedure not present</env:Text>\r\n            </env:Reason>\r\n        </env:Fault>\r\n    </env:Body>\r\n</env:Envelope>\r\n```\r\nScreen shoot for ref:\r\n\r\n![screen shot 2018-04-10 at 21 10 39](https://user-images.githubusercontent.com/3495481/38581082-a5bc8584-3d03-11e8-9803-cfd800dce10d.png)\r\n\r\nThanks.\r\n\r\n"},
{"text": "### Preconditions\r\n1. Magento 2.2.5\r\n2. PHP 7.0\r\n3. MySQL 5.7\r\n\r\n### Steps to reproduce\r\n1. Create a new customer account\r\n2. Login with that customer using the default Magento frontend\r\n3. View the customer in the Magento admin area, and note that the Last Logged In value has been updated\r\n4. Request a customer token via this API endpoint: `/rest/V1/integration/customer/token`\r\n\r\n### Expected result\r\nRequesting the customer token should also update the last logged in value.\r\n\r\n### Actual result\r\nLast logged In value does not get updated.\r\n"},
{"text": "<!---\r\n    Thank you for contributing to Magento.\r\n    To help us process this issue we recommend that you add the following information:\r\n     - Summary of the issue,\r\n     - Information on your environment,\r\n     - Steps to reproduce,\r\n     - Expected and actual results,\r\n\r\n    Please also have a look at our guidelines article before adding a new issue https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\n-->\r\n\r\n### Preconditions\r\n<!---\r\n    Please provide as detailed information about your environment as possible.\r\n    For example Magento version, tag, HEAD, PHP & MySQL version, etc..\r\n-->\r\n1. Magento 2.2.2 \r\n\r\n### Steps to reproduce\r\n<!---\r\n    It is important to provide a set of clear steps to reproduce this bug.\r\n    If relevant please include code samples\r\n-->\r\n1. Generate cart using POST rest/V1/guest-carts\r\n2. Add product to cart POST rest/V1/guest-carts/[cart-id]/items\r\n**REQUEST** \r\n`\r\n{\r\n  \"cartItem\": {\r\n    \"sku\": \"[sku]\",\r\n    \"qty\": 1,\r\n    \"quoteid\": \"[cart-id]\"\r\n  }\r\n}\r\n`\r\n3. Make a request to endpoint POST rest/V1/guest-carts/[:cart-id]/shipping-information \r\n**REQUEST** \r\n```\r\n{\r\n  \"addressInformation\":{\r\n    \"shippingAddress\":{\r\n        \"countryid\":\"IN\",\r\n        \"region\":\"XYZ\",\r\n        \"regionid\":0,\r\n          \"street\":[\"test\"],\r\n        \"telephone\":\"99040503256\",\r\n          \"postcode\":\"1234\",\r\n        \"city\":\"\",\r\n        \"firstname\":\"Kandarp\",\r\n        \"lastname\":\"Patel\",\r\n        \"middlename\":\"Test\"\r\n    },\r\n    \r\n    \"shippingmethodcode\":\"flatrate\",\r\n    \"shippingcarriercode\":\"flatrate\"\r\n  }\r\n}\r\n\r\n````\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. API should not allow the save shipping address as city is blank. \r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. API allow to save save shipping address.\r\n"},
{"text": "**Preconditions**\r\n1.\tMagento CE 2.2.5\r\n2.\tPHP 7.1\r\n**Steps to reproduce**\r\n1.\tCreate product using default Magento REST API /rest/V1/products with the string {\"product\":{\"id\":\"\",\"sku\":\"DTD-1\",\"name\":\"DTD Descrption\",\"price\":45,\"typeId\":\"simple\",\"weight\":\"0.25\",\"attributesetid\":4}}\r\n2.\tProduct created in Magento and provided attributes set for Default store view as well as All store views\r\n3.\tNow update the created product by changing product\u2019s description by using same REST API /rest/V1/products with the following string {\"product\":{\"id\":\"2057\",\"sku\":\"DTD-1\",\"name\":\"DTD\",\"price\":45,\"typeId\":\"simple\",\"weight\":\"0.25\",\"attributesetid\":4}} [\"id\" is created product\u2019s id]\r\n4.\tCheck if the product description updated in All store views\r\n**Expected result**\r\n1.\tThe description should be updated in All store views as well as Default store view\r\n**Actual result**\r\n1.\tThe description is updating in Default store view only, not updating in All store views\r\n**Note:**\r\nWe are facing same issue with product which is created programmatically.\r\n"},
{"text": "### Additional information\r\n\r\ntest case steps description : https://github.com/magento/magento2/issues/17186#issuecomment-528501666\r\n\r\n<!---\r\n    Thank you for contributing to Magento.\r\n    To help us process this issue we recommend that you add the following information:\r\n     - Summary of the issue,\r\n     - Information on your environment,\r\n     - Steps to reproduce,\r\n     - Expected and actual results,\r\n\r\n    Please also have a look at our guidelines article before adding a new issue https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\n-->\r\n\r\n### Preconditions\r\n<!---\r\n    Please provide as detailed information about your environment as possible.\r\n    For example Magento version, tag, HEAD, PHP & MySQL version, etc..\r\n-->\r\n1. Magento 2.2.3 & 2.3.x\r\n\r\n### Steps to reproduce\r\n<!---\r\n    It is important to provide a set of clear steps to reproduce this bug.\r\n    If relevant please include code samples\r\n-->\r\n1. Send REST PUT request to translate category name in specific store view : {{BaseURL}}rest/{{codeStoreView}}/V1/categories/{id}\r\n\r\n`{\r\n\t\"saveOptions\": true,\r\n\t\"category\": {\r\n\t\t\"id\": 3,\r\n\t\t\"name\": \"New Category Name Translated\"\r\n\t}\r\n}`\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. It should only update the category name field and create only one row in database for the specific store view\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. The request uncheck Enable Category, Include in Menu, Category Image, etc... attributes and create multiple rows in database for the specific store view\r\n"},
{"text": "The Get endpoint from catalogProductAttributeManagementV1 of REST API returns Array instead of defined Boolean for options: isdefault. I think array would be fine but should also be defined correctly in Swagger definition.\r\n\r\n### Preconditions\r\nMagento 2.2.5\r\nLinux\r\nApache 2.2.31 (Unix) modfastcgi\r\nPHP 7.0.30\r\nMySQL 5.6.23-72.1\r\n\r\n### Steps to reproduce\r\nPrerequsite: Installation with multiple Store Views and attribute countryofmanufacture with different default options per store view\r\nREST Request on catalogProductAttributeManagementV1 (Get) for attribute set that has attribute countryofmanufacture included\r\n\r\n### Expected result\r\nSwagger defines field isdefault as boolean:\r\n```\r\n[\r\n  {\r\n    ...\r\n    \"options\": [\r\n      {\r\n        ...\r\n        \"isdefault\": true,\r\n        ...\r\n```\r\n### Actual result\r\nMagento returns array of store view Id's which has option as default:\r\n```\r\n...\r\n  {\r\n    \"attributeid\": 609,\r\n    \"attributecode\": \"countryofmanufacture\",\r\n    \"frontendinput\": \"select\",\r\n    \"entitytypeid\": \"4\",\r\n    \"isrequired\": false,\r\n    \"options\": [\r\n      ...\r\n      {\r\n        \"label\": \"Deutschland\",\r\n        \"value\": \"DE\",\r\n        \"isdefault\": [ \"2\" ]\r\n      },\r\n      ...\r\n      {\r\n        \"label\": \"Schweden\",\r\n        \"value\": \"SE\"\r\n      },\r\n      ...\r\n      {\r\n        \"label\": \"Schweiz\",\r\n        \"value\": \"CH\",\r\n        \"isdefault\": [ \"1\", \"4\", \"8\", \"9\", \"10\", \"11\", \"12\" ]\r\n      },\r\n...\r\n```"},
{"text": "<!---\r\n    Thank you for contributing to Magento.\r\n    To help us process this issue we recommend that you add the following information:\r\n     - Summary of the issue,\r\n     - Information on your environment,\r\n     - Steps to reproduce,\r\n     - Expected and actual results,\r\n\r\n    Please also have a look at our guidelines article before adding a new issue https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\n-->\r\n\r\n### Preconditions\r\n<!---\r\n    Please provide as detailed information about your environment as possible.\r\n    For example Magento version, tag, HEAD, PHP & MySQL version, etc..\r\n-->\r\n1. Magento 2.2.3\r\n2. 10.0.32-MariaDB-0\r\n\r\n\r\n\r\n### Steps to reproduce\r\n<!---\r\n    It is important to provide a set of clear steps to reproduce this bug.\r\n    If relevant please include code samples\r\n-->\r\n1. Get request to GET    /V1/guest-carts/:cartId/payment-information working fine\r\n2. While post request for the same POST   /V1/guest-carts/:cartId/payment-information showing  \"The payment method you requested is not available.\"\r\n3. Although the payment method used is taken from the get method result.\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. [Screenshots, logs or description]\r\n![getrequest](https://user-images.githubusercontent.com/24405051/42289275-469ba320-7fdc-11e8-9408-4dd76fc2105a.png)\r\n![postrequest](https://user-images.githubusercontent.com/24405051/42289284-5420ce1c-7fdc-11e8-8f06-43af1eafb8cc.png)\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. [Screenshots, logs or description]\r\n"},
{"text": "### Preconditions\r\nMagento 2.2.2 with one website, one store and two storeviews on ubuntu/nginx/php7\r\n\r\n### Steps to reproduce\r\n- call soap service and pass the data of the product you want to create: \r\n$newproductdata = array(\r\n\t'sku' => 'prodotto7',\r\n\t'name' => 'Prodotto7',\r\n\t'attributeSetId' => 4,\r\n\t'visibility' => 4,\r\n\t'typeId' => 'simple',\r\n\t'price' => '50',\r\n\t'status' => 1,\r\n\t'weight' => '1',\r\n\t'customattributes' => [\r\n\t\t['attributecode' => 'description', 'value' => 'Test Description' ],\r\n\t\t['attributecode' => 'shortdescription', 'value' => 'Test Short Description' ],\r\n\t],\r\n);\r\n$soapClient = new SoapClient(\"$baseurl=catalogProductRepositoryV1\", $options);\r\n$response = $soapClient->catalogProductRepositoryV1save(array('product' => $newproductdata));\r\n\r\n### Expected result\r\nproduct is created with description and short description\r\n\r\n### Actual result\r\nproduct is created but description, short description and all other parameters set in customattributes (eg category ids) are not present\r\n\r\n"},
{"text": "<!---\r\n    Thank you for contributing to Magento.\r\n    To help us process this issue we recommend that you add the following information:\r\n     - Summary of the issue,\r\n     - Information on your environment,\r\n     - Steps to reproduce,\r\n     - Expected and actual results,\r\n\r\n    Please also have a look at our guidelines article before adding a new issue https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\n-->\r\n\r\n### Preconditions\r\n<!---\r\n    Please provide as detailed information about your environment as possible.\r\n    For example Magento version, tag, HEAD, PHP & MySQL version, etc..\r\n-->\r\n1. Magento 2.2.5\r\n2. php 7.0.30\r\n\r\n### Steps to reproduce\r\n<!---\r\n    It is important to provide a set of clear steps to reproduce this bug.\r\n    If relevant please include code samples\r\n-->\r\n1. Hit Product rest api for 200k products with pageSize = 0 to return full 200k items.\r\n2. Consumer Key : **[redacted]**\r\n3. Consumer Secret : **[redacted]**\r\n4. Access Token : **[redacted]**\r\n5. Access Token Secret : **[redacted]**\r\n\r\n `$requestUrl='**[redacted]**/rest/V1/products?searchCriteria=0&searchCriteria[filtergroups][0][filters][0][field]=visibility&searchCriteria[filtergroups][0][filters][0][value]=4&searchCriteria[filtergroups][0][filters][0][conditiontype]=eq'\r\n\r\n\t\t\t$ch = curlinit($requestUrl);\r\n\t\t\tcurlsetopt($ch, CURLOPTCUSTOMREQUEST, \"GET\");\r\n\t\t\tcurlsetopt($ch, CURLOPTHTTPHEADER, array(\"Content-Type: application/json\",\"Authorization: Bearer  **[redacted]**\"));\r\n\t\t\tcurlsetopt($ch, CURLOPTRETURNTRANSFER, true);\r\n\t\t\t$result = curlexec($ch);\r\n\t\t\t$result = jsondecode($result,true);\r\n                        echo 'Items Count =>  '.count($result['items']);\r\n`\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. [Return the items requested on the api]\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. [Blank page with no errors and no result]\r\n"},
{"text": "Magento 2.2.4\r\n\r\n### Preconditions\r\n\r\nI need to find all product in categories so I user a \"searchCriteria\" with a unique \"filterGroups\" and one \"filter\" foreach categories wanted call  /V1/products resource (rest api). \r\nIn the old server with Magento 2.0 it works great, now we upgrade server and Magento if i search by more categories (or conditions) doesn't work.\r\n\r\n### Steps to reproduce\r\n\r\n1. Create some categories (two or tre)\r\n2. Create come products foreach category\r\n3. Enable a REST API token\r\n4. Make a call to resource \"/V1/products\" with a search parameter like this:\r\n\r\n```\r\n[\"searchCriteria\"]=>\r\n  array(1) {\r\n    [\"filterGroups\"]=>\r\n    array(1) {\r\n      [1]=>\r\n      array(1) {\r\n        [\"filters\"]=>\r\n        array(2) {\r\n          [0]=>\r\n          array(3) {\r\n            [\"field\"]=>\r\n            string(11) \"categoryid\"\r\n            [\"value\"]=>\r\n            string(3) \"{id category 1}\"\r\n          }\r\n          [1]=>\r\n          array(3) {\r\n            [\"field\"]=>\r\n            string(11) \"categoryid\"\r\n            [\"value\"]=>\r\n            string(3) \"{id category 2}\"\r\n          }\r\n        }\r\n      }\r\n    }\r\n  }\r\n```\r\n\r\n### Expected result\r\n\r\nThis condition should be return all products in category **{id category 1} OR {id category 2}** \r\n\r\n### Actual result\r\nGenerally empty list of products, some time only products in the last category in query.\r\n\r\n\r\nThanks"},
{"text": "<!---\r\n    Thank you for contributing to Magento.\r\n    To help us process this issue we recommend that you add the following information:\r\n     - Summary of the issue,\r\n     - Information on your environment,\r\n     - Steps to reproduce,\r\n     - Expected and actual results,\r\n\r\n    Please also have a look at our guidelines article before adding a new issue https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\n-->\r\n\r\nWe would like to be able to assign websites when creating a product.\r\nThis is not possible in Magento C.E. 2.2.4 and older. \r\n\r\n### Preconditions\r\n<!---\r\n    Please provide as detailed information about your environment as possible.\r\n    For example Magento version, tag, HEAD, PHP & MySQL version, etc..\r\n-->\r\n1.  Magento ver. 2.2.4\r\n2.  Postman 6.0.10\r\n\r\n### Steps to reproduce\r\n<!---\r\n    It is important to provide a set of clear steps to reproduce this bug.\r\n    If relevant please include code samples\r\n-->\r\n1. Create a second website in Magento.\r\n\r\n2. Create a product and set extensionattributes, websiteids to 2\r\n![afbeelding](https://user-images.githubusercontent.com/7535994/41466250-bffbf412-70a1-11e8-8229-f082b8079752.png)\r\n3. Create another product in website 1\r\n![afbeelding](https://user-images.githubusercontent.com/7535994/41466369-458d2af6-70a2-11e8-9414-dbbfc454faa9.png)\r\n\r\nNOTE: it's doesnt matter if we used storeview all or not. In this case it has the same behavior. I just expected as in #11324 that we should use storeview all when assigning websites. \r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. Create the product in websites with the id's that are given. not to all websites.\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. Product was created in all websites.\r\n"},
{"text": "### Preconditions\r\n1. Magento 2.2.3/2.2.4\r\n2. Create regular downloadable product, upload downloadable content\r\n\r\n### Steps to reproduce\r\n1. Update downloadable product via REST API with call: PUT rest/V1/products/{sku}:\r\n```\r\n{\r\n  \"product\": {\r\n    \"name\": \"BasicBeginner's Yoga (updated)\"\r\n  }\r\n}\r\n```\r\n\r\n### Expected result\r\n1. Product attributes specified in request updated, other data remain unchanged\r\n\r\n### Actual result\r\n1. After update product has no links to download content (no downloadable information).\r\n\r\n<img width=\"1086\" alt=\"beginnersyogaproductsinventorycatalogmagentoadminafter\" src=\"https://user-images.githubusercontent.com/1716535/41085748-8cee6b16-6a40-11e8-8c79-d72c1adbb2e6.png\">\r\n"},
{"text": "<!---\r\n    Thank you for contributing to Magento.\r\n    To help us process this issue we recommend that you add the following information:\r\n     - Summary of the issue,\r\n     - Information on your environment,\r\n     - Steps to reproduce,\r\n     - Expected and actual results,\r\n\r\n    Please also have a look at our guidelines article before adding a new issue https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\n-->\r\n\r\n### Preconditions\r\n<!---\r\n    Please provide as detailed information about your environment as possible.\r\n    For example Magento version, tag, HEAD, PHP & MySQL version, etc..\r\n-->\r\n1. Magento version: 2.3\r\n2. PHP: 7.1.18\r\n3. Server: nginx, version: 1.12.2\r\n\r\n### Steps to reproduce\r\n<!---\r\n    It is important to provide a set of clear steps to reproduce this bug.\r\n    If relevant please include code samples\r\n-->\r\n1. Create empty Magento 2.3 instance\r\n2. Install sample data from repo\r\n3. Using graphql client/plugin of your choice (tested on many of them, always with the same result) send POST request to http://[your Magento instance]/index.php/graphql\r\n```graphql\r\nquery GetProductsQuery($page: Int, $filterInput: ProductFilterInput){\r\n  products(\r\n    pageSize: 10\r\n    currentPage: $page\r\n    filter: $filterInput\r\n    sort: {}\r\n  ) {\r\n    items {\r\n    \tname\r\n    }\r\n  }\r\n}\r\n```\r\nwith variables:\r\n```json\r\n{\r\n  \"page\": 1,\r\n  \"price\": {\r\n    \"gt\": \"10\"\r\n  }\r\n}\r\n```\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. Query should return filtered products list, since `ProductFilterInput` is an input type, according to scheme\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. Received following error:\r\n```\r\nVariable \"$filterInput\" cannot be non-input type \"ProductFilterInput\".\r\nVariable \"$filterInput\" of type \"ProductFilterInput\" used in position expecting type \"ProductFilterInput\".\r\n```\r\n\r\nI've tested this approach on clean GraphQL installation and it worked without any problem.\r\n"},
{"text": "### Preconditions (*)\r\n\r\n1. Error occourds in 2.1.14, but I can reproduce this also in 2.3-develop\r\n2. at least two store views. Default store-view locale != second store view\r\n3. It doesn't matter, if you have one or multiple stores\r\n\r\n### Steps to reproduce (*)\r\n1. Configure stores. I use Store-View \"default\" with locale enUS and StoreView \"second\" with locale deDE\r\n2. Use something, that returns magento phrase (I wrote a test module here: https://github.com/jwundrak/magento2-api-locale )\r\n3. Call rest API (with the module /rest/second/V1/localeTest)\r\n\r\n### Actual result (*)\r\n\r\nOutput of the test module:\r\n~~~\r\n{\r\n    \"locale\": \"enUS\",\r\n    \"testtranslation\": \"Category\",\r\n    \"storecode\": \"second\",\r\n    \"storelocale\": \"deDE\"\r\n}\r\n~~~\r\n\r\n### Expected result (*)\r\n\r\nOutput of the test module:\r\n~~~\r\n{\r\n    \"locale\": \"deDE\",\r\n    \"testtranslation\": \"Kategorie\",\r\n    \"storecode\": \"second\",\r\n    \"storelocale\": \"deDE\"\r\n}\r\n~~~\r\n\r\n### Possible solution\r\n\r\nIn `\\Magento\\Webapi\\Controller\\PathProcessor::process` I start an emulation of the locale: `$this->localeResolver->emulate($this->storeManager->getStore()->getId());` . I'm not sure, if this is the correct way, but works here in 2.1 and 2.3: https://gist.github.com/jwundrak/11ea7ca0b5c6cea57d3b7c8133548634"},
{"text": "\r\n### Preconditions (*)\r\nMagento 2 All Versions.\r\n\r\n### Steps to reproduce (*)\r\n1. Create an attribute (select or multiselect) from the backend (example: attributecode = brandnumber)\r\n2. add new Option to this attribute from the backend (12345)\r\n3. Add new Option to this attribute by the REST API (endpoint : /V1/products/attributes/brandnumber/options), json = {\"option\":{\"label\":\"012345\"}} \r\n\r\n### Expected result (*)\r\n1. the expected result to have two options (12345 and 012345).\r\n\r\n### Actual result (*)\r\n1. the endpoint return false and the option does not created\r\n\r\n### Fix the issue \r\n1. You need to go to this file Magento\\Catalog\\Model\\Product\\Attribute\\OptionManagement\r\n2. go to the \"add\" function.\r\n3. add \"true\" to the inarray condition\r\n\r\n### Current Code\r\n ```bash\r\n /**\r\n     * {@inheritdoc}\r\n     */\r\n    public function add($attributeCode, $option)\r\n    {\r\n        /** @var \\Magento\\Eav\\Api\\Data\\AttributeOptionInterface[] $currentOptions */\r\n        $currentOptions = $this->getItems($attributeCode);\r\n        if (isarray($currentOptions)) {\r\n            arraywalk($currentOptions, function (&$attributeOption) {\r\n                /** @var \\Magento\\Eav\\Api\\Data\\AttributeOptionInterface $attributeOption */\r\n                    $attributeOption = $attributeOption->getLabel();\r\n            });\r\n            if (inarray($option->getLabel(), $currentOptions)) {\r\n                return false;\r\n            }\r\n        }\r\n        return $this->eavOptionManagement->add(\r\n            \\Magento\\Catalog\\Api\\Data\\ProductAttributeInterface::ENTITYTYPECODE,\r\n            $attributeCode,\r\n            $option\r\n        );\r\n    }\r\n ```\r\n \r\n### Working Code\r\n ```bash\r\n/**\r\n     * {@inheritdoc}\r\n     */\r\n    public function add($attributeCode, $option)\r\n    {\r\n        /** @var \\Magento\\Eav\\Api\\Data\\AttributeOptionInterface[] $currentOptions */\r\n        $currentOptions = $this->getItems($attributeCode);\r\n        if (isarray($currentOptions)) {\r\n            arraywalk($currentOptions, function (&$attributeOption) {\r\n                /** @var \\Magento\\Eav\\Api\\Data\\AttributeOptionInterface $attributeOption */\r\n                    $attributeOption = $attributeOption->getLabel();\r\n            });\r\n            if (inarray($option->getLabel(), $currentOptions,true)) {\r\n                return false;\r\n            }\r\n        }\r\n        return $this->eavOptionManagement->add(\r\n            \\Magento\\Catalog\\Api\\Data\\ProductAttributeInterface::ENTITYTYPECODE,\r\n            $attributeCode,\r\n            $option\r\n        );\r\n    }\r\n ```"},
{"text": "### Preconditions\r\n1. Vanilla Magento 2.2.6 \r\n2. PHP Version 7.0.31\r\n\r\n### Steps to reproduce\r\n1.  Create a customer via Backend with the last name \"Foo & Bar Corp\"\r\n2. Create an order (via frontend is fine)\r\n3. Export the order via XML interfcae\r\n\r\n```\r\ncurl -XPOST -H 'Content-Type: application/json' http://hostname/rest/V1/integration/admin/token -d '{ \"username\": \"adminusername\", \"password\": \"adminpassword\" }'\r\nexport B=code received above\r\n curl -X GET --header \"Accept: application/xml\" --header \"Authorization: Bearer $B\" \"http://hostname/rest/english/V1/orders/1\"\r\n```\r\n\r\n### Expected result\r\nThe `customerlastname` tag should contain `Foo &amp; Bar Corp`\r\n\r\n### Actual result\r\nThe `customerlastname` tag contains `Foo &amp;amp Bar Corp`\r\n\r\n### Summary\r\nSo I think at some point (2014) there was a bug in PHP (SimpleXML) that contained the issue with the ampersand, so that was a fix so that this won't influence any functionality. Currently, on 7.0+ this fix doesn't make sense and creates an error. \r\n\r\n### Proposed solution\r\n`Magento\\Framework\\Webapi\\Rest\\Response\\Renderer` class, `formatValue` method. Delete the replacement of the ampersand. This solves the issue.\r\n"},
{"text": "<!---\r\n    Thank you for contributing to Magento.\r\n    To help us process this issue we recommend that you add the following information:\r\n     - Summary of the issue,\r\n     - Information on your environment,\r\n     - Steps to reproduce,\r\n     - Expected and actual results,\r\n\r\n    Please also have a look at our guidelines article before adding a new issue https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\n-->\r\n\r\n### Preconditions\r\n<!---\r\n    Please provide as detailed information about your environment as possible.\r\n    For example Magento version, tag, HEAD, PHP & MySQL version, etc..\r\n-->\r\n1. Magento 2.\r\n\r\n### Steps to reproduce\r\n<!---\r\n    It is important to provide a set of clear steps to reproduce this bug.\r\n    If relevant please include code samples\r\n-->\r\n1. Create an Order.\r\n2. Note the Order Increment ID\r\n3. Update order via REST API:\r\n`POST http://ce.dev.local/rest/V1/orders`\r\n`Accept: */*`\r\n`Cache-Control: no-cache`\r\n`Content-Type: application/json`\r\n`Authorization: Bearer <API key>`\r\n`{`\r\n  `\"entity\": {`\r\n   `\"entityId\": \"<Order ID>\",`\r\n   `\"state\": \"complete\",`\r\n    `\"status\": \"complete\"`\r\n  `}`\r\n`}`\r\n\r\n\r\n### Expected result\r\n<!--- Tell us what should happen -->\r\n1. Order Increment ID remains the same.\r\n\r\n### Actual result\r\n<!--- Tell us what happens instead -->\r\n1. Order Increment ID is changed."},
{"text": "### Preconditions (*)\r\n1. Magento v2.3.0\r\n\r\n### Steps to reproduce (*)\r\n1. Have two different custom modules i.e. `app/code/CustomModule/Module1` & `app/code/CustomModule/Module2`\r\n2. In each add custom attributes:\r\nin `Module1/etc/extensionattributes.xml`\r\n```\r\n<?xml version=\"1.0\"?>\r\n<config xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\r\n        xsi:noNamespaceSchemaLocation=\"urn:magento:framework:Api/etc/extensionattributes.xsd\">\r\n    <extensionattributes for=\"Magento\\Customer\\Api\\Data\\CustomerInterface\">\r\n        <attribute code=\"defaultphone\" type=\"string\"/>\r\n    </extensionattributes>\r\n</config>\r\n```\r\nin `Module2/etc/extensionattributes.xml`\r\n```\r\n<?xml version=\"1.0\"?>\r\n<config xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\r\n        xsi:noNamespaceSchemaLocation=\"urn:magento:framework:Api/etc/extensionattributes.xsd\">\r\n\r\n    <extensionattributes for=\"\\Magento\\Customer\\Api\\Data\\CustomerInterface\">\r\n        <attribute code=\"customattribute\" type=\"string\"/>\r\n        <attribute code=\"othercustomattribute\" type=\"string\"/>\r\n    </extensionattributes>\r\n\r\n</config>\r\n```\r\n3. For both modules, update the `Setup/InstallData.php` to add the fields in the admin panel\r\n4. Through a custom api endpoint post request, I correctly save the data in the correct fields (once I check into the customer admin panel attributes form, I can see the correct data saved in the correct place)\r\n\r\n### Expected result (*)\r\n1. After posting the custom attribute to the customer, calling `/V1/customers/me` returns a  json object that has the correct data (i.e. defaultphone: **defaultphonevalue**)\r\n\r\n### Actual result (*)\r\n1. After posting the custom attribute to the customer, calling `/V1/customers/me` returns a  json object that has the wrong data (i.e. defaultphone: **customattrbutevalue**)\r\n\r\n"},
{"text": "     - Summary of the issue,\r\n\r\nPOST on /orders succeeds or fails using semantically equivalent json body but different ordering of properties. \r\nJSON data never has a guaranteed property order. Many systems use maps with undefined iteration order to form the data.\r\n\r\n     - Information on your environment,\r\n\r\nMagento 2.3 on Ubuntu.\r\n\r\n     - Steps to reproduce,\r\n\r\nIssue Swagger or Curl calls using the attached json data. One will succeed and the other woll fail even though the data is semantically equivalent and only different in the ordering of properties. See more details below.\r\n\r\n     - Expected and actual results,\r\n\r\nBoth calls should succeed, return identical response and create the same order.\r\n\r\n-->\r\n\r\n### Preconditions (*)\r\n\r\n1. Magento 2.3\r\n2. Ubuntu \r\n \r\n\r\n### Steps to reproduce (*)\r\nUse Swagger or Curl to issue a POST on /orders with these json payloads. They only differ in how the properties are ordered. You will probably need to adapt the content to use a customerid that exists on your system.\r\n\r\n[badjson.txt](https://github.com/magento/magento2/files/3213652/badjson.txt)\r\n[goodjson.txt](https://github.com/magento/magento2/files/3213655/goodjson.txt)\r\n\r\n1. good.json\r\nPOST succeeds.\r\n\r\n2. bad.json\r\nPOST fails:\r\n{\r\n    \"message\": \"We can't save the address:\\n%1\",\r\n    \"parameters\": [\r\n        \"Email has a wrong format\"\r\n    ],\r\n    \"trace\": \"#0 /var/www/html/magento2/vendor/magento/framework/Model/ResourceModel/Db/AbstractDb.php(410): Magento\\\\Sales\\\\Model\\\\ResourceModel\\\\Order\\\\Address->beforeSave(Object(Magento\\\\Sales\\\\Model\\\\Order\\\\Address))\\n#1 /var/www/html/magento2/vendor/magento/framework/Model/AbstractModel.php(648): Magento\\\\Framework\\\\Model\\\\ResourceModel\\\\Db\\\\AbstractDb->save(Object(Magento\\\\Sales\\\\Model\\\\Order\\\\Address))\\n#2 /var/www/html/magento2/vendor/magento/module-sales/Model/ResourceModel/Order/Handler/Address.php(63): Magento\\\\Framework\\\\Model\\\\AbstractModel->save()\\n#3 /var/www/html/magento2/vendor/magento/framework/Interception/Interceptor.php(58): Magento\\\\Sales\\\\Model\\\\ResourceModel\\\\Order\\\\Handler\\\\Address->process(Object(Magento\\\\Sales\\\\Model\\\\Order\\\\Interceptor))\\n#4 /var/www/html/magento2/vendor/magento/framework/Interception/Interceptor.php(138): Magento\\\\Sales\\\\Model\\\\ResourceModel\\\\Order\\\\Handler\\\\Address\\\\Interceptor->callParent('process', Array)\\n#5 /var/www/html/magento2/vendor/magento/framework/Interception/Interceptor.php(153): Magento\\\\Sales\\\\Model\\\\ResourceModel\\\\Order\\\\Handler\\\\Address\\\\Interceptor->Magento\\\\Framework\\\\Interception\\\\{closure}(Object(Magento\\\\Sales\\\\Model\\\\Order\\\\Interceptor))\\n#6 /var/www/html/magento2/generated/code/Magento/Sales/Model/ResourceModel/Order/Handler/Address/Interceptor.php(39): Magento\\\\Sales\\\\Model\\\\ResourceModel\\\\Order\\\\Handler\\\\Address\\\\Interceptor->callPlugins('process', Array, Array)\\n#7 /var/www/html/magento2/vendor/magento/module-sales/Model/ResourceModel/Order/Relation.php(98): Magento\\\\Sales\\\\Model\\\\ResourceModel\\\\Order\\\\Handler\\\\Address\\\\Interceptor->process(Object(Magento\\\\Sales\\\\Model\\\\Order\\\\Interceptor))\\n#8 /var/www/html/magento2/vendor/magento/framework/Model/ResourceModel/Db/VersionControl/RelationComposite.php(48): Magento\\\\Sales\\\\Model\\\\ResourceModel\\\\Order\\\\Relation->processRelation(Object(Magento\\\\Sales\\\\Model\\\\Order\\\\Interceptor))\\n#9 /var/www/html/magento2/vendor/magento/framework/Model/ResourceModel/Db/VersionControl/AbstractDb.php(57): Magento\\\\Framework\\\\Model\\\\ResourceModel\\\\Db\\\\VersionControl\\\\RelationComposite->processRelations(Object(Magento\\\\Sales\\\\Model\\\\Order\\\\Interceptor))\\n#10 /var/www/html/magento2/vendor/magento/framework/Model/ResourceModel/Db/AbstractDb.php(419): Magento\\\\Framework\\\\Model\\\\ResourceModel\\\\Db\\\\VersionControl\\\\AbstractDb->processAfterSaves(Object(Magento\\\\Sales\\\\Model\\\\Order\\\\Interceptor))\\n#11 /var/www/html/magento2/vendor/magento/module-sales/Model/ResourceModel/Order.php(178): Magento\\\\Framework\\\\Model\\\\ResourceModel\\\\Db\\\\AbstractDb->save(Object(Magento\\\\Sales\\\\Model\\\\Order\\\\Interceptor))\\n#12 /var/www/html/magento2/generated/code/Magento/Sales/Model/ResourceModel/Order/Interceptor.php(37): Magento\\\\Sales\\\\Model\\\\ResourceModel\\\\Order->save(Object(Magento\\\\Sales\\\\Model\\\\Order\\\\Interceptor))\\n#13 /var/www/html/magento2/vendor/magento/module-sales/Model/OrderRepository.php(168): Magento\\\\Sales\\\\Model\\\\ResourceModel\\\\Order\\\\Interceptor->save(Object(Magento\\\\Sales\\\\Model\\\\Order\\\\Interceptor))\\n#14 /var/www/html/magento2/vendor/magento/framework/Interception/Interceptor.php(58): Magento\\\\Sales\\\\Model\\\\OrderRepository->save(Object(Magento\\\\Sales\\\\Model\\\\Order\\\\Interceptor))\\n#15 /var/www/html/magento2/vendor/magento/framework/Interception/Interceptor.php(138): Magento\\\\Sales\\\\Model\\\\OrderRepository\\\\Interceptor->callParent('save', Array)\\n#16 /var/www/html/magento2/vendor/magento/framework/Interception/Interceptor.php(153): Magento\\\\Sales\\\\Model\\\\OrderRepository\\\\Interceptor->Magento\\\\Framework\\\\Interception\\\\{closure}(Object(Magento\\\\Sales\\\\Model\\\\Order\\\\Interceptor))\\n#17 /var/www/html/magento2/generated/code/Magento/Sales/Model/OrderRepository/Interceptor.php(78): Magento\\\\Sales\\\\Model\\\\OrderRepository\\\\Interceptor->callPlugins('save', Array, Array)\\n#18 [internal function]: Magento\\\\Sales\\\\Model\\\\OrderRepository\\\\Interceptor->save(Object(Magento\\\\Sales\\\\Model\\\\Order\\\\Interceptor))\\n#19 /var/www/html/magento2/vendor/magento/module-webapi/Controller/Rest/SynchronousRequestProcessor.php(95): calluserfuncarray(Array, Array)\\n#20 /var/www/html/magento2/vendor/magento/module-webapi/Controller/Rest.php(188): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\SynchronousRequestProcessor->process(Object(Magento\\\\Framework\\\\Webapi\\\\Rest\\\\Request\\\\Proxy))\\n#21 /var/www/html/magento2/vendor/magento/framework/Interception/Interceptor.php(58): Magento\\\\Webapi\\\\Controller\\\\Rest->dispatch(Object(Magento\\\\Framework\\\\App\\\\Request\\\\Http))\\n#22 /var/www/html/magento2/vendor/magento/framework/Interception/Interceptor.php(138): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\Interceptor->callParent('dispatch', Array)\\n#23 /var/www/html/magento2/vendor/magento/framework/Interception/Interceptor.php(153): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\Interceptor->Magento\\\\Framework\\\\Interception\\\\{closure}(Object(Magento\\\\Framework\\\\App\\\\Request\\\\Http))\\n#24 /var/www/html/magento2/generated/code/Magento/Webapi/Controller/Rest/Interceptor.php(26): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\Interceptor->callPlugins('dispatch', Array, Array)\\n#25 /var/www/html/magento2/vendor/magento/framework/App/Http.php(135): Magento\\\\Webapi\\\\Controller\\\\Rest\\\\Interceptor->dispatch(Object(Magento\\\\Framework\\\\App\\\\Request\\\\Http))\\n#26 /var/www/html/magento2/generated/code/Magento/Framework/App/Http/Interceptor.php(24): Magento\\\\Framework\\\\App\\\\Http->launch()\\n#27 /var/www/html/magento2/vendor/magento/framework/App/Bootstrap.php(258): Magento\\\\Framework\\\\App\\\\Http\\\\Interceptor->launch()\\n#28 /var/www/html/magento2/index.php(39): Magento\\\\Framework\\\\App\\\\Bootstrap->run(Object(Magento\\\\Framework\\\\App\\\\Http\\\\Interceptor))\\n#29 {main}\"\r\n}\r\n\r\n```\r\n### Expected result (*)\r\nBoth calls should succeed, return identical response and create the same sales order.\r\n\r\n### Actual result (*)\r\nSuccess or failure depending on ordering of properties.\r\n"},
{"text": "<!---\r\nPlease review our guidelines before adding a new issue: https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\nFields marked with (*) are required. Please don't remove the template.\r\n-->\r\n\r\n### Preconditions (*)\r\nMagento 2.2.7 and Magento 2.3-develop provided by the bot.\r\n\r\n### Steps to reproduce (*)\r\n1. Create multiple store views\r\n2. Create a customer and set his store view to one that is not the default\r\n3. Use the rest api to change the first name of the customer (put to PUT rest/V1/customers/8)\r\n\r\nI used the following body. (note the missing storeid)\r\n\r\n```\r\n{ \"customer\":         {\r\n            \"id\": 1,\r\n            \"groupid\": 1,\r\n            \"defaultbilling\": \"0\",\r\n            \"defaultshipping\": \"0\",\r\n            \"createdat\": \"2019-05-13 14:33:11\",\r\n            \"updatedat\": \"2019-05-13 14:33:11\",\r\n            \"createdin\": \"alternate store view\",\r\n            \"email\": \"xxx@redacted.com\",\r\n            \"firstname\": \"firstname alternate\",\r\n            \"lastname\": \"lastname\",\r\n            \"gender\": 0,\r\n            \"websiteid\": 1,\r\n            \"addresses\": [],\r\n            \"disableautogroupchange\": 0\r\n        }\r\n}\r\n```\r\n\r\n\r\n### Expected result (*)\r\n1. The first name is changed.\r\n2. All fields not passed in the PUT call are not changed. (Including storeid).\r\n\r\n```\r\n{\r\n    \"items\": [\r\n        {\r\n            \"id\": 1,\r\n            \"groupid\": 1,\r\n            \"defaultbilling\": \"0\",\r\n            \"defaultshipping\": \"0\",\r\n            \"createdat\": \"2019-05-13 14:33:11\",\r\n            \"updatedat\": \"2019-05-13 14:40:56\",\r\n            \"createdin\": \"alternate store view\",\r\n            \"email\": \"bob.brinks@nl.spotler.com\",\r\n            \"firstname\": \"firstname alternate\",\r\n            \"lastname\": \"lastname\",\r\n            \"gender\": 0,\r\n            \"storeid\": 2,\r\n            \"websiteid\": 1,\r\n            \"addresses\": [],\r\n            \"disableautogroupchange\": 0\r\n        }\r\n    ],\r\n    \"searchcriteria\": {\r\n        \"filtergroups\": [],\r\n        \"pagesize\": 10\r\n    },\r\n    \"totalcount\": 1\r\n}\r\n```\r\n\r\n### Actual result (*)\r\n1. The storeid is changed to the default storeid\r\n\r\n```\r\n{\r\n    \"items\": [\r\n        {\r\n            \"id\": 1,\r\n            \"groupid\": 1,\r\n            \"defaultbilling\": \"0\",\r\n            \"defaultshipping\": \"0\",\r\n            \"createdat\": \"2019-05-13 14:33:11\",\r\n            \"updatedat\": \"2019-05-13 14:40:56\",\r\n            \"createdin\": \"alternate store view\",\r\n            \"email\": \"bob.brinks@nl.spotler.com\",\r\n            \"firstname\": \"firstname alternate\",\r\n            \"lastname\": \"lastname\",\r\n            \"gender\": 0,\r\n            \"storeid\": 1,\r\n            \"websiteid\": 1,\r\n            \"addresses\": [],\r\n            \"disableautogroupchange\": 0\r\n        }\r\n    ],\r\n    \"searchcriteria\": {\r\n        \"filtergroups\": [],\r\n        \"pagesize\": 10\r\n    },\r\n    \"totalcount\": 1\r\n}\r\n```\r\n"},
{"text": "**Preconditions**\r\n\r\n1. Magento 2.2.7 community Edition.\r\n2. REST API filtering products using rest/V1/products?searchCriteria\r\n\r\n\r\n**Steps to reproduce**\r\n1. we have disable showing out of stock products from Magento Dashboard (Stores > Configuration > Catalog > Inventory > Display Out of stock products **No**)\r\n2. we using this api to filtering product \r\n`/rest/V1/products?searchCriteria[filtergroups][0][filters][0][field]=categoryid&searchCriteria[filtergroups][0][filters][0][value]=35&searchCriteria[currentpage]=1&searchCriteria[pagesize]=40`\r\n\r\n\r\n**Expected result**\r\n1. The response contains infromation about stock per each product in the \"extensionattributes\" section\r\n\r\n\r\n**Actual result**\r\n1. There is no information about stock status per product in \"extensionattributes\" and no possibility to understand is it available on Storefront"},
{"text": "<!---\r\nPlease review our guidelines before adding a new issue: https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\nFields marked with (*) are required. Please don't remove the template.\r\n-->\r\n\r\n### Preconditions (*)\r\n<!---\r\nProvide the exact Magento version (example: 2.2.5) and any important information on the environment where bug is reproducible.\r\n-->\r\n1. Magento Commerce Edition 2.2.8\r\n2. Have a Product with an image uploaded (Luma sample data provides this)\r\n\r\n### Steps to reproduce (*)\r\n<!---\r\nImportant: Provide a set of clear steps to reproduce this bug. We can not provide support without clear instructions on how to reproduce.\r\n-->\r\n1. Send the following request to \"/V1/products/24-WG080/media/52\"\r\nbase64encodeddata is empty as this would bloat the issue-text\r\n\r\n`{\"entry\":{\"mediatype\":\"image\",\"label\":\"Label for my Image\":1,\"disabled\":false,\"types\":[\"image\",\"smallimage\",\"thumbnail\"],\"content\":{\"base64encodeddata\":\"...\",\"type\":\"image/jpeg\",\"name\":\"luma-yoga-kit-2\"},\"id\":52}}`\r\n\r\n### Expected result (*)\r\n<!--- Tell us what do you expect to happen. -->\r\n1. Everything provided by the request is updated for the media entity\r\n2. The actual file-content is replaced with what is provided in the base64encodeddata\r\n3. The endpoint returns true\r\n\r\n### Actual result (*)\r\n<!--- Tell us what happened instead. Include error messages and issues. -->\r\n1. label, types and disabled is updated for the media entity\r\n2. The actual file-content is NOT replaced with what is provided in the base64encodeddata\r\n3. The endpoint returns true\r\n"},
{"text": "### Preconditions (*)\r\n1. Magento 2.3.1\r\n2. Product attribute with attribute code \"testattribute\" exists with the default frontend label \"Test\"\r\n\r\n### Steps to reproduce (*)\r\n1. Call the url https://domain.tld/rest/V1/products/attributes/testattribute with a PUT request containing the following data:\r\n{\r\n  \"attribute\": {\r\n    \"defaultfrontendlabel\": \"Test2\"\r\n  }\r\n}\r\n\r\n### Expected result (*)\r\n<!--- Tell us what do you expect to happen. -->\r\n1. The default frontend label should be changed to \"Test2\"\r\n\r\n### Actual result (*)\r\n<!--- Tell us what happened instead. Include error messages and issues. -->\r\n1. Get an 400 Bad Request, saying something about missing the frontendinput\r\n2. The default frontend label still is set to \"Test\"\r\n3. If the frontendinput is supplied it states the attribute already exist\r\n\r\n### Workaround \r\nAlso supply the attributeid in your data like:\r\n\r\n{\r\n  \"attribute\": {\r\n    \"attributeid\": 138,\r\n    \"defaultfrontendlabel\": \"Test2\"\r\n  }\r\n}\r\n\r\nBut this is kind of strange because we already supplied the attribute code in the URL to identify what attribute we like to change. Also in our case forcing me to first fire an extra GET request to get the attribute id from the Magento installation.\r\n\r\n"},
{"text": "### Precondition (*)\r\nMagento 2.3.x\r\n\r\n### Summary (*)\r\nI want to return JSON in camelCase in my custom webapi.xml and interface that I have created.\r\nThere is no way to configure in webapi.xml the format that you wish to use.\r\n\r\nBy default M2 will return data like so: servertransactionid but my third party JavaScript is expecting serverTransactionId for example.\r\n\r\nSecondly, It is also rather annoying to have to create an interface to do this instead of just being able to use jsonencode the data. Using jsonencode is not the solution as you end up with \\ in the format.\r\n\r\nSee below:\r\n\r\n### Examples (*)\r\n```\r\ninterface Check3dsVersionInterface\r\n{\r\n    /**\r\n     * @return string\r\n     */\r\n    public function getServerTransactionId();\r\n\r\n    /**\r\n     * @param string $serverTransactionId\r\n     * @return $this\r\n     */\r\n    public function setServerTransactionId($serverTransactionId);\r\n```\r\n\r\nwebapi.xml:\r\n```\r\n<route url=\"/V1/xx-payments/:cartId/check-3ds-version\" method=\"POST\">\r\n        <service class=\"xx\\xx\\Api\\xxServiceInterface\" method=\"check3dsVersion\"/>\r\n        <resources>\r\n            <resource ref=\"anonymous\" />\r\n        </resources>\r\n    </route>\r\n```\r\n\r\n\r\n### Proposed solution\r\nIn webapi.xml, it would be useful to specify the format of the json, for example to return as camelCase or as it is currently which is underscores\r\n"},
{"text": "<!---\r\n    Thank you for contributing to Magento.\r\n    To help us process this issue we recommend that you add the following information:\r\n     - Summary of the issue,\r\n     - Information on your environment,\r\n     - Steps to reproduce,\r\n     - Expected and actual results,\r\n    Fields marked with (*) are required. Please don't remove the template.\r\n\r\n    Please also have a look at our guidelines article before adding a new issue https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\n-->\r\nWhen trying to request Web API end-point which has an interface with methods returning DateTime Magento throws the following error:\r\n\r\n```\r\nEach getter must have a doc block. See DateTime::format()\r\n```\r\n\r\n### Preconditions (*)\r\n1. Magento version 2.3-develop\r\n2. PHP v7.2\r\n\r\n### Steps to reproduce (*)\r\n1. Create a new interface as shown below.\r\n\r\n```\r\ninterface TestInterface\r\n{\r\n    /**\r\n     * Gets the current date.\r\n     * \r\n     * @return \\DateTime\r\n     */\r\n    public function getDate() : \\DateTime;\r\n}\r\n```\r\n\r\n2. Implement the interface and simply return an a new DateTime object.\r\n\r\n```\r\nclass TestApi implements TestInterface\r\n{\r\n    /**\r\n     * Gets the current date.\r\n     * \r\n     * @return \\DateTime\r\n     */\r\n    public function getDate() : \\DateTime {\r\n        return new \\DateTime();\r\n    }\r\n}\r\n```\r\n\r\n3. Create an entry in webapi.xml pointing to the service.\r\n\r\n```\r\n    <route method=\"GET\" url=\"/V1/test\">\r\n        <service class=\"TestInterface\" method=\"getDate\"/>\r\n        <resources>\r\n            <resource ref=\"anonymous\"/>\r\n        </resources>\r\n    </route>\r\n```\r\n\r\n4. Call the service using curl.\r\n\r\n### Expected result (*)\r\n1. The DateTime should be correctly serialized.\r\n2. When using JSON serializer, the output should be in ISO8601\r\n\r\n### Actual result (*)\r\n1. An error is thrown as shown below.\r\n\r\n```\r\nEach getter must have a doc block. See DateTime::format()\r\n```\r\n\r\n"},
{"text": "<!---\r\nPlease review our guidelines before adding a new issue: https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\nFields marked with (*) are required. Please don't remove the template.\r\n-->\r\n\r\n### Preconditions (*)\r\n<!---\r\nProvide the exact Magento version (example: 2.2.5) and any important information on the environment where bug is reproducible.\r\n-->\r\n1. Two websites\r\n\r\n|Web Site|Store|Store View|\r\n|---|---|---|\r\n|Main Website<br>`base`|Main Website Store<br>`mainwebsitestore`|Default Store View<br>`default`|\r\n|Test Website<br>`additional`|Test Website Store<br>`testwebsitestore`|Test Store View<br>`test`|\r\n2. **Account Sharing Options** has its default global setting **Share Customer Accounts** = **Per Website**\r\n\r\n### Steps to reproduce (*)\r\n<!---\r\nImportant: Provide a set of clear steps to reproduce this bug. We can not provide support without clear instructions on how to reproduce.\r\n-->\r\n1. Create Customer on the `default` Store View\r\n**Headers**\r\n```json\r\n{\r\n  \"Store\": \"default\"\r\n}\r\n```\r\n\r\n**Request**\r\n```graphql\r\nmutation {\r\n  createCustomer(\r\n    input: {\r\n      prefix: \"Prince\"\r\n      firstname: \"John\"\r\n      suffix: \"IV\"\r\n      middlename: \"Ruel\"\r\n      lastname: \"Doe\"\r\n      email: \"John.Doe@example.com\"\r\n      dob: \"10/10/10\"\r\n      gender: 1\r\n      password: \"123123qA\"\r\n    }\r\n  ) {\r\n    customer {\r\n      prefix\r\n      firstname\r\n      lastname\r\n      middlename\r\n      suffix\r\n      email\r\n      dob\r\n      gender\r\n    }\r\n  }\r\n}\r\n```\r\n2. Create Customer on the `test` Store View\r\n**Headers**\r\n```json\r\n{\r\n  \"Store\": \"test\"\r\n}\r\n```\r\n\r\n**Request**\r\n```graphql\r\nmutation {\r\n  createCustomer(\r\n    input: {\r\n      prefix: \"Prince\"\r\n      firstname: \"John\"\r\n      suffix: \"IV\"\r\n      lastname: \"Doe\"\r\n      email: \"John.Doe@example.com\"\r\n      dob: \"11/11/11\"\r\n      gender: 3\r\n      password: \"123123qAqA\"\r\n    }\r\n  ) {\r\n    customer {\r\n      prefix\r\n      firstname\r\n      lastname\r\n      middlename\r\n      suffix\r\n      email\r\n      dob\r\n      gender\r\n    }\r\n  }\r\n}\r\n```\r\n2. Generate Customer's token for the customer on `default` Store View\r\n**Headers**\r\n```graphql\r\n{\r\n  \"Store\": \"default\"\r\n}\r\n```\r\n**Request**\r\n```graphql\r\nmutation {\r\n  generateCustomerToken(\r\n    email: \"John.Doe@example.com\"\r\n    password: \"123123qA\"\r\n  ) {\r\n    token\r\n  }\r\n}\r\n```\r\n3. Get Customers information from the `test` Store View using token for `default` Store Virew\r\n**Headers**\r\n{\r\n  \"Authorization\": \"Bearer xo0aqut1x5erzjv2du6vu6qbbegkjpmr\",\r\n  \"Store\": \"ssetview\"\r\n}\r\n**Request**\r\n```graphql\r\nquery {\r\n  customer {\r\n    createdat\r\n    defaultbilling\r\n    defaultshipping\r\n    dob\r\n    email\r\n    firstname\r\n    gender\r\n    groupid\r\n    id\r\n    issubscribed\r\n    lastname\r\n    middlename\r\n    prefix\r\n    suffix\r\n    taxvat\r\n    groupid\r\n  }\r\n}\r\n```\r\n### Expected result (*)\r\n<!--- Tell us what do you expect to happen. -->\r\n1. Authorization problem\r\n\r\n### Actual result (*)\r\n<!--- Tell us what happened instead. Include error messages and issues. -->\r\n1. Information was returned from the Default Store View. "},
{"text": "<!---\r\nPlease review our guidelines before adding a new issue: https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\nFields marked with (*) are required. Please don't remove the template.\r\n-->\r\n\r\n### Preconditions (*)\r\n<!---\r\nProvide the exact Magento version (example: 2.2.5) and any important information on the environment where bug is reproducible.\r\n-->\r\n1. Magento 2.3.x\r\n\r\n### Steps to reproduce (*)\r\n<!---\r\nImportant: Provide a set of clear steps to reproduce this bug. We can not provide support without clear instructions on how to reproduce.\r\n-->\r\n1. Go to the [postman](https://www.getpostman.com/) and use this URL and param with the GET method\r\nURL: http://www.example.com/rest/V1/products-render-info\r\n2. Param:\r\n\r\n```\r\nsearchCriteria[filtergroups][0][filters][0][field] => categoryid\r\nsearchCriteria[filtergroups][0][filters][0][value] => 4 ( Any Category id )\r\nsearchCriteria[filtergroups][0][filters][0][conditiontype] => eq\r\nsearchCriteria[sortorders][0][field] => name\r\nsearchCriteria[sortorders][0][direction] => ASC\r\nstoreId => 1\r\ncurrencyCode => USD\r\nsearchCriteria[pageSize] => 5\r\nsearchCriteria[currentPage] => 1 \r\n```\r\n\r\n\r\n### Expected result (*)\r\n<!--- Tell us what do you expect to happen. -->\r\n1. As per the getList method code, the response should contain items with data, Search criteria with filters and sort options and the total number of products\r\n\r\n2. getList Method code:\r\n![getList](https://user-images.githubusercontent.com/12657201/65583851-91c55900-df9d-11e9-9fc0-cc77103c01f2.png)\r\n\r\n\r\n### Actual result (*)\r\n<!--- Tell us what happened instead. Include error messages and issues. -->\r\n1. In response, we get items data only.\r\n"},
{"text": "<!---\r\nPlease review our guidelines before adding a new issue: https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\nFields marked with (*) are required. Please don't remove the template.\r\n-->\r\n\r\n### Description\r\n\r\nCurrently, there is no way to set exact number of cart items. The POST request is adding posted quantity to existing quantity in the cart. The idea is to introduce ability to rewrite the items with PUT request\r\n\r\n### Steps to reproduce (*)\r\n<!---\r\nImportant: Provide a set of clear steps to reproduce this bug. We can not provide support without clear instructions on how to reproduce.\r\n-->\r\n70096:ItemId already exists and qty=3\r\ncan`t update cart items when set Maximum Qty Allowed in Shopping Cart\r\n1.POST:http://xxxxxx.com/rest/V1/carts/mine/items\r\n2.body:```{\"cartItem\":{\"sku\":\"AM-OL-I3T-CA-OS\",\"qty\":4,**\"itemid\":70096,**\"quoteId\":\"3xxx45\",\"productoption\":{\"extensionattributes\":{\"customoptions\":[],\"configurableitemoptions\":[{\"optionid\":\"93\",\"optionvalue\":\"66\"}],\"bundleoptions\":[]}}}}```\r\n3.set Maximum Qty Allowed in Shopping Cart=6\r\n\r\nIf I do post, I get an error:The requested qty exceeds the maximum qty allowed in shopping cart\r\ntips: If oldQty is 3, postQty is 2, final qty is 2, there is no problem! \r\n        if oldQty is 3, postQty is 4, I get an error:The requested qty exceeds the maximum qty allowed in shopping cart\r\n### Expected result (*)\r\n<!--- Tell us what do you expect to happen. -->\r\nUpdate: after review this issue expected result was updated https://github.com/magento/magento2/issues/28162#issuecomment-631621530\r\n\r\n> Desire state should be\r\n> POST `carts/mine/items` - add item(s). If called several times - increment Qty\r\n> PUT  `carts/mine/items` - add item(s). If called several times - each time overwrite previously created item.\r\n> \r\n\r\n1. I want to change the qty of products in the cart 3 to 4\r\n2. It should be overwrite, not increment\r\n### Actual result (*)\r\n<!--- Tell us what happened instead. Include error messages and issues. -->\r\n1.  I get an error:**The requested qty exceeds the maximum qty allowed in shopping cart**\r\n2.\r\n"},
{"text": "<!---\r\nPlease review our guidelines before adding a new issue: https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\nFields marked with (*) are required. Please don't remove the template.\r\n-->\r\n\r\n### Preconditions (*)\r\n<!---\r\nProvide the exact Magento version (example: 2.3.2) and any important information on the environment where bug is reproducible.\r\n-->\r\n1. Magento 2.3.3\r\n2. PHP 7.2.22\r\n3. nginx/1.10.3\r\n\r\n### Steps to reproduce (*)\r\n<!---\r\nImportant: Provide a set of clear steps to reproduce this bug. We can not provide support without clear instructions on how to reproduce.\r\n-->\r\n1. Send a post request to the endpoint **/rest/V1/customers**\r\n2. In the payload send an invalid **groupid** (by default Magento has the ids: 0, 1, 2, 3)\r\n3. **(optional)** Another strange thing is that we can send the request to create a customer without password and the api creates the register.\r\n4. Example of Request:\r\n![CreateCustomerBug](https://user-images.githubusercontent.com/48294687/80734243-418b1800-8ae5-11ea-8435-787f7db9b7bf.png)\r\n\r\n### Expected result (*)\r\n<!--- Tell us what do you expect to happen. -->\r\n1. Should throws an Exception informing that the groupid are not found\r\n\r\n### Actual result (*)\r\n<!--- Tell us what happened instead. Include error messages and issues. -->\r\n1. It's creates the client record successfully \r\n2. The client **can't** see products or add products to the quote\r\n3. https://www.loom.com/share/bf9c71c78bd6427b9537285c6064eb80"},
{"text": "<!---\r\nPlease review our guidelines before adding a new issue: https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\nFields marked with (*) are required. Please don't remove the template.\r\n-->\r\n\r\n### Preconditions\r\n<!---\r\nProvide the exact Magento version (example: 2.3.2) and any important information on the environment where bug is reproducible.\r\n-->\r\n1. Magento 2.3.4\r\n2. **Website 1** has default currency **EUR**\r\n3. **Store 1** (which related to **Website 1**) has default currency **USD**\r\n\r\n### Steps to reproduce\r\n<!---\r\nImportant: Provide a set of clear steps to reproduce this bug. We can not provide support without clear instructions on how to reproduce.\r\n-->\r\n1. Create order in **Store 1** \r\n2. Get information about order via API: `/v1/order/%number%`\r\n\r\n### Expected result\r\n<!--- Tell us what do you expect to happen. -->\r\n1. Order currency is set to `EUR` \r\n2. Order item attribute `baseprice` contains **base item price (in EUR)** \r\n3. Order item attribute `basepriceincltax` contains **base item price (in EUR) + tax (if applied)** \r\n4. Order item attribute `price` contains **converted to store currency item price (in USD)** \r\n5. Order item attribute `priceincltax` **contains converted to store currency item price (in USD) + tax (if applied)** \r\n\r\n### Actual result \r\n<!--- Tell us what happened instead. Include error messages and issues. -->\r\n1. Order currency is set to `EUR` \r\n2. Order item attribute `baseprice` contains **base item price (in EUR)** \r\n3. Order item attribute `basepriceincltax` contains **base item price (in EUR) + tax (if applied)**\r\n4. Order item attribute `price` contains **base item price (in EUR)** \r\n5. Order item attribute `priceincltax` **contains converted to store currency item price (in USD) + tax (if applied)** \r\n\r\n### Additional information\r\n- Possibly related issue #22215\r\n- In the `quoteitem` table `price` is already contains base price instead of calculated, so this value is copied to order item as well.\r\n\r\nI believe this issue should be fixed because it seems strange when only in the API attribute `price` doesn't cover order item price currency convertations while even `priceinctax` does."},
{"text": "<!---\r\nPlease review our guidelines before adding a new issue: https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\nFields marked with (*) are required. Please don't remove the template.\r\n-->\r\n\r\n### Preconditions (*)\r\n<!---\r\nProvide the exact Magento version (example: 2.2.5) and any important information on the environment where bug is reproducible.\r\n-->\r\n1. Magento 2.3.1 with MSI enabled\r\n2. Single Default Source for Inventory\r\n3. The order created from Admin Panel\r\n\r\n### Steps to reproduce (*)\r\n<!---\r\nImportant: Provide a set of clear steps to reproduce this bug. We can not provide support without clear instructions on how to reproduce.\r\n-->\r\n1.  Create an order created from Admin Panel\r\n2. Create Shipment via API:\r\n\r\n```json\r\n{\r\n  \"entity\": {\r\n    \"incrementid\": \"000000003\",\r\n    \"orderid\": 3,\r\n    \"items\": [\r\n        {\r\n          \"sku\": \"WSH12-32-Red\",\r\n          \"qty\": 1\r\n        }\r\n      ],\r\n    \"tracks\": [\r\n      {\r\n        \"orderid\": 3,\r\n        \"qty\": 1,\r\n        \"tracknumber\": \"123\",\r\n        \"title\": \"Test\",\r\n        \"carriercode\": \"dhl\"\r\n      }\r\n    ]  \r\n  }\r\n}\r\n```\r\n\r\n### Expected result (*)\r\n<!--- Tell us what do you expect to happen. -->\r\n1. Shipment is created in Admin\r\n\r\n### Actual result (*)\r\n<!--- Tell us what happened instead. Include error messages and issues. -->\r\n1. Fatal Error on API Response\r\n```json\r\ncan't parse JSON.  Raw result:\r\n\r\n<br />\r\n<b>Fatal error</b>:  Uncaught TypeError: Argument 1 passed to Magento\\InventoryConfiguration\\Model\\IsSourceItemManagementAllowedForProductType\\Interceptor::execute() must be of the type string, null given, called in /opt/lampp7.2/htdocs/magento/2.3.sample/vendor/magento/module-inventory-sales/Model/GetSkuFromOrderItem.php on line 48 and defined in /opt/lampp7.2/htdocs/magento/2.3.sample/generated/code/Magento/InventoryConfiguration/Model/IsSourceItemManagementAllowedForProductType/Interceptor.php:20\r\nStack trace:\r\n#0 /opt/lampp7.2/htdocs/magento/2.3.sample/vendor/magento/module-inventory-sales/Model/GetSkuFromOrderItem.php(48): Magento\\InventoryConfiguration\\Model\\IsSourceItemManagementAllowedForProductType\\Interceptor-&gt;execute(NULL)\r\nmagento/inventory#1 /opt/lampp7.2/htdocs/magento/2.3.sample/vendor/magento/module-inventory-shipping/Model/GetItemsToDeductFromShipment.php(75): Magento\\InventorySales\\Model\\GetSkuFromOrderItem-&gt;execute(Object(Magento\\Sales\\Model\\Order\\Item\\Interceptor))\r\nmagento/inventory#2 /opt/lampp7.2/htdocs/magento/2.3.sample/vendor/magento/module- in <b>/opt/lampp7.2/htdocs/magento/2.3.sample/generated/code/Magento/InventoryConfiguration/Model/IsSourceItemManagementAllowedForProductType/Interceptor.php</b> on line <b>20</b><br />\r\n{\"messages\":{\"error\":[{\"code\":500,\"message\":\"Server internal error. See details in report api\\/398581820999\"}]}}\r\n```\r\n\r\nNote: **Works after disabling the MSI modules.**\r\n"},
{"text": "**Preconditions (*)**\r\n\r\n    Magento 2.3.3\r\n\r\n**Steps to reproduce (*)**\r\n\r\nWhen i request\r\n/V1/products/attributes/{attributeCode}/options\r\nIt only returns label and value for Default View\r\n\r\n**Actual result (*)**\r\n```\r\n[\r\n {\r\n  \"label\":\"abc\",\r\n  \"value\":\"123\"\r\n }\r\n {\r\n  \"label\":\"abcd\",\r\n  \"value\":\"1233\"\r\n }\r\n]\r\n```\r\n\r\n**Expected result (*)**\r\n\r\nIn the documentation at http://devdocs.magento.com/swagger/\r\nit should return something like this:\r\n\r\n```\r\n[\r\n  {\r\n    \"label\": \"string\",\r\n    \"value\": \"string\",\r\n    \"sortOrder\": 0,\r\n    \"isDefault\": true,\r\n    \"storeLabels\": [\r\n      {\r\n        \"storeId\": 0,\r\n        \"label\": \"string\"\r\n      }\r\n    ]\r\n  }\r\n]\r\n```\r\n\r\nThis issue is the same as https://github.com/magento/magento2/issues/2733 \r\nI can confirm that this issue is still in M2.3.3\r\n"},
{"text": "### Preconditions (*)\r\n1. PHP 7.3.12\r\n2. Magento 2.4-develop\r\n\r\n### Steps to reproduce (*)\r\n1. Create multiple websites and store views. For example website1 with storeview1 and website2 with storeview2;\r\n![Screenshot from 2020-06-15 15-33-37](https://user-images.githubusercontent.com/51679138/84657874-a081e080-af1d-11ea-8739-7508a247800d.png)\r\n\r\n2. Go to Admin->Stores->Configuration->Customers->Customer Configuration->Account Sharing Options and set **Share Customer Accounts** to '**Per Website**';\r\n3. Create a user account in website1;\r\n4. Use REST API to login with user and password to retrieve the bearer token\r\n![Screenshot from 2020-06-15 15-37-20](https://user-images.githubusercontent.com/51679138/84658173-26059080-af1e-11ea-92d0-a919cb1ef41a.png)\r\n\r\n5. Read user details with **GET** `/rest/storeview1/V1/customers/me`\r\n6. Read user details with **GET** `/rest/storeview2/V1/customers/me`\r\n\r\n### Expected result (*)\r\n1. /rest/storeview1/V1/customers/me should return user information\r\n2. /rest/storeview2/V1/customers/me should return an error (e.g. unauthorized)\r\n\r\n### Actual result (*)\r\n1. /rest/storeview1/V1/customers/me returns user information\r\n2. /rest/storeview2/V1/customers/me returns user information\r\n"},
{"text": "<!---\r\nPlease review our guidelines before adding a new issue: https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\nFields marked with (*) are required. Please don't remove the template.\r\n-->\r\n\r\n### Preconditions (*)\r\n<!---\r\nProvide the exact Magento version (example: 2.3.2) and any important information on the environment where bug is reproducible.\r\n-->\r\nM 2.4-develop\r\n1. Registered Customer\r\n\r\n### Steps to reproduce (*)\r\n<!---\r\nImportant: Provide a set of clear steps to reproduce this bug. We can not provide support without clear instructions on how to reproduce.\r\n-->\r\n1. Set your hostname, Customer's email and Customer's password as bash variables. In my case\r\n```shell\r\nendpoint=\"http://magento2.loc/rest\";\r\nemail=\"John.Doe@example.com\";\r\npassword=\"123123qA\";\r\n```\r\n2. Get Customer token\r\n```shell\r\ncustomertoken=$(curl -X POST \"$endpoint/V1/integration/customer/token\" \\\r\n-H \"Content-Type: application/json\" \\\r\n-d \"{\\\"username\\\":\\\"$email\\\",\\\"password\\\":\\\"$password\\\"}\") && echo $customertoken  && customertoken=$(echo $customertoken | tr -d '\"')\r\n```\r\n3. Try to change the **lastname** of the Customer with payload that has no `websiteid` field\r\n```shell\r\ncurl -X PUT \"http://magento2.loc/rest/all/V1/customers/me\" \\\r\n-H \"Content-Type: application/json\" \\\r\n-H \"Authorization: Bearer $customertoken\" \\\r\n-d \"{ \\\"customer\\\": { \\\"firstname\\\": \\\"John\\\", \\\"lastname\\\": \\\"DoubleDoe\\\", \\\"email\\\": \\\"John.Doe@example.com\\\"} }\"\r\n```\r\n\r\n### Expected result (*)\r\n<!--- Tell us what do you expect to happen. -->\r\n1. Message:\r\n```json\r\n{\"message\":\"\\\"websiteid\\\" is a required value.\"}\r\n```\r\n\r\n### Actual result (*)\r\n<!--- Tell us what happened instead. Include error messages and issues. -->\r\n1. Message:\r\n```json\r\n{\"message\":\"\\\"Associate to Website\\\" is a required value.\"}\r\n```\r\n\r\n**Note**\r\nThese are all required fields. \r\nThere is no such field as  \"Associate to Website\"\r\n```\r\n{\r\n  \"customer\": {\r\n    \"id\": 0,\r\n    \"groupid\": 0,\r\n    \"defaultbilling\": \"string\",\r\n    \"defaultshipping\": \"string\",\r\n    \"confirmation\": \"string\",\r\n    \"createdat\": \"string\",\r\n    \"updatedat\": \"string\",\r\n    \"createdin\": \"string\",\r\n    \"dob\": \"string\",\r\n    \"email\": \"string\",\r\n    \"firstname\": \"string\",\r\n    \"lastname\": \"string\",\r\n    \"middlename\": \"string\",\r\n    \"prefix\": \"string\",\r\n    \"suffix\": \"string\",\r\n    \"gender\": 0,\r\n    \"storeid\": 0,\r\n    \"taxvat\": \"string\",\r\n    \"websiteid\": 0,\r\n    \"addresses\": [\r\n      {\r\n        \"id\": 0,\r\n        \"customerid\": 0,\r\n        \"region\": {\r\n          \"regioncode\": \"string\",\r\n          \"region\": \"string\",\r\n          \"regionid\": 0,\r\n          \"extensionattributes\": {}\r\n        },\r\n        \"regionid\": 0,\r\n        \"countryid\": \"string\",\r\n        \"street\": [\r\n          \"string\"\r\n        ],\r\n        \"company\": \"string\",\r\n        \"telephone\": \"string\",\r\n        \"fax\": \"string\",\r\n        \"postcode\": \"string\",\r\n        \"city\": \"string\",\r\n        \"firstname\": \"string\",\r\n        \"lastname\": \"string\",\r\n        \"middlename\": \"string\",\r\n        \"prefix\": \"string\",\r\n        \"suffix\": \"string\",\r\n        \"vatid\": \"string\",\r\n        \"defaultshipping\": true,\r\n        \"defaultbilling\": true,\r\n        \"extensionattributes\": {},\r\n        \"customattributes\": [\r\n          {\r\n            \"attributecode\": \"string\",\r\n            \"value\": \"string\"\r\n          }\r\n        ]\r\n      }\r\n    ],\r\n    \"disableautogroupchange\": 0,\r\n    \"extensionattributes\": {\r\n      \"issubscribed\": true\r\n    },\r\n    \"customattributes\": [\r\n      {\r\n        \"attributecode\": \"string\",\r\n        \"value\": \"string\"\r\n      }\r\n    ]\r\n  },\r\n  \"passwordHash\": \"string\"\r\n}\r\n```"},
{"text": "<!---\r\nPlease review our guidelines before adding a new issue: https://github.com/magento/magento2/wiki/Issue-reporting-guidelines\r\nFields marked with (*) are required. Please don't remove the template.\r\n-->\r\n\r\n### Preconditions (*)\r\n<!---\r\nProvide the exact Magento version (example: 2.3.2) and any important information on the environment where bug is reproducible.\r\n-->\r\n1. Magento 2.3-develop\r\n2. Registered Customer\r\n\r\n### Steps to reproduce (*)\r\n<!---\r\nImportant: Provide a set of clear steps to reproduce this bug. We can not provide support without clear instructions on how to reproduce.\r\n-->\r\n1. Get Customers token\r\n```shell\r\nendpoint=\"http://magento2.loc/rest\"\r\ncustomertoken=$(curl -X POST \"$endpoint/V1/integration/customer/token\" \\\r\n -H \"Content-Type: application/json\" \\\r\n -d '{\"username\":\"John.Doe@example.com\",\"password\":\"123123qA\"}') && echo $customertoken  && customertoken=$(echo $customertoken | tr -d '\"')\r\n```\r\n2. Navigate to `/swagger`\r\n3. Paste the token and click 'Apply' in the top-right corner\r\n4. Can I update my details using customerCustomerRepository?\r\n\r\n### Expected result (*)\r\n<!--- Tell us what do you expect to happen. -->\r\n1. Yes, I can\r\n\r\n### Actual result (*)\r\n<!--- Tell us what happened instead. Include error messages and issues. -->\r\n1. No, I cannot.\r\n![image](https://user-images.githubusercontent.com/11827230/69957241-e4c20c00-150a-11ea-8083-c0a252944c37.png)\r\n"},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n - API\r\n\r\n##### SUMMARY\r\n\r\nAzure AD SAML uses multiple certificates at once when signing responses (https://docs.microsoft.com/en-us/azure/active-directory/develop/active-directory-signing-key-rollover#other). This doesn't work with our SAML implementation.\r\n\r\n##### ADDITIONAL INFORMATION\r\n\r\n"},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n - UI\r\n\r\n##### SUMMARY\r\n\r\n![screenshot from 2017-09-28 14-41-25](https://user-images.githubusercontent.com/5208768/30984403-3986e62a-a45b-11e7-9d34-01d26eb9753e.png)\r\n\r\n*How* to sort it might be worth discussion (US first? Alphabetically?), but the current unsorted is odd.\r\n\r\n##### ENVIRONMENT\r\n* AWX version: currentish\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\nGo to Inventory Source, select AWS, select region dropdown.\r\n\r\n##### ADDITIONAL INFORMATION\r\n"},
{"text": "##### ISSUE TYPE\r\n<!--- Pick one below and delete the rest: -->\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n<!-- Pick the area of AWX for this issue, you can have multiple, delete the rest: -->\r\n - UI\r\n\r\n##### SUMMARY\r\n<!-- Briefly describe the problem. -->\r\nAny job i try to run just stays in pending. I have no other jobs running\r\n\r\n##### ENVIRONMENT\r\n<!--\r\n* AWX version: latest\r\n* Ansible version:  2.3.1\r\n* Operating System: Centos 7\r\n* Web Browser: Chrome\r\n-->\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\nCan't find a way\r\n\r\n##### EXPECTED RESULTS\r\nJob should run\r\n\r\n##### ACTUAL RESULTS\r\n\r\njob staying in pendning\r\n\r\n##### ADDITIONAL INFORMATION\r\n\r\noutput from awxtask log:\r\n\r\n```\r\n[2017-09-27 21:53:56,680: DEBUG/Worker-42] Running Tower task manager.\r\n2017-09-27 21:53:56,690 DEBUG    awx.main.scheduler Starting Scheduler\r\n2017-09-27 21:53:56,690 DEBUG    awx.main.scheduler Starting Scheduler\r\n[2017-09-27 21:53:56,690: DEBUG/Worker-42] Starting Scheduler\r\n2017-09-27 21:53:56,732 DEBUG    awx.main.scheduler projectupdate 123 (pending) is blocked from running\r\n2017-09-27 21:53:56,732 DEBUG    awx.main.scheduler projectupdate 123 (pending) is blocked from running\r\n[2017-09-27 21:53:56,732: DEBUG/Worker-42] projectupdate 123 (pending) is blocked from running\r\n[2017-09-27 21:53:56,748: INFO/MainProcess] Task awx.main.scheduler.tasks.runtaskmanager[a1bc3e85-bf92-47dc-bce7-4dc2c94a0e2d] succeeded in 0.0872339019988s: None\r\n[2017-09-27 21:54:16,590: INFO/MainProcess] Received task: awx.main.scheduler.tasks.runtaskmanager[5f2404ff-bc40-4d0e-8732-28715e1e3dd6] expires:[2017-09-27 21:54:36.587988+00:00]\r\n[2017-09-27 21:54:16,591: DEBUG/MainProcess] TaskPool: Apply <function fasttracetask at 0x5c62668> (args:(u'awx.main.scheduler.tasks.runtaskmanager', u'5f2404ff-bc40-4d0e-8732-28715e1e3dd6', [], {}, {u'utc': True, u'iseager': False, u'chord': None, u'group': None, u'args': [], u'retries': 0, u'deliveryinfo': {u'priority': None, u'redelivered': False, u'routingkey': u'tower', u'exchange': u'tower'}, u'expires': u'2017-09-27T21:54:36.587988+00:00', u'hostname': 'celery@localhost', u'task': u'awx.main.scheduler.tasks.runtaskmanager', u'callbacks': None, u'correlationid': u'5f2404ff-bc40-4d0e-8732-28715e1e3dd6', u'errbacks': None, u'timelimit': [None, None], u'taskset': None, u'kwargs': {}, u'eta': None, u'replyto': u'64ec93c0-61c0-3f6d-8363-645f9f0796f5', u'id': u'5f2404ff-bc40-4d0e-8732-28715e1e3dd6', u'headers': {}}) kwargs:{})\r\n[2017-09-27 21:54:16,594: DEBUG/MainProcess] Task accepted: awx.main.scheduler.tasks.runtaskmanager[5f2404ff-bc40-4d0e-8732-28715e1e3dd6] pid:198\r\n[2017-09-27 21:54:16,586: INFO/MainProcess] Scheduler: Sending due task taskmanager (awx.main.scheduler.tasks.runtaskmanager)\r\n[2017-09-27 21:54:16,588: DEBUG/MainProcess] awx.main.scheduler.tasks.runtaskmanager sent. id->5f2404ff-bc40-4d0e-8732-28715e1e3dd6\r\n[2017-09-27 21:54:16,594: DEBUG/MainProcess] beat: Waking up in 9.95 seconds.\r\n2017-09-27 21:54:16,617 DEBUG    awx.main.scheduler Running Tower task manager.\r\n2017-09-27 21:54:16,617 DEBUG    awx.main.scheduler Running Tower task manager.\r\n[2017-09-27 21:54:16,617: DEBUG/Worker-42] Running Tower task manager.\r\n2017-09-27 21:54:16,624 DEBUG    awx.main.scheduler Starting Scheduler\r\n2017-09-27 21:54:16,624 DEBUG    awx.main.scheduler Starting Scheduler\r\n[2017-09-27 21:54:16,624: DEBUG/Worker-42] Starting Scheduler\r\n2017-09-27 21:54:16,659 DEBUG    awx.main.scheduler projectupdate 123 (pending) is blocked from running\r\n2017-09-27 21:54:16,659 DEBUG    awx.main.scheduler projectupdate 123 (pending) is blocked from running\r\n[2017-09-27 21:54:16,659: DEBUG/Worker-42] projectupdate 123 (pending) is blocked from running\r\n[2017-09-27 21:54:16,669: INFO/MainProcess] Task awx.main.scheduler.tasks.runtaskmanager[5f2404ff-bc40-4d0e-8732-28715e1e3dd6] succeeded in 0.0774938369996s: None\r\n```"},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n\r\n\r\n##### COMPONENT NAME\r\n - UI\r\n\r\n##### SUMMARY\r\nI am trying to connect awx to our Microsoft Active Directory and encounter the following problem\r\n\r\nawx only tries to establish a connection to the ad/ldap server if i write the user name : domain\\username\r\n\r\nThis fails: Filter: sAMAccountName=domain\\username\r\nthe request should look like this: sAMAccountName=username\r\n\r\nIf I only try to log in with the username, no connection to the ldap server will be established.\r\n(i can see this with tcpdump)\r\nHow can I force awx that everyone tries to go against the ldap server\r\n\r\n\r\n##### ENVIRONMENT\r\n<!--\r\n* AWX version: 1.0.0.550\r\n* Ansible version:  2.4.0\r\n* Operating System: Centos 7\r\n* Web Browser:\r\n-->\r\n"},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n - API\r\n\r\n##### SUMMARY\r\nWith the split of SSH credential and Vault credential we need to be able to add multiple credentials through API. This is not supported at the moment.\r\n\r\n##### ENVIRONMENT\r\n* AWX version: 1.0.0.561\r\n* AWX install method: docker on linux\r\n* Ansible version:  2.4.0.0\r\n* Operating System: CentOS 7.3\r\n* Web Browser: Chrome\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\nI use a custom Python script with requests to process the below:\r\n\r\n  towerjobtemplates:\r\n      - name: \"alpine-core - deploy\"\r\n        jobtype: run\r\n        inventory: \"alpine-core\"\r\n        project: \"master-alpine-core\"\r\n        machinecredential: \"alpine-core machine-credential\"\r\n        playbook: playbooks/alpinecore/deploy.yml\r\n        extravars: \"env: '{{ ansiblelocal.localfacts.env }}'\"\r\n        surveyenabled: yes\r\n        allowsimultaneous: yes\r\n        endpoint: \"jobtemplates/\"\r\n\r\n##### EXPECTED RESULTS\r\n\r\nTemplate created with both Machine and Vault credential added.\r\n\r\n##### ACTUAL RESULTS\r\n\r\n[*] creating towerjobtemplates; invalid response from HTTP: https://mdc-co-awx01.msgreen.dom/api/v1/jobtemplates/ code: 400, BAD REQUEST: {\"credential\":[\"Must either set a default value or ask to promp\r\nt on launch.\"]}\r\ninvalid response from HTTP: https://mdc-co-awx01.msgreen.dom/api/v1/jobtemplates/ code: 400, BAD REQUEST: {\"credential\":[\"Must either set a default value or ask to prompt on launch.\"]}\r\n\r\n##### ADDITIONAL INFORMATION\r\n"},
{"text": "##### ISSUE TYPE\r\n<!--- Pick one below and delete the rest: -->\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n<!-- Pick the area of AWX for this issue, you can have multiple, delete the rest: -->\r\n - API\r\n - UI\r\n - Installer\r\n\r\n##### SUMMARY\r\nAfter setting the splunk logging at the AWX UI, i am not able to see any logs at the splunk interface. \r\n\r\n```\r\ndocker -f logs awxweb \r\n\r\n2017-10-02 08:48:39,088 WARNING  awx.api.generics status 500 received by user admin attempting to access /api/v2/settings/logging/test/ from 10.35.100.2\r\n[pid: 443|app: 0|req: 391/8226] 10.35.100.2 () {52 vars in 2293 bytes} [Mon Oct  2 08:48:39 2017] POST /api/v2/settings/logging/test/ => generated 26 bytes in 95 msecs (HTTP/1.1 500) 7 headers in 216 bytes (1 switches on core 0)\r\n10.35.100.2 - - [02/Oct/2017:08:48:39 +0000] \"POST /api/v2/settings/logging/test/ HTTP/1.1\" 500 37 \"https://tower.app.foo.net/\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10105) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36\" \r\n```\r\n\r\n##### ENVIRONMENT\r\n<!--\r\n* AWX version: 1.0.0.526\r\n* AWX install method: docker on linux\r\n* Ansible version:   2.3.2.0\r\n* Operating System: Centos 7\r\n* Web Browser: Google Chrome \r\nVersion 61.0.3163.100 \r\n-->\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\nBelow is my settings:\r\n\r\n![screen shot 2017-10-02 at 13 07 15](https://user-images.githubusercontent.com/97524/31073056-08496446-a773-11e7-9334-a1db03b154eb.png)\r\n\r\n\r\n##### EXPECTED RESULTS\r\n\r\nTo see some output at the splunk search:\r\n\r\nindex=awx\r\n\r\n##### ACTUAL RESULTS\r\n\r\nNo results\r\n##### ADDITIONAL INFORMATION\r\n\r\nToken is created for submitting logs. inventory outputs is as below:\r\n\r\n```\r\nlocalhost ansibleconnection=local ansiblepythoninterpreter=\"/usr/bin/env python\"\r\n[all:vars]\r\nusecontainerforbuild=true\r\nawxofficial=false\r\npostgresdatadir=/mnt/pgdocker\r\nhostport=80\r\npgusername=awx\r\npgpassword=xxx!\r\npgdatabase=awx\r\npgport=5432\r\nawxsecretkey=xxx\r\n```\r\n"},
{"text": "Not sure whether this has been reported before. I will still report it nonetheless. Thank you for your help.\r\n\r\n##### ISSUE TYPE\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n - API\r\n\r\n##### SUMMARY\r\nI can't login using default credentials after a standard installation of AWX.\r\n\r\n##### ENVIRONMENT\r\n<!--\r\n* AWX version: latest\r\n* AWX install method: docker on linux\r\n* Ansible version:  2.4.0.0\r\n* Operating System: Debian Jessie\r\n* Web Browser: Chrome, Firefox\r\n-->\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\n1. Install AWX on docker on Debian Jessie as documented.\r\n2. Login using default credentials (admin password)\r\n\r\n##### EXPECTED RESULTS\r\n\r\nIt shouldn't log me out\r\n\r\n##### ACTUAL RESULTS\r\n\r\nIt logs me out immediately after I log in using default credentials. I did not change any values in inventory file prior to build.\r\n\r\n##### ADDITIONAL INFORMATION\r\n\r\nThis is the requests as shown under Developer Tools\r\n\r\n<img width=\"522\" alt=\"2017-10-041116\" src=\"https://user-images.githubusercontent.com/4113595/31158627-91e207ca-a8f5-11e7-94fd-8f296cfc36ee.png\">\r\n\r\n"},
{"text": "##### ISSUE TYPE\r\n<!--- Pick one below and delete the rest: -->\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n<!-- Pick the area of AWX for this issue, you can have multiple, delete the rest: -->\r\n - UI\r\n\r\n##### SUMMARY\r\n<!-- Briefly describe the problem. -->\r\n\r\nHello. I am having a problem performing callbacks from a job template in the UI. I currently have 2 hosts in inventory, but when I browse to the callback job in the API, it displays:\r\n\r\n\"matchinghosts\": []\r\n\r\n##### ENVIRONMENT\r\n<!--\r\n* AWX version: 1.0.0.312\r\n* AWX install method: docker on linux\r\n* Ansible version:  2.3.1.0\r\n* Operating System:\r\n* Web Browser: Chrome\r\n-->\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\n<!-- For bugs, please show exactly how to reproduce the problem. For new\r\nfeatures, show how the feature would be used.  -->\r\n\r\nRun curl command from client requesting callback:\r\n\r\ncurl -d \"hostconfigkey=KEY\" http://awxweb:80/api/v2/jobtemplates/12/callback/\r\n\r\n\r\n##### EXPECTED RESULTS\r\n\r\n<!-- For bug reports, what did you expect to happen when running the steps\r\nabove? -->\r\n\r\nExpected job template to run\r\n\r\n##### ACTUAL RESULTS\r\n\r\n<!-- For bug reports, what actually happened? -->\r\n\r\nReceive error message on client:\r\n\r\n{\"msg\":\"No matching host could be found!\"}\r\n\r\n##### ADDITIONAL INFORMATION\r\n\r\n<!-- Include any links to sosreport, database dumps, screenshots or other\r\ninformation. -->\r\n"},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n - UI\r\n\r\n##### SUMMARY\r\n\r\nproject checkout with the `subversion` module fails when `scmpassword` is used with a Jinja `{{ | quote}}`\r\n\r\n##### ENVIRONMENT\r\n* AWX version:  1.0.0.561\r\n* AWX install method: docker on linux\r\n* Ansible version:  2.4.0.0\r\n* Operating System: Arch Linux\r\n* Web Browser: Chrome\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\n1. Create a Subversion credential (user/pass, not SSH key)\r\n2. Create a project that checks out a repository using this key\r\n3. Run the update job for the project.\r\n\r\n##### EXPECTED RESULTS\r\n\r\nno errors\r\n\r\n##### ACTUAL RESULTS\r\n\r\n```\r\nUsing /etc/ansible/ansible.cfg as config file\r\n[DEPRECATION WARNING]: DEFAULTASKSUDOPASS option, In favor of become which \r\nis a generic framework . This feature will be removed in version 2.8. \r\nDeprecation warnings can be disabled by setting deprecationwarnings=False in \r\nansible.cfg.\r\n\r\nPLAY [all] *********************************************************************\r\n\r\nTASK [delete project directory before update] **********************************\r\nok: [localhost]\r\n\r\nTASK [update project using git and accept hostkey] *****************************\r\nskipping: [localhost]\r\n\r\nTASK [Set the git repository version] ******************************************\r\nskipping: [localhost]\r\n\r\nTASK [update project using git] ************************************************\r\nskipping: [localhost]\r\n\r\nTASK [Set the git repository version] ******************************************\r\nskipping: [localhost]\r\n\r\nTASK [update project using hg] *************************************************\r\nskipping: [localhost]\r\n\r\nTASK [Set the hg repository version] *******************************************\r\nskipping: [localhost]\r\n\r\nTASK [update project using svn] ************************************************\r\nskipping: [localhost]\r\n\r\nTASK [Set the svn repository version] ******************************************\r\nskipping: [localhost]\r\n\r\nTASK [update project using svn with auth] **************************************\r\nfatal: [localhost]: FAILED! => {\"changed\": false, \"cmd\": \"/usr/bin/svn --non-interactive --trust-server-cert --no-auth-cache --username ROUSER --password '********' checkout -r HEAD https://svnrepo1/projects/trunk/admin/ansible /var/lib/awx/projects/6eaiansible\", \"failed\": true, \"msg\": \"svn: E170001: Unable to connect to a repository at URL 'https://svnrepo1/projects/trunk/admin/ansible'\\nsvn: E170001: OPTIONS of 'https://svnrepo1/projects/trunk/admin/ansible': authorization failed: Could not authenticate to server: rejected Basic challenge (https://svnrepo1)\", \"rc\": 1, \"stderr\": \"svn: E170001: Unable to connect to a repository at URL 'https://svnrepo1/projects/trunk/admin/ansible'\\nsvn: E170001: OPTIONS of 'https://svnrepo1/projects/trunk/admin/ansible': authorization failed: Could not authenticate to server: rejected Basic challenge (https://svnrepo1)\\n\", \"stderrlines\": [\"svn: E170001: Unable to connect to a repository at URL 'https://svnrepo1/projects/trunk/admin/ansible'\", \"svn: E170001: OPTIONS of 'https://svnrepo1/projects/trunk/admin/ansible': authorization failed: Could not authenticate to server: rejected Basic challenge (https://svnrepo1)\"], \"stdout\": \"\", \"stdoutlines\": []}\r\n\r\nPLAY RECAP *********************************************************************\r\nlocalhost                  : ok=1    changed=0    unreachable=0    failed=1   \r\n```\r\n\r\n##### ADDITIONAL INFORMATION\r\n\r\nIn looking at the `awx/playbooks/projectupdate.yml`, I was able to reproduce this by itself on Ansible Core : ansible/ansible#31250\r\n\r\nIf you take out the Jinja callout to `quote` for `scmpassword`, it works successfully.  I don't know if that means that `quote` is broken, or how it's passed along within the `subversion` module."},
{"text": "##### ISSUE TYPE\r\n<!--- Pick one below and delete the rest: -->\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n<!-- Pick the area of AWX for this issue, you can have multiple, delete the rest: -->\r\n - API\r\n - UI\r\n\r\n##### SUMMARY\r\nAfter upgrading from 1.0.561 I started getting this error running any of my job templates:\r\n\r\n`ERROR! Unexpected Exception, this is probably a bug: 'ascii' codec can't decode byte 0xc3 in position 1551: ordinal not in range(128)`\r\n\r\nI tried to upgrade from every new tag since 1.0.0.588 with the same results\r\n\r\n##### ENVIRONMENT\r\n* AWX version: 1.0.1.8\r\n* AWX install method: docker on linux (official builds)\r\n* Ansible version:  2.4.0.0\r\n* Operating System: Centos 7.4\r\n* Web Browser: Chrome 60\r\n\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\n1. Upgrade AWX\r\n2. Run a job template\r\n\r\n##### EXPECTED RESULTS\r\n\r\nThe job template should run as before the upgrade\r\n\r\n##### ACTUAL RESULTS\r\n\r\nThe playbook fails with the error message:\r\n\r\n`ERROR! Unexpected Exception, this is probably a bug: 'ascii' codec can't decode byte 0xc3 in position 1382: ordinal not in range(128)\r\n`\r\n\r\nThe position varies from one template to another\r\n\r\n##### ADDITIONAL INFORMATION\r\n\r\ndebug output:\r\n`\r\nIdentity added: /tmp/awx427Qd0YLs/credential2 (/tmp/awx427Qd0YLs/credential2)\r\n2\r\nansible-playbook 2.4.0.0\r\n3\r\n  config file = /etc/ansible/ansible.cfg\r\n4\r\n  configured module search path = [u'/var/lib/awx/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules']\r\n5\r\n  ansible python module location = /usr/lib/python2.7/site-packages/ansible\r\n6\r\n  executable location = /usr/bin/ansible-playbook\r\n7\r\n  python version = 2.7.5 (default, Aug  4 2017, 00:39:18) [GCC 4.8.5 20150623 (Red Hat 4.8.5-16)]\r\n8\r\nUsing /etc/ansible/ansible.cfg as config file\r\n9\r\nERROR! Unexpected Exception, this is probably a bug: 'ascii' codec can't decode byte 0xc3 in position 1382: ordinal not in range(128)\r\n10\r\nthe full traceback was:\r\n12\r\nTraceback (most recent call last):\r\n13\r\n  File \"/usr/bin/ansible-playbook\", line 106, in <module>\r\n14\r\n    exitcode = cli.run()\r\n15\r\n  File \"/usr/lib/python2.7/site-packages/ansible/cli/playbook.py\", line 104, in run\r\n16\r\n    loader, inventory, variablemanager = self.playprereqs(self.options)\r\n17\r\n  File \"/usr/lib/python2.7/site-packages/ansible/cli/init.py\", line 784, in playprereqs\r\n18\r\n    inventory = InventoryManager(loader=loader, sources=options.inventory)\r\n19\r\n  File \"/usr/lib/python2.7/site-packages/ansible/inventory/manager.py\", line 144, in init\r\n20\r\n    self.parsesources()\r\n21\r\n  File \"/usr/lib/python2.7/site-packages/ansible/inventory/manager.py\", line 205, in parsesources\r\n22\r\n    parse = self.parsesource(source, cache=cache)\r\n23\r\n  File \"/usr/lib/python2.7/site-packages/ansible/inventory/manager.py\", line 280, in parsesource\r\n24\r\n    display.warning('\\n* Failed to parse %s with %s plugin: %s' % (tonative(fail['src']), fail['plugin'], tonative(fail['exc'])))\r\n25\r\n  File \"/usr/lib/python2.7/site-packages/ansible/utils/display.py\", line 220, in warning\r\n26\r\n    self.display(newmsg, color=C.COLORWARN, stderr=True)\r\n27\r\n  File \"/usr/lib/python2.7/site-packages/ansible/utils/display.py\", line 114, in display\r\n28\r\n    msg = stringc(msg, color)\r\n29\r\n  File \"/usr/lib/python2.7/site-packages/ansible/utils/color.py\", line 93, in stringc\r\n30\r\n    return u\"\\n\".join([u\"\\033[%sm%s\\033\" % (colorcode, t) for t in text.split(u'\\n')])\r\n31\r\nUnicodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 1382: ordinal not in range(128)\r\n`"},
{"text": "##### ISSUE TYPE\r\n<!--- Pick one below and delete the rest: -->\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n<!-- Pick the area of AWX for this issue, you can have multiple, delete the rest: -->\r\n - UI\r\n\r\n##### SUMMARY\r\n<!-- Briefly describe the problem. -->\r\nIn my playbook, I need to become a \"non-root\" user (becomeuser: user1).\r\n\r\n##### ENVIRONMENT\r\n<!--\r\n* AWX version: 1.0.0.573\r\n* AWX install method: docker on linux\r\n* Ansible version:  2.4.0.1\r\n* Operating System: RHEL 7.3\r\n* Web Browser:\r\n-->Chrome\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\n<!-- For bugs, please show exactly how to reproduce the problem. For new\r\nfeatures, show how the feature would be used.  -->\r\nOn playbook with become \"non-root\" user escalation.\r\n\r\n##### EXPECTED RESULTS\r\n\r\n<!-- For bug reports, what did you expect to happen when running the steps\r\nabove? -->\r\nOn Ansible Tower, launching the same playbook I have no error and we see a sudo in the debug message : \r\n\r\n`\r\nEXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o StrictHostKeyChecking=no -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o User=ansible -o ConnectTimeout=60 -o ControlPath=/tmp/ansibletowermnllKi/cp/%h%p%r server1 '/bin/sh -c '\"'\"'**sudo -H -S -n -u user1 /bin/sh -c '\"'\"'\"'\"'\"'\"'\"'\"'echo BECOME-SUCCESS-jkukqsralylqokbrfuyaizwikoucnypn; /usr/bin/python**'\"'\"'\"'\"'\"'\"'\"'\"' && sleep 0'\"'\"''\u001b \r\n`\r\n##### ACTUAL RESULTS\r\n\r\n<!-- For bug reports, what actually happened? -->\r\nAWX displays the following error : \r\n\r\n \"msg\": \"Failed to set permissions on the temporary files Ansible needs to create when becoming an unprivileged user (rc: 1, err: chown: changing ownership of `/tmp/ansible-tmp-1507640208.53-227607229839391/': Operation not permitted\\nchown: changing ownership of `/tmp/ansible-tmp-1507640208.53-227607229839391/command.py': Operation not permitted\\n}). For information on working around this, see https://docs.ansible.com/ansible/become.html#becoming-an-unprivileged-user\".\r\n\r\nIn debug mode, the following message is display : \r\n\r\nSSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o StrictHostKeyChecking=no -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o User=ansible -o ConnectTimeout=60 -o ControlPath=/tmp/awx253i9fKoF/cp/%h%p%r server1 '/bin/sh -c '\"'\"'**chown user1 /tmp/ansible-tmp-1507640208.53-227607229839391/ /tmp/ansible-tmp-1507640208.53-227607229839391/command.py** && sleep 0'\"'\"''\r\n"},
{"text": "##### ISSUE TYPE\r\n<!--- Pick one below and delete the rest: -->\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n<!-- Pick the area of AWX for this issue, you can have multiple, delete the rest: -->\r\n - UI\r\n\r\n##### SUMMARY\r\n<!-- Briefly describe the problem. -->\r\nI'm using LDAP for user authentication. (but i can reproduce the error with local users as well)\r\nI have a user, who is an Admin, but it can't add surveys to job templates. \r\nThis is the error i get:\r\nERROR!\r\nYou do not have permission to perform this action.\r\n\r\nApparently only the default Admin user can do that\r\n\r\n##### ENVIRONMENT\r\n\r\n* AWX version: 1.0.0.561\r\n* AWX install method:  docker on linux (from docker hub)\r\n* Ansible version:  \r\n* Operating System: MacOS Sierra\r\n* Web Browser: Chrome\r\n\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\n<!-- For bugs, please show exactly how to reproduce the problem. For new\r\nfeatures, show how the feature would be used.  -->\r\nLogin as a users, with admin roles, different from the local admin user.\r\nCreate a new job template, add a survey.\r\n\r\n##### EXPECTED RESULTS\r\n\r\n<!-- For bug reports, what did you expect to happen when running the steps\r\nabove? -->\r\nTo Be able to add the survey\r\n##### ACTUAL RESULTS\r\nUnable to add survey\r\n<!-- For bug reports, what actually happened? -->\r\n\r\n##### ADDITIONAL INFORMATION\r\n\r\n<!-- Include any links to sosreport, database dumps, screenshots or other\r\ninformation. -->\r\n"},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n- AWX task?\r\n\r\n##### SUMMARY\r\n\r\nWhen I ran a Job a second time against a set of host I've just rebuilt with `terraform`, it fails due to the host keys being different, invoking a possible spoofing attack. \r\n\r\n##### ENVIRONMENT\r\n\r\n* AWX version: 1.0.1.31\r\n* AWX install method: docker on linux\r\n* Ansible version:  2.4\r\n* Operating System: Centos7 docker's image\r\n* Web Browser: Chrome Version 61.0.3163.100 \r\n\r\n##### STEPS TO REPRODUCE\r\n\r\n* Create a set of virtual machines\r\n* Execute a Job template a first time\r\n* Destroy then provision again the same set of VM\r\n* Execute again the same Job template\r\n\r\n##### EXPECTED RESULTS\r\n\r\nAs said in the issue #387, host keys are ignored, thus the job execution should not fail for such a reason.\r\n\r\n##### ACTUAL RESULTS\r\n\r\nAt the second execution, it fails with this output:\r\n```\r\nfatal: [node1.test]: UNREACHABLE! => {\"changed\": false, \"msg\": \"Failed to connect to the host via ssh: @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\\r\\n@       WARNING: POSSIBLE DNS SPOOFING DETECTED!          @\\r\\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\\r\\nThe ECDSA host key for node1.test.somedomain.com has changed,\\r\\nand the key for the corresponding IP address xxx.xxx.xxx.xxx \\r\\nis unknown. This could either mean that\\r\\nDNS SPOOFING is happening or the IP address for the host\\r\\nand its host key have changed at the same time.\\r\\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\\r\\n@    WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!     @\\r\\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\\r\\nIT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!\\r\\nSomeone could be eavesdropping on you right now (man-in-the-middle attack)!\\r\\nIt is also possible that a host key has just been changed.\\r\\nThe fingerprint for the ECDSA key sent by the \u2026\r\n```"},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n - API\r\n\r\n##### SUMMARY\r\nec2.py is out of date with that of the ansible-contrib version.\r\n\r\n##### ENVIRONMENT\r\nn/a\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\nLook at [current awx ec2.py](https://github.com/ansible/awx/blob/devel/awx/plugins/inventory/ec2.py) and look at [current contrib ec2.py](https://github.com/ansible/ansible/blob/devel/contrib/inventory/ec2.py)\r\n\r\n##### ADDITIONAL INFORMATION\r\n\r\nI want to be able to use the IAM Sts:AssumeRole feature so that I don't have to provide AWX with credentials to the AWS accounts it needs to, when instead it can pivot using the credentials given to the machine via its instance profile.\r\n"},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n\r\n\r\n##### COMPONENT NAME\r\n - API\r\n - UI\r\n\r\n##### SUMMARY\r\nUser that launched a job, cannot see the job in the following scenario:\r\n\r\n1. I created a user X that is an Admin of a created organization, and the Admin gave privileges to user X to use a project. \r\n2. User x dynamically creates an inventory and template and then executes the template (successfully), and user can see the job at this point.\r\n3. User x then deletes the inventory and template, now User x cannot see the job even though User X is the one that launched the job.\r\n\r\nThis was done through the UI and cli with the same results.\r\n\r\n##### ENVIRONMENT\r\n<!--\r\n* AWX version: 1.0.0.588\r\n* AWX install method: docker\r\n* Ansible version:  2.4.0.0\r\n* Operating System: RHEL 7.4\r\n* Web Browser: Firefox 52.3\r\n-->\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\nexplained in the summary\r\n\r\n##### EXPECTED RESULTS\r\n\r\nUser X can see the job that User X launched\r\n\r\n##### ACTUAL RESULTS\r\n\r\nUser X cannot see the job that they launched it.\r\n\r\n##### ADDITIONAL INFORMATION\r\n\r\n"},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n - API\r\n - UI\r\n\r\n##### SUMMARY\r\n\r\nSatellite 6 inventory does not list hosts that are not managed by Foreman, leaving the inventory incomplete. I think this is different from a behavior I used to see in AWX 1.0.0 and Ansible 2.3. This is a necessary behavior, as I am migrating old hosts to be Foreman-managed using Ansible.\r\n\r\n##### ENVIRONMENT\r\n* AWX version: 1.0.1.31\r\n* AWX install method: docker on linux\r\n* Ansible version:  2.4.0\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\n1. Configure a Satellite 6 inventory\r\n1. Add a host to Satellite 6 that is not \"managed\"\r\n1. Sync the inventory\r\n1. The new host is not listed in Hosts.\r\n\r\n##### EXPECTED RESULTS\r\n\r\nThe new host should be listed in Hosts.\r\n\r\n##### ACTUAL RESULTS\r\n\r\nThe new host is not listed in Hosts, or used as part of the inventory.\r\n\r\n##### ADDITIONAL INFORMATION\r\n\r\nRunning an old copy of the Foreman remote inventory script on another machine, I am able to see the un-managed hosts alongside hostvars and `groups['all']`. This makes the AWX behavior even stranger. \r\n\r\nThe unmanaged hosts cannot even be iterated over with `groups['all']`."},
{"text": "##### ISSUE TYPE\r\n<!--- Pick one below and delete the rest: -->\r\n - Bug Report\r\n\r\n\r\n##### COMPONENT NAME\r\n<!-- Pick the area of AWX for this issue, you can have multiple, delete the rest: -->\r\n - UI\r\n\r\n##### SUMMARY\r\nWhen authenticating via LDAP (Active Directory), seeing sporadic login failures. I see errors in the awxweb container logs\r\n\r\n##### ENVIRONMENT\r\n\r\n* AWX version: 1.0.0.588\r\n* AWX install method: docker on linux\r\n* Ansible version:  2.3.2.0\r\n* Operating System: RHEL 7\r\n* Web Browser: Chrome\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\nLogin via web UI. Logins sporadically fail. Can't reproduce the issue for local accounts (admin, etc.)\r\n\r\n##### EXPECTED RESULTS\r\n\r\nLDAP Logins should consistently work\r\n\r\n##### ACTUAL RESULTS\r\n\r\nSporadic login failure/timeout\r\n\r\n##### ADDITIONAL INFORMATION\r\n\r\n```\r\n2017/10/18 14:56:51 [warn] 597#0: *314 upstream server temporarily disabled while reading response header from upstream, client: 10.0.1.33, server: , request: \"POST /api/v2/authtoken/ HTTP/1.1\", upstream: \"uwsgi://127.0.0.1:8050\", host: \"host1.xxx.com\", referrer: \"http://host1.xxx.com/\"\r\n2017/10/18 14:56:51 [error] 597#0: *314 upstream timed out (110: Connection timed out) while reading response header from upstream, client: 10.0.1.33, server: , request: \"POST /api/v2/authtoken/ HTTP/1.1\", upstream: \"uwsgi://127.0.0.1:8050\", host: \"host1.xxx.com\", referrer: \"http://host1.xxx.com/\"\r\n10.0.1.33 - - [18/Oct/2017:14:56:51 +0000] \"POST /api/v2/authtoken/ HTTP/1.1\" 504 585 \"http://host1.xxx.com/\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36\" \"-\"\r\nWed Oct 18 14:56:52 2017 - *** HARAKIRI ON WORKER 1 (pid: 720, try: 1) ***\r\nWed Oct 18 14:56:52 2017 - HARAKIRI !!! worker 1 status !!!\r\nWed Oct 18 14:56:52 2017 - HARAKIRI [core 0] 10.95.126.12 - POST /api/v2/authtoken/ since 1508338491\r\nWed Oct 18 14:56:52 2017 - HARAKIRI !!! end of worker 1 status !!!\r\nDAMN ! worker 1 (pid: 720) died, killed by signal 9 :( trying respawn ...\r\nRespawned uWSGI worker 1 (new pid: 743)\r\nWSGI app 0 (mountpoint='') ready in 2 seconds on interpreter 0x1e3c560 pid: 743 (default app)\r\n```\r\n"},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n - API\r\n - Installer\r\n\r\n##### SUMMARY\r\nWhen `httpproxy` variable is set in the installer inventory `awxrest.py` will try to use the proxy when making requests to the AWX API (http://awxweb:8052). That will cause an error since the proxy will not be able to access that internal URL.\r\n\r\n##### ENVIRONMENT\r\n* AWX version: 1.0.1.77\r\n* AWX install method: docker on linux (official images)\r\n* Ansible version:  2.4.0.0\r\n* Operating System: Centos 7.4\r\n* Web Browser: Chrome 60\r\n\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\n1. Set `httpproxy` variable in installer inventory\r\n2. After installing AWX run any template\r\n\r\n##### EXPECTED RESULTS\r\nThe template should run without a problem\r\n\r\n##### ACTUAL RESULTS\r\nThe template will call ansible-playbook that will use the `awxrest.py` inventory script. The script will make a request to AWX API honoring httpproxy environment variable and fail.\r\n\r\n##### ADDITIONAL INFORMATION\r\nIncluding `awxweb` in the noproxy variable solves the issue. This information should be included in the documentation and inventory comments. Another option is to have the container always include `awxweb` to the `noproxy` environment variable. Or change the script to bypass proxy for local URLs.\r\n"},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n - API\r\n\r\n##### SUMMARY\r\nFound this issue when trying saving credential with null foreign keys\r\n\r\n##### ENVIRONMENT\r\n* AWX version: Any\r\n* AWX install method: docker for mac\r\n* Ansible version:  N/A\r\n* Operating System: N/A\r\n* Web Browser: N/A\r\n\r\n##### STEPS TO REPRODUCE\r\n- In AWX server, enter `shellplus`,\r\n- In `shellplus`, run `cred = Credential(name='hey', organization=None, credentialtype=CredentialType.objects.get(pk=1), inputs={})`. Make sure the to-be-created credential won't conflict with existing ones.\r\n\r\n##### EXPECTED RESULTS\r\nCredential is created.\r\n\r\n##### ACTUAL RESULTS\r\nStack overflow with looping\r\n```\r\n...\r\n/awxdevel/awx/main/models/credential.pyc in getattr(self, item)\r\n    254         if item in V1Credential.FIELDS:\r\n    255             return self.inputs.get(item, V1Credential.FIELDS[item].default)\r\n--> 256         elif item in self.inputs:\r\n    257             return self.inputs[item]\r\n    258         raise AttributeError(item)\r\n\r\n/awxdevel/awx/main/models/credential.pyc in getattr(self, item)\r\n    254         if item in V1Credential.FIELDS:\r\n    255             return self.inputs.get(item, V1Credential.FIELDS[item].default)\r\n--> 256         elif item in self.inputs:\r\n    257             return self.inputs[item]\r\n    258         raise AttributeError(item)\r\n\r\n/awxdevel/awx/main/models/credential.pyc in getattr(self, item)\r\n    254         if item in V1Credential.FIELDS:\r\n    255             return self.inputs.get(item, V1Credential.FIELDS[item].default)\r\n--> 256         elif item in self.inputs:\r\n    257             return self.inputs[item]\r\n    258         raise AttributeError(item)\r\n...\r\n```\r\n\r\n##### ADDITIONAL INFORMATION\r\nSetting null foreign keys like `\"organization\": null` is not permitted from API browser. That's probably why this issue has been hidden."},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n - UI\r\n\r\n##### SUMMARY\r\nWhen using credentials (specifically tested with Cloudforms credentials), a password with a string interpolation special character (\"%\") causes the parser to raise an exception. This can be fixed by \"escaping\" the character in the password with \"%%\". So, a password that's \"hello%world\" could be input as \"hello%%world\" and it will work (no exception and successful password string). \r\n\r\n##### ENVIRONMENT\r\n* AWX version: ansible-tower 3.1.5 (1.el7)\r\n* AWX install method: ansible-tower-setup-3.1.5.tar.gz + install.sh\r\n* Ansible version:  2.3.2.0 (2.el7)\r\n* Operating System: Red Hat Enterprise Linux Server release 7.4 (Maipo)\r\n* Web Browser: Chrome 61.0.3163.100 (Windows 10)\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\nAdd a new Cloudforms credential with a password containing a \"%\" symbol. Use that credential in a dynamic inventory source (also to Cloudforms). \r\n\r\n##### EXPECTED RESULTS\r\n\r\nPassword is accepted and sent as seen in the text box input. \r\n\r\n##### ACTUAL RESULTS\r\n\r\nInventory sync failed because of a string interpolation failure (parsing the password). \r\n\r\n##### ADDITIONAL INFORMATION\r\n\r\nException log:\r\n\r\n```\r\n  1.339 INFO     Updating inventory 3: Cloudforms Dynamic\r\n    1.358 INFO     Reading executable JSON source: /var/lib/awx/venv/tower/lib/python2.7/site-packages/awx/plugins/inventory/cloudforms.py\r\n    1.474 ERROR    Failed to load JSON from: \r\nTraceback (most recent call last):\r\n  File \"/usr/bin/tower-manage\", line 9, in <module>\r\n    loadentrypoint('ansible-tower==3.1.5', 'consolescripts', 'tower-manage')()\r\n  File \"/lib/python2.7/site-packages/awx/init.py\", line 105, in manage\r\n  File \"/var/lib/awx/venv/tower/lib/python2.7/site-packages/django/core/management/init.py\", line 354, in executefromcommandline\r\n    utility.execute()\r\n  File \"/var/lib/awx/venv/tower/lib/python2.7/site-packages/django/core/management/init.py\", line 346, in execute\r\n    self.fetchcommand(subcommand).runfromargv(self.argv)\r\n  File \"/var/lib/awx/venv/tower/lib/python2.7/site-packages/django/core/management/base.py\", line 394, in runfromargv\r\n    self.execute(*args, **cmdoptions)\r\n  File \"/var/lib/awx/venv/tower/lib/python2.7/site-packages/django/core/management/base.py\", line 445, in execute\r\n    output = self.handle(*args, **options)\r\n  File \"/var/lib/awx/venv/tower/lib/python2.7/site-packages/django/core/management/base.py\", line 661, in handle\r\n    return self.handlenoargs(**options)\r\n  File \"/lib/python2.7/site-packages/awx/main/management/commands/inventoryimport.py\", line 1290, in handlenoargs\r\n  File \"/lib/python2.7/site-packages/awx/main/management/commands/inventoryimport.py\", line 503, in loadinventorysource\r\n  File \"/lib/python2.7/site-packages/awx/main/management/commands/inventoryimport.py\", line 392, in load\r\n  File \"/lib/python2.7/site-packages/awx/main/management/commands/inventoryimport.py\", line 380, in commandtojson\r\nRuntimeError: ['/var/lib/awx/venv/tower/lib/python2.7/site-packages/awx/plugins/inventory/cloudforms.py', '--list'] failed (rc=1) with output: Traceback (most recent call last):\r\n  File \"/var/lib/awx/venv/tower/lib/python2.7/site-packages/awx/plugins/inventory/cloudforms.py\", line 464, in <module>\r\n    CloudFormsInventory()\r\n  File \"/var/lib/awx/venv/tower/lib/python2.7/site-packages/awx/plugins/inventory/cloudforms.py\", line 51, in init\r\n    self.readsettings()\r\n  File \"/var/lib/awx/venv/tower/lib/python2.7/site-packages/awx/plugins/inventory/cloudforms.py\", line 140, in readsettings\r\n    self.cloudformspw = config.get('cloudforms', 'password')\r\n  File \"/usr/lib64/python2.7/ConfigParser.py\", line 623, in get\r\n    return self.interpolate(section, option, value, d)\r\n  File \"/usr/lib64/python2.7/ConfigParser.py\", line 691, in interpolate\r\n    self.interpolatesome(option, L, rawval, section, vars, 1)\r\n  File \"/usr/lib64/python2.7/ConfigParser.py\", line 732, in interpolatesome\r\n    \"'%%' must be followed by '%%' or '(', found: %r\" % (rest,))\r\nConfigParser.InterpolationSyntaxError: '%' must be followed by '%' or '(', found: '%7K'\r\n```\r\n"},
{"text": "##### ISSUE TYPE\r\n<!--- Pick one below and delete the rest: -->\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n<!-- Pick the area of AWX for this issue, you can have multiple, delete the rest: -->\r\n - API\r\n\r\n\r\n##### SUMMARY\r\n[According to the documentation](http://docs.ansible.com/ansible-tower/latest/html/administration/tipsandtricks.html#locate-and-configure-the-ansible-configuration-file), an `ansible.cfg` adjacent to a playbook should be picked up and used by Ansible Tower during job run. This is not working.\r\n\r\nInstead, `ansible.cfg` inside a project is only read if it is at the root of the project.\r\n\r\n##### ENVIRONMENT\r\n\r\n* AWX version: 3.2.1.21\r\n* AWX install method: AMI provided by Ansible\r\n* Ansible version:  2.4.0.0\r\n* Operating System: CentOS 7.4.1708\r\n* Web Browser: Safari 11.0 (12604.1.38.1.7)\r\n\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\n1. Create a new project using [this repo](https://github.com/samdoran/bugdemo.git) and the `master` branch.\r\n2. Create a Job Template that runs `subdir/bug.yml` with Show Changes enabled and set the verbosity to 3(Debug).\r\n3. Run the Job Template.\r\n\r\n<img width=\"1008\" alt=\"screen shot 2017-10-20 at 12 38 02\" src=\"https://user-images.githubusercontent.com/4047861/31832758-23eb89a0-b596-11e7-83d4-79670f84357c.png\">\r\n\r\n\r\n##### EXPECTED RESULTS\r\n\r\nAnsible will see the `ansible.cfg` adjacent to the playbook and use that. It will be reflected in the debug output:\r\n\r\n```\r\nIdentity added: /tmp/awx66RIxb4K/credential3 (/tmp/awx66RIxb4K/credential3)\r\nansible-playbook 2.4.0.0\r\n  config file = /var/lib/awx/projects/6bugdemo/subdir/ansible.cfg\r\n  configured module search path = [u'/var/lib/awx/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules']\r\n  ansible python module location = /usr/lib/python2.7/site-packages/ansible\r\n  executable location = /usr/bin/ansible-playbook\r\n  python version = 2.7.5 (default, Aug  4 2017, 00:39:18) [GCC 4.8.5 20150623 (Red Hat 4.8.5-16)]\r\nUsing /var/lib/awx/projects/6bugdemo/subdir/ansible.cfg as config file\r\n\r\n...\r\n\r\nTASK [Create a file using setting in ansible.cfg] ******************************\r\ntask path: /var/lib/awx/projects/6bugdemo/subdir/bug.yml:7\r\n\r\n...\r\n\r\n--- before: /tmp/template.txt\r\n+++ after: /tmp/tmpyRyXCE/template.j2\r\n@@ -1,2 +1,2 @@\r\n-# Ansible managed\r\n+# SET IN ADJACENT ANSIBLE.CFG\r\n # The line above should read SET IN ADJACENT ANSIBLE.CFG\r\n```\r\n\r\n##### ACTUAL RESULTS\r\n\r\nAnsible does not see the config file and does not use settings specificed in the `ansible.cfg` adjacent to the playbook in the repository.\r\n\r\n```\r\nIdentity added: /tmp/awx480lFZ3j/credential3 (/tmp/awx480lFZ3j/credential3)\r\nansible-playbook 2.4.0.0\r\n  config file = None\r\n  configured module search path = [u'/var/lib/awx/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules']\r\n  ansible python module location = /usr/lib/python2.7/site-packages/ansible\r\n  executable location = /usr/bin/ansible-playbook\r\n  python version = 2.7.5 (default, Aug  4 2017, 00:39:18) [GCC 4.8.5 20150623 (Red Hat 4.8.5-16)]\r\nNo config file found; using defaults\r\nParsed /tmp/awx480lFZ3j/tmpQ7jDnB.awxrest.py inventory source with script plugin\r\n\r\n...\r\n\r\nTASK [Create a file using setting in ansible.cfg] ******************************\r\ntask path: /var/lib/awx/projects/6bugdemo/subdir/bug.yml:7\r\n\r\n...\r\n\r\n--- before: /tmp/template.txt\r\n+++ after: /tmp/tmpcNJ5lq/template.j2\r\n@@ -1,2 +1,2 @@\r\n+# Ansible managed\r\n # The line above should read SET IN ADJACENT ANSIBLE.CFG\r\n```\r\n\r\n##### ADDITIONAL INFORMATION\r\n\r\nDisable job isolation seems to have no affect on this bug \u2014 behavior is the same in both cases.\r\n\r\nI also have a branch in that bug repo that puts an `ansible.cfg` file at the root of the repo. If you change the Project to use the `top-level-config` branch, then run the same Job Template, you can see that the config file at the root of the repo, not adjacent to the playbook, gets picked up. This should not be the case.\r\n\r\n```\r\nIdentity added: /tmp/awx66RIxb4K/credential3 (/tmp/awx66RIxb4K/credential3)\r\nansible-playbook 2.4.0.0\r\n  config file = /var/lib/awx/projects/6bugdemo/ansible.cfg\r\n  configured module search path = [u'/var/lib/awx/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules']\r\n  ansible python module location = /usr/lib/python2.7/site-packages/ansible\r\n  executable location = /usr/bin/ansible-playbook\r\n  python version = 2.7.5 (default, Aug  4 2017, 00:39:18) [GCC 4.8.5 20150623 (Red Hat 4.8.5-16)]\r\nUsing /var/lib/awx/projects/6bugdemo/ansible.cfg as config file\r\nParsed /tmp/awx66RIxb4K/tmpbDIjjO.awxrest.py inventory source with script plugin\r\n\r\n...\r\n\r\nTASK [Create a file using setting in ansible.cfg] ******************************\r\ntask path: /var/lib/awx/projects/6bugdemo/subdir/bug.yml:7\r\n\r\n...\r\n\r\n--- before: /tmp/template.txt\r\n+++ after: /tmp/tmpyRyXCE/template.j2\r\n@@ -1,2 +1,2 @@\r\n-# Ansible managed\r\n+# SET IN PROJECT ROOT ANSIBLE.CFG\r\n # The line above should read SET IN ADJACENT ANSIBLE.CFG\r\n\r\n```"},
{"text": " - Bug Report\r\n - UI\r\n\r\n##### SUMMARY\r\nAfter having successfully deployed AWX on an Openshift cluster following this blog post (https://developers.redhat.com/blog/2017/10/16/guide-starting-use-awx-top-openshift-upstream-red-hat-ansible-tower/); we are unable to start a deployement. The fetch of the playbook is failing on a \"permission denied on /tmp\"\r\n##### ENVIRONMENT\r\n\r\n* AWX version: 1.0.1.93\r\n* AWX install method: openshift\r\n* Ansible version:  2.4.0.0\r\n* Operating System: Linux\r\n* Web Browser: Chrome\r\n\r\n##### STEPS TO REPRODUCE\r\nDefine a new deployement.\r\n - Project creation is working fine and git repo is correctly fetched (using git credentials)\r\n- Inventory is defined (some variables in the json field of one group)\r\n- Create the template and associate everything.\r\n\r\nWe have a user dedicated to ansible on targeted hosts and are sudoers NOPASSWD.\r\n\r\nThe fetch of the  of the repo seems to work as the Project name appear with a green point on the task detail.\r\n\r\n\r\n##### EXPECTED RESULTS\r\n\r\nThe task should start and working correctly\r\n\r\n##### ACTUAL RESULTS\r\n\r\n\r\nThe task hang in error with the following trace : \r\n```\r\nTraceback (most recent call last):\r\nFile \"/usr/lib/python2.7/site-packages/awx/main/tasks.py\", line 786, in run\r\nsafeargs = self.buildsafeargs(instance, **kwargs)\r\nFile \"/usr/lib/python2.7/site-packages/awx/main/tasks.py\", line 1161, in buildsafeargs\r\nreturn self.buildargs(job, display=True, **kwargs)\r\nFile \"/usr/lib/python2.7/site-packages/awx/main/tasks.py\", line 1088, in buildargs\r\nargs = ['ansible-playbook', '-i', self.buildinventory(job, **kwargs)]\r\nFile \"/usr/lib/python2.7/site-packages/awx/main/tasks.py\", line 681, in buildinventory\r\nwith open(path, 'w') as f:\r\nIOError: [Errno 13] Permission denied: u'/tmp/awx28Ee1gSY/inventory'\r\n```\r\n\r\n##### ADDITIONAL INFORMATION\r\nThe same scenario is being run correctly on an Ansible Tower (evaluation mode) version 3.1.3 "},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n - API\r\n - UI\r\n\r\n##### SUMMARY\r\nI am trying to clone a repository from our internal Bitbucket server. The server runs with a self signed certificate. The clone operation breaks due to `Peer's Certificate issuer is not recognized`.\r\n\r\nAs a workaround, I tried to disabled SSL verification via the `.gitconfig` for the `root` user on the `awx-task` container, but with no luck. The process forked by AWX seems to ignore that. Second problem would be that this is just a transient solution.\r\n\r\nThe following Stackoverflow post describes another issue related to this:\r\nhttps://serverfault.com/questions/877530/git-called-by-awx-ignores-manually-installed-root-ca\r\n\r\n**This is essentially a showstopper for us, as we cannot clone Ansible provisioning code without pain.**\r\n\r\n##### ENVIRONMENT\r\n* AWX version: `1.0.1.81`\r\n* AWX install method: docker on CentOS 7 \r\n* Ansible version:  `2.4.0.0`\r\n* Web Browser: Chrome `62.0.3202.62`\r\n\r\n##### STEPS TO REPRODUCE\r\n* Create new credential entity for your repo via UI\r\n* Create new `Project` via the UI\r\n  * Use afore created credentials\r\n  * Use HTTPS protocol, use Git repo secured by self signed certificate\r\n\r\n##### EXPECTED RESULTS\r\n* Add a checkbox to the `Project` creation page that disables SSL verification for the given project\r\n* The forked `git clone` task command needs to leverage that setting\r\n* In result, the repo with the self-signed cert can be cloned\r\n\r\n##### ACTUAL RESULTS\r\n* Repo cannot be cloned due to certificate trust error\r\n\r\n##### ADDITIONAL INFORMATION\r\n![awx-git-clone-error](https://user-images.githubusercontent.com/282736/31938091-d6985bdc-b8b6-11e7-9fd6-8dffa1a89b70.png)\r\n"},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n - API\r\n - Notifications\r\n\r\n##### SUMMARY\r\nI have a template with 50 hosts. When the job completions notification are sent (I use a webhook callback), they only contain data for ~16 hosts. If I immediately use the API to retrieve \"jobhostsummaries\", I get only ~30 hosts. After a few secs, all the hosts are retrievable using the API.\r\n\r\n##### ENVIRONMENT\r\n* AWX version: 1.0.0.588\r\n* AWX install method: docker on linux\r\n* Ansible version:  2.4.0.0\r\n\r\n##### STEPS TO REPRODUCE\r\nSince this is a timing problem, I don't know how to replicate it exactly, but with my setup (50 hosts and AWX hosted on a powerful server), even with the \"Hello World\" project, the notifications are sent too early\r\n\r\n##### ADDITIONAL INFORMATION\r\nhttps://github.com/ansible/awx/blob/73ece87e6895377b36cb7f19fb9d2bc414dad6cc/awx/main/models/jobs.py#L633\r\nAccording to this, this problem is known, but only wait for any host data to be available, but not all of it."},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n - API\r\n\r\n##### SUMMARY\r\nIf a JT has no survey and `\"askvariablesonlaunch\": false`, you can still force it to launch with your own variables by making a schedule that defines those variables inside of `extradata`.\r\n\r\n##### ENVIRONMENT\r\nN/A\r\n\r\n##### STEPS TO REPRODUCE\r\n - Create a JT that does not prompt for variables and has no survey\r\n - Create a schedule that runs that JT, provide extra variables `foobar: foobaz`\r\n\r\n##### EXPECTED RESULTS\r\n\r\n1. Validation error saving the schedule\r\n2. Job does not have extravars of `foobar: foobaz`\r\n\r\n##### ACTUAL RESULTS\r\nno error saving.\r\n\r\njob has those extravars.\r\n\r\n##### ADDITIONAL INFORMATION\r\n\r\nRealized while trying to scope out some things around https://github.com/ansible/awx/issues/169\r\n\r\nThis line of thinking will also lead us down a rabbit hole around what workflow extra variables can mean, artifacts, etc."},
{"text": "##### ISSUE TYPE\r\n<!--- Pick one below and delete the rest: -->\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n<!-- Pick the area of AWX for this issue, you can have multiple, delete the rest: -->\r\n - UI\r\n\r\n##### SUMMARY\r\nAfter updating the docker images (awx-task and awx-web) and waiting a few minutes I launch the first job which requires an inventory sync. That inventory sync fails with `IOError: Source does not exist: /var/lib/awx/projects/6p1/hosts`\r\n\r\n##### ENVIRONMENT\r\n\r\n* AWX version: 1.0.1.93\r\n* AWX install method: docker\r\n* Ansible version:  2.4.0.0\r\n* Operating System: CentOS 7.3\r\n* Web Browser: Chrome\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\n1. Update docker images\r\n\r\n```\r\ndocker stop <awxweb and task>\r\ndocker pull ansible/awxtask\r\ndocker pull ansible/awxweb\r\n```\r\n\r\n2. Launch containers\r\n\r\n```\r\nansible-playbook -i inventory installer.yml\r\n```\r\n\r\n3. Wait a few moments then trigger job template via API\r\n\r\n##### EXPECTED RESULTS\r\n\r\nI expected job to run\r\n\r\n##### ACTUAL RESULTS\r\n\r\n<!-- For bug reports, what actually happened? -->\r\n\r\n##### ADDITIONAL INFORMATION\r\n\r\nJob fails with the following output\r\n\r\n```\r\n2017-10-25 15:09:01,086 INFO     awx.main.commands.inventoryimport Updating inventory 3: j1\r\nTraceback (most recent call last):\r\n  File \"/usr/bin/awx-manage\", line 9, in <module>\r\n    loadentrypoint('awx==1.0.1.93', 'consolescripts', 'awx-manage')()\r\n  File \"/usr/lib/python2.7/site-packages/awx/init.py\", line 107, in manage\r\n    executefromcommandline(sys.argv)\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/core/management/init.py\", line 354, in executefromcommandline\r\n    utility.execute()\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/core/management/init.py\", line 346, in execute\r\n    self.fetchcommand(subcommand).runfromargv(self.argv)\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/core/management/base.py\", line 394, in runfromargv\r\n    self.execute(*args, **cmdoptions)\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/core/management/base.py\", line 445, in execute\r\n    output = self.handle(*args, **options)\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/core/management/base.py\", line 661, in handle\r\n    return self.handlenoargs(**options)\r\n  File \"/usr/lib/python2.7/site-packages/awx/main/management/commands/inventoryimport.py\", line 1000, in handlenoargs\r\n    self.iscustom)\r\n  File \"/usr/lib/python2.7/site-packages/awx/main/management/commands/inventoryimport.py\", line 234, in loadinventorysource\r\n    raise IOError('Source does not exist: %s' % source)\r\nIOError: Source does not exist: /var/lib/awx/projects/6p1/hosts\r\n```\r\n\r\nThe second launch of this same job succeeds.\r\n"},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n - API\r\n\r\n##### SUMMARY\r\nIf you modify a survey, changing questions to/from password-type, the default value will break.\r\n\r\n##### ENVIRONMENT\r\n* AWX version: 1.0.1\r\n* AWX install method: docker for mac\r\n* Ansible version:  N/A\r\n* Operating System:\r\n* Web Browser:\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\n - Create a survey in the UI\r\n - Either\r\n   - modify a survey type question to text\r\n   - modify a text question to be survey type\r\n - launch a job without answering questions, inspect values of variables\r\n\r\n##### EXPECTED RESULTS\r\n\r\nDefaults are preserved after modification?\r\n\r\nMore realistic: modification request returns error code with message about how to resolve the problem.\r\n\r\n##### ACTUAL RESULTS\r\n\r\n - password-->non-password\r\n   - default becomes literal string \"$encrypted$\"\r\n - non-password-->password\r\n   - shows as \"$encrypted$\", but actually a hashed value that's passed to playbook\r\n\r\n##### ADDITIONAL INFORMATION\r\n\r\nWill overlap with some concerns related to https://github.com/ansible/awx/issues/169\r\n"},
{"text": "##### ISSUE TYPE\r\n<!--- Pick one below and delete the rest: -->\r\n - Bug Report\r\n\r\n\r\n##### COMPONENT NAME\r\n<!-- Pick the area of AWX for this issue, you can have multiple, delete the rest: -->\r\n - UI\r\n\r\n\r\n##### SUMMARY\r\nAny workflow template created with a survey not working for non-admin (normal-users), the workflow template survey comes up blank.\r\n\r\n##### ENVIRONMENT\r\n* AWX version: All\r\n* AWX install docker on linux\r\n* Ansible version:  All\r\n* Operating System: CentOS7 and RHEL 7.4/7.3\r\n* Web Browser: Chrome/Firefox\r\n\r\n##### STEPS TO REPRODUCE\r\nCreate any workflow\r\nAttach/create a survey\r\nAssign normal-user execute or even admin permission to workflow\r\nLunch the workflow as normal-user\r\n\r\n##### EXPECTED RESULTS\r\nSee the survey questions\r\n\r\n##### ACTUAL RESULTS\r\nSurvey questions missing\r\n\r\n##### ADDITIONAL INFORMATION\r\n"},
{"text": "##### ISSUE TYPE\r\n<!--- Pick one below and delete the rest: -->\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n<!-- Pick the area of AWX for this issue, you can have multiple, delete the rest: -->\r\n - API\r\n\r\n##### SUMMARY\r\n<!-- Briefly describe the problem. -->\r\nIt is not possible to check out a SCM URL using subversion because the password is not correctly placed into the command string that runs.\r\n\r\n##### ENVIRONMENT\r\n- AWX version:  1.0.1.120\r\n- AWX install method: docker on linux\r\n - Ansible version:  2.4.1.0\r\n- Operating System: Centos 7.4\r\n- Web Browser: 52.4.0 (64-bit)\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\n- Create a new credentials(Source Control)\r\n- Double check username/password\r\n\r\n- Create a new project using the created credentials\r\n- Start an SCM update\r\n\r\nAt this point it will fail.\r\n\r\n##### EXPECTED RESULTS\r\n\r\nCorrectly checking out the repository\r\n\r\n##### ACTUAL RESULTS\r\n\r\nTASK [update project using svn with auth] ************************************** fatal: [localhost]: FAILED! => {\"changed\": false, \"cmd\": \"/usr/bin/svn --non-interactive --trust-server-cert --no-auth-cache --username testUser --password '********' checkout -r HEAD https://test.test.com/test/ /var/lib/awx/projects/6linuxtest\", \"failed\": true, \"msg\": \"svn: E170001: Unable to connect to a repository at URL 'https://test.test.com/test/'\\nsvn: E170001: OPTIONS of 'https://test.test.com/test/': authorization failed: Could not authenticate to server: rejected Basic challenge (https://test.test.com)\", \"rc\": 1, \"stderr\": \"svn: E170001: Unable to connect to a repository at URL 'https://test.test.com/test/'\\nsvn: E170001: OPTIONS of 'https://test.test.com/test/': authorization failed: Could not authenticate to server: rejected Basic challenge (https://test.test.com/test/)\\n\", \"stderrlines\": [\"svn: E170001: Unable to connect to a repository at URL 'https://test.test.com/test/'\", \"svn: E170001: OPTIONS of 'https://test.test.com/test/': authorization failed: Could not authenticate to server: rejected Basic challenge (https://test.test.com/test/)\"], \"stdout\": \"\", \"stdoutlines\": []}\r\n\r\n##### ADDITIONAL INFORMATION\r\n\r\nWhen you run the command in the shell of the docker container and replace the password manually it successfully checks out the folder. \r\n\r\n```\r\nsvn --non-interactive --trust-server-cert --no-auth-cache --username testUser --password 'manuallyTypedPassword' checkout -r HEAD https://test.test.com/test/\r\n```\r\n\r\nAll the auth caches have been cleared. I think that it may not correctly be escaping the password or something similar?\r\n\r\n"},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n - UI\r\n\r\n##### SUMMARY\r\nmaster playbook that imports others doesn't show up in the playbook selection drop-down list.\r\n##### ENVIRONMENT\r\n* AWX version: 1.0.1.35\r\n* AWX install method: docker\r\n* Ansible version:  2.4.0\r\n* Operating System: Fedora\r\n* Web Browser: Firefox\r\n\r\n##### STEPS TO REPRODUCE\r\nCommit a master playbook that import other to your project, without adding a -hosts attribute\r\n- importplaybook: play1.yml\r\n- importplaybook: play2.yml  \r\n- importplaybook: play2.yml\r\n\r\n\r\n<!-- For bugs, please show exactly how to reproduce the problem. For new\r\nfeatures, show how the feature would be used.  -->\r\n\r\n##### EXPECTED RESULTS\r\n\r\nThe master playbook should appear in the drop-down list\r\n\r\n##### ACTUAL RESULTS\r\n\r\nThe master playbook doesn't show up. Only if I do this, it appears:\r\n\r\n```\r\n- hosts: all\r\n  gatherfacts: no\r\n\r\n- importplaybook: play1.yml\r\n- importplaybook: play2.yml  \r\n- importplaybook: play2.yml\r\n```\r\n\r\n##### ADDITIONAL INFORMATION\r\n\r\n"},
{"text": "##### ISSUE TYPE\r\n<!--- Pick one below and delete the rest: -->\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n<!-- Pick the area of AWX for this issue, you can have multiple, delete the rest: -->\r\n - UI\r\n\r\n##### SUMMARY\r\n<!-- Briefly describe the problem. -->\r\nAuthencation setting not save to database\r\n\r\n##### ENVIRONMENT\r\n* AWX version: 1.0.1.120\r\n* AWX install method: docker on linux\r\n* Ansible version:  2.4.1.0 \r\n* Operating System: Linux\r\n* Web Browser: Chrome\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\n<!-- For bugs, please show exactly how to reproduce the problem. For new\r\nfeatures, show how the feature would be used.  -->\r\nThe LDAP authentication setting ok in the web page, but after logout and login again, I found out the setting not there. go the database and found out the setting not updated to the database. So, just update the database manually, and then it works.\r\nsometimes you can see the setting was lost when you change the other tab and then go back.\r\nlooks like the setting stored in user session but database update failed. \r\n\r\n##### EXPECTED RESULTS\r\n\r\n<!-- For bug reports, what did you expect to happen when running the steps\r\nabove? -->\r\n\r\n##### ACTUAL RESULTS\r\n\r\n<!-- For bug reports, what actually happened? -->\r\n\r\n##### ADDITIONAL INFORMATION\r\n\r\n<!-- Include any links to sosreport, database dumps, screenshots or other\r\ninformation. -->\r\n"},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n - API\r\n - UI\r\n\r\n##### SUMMARY\r\nrelated to issue: https://github.com/ansible/awx/issues/458\r\nWhen a job has associated objects removed from it (projects, inventory, credentials, and template), a system auditor can no longer access the job id, but the admin can.  Not sure why there is any case, where the system wide auditor cannot read a job.\r\n\r\nfrom the UI:\r\nInsufficient Permissions: You do not have permission to view this job.\r\nusing the cli (as a system auditor): towercli.exceptions.Forbidden: You don't have permission to do that.\r\n\r\n##### ENVIRONMENT\r\n* AWX version: AWX 1.0.0.588\r\n* AWX install method:  docker\r\n* Ansible version:  Ansible 2.4.0.0 \r\n* Operating System: RHEL 7.4\r\n* Web Browser: FF ESR 52.3\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\nrun a job as a normal user under any organization.\r\nAfter the job is run, delete the template, inventory, project, and credentials associated with the job.\r\n\r\nQuery the job that was run using a user that is a system auditor for the AWX instance.\r\n\r\n##### EXPECTED RESULTS\r\n\r\nAble to query the job to get stdout and status.\r\n\r\n##### ACTUAL RESULTS\r\n\r\nauditor is unable to query the job\r\n\r\n##### ADDITIONAL INFORMATION\r\n\r\n"},
{"text": "##### ISSUE TYPE\r\n<!--- Pick one below and delete the rest: -->\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n<!-- Pick the area of AWX for this issue, you can have multiple, delete the rest: -->\r\n - API\r\n\r\n##### SUMMARY\r\nCould not run provisioning callback jobs when using loadbalancer IP/host. \r\n`$ curl --data \"hostconfigkey=ac2960188ddd70b965fedcd037b57732\" https://tower.staging.hcom:443/api/v2/jobtemplates/24/callback/ -XPOST\r\n{\"msg\":\"No matching host could be found!\"}`\r\n\r\nwhere https://tower.staging.hcom:443 is load-balancer VIP\r\nNecessary REMOTEHOSTHEADERS are set correctly.\r\n\r\n##### ENVIRONMENT\r\n* AWX version: 1.0.1-143\r\n* AWX install method: docker on linux\r\n* Ansible version:  2.4\r\n* Operating System: Linux\r\n* Web Browser: curl\r\n\r\n##### STEPS TO REPRODUCE\r\nRun callback job using LB host\r\n\r\n##### EXPECTED RESULTS\r\nCallback job is executed successfully basing on \"REMOTEADDR\" HTTP header. \r\n\r\n##### ACTUAL RESULTS\r\n<!-- For bug reports, what did you expect to happen when running the steps\r\nabove? -->\r\nRun job using LP IP-address:\r\n`$ curl --data \"hostconfigkey=ac2960188ddd70b965fedcd037b57731\" https://tower.staging.hcom:443/api/v2/jobtemplates/24/callback/ -XPOST\r\n{\"msg\":\"No matching host could be found!\"}`\r\n\r\nActual HTTP header which is sent from LB:\r\n\r\n> POST /api/v2/jobtemplates/24/callback/ HTTP/1.1\r\n> User-Agent: curl/7.29.0\r\n> Host: tower.staging.hcom\r\n> Accept: */*\r\n> Content-Length: 48\r\n> Content-Type: application/x-www-form-urlencoded\r\n> REMOTEADDR: 10.187.106.161\r\n> hostconfigkey=ac2960188ddd70b965fedcd037b57731\r\n> 11:33:56.249775 IP 10.187.64.17.51905 > 10.187.65.120.http: Flags [.], ack 1424990846, win 8190, length 0\r\n\r\nAWX settings:\r\n`    \"REMOTEHOSTHEADERS\": [\r\n        \"True-Client-IP\",\r\n        \"REMOTEADDR\",\r\n        \"REMOTEHOST\"\r\n    ],`\r\n\r\nSo, LB correctly sets REMOTEADDR header which is configured in AWX system settings - \"REMOTE HOST HEADERS\" but AWX still rejects such callback job execution.\r\n\r\nLogs:\r\n`2017-11-02 16:41:51,837 WARNING  awx.api.generics status 400 received by user AnonymousUser attempting to access /api/v2/jobtemplates/24/callback/ from 10.187.64.17\r\n10.187.64.17 - - [02/Nov/2017:16:41:51 +0000] \"POST /api/v2/jobtemplates/24/callback/ HTTP/1.1\" 400 53 \"-\" \"curl/7.29.0\" \"-\"\r\n[pid: 318|app: 0|req: 795/24358] 10.187.64.17 () {36 vars in 530 bytes} [Thu Nov  2 16:41:51 2017] POST /api/v2/jobtemplates/24/callback/ => generated 42 bytes in 60 msecs (HTTP/1.1 400) 6 headers in 191 bytes (1 switches on core 0)`\r\n\r\nwhere 10.187.64.17 is LB address, not actual client address.\r\n\r\nWhen calling AWX host directly everything works fine (AWX recognizes remote host as one from inventory):\r\n\r\n`curl --data \"hostconfigkey=ac2960188ddd70b965fedcd037b57732\" http://chhlapphot830/api/v2/jobtemplates/24/callback/`\r\n\r\n`10.187.106.161 - - [02/Nov/2017:16:44:43 +0000] \"POST /api/v2/jobtemplates/24/callback/ HTTP/1.1\" 201 5 \"-\" \"curl/7.29.0\" \"-\"\r\n[pid: 404|app: 0|req: 61/24393] 10.187.106.161 () {36 vars in 527 bytes} [Thu Nov  2 16:44:42 2017] POST /api/v2/jobtemplates/24/callback/ => generated 0 bytes in 227 msecs (HTTP/1.1 201) 6 headers in 204 bytes (1 switches on core 0)\r\n[pid: 376|app: 0|req: 234/24394] 10.187.64.17 () {46 vars in 2333 bytes} [Thu Nov  2 16:44:44 2017] GET /api/v2/dashboard/graphs/jobs/?period=month&jobtype=all => generated 1126 bytes in 49 msecs (HTTP/1.1 200) 7 headers in 202 bytes (1 switches on core 0)`\r\n <!-- For bug reports, what actually happened? -->\r\n\r\n"},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n - API\r\n- AWX-TASK Container\r\n\r\n##### SUMMARY\r\nWhen cloning a Git Repo over SSH which has submodules, the Submodules fail to clone.\r\nThis is with cert or password auth. The credentials get used for the main repo, but are not applyed to the Submodule. This is because AWX sets the username when cloning the main repo, but does not do that for submodules.\r\n\r\nSo This will Fail\r\n```\r\n[submodule \"roles/yourrole\"]\r\n\tpath = roles/yourrole\r\n\turl = ssh://git.yourserver.com:29418/ansible/roles/yourrole.git\r\n```\r\n\r\nWhen adding a username in `.gitmodules` the clone works and the cert gets used correctly by awx. Howerver this is bad practice as other users of that Repo fail to clone it because they always have a wrong user.\r\n```\r\n[submodule \"roles/yourrole\"]\r\n\tpath = roles/yourrole\r\n\turl = ssh://awxuser@git.yourserver.com:29418/ansible/roles/yourrole.git\r\n```\r\n\r\n\r\nAs a Workaround , one can add this in `/etc/ssh/sshconf` to force that username on a specific server in the `awxtask` container.\r\n```\r\nHost git.yourserver.com\r\n        HostName git.yourserver.com\r\n        User awxuser\r\n```\r\n\r\n##### ENVIRONMENT\r\n* AWX version: 1.0.1.100\r\n* AWX install method: docker / open source installer via playbook\r\n* Ansible version:  2.4.0.0\r\n* Operating System: RHEL7\r\n* Web Browser: Chrome\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\nClone Project wirth submodules over SSH. The submodules must not specefy a username.\r\n\r\n```\r\n[submodule \"roles/yourrole\"]\r\n\tpath = roles/yourrole\r\n\turl = ssh://git.yourserver.com:29418/ansible/roles/yourrole.git\r\n```\r\n\r\nAll hase to be done over SSH and authentication is required for the Git Server.\r\n\r\n##### EXPECTED RESULTS\r\n\r\nClone submodules works with the Username and the Password/cert of the Credentials that are used to clone the Project in AWX.\r\n\r\n##### ACTUAL RESULTS\r\n\r\n```\r\nfatal: [localhost]: FAILED! => {\"changed\": false, \"cmd\": \"/usr/bin/git submodule foreach /usr/bin/git fetch\", \"failed\": true, \"msg\": \"Permission denied (password,keyboard-interactive,publickey).\\r\\nfatal: Could not read from remote repository.\\n\\nPlease make sure you have the correct access rights\\nand the repository exists.\\nStopping at 'roles/yourrole'; script returned non-zero status.\", \"rc\": 1, \"stderr\": \"Permission denied (password,keyboard-interactive,publickey).\\r\\nfatal: Could not read from remote repository.\\n\\nPlease make sure you have the correct access rights\\nand the repository exists.\\nStopping at 'roles/yourrole'; script returned non-zero status.\\n\", \"stderrlines\": [\"Permission denied (password,keyboard-interactive,publickey).\", \"fatal: Could not read from remote repository.\", \"\", \"Please make sure you have the correct access rights\", \"and the repository exists.\", \"Stopping at 'roles/yourrole'; script returned non-zero status.\"], \"stdout\": \"Entering 'roles/yourrole'\\n\", \"stdoutlines\": [\"Entering 'roles/yourrole'\"]}\r\n```\r\n"},
{"text": "##### ISSUE TYPE\r\n<!--- Pick one below and delete the rest: -->\r\n - Bug Report\r\n\r\n\r\n##### COMPONENT NAME\r\n<!-- Pick the area of AWX for this issue, you can have multiple, delete the rest: -->\r\n - API\r\n\r\n\r\n##### SUMMARY\r\n<!-- Briefly describe the problem. -->\r\nI am trying to deploy a playbook on a remote host, deploying some docker containers like Mysql for example, but when using delegateto: mysql to create DB inside the container it gives me:\r\n\r\n```\r\ndocker: executable file not found in PATH\r\n```\r\n\r\nBecause docker is not present on awx-task container. \r\nIs it possible to use docker remote host to deploy the playbook on the remote host and then use delegateto to get inside the container host.\r\n\r\nOr to install docker inside awx-task so it can use it to delegateto: directly on the remote container host.\r\n\r\n##### ENVIRONMENT\r\n* AWX version:1.0.1.153 \r\n* AWX install method: docker on linux\r\n* Ansible version:  2.4.1.0\r\n* Operating System: Ubuntu Linux\r\n* Web Browser: Chrome\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\n<!-- For bugs, please show exactly how to reproduce the problem. For new\r\nfeatures, show how the feature would be used.  -->\r\nDeploy the following playbook\r\n\r\n```\r\n- hosts: all\r\n  become: yes\r\n  gatherfacts: False\r\n  vars:\r\n   - ansiblepythoninterpreter: /usr/bin/python2.7\r\n   - ansiblesudopass:\r\n  tasks:\r\n    - name: Mysql docker container UP\r\n      dockercontainer:\r\n        name: db\r\n        image: mysql:latest\r\n        state: started\r\n        restartpolicy: always\r\n        env:\r\n          MYSQLROOTPASSWORD: \r\n\r\n    - name: add Mysql container to inventory\r\n      addhost:\r\n        name: db\r\n        ansibleconnection: docker\r\n        ansibleuser: root\r\n        ansibledockerextraargs: \"-H=tcp://remotehost:2375\"\r\n      changedwhen: False\r\n\r\n    - name: install DB\r\n      delegateto: db\r\n      gatherfacts: False\r\n      mysqldb:\r\n        name: test\r\n        state: present\r\n\r\n```\r\n\r\n\r\n##### EXPECTED RESULTS\r\n\r\n<!-- For bug reports, what did you expect to happen when running the steps\r\nabove? -->\r\n\r\nTo install DB on remote docker container\r\n\r\n##### ACTUAL RESULTS\r\n\r\n<!-- For bug reports, what actually happened? -->\r\n\r\n```\r\ndocker: executable file not found in PATH\r\n```\r\n\r\n\r\n##### ADDITIONAL INFORMATION\r\n\r\n<!-- Include any links to sosreport, database dumps, screenshots or other\r\ninformation. -->\r\n\r\nTried to install docker on awx-task docker container and it will not show the following error anymore:\r\n```\r\ndocker: executable file not found in PATH\r\n```\r\n\r\nBut instead shows that the docker daemon is not active.\r\n"},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n - API\r\n - UI\r\n\r\n##### SUMMARY\r\nJust deployed awx on OCP 3.5 following this [guide](https://developers.redhat.com/blog/2017/10/16/guide-starting-use-awx-top-openshift-upstream-red-hat-ansible-tower/) and now attempting to set up LDAP / AD. When we click save the page refreshes & the filled in boxes stay, however, if you browse to another area data in the fields is lost.\r\n\r\n##### ENVIRONMENT\r\n* AWX version: AWX 1.0.1.157\r\n* AWX install method: openshift\r\nopenshift v3.5.5.31\r\nkubernetes v1.5.2+43a9be4\r\n* Ansible version: Ansible 2.4.1.0\r\n* Operating System: Red Hat Enterprise Linux Server release 7.3 (Maipo)\r\n* Web Browser: \r\nMac OS X 10126 Chrome/61.0.3163.100\r\nMac OS X 10.12 Firefox/56.0\r\n\r\n##### STEPS TO REPRODUCE\r\nLog in with default admin / password > settings > authentication > subcategory LDAP > fill in text fields > click save.\r\n\r\n##### EXPECTED RESULTS\r\nExpected settings to be saved.\r\n\r\n##### ACTUAL RESULTS\r\nPaged refreshed however data in fields is not saved if you browse to another section in awx.\r\n\r\n##### ADDITIONAL INFORMATION\r\nPlease note, that we do not have any external load balancers in front of OCP, other than using the native HAProxy.\r\n\r\nSee the following errors in the logs\r\n>2017/11/10 16:57:24 [error] 39#0: *39 connect() failed (111: Connection refused) while connecting to upstream, client: 10.1.0.1, server: , request: \"PATCH /api/v2/settings/all/ HTTP/1.1\", upstream: \"uwsgi://[::1]:8050\", host: \"awxui.openshift.server.com\", referrer: \"http://awxui.openshift.server.com/\"\r\n2017/11/10 16:57:24 [warn] 39#0: *39 upstream server temporarily disabled while connecting to upstream, client: 10.1.0.1, server: , request: \"PATCH /api/v2/settings/all/ HTTP/1.1\", upstream: \"uwsgi://[::1]:8050\", host: \"awxui.openshift.server.com\", referrer: \"http://awxui.openshift.server.com/\"\r\n2017-11-10 16:57:24,957 WARNING  awx.api.generics status 400 received by user admin attempting to access /api/v2/settings/all/ from 10.1.0.1\r\n[pid: 34|app: 0|req: 1/22] 10.1.0.1 () {60 vars in 3571 bytes} [Fri Nov 10 16:57:24 2017] PATCH /api/v2/settings/all/ => generated 54 bytes in 439 msecs (HTTP/1.1 400) 7 headers in 248 bytes (1 switches on core 0)\r\n10.1.0.1 - - [10/Nov/2017:16:57:24 +0000] \"PATCH /api/v2/settings/all/ HTTP/1.1\" 400 65 \"http://awxui.openshift.server.com/\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10126) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36\" \"167.209.70.250\"\r\nerror: unexpected EOF\r\n\r\nWorking on gathering and making all logs available.\r\n"},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n##### COMPONENT NAME\r\n - API\r\n##### SUMMARY\r\nsdtout api  for example  /api/v2/jobs/216/stdout/ not work the result is always the message\r\n**stdout capture is missing**\r\nBut in AWX the standard output of job work fine.\r\n\r\n\r\n##### ENVIRONMENT\r\n* AWX api v2\r\n* AWX install method: docker on linux\r\n* Ansible version:  X.Y.Z\r\n* Operating System:RHEL 7.x\r\n* Web Browser:All\r\n\r\n##### STEPS TO REPRODUCE\r\nExecute a job on AWX UI\r\ncall the api /api/v2/jobs/{ID}/stdout/\r\nwhere ID = Job ID\r\n\r\n##### EXPECTED RESULTS\r\n\r\nstandard output of executed jobs with JSON format\r\n\r\n##### ACTUAL RESULTS\r\n\r\n**stdout capture is missing**\r\n\r\n"},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n \r\n##### COMPONENT NAME\r\n<!-- Pick the area of AWX for this issue, you can have multiple, delete the rest: -->\r\n - API\r\n - UI\r\n\r\n\r\n##### SUMMARY\r\nHello guys, i have a job without valid project ( no playbook, because my url wrong ) and when i launch this project in job section i see that my job template is running, and i'm don't have ability to delete or terminate this, why? i wanna to force delete this job.i'm click on cancel button, the windows with (Are you sure you want to cancel the job below?) i'm click on ok and nothing changes.\r\njob is still running\r\n\r\n##### ENVIRONMENT\r\n* AWX version 1.0.1.120\r\n* AWX install method: , docker on linux\r\n* Ansible version:  2.4.1.0\r\n* Operating System: Ubuntu 16.04\r\n* Web Browser: Mozila\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\n\r\nset the wrong scm url to github and launch project\r\n\r\n"},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n - API\r\n\r\n##### SUMMARY\r\n\r\n1. Create job template\r\n2. Set inventory to prompt on launch (no default)\r\n3. Enable provisioning callback\r\n4. Hit save\r\n\r\n##### ENVIRONMENT\r\n* AWX version: any\r\n\r\n##### EXPECTED RESULTS\r\n\r\nError (because that isn't going to work)\r\n\r\n##### ACTUAL RESULTS\r\n\r\nSucceeds. AWX 500s if you hit the callback.\r\n\r\n##### ADDITIONAL INFORMATION\r\n\r\n"},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n - API\r\n\r\n##### SUMMARY\r\nIf the API client provides job template related resources on launch (creds, inventory), the API would give a 403 response.\r\n\r\n##### ENVIRONMENT\r\n* AWX version: 1.0.1\r\n* AWX install method: docker for mac\r\n* Ansible version:  N/A\r\n* Operating System:\r\n* Web Browser:\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\n - Create a job template set to prompt for everything on launch\r\n - Log in as a user with executerole to the job template, and nothing else\r\n - Launch the job in the UI\r\n\r\n##### EXPECTED RESULTS\r\nThis is the same as launching the JT without providing new resources. The executerole should be enough to launch.\r\n\r\n##### ACTUAL RESULTS\r\nPermission denied for not having access to related resources that are already attached to the job template.\r\n\r\n##### ADDITIONAL INFORMATION\r\nhttps://github.com/ansible/awx/pull/649"},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n - API\r\n\r\n##### SUMMARY\r\n\r\nWhen I pass valid YAML for an injector that isn't a valid injector configuration, the error is not user-friendly.\r\n\r\n##### ENVIRONMENT\r\n* AWX version: 1.x\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\nWrite a new credential type.\r\n\r\nEnter the following YAML as an injector, because you forgot the syntax:\r\n```\r\nextravars:\r\n - 'a': \"{{ b }}\"\r\n - 'c': \"{{ d }}\"\r\n```\r\n\r\n##### EXPECTED RESULTS\r\n\r\nNot sure, something like:\r\n\r\n`List passed, expected dictionary`.\r\n\r\n##### ACTUAL RESULTS\r\n\r\n`[OrderedDict([('a', '{{ b }}')]), OrderedDict([('c', '{{ d }}')])] is not of type 'object'`\r\n\r\n##### ADDITIONAL INFORMATION\r\n\r\nProbably applies to inputs as well.\r\n"},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n - API\r\n\r\n##### SUMMARY\r\n\r\nI cannot inject unicode extra vars with a custom credential type.\r\n\r\n##### ENVIRONMENT\r\n* AWX version: 1.any\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\n1. Create a custom credential type\r\n2. Unleash the dragon in the injector\r\n```\r\nextravars:\r\n  '': '{{ dragonname }}'\r\n```\r\n\r\n##### EXPECTED RESULTS\r\n\r\nSucceeds (this works when setting regular extravars)\r\n\r\n##### ACTUAL RESULTS\r\n\r\nValidation error:\r\n`'\\U0001f409\\U0001f409\\U0001f409' does not match any of the regexes: '^[a-zA-Z]+[a-zA-Z0-9]*$'`\r\n\r\n##### ADDITIONAL INFORMATION\r\n\r\n"},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n - API\r\n\r\n##### SUMMARY\r\nPOST to a job's relaunch endpoint when it has a credential that requires passwords, not providing the passwords, creates a job with \"new\" status, which never goes away.\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\n - Create a credential that asks for ssh password\r\n - Attach this to a JT, launch it, provide the password\r\n - POST to `/api/v2/jobs/N/relaunch/` where N was that previous job, and provide `{}` request data\r\n\r\n##### EXPECTED RESULTS\r\n\r\nA 400 status response is returned\r\n\r\nA new job is not created.\r\n\r\n##### ACTUAL RESULTS\r\n\r\nA 400 status response is returned.\r\n\r\nA job is created. This job has `\"status\": \"new\"`, which is not good.\r\n\r\nNew job is not started, left in \"new\" state.\r\n\r\n"},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n - API\r\n\r\n##### SUMMARY\r\nThis is an old issue, ~Tower 3.0, moving this to AWX. \r\n\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\nRun the following integration test ...\r\n\r\n```\r\ntests/api/testjobs.py::TestUpdateOnLaunch::testinventory[aws] PASSED\r\ntests/api/testjobs.py::TestUpdateOnLaunch::testinventory[aws] ERROR\r\n ERROR at teardown of TestUpdateOnLaunch.testinventory[aws] \r\nTraceback (most recent call last):\r\n  File \"/Users/jlaska/Projects/tower-qa.git/tests/lib/common/api/pages/base.py\", line 162, in delete\r\n    return self.handlerequest(r)\r\n  File \"/Users/jlaska/Projects/tower-qa.git/tests/lib/common/api/pages/base.py\", line 132, in handlerequest\r\n    raise common.exceptions.InternalServerErrorException(excstr, data)\r\nInternalServerErrorException: ('Internal Server Error (500) received', {})\r\n```\r\n\r\n\r\n##### ACTUAL RESULTS\r\n\r\n```\r\n2015-06-20 13:54:42,853 ERROR    django.request Internal Server Error: /api/v1/groups/3631/\r\nTraceback (most recent call last):\r\n  File \"/usr/lib64/python2.7/site-packages/django/core/handlers/base.py\", line 112, in getresponse\r\n    response = wrappedcallback(request, *callbackargs, **callbackkwargs)\r\n  File \"/usr/lib64/python2.7/site-packages/django/db/transaction.py\", line 371, in inner\r\n    return func(*args, **kwargs)\r\n  File \"/usr/lib64/python2.7/site-packages/django/views/generic/base.py\", line 69, in view\r\n    return self.dispatch(request, *args, **kwargs)\r\n  File \"/usr/lib64/python2.7/site-packages/django/views/decorators/csrf.py\", line 57, in wrappedview\r\n    return viewfunc(*args, **kwargs)\r\n  File \"/usr/lib/python2.7/site-packages/awx/lib/site-packages/restframework/views.py\", line 400, in dispatch\r\n    response = self.handleexception(exc)\r\n  File \"/usr/lib/python2.7/site-packages/awx/lib/site-packages/restframework/views.py\", line 397, in dispatch\r\n    response = handler(request, *args, **kwargs)\r\n  File \"/usr/lib/python2.7/site-packages/awx/lib/site-packages/restframework/generics.py\", line 497, in delete\r\n    return self.destroy(request, *args, **kwargs)\r\n  File \"/usr/lib/python2.7/site-packages/awx/api/views.py\", line 1399, in destroy\r\n  File \"/usr/lib64/python2.7/site-packages/django/db/transaction.py\", line 371, in inner\r\n    return func(*args, **kwargs)\r\n  File \"/usr/lib/python2.7/site-packages/awx/main/models/inventory.py\", line 593, in markinactiverecursive\r\n  File \"/usr/lib/python2.7/site-packages/awx/main/models/inventory.py\", line 586, in markactual\r\n  File \"/usr/lib64/python2.7/site-packages/django/db/models/query.py\", line 493, in update\r\n    rows = query.getcompiler(self.db).executesql(None)\r\n  File \"/usr/lib64/python2.7/site-packages/django/db/models/sql/compiler.py\", line 980, in executesql\r\n    cursor = super(SQLUpdateCompiler, self).executesql(resulttype)\r\n  File \"/usr/lib64/python2.7/site-packages/django/db/models/sql/compiler.py\", line 786, in executesql\r\n    cursor.execute(sql, params)\r\n  File \"/usr/lib64/python2.7/site-packages/django/db/backends/util.py\", line 53, in execute\r\n    return self.cursor.execute(sql, params)\r\n  File \"/usr/lib64/python2.7/site-packages/django/db/utils.py\", line 99, in exit\r\n    six.reraise(djexctype, djexcvalue, traceback)\r\n  File \"/usr/lib64/python2.7/site-packages/django/db/backends/util.py\", line 53, in execute\r\n    return self.cursor.execute(sql, params)\r\nOperationalError: deadlock detected\r\nDETAIL:  Process 24823 waits for ShareLock on transaction 46387; blocked by process 29587.\r\nProcess 29587 waits for ShareLock on transaction 46453; blocked by process 24823.\r\nHINT:  See server log for query details.\r\nCONTEXT:  while updating tuple (305,4) in relation \"mainhost\"\r\n```\r\n\r\n\r\n##### ADDITIONAL INFORMATION\r\n\r\n\r\nPostgres log:\r\n\r\n```\r\n< 2015-06-20 17:54:42.851 UTC >ERROR:  deadlock detected\r\n< 2015-06-20 17:54:42.851 UTC >DETAIL:  Process 24823 waits for ShareLock on transaction 46387; blocked by process 29587.\r\n        Process 29587 waits for ShareLock on transaction 46453; blocked by process 24823.\r\n        Process 24823: UPDATE \"mainhost\" SET \"active\" = false WHERE \"mainhost\".\"id\" IN (4554, 4546, 4544, 4541, 4540, 4532, 4527, 4519, 4503, 4502, 4501, 4556, 4531, 4548, 4536, 4530, 4537, 4542, 4529, 4525, 4552, 4533, 4555, 4553, 4551, 4550, 4549, 4547, 4545, 4538, 4535, 4528, 4526, 4524, 4523, 4522, 4521, 4520, 4517, 4513, 4512, 4511, 4510, 4509, 4508, 4507, 4506, 4505, 4504, 4539, 4518, 4534, 4514, 4543, 4516, 4515)\r\n        Process 29587: UPDATE \"maingroup\" SET \"modified\" = '2015-06-20 17:54:41.875553+00:00', \"modifiedbyid\" = NULL, \"hasactivefailures\" = true, \"hostswithactivefailures\" = 4 WHERE \"maingroup\".\"id\" = 3632\r\n< 2015-06-20 17:54:42.851 UTC >HINT:  See server log for query details.\r\n< 2015-06-20 17:54:42.851 UTC >CONTEXT:  while updating tuple (305,4) in relation \"mainhost\"\r\n< 2015-06-20 17:54:42.851 UTC >STATEMENT:  UPDATE \"mainhost\" SET \"active\" = false WHERE \"mainhost\".\"id\" IN (4554, 4546, 4544, 4541, 4540, 4532, 4527, 4519, 4503, 4502, 4501, 4556, 4531, 4548, 4536, 4530, 4537, 4542, 4529, 4525, 4552, 4533, 4555, 4553, 4551, 4550, 4549, 4547, 4545, 4538, 4535, 4528, 4526, 4524, 4523, 4522, 4521, 4520, 4517, 4513, 4512, 4511, 4510, 4509, 4508, 4507, 4506, 4505, 4504, 4539, 4518, 4534, 4514, 4543, 4516, 4515)\r\n```\r\n\r\n\"Assuming I'm understanding correctly, this error happens because a DELETE request is issued while asynchronous work (calculated fields or cascade deletion)? Is there a way I can instrument integration to detect and wait for any asynchronous processing to complete?\"\r\n"},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n - UI\r\n\r\n##### SUMMARY\r\nAWX task and was stop working after restart container with RabbitMQ\r\n\r\n##### ENVIRONMENT\r\n* AWX version: 1.0.1.167\r\n* AWX install method: docker on linux\r\n* Web Browser: FireFox\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\nJust restart container with RabbitMQ. Web and Task containers will lost connection.\r\n\r\n##### EXPECTED RESULTS\r\n\r\nContinue working.\r\n\r\n##### ACTUAL RESULTS\r\n\r\nIn Web showing pending status for jobs."},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n - API\r\n\r\n##### SUMMARY\r\nuri module will output the password argument in plaintext to the eventdata.taskargs field within the jobevents list\r\n\r\n##### ENVIRONMENT\r\n* AWX version: 1.0.1.50\r\n* AWX install method: docker on linux\r\n* Ansible version:  2.4.0.0\r\n* Operating System: Red Hat Enterprise Linux\r\n* Web Browser: Chrome\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\nexamine the jobevents list for any job that includes a uri task with a password\r\n\r\n##### EXPECTED RESULTS\r\n\r\nblanked out password similar to how vault passwords are handled within jobevents\r\n\r\n##### ACTUAL RESULTS\r\n\r\n\"eventdata\": {\r\n                \"playpattern\": \"linux\",\r\n                \"play\": \"Generate oAuth Token\",\r\n                \"eventloop\": null,\r\n                \"taskargs\": \"body=username=username&password=password\"\r\n\r\n*username and password have been substituted"},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n - API\r\n\r\n##### SUMMARY\r\nIf an instance in an instance group is at or over capacity, but the instance group is not over capacity, that instance can still get more jobs and, when the capacity is exceeded, the percentage will become negative for the instance.\r\n\r\n\r\n##### ENVIRONMENT\r\n* AWX version: 1.0.1\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\nLaunch several jobs against a particular instance group, such that the capacity of a particular instance is exceeded.\r\n\r\n##### EXPECTED RESULTS\r\n\r\nThe instance that is at capacity would not be assigned additional work, but work would rather be assigned to the node on which capacity remains\r\n\r\n##### ACTUAL RESULTS\r\n\r\nThe work may be assigned to the instance that is at or above capacity.\r\n\r\n##### ADDITIONAL INFORMATION\r\n\r\n<!-- Include any links to sosreport, database dumps, screenshots or other\r\ninformation. -->\r\n"},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n\r\n\r\n##### COMPONENT NAME\r\n - API\r\n\r\n\r\n##### SUMMARY\r\nWhile  deleting an ec2 inventory source the following was observed:\r\n\r\n```\r\nawx1        | 19:02:17 uwsgi.1     | 2017-11-14 19:02:17,163 ERROR    django.request Internal Server Error: /api/v2/inventorysources/22/hosts/\r\nawx1        | 19:02:17 uwsgi.1     | Traceback (most recent call last):\r\nawx1        | 19:02:17 uwsgi.1     |   File \"/venv/awx/lib/python2.7/site-packages/django/core/handlers/base.py\", line 132, in getresponse\r\nawx1        | 19:02:17 uwsgi.1     |     response = wrappedcallback(request, *callbackargs, **callbackkwargs)\r\nawx1        | 19:02:17 uwsgi.1     |   File \"/venv/awx/lib/python2.7/site-packages/django/utils/decorators.py\", line 145, in inner\r\nawx1        | 19:02:17 uwsgi.1     |     return func(*args, **kwargs)\r\nawx1        | 19:02:17 uwsgi.1     |   File \"/venv/awx/lib/python2.7/site-packages/django/views/decorators/csrf.py\", line 58, in wrappedview\r\nawx1        | 19:02:17 uwsgi.1     |     return viewfunc(*args, **kwargs)\r\nawx1        | 19:02:17 uwsgi.1     |   File \"/venv/awx/lib/python2.7/site-packages/django/views/generic/base.py\", line 71, in view\r\nawx1        | 19:02:17 uwsgi.1     |     return self.dispatch(request, *args, **kwargs)\r\nawx1        | 19:02:17 uwsgi.1     |   File \"./awx/api/generics.py\", line 246, in dispatch\r\nawx1        | 19:02:17 uwsgi.1     |     return super(APIView, self).dispatch(request, *args, **kwargs)\r\nawx1        | 19:02:17 uwsgi.1     |   File \"/venv/awx/lib/python2.7/site-packages/restframework/views.py\", line 466, in dispatch\r\nawx1        | 19:02:17 uwsgi.1     |     response = self.handleexception(exc)\r\nawx1        | 19:02:17 uwsgi.1     |   File \"/venv/awx/lib/python2.7/site-packages/restframework/views.py\", line 463, in dispatch\r\nawx1        | 19:02:17 uwsgi.1     |     response = handler(request, *args, **kwargs)\r\nawx1        | 19:02:17 uwsgi.1     |   File \"/venv/awx/lib/python2.7/site-packages/restframework/generics.py\", line 220, in delete\r\nawx1        | 19:02:17 uwsgi.1     |     return self.destroy(request, *args, **kwargs)\r\nawx1        | 19:02:17 uwsgi.1     |   File \"./awx/api/generics.py\", line 466, in destroy\r\nawx1        | 19:02:17 uwsgi.1     |     self.performlistdestroy(instancelist)\r\nawx1        | 19:02:17 uwsgi.1     |   File \"./awx/api/generics.py\", line 476, in performlistdestroy\r\nawx1        | 19:02:17 uwsgi.1     |     self.performdestroy(instance, checkpermission=False)\r\nawx1        | 19:02:17 uwsgi.1     |   File \"./awx/api/generics.py\", line 452, in performdestroy\r\nawx1        | 19:02:17 uwsgi.1     |     super(DestroyAPIView, self).performdestroy(instance)\r\nawx1        | 19:02:17 uwsgi.1     |   File \"/venv/awx/lib/python2.7/site-packages/restframework/mixins.py\", line 91, in performdestroy\r\nawx1        | 19:02:17 uwsgi.1     |     instance.delete()\r\nawx1        | 19:02:17 uwsgi.1     |   File \"./awx/main/models/inventory.py\", line 604, in delete\r\nawx1        | 19:02:17 uwsgi.1     |     super(Host, self).delete(*args, **kwargs)\r\nawx1        | 19:02:17 uwsgi.1     |   File \"/venv/awx/lib/python2.7/site-packages/django/db/models/base.py\", line 896, in delete\r\nawx1        | 19:02:17 uwsgi.1     |     collector.delete()\r\nawx1        | 19:02:17 uwsgi.1     |   File \"/venv/awx/lib/python2.7/site-packages/django/db/models/deletion.py\", line 309, in delete\r\nawx1        | 19:02:17 uwsgi.1     |     query.deletebatch(pklist, self.using)\r\nawx1        | 19:02:17 uwsgi.1     |   File \"/venv/awx/lib/python2.7/site-packages/django/db/models/sql/subqueries.py\", line 41, in deletebatch\r\nawx1        | 19:02:17 uwsgi.1     |     self.doquery(self.getmeta().dbtable, self.where, using=using)\r\nawx1        | 19:02:17 uwsgi.1     |   File \"/venv/awx/lib/python2.7/site-packages/django/db/models/sql/subqueries.py\", line 26, in doquery\r\nawx1        | 19:02:17 uwsgi.1     |     self.getcompiler(using).executesql(NORESULTS)\r\nawx1        | 19:02:17 uwsgi.1     |   File \"/venv/awx/lib/python2.7/site-packages/django/db/models/sql/compiler.py\", line 840, in executesql\r\nawx1        | 19:02:17 uwsgi.1     |     cursor.execute(sql, params)\r\nawx1        | 19:02:17 uwsgi.1     |   File \"/venv/awx/lib/python2.7/site-packages/django/db/backends/utils.py\", line 79, in execute\r\nawx1        | 19:02:17 uwsgi.1     |     return super(CursorDebugWrapper, self).execute(sql, params)\r\nawx1        | 19:02:17 uwsgi.1     |   File \"/venv/awx/lib/python2.7/site-packages/django/db/backends/utils.py\", line 64, in execute\r\nawx1        | 19:02:17 uwsgi.1     |     return self.cursor.execute(sql, params)\r\nawx1        | 19:02:17 uwsgi.1     |   File \"/venv/awx/lib/python2.7/site-packages/django/db/utils.py\", line 98, in exit\r\nawx1        | 19:02:17 uwsgi.1     |     six.reraise(djexctype, djexcvalue, traceback)\r\nawx1        | 19:02:17 uwsgi.1     |   File \"/venv/awx/lib/python2.7/site-packages/django/db/backends/utils.py\", line 64, in execute\r\nawx1        | 19:02:17 uwsgi.1     |     return self.cursor.execute(sql, params)\r\nawx1        | 19:02:17 uwsgi.1     | OperationalError: deadlock detected\r\nawx1        | 19:02:17 uwsgi.1     | DETAIL:  Process 2534 waits for ShareLock on transaction 24363; blocked by process 2535.\r\nawx1        | 19:02:17 uwsgi.1     | Process 2535 waits for ShareLock on transaction 24358; blocked by process 2534.\r\nawx1        | 19:02:17 uwsgi.1     | HINT:  See server log for query details.\r\nawx1        | 19:02:17 uwsgi.1     | CONTEXT:  while deleting tuple (0,74) in relation \"maingrouphosts\"\r\n```\r\n\r\n\r\n##### ENVIRONMENT\r\n* AWX version: 3.2.2\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\n1) Create and sync an ec2 inventory source\r\n2) Send delete requests to the inventory source's related hosts and groups endpoints.\r\n\r\n##### EXPECTED RESULTS\r\n\r\nSuccessful, performant deletion.\r\n\r\n\r\n##### ACTUAL RESULTS\r\n\r\n500 error and no hosts deleted.\r\n\r\n##### ADDITIONAL INFORMATION\r\n"},
{"text": "##### ISSUE TYPE\r\n<!--- Pick one below and delete the rest: -->\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n<!-- Pick the area of AWX for this issue, you can have multiple, delete the rest: -->\r\n - API\r\n\r\n\r\n##### SUMMARY\r\n<!-- Briefly describe the problem. -->\r\nAfter SAML configured, got 502 from django on metadata page.\r\nSeems like it cant find saml backend.\r\n\r\n##### ENVIRONMENT\r\n* AWX version: AWX 1.0.1.229\r\n* AWX install method: docker for linux\r\n* Ansible version: 2.4.1.0\r\n* Operating System: centos7-core 3.10.0-327.22.2.el7.x8664\r\n* Web Browser: Firefox 56.0 / Chromium 62.0 (Linux Mint)\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\n<!-- For bugs, please show exactly how to reproduce the problem. For new\r\nfeatures, show how the feature would be used.  -->\r\nClean install, with only saml auth configured.\r\n\r\n\r\n##### EXPECTED RESULTS\r\n\r\n<!-- For bug reports, what did you expect to happen when running the steps\r\nabove? -->\r\nCorrect metadata.xml file\r\n\r\n##### ACTUAL RESULTS\r\n<!-- For bug reports, what actually happened? -->\r\n502 bad gateway, \r\nin awxweb logs:\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/socialcore/backends/utils.py\", line 57, in getbackend\r\n    raise MissingBackend(name)\r\nMissingBackend: Missing backend \"saml\" entry\r\n\r\n\r\n##### ADDITIONAL INFORMATION\r\nI've done 2 setups, first was with reverse proxy for https and ssl termination, the second one (after 1st try with saml failed) was clean install, with just SAML auth configured, but result was the same, even with empty config.\r\n\r\n<!-- Include any links to sosreport, database dumps, screenshots or other\r\ninformation. -->\r\n"},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n - UI\r\n- API\r\n\r\n##### SUMMARY\r\nEnd Date & Time in a Schedule is incorrectly inserted into the database as UTC without timezone conversion, which puts the schedule end date/time at a different time than intended.\r\n\r\nOur current workaround is to specify the date/time already converted to UTC, i.e.:\r\n\r\nBug:\r\n\r\nStart date: 11/21/17 - 12:00:00 CST\r\nEnd date: 11/23/17 - 12:00:00 CST <---- this end date/time will actually be 06:00:00 CST in the DB\r\n\r\nWorkaround:\r\n\r\nStart date: 11/21/17 - 12:00:00 CST\r\nEnd date: 11/23/17 - 18:00:00 UTC <---- this end date/time will actually be 12:00:00 CST in the DB\r\n\r\n##### ENVIRONMENT\r\n* AWX version: 1.0.1.223\r\n* AWX install method: official image\r\n* Ansible version:  2.4.1\r\n* Operating System: Centos 7.6\r\n* Web Browser: Chrome/Safari\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\nIn Schedules:\r\n\r\n1. Set a non-UTC local time zone\r\n2. Specify an end date & time\r\n3. Save Schedule\r\n4. Look at the DB row or refresh the UI, the time will now show an incorrect time.\r\n\r\n##### EXPECTED RESULTS\r\n\r\nEnd date & time should be in local time, and should be inserted into the DB with time zone conversion.\r\n\r\n##### ACTUAL RESULTS\r\n\r\nEnd time is inserted directly as UTC with no time zone conversion (workaround pictured)\r\n\r\n<img width=\"1333\" alt=\"screen shot 2017-11-24 at 2 40 35 pm\" src=\"https://user-images.githubusercontent.com/2091431/33223521-ea104314-d125-11e7-99c3-1c525d43a477.png\">\r\n\r\n<img width=\"612\" alt=\"screen shot 2017-11-24 at 2 42 45 pm\" src=\"https://user-images.githubusercontent.com/2091431/33223536-0bb8a9b6-d126-11e7-84f0-a19ca1130b93.png\">\r\n"},
{"text": "##### ISSUE TYPE\r\n<!--- Pick one below and delete the rest: -->\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n<!-- Pick the area of AWX for this issue, you can have multiple, delete the rest: -->\r\n - API\r\n\r\n##### SUMMARY\r\n<!-- Briefly describe the problem. -->\r\nCloudForms inventory import fails with django.core.exceptions.ValidationError. Have tried with both a \"normal\" Cloudforms user credential and an \"admin\" one but same result both times.\r\n\r\n##### ENVIRONMENT\r\n* AWX version: 1.0.1.225 \r\n* AWX install method: docker for mac\r\n* Ansible version:  2.4.1\r\n* Operating System: MacOS 10.12.6\r\n* Web Browser: Chrome 62\r\n* Cloudforms: 4.2 (Management engine Version 5.7.3.2.201706211448546c833cc)\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\n<!-- For bugs, please show exactly how to reproduce the problem. For new\r\nfeatures, show how the feature would be used.  -->\r\n\r\n1. Create new inventory source with source type of Red Hat Cloudforms\r\n2. Run sync\r\n\r\n##### EXPECTED RESULTS\r\n\r\n<!-- For bug reports, what did you expect to happen when running the steps\r\nabove? -->\r\n\r\n* Inventory import successfully completes.\r\n\r\n##### ACTUAL RESULTS\r\n\r\n<!-- For bug reports, what actually happened? -->\r\n\r\n* Inventory import fails with \"django.core.exceptions.ValidationError: [u\\\"'<object object at 0x7830fe0>' value must be either True or False.\\\"]\" error\r\n\r\n##### ADDITIONAL INFORMATION\r\n\r\n<!-- Include any links to sosreport, database dumps, screenshots or other\r\ninformation. -->\r\nLog file:\r\n```\r\n2017-11-23 01:44:04,433 INFO     awx.main.commands.inventoryimport Updating inventory 2: CF\r\n2017-11-23 01:44:04,472 INFO     awx.main.commands.inventoryimport Reading Ansible inventory source: /usr/lib/python2.7/site-packages/awx/plugins/inventory/cloudforms.py\r\n2017-11-23 01:44:34,698 INFO     awx.main.commands.inventoryimport Processing JSON output...\r\n2017-11-23 01:44:34,720 INFO     awx.main.commands.inventoryimport Loaded 322 groups, 266 hosts\r\n...\r\n2017-11-23 01:44:34,739 WARNING  awx.main.commands.inventoryimport Host \\\"<redacted1>\\\" has no \\\"id\\\" variable\r\n2017-11-23 01:44:34,739 WARNING  awx.main.commands.inventoryimport Host \\\"<redacted2>\\\" has no \\\"id\\\" variable\r\n2017-11-23 01:44:34,739 WARNING  awx.main.commands.inventoryimport Host \\\"<redacted3>\\\" has no \\\"id\\\" variable\r\n...\r\n2017-11-23 01:44:38,254 INFO     awx.main.commands.inventoryimport Group \\\"<redacted4>ovf\\\" added\r\n2017-11-23 01:44:38,261 INFO     awx.main.commands.inventoryimport Group \\\"<redacted5>ovf\\\" added\r\n2017-11-23 01:44:38,269 INFO     awx.main.commands.inventoryimport Group \\\"location\\\" added\r\n2017-11-23 01:44:38,276 INFO     awx.main.commands.inventoryimport Group \\\"redhat\\\" added\r\n2017-11-23 01:44:38,283 INFO     awx.main.commands.inventoryimport Group \\\"tags\\\" added\r\n2017-11-23 01:44:38,290 INFO     awx.main.commands.inventoryimport Group \\\"type\\\" added\r\n2017-11-23 01:44:38,298 INFO     awx.main.commands.inventoryimport Group \\\"vendor\\\" added\r\nTraceback (most recent call last):\r\n  File \\\"/usr/bin/awx-manage\\\", line 9, in <module>\r\n    loadentrypoint('awx==1.0.1.225', 'consolescripts', 'awx-manage')()\r\n  File \\\"/usr/lib/python2.7/site-packages/awx/init.py\\\", line 109, in manage\r\n    executefromcommandline(sys.argv)\r\n  File \\\"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/core/management/init.py\\\", line 364, in executefromcommandline\r\n    utility.execute()\r\n  File \\\"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/core/management/init.py\\\", line 356, in execute\r\n    self.fetchcommand(subcommand).runfromargv(self.argv)\r\n  File \\\"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/core/management/base.py\\\", line 283, in runfromargv\r\n    self.execute(*args, **cmdoptions)\r\n  File \\\"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/core/management/base.py\\\", line 330, in execute\r\n    output = self.handle(*args, **options)\r\n  File \\\"/usr/lib/python2.7/site-packages/awx/main/management/commands/inventoryimport.py\\\", line 1020, in handle\r\n    self.loadintodatabase()\r\n  File \\\"/usr/lib/python2.7/site-packages/awx/main/management/commands/inventoryimport.py\\\", line 892, in loadintodatabase\r\n    self.createupdatehosts()\r\n  File \\\"/usr/lib/python2.7/site-packages/awx/main/management/commands/inventoryimport.py\\\", line 798, in createupdatehosts\r\n    dbhost = self.inventory.hosts.updateorcreate(name=memhostname, defaults=hostattrs)[0]\r\n  File \\\"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/db/models/fields/relateddescriptors.py\\\", line 665, in updateorcreate\r\n    return super(RelatedManager, self.dbmanager(db)).updateorcreate(**kwargs)\r\n  File \\\"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/db/models/manager.py\\\", line 85, in managermethod\r\n    return getattr(self.getqueryset(), name)(*args, **kwargs)\r\n  File \\\"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/db/models/query.py\\\", line 482, in updateorcreate\r\n    obj, created = self.createobjectfromparams(lookup, params)\r\n  File \\\"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/db/models/query.py\\\", line 498, in createobjectfromparams\r\n    obj = self.create(**params)\r\n  File \\\"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/db/models/query.py\\\", line 394, in create\r\n    obj.save(forceinsert=True, using=self.db)\r\n  File \\\"/usr/lib/python2.7/site-packages/awx/main/models/inventory.py\\\", line 665, in save\r\n    super(Host, self).save(*args, **kwargs)\r\n  File \\\"/usr/lib/python2.7/site-packages/awx/main/models/base.py\\\", line 264, in save\r\n    super(PrimordialModel, self).save(*args, **kwargs)\r\n  File \\\"/usr/lib/python2.7/site-packages/awx/main/models/base.py\\\", line 159, in save\r\n    super(CreatedModifiedModel, self).save(*args, **kwargs)\r\n  File \\\"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/db/models/base.py\\\", line 808, in save\r\n    forceupdate=forceupdate, updatefields=updatefields)\r\n  File \\\"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/db/models/base.py\\\", line 838, in savebase\r\n    updated = self.savetable(raw, cls, forceinsert, forceupdate, using, updatefields)\r\n  File \\\"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/db/models/base.py\\\", line 924, in savetable\r\n    result = self.doinsert(cls.basemanager, using, fields, updatepk, raw)\r\n  File \\\"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/db/models/base.py\\\", line 963, in doinsert\r\n    using=using, raw=raw)\r\n  File \\\"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/db/models/manager.py\\\", line 85, in managermethod\r\n    return getattr(self.getqueryset(), name)(*args, **kwargs)\r\n  File \\\"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/db/models/query.py\\\", line 1076, in insert\r\n    return query.getcompiler(using=using).executesql(returnid)\r\n  File \\\"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/db/models/sql/compiler.py\\\", line 1106, in executesql\r\n    for sql, params in self.assql():\r\n  File \\\"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/db/models/sql/compiler.py\\\", line 1059, in assql\r\n    for obj in self.query.objs\r\n  File \\\"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/db/models/sql/compiler.py\\\", line 998, in preparevalue\r\n    value = field.getdbprepsave(value, connection=self.connection)\r\n  File \\\"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/db/models/fields/init.py\\\", line 770, in getdbprepsave\r\n    prepared=False)\r\n  File \\\"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/db/models/fields/init.py\\\", line 762, in getdbprepvalue\r\n    value = self.getprepvalue(value)\r\n  File \\\"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/db/models/fields/init.py\\\", line 1043, in getprepvalue\r\n    return self.topython(value)\r\n  File \\\"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/db/models/fields/init.py\\\", line 1036, in topython\r\n    params={'value': value},\r\ndjango.core.exceptions.ValidationError: [u\\\"'<object object at 0x6aa0f40>' value must be either True or False.\\\"]\r\n```"},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n - UI\r\n\r\n##### SUMMARY\r\nI'd like to attach superuser role to two groups, AWX interface will allow saving such configuration, but it silently ignores the second group provided. \r\n\r\n##### ENVIRONMENT\r\n* AWX version: 1.0.1.111\r\n* AWX install method: docker on linux\r\n* Ansible version:  2.4.0.0\r\n* Operating System: \r\n* Web Browser: \r\n\r\n##### STEPS TO REPRODUCE\r\n\r\nI'm setting issuperuser flag for two groups (Admins and Superadmins in example bellow)\r\n\r\n```json\r\n{\r\n \"issuperuser\": [\r\n \t\"CN=Admins,OU=Groups,DC=example,DC=com\",\r\n        \"CN=Superadmins,OU=Groups,DC=example,DC=com\"\r\n ]\r\n}\r\n```\r\n\r\n##### EXPECTED RESULTS\r\n\r\nConfiguration is saved as provided, users from either group can log in and will be superusers.\r\n\r\n##### ACTUAL RESULTS\r\n\r\nWhen I provide such configuration in the admin interface, AWX will accept the configuration, but when visiting the settings again, it will show configuration reduced to a version, that's using just the first group:\r\n\r\n```json\r\n{\r\n \"issuperuser\": \"CN=Admins,OU=Groups,DC=example,DC=com\"\r\n}\r\n```\r\n\r\nAlso only the \"Admins\" group users will get superuser rights upon logging in.\r\n\r\n##### ADDITIONAL INFORMATION\r\n\r\nThis can be obviously worked around by creating a group in LDAP, that will contain both groups, but sometimes that might be impractical from organization perspective. At least, AWX should warn about such configuration and fail to save it.\r\n"},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n - API\r\n\r\n##### SUMMARY\r\nJob template machine credential shows as an empty dictionary for `credential` in summary fields\r\n\r\n##### ENVIRONMENT\r\n* AWX version: 1.0.1\r\n* AWX install method: docker for mac\r\n* Ansible version:  N/A\r\n* Operating System:\r\n* Web Browser: Chome\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\n - create a job template\r\n - associate a machine credential with the job template\r\n - view the list view of all job templates or all unified job templates\r\n\r\n##### EXPECTED RESULTS\r\n\r\nunclear, either no credential in summaryfields, or summary field data\r\n\r\n##### ACTUAL RESULTS\r\n\r\nempty entry for `credential`.\r\n\r\nexample, looking at `/api/v2/jobtemplates/?id=34`:\r\n\r\n```json\r\n{\r\n    \"count\": 1,\r\n    \"next\": null,\r\n    \"previous\": null,\r\n    \"results\": [\r\n        {\r\n            \"id\": 34,\r\n            \"type\": \"jobtemplate\",\r\n            \"url\": \"/api/v2/jobtemplates/34/\",\r\n            \"related\": {\r\n                \"createdby\": \"/api/v2/users/1/\",\r\n                \"modifiedby\": \"/api/v2/users/1/\",\r\n                \"labels\": \"/api/v2/jobtemplates/34/labels/\",\r\n                \"inventory\": \"/api/v2/inventories/7/\",\r\n                \"project\": \"/api/v2/projects/29/\",\r\n                \"credential\": \"/api/v2/credentials/13/\",\r\n                \"extracredentials\": \"/api/v2/jobtemplates/34/extracredentials/\",\r\n                \"credentials\": \"/api/v2/jobtemplates/34/credentials/\",\r\n                \"notificationtemplateserror\": \"/api/v2/jobtemplates/34/notificationtemplateserror/\",\r\n                \"notificationtemplatessuccess\": \"/api/v2/jobtemplates/34/notificationtemplatessuccess/\",\r\n                \"jobs\": \"/api/v2/jobtemplates/34/jobs/\",\r\n                \"objectroles\": \"/api/v2/jobtemplates/34/objectroles/\",\r\n                \"notificationtemplatesany\": \"/api/v2/jobtemplates/34/notificationtemplatesany/\",\r\n                \"accesslist\": \"/api/v2/jobtemplates/34/accesslist/\",\r\n                \"launch\": \"/api/v2/jobtemplates/34/launch/\",\r\n                \"instancegroups\": \"/api/v2/jobtemplates/34/instancegroups/\",\r\n                \"schedules\": \"/api/v2/jobtemplates/34/schedules/\",\r\n                \"activitystream\": \"/api/v2/jobtemplates/34/activitystream/\",\r\n                \"surveyspec\": \"/api/v2/jobtemplates/34/surveyspec/\"\r\n            },\r\n            \"summaryfields\": {\r\n                \"inventory\": {\r\n                    \"id\": 7,\r\n                    \"name\": \"localhost\",\r\n                    \"description\": \"created by Alans cloud scripts\",\r\n                    \"hasactivefailures\": false,\r\n                    \"totalhosts\": 1,\r\n                    \"hostswithactivefailures\": 0,\r\n                    \"totalgroups\": 0,\r\n                    \"groupswithactivefailures\": 0,\r\n                    \"hasinventorysources\": false,\r\n                    \"totalinventorysources\": 0,\r\n                    \"inventorysourceswithfailures\": 0,\r\n                    \"organizationid\": 1,\r\n                    \"kind\": \"\"\r\n                },\r\n                \"credential\": {},\r\n                \"project\": {\r\n                    \"id\": 29,\r\n                    \"name\": \"sampleplaybooks\",\r\n                    \"description\": \"\",\r\n                    \"status\": \"successful\",\r\n                    \"scmtype\": \"git\"\r\n                },\r\n                \"createdby\": {\r\n                    \"id\": 1,\r\n                    \"username\": \"admin\",\r\n                    \"firstname\": \"\",\r\n                    \"lastname\": \"\"\r\n                },\r\n                \"modifiedby\": {\r\n                    \"id\": 1,\r\n                    \"username\": \"admin\",\r\n                    \"firstname\": \"\",\r\n                    \"lastname\": \"\"\r\n                },\r\n                \"objectroles\": {\r\n                    \"adminrole\": {\r\n                        \"id\": 241,\r\n                        \"description\": \"Can manage all aspects of the job template\",\r\n                        \"name\": \"Admin\"\r\n                    },\r\n                    \"executerole\": {\r\n                        \"id\": 240,\r\n                        \"description\": \"May run the job template\",\r\n                        \"name\": \"Execute\"\r\n                    },\r\n                    \"readrole\": {\r\n                        \"id\": 239,\r\n                        \"description\": \"May view settings for the job template\",\r\n                        \"name\": \"Read\"\r\n                    }\r\n                },\r\n                \"usercapabilities\": {\r\n                    \"edit\": true,\r\n                    \"start\": true,\r\n                    \"copy\": true,\r\n                    \"schedule\": true,\r\n                    \"delete\": true\r\n                },\r\n                \"labels\": {\r\n                    \"count\": 0,\r\n                    \"results\": []\r\n                },\r\n                \"recentjobs\": []\r\n            },\r\n            \"created\": \"2017-11-17T18:47:39.395073Z\",\r\n            \"modified\": \"2017-11-17T18:47:40.467277Z\",\r\n            \"name\": \"Hello World\",\r\n            \"description\": \"echo statement\",\r\n            \"jobtype\": \"run\",\r\n            \"inventory\": 7,\r\n            \"project\": 29,\r\n            \"playbook\": \"helloworld.yml\",\r\n            \"forks\": 0,\r\n            \"limit\": \"\",\r\n            \"verbosity\": 0,\r\n            \"extravars\": \"\",\r\n            \"jobtags\": \"\",\r\n            \"forcehandlers\": false,\r\n            \"skiptags\": \"\",\r\n            \"startattask\": \"\",\r\n            \"timeout\": 0,\r\n            \"usefactcache\": false,\r\n            \"lastjobrun\": null,\r\n            \"lastjobfailed\": false,\r\n            \"nextjobrun\": null,\r\n            \"status\": \"never updated\",\r\n            \"hostconfigkey\": \"\",\r\n            \"askdiffmodeonlaunch\": false,\r\n            \"askvariablesonlaunch\": false,\r\n            \"asklimitonlaunch\": false,\r\n            \"asktagsonlaunch\": false,\r\n            \"askskiptagsonlaunch\": false,\r\n            \"askjobtypeonlaunch\": false,\r\n            \"askverbosityonlaunch\": false,\r\n            \"askinventoryonlaunch\": false,\r\n            \"askcredentialonlaunch\": false,\r\n            \"surveyenabled\": false,\r\n            \"becomeenabled\": false,\r\n            \"diffmode\": false,\r\n            \"allowsimultaneous\": false,\r\n            \"credential\": 13,\r\n            \"vaultcredential\": null\r\n        }\r\n    ]\r\n}\r\n```\r\n\r\n##### ADDITIONAL INFORMATION\r\n\r\n<!-- Include any links to sosreport, database dumps, screenshots or other\r\ninformation. -->\r\n"},
{"text": "##### ISSUE TYPE\r\n<!--- Pick one below and delete the rest: -->\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n<!-- Pick the area of AWX for this issue, you can have multiple, delete the rest: -->\r\n - API\r\n\r\n##### SUMMARY\r\nWhen user AWX without HTTPS (plain HTTP), logging in with the GitHub OAuth button fails.\r\n\r\n##### ENVIRONMENT\r\n* AWX version: 1.0.1.229\r\n* AWX install method: docker on linux\r\n* Ansible version:  2.4.1.0\r\n* Operating System: debian stretch\r\n* Web Browser: firefox\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\n* Setup AWX, access through port 80 (default)\r\n* Setup GitHub Org auth (but really, it's the same with any Social Auth plugin)\r\n* Log in using the social auth\r\n\r\n##### EXPECTED RESULTS\r\n\r\nYou're logged-in\r\n\r\n##### ACTUAL RESULTS\r\n\r\nYou're not.\r\nawxweb has a log saying :\r\n```\r\n2017-11-28 17:57:48,299 ERROR    social Session value state missing.\r\n```\r\non the `GET /sso/complete/github-org/` call.\r\n\r\n##### ADDITIONAL INFORMATION\r\n\r\nThe session to persist the `state` parameter between the initial and the `complete` view of the oauth dance is defined by:\r\nhttps://github.com/ansible/awx/blob/9ed2a0da8f4883a7d6311de2958a01e70605b062/awx/settings/defaults.py#L492\r\n\r\nWhich uses the default Django session store, which uses a secure cookie due to\r\nhttps://github.com/ansible/awx/blob/9ed2a0da8f4883a7d6311de2958a01e70605b062/awx/settings/defaults.py#L188\r\n\r\nSo, if we're not using HTTPS, the cookie will not be sent on the second call, so the session will not be retrieved, the `state` value is absent and the oauth dance fails.\r\n\r\n##### WORK AROUND\r\n\r\nI guess either use HTTPS or override the SESSIONCOOKIESECURE to False."},
{"text": "\r\n![awxtowererror](https://user-images.githubusercontent.com/34062219/33321663-8443713e-d457-11e7-9e44-4e63609ebcd3.png)\r\n##### ISSUE TYPE\r\n<!--- Pick one below and delete the rest: -->\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n<!-- Pick the area of AWX for this issue, you can have multiple, delete the rest: -->\r\n - UI\r\n\r\n##### SUMMARY\r\n<!-- Getting HTTP code 500 error when trying to get inventory source sync status while logged in as any user other then global system administartor (default admin)-->\r\nGetting HTTP code 500 error when trying to get inventory source sync status while logged in as any user other then global system administartor (default admin)\r\n\r\n##### ENVIRONMENT\r\n* AWX version: 1.0.1.225\r\n* AWX install method: docker on linux\r\n* Ansible version:  2.4.1.0-1.el7\r\n* Operating System: Red Hat Enterprise Linux Server release 7.4 (Maipo)\r\n* Web Browser: Google Chrome Version 62.0.3202.94 (Official Build) (64-bit)\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\n<!-- 1. Log in as any user without system administrator privileges.  -->\r\n1. Create a user and give him admin privileges on projects and inventory, organisation and all other elements. The user MUST not have a \"system administrator\" role.\r\n2. Log in as any user without system administrator privileges.\r\n3. Create a git project and an inventory sourced from that project and syncronize that source using \"2 round arrows\" from a toolbox to the right.\r\n4. Give the user all privileges on the project and inventory.\r\n5. After all press \"green cloud\" in front of inventory source object and request the URL  /#/inventorysync/1219\r\n\r\nObserve the error message similar to one from a picture attached to this issue.\r\n\r\n\r\n##### EXPECTED RESULTS\r\n\r\n<!-- For bug reports, what did you expect to happen when running the steps\r\nabove? -->\r\nExpected that a screen with syncronization job status in a left part of the screen and ansible output in a right part of the screen should appear as it do when the user has system administrator privileges (default admin)\r\n\r\n\r\n##### ACTUAL RESULTS\r\n\r\n<!-- For bug reports, what actually happened? -->\r\n\r\n##### ADDITIONAL INFORMATION\r\n\r\n<!-- Include any links to sosreport, database dumps, screenshots or other\r\ninformation. -->\r\n\r\nIn the same time we have the following error in awxweb docker container log:\r\n\r\nHOSTIP - - [28/Nov/2017:13:08:21 +0000] \"GET /api/v2/config/ HTTP/1.1\" 200 506 \"http://HOSTNAME:PORT/\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36\" \"-\"\r\n2017-11-28 13:08:22,116 ERROR    django.request Internal Server Error: /api/v2/inventoryupdates/1219/\r\nTraceback (most recent call last):\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/core/handlers/exception.py\", line 41, in inner\r\n    response = getresponse(request)\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/core/handlers/base.py\", line 249, in legacygetresponse\r\n    response = self.getresponse(request)\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/core/handlers/base.py\", line 187, in getresponse\r\n    response = self.processexceptionbymiddleware(e, request)\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/core/handlers/base.py\", line 185, in getresponse\r\n    response = wrappedcallback(request, *callbackargs, **callbackkwargs)\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/utils/decorators.py\", line 185, in inner\r\n    return func(*args, **kwargs)\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/views/decorators/csrf.py\", line 58, in wrappedview\r\n    return viewfunc(*args, **kwargs)\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/views/generic/base.py\", line 68, in view\r\n    return self.dispatch(request, *args, **kwargs)\r\n  File \"/usr/lib/python2.7/site-packages/awx/api/generics.py\", line 248, in dispatch\r\n    return super(APIView, self).dispatch(request, *args, **kwargs)\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/restframework/views.py\", line 489, in dispatch\r\n    response = self.handleexception(exc)\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/restframework/views.py\", line 449, in handleexception\r\n    self.raiseuncaughtexception(exc)\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/restframework/views.py\", line 486, in dispatch\r\n    response = handler(request, *args, **kwargs)\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/restframework/generics.py\", line 210, in get\r\n    return self.retrieve(request, *args, **kwargs)\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/restframework/mixins.py\", line 56, in retrieve\r\n    instance = self.getobject()\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/restframework/generics.py\", line 101, in getobject\r\n    self.checkobjectpermissions(self.request, obj)\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/restframework/views.py\", line 339, in checkobjectpermissions\r\n    if not permission.hasobjectpermission(request, self, obj):\r\n  File \"/usr/lib/python2.7/site-packages/awx/api/permissions.py\", line 137, in hasobjectpermission\r\n    return self.haspermission(request, view, obj)\r\n  File \"/usr/lib/python2.7/site-packages/awx/api/permissions.py\", line 128, in haspermission\r\n    response = self.checkpermissions(request, view, obj)\r\n  File \"/usr/lib/python2.7/site-packages/awx/api/permissions.py\", line 117, in checkpermissions\r\n    result = checkmethod and checkmethod(request, view, obj)\r\n  File \"/usr/lib/python2.7/site-packages/awx/api/permissions.py\", line 43, in checkgetpermissions\r\n    return checkuseraccess(request.user, view.model, 'read', obj)\r\n  File \"/usr/lib/python2.7/site-packages/awx/main/access.py\", line 116, in checkuseraccess\r\n    result = accessmethod(*args, **kwargs)\r\n  File \"/usr/lib/python2.7/site-packages/awx/main/access.py\", line 216, in canread\r\n    return bool(obj and self.getqueryset().filter(pk=obj.pk).exists())\r\n  File \"/usr/lib/python2.7/site-packages/awx/main/access.py\", line 200, in getqueryset\r\n    qs = self.filteredqueryset()\r\n  File \"/usr/lib/python2.7/site-packages/awx/main/access.py\", line 886, in filteredqueryset\r\n    return qs.filter(inventorysourceinventoryin=Inventory.accessiblepkqs(self.user, 'readrole'))\r\nNameError: global name 'qs' is not defined\r\n2017-11-28 13:08:22,116 ERROR    django.request Internal Server Error: /api/v2/inventoryupdates/1219/\r\nTraceback (most recent call last):\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/core/handlers/exception.py\", line 41, in inner\r\n    response = getresponse(request)\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/core/handlers/base.py\", line 249, in legacygetresponse\r\n    response = self.getresponse(request)\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/core/handlers/base.py\", line 187, in getresponse\r\n    response = self.processexceptionbymiddleware(e, request)\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/core/handlers/base.py\", line 185, in getresponse\r\n    response = wrappedcallback(request, *callbackargs, **callbackkwargs)\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/utils/decorators.py\", line 185, in inner\r\n    return func(*args, **kwargs)\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/views/decorators/csrf.py\", line 58, in wrappedview\r\n    return viewfunc(*args, **kwargs)\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/views/generic/base.py\", line 68, in view\r\n    return self.dispatch(request, *args, **kwargs)\r\n  File \"/usr/lib/python2.7/site-packages/awx/api/generics.py\", line 248, in dispatch\r\n    return super(APIView, self).dispatch(request, *args, **kwargs)\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/restframework/views.py\", line 489, in dispatch\r\n    response = self.handleexception(exc)\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/restframework/views.py\", line 449, in handleexception\r\n    self.raiseuncaughtexception(exc)\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/restframework/views.py\", line 486, in dispatch\r\n    response = handler(request, *args, **kwargs)\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/restframework/generics.py\", line 210, in get\r\n    return self.retrieve(request, *args, **kwargs)\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/restframework/mixins.py\", line 56, in retrieve\r\n    instance = self.getobject()\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/restframework/generics.py\", line 101, in getobject\r\n    self.checkobjectpermissions(self.request, obj)\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/restframework/views.py\", line 339, in checkobjectpermissions\r\n    if not permission.hasobjectpermission(request, self, obj):\r\n  File \"/usr/lib/python2.7/site-packages/awx/api/permissions.py\", line 137, in hasobjectpermission\r\n    return self.haspermission(request, view, obj)\r\n  File \"/usr/lib/python2.7/site-packages/awx/api/permissions.py\", line 128, in haspermission\r\n    response = self.checkpermissions(request, view, obj)\r\n  File \"/usr/lib/python2.7/site-packages/awx/api/permissions.py\", line 117, in checkpermissions\r\n    result = checkmethod and checkmethod(request, view, obj)\r\n  File \"/usr/lib/python2.7/site-packages/awx/api/permissions.py\", line 43, in checkgetpermissions\r\n    return checkuseraccess(request.user, view.model, 'read', obj)\r\n  File \"/usr/lib/python2.7/site-packages/awx/main/access.py\", line 116, in checkuseraccess\r\n    result = accessmethod(*args, **kwargs)\r\n  File \"/usr/lib/python2.7/site-packages/awx/main/access.py\", line 216, in canread\r\n    return bool(obj and self.getqueryset().filter(pk=obj.pk).exists())\r\n  File \"/usr/lib/python2.7/site-packages/awx/main/access.py\", line 200, in getqueryset\r\n    qs = self.filteredqueryset()\r\n  File \"/usr/lib/python2.7/site-packages/awx/main/access.py\", line 886, in filteredqueryset\r\n    return qs.filter(inventorysourceinventoryin=Inventory.accessiblepkqs(self.user, 'readrole'))\r\nNameError: global name 'qs' is not defined\r\n[pid: 29|app: 0|req: 16/37] HOSTIP () {46 vars in 2488 bytes} [Tue Nov 28 13:08:22 2017] GET /api/v2/inventoryupdates/1219/ => generated 41 bytes in 49 msecs (HTTP/1.1 500) 5 headers in 177 bytes (1 switches on core 0)\r\nHOSTIP - - [28/Nov/2017:13:08:22 +0000] \"GET /api/v2/inventoryupdates/1219/ HTTP/1.1\" 500 41 \"http://HOSTNAME:PORT/\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36\" \"-\"\r\n"},
{"text": "##### ISSUE TYPE\r\n<!--- Pick one below and delete the rest: -->\r\n - Bug Report\r\n \r\n\r\n##### COMPONENT NAME\r\n<!-- Pick the area of AWX for this issue, you can have multiple, delete the rest: -->\r\n - API\r\n \r\n##### SUMMARY\r\n<!-- Briefly describe the problem. -->\r\nI am not able to use the registered task value when executed playbook using isolated node functionality.\r\n##### ENVIRONMENT\r\n* AWX version: 3.4.1\r\n* AWX install method:  docker on linux,\r\n* Ansible version:  2.4\r\n* Operating System: Oracle Linux\r\n* Web Browser: Chrome\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\n<!-- For bugs, please show exactly how to reproduce the problem. For new\r\nfeatures, show how the feature would be used.  -->\r\n\r\n---\r\n- hosts: all\r\n  connection: local\r\n\r\n  tasks:\r\n\r\n    - name: Include user credentials\r\n      includevars:\r\n       dir: 'vars'\r\n       filesmatching: \"{{ inventoryhostname}}.yml\"\r\n\r\n\r\n    - name: Check Configure Extended access list\r\n      tags:\r\n           - acl\r\n      iosconfig:\r\n        provider: \"{{ clin }}\"\r\n        match: exact\r\n        parents:\r\n             - ip access-list extended ABC\r\n        lines:\r\n             - permit tcp 192.168.102.0 0.0.0.255 any eq www\r\n           \r\n        before: \"no ip access-list extended ABC\"\r\n      checkmode: yes\r\n      register: ResultA\r\n\r\n    - debug:\r\n        msg: \"{{ ResultA }}\"\r\n\r\n\r\n##### EXPECTED RESULTS\r\n\r\n<!-- For bug reports, what did you expect to happen when running the steps\r\nabove? -->\r\nRegistered variable key value pair.\r\n##### ACTUAL RESULTS\r\nTASK [debug] *******************************************************************17:17:25\r\n83\r\nok: [10.1.2.2] => {\r\n\r\n    \"msg\": \"Hello world!\"\r\n\r\n}\r\n<!-- For bug reports, what actually happened? -->\r\nRegistered variable value not retrieved when running playbook on ISOLATED instance..\r\n##### ADDITIONAL INFORMATION\r\nIt works fine with Normal instance. i.e. using Tower/controller node.\r\n<!-- Include any links to sosreport, database dumps, screenshots or other\r\ninformation. -->\r\n"},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n - API\r\n - UI\r\n\r\n\r\n##### SUMMARY\r\nCannot send slack notifications or use the slack ansible module in playbooks. \r\n\r\n##### ENVIRONMENT\r\n* AWX version: 1.0.1.231\r\n* AWX install method: docker on linux\r\n* Ansible version:  2.4.1.0\r\n* Operating System: Ubuntu\r\n* Web Browser: Firefox\r\n\r\n##### STEPS TO REPRODUCE\r\nSimply create a slack channel, create a webhook integration, and attempt to use it as a notification, or create a playbook with a slack module and try to run it. It works just fine when running the playbook via the host machine, but it never completes from within the docker container.\r\n\r\n##### EXPECTED RESULTS\r\n\r\nBoth the notification test from within the AWX ui and the playbook with a slack module task should work.\r\n\r\n##### ACTUAL RESULTS\r\n\r\nThe notification test failed. The playbook with the slack module task failed. The playbook succeeded using \"ansible-playbook\" command on the host machine, with a \"delegateto: localhost.\"\r\n\r\n##### ADDITIONAL INFORMATION\r\n\r\n\r\n"},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n - API\r\n\r\n##### SUMMARY\r\nCanceling a job results in an activity stream entry for its related job template, although the user was not editing the JT.\r\n\r\n##### ENVIRONMENT\r\n* AWX version: 1.0.1\r\n* AWX install method: docker for mac\r\n* Ansible version:  N/A\r\n* Operating System:\r\n* Web Browser: Chrome\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\nLaunch a job template. Cancel the job it spawns. Inspect activity stream for job templates.\r\n\r\n##### EXPECTED RESULTS\r\n\r\nNo entry.\r\n\r\nMaybe a related entry for the job model?\r\n\r\n##### ACTUAL RESULTS\r\n\r\nGot this entry in the UI by user \"System\":\r\n\r\n```json\r\n{\r\n \"currentjob\": [\r\n  \"2017-11-21 20:20:39.540844+00:00-74-successful\",\r\n  null\r\n ],\r\n \"lastjob\": [\r\n  \"2017-11-21 20:11:50.543293+00:00-50-canceled\",\r\n  \"2017-11-21 20:20:39.540844+00:00-74-successful\"\r\n ],\r\n \"lastjobfailed\": [\r\n  true,\r\n  false\r\n ],\r\n \"lastjobrun\": [\r\n  \"2017-11-22 01:53:54.496975+00:00\",\r\n  \"2017-11-22 01:54:22.307195+00:00\"\r\n ],\r\n \"status\": [\r\n  \"running\",\r\n  \"successful\"\r\n ]\r\n}\r\n```\r\n\r\nIn the API:\r\n\r\nhttps://gist.github.com/AlanCoding/48ea62f3b7293fb102b45086843f9ef0\r\n\r\n##### ADDITIONAL INFORMATION\r\n\r\nN/A\r\n"},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n - API\r\n\r\n##### SUMMARY\r\nI realize a POC on AWX and when i use the API v2 i get an error. This error is an internal server error when i attempt to add a tower credential via an Ansible playbook. \r\nI don't have this error on API v1 but i don't have all attributes that i want.\r\n\r\n##### ENVIRONMENT\r\n* AWX version: 1.0.1.223\r\n* AWX install method: docker on linux + postgres on standalone mode\r\n* Ansible version:  2.4.1\r\n* Operating System: CentOS 7.4\r\n\r\n##### STEPS TO REPRODUCE\r\n`tasks:\r\n       - name: Create an organization\r\n         towerorganization:\r\n           name: \"Pyxis\"\r\n           description: \"Pyxis organization\"\r\n           state: present\r\n           towerconfigfile: \"/etc/tower/towercli.cfg\"` \r\n\r\n##### EXPECTED RESULTS\r\nAdd an organization on AWX via Ansible playbook.\r\n\r\n##### ACTUAL RESULTS\r\n\r\n> fatal: [localhost]: FAILED! => {\r\n    \"changed\": false,\r\n    \"failed\": true,\r\n    \"modulestderr\": \"*** DETAILS: Checking for an existing record. *********************************\\nGET http://10.11.176.196 last):\\n  File \\\"/tmp/ansibleX2jOZs/ansiblemoduletowerorganization.py\\\", line 147, in <module>\\n    main()\\n  File \\\"/tmp/sult = organization.modify(name=name, description=description, createonmissing=True)\\n  File \\\"/usr/lib/python2.7/site-packageateonmissing=createonmissing, forceonexists=True, **kwargs)\\n  File \\\"/usr/lib/python2.7/site-packages/towercli/models/ckages/towercli/models/base.py\\\", line 202, in lookup\\n    existingdata = self.get(includedebugheader=includedebugheadere.py\\\", line 465, in get\\n    response = self.read(pk=pk, failonnoresults=True, failonmultipleresults=True, **kwargs)\\n   read\\n    r = client.get(url, params=kwargs)\\n  File \\\"/usr/lib/python2.7/site-packages/requests/sessions.py\\\", line 476, in gite-packages/towercli/api.py\\\", line 199, in request\\n    raise exc.ServerError('The Tower server sent back a server error. '\\ease try again later.\\n\",\r\n    \"modulestdout\": \"\",\r\n    \"msg\": \"MODULE FAILURE\",\r\n    \"rc\": 0\r\n}\r\n"},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n - API\r\n - UI\r\n\r\n##### SUMMARY\r\nOne template from a project playbook with 1 inventory and 2 credentials. If i grant a team Admin permission on this template it cannot be saved: operation not permitted.\r\n\r\n##### ENVIRONMENT\r\n* AWX version: 1.0.1.268\r\n* AWX install method: docker swarm\r\n* Ansible version:  2.4.x\r\n* Operating System: Ubuntu 16.04\r\n* Web Browser: Chromium 63\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\n- Create a project, credentials, inventories\r\n- Create a template from a playbook with credentials and inventories\r\n- Add a team (user?) Admin permission on the template\r\n- Edit the template\r\n- Save\r\n\r\n##### EXPECTED RESULTS\r\n\r\nTemplate is saved when only the template has admin permission for the user.\r\n\r\n##### ACTUAL RESULTS\r\n\r\nError on save: ERROR! Operation not permitted (not exact as it is localized to browser language)\r\n\r\nIn the browser network tab: PUT /api/v2/jobtemplates/9/ 403 Forbidden\r\n\r\n##### ADDITIONAL INFORMATION\r\n\r\nWhen the user has no permission to dependencies of the template it is visible during the page load: the network page:\r\n    /api/v2/credentials/3/  - 403 Forbidden\r\n\r\nIf I add permission to all credentials/inventories it works. But for credentials teams cannot be granted, only users (but this is another story)"},
{"text": "##### ISSUE TYPE\r\n<!--- Pick one below and delete the rest: -->\r\n - Bug Report\r\n\r\n\r\n##### COMPONENT NAME\r\n - API\r\n - UI\r\n\r\n##### SUMMARY\r\nSlack notification is not working for job completion (success or failure) but works fine for workflow job \r\n\r\n##### ENVIRONMENT\r\n* AWX version: 1.0.1.234 \r\n* AWX install method: docker on linux, \r\n* Ansible version:  2.4.1.0\r\n* Operating System: Redhat 7\r\n* Web Browser: chrome\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\n<!-- For bugs, please show exactly how to reproduce the problem. For new\r\nfeatures, show how the feature would be used.  -->\r\n\r\nI created a slack chat bot (not using webhook) following the instruction from https://www.linkedin.com/pulse/slack-chat-bot-ansible-tower-rahul-natarajan/\r\n\r\nI got the token from slack and it into the Slack notification in AWX.  \r\nThe test notificaiton with the bell alarm icon works fine.  However when I associate a job with the slack notificaition, nothing is send to slack when the job completes successful or in error.\r\n\r\n\r\n\r\n##### EXPECTED RESULTS\r\n\r\n<!-- For bug reports, what did you expect to happen when running the steps\r\nabove? -->\r\n\r\nI expect a message send to the slack channel defined according to the success/fail setting defined in the job template->notification screen.\r\n\r\n##### ACTUAL RESULTS\r\n\r\n<!-- For bug reports, what actually happened? -->\r\nNo message appear in the slack channel configured. \r\n\r\n##### ADDITIONAL INFORMATION\r\n\r\n<!-- Include any links to sosreport, database dumps, screenshots or other\r\ninformation. -->\r\n"},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n - API\r\n\r\n##### SUMMARY\r\nThe job relaunch endpoint has become extremely noisy for no apparent reason.\r\n\r\n##### ENVIRONMENT\r\n* AWX version: 1.0.1\r\n* AWX install method: docker for mac\r\n* Ansible version:  N/A\r\n* Operating System: N/A\r\n* Web Browser: N/A\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\nLaunch a job\r\n\r\nGET `/api/v2/jobs/N/relaunch/`\r\n\r\n##### EXPECTED RESULTS\r\n\r\nNice clean output like\r\n\r\n```json\r\n{\r\n    \"passwordsneededtostart\": [],\r\n    \"retrycounts\": {...}\r\n}\r\n```\r\n\r\nthat's how it was before\r\n\r\n##### ACTUAL RESULTS\r\n\r\nThe endpoint contains the full serialization of the job, which is unlike the job template launch, and other similar endpoints.\r\n\r\n##### ADDITIONAL INFORMATION\r\n\r\nProbably related to the recent feature churn (like retry on failed hosts), or upgrade of DRF.\r\n"},
{"text": "##### ISSUE TYPE\r\n - Bug Report\r\n\r\n##### COMPONENT NAME\r\n - API\r\n\r\n##### SUMMARY\r\nI run a template and sometimes the stdout is empty. I open the stdout link: /api/v2/jobs/192/stdout/?format=txtdownload (which is not working, but deleting the format part:) /api/v2/jobs/192/stdout/ and it shows:\r\n\r\n```\r\nHTTP 200 OK\r\nAllow: GET, HEAD, OPTIONS\r\nContent-Type: text/plain ;utf-8\r\nVary: Accept\r\nX-API-Node: awx\r\nX-API-Time: 0.017s\r\n\r\n\r\n\r\nstdout capture is missing\r\n```\r\n\r\n##### ENVIRONMENT\r\n* AWX version: 1.0.1.203 - 1.0.1.268 (at least)\r\n* AWX install method: docker on linux (docker-compose deployed to docker swarm)\r\n* Ansible version:  2.4.x\r\n* Operating System: Linux (not relevant)\r\n* Web Browser: Chromium 63 (not relevant)\r\n\r\n##### STEPS TO REPRODUCE\r\n\r\nI run playbooks, and after a few runs stdout is always empty. The task is run successfully or with failure as it should.\r\n\r\n##### EXPECTED RESULTS\r\n\r\nStdout is shown every time.\r\n\r\n##### ACTUAL RESULTS\r\n\r\nStdout is empty, downloading stdout shows: \"stdout capture is missing\"\r\n\r\n##### ADDITIONAL INFORMATION\r\n\r\nIf I restart the awxtag container (in my case as it is deployed with Swarm: docker kill ...) the problem disappears for some time.\r\n\r\nThis is from the awxtag output (in case of missing stdout):\r\n\r\n```\r\n...\r\n2017-11-30 10:45:33,575 ERROR    awx.main.commands.runcallbackreceiver Detail: Traceback (most recent call last):\r\n  File \"/usr/lib/python2.7/site-packages/awx/main/management/commands/runcallbackreceiver.py\", line 138, in callbackworker\r\n    JobEvent.createfromdata(**body)\r\n  File \"/usr/lib/python2.7/site-packages/awx/main/models/jobs.py\", line 1288, in createfromdata\r\n    jobevent = JobEvent.objects.create(**kwargs)\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/db/models/manager.py\", line 85, in managermethod\r\n    return getattr(self.getqueryset(), name)(*args, **kwargs)\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/db/models/query.py\", line 394, in create\r\n    obj.save(forceinsert=True, using=self.db)\r\n  File \"/usr/lib/python2.7/site-packages/awx/main/models/jobs.py\", line 1230, in save\r\n    updatedfields = self.updatefromeventdata()\r\n  File \"/usr/lib/python2.7/site-packages/awx/main/models/jobs.py\", line 1116, in updatefromeventdata\r\n    job = self.job\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/db/models/fields/relateddescriptors.py\", line 184, in get\r\n    relobj = self.getobject(instance)\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/db/models/fields/relateddescriptors.py\", line 159, in getobject\r\n    return qs.get(self.field.getreverserelatedfilter(instance))\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/db/models/query.py\", line 374, in get\r\n    num = len(clone)\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/db/models/query.py\", line 232, in len\r\n    self.fetchall()\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/db/models/query.py\", line 1118, in fetchall\r\n    self.resultcache = list(self.iterableclass(self))\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/polymorphic/query.py\", line 42, in polymorphiciterator\r\n    o = next(baseiter)\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/db/models/query.py\", line 53, in iter\r\n    results = compiler.executesql(chunkedfetch=self.chunkedfetch)\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/db/models/sql/compiler.py\", line 882, in executesql\r\n    cursor = self.connection.cursor()\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/db/backends/base/base.py\", line 254, in cursor\r\n    return self.cursor()\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/db/backends/base/base.py\", line 231, in cursor\r\n    return self.preparecursor(self.createcursor(name))\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/db/utils.py\", line 94, in exit\r\n    six.reraise(djexctype, djexcvalue, traceback)\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/db/backends/base/base.py\", line 231, in cursor\r\n    return self.preparecursor(self.createcursor(name))\r\n  File \"/var/lib/awx/venv/awx/lib/python2.7/site-packages/django/db/backends/postgresql/base.py\", line 220, in createcursor\r\n    cursor = self.connection.cursor()\r\nInterfaceError: connection already closed\r\n\r\n[2017-11-30 10:45:33,855: INFO/MainProcess] Received task: awx.main.tasks.updateinventorycomputedfields[415ee508-ea5d-4438-b01e-d8893c695195]  \r\n[2017-11-30 10:45:33,856: DEBUG/MainProcess] TaskPool: Apply <function fasttracetask at 0x398cc80> (args:('awx.main.tasks.updateinventorycomputedfields', '415ee508-ea5d-4438-b01e-d8893c695195', {'origin': 'gen1300@awx', 'lang': 'py', 'task': 'awx.main.tasks.updateinventorycomputedfields', 'group': None, 'rootid': 'e2d017d1-af7e-4055-a2fa-abc9d00b7cc0', u'deliveryinfo': {u'priority': None, u'redelivered': False, u'routingkey': u'tower', u'exchange': u''}, 'expires': None, u'correlationid': '415ee508-ea5d-4438-b01e-d8893c695195', 'retries': 0, 'timelimit': [None, None], 'argsrepr': '(2, True)', 'eta': None, 'parentid': 'b9a32fd8-85a0-41f3-913d-18eb131efef8', u'replyto': '0d3e5470-35b1-31a3-bb7b-2d6394e29252', 'id': '415ee508-ea5d-4438-b01e-d8893c695195', 'kwargsrepr': '{}'}, u'[[2, true], {}, {\"chord\": null, \"callbacks\": null, \"errbacks\": null, \"chain\": null}]', 'application/json', 'utf-8') kwargs:{})\r\n[2017-11-30 10:45:33,857: DEBUG/MainProcess] Task accepted: awx.main.tasks.updateinventorycomputedfields[415ee508-ea5d-4438-b01e-d8893c695195] pid:1465\r\n[2017-11-30 10:45:33,864: INFO/MainProcess] Received task: awx.main.tasks.handleworksuccess[da5909e7-b979-4937-b060-9a3ab0524f04]  \r\n[2017-11-30 10:45:33,865: DEBUG/MainProcess] TaskPool: Apply <function fasttracetask at 0x398cc80> (args:('awx.main.tasks.handleworksuccess', 'da5909e7-b979-4937-b060-9a3ab0524f04', {'origin': 'gen1300@awx', 'lang': 'py', 'task': 'awx.main.tasks.handleworksuccess', 'group': None, 'rootid': 'e2d017d1-af7e-4055-a2fa-abc9d00b7cc0', u'deliveryinfo': {u'priority': None, u'redelivered': False, u'routingkey': u'tower', u'exchange': u''}, 'expires': None, u'correlationid': 'da5909e7-b979-4937-b060-9a3ab0524f04', 'retries': 0, 'timelimit': [None, None], 'argsrepr': '(None,)', 'eta': None, 'parentid': 'b9a32fd8-85a0-41f3-913d-18eb131efef8', u'replyto': '0d3e5470-35b1-31a3-bb7b-2d6394e29252', 'id': 'da5909e7-b979-4937-b060-9a3ab0524f04', 'kwargsrepr': \"{'taskactual': {'type': 'job', 'id': 194}}\"}, u'[[null], {\"taskactual\": {\"type\": \"job\", \"id\": 194}}, {\"chord\": null, \"callbacks\": null, \"errbacks\": null, \"chain\": null}]', 'application/json', 'utf-8') kwargs:{})\r\n[2017-11-30 10:45:33,871: DEBUG/MainProcess] Task accepted: awx.main.tasks.handleworksuccess[da5909e7-b979-4937-b060-9a3ab0524f04] pid:1463\r\n2017-11-30 10:45:33,873 DEBUG    awx.main.models.inventory Going to update inventory computed fields\r\n[2017-11-30 10:45:33,873: DEBUG/ForkPoolWorker-378] Going to update inventory computed fields\r\n[2017-11-30 10:45:33,890: INFO/ForkPoolWorker-375] Task awx.main.tasks.runjob[b9a32fd8-85a0-41f3-913d-18eb131efef8] succeeded in 18.663942109s: None\r\n2017-11-30 10:45:33,926 DEBUG    awx.main.models.inventory Finished updating inventory computed fields\r\n[2017-11-30 10:45:33,926: DEBUG/ForkPoolWorker-378] Finished updating inventory computed fields\r\n[2017-11-30 10:45:33,929: DEBUG/ForkPoolWorker-377] Start from server, version: 0.9, properties: {'information': 'Licensed under the MPL.  See http://www.rabbitmq.com/', 'product': 'RabbitMQ', 'copyright': 'Copyright (C) 2007-2017 Pivotal Software, Inc.', 'capabilities': {'exchangeexchangebindings': True, 'connection.blocked': True, 'authenticationfailureclose': True, 'directreplyto': True, 'basic.nack': True, 'perconsumerqos': True, 'consumerpriorities': True, 'consumercancelnotify': True, 'publisherconfirms': True}, 'clustername': 'rabbit@b3ced9c88a6b', 'platform': 'Erlang/OTP 19.2.1', 'version': '3.6.14'}, mechanisms: ['AMQPLAIN', 'PLAIN'], locales: [u'enUS']\r\n[2017-11-30 10:45:33,931: DEBUG/ForkPoolWorker-377] using channelid: 1\r\n[2017-11-30 10:45:33,932: DEBUG/ForkPoolWorker-377] Channel open\r\n[2017-11-30 10:45:33,933: INFO/ForkPoolWorker-378] Task awx.main.tasks.updateinventorycomputedfields[415ee508-ea5d-4438-b01e-d8893c695195] succeeded in 0.0754506569992s: None\r\n[2017-11-30 10:45:33,938: INFO/MainProcess] Received task: awx.main.scheduler.tasks.runjobcomplete[018be77a-9f63-4436-95a1-f017e5b4c404]  \r\n[2017-11-30 10:45:33,938: DEBUG/MainProcess] TaskPool: Apply <function fasttracetask at 0x398cc80> (args:('awx.main.scheduler.tasks.runjobcomplete', '018be77a-9f63-4436-95a1-f017e5b4c404', {'origin': 'gen1463@awx', 'lang': 'py', 'task': 'awx.main.scheduler.tasks.runjobcomplete', 'group': None, 'rootid': 'e2d017d1-af7e-4055-a2fa-abc9d00b7cc0', u'deliveryinfo': {u'priority': 0, u'redelivered': False, u'routingkey': u'towerscheduler.job.complete', u'exchange': u'scheduler'}, 'expires': None, u'correlationid': '018be77a-9f63-4436-95a1-f017e5b4c404', 'retries': 0, 'timelimit': [None, None], 'argsrepr': '(194,)', 'eta': None, 'parentid': 'da5909e7-b979-4937-b060-9a3ab0524f04', u'replyto': '2eab75a3-a7dd-31de-b662-b6874d21acf1', 'id': '018be77a-9f63-4436-95a1-f017e5b4c404', 'kwargsrepr': '{}'}, u'[[194], {}, {\"chord\": null, \"callbacks\": null, \"errbacks\": null, \"chain\": null}]', 'application/json', 'utf-8') kwargs:{})\r\n[2017-11-30 10:45:33,942: DEBUG/MainProcess] Task accepted: awx.main.scheduler.tasks.runjobcomplete[018be77a-9f63-4436-95a1-f017e5b4c404] pid:1300\r\n[2017-11-30 10:45:33,944: INFO/ForkPoolWorker-377] Task awx.main.tasks.handleworksuccess[da5909e7-b979-4937-b060-9a3ab0524f04] succeeded in 0.0770123319999s: None\r\n2017-11-30 10:45:33,955 DEBUG    awx.main.scheduler Starting Scheduler\r\n2017-11-30 10:45:33,955 DEBUG    awx.main.scheduler Starting Scheduler\r\n[2017-11-30 10:45:33,955: DEBUG/ForkPoolWorker-375] Starting Scheduler\r\n[2017-11-30 10:45:33,978: INFO/ForkPoolWorker-375] Task awx.main.scheduler.tasks.runjobcomplete[018be77a-9f63-4436-95a1-f017e5b4c404] succeeded in 0.0385397499995s: None\r\n```\r\n\r\nThe \"connection already closed\" error is not present when the stdout is working - maybe this helps.\r\n\r\nWhen the stdout is lost it is no longer working on any template (including project update/pull) so I think the problem is not because of the template. The missing stdout is not necessary large, it is not a size limit or something.\r\n\r\n"},
{"labels":[null,"api",null],"text":"I need to use U-Net in Qt5. Before it, I tried to make experiment in cmake. The result was perfect.\r\nHowever, I integrated the code into a Qt5 application to load the same model,  it reported an error. \r\n\r\nThe CMakeList.txt file without Q5:\r\n```\r\ncmake_minimum_required(VERSION 3.0 FATAL_ERROR)\r\nproject(custom_ops)\r\nfind_package(Torch REQUIRED)\r\nset(TORCH_DIRS0 /home/SCHUSE/software/libtorch/include)\r\nset(TORCH_DIRS1 /home/SCHUSE/software/libtorch/include/csrc/api/include)\r\nfind_package( OpenCV REQUIRED )\r\ninclude_directories( ${OpenCV_INCLUDE_DIRS} )\r\ninclude_directories( ${TORCH_DIRS0} ${TORCH_DIRS1} )\r\nadd_executable(unet-app unet-app.cpp)\r\ntarget_link_libraries(unet-app ${TORCH_LIBRARIES} ${OpenCV_LIBS})\r\nset_property(TARGET unet-app PROPERTY CXX_STANDARD 11)\r\n```\r\n\r\nHere, its the code of loading model:\r\n```\r\nstd::shared_ptr<torch::jit::script::Module> module = torch::jit::load(argv[1]);\r\n```\r\nIN THIS WAY, THE MODEL WORKS PERFECTLY!!!!!!!!!!!!!!!!!!\r\n\r\n>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\r\n>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\r\nFor the Qt5 application, this application uses gstreamer, opencv and libtorch. The CMakeList.txt file with Qt5:\r\n```\r\nproject(multi_camera)\r\ncmake_minimum_required(VERSION 3.0 FATAL_ERROR)\r\nset(CMAKE_CXX_STANDARD 11)\r\nfind_package(PkgConfig REQUIRED)\r\nfind_package(Torch REQUIRED)\r\nfind_package(OpenCV REQUIRED )\r\nset(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} ${TORCH_CXX_FLAGS}\")\r\n# Enter the directory of the tiscamera repository here:\r\nset(TISCAMERA_DIR /home/yaok/software/camera/tiscamera) \r\nset(TORCH_DIRS0 /home/SCHUSE/software/libtorch/include)\r\nset(TORCH_DIRS1 /home/SCHUSE/software/libtorch/include/csrc/api/include)\r\nset(CUDA_DIR /usr/local/cuda/include )\r\nset(CMAKE_BUILD_TYPE Debug)\r\npkg_check_modules(GSTREAMER REQUIRED gstreamer-1.0 gstreamer-app-1.0 gstreamer-video-1.0)\r\npkg_check_modules(TCAMLIB tcam)\r\n\r\nset(CMAKE_AUTOMOC ON)\r\nset(CMAKE_AUTOUIC ON)\r\nfind_package(Qt5 COMPONENTS Widgets Core Xml)\r\nif (Qt5Widgets_FOUND)\r\n    if (Qt5Widgets_VERSION VERSION_LESS 5.5)\r\n        message(FATAL_ERROR \"Minimum supported Qt5 version is 5.5\" ${Qt5_DIR} ${QT_QMAKE_EXECUTABLE})\r\n    endif()\r\nelse()\r\n    message(SEND_ERROR \"The Qt5Widgets library could not be found!\")\r\nendif(Qt5Widgets_FOUND)\r\n\r\ninclude_directories( ${CMAKE_CURRENT_BINARY_DIR} ${TISCAMERA_DIR}/examples/cpp/common  ${GSTREAMER_INCLUDE_DIRS} ${TCAM_INCLUDE_DIRS} ${OpenCV_INCLUDE_DIRS} ${CUDA_DIR})\r\ninclude_directories( ${TORCH_DIRS0} ${TORCH_DIRS1} )\r\n\r\nadd_definitions(${GSTREAMER_CFLAGS_OTHER})  \r\nadd_executable(multi_camera main.cpp mainwindow.cpp qcameraform.cpp tcamcamera.cpp cpropertiesdialog.cpp qdetthread.cpp qrevthread.cpp qsavethread.cpp segdetector.cpp  )\r\ntarget_link_libraries(multi_camera ${TCAMLIB_LIBRARIES} ${GSTREAMER_LIBRARIES} Qt5::Widgets Qt5::Core Qt5::Xml ${TORCH_LIBRARIES} ${OpenCV_LIBS})\r\nset_property(TARGET multi_camera PROPERTY CXX_STANDARD 11)\r\n```\r\nThe c++ code in QT5:\r\n```\r\nstd::shared_ptr<torch::jit::script::Module> module = torch::jit::load(model_name);\r\n```\r\n\r\nTHE ERROR INFORMATION IS :\r\n```\r\nstart load model: /home/SCHUSE/Downloads/torch_unet/aunet_model.pt\r\nterminate called after throwing an instance of 'std::runtime_error'\r\n  what():  expected ] but found 'number' here:\r\n  _195 = _193.bias\r\n  _196 = getattr(_188, \"4\")\r\n  weight32 = _196.weight\r\n  bias32 = _196.bias\r\n  running_mean32 = _196.running_mean\r\n  running_var32 = _196.running_var\r\n  _197 = self.Conv_Seg\r\n  _198 = _197.weight\r\n  _199 = _197.bias\r\n  input0 = torch._convolution(input, _3, _4, [1, 1], [1, 1], [1, 1], False, [0, 0], 1, False, False, True)\r\n                                                 ~ <--- HERE\r\n  input1 = torch.batch_norm(input0, weight, bias, running_mean, running_var, False, 0.10000000000000001, 1.0000000000000001e-05, True)\r\n  input2 = torch.relu_(input1)\r\n  input3 = torch._convolution(input2, _7, _8, [1, 1], [1, 1], [1, 1], False, [0, 0], 1, False, False, True)\r\n  x = torch.batch_norm(input3, weight0, bias0, running_mean0, running_var0, False, 0.10000000000000001, 1.0000000000000001e-05, True)\r\n  identity = torch._convolution(input, _11, _12, [1, 1], [0, 0], [1, 1], False, [0, 0], 1, False, False, True)\r\n  input4 = torch.add_(x, identity, alpha=1)\r\n  input5 = torch.relu_(input4)\r\n  input6 = torch.max_pool2d(input5, [2, 2], [2, 2], [0, 0], [1, 1], False)\r\n  input7 = torch._convolution(input6, _16, _17, [1, 1], [1, 1], [1, 1], False, [0, 0], 1, False, False, True)\r\nAborted (core dumped)\r\n```\r\nThe environment is:\r\n```\r\n-- Caffe2: CUDA detected: 10.0\r\n-- Caffe2: CUDA nvcc is: /usr/local/cuda-10.0/bin/nvcc\r\n-- Caffe2: CUDA toolkit directory: /usr/local/cuda-10.0\r\n-- Caffe2: Header version is: 10.0\r\n-- Found cuDNN: v7.4.2  (include: /usr/include, library: /usr/lib/x86_64-linux-gnu/libcudnn.so)\r\n-- Autodetected CUDA architecture(s):  6.1\r\n-- Added CUDA NVCC flags for: -gencode;arch=compute_61,code=sm_61\r\n-- Pytorch: 1.1.0\r\n-- libtorch:  libtorch-shared-with-deps-1.1.0\r\n```\r\nActually, I load the same model and I make sure that the path is correct. \r\nNow, I cannot localize the problem and do not know the reason for that error. \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\n\ncc @malfet @seemethere @walterddr @yf225 @glaringlee"},{"labels":["api",null,null,null],"text":"## 🚀 Feature\r\nCreate a specialized schema type that can represent None, int, or tuple of ints. Could be named `Dims`, `DimList`, `ReductionDim`, or something else.\r\n\r\n## Motivation\r\n\r\nCurrently, the only single schema type that can do this is `int[1]?`, which is an `optional<IntArrayRef>` in C++. This type seems to almost work correctly, except that if the function is called from C++ with an integer, the `optional<IntArrayRef>` is filled with a garbage value. The value must be wrapped with `IntArrayRef({<value>})` to get correct behavior:\r\n\r\n```\r\nvoid func(optional<IntArrayRef> opt_dims) {\r\n  if (opt_dims.has_value()) {\r\n    for (auto dim : opt_dims.value()) {\r\n      std::cout << dim << \" \" << std::endl;\r\n    }\r\n  }\r\n  std::cout << std::endl;\r\n}\r\n\r\nfunc(23); // This prints out a garbage value\r\nfunc({23}); // This also prints out a garbage value\r\nfunc(IntArrayRef({23})); // This correctly prints out \"23\"\r\n```\r\n\r\nAfter `int[n]?` was introduced, I tried to use it to fix #29137, but the issue with `optional<IntArrayRef>` silently breaks any C++ calls that provide an integer as the dim argument. The C++ API of `at::sum` cannot easily be changed to prevent callers from providing an int--for one, that would be a BC break, but also, there does not seem to be any way to detect whether the `optional<IntArrayRef>` argument was initialized in this faulty way.\r\n\r\nMore details starting here: https://github.com/pytorch/pytorch/pull/43982#issuecomment-689173522\r\nAnd an older discussion starting here: https://github.com/pytorch/pytorch/pull/30822#issuecomment-571818073\r\n\r\n## Pitch\r\n\r\n@zdevito wrote a good pitch here: https://github.com/pytorch/pytorch/pull/30822#issuecomment-572783469\r\n\r\nIf we had a dedicated class to represent an optional list of dimensions, we would avoid having to use `optional<IntArrayRef>`. This dimension list class would have constructors that accept the following:\r\n* An integer\r\n* A list of integers\r\n* A representation of `None` (perhaps c10::nullopt)\r\n\r\n## Alternatives\r\n\r\n\r\n\r\n## Additional context\r\n\r\nI think it's important to consider how this new dimension list class would interact with the `Dimname[n]` schema type, which accepts `None` as a valid value. Currently, if a function has one overload where an argument type is `Dimname[1]`, and another overload where that argument is `int[1]?`, this creates an ambiguous situation since both overloads would accept `None`. Some additional info: https://github.com/pytorch/pytorch/pull/43982#discussion_r481426382\r\n\r\nThis ambiguous situation compiles without error. Apparently codegen will arbitrarily choose which C++ function gets called (perhaps based on the alphabetical order of the schema overload names). To avoid the ambiguity, we could potentially have something like a `DimnameListNotNone` schema type that does everything that `Dimname[1]` does, except that it does not accept `None`. Perhaps there are other possible solutions though.\r\n\r\n@t-vi suggested trying to split `Dimname[1]` into `Dimname?[]` and `Dimname[]`, and I haven't tried that yet. Still, it would not be ideal to have to have two separate overloads for the dimname list case.\r\n\r\n\r\ncc @yf225 @glaringlee @ezyang @bhosmer @smessmer @ljk53 @mruberry @rgommers "},{"labels":["api",null],"text":"##  Bug\r\n\r\nTrying convert a RefArray into a tensor like this  :\r\n \r\n```cpp\r\nauto tmp = torch::ones({2,3});\r\nauto shapes = torch::tensor({tmp.sizes()});\r\n```\r\nresults in this exception message : \r\n```\r\nfalse INTERNAL ASSERT FAILED at \"D:\\\\Codes\\\\cpp\\\\port\\\\LibtorchPort\\\\Dependencies\\\\libtorch-debug-latest\\\\libtorch\\\\include\\\\torch\\\\csrc\\\\api\\\\include\\\\torch\\\\detail\\\\TensorDataContainer.h\":299, please report a bug to PyTorch. TensorDataContainer is already a Tensor type, `fill_tensor` should not be called\r\n```\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\nRun this : \r\n \r\n```cpp\r\nauto tmp = torch::ones({2,3});\r\nauto shapes = torch::tensor({tmp.sizes()});\r\n```\r\n## Expected behavior\r\n\r\nShouldnt happen (since it has a `vec()` member which can be automatically used in this case!) or at least should issue a better error message. \r\n\r\n## Environment\r\n\r\nPlease copy and paste the output from our\r\n[environment collection script](https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py)\r\n(or fill out the checklist below manually).\r\n\r\nYou can get the script and run it with:\r\n```\r\nwget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\r\n# For security purposes, please check the contents of collect_env.py before running it.\r\npython collect_env.py\r\n```\r\n\r\n - PyTorch Version (e.g., 1.0): 1.6\r\n - OS (e.g., Linux): Windows 10\r\n - How you installed PyTorch (`conda`, `pip`, source): pip for python, downloaded the prebuilt libraries for libtorch\r\n - Build command you used (if compiling from source): - \r\n - Python version: 3.7\r\n - CUDA/cuDNN version: - \r\n - GPU models and configuration: - \r\n - Any other relevant information: I use cpu-mode\n\ncc @yf225 @glaringlee"},{"labels":["api",null,null,null],"text":"##  Bug\r\n\r\nAs the title suggested, the `right` argument in `torch.bucketize` works opposite to the description of the documentation,\r\nas well as `numpy.digitize`.\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Run the example in the docstring, get the same results as in the docstring\r\n```python\r\n>>> boundaries = torch.tensor([1, 3, 5, 7, 9])\r\n>>> v = torch.tensor([[3, 6, 9], [3, 6, 9]])\r\n>>> torch.bucketize(v, boundaries)\r\ntensor([[1, 3, 4],\r\n        [1, 3, 4]])\r\n>>> torch.bucketize(v, boundaries, right=True)\r\ntensor([[2, 3, 5],\r\n        [2, 3, 5]])\r\n```\r\n2. Run it with `numpy.digitize`\r\n```python\r\n>>> boundaries = numpy.array([1, 3, 5, 7, 9])\r\n>>> v = numpy.array([[3, 6, 9], [3, 6, 9]])\r\n>>> numpy.digitize(v, boundaries)\r\narray([[2, 3, 5],\r\n       [2, 3, 5]])\r\n>>> numpy.digitize(v, boundaries, right=True)\r\narray([[1, 3, 4],\r\n       [1, 3, 4]])\r\n```\r\n3. The two functions have consistent docstrings, but give opposite results.\r\n    To me the pytorch results **contradict the documentation**. (**Edited**)\r\n\r\n## Expected behavior\r\n\r\npytorch function behavior should agree with their documentations. (**Edited**)\r\n\r\n## Environment\r\n\r\nPyTorch version: 1.6.0\r\nIs debug build: False\r\nCUDA used to build PyTorch: 10.2\r\n\r\nOS: CentOS Linux release 7.8.2003 (Core) (x86_64)\r\nGCC version: (GCC) 7.4.0\r\nClang version: Could not collect\r\nCMake version: version 3.14.0\r\n\r\nPython version: 3.8 (64-bit runtime)\r\nIs CUDA available: False\r\nCUDA runtime version: No CUDA\r\nGPU models and configuration: No CUDA\r\nNvidia driver version: No CUDA\r\ncuDNN version: No CUDA\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.18.5\r\n[pip3] torch==1.6.0\r\n[pip3] torchvision==0.7.0\r\n[conda] blas                      1.0                         mkl  \r\n[conda] cudatoolkit               10.2.89              hfd86e86_1  \r\n[conda] magma-cuda102             2.5.2                         1    pytorch\r\n[conda] mkl                       2020.1                      217  \r\n[conda] mkl-include               2020.1                      217  \r\n[conda] mkl-service               2.3.0            py38he904b0f_0  \r\n[conda] mkl_fft                   1.1.0            py38h23d657b_0  \r\n[conda] mkl_random                1.1.1            py38h0573a6f_0  \r\n[conda] numpy                     1.18.5           py38ha1c710e_0  \r\n[conda] numpy-base                1.18.5           py38hde5b4d6_0  \r\n[conda] pytorch                   1.6.0           py3.8_cuda10.2.89_cudnn7.6.5_0    pytorch\r\n[conda] torchvision               0.7.0                py38_cu102    pytorch\r\n\r\ncc @yf225 @glaringlee @mruberry @rgommers"},{"labels":[null,"api",null,null,null],"text":"##  Bug\r\n\r\nF.mse_loss(a, b, reduction='elementwise_mean') has very different behaviors depending on if `b` require a gradient or not.\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n```\r\nimport torch\r\nfrom torch.nn import functional as F\r\n\r\nA = torch.ones(2)\r\nB = torch.zeros(2, requires_grad=True)\r\nprint(F.mse_loss(A, B, reduction='elementwise_mean'))\r\n\r\nC = torch.zeros(2)\r\nprint(F.mse_loss(A, C, reduction='elementwise_mean'))\r\n```\r\n\r\nreturns\r\n```\r\n# first call takes the sum\r\ntensor(2., grad_fn=<SumBackward0>)\r\n\r\n# second call takes the mean and prints a warning\r\n/home/vitchyr/anaconda2/envs/tmp/lib/python3.6/site-packages/torch/nn/_reduction.py:14: UserWarning: reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\r\n  warnings.warn(\"reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\")\r\ntensor(1.)\r\n```\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## Expected behavior\r\n\r\nI think the second behavior (a deprecation warning and taking the mean) is the correct/expected behavior, but the two behaviors do not match.\r\n\r\n## Environment\r\n```\r\nPyTorch version: 1.6.0\r\nIs debug build: False\r\nCUDA used to build PyTorch: 10.2\r\n\r\nOS: Ubuntu 16.04.6 LTS (x86_64)\r\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609\r\nClang version: Could not collect\r\nCMake version: version 3.5.1\r\n\r\nPython version: 3.6 (64-bit runtime)\r\nIs CUDA available: False\r\nCUDA runtime version: 10.1.105\r\nGPU models and configuration: \r\nGPU 0: GeForce GTX 1080\r\nGPU 1: GeForce GTX 1080\r\n\r\nNvidia driver version: 418.56\r\ncuDNN version: Probably one of the following:\r\n/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcudnn.so.6\r\n/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcudnn.so.7\r\n\r\nVersions of relevant libraries:\r\n[pip] numpy==1.16.3\r\n[pip] torch==1.6.0\r\n[conda] numpy                     1.16.3                   pypi_0    pypi\r\n[conda] torch                     1.6.0                    pypi_0    pypi\r\n```\r\n## Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n\r\n\r\ncc @ezyang @gchanan @zou3519 @yf225 @glaringlee @albanD @mruberry"},{"labels":["api",null],"text":"I followed [https://pytorch.org/tutorials/advanced/cpp_export.html](url) to trace a model from existing weights in python as shown below\r\n\r\n`        \r\n\r\n        if self.conf.use_cuda:\r\n            torch.set_default_tensor_type('torch.cuda.FloatTensor')\r\n        else:\r\n            torch.set_default_tensor_type('torch.FloatTensor')\r\n\r\n        self.learner = face_learner(self.conf, self.device)\r\n        # load pretrained model for learner object\r\n        self.learner.model.load_state_dict(torch.load(self.conf.learner_model_path))\r\n        self.learner.model.eval()\r\n\r\n        # read the example image used for tracing\r\n        image=cv2.imread(\"videos/example.jpg\",1)\r\n\r\n        test_transform = trans.Compose([\r\n                    trans.ToTensor(),\r\n                    trans.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\r\n                ])\r\n\r\n        resized_image = cv2.resize(image, (112, 112))\r\n        # Use torch.jit.trace to generate a torch.jit.ScriptModule via tracing.\r\n        traced_script_module = torch.jit.trace(self.learner.model, test_transform(resized_image).unsqueeze(0).to(self.device))\r\n        traced_script_module.save(\"traced_facelearner_model_new.pt\")\r\n`\r\n\r\nThe face learner model gives 1x512 embedding as output.\r\n\r\n`\r\n\r\n                torch::jit::script::Module model = torch::jit::load(\"traced_facelearner_model_new.pt\");\r\n\t\tmodel.to(torch::kCUDA);\r\n\t\tmodel.eval();\r\n\r\n\t\tcv::Mat visibleFrame = cv::imread(\"example.jpg\");\r\n\r\n\t\tcv::resize(visibleFrame, visibleFrame, cv::Size(112, 112));\r\n\t\tat::Tensor tensor_image = torch::from_blob(visibleFrame.data, { 1, visibleFrame.rows, visibleFrame.cols, 3 }, at::kByte);\r\n\t\ttensor_image = tensor_image.permute({ 0, 3, 1, 2 });\r\n\t\ttensor_image = tensor_image.to(at::kFloat);\r\n\r\n\t\ttensor_image[0][0] = tensor_image[0][0].sub(0.5).div(0.5);\r\n\t\ttensor_image[0][1] = tensor_image[0][1].sub(0.5).div(0.5);\r\n\t\ttensor_image[0][2] = tensor_image[0][2].sub(0.5).div(0.5);\r\n\r\n\t\ttensor_image = tensor_image.to(torch::kCUDA);\r\n\t\tstd::vector<torch::jit::IValue> input;\r\n\t\tinput.emplace_back(tensor_image);\r\n\t\t// Execute the model and turn its output into a tensor.\r\n\t\tauto output = model.forward(input).toTensor();\r\n`\r\n\r\nI'm pretty sure my preprocessing steps on the image in libtorch and pytorch are the same. But the output embedding is still different. \r\nfor eg: python output of first 3 values in the embedding\r\ntensor([[ 2.3617e-02, -1.3115e-02,  7.1695e-02,\r\n\r\nc++ output of first 3 values\r\n Columns 1 to 10 -0.0248 -0.0245 -0.0204\r\n\r\n\r\nPC Specifications:\r\nIntel i7\r\nGtX 970M \r\nWindows 10\n\ncc @suo @gmagogsfm @yf225 @glaringlee"},{"labels":[null,"api",null,null],"text":"##  Bug\r\n\r\nWe are building libtorch using ./scripts/build_anroid.sh.\r\n\r\nWe need the support for Aten Ops and TorchScript, so building without the BUILD_CAFFE2_MOBILE option.\r\n\r\nThe build is successful, but the library does not link ${TORCH_SRC_DIR}/csrc/api/src/optim/adam.cpp and dependencies because of NO_API being set for Mobile Builds.\r\n\r\nBecause of this I am unable to train the model and instantiate Adam Optimizer instance from the code.\r\n\r\ntorch::optim::Adam optimizer(parameters, lr); //Linker Error\r\noptimizer.zero_grad(); //Linker Error\r\noptimizer.step(); //Linker Error\r\n\r\nFollowing is the Linker error:\r\n/home/atibrewal/work/apprecommender/src/RNNRecommender.cpp:374: undefined reference to `torch::optim::AdamOptions::AdamOptions(double)'\r\n/home/atibrewal/work/apprecommender/src/RNNRecommender.cpp:375: undefined reference to `torch::optim::Optimizer::zero_grad()'\r\n/home/atibrewal/work/apprecommender/src/RNNRecommender.cpp:395: undefined reference to `torch::optim::Adam::step(std::__ndk1::function<at::Tensor ()>)'\r\nCMakeFiles/hxRecommenderEngine.dir/src/RNNRecommender.cpp.o: In function `OptimizerParamGroup':\r\n/home/atibrewal/work/hielibs_android/include/torch/csrc/api/include/torch/optim/optimizer.h:68: undefined reference to `torch::optim::OptimizerParamGroup::params() const'\r\n/home/atibrewal/work/hielibs_android/include/torch/csrc/api/include/torch/optim/optimizer.h:68: undefined reference to `torch::optim::OptimizerParamGroup::has_options() const'\r\n/home/atibrewal/work/hielibs_android/include/torch/csrc/api/include/torch/optim/optimizer.h:68: undefined reference to `torch::optim::OptimizerParamGroup::options() const'\r\nCMakeFiles/hxRecommenderEngine.dir/src/RNNRecommender.cpp.o: In function `AdamOptions':\r\n/home/atibrewal/work/hielibs_android/include/torch/csrc/api/include/torch/optim/adam.h:21: undefined reference to `vtable for torch::optim::AdamOptions'\r\n/home/atibrewal/work/hielibs_android/include/torch/csrc/api/include/torch/optim/adam.h:21: undefined reference to `vtable for torch::optim::AdamOptions'\r\nCMakeFiles/hxRecommenderEngine.dir/src/RNNRecommender.cpp.o: In function `Adam':\r\n/home/atibrewal/work/hielibs_android/include/torch/csrc/api/include/torch/optim/adam.h:52: undefined reference to `vtable for torch::optim::Adam'\r\n/home/atibrewal/work/hielibs_android/include/torch/csrc/api/include/torch/optim/adam.h:52: undefined reference to `vtable for torch::optim::Adam'\r\nCMakeFiles/hxRecommenderEngine.dir/src/RNNRecommender.cpp.o: In function `OptimizerOptions':\r\n/home/atibrewal/work/hielibs_android/include/torch/csrc/api/include/torch/optim/optimizer.h:49: undefined reference to `vtable for torch::optim::OptimizerOptions'\r\n/home/atibrewal/work/hielibs_android/include/torch/csrc/api/include/torch/optim/optimizer.h:49: undefined reference to `vtable for torch::optim::OptimizerOptions'\r\nCMakeFiles/hxRecommenderEngine.dir/src/RNNRecommender.cpp.o: In function `Optimizer':\r\n/home/atibrewal/work/hielibs_android/include/torch/csrc/api/include/torch/optim/optimizer.h:91: undefined reference to `vtable for torch::optim::Optimizer'\r\n/home/atibrewal/work/hielibs_android/include/torch/csrc/api/include/torch/optim/optimizer.h:91: undefined reference to `vtable for torch::optim::Optimizer'\r\n/home/atibrewal/work/hielibs_android/include/torch/csrc/api/include/torch/optim/optimizer.h:93: undefined reference to `torch::optim::Optimizer::add_param_group(torch::optim::OptimizerParamGroup const&)'\r\nCMakeFiles/hxRecommenderEngine.dir/src/RNNRecommender.cpp.o: In function `~Optimizer':\r\n/home/atibrewal/work/hielibs_android/include/torch/csrc/api/include/torch/optim/optimizer.h:103: undefined reference to `vtable for torch::optim::Optimizer'\r\n/home/atibrewal/work/hielibs_android/include/torch/csrc/api/include/torch/optim/optimizer.h:103: undefined reference to `vtable for torch::optim::Optimizer'\r\nCMakeFiles/hxRecommenderEngine.dir/src/RNNRecommender.cpp.o:(.data.rel.ro._ZTVN5torch5optim25OptimizerCloneableOptionsINS0_11AdamOptionsEEE[_ZTVN5torch5optim25OptimizerCloneableOptionsINS0_11AdamOptionsEEE]+0x18): undefined reference to `torch::optim::OptimizerOptions::serialize(torch::serialize::InputArchive&)'\r\nCMakeFiles/hxRecommenderEngine.dir/src/RNNRecommender.cpp.o:(.data.rel.ro._ZTVN5torch5optim25OptimizerCloneableOptionsINS0_11AdamOptionsEEE[_ZTVN5torch5optim25OptimizerCloneableOptionsINS0_11AdamOptionsEEE]+0x20): undefined reference to `torch::optim::OptimizerOptions::serialize(torch::serialize::OutputArchive&) const'\r\nCMakeFiles/hxRecommenderEngine.dir/src/RNNRecommender.cpp.o:(.data.rel.ro._ZTIN5torch5optim25OptimizerCloneableOptionsINS0_11AdamOptionsEEE[_ZTIN5torch5optim25OptimizerCloneableOptionsINS0_11AdamOptionsEEE]+0x10): undefined reference to `typeinfo for torch::optim::OptimizerOptions'\r\n\r\n\r\n## Environment\r\n\r\n - PyTorch Version (e.g., 1.0): Pytorch 1.5.1 and 1.6.0\r\n - OS (e.g., Linux): Android arm64-v8a\r\n - How you installed PyTorch (`conda`, `pip`, source): source\r\n - Build command you used (if compiling from source): /scripts/build_anroid.sh\r\n - Python version: NA\r\n - CUDA/cuDNN version: NA (using a CPU version)\r\n - GPU models and configuration: NA\r\n - Any other relevant information: Android NDK version 19c\r\n\r\n\n\ncc @yf225 @glaringlee @vincentqb"},{"labels":["api",null],"text":"## MultiheadAttention model parameters are different in python and C++.\r\nIn C++, MultiheadAttention module's parameter is no set, its Linear sub-module's parameters can be retrieved C++. \r\nIn python parameters of the module and sub module can be retrieved.\r\n\r\nThe corresponding C++ code with output is as follows\r\n```c++\r\n#include <torch/torch.h>\r\n#include <iostream>\r\nnamespace nn = torch::nn;\r\nint main() {\r\n  int64_t d_model = 4;\r\n  int64_t nhead = 2;\r\n  double dropout = 0.0;\r\n  nn::MultiheadAttention mmodel = nn::MultiheadAttention(nn::MultiheadAttentionOptions(d_model, nhead).dropout(dropout));\r\n  for (const auto& module : mmodel->modules()) {\r\n    std::cout<< \" Module name :\" << module->name() << std::endl;\r\n    for (auto& param : module->named_parameters(false)) {\r\n      std::cout<< param.key() << \":\" << param.value() << std::endl;\r\n    }\r\n  }\r\n}\r\n```\r\nC++ Output:\r\n\r\n Module name :torch::nn::MultiheadAttention\r\n Module name :torch::nn::LinearImpl\r\nweight:-0.3390  0.1080 -0.0194 -0.1426\r\n 0.0612  0.0071  0.1883  0.1399\r\n-0.2122  0.4950 -0.2251  0.0851\r\n 0.3598  0.0617 -0.3281 -0.0391\r\n[ CPUFloatType{4,4} ]\r\nbias: 0\r\n 0\r\n 0\r\n 0\r\n[ CPUFloatType{4} ]\r\n\r\nPython code with output is as follows\r\n\r\n```python\r\nimport torch.nn as nn\r\nd_model = 4\r\nnhead = 2\r\ndropout = 0.0\r\nnet = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\r\nfor m in net.modules():\r\n    print('Module name :', m)\r\n    for nm, p in m.named_parameters(recurse=False):\r\n        print(nm, \":\", p)\r\n```\r\nPython Output:\r\n\r\nModule name : MultiheadAttention(\r\n  (out_proj): _LinearWithBias(in_features=4, out_features=4, bias=True)\r\n)\r\nin_proj_weight : Parameter containing:\r\ntensor([[ 0.3215,  0.1712, -0.4258,  0.0608],\r\n        [ 0.1573, -0.3351, -0.5111,  0.1464],\r\n        [-0.2922,  0.0303,  0.5510, -0.5638],\r\n        [ 0.3144,  0.2177,  0.1631,  0.0863],\r\n        [ 0.5004, -0.2727,  0.3545, -0.1129],\r\n        [ 0.4676, -0.2856, -0.0074, -0.5064],\r\n        [-0.5378,  0.2378,  0.1775, -0.1606],\r\n        [-0.0225, -0.5279,  0.4279, -0.3752],\r\n        [ 0.4622, -0.2481, -0.3727,  0.5852],\r\n        [-0.6048, -0.4132, -0.6092, -0.5233],\r\n        [-0.3640,  0.1864, -0.3457, -0.5625],\r\n        [ 0.2493, -0.3487, -0.3142, -0.1200]], requires_grad=True)\r\nin_proj_bias : Parameter containing:\r\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\r\nModule name : _LinearWithBias(in_features=4, out_features=4, bias=True)\r\nweight : Parameter containing:\r\ntensor([[-0.3266,  0.3457,  0.2251, -0.3043],\r\n        [-0.0438,  0.4598, -0.0973,  0.3782],\r\n        [ 0.0520,  0.3891, -0.1004, -0.2929],\r\n        [ 0.0734,  0.2197, -0.2849,  0.2117]], requires_grad=True)\r\nbias : Parameter containing:\r\ntensor([0., 0., 0., 0.], requires_grad=True)\r\n\r\n\r\nAm I missing something in the C++ usage, or is there a bug. Need help to confirm C++ API usage. \r\n \r\n\n\ncc @yf225 @glaringlee"},{"labels":[null,"api",null],"text":"##  Bug\r\n\r\nOn Top of Master Linux libtorch torch::cuda::is_available() returns zero even when linked against torch_cuda. I have linked against the latest wget https://download.pytorch.org/libtorch/nightly/cpu/libtorch-shared-with-deps-latest.zip\r\n\r\nIf you put the code inside pytorch's build system with cpp /tests it works ok. \r\n\r\nSnippet:\r\n\r\n    torch::Device device = torch::kCPU;\r\n    std::cout << \"CUDA DEVICE COUNT: \" << torch::cuda::device_count() << std::endl;\r\n    if (torch::cuda::is_available()) {\r\n      std::cout << \"CUDA is available! Training on GPU.\" << std::endl;\r\n      device = torch::kCUDA;\r\n    }\r\n\r\n\r\n\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Download library from https://download.pytorch.org/libtorch/nightly/cpu/libtorch-shared-with-deps-latest.zip\r\n\r\n1. link above program and run. Cuda is not detected. \r\n1.\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## Expected behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n## Environment\r\n\r\nCuda should be detected. \r\n\r\n\r\nPlease copy and paste the output from our\r\n[environment collection script](https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py)\r\n(or fill out the checklist below manually).\r\n\r\nYou can get the script and run it with:\r\n```\r\nwget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\r\n# For security purposes, please check the contents of collect_env.py before running it.\r\npython collect_env.py\r\n```\r\n\r\n - PyTorch Version (e.g., 1.0):\r\n - OS (e.g., Linux):\r\n - How you installed PyTorch (`conda`, `pip`, source):\r\n - Build command you used (if compiling from source):\r\n - Python version:\r\n - CUDA/cuDNN version:\r\n - GPU models and configuration:\r\n - Any other relevant information:\r\n\r\n## Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n\n\ncc @malfet @yf225 @glaringlee"},{"labels":["api",null,null],"text":"nn::Sequential(nn::Linear(dim_states, h_neurons),\r\n\t\t\t\t\t\t\tnn::Functional(torch::tanh),\r\n\t\t\t\t\t\t\tnn::Linear(h_neurons, h_neurons),\r\n\t                        nn::Functional(torch::tanh),\r\n\t\t\t\t\t\t\tnn::Linear(h_neurons, dim_acts),\r\n\t\t\t\t\t\t\tnn::Functional(torch::softmax(-1)));\r\n\r\ncompile error\r\n../src/actorcritic.cpp:13:40: error: no matching function for call to ‘softmax(int)’\r\n\r\nnn::Functional(torch::softmax((int64_t)-1)  \r\nerror: no matching function for call to ‘softmax(int64_t)’\n\ncc @yf225 @glaringlee @albanD @mruberry"},{"labels":["api",null],"text":"##  Bug\r\n\r\nMultiheadAttention c++ API did not register parameters under some conditions. The most important ones are 'in_proj_weight' and 'in_proj_bias'.\r\n\r\nHere is the parameter registration phase in c++ impl:\r\nhttps://github.com/pytorch/pytorch/blob/47766e648ff16d4b1175d04710caed566de14ab4/torch/csrc/api/src/nn/modules/activation.cpp#L450\r\n\r\nHere is the parameter registration phase in python impl:\r\nhttps://github.com/pytorch/pytorch/blob/75a4862f639de666c66a0db240c993918b80707f/torch/nn/modules/activation.py#L842\r\n\r\nThe problem here is that in python, the following code will register parameter automatically, but c++ version doesn't.\r\n```\r\nself.in_proj_bias = Parameter(torch.empty(3 * embed_dim))\r\n```\r\nThe reason is that `Module` has a customized __setattr__ which handles the parameter/module registration automatically:\r\nhttps://github.com/pytorch/pytorch/blob/eace0533985641d9c2f36e43e3de694aca886bd9/torch/nn/modules/module.py#L657\r\n\r\nThis will cause problem when people want to update parameters' value by iterating parameter that returned by calling parameters(), since some of the parameters won't be returned by c++ version. Here is an example:\r\nhttps://github.com/pytorch/pytorch/blob/f71cccc457421ad220cf58914c8bc3801b072300/test/test_nn.py#L4678\r\n\r\nThe possible equivalent c++ impl will be something like this:\r\n```\r\ntorch::MultiheadAttention model(torch::MultiheadAttentionOptions(4, 2).dropout(0.0));\r\n{\r\n    torch::NoGradGuard guard;\r\n    for (auto& p : model->parameters()) {\r\n      auto sz = p.view(-1).size(0);\r\n      p.copy_(torch::cos(torch::arange(0, sz, tensor_options).view(p.sizes())));\r\n    }\r\n}\r\n```\r\nCurrently, c++ code will return two less parameters from module->parameters() than python version due to not registering the parameter correctly.\r\n\r\n## To Reproduce\r\n\r\nAbove c++ code piece is an example.\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## Expected behavior\r\n\r\nPython and c++ api should return same number of parameters when calling parameters().\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n## Environment\r\n\r\n ```\r\nPyTorch version: 1.7.0a0+fced54a\r\nIs debug build: No\r\nCUDA used to build PyTorch: 9.2\r\n\r\nOS: CentOS Linux 7 (Core)\r\nGCC version: (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)\r\nCMake version: version 3.14.0\r\n\r\nPython version: 3.8\r\nIs CUDA available: Yes\r\nCUDA runtime version: 9.2.88\r\nGPU models and configuration: \r\nGPU 0: Tesla M40\r\nGPU 1: Tesla M40\r\n\r\nNvidia driver version: 418.126.02\r\ncuDNN version: Probably one of the following:\r\n/usr/lib64/libcudnn.so.7.6.5\r\n/usr/local/cuda-9.2/targets/x86_64-linux/lib/libcudnn.so.7.1.4\r\n```\r\n\r\n## Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n\r\n\r\ncc @yf225 @glaringlee"},{"labels":[null,"api"],"text":"I have a code that successfully compiles on some machines but not on the others. \r\n\r\nproject structure:\r\nforeach_cuda\r\n--[libtorch]\r\n--CMakeLists.txt\r\n--main.cu\r\n--[build] \r\n\r\n**How am i running it**\r\n-> module list \r\n 1) cuda/10.2   2) cudnn/v7.6.5.32-cuda.10.2\r\n\r\n-> cd build \r\n-> cmake -DCMAKE_PREFIX_PATH=/private/home/iuriiz/fun/cuda-tutorial/libtorch ..\r\n-> cmake --build . --config Release\r\nFAIL\r\n\r\nBuild error: \r\n_make[2]: *** No rule to make target '/usr/local/cuda/lib64/libnvToolsExt.so', needed by 'foreach_cuda'.  Stop.\r\nCMakeFiles/Makefile2:72: recipe for target 'CMakeFiles/foreach_cuda.dir/all' failed\r\nmake[1]: *** [CMakeFiles/foreach_cuda.dir/all] Error 2\r\nMakefile:83: recipe for target 'all' failed\r\nmake: *** [all] Error 2_\r\n\r\n**Setup**\r\nMachine: internal devfair\r\nCUDA version: 10.2\r\nLibtorch: https://download.pytorch.org/libtorch/cu102/libtorch-shared-with-deps-1.5.1.zip\r\n\r\n**Code**\r\nCMakeLists.txt\r\n```\r\ncmake_minimum_required(VERSION 3.0 FATAL_ERROR)\r\nproject(foreach_cuda)\r\n\r\nfind_package(Torch REQUIRED)\r\nfind_package(CUDA REQUIRED)\r\n\r\ncuda_add_executable(foreach_cuda main.cu)\r\n\r\ntarget_link_libraries(foreach_cuda \"${TORCH_LIBRARIES}\")\r\nset_property(TARGET foreach_cuda PROPERTY CXX_STANDARD 14)\r\nset(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} ${TORCH_CXX_FLAGS}\")\r\n```\r\n\r\nmain.cu\r\n\r\n```\r\n#include <iostream>\r\n#include <math.h>\r\n#include <torch/torch.h>\r\n#include <torch/cuda.h>\r\n#include <cuda.h>\r\n#include <cuda_runtime.h>\r\n#include <ATen/ATen.h>\r\n#include <ATen/AccumulateType.h>\r\n#include <ATen/cuda/CUDAContext.h>\r\n#include <ATen/cuda/Exceptions.h>\r\n#include <chrono>\r\n\r\n\r\nint main(void)\r\n{\r\n  std::cout << \"CUDA available: \" << torch::cuda::is_available() << std::endl;\r\n  \r\n  return 0;\r\n}\r\n```\r\n\r\n\n\ncc @malfet @yf225 @glaringlee"},{"labels":["api",null,null],"text":"I want build some preprocess tensor in my c++ code， example as\r\n\r\n    # include \"common/libtorch/include/torch/script.h\"\r\n    # include \"common/libtorch/include/torch/csrc/api/include/torch/torch.h\"\r\n    # include <iostream>\r\n    # include <vector>\r\n    using namespace std;\r\n    int main(int argc, char *argv[]) {\r\n        // 构建示例输入\r\n        // std::vector<torch::jit::IValue> inputs;\r\n        std::vector<int64_t> res_data;\r\n        res_data.resize(1 * 3* 16 * 16);\r\n        cout << res_data.size() << endl;\r\n        torch::Tensor res_tensor = torch::from_blob(res_data.data(),{1, 3, 16, 16}, torch::kInt64);\r\n        cout << \"OK\" << endl;\r\n    }\r\n\r\nbut i got the error:\r\n\r\n    terminate called after throwing an instance of 'std::system_error'\r\n    what():  Unknown error -1\r\n    Aborted (core dumped)\r\n\r\nmy g++ version=5.5，using std=c++14 option，my libtorch version=1.5. Is someone know about this error ? thank you very much !!\r\n\r\n    \n\ncc @yf225 @glaringlee"},{"labels":["api",null,null],"text":"##  Bug\r\n\r\nI followed the example for [bind_module](https://pytorch.org/cppdocs/api/function_namespacetorch_1_1python_1a977cbbe6d9378ef36203873c87858095.html?highlight=pybind11_module) to test a simple python wrapper for a `torch::nn::Module subclass`. It compiles just fine, but when I try to import the compiled module, I get the error `ImportError: generic_type: type \"Net\" referenced unknown base type \"torch::nn::Module\"`.\r\n\r\n## To Reproduce\r\nSteps to reproduce the behavior:\r\n1. Create the following file structure\r\n```\r\n├── setup.py\r\n├── src\r\n     ├── pybind\r\n             └── test_pybindings.cpp\r\n```\r\n2. `test_pybindings.cpp`:\r\n```\r\n#include <torch/torch.h>\r\n#include <torch/python.h>\r\n\r\nstruct Net : torch::nn::Module {\r\n    Net(int in, int out) { }\r\n    torch::Tensor forward(torch::Tensor x) { return x; }\r\n};\r\n\r\nPYBIND11_MODULE(test_module, m) {\r\n    torch::python::bind_module<Net>(m, \"Net\")\r\n        .def(py::init<int, int>())\r\n        .def(\"forward\", &Net::forward);\r\n}\r\n```\r\n\r\n3. `setup.py` (based on the example from [here](https://pytorch.org/docs/stable/cpp_extension.html#torch.utils.cpp_extension.CppExtension):\r\n```\r\nimport sys\r\nimport torch.cuda\r\nfrom setuptools import setup\r\nfrom torch.utils.cpp_extension import BuildExtension, CppExtension, CUDAExtension\r\nfrom torch.utils.cpp_extension import CUDA_HOME\r\n\r\next_modules = [\r\n    CppExtension(\r\n        'test_module',\r\n        ['src/pybind/test_pybindings.cpp'],\r\n        extra_compile_args=['-O3', '-g', '-Werror', '-fopenmp'])\r\n]\r\nsetup(name='test_module', ext_modules=ext_modules,\r\n        cmdclass={'build_ext': BuildExtension})\r\n```\r\n\r\n4. Alternatively, `CMakeLists.txt` (gives the same error):\r\n```    \r\ncmake_minimum_required(VERSION 2.8.8)\r\nproject(test_module)\r\n\r\n# Set this to something else on the command line if the path is different\r\nif (NOT CUDA_TOOLKIT_ROOT_DIR)\r\n    set(CUDA_TOOLKIT_ROOT_DIR /usr/local/cuda)\r\nendif()\r\n\r\nfind_package(Torch REQUIRED)\r\n\r\n# Try to compile with c++14\r\n# http://stackoverflow.com/a/25836953\r\ninclude(CheckCXXCompilerFlag)\r\nCHECK_CXX_COMPILER_FLAG(\"-std=c++14\" COMPILER_SUPPORTS_CXX14)\r\nif(COMPILER_SUPPORTS_CXX14)\r\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -std=c++14\")\r\n    message(STATUS \"The compiler ${CMAKE_CXX_COMPILER} supports C++14.\")\r\nelse()\r\n    message(STATUS \"The compiler ${CMAKE_CXX_COMPILER} has no C++14 support. Please use a different C++ compiler.\")\r\nendif()\r\n\r\n# Enable compile optimizations and necessary flags\r\nset(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -O3 -fopenmp -fPIC\")\r\n\r\n# Enable debug flags (use if you want to debug in gdb)\r\nset(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -g3 -Wall\")\r\n\r\n# Include our header files\r\ninclude_directories(${TORCH_INCLUDE_DIRS})\r\n\r\n\r\n# TORCH_LIBRARIES doesn't include torch_python, so just get the path ourselves\r\nlink_directories(${TORCH_INSTALL_PREFIX}/lib/)\r\nadd_subdirectory(pybind11)\r\n\r\npybind11_add_module(test_module src/pybind/test_pybindings.cpp)\r\ntarget_link_libraries(test_module\r\n        PRIVATE c10 torch torch_cpu torch_python)\r\n```\r\n\r\n## Expected behavior\r\n\r\nWithin the proper build directory (or by adding it to the `PYTHONPATH`) I would expect `python3 -c \"import test_module\"` to run without error, but it gives:\r\n```\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nImportError: generic_type: type \"Net\" referenced unknown base type \"torch::nn::Module\"\r\n```\r\n\r\n## Environment\r\n\r\nPyTorch version: 1.6.0a0+dfbf016\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.2\r\n\r\nOS: Ubuntu 16.04.6 LTS\r\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609\r\nCMake version: version 3.5.1\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: 10.2.89\r\nGPU models and configuration: GPU 0: GeForce RTX 2070 SUPER\r\nNvidia driver version: 450.36.06\r\ncuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.19.0\r\n[pip3] torch==1.6.0a0+dfbf016\r\n[conda] Could not collect\r\n\r\n\r\n## Additional context\r\n\r\nNote that I installed pytorch from source with `python3 setup.py install --user`, and set `Torch_DIR` in my `.bashrc` to `~/.local/lib/python3.6/site-packages/torch/share/cmake/Torch` to allow the cmake build (which is preferred but not required for me), and to have the C++ torch and python version be the same build. \r\nI am on the master branch commit dfbf0164c9d47e89ec019668f3cc92ac345cfc8f.\r\n\n\ncc @yf225 @glaringlee"},{"labels":["api",null,null,null],"text":"##  Bug\r\n\r\nUsing the data_parallel C++ interface results in code that is much slower on multiple GPUs than on a single GPU.  In addition, the GPU utilization is less than 10% with muliple GPUs compared to over 96% with a single GPU.\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n Implement a non-trivial model (e.g. ResNet50 or SlowFast) using the libtorch c++ interface (I used libtorch-win-shared-with-deps-1.5.0.zip + cuda 10.1)\r\n\r\nAdd mulitiple GPU support via torch::nn::parallel::data_parallel\r\n\r\nTime training runs with a single GPU and with multiple GPUs \r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## Expected behavior\r\n\r\nRuns with multiple GPUs should be faster than runs on a single GPU.  Definitely not *much* slower.\r\n\r\n## Environment\r\n\r\n\r\n - PyTorch Version (e.g., 1.0): LibTorch 1.5.0 pre-built library\r\n - OS (e.g., Linux): Windows 7\r\n - How you installed PyTorch (`conda`, `pip`, source): N/A\r\n - Build command you used (if compiling from source): \r\n - Python version: N/A\r\n - CUDA/cuDNN version: 10.1\r\n - GPU models and configuration: 2x GTX 1080\r\n - Any other relevant information:\r\n\r\n## Additional context\r\n\r\nThis is in line with what @dmagee reported in #18837. Looking though the code, it appears as if replicas of the modules are cloned and deleted on every iteration of training. Is there a way to use data_parallel and avoid this overhead?\n\ncc @VitalyFedyunin @ngimel @yf225 @glaringlee @albanD @mruberry"},{"labels":[null,"api",null,null],"text":"I want to perform on the GPU non-maximum-suppression on the output of a darknet/yolo CNN. \r\nThe following testing code works fine : \r\n\r\n//Credits: adapted from https://github.com/pprp to test nms parallel algo with at::Tensor as input\r\n#include <stdio.h>\r\n#include <stdlib.h>\r\n#include \"string\"\r\n//#include <windows.h>//needed for LoadLibrary\r\n#include <cuda_runtime.h>\r\n#include <iostream>\r\n#include <opencv2/core/core.hpp>\r\n#include <opencv2/highgui/highgui.hpp>\r\n#include \"opencv2/imgproc/imgproc.hpp\"\r\n#include \"device_launch_parameters.h\"\r\n\r\n#include \"device_functions.h\"\r\n\r\n#include <ATen/ATen.h>\r\n#include <ATen/cuda/CUDAContext.h>\r\n#include <THC/THC.h>\r\n#include <THC/THCDeviceUtils.cuh>\r\n\r\n\r\n#include \"torch/torch.h\"//->including torch gives problems!!!???\r\n\r\n\r\nusing namespace std;\r\n\r\n#define HANDLE_ERROR(ans) { gpuAssert((ans), __FILE__, __LINE__); }\r\n\r\ninline void gpuAssert(cudaError_t code, const char *file, int line, bool abort=true)\r\n{\r\n\tif (code != cudaSuccess)\r\n\t{\r\n\t\tfprintf(stderr,\"GPUassert: %s %s %d\\n\", cudaGetErrorString(code), file, line);\r\n\t\tif (abort) exit(code);\r\n\t}\r\n}\r\n\r\n\r\ntypedef struct\r\n{\r\n\tdouble x,y,w,h;\r\n\tchar s[100];\r\n\tchar cls[100];\r\n\tdouble cmps;\r\n}box;\r\n\r\n__device__ inline float devIoU(float const* const   b1, float const* const  b2) {\r\n\tfloat ai = (float)(b1[2] + 1) * (b1[3] + 1);\r\n\tfloat aj = (float)(b2[2] + 1) * (b2[3] + 1);\r\n\tfloat x_inter, x2_inter, y_inter, y2_inter;\r\n\r\n\tx_inter = max(b1[0], b2[0]);\r\n\ty_inter = max(b1[1], b2[1]);\r\n\r\n\tx2_inter = min((b1[0] + b1[2]), (b2[0] + b2[2]));\r\n\ty2_inter = min((b1[1] + b1[3]), (b2[1] + b2[3]));\r\n\r\n\tfloat w = (float)max((float)0, x2_inter - x_inter);\r\n\tfloat h = (float)max((float)0, y2_inter - y_inter);\r\n\r\n\tfloat inter = ((w * h) / (ai + aj - w * h));\r\n\treturn inter;\r\n}\r\n\r\n\r\n__global__ void NMS_GPU(const int n_boxes, const float nms_overlap_thresh,\r\n\tconst float* dev_boxes, bool* d_res) {\r\n\tunsigned int xIndex = blockIdx.x * blockDim.x + threadIdx.x;\r\n\t//unsigned int xIndex = threadIdx.x;//only 1 block with index 0!\r\n\tfloat cur_box[5];\r\n\tfloat a_box[5];\r\n\tcur_box[0] = dev_boxes[xIndex * 5 + 0];\r\n\tcur_box[1] = dev_boxes[xIndex * 5 + 1];\r\n\tcur_box[2] = dev_boxes[xIndex * 5 + 2];\r\n\tcur_box[3] = dev_boxes[xIndex * 5 + 3];\r\n\tcur_box[4] = dev_boxes[xIndex * 5 + 4];\r\n\t//__syncthreads();//not necessary as cur_box is not a shared resource\r\n\tfor (int i = 0; i < 19; i++)\r\n\t{\r\n\t\tif (i != xIndex)\r\n\t\t{\r\n\t\t\ta_box[0] = dev_boxes[i * 5 + 0];\r\n\t\t\ta_box[1] = dev_boxes[i * 5 + 1];\r\n\t\t\ta_box[2] = dev_boxes[i * 5 + 2];\r\n\t\t\ta_box[3] = dev_boxes[i * 5 + 3];\r\n\t\t\ta_box[4] = dev_boxes[i * 5 + 4];\r\n\t\t\tif (a_box[4] < cur_box[4] )\r\n\t\t\t{\r\n\t\t\t\tif (devIoU(a_box, cur_box) > nms_overlap_thresh)\r\n\t\t\t\t{\r\n\t\t\t\t\td_res[i] = false;\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}\r\n\r\n\r\n\r\nint main()\r\n{\r\n\tint const threadsPerBlock = sizeof(unsigned long long) * 8;//Bufo : =64(float size)\r\n\t//LoadLibrary(TEXT(\"D:\\\\dev\\\\Cpp\\\\dependencies\\\\torchnew\\\\lib\\\\torch_cuda.dll\"));\r\n\tat::DeviceType device_type;\r\n\r\n\tif (at::cuda::is_available()) {\r\n\t\tdevice_type = at::kCUDA;\r\n\t}\r\n\telse {\r\n\t\tdevice_type = at::kCPU;\r\n\t\tstd::cout << \"No GPU avalaible, sorry ...\" << std::endl;\r\n\t\treturn 0;\r\n\t}\r\n\tat::Device device(device_type);\r\n\tstd::cout << \"Device : \" << device_type << std::endl;\r\n\r\n\tconst int count = 19;\r\n\tcv::Mat temp = cv::imread(\"Cow_45.jpg\",1);\r\n\r\n\tbool *h_res =(bool*)malloc(sizeof(bool)*count);//contains the result of the nms algo (cpu context)\r\n\tfor(int i=0; i<count; i++)\r\n\t{\r\n\t\th_res[i] = true;\r\n\t}\r\n\r\n\tbox b[count];\r\n\tb[0].x = 996.000000;b[0].y = 2566.420000;b[0].w = 170.793000;b[0].h=172.580000;\r\n\tstrcpy(b[0].cls,\"nose\");strcpy(b[0].s,\"0.983194\");b[0].cmps=0.983194;\r\n\tb[1].x = 4238.937000;b[1].y = 1594.513000;b[1].w = 160.063000;b[1].h=148.487000;\r\n\tstrcpy(b[1].cls,\"eye\");strcpy(b[1].s,\"0.992166\");b[1].cmps=0.992166;\r\n\tb[2].x = 4656.389000;b[2].y = 2175.186000;b[2].w = 316.180000;b[2].h=221.552000;\r\n\tstrcpy(b[2].cls,\"nose\");strcpy(b[2].s,\"0.994816\");b[2].cmps=0.994816;\r\n\tb[3].x = 4316.000000;b[3].y = 1660.000000;b[3].w = 127.474000;b[3].h=113.452000;\r\n\tstrcpy(b[3].cls,\"eye\");strcpy(b[3].s,\"0.990833\");b[3].cmps=0.990833;\r\n\tb[4].x = 997.013000;b[4].y = 2664.408000;b[4].w = 222.214000;b[4].h=229.068000;\r\n\tstrcpy(b[4].cls,\"nose\");strcpy(b[4].s,\"0.985067\");b[4].cmps=0.985067;\r\n\tb[5].x = 666.069000;b[5].y = 2029.219000;b[5].w = 135.689000;b[5].h=160.833000;\r\n\tstrcpy(b[5].cls,\"eye\");strcpy(b[5].s,\"0.993240\");b[5].cmps=0.993240;\r\n\tb[6].x = 4653.547000;b[6].y = 2324.000000;b[6].w = 338.125000;b[6].h=133.902000;\r\n\tstrcpy(b[6].cls,\"nose\");strcpy(b[6].s,\"0.982858\");b[6].cmps=0.982858;\r\n\tb[7].x = 4476.556000;b[7].y = 2131.557000;b[7].w = 253.402000;b[7].h=273.601000;\r\n\tstrcpy(b[7].cls,\"nose\");strcpy(b[7].s,\"0.959098\");b[7].cmps=0.959098;\r\n\tb[8].x = 754.326000;b[8].y = 2571.066000;b[8].w = 324.674000;b[8].h=161.605000;\r\n\tstrcpy(b[8].cls,\"nose\");strcpy(b[8].s,\"0.993699\");b[8].cmps=0.993699;\r\n\tb[9].x = 729.962000;b[9].y = 2658.741000;b[9].w = 349.038000;b[9].h=192.046000;\r\n\tstrcpy(b[9].cls,\"nose\");strcpy(b[9].s,\"0.986209\");b[9].cmps=0.986209;\r\n\tb[10].x = 1271.863000;b[10].y = 2058.679000;b[10].w = 138.781000;b[10].h=137.553000;\r\n\tstrcpy(b[10].cls,\"eye\");strcpy(b[10].s,\"0.989965\");b[10].cmps=0.989965;\r\n\tb[11].x = 4316.000000;b[11].y = 1601.751000;b[11].w = 134.204000;b[11].h=141.249000;\r\n\tstrcpy(b[11].cls,\"eye\");strcpy(b[11].s,\"0.988307\");b[11].cmps=0.988307;\r\n\tb[12].x = 650.901000;b[12].y = 2032.621000;b[12].w = 91.484000;b[12].h=42.112000;\r\n\tstrcpy(b[12].cls,\"eye\");strcpy(b[12].s,\"0.969982\");b[12].cmps=0.969982;\r\n\tb[13].x = 1328.000000;b[13].y = 2058.692000;b[13].w = 103.849000;b[13].h=136.518000;\r\n\tstrcpy(b[13].cls,\"eye\");strcpy(b[13].s,\"0.987316\");b[13].cmps=0.987316;\r\n\tb[14].x = 214.809000;b[14].y = 1599.809000;b[14].w = 1553.705000;b[14].h=1319.679000;\r\n\tstrcpy(b[14].cls,\"head\");strcpy(b[14].s,\"0.997623\");b[14].cmps=0.997623;\r\n\tb[15].x = 3826.177000;b[15].y = 1072.206000;b[15].w = 1254.063000;b[15].h=1412.903000;\r\n\tstrcpy(b[15].cls,\"head\");strcpy(b[15].s,\"0.997487\");b[15].cmps=0.997487;\r\n\tb[16].x = 729.632000;b[16].y = 2578.523000;b[16].w = 442.495000;b[16].h=302.378000;\r\n\tstrcpy(b[16].cls,\"nose\");strcpy(b[16].s,\"0.960093\");b[16].cmps=0.960093;\r\n\tb[17].x = 655.430000;b[17].y = 2031.151000;b[17].w = 91.570000;b[17].h=148.691000;\r\n\tstrcpy(b[17].cls,\"eye\");strcpy(b[17].s,\"0.993275\");b[17].cmps=0.993275;\r\n\tb[18].x = 4251.712000;b[18].y = 1660.000000;b[18].w = 147.288000;b[18].h=105.309000;\r\n\tstrcpy(b[18].cls,\"eye\");strcpy(b[18].s,\"0.992576\");b[18].cmps=0.992576;\r\n\r\n\t//***************************************************************************************************************************************\r\n\t//copy boxes to a  at::tensor\r\n\tat::Tensor boxes = at::zeros({ count,5 });\r\n\r\n\tfor (int i = 0; i < count; i++) {\r\n\t\tboxes[i][0] = b[i].x;\r\n\t\tboxes[i][1] = b[i].y;\r\n\t\tboxes[i][2] = b[i].w;\r\n\t\tboxes[i][3] = b[i].h;\r\n\t\tboxes[i][4] = b[i].cmps;\r\n\t}\r\n\r\n\tboxes  = boxes.to(device);\r\n\tfloat* boxes_as_array = boxes.data<float>();//convert at::tensor to a flat array\r\n\r\n\tfloat nms_overlap_thresh = 0.1;\r\n\r\n\t//Comment: this piece of code is apparently necessary to assign the Torch cuda context to the global cuda context\r\n\tTHCState* state = at::globalContext().lazyInitCUDA(); // TODO replace with getTHCState\r\n\tconst int col_blocks = THCCeilDiv(count, threadsPerBlock);\r\n\tunsigned long long* mask_dev = NULL;\r\n\tmask_dev = (unsigned long long*) THCudaMalloc(state,count * col_blocks * sizeof(unsigned long long));\r\n\t//-------------------------------------------------------------------------------------------------------------\r\n\r\n\tbool *d_res;\r\n    //port h_res to GPU\r\n\tHANDLE_ERROR(cudaMalloc((void**)&d_res, count*sizeof(bool)));\r\n\tHANDLE_ERROR(cudaMemcpy(d_res, h_res,sizeof(bool)*count, cudaMemcpyHostToDevice));\r\n\r\n\tNMS_GPU<<<dim3(1,count,1),count>>>(count,nms_overlap_thresh, boxes_as_array,d_res);\r\n\t\r\n\t//port d_res to CPU\r\n\tHANDLE_ERROR(cudaMemcpy(h_res, d_res, sizeof(bool)*count, cudaMemcpyDeviceToHost));\r\n\r\n\t//display result\r\n\tfor(int i =0; i<count ; i++)\r\n\t{\r\n\t\tif(*(h_res+i) == true)\r\n\t\t{\r\n\t\t\t//printf(\"GPU Draw: %d--%d\\n\",i,*(h_res+i));\r\n\t\t\tcv::putText(temp,b[i].cls,cv::Point((int)b[i].x,(int)b[i].y-5),cv::FONT_HERSHEY_SIMPLEX,1.7,cv::Scalar(255,255,255),5,8,0);\r\n\t\t\tcv::putText(temp,b[i].s,cv::Point((int)b[i].x+120,(int)b[i].y-5),cv::FONT_HERSHEY_SIMPLEX,1.7,cv::Scalar(255,255,255),5,8,0);\r\n\t\t\tcv::rectangle(temp,cv::Point((int)b[i].x,(int)b[i].y),cv::Point((int)b[i].x + (int)b[i].w,(int)b[i].y + (int)b[i].h),cv::Scalar(92.185,194),8,8,0);\r\n\t\t}\r\n\t}\r\n\tcv::namedWindow(\"Window\",0);\r\n\tcv::resizeWindow(\"Window\",1064,800);\r\n\tcv::imshow(\"Window\",temp);\r\n\tcv::waitKey(0);\r\n\treturn 0;\r\n}\r\n\r\nProblem : When I include \"torch/torch.h\"  (uncomment line 23) - something I need for rest of the project -  I get the following error (Visual Studio 2019):\r\n\r\n\"Error\t\tmember \"torch::jit::detail::ParameterPolicy::all_slots\" may not be initialized\tacudaNMSTEST\tD:\\dev\\Cpp\\dependencies\\torchnew\\include\\torch\\csrc\\jit\\api\\module.h\t490\t\"\r\n\r\nI struggled a couple of days to find a solution, but in vain. Any idea what is going on/what I did wrong?\r\n\r\n\n\ncc @malfet @yf225 @glaringlee @peterjc123 @nbcsm @guyang3532"},{"labels":[null,null,"api",null,null,null,null],"text":"##  Bug\r\n\r\nTensor.std(0) returns a scalar instead of a vector.\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n```\r\nfloat data[] = { 1, 2, 3, 4, 5, 6 };\r\ntorch::Tensor f = torch::from_blob(data, {2, 3});\r\nstd::cout << f.mean(0) << std::endl;\r\n// yields a 1-d tensor as expected.\r\n// 2.5000\r\n// 3.5000\r\n// 4.5000\r\n// [ CPUFloatType{3} ]\r\nstd::cout << f.std(0) << std::endl;\r\n// yields a scalar, unexpected.\r\n// 1.70783\r\n// [ CPUFloatType{} ]\r\n```\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## Expected behavior\r\n\r\nTensor.std(0) should return a vector to be consistent with other methods. As @ptrblck pointed out in this thread https://discuss.pytorch.org/t/tensor-std-0-returns-a-scalar-instead-of-a-vector/85974, the reason this is happening is because 0 is being interpreted as the `unbiased` argument here, and suggests `f.std(true, 0)` as a workaround. However, even `f.std(true, 0)` actually collapses dimension 1, which is also unintuitive.\r\n\r\nIdeally, these behaviors should be fixed or listed in the documentation.\r\n\r\n## Environment\r\n\r\n`Libtorch 1.4.0` on XCode 11.4 \r\n\r\n## Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n\n\ncc @ezyang @gchanan @zou3519 @yf225 @glaringlee @bhosmer @smessmer @ljk53 @SsnL"},{"labels":[null,null,"api",null],"text":"##  Bug\r\n\r\n`libtorch/include/c10/util/logging_is_not_google_glog.h` exposes `ERROR`, `FATAL`, etc in the global namespace.\r\nThis is included by `torch/script.h`.\r\n\r\nThis causes the conflict with a user code.\r\n\r\n## Expected behavior\r\n\r\nPut them in some namespace.\r\n\r\n## Environment\r\n\r\nbuild-hash: 4ff3872a2099993bf7e...\r\nbuild-version: 1.5.0+cpu\r\n\n\ncc @malfet @yf225 @glaringlee"},{"labels":["api",null,null],"text":"##  Bug\r\nIs was following the example for saving a `torch::tensor` in `c++` and loading it in python kindly provided by @xiangpan-osu at the bottom of #20356. In particular, I wrote \r\n```c++\r\n#include <torch/script.h>\r\n\r\n#include <iostream>\r\n#include <memory>\r\n\r\nint main() {\r\n  auto x = torch::ones({3, 3});\r\n  auto bytes = torch::jit::pickle_save(x);\r\n  std::ofstream fout(\"x.zip\", std::ios::out | std::ios::binary);\r\n  fout.write(bytes.data(), bytes.size());\r\n  fout.close();\r\n  return 0;\r\n}\r\n```\r\nand compiled the program with \r\n```c++\r\ncmake_minimum_required(VERSION 3.0 FATAL_ERROR)\r\nfind_package(Torch REQUIRED)\r\n\r\nadd_executable(example-app test.cpp)\r\ntarget_link_libraries(example-app  PUBLIC \"${TORCH_LIBRARIES}\")\r\nset_property(TARGET example-app PROPERTY CXX_STANDARD 17)\r\n```\r\nWhen loading the saved file `x.zip` in python, I receive the following error: \r\n```python\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-2-f3cc1cba2382> in <module>\r\n----> 1 torch.load('x.zip')\r\n\r\n~/.local/lib/python3.7/site-packages/torch/serialization.py in load(f, map_location, pickle_module, **pickle_load_args)\r\n    526         if _is_zipfile(opened_file):\r\n    527             with _open_zipfile_reader(f) as opened_zipfile:\r\n--> 528                 return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)\r\n    529         return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)\r\n    530 \r\n\r\n~/.local/lib/python3.7/site-packages/torch/serialization.py in _load(zip_file, map_location, pickle_module, **pickle_load_args)\r\n    780     unpickler = pickle_module.Unpickler(data_file, **pickle_load_args)\r\n    781     unpickler.persistent_load = persistent_load\r\n--> 782     result = unpickler.load()\r\n    783 \r\n    784     return result\r\n\r\n~/.local/lib/python3.7/site-packages/torch/serialization.py in persistent_load(saved_id)\r\n    772         data_type, key, location, size = data\r\n    773         if key not in loaded_storages:\r\n--> 774             load_tensor(data_type(size), size, key, _maybe_decode_ascii(location))\r\n    775         storage = loaded_storages[key]\r\n    776         return storage\r\n\r\n~/.local/lib/python3.7/site-packages/torch/serialization.py in load_tensor(obj, size, key, location)\r\n    757         name = 'tensors/{}'.format(key)\r\n    758         size_long = struct.pack(\"<Q\", size)\r\n--> 759         tensor_file = io.BytesIO(size_long + zip_file.get_record(name))\r\n    760         offset = None\r\n    761         is_real_file = False\r\n\r\nRuntimeError: [enforce fail at inline_container.cc:197] . file not found: archive/tensors/0\r\nframe #0: c10::ThrowEnforceNotMet(char const*, int, char const*, std::string const&, void const*) + 0x47 (0x7f7db9c0fd37 in /home/fabian/.local/lib/python3.7/site-packages/torch/lib/libc10.so)\r\nframe #1: caffe2::serialize::PyTorchStreamReader::getRecordID(std::string const&) + 0xe0 (0x7f7dbcd92e30 in /home/fabian/.local/lib/python3.7/site-packages/torch/lib/libtorch.so)\r\nframe #2: caffe2::serialize::PyTorchStreamReader::getRecord(std::string const&) + 0x25 (0x7f7dbcd959f5 in /home/fabian/.local/lib/python3.7/site-packages/torch/lib/libtorch.so)\r\nframe #3: <unknown function> + 0x6a6488 (0x7f7e04ec6488 in /home/fabian/.local/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\r\nframe #4: <unknown function> + 0x295a74 (0x7f7e04ab5a74 in /home/fabian/.local/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\r\nframe #5: _PyMethodDef_RawFastCallKeywords + 0x13b (0x5c85bb in /usr/bin/python)\r\nframe #6: _PyObject_FastCallKeywords + 0x6c9 (0x5ca149 in /usr/bin/python)\r\nframe #7: /usr/bin/python() [0x535a11]\r\nframe #8: _PyEval_EvalFrameDefault + 0x4511 (0x53c5a1 in /usr/bin/python)\r\nframe #9: _PyEval_EvalCodeWithName + 0xb87 (0x536f27 in /usr/bin/python)\r\nframe #10: _PyFunction_FastCallKeywords + 0x488 (0x5c9468 in /usr/bin/python)\r\nframe #11: /usr/bin/python() [0x535880]\r\nframe #12: _PyEval_EvalFrameDefault + 0x552 (0x5385e2 in /usr/bin/python)\r\nframe #13: _PyEval_EvalCodeWithName + 0xb87 (0x536f27 in /usr/bin/python)\r\nframe #14: _PyFunction_FastCallDict + 0x34e (0x5ca63e in /usr/bin/python)\r\nframe #15: /usr/bin/python() [0x5cbcf4]\r\nframe #16: PyObject_CallFunctionObjArgs + 0x89 (0x5cc109 in /usr/bin/python)\r\nframe #17: /usr/bin/python() [0x46f5c3]\r\nframe #18: _PyMethodDescr_FastCallKeywords + 0x1c3 (0x4daca3 in /usr/bin/python)\r\nframe #19: /usr/bin/python() [0x535956]\r\nframe #20: _PyEval_EvalFrameDefault + 0x683 (0x538713 in /usr/bin/python)\r\nframe #21: _PyEval_EvalCodeWithName + 0xb87 (0x536f27 in /usr/bin/python)\r\nframe #22: _PyFunction_FastCallDict + 0x34e (0x5ca63e in /usr/bin/python)\r\nframe #23: _PyEval_EvalFrameDefault + 0x19a2 (0x539a32 in /usr/bin/python)\r\nframe #24: _PyEval_EvalCodeWithName + 0x247 (0x5365e7 in /usr/bin/python)\r\nframe #25: _PyFunction_FastCallKeywords + 0x488 (0x5c9468 in /usr/bin/python)\r\nframe #26: /usr/bin/python() [0x535880]\r\nframe #27: _PyEval_EvalFrameDefault + 0x4511 (0x53c5a1 in /usr/bin/python)\r\nframe #28: _PyEval_EvalCodeWithName + 0x247 (0x5365e7 in /usr/bin/python)\r\nframe #29: PyEval_EvalCode + 0x23 (0x64cbb3 in /usr/bin/python)\r\nframe #30: /usr/bin/python() [0x64e321]\r\nframe #31: _PyMethodDef_RawFastCallKeywords + 0x70 (0x5c84f0 in /usr/bin/python)\r\nframe #32: /usr/bin/python() [0x535990]\r\nframe #33: _PyEval_EvalFrameDefault + 0x552 (0x5385e2 in /usr/bin/python)\r\nframe #34: /usr/bin/python() [0x4d90d4]\r\nframe #35: _PyEval_EvalFrameDefault + 0x1a7f (0x539b0f in /usr/bin/python)\r\nframe #36: /usr/bin/python() [0x4d90d4]\r\nframe #37: _PyEval_EvalFrameDefault + 0x1a7f (0x539b0f in /usr/bin/python)\r\nframe #38: /usr/bin/python() [0x4d90d4]\r\nframe #39: _PyMethodDescr_FastCallKeywords + 0x34d (0x4dae2d in /usr/bin/python)\r\nframe #40: /usr/bin/python() [0x535956]\r\nframe #41: _PyEval_EvalFrameDefault + 0x683 (0x538713 in /usr/bin/python)\r\nframe #42: _PyFunction_FastCallKeywords + 0x18b (0x5c916b in /usr/bin/python)\r\nframe #43: /usr/bin/python() [0x535880]\r\nframe #44: _PyEval_EvalFrameDefault + 0x552 (0x5385e2 in /usr/bin/python)\r\nframe #45: _PyFunction_FastCallKeywords + 0x18b (0x5c916b in /usr/bin/python)\r\nframe #46: /usr/bin/python() [0x535880]\r\nframe #47: _PyEval_EvalFrameDefault + 0x683 (0x538713 in /usr/bin/python)\r\nframe #48: _PyEval_EvalCodeWithName + 0x247 (0x5365e7 in /usr/bin/python)\r\nframe #49: _PyFunction_FastCallKeywords + 0x488 (0x5c9468 in /usr/bin/python)\r\nframe #50: /usr/bin/python() [0x535880]\r\nframe #51: _PyEval_EvalFrameDefault + 0x1451 (0x5394e1 in /usr/bin/python)\r\nframe #52: _PyEval_EvalCodeWithName + 0x247 (0x5365e7 in /usr/bin/python)\r\nframe #53: _PyFunction_FastCallKeywords + 0x488 (0x5c9468 in /usr/bin/python)\r\nframe #54: /usr/bin/python() [0x535880]\r\nframe #55: _PyEval_EvalFrameDefault + 0x683 (0x538713 in /usr/bin/python)\r\nframe #56: _PyEval_EvalCodeWithName + 0x247 (0x5365e7 in /usr/bin/python)\r\nframe #57: _PyFunction_FastCallKeywords + 0x488 (0x5c9468 in /usr/bin/python)\r\nframe #58: /usr/bin/python() [0x535880]\r\nframe #59: _PyEval_EvalFrameDefault + 0x683 (0x538713 in /usr/bin/python)\r\nframe #60: _PyFunction_FastCallKeywords + 0x18b (0x5c916b in /usr/bin/python)\r\nframe #61: /usr/bin/python() [0x535880]\r\nframe #62: _PyEval_EvalFrameDefault + 0x683 (0x538713 in /usr/bin/python)\r\nframe #63: _PyEval_EvalCodeWithName + 0x247 (0x5365e7 in /usr/bin/python)\r\n``` \r\nDoes somebody have any ideas I cannot load the tensor in python? I find it difficult to make sense of the error message above and would appreciate any hints and suggestions! \r\n## Environment\r\nCollecting environment information...\r\nPyTorch version: 1.4.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.1\r\n\r\nOS: Ubuntu 19.10\r\nGCC version: (Ubuntu 9.2.1-9ubuntu2) 9.2.1 20191008\r\nCMake version: version 3.13.4\r\n\r\nPython version: 3.7\r\nIs CUDA available: Yes\r\nCUDA runtime version: 10.1.168\r\nGPU models and configuration: GPU 0: Quadro T1000\r\nNvidia driver version: 435.21\r\ncuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.17.0\r\n[pip3] torch==1.4.0\r\n[pip3] torchvision==0.5.0\r\n[conda] Could not collect\n\ncc @yf225 @glaringlee"},{"labels":["api",null],"text":"Valgrind is my go-to for wrangling possible memory leaks. It is a beautiful piece of software, but is unfortunately (and necessarily) imperfect. I just ran a libtorch-based application through a relatively brief optimization of a CNN model, and it generated a fair number of loss records. Fortunately, all of them appear to be of the possibly lost variety (as opposed to definitely lost); I was using all of the available leak-check-heuristics available to valgrind. Many of these records reflect pytorch-based allocations embedded in pthread-related activities, which may just suggest that threads are not being thoroughly cleaned up on exit.\r\nHowever, there are a number of records which, at least going by the traceback, don’t reflect an allocation embedded in thread creation. For brevity, I won't quote any of them here, because I just want to ask a larger question: Is libtorch (v. 1.5, specifically) being subjected to any kind of careful memory-leak vetting, whether by valgrind or some other checker? I know valgrind is not necessarily the ultimate authority; something as simple as a -fsanitize=address compilation could do as well or better.\n\ncc @yf225 @glaringlee"},{"labels":[null,null,"api",null,null],"text":"##  Bug\r\n`IntegrationTest.CartPole` from `test/cpp/api/integration.cpp` sometimes times out on `pytorch_bazel_build` CI jobs, see for example:\r\nSee failure: https://circleci.com/api/v1.1/project/github/pytorch/pytorch/5577465/output/104/0?file=true&allocation-id=5ecd716dc9b52d5635d36866-0-build%2F5B5F7F46\r\n\n\ncc @ezyang @gchanan @zou3519 @malfet @yf225 @glaringlee"},{"labels":[null,"api",null,null],"text":"##  Bug\r\n\r\nI tried to build with my custom C++ application with Cent OS 7 and it failed. Then I tried to build from source with pytorch 1.5.0 and it crashed in a different place.\r\n\r\nSince the website claim Cent OS 7 is supported with GLIbc version > 2.17, how I can use it on Cent OS 7?\r\n\r\n## To Reproduce\r\n\r\n```\r\n# download https://download.pytorch.org/libtorch/cpu/libtorch-shared-with-deps-1.5.0%2Bcpu.zip\r\n# My custom cmake follow the guideline\r\n```\r\n\r\nerror messaage\r\n```\r\n-- The C compiler identification is GNU 4.8.5\r\n-- The CXX compiler identification is GNU 4.8.5\r\n-- Check for working C compiler: /usr/bin/cc\r\n-- Check for working C compiler: /usr/bin/cc -- works\r\n-- Detecting C compiler ABI info\r\n-- Detecting C compiler ABI info - done\r\n-- Detecting C compile features\r\n-- Detecting C compile features - done\r\n-- Check for working CXX compiler: /usr/bin/c++\r\n-- Check for working CXX compiler: /usr/bin/c++ -- works\r\n-- Detecting CXX compiler ABI info\r\n-- Detecting CXX compiler ABI info - done\r\n-- Detecting CXX compile features\r\n-- Detecting CXX compile features - done\r\nBuilding torch with the host...\r\n-- Looking for pthread.h\r\n-- Looking for pthread.h - found\r\n-- Looking for pthread_create\r\n-- Looking for pthread_create - not found\r\n-- Looking for pthread_create in pthreads\r\n-- Looking for pthread_create in pthreads - not found\r\n-- Looking for pthread_create in pthread\r\n-- Looking for pthread_create in pthread - found\r\n-- Found Threads: TRUE\r\n-- Found torch: /home/centos/pytorch/pytorch-native/libtorch/lib/libtorch.so\r\n-- Found JNI: /usr/lib/jvm/jre/lib/amd64/libjawt.so\r\n-- Configuring done\r\n-- Generating done\r\n-- Build files have been written to: /home/centos/pytorch/build\r\n\r\nIn file included from /home/centos/pytorch/pytorch-native/libtorch/include/c10/util/typeid.h:22:0,\r\n                 from /home/centos/pytorch/pytorch-native/src/pytorch_jni_utils.h:16,\r\n                 from /home/centos/pytorch/pytorch-native/src/ai_pytorch_jni_PyTorchLibrary_nn_functional.cc:15:\r\n/home/centos/pytorch/pytorch-native/libtorch/include/c10/util/C++17.h:16:2: error: #error \"You're trying to build PyTorch with a too old version of GCC. We need GCC 5 or later.\"\r\n #error \"You're trying to build PyTorch with a too old version of GCC. We need GCC 5 or later.\"\r\n  ^\r\n/home/centos/pytorch/pytorch-native/libtorch/include/c10/util/C++17.h:24:2: error: #error You need C++14 to compile PyTorch\r\n #error You need C++14 to compile PyTorch\r\n  ^\r\nIn file included from /home/centos/djl/pytorch/pytorch-native/libtorch/include/c10/util/ArrayRef.h:19:0,\r\n                 from /home/centos/djl/pytorch/pytorch-native/libtorch/include/c10/core/MemoryFormat.h:5,\r\n                 from /home/centos/djl/pytorch/pytorch-native/libtorch/include/ATen/core/TensorBody.h:5,\r\n                 from /home/centos/djl/pytorch/pytorch-native/libtorch/include/ATen/Tensor.h:11,\r\n                 from /home/centos/djl/pytorch/pytorch-native/libtorch/include/ATen/Context.h:4,\r\n                 from /home/centos/djl/pytorch/pytorch-native/libtorch/include/ATen/ATen.h:5,\r\n                 from /home/centos/djl/pytorch/pytorch-native/libtorch/include/torch/csrc/api/include/torch/types.h:3,\r\n                 from /home/centos/djl/pytorch/pytorch-native/libtorch/include/torch/script.h:3,\r\n                 from /home/centos/djl/pytorch/pytorch-native/src/ai_djl_pytorch_jni_PyTorchLibrary_inference.cc:13:\r\n/home/centos/djl/pytorch/pytorch-native/libtorch/include/c10/util/C++17.h:16:2: error: #error \"You're trying to build PyTorch with a too old version of GCC. We need GCC 5 or later.\"\r\n #error \"You're trying to build PyTorch with a too old version of GCC. We need GCC 5 or later.\"\r\n  ^\r\n/home/centos/djl/pytorch/pytorch-native/libtorch/include/c10/util/C++17.h:24:2: error: #error You need C++14 to compile PyTorch\r\n #error You need C++14 to compile PyTorch\r\n  ^\r\nIn file included from /home/centos/djl/pytorch/pytorch-native/libtorch/include/c10/util/typeid.h:22:0,\r\n                 from /home/centos/djl/pytorch/pytorch-native/src/djl_pytorch_jni_utils.h:16,\r\n                 from /home/centos/djl/pytorch/pytorch-native/src/ai_djl_pytorch_jni_PyTorchLibrary_torch_isjm.cc:15:\r\n/home/centos/djl/pytorch/pytorch-native/libtorch/include/c10/util/C++17.h:16:2: error: #error \"You're trying to build PyTorch with a too old version of GCC. We need GCC 5 or later.\"\r\n```\r\n\r\n\r\nAfter this, build from source\r\n\r\n```\r\n# checkout tags/v1.5.0\r\nmkdir build && cd build\r\npython3 ../tools/build_libtorch.py\r\n```\r\n\r\nError message\r\n```\r\ncmake -DBUILD_PYTHON=False -DBUILD_TEST=True -DCMAKE_BUILD_TYPE=Release -DCMAKE_CXX_COMPILER=/usr/bin/cmake -DCMAKE_INSTALL_PREFIX=/home/centos/pytorch/torch -DCMAKE_PREFIX_PATH=/usr/lib/python3.6/site-packages -DNUMPY_INCLUDE_DIR=/home/centos/.local/lib/python3.6/site-packages/numpy/core/include -DPYTHON_EXECUTABLE=/usr/bin/python3 -DPYTHON_INCLUDE_DIR=/usr/include/python3.6m -DUSE_NUMPY=True /home/centos/pytorch\r\n-- The CXX compiler identification is unknown\r\n-- The C compiler identification is GNU 4.8.5\r\n-- Check for working CXX compiler: /usr/bin/cmake\r\n-- Check for working CXX compiler: /usr/bin/cmake -- broken\r\nCMake Error at /usr/local/share/cmake-3.6/Modules/CMakeTestCXXCompiler.cmake:54 (message):\r\n  The C++ compiler \"/usr/bin/cmake\" is not able to compile a simple test\r\n  program.\r\n\r\n  It fails with the following output:\r\n\r\n   Change Dir: /home/centos/pytorch/build_libtorch/build/CMakeFiles/CMakeTmp\r\n\r\n\r\n\r\n  Run Build Command:\"/usr/bin/gmake\" \"cmTC_53171/fast\"\r\n\r\n  /usr/bin/gmake -f CMakeFiles/cmTC_53171.dir/build.make\r\n  CMakeFiles/cmTC_53171.dir/build\r\n\r\n  gmake[1]: Entering directory\r\n  `/home/centos/pytorch/build_libtorch/build/CMakeFiles/CMakeTmp'\r\n\r\n  Building CXX object CMakeFiles/cmTC_53171.dir/testCXXCompiler.cxx.o\r\n\r\n  /usr/bin/cmake -o CMakeFiles/cmTC_53171.dir/testCXXCompiler.cxx.o -c\r\n  /home/centos/pytorch/build_libtorch/build/CMakeFiles/CMakeTmp/testCXXCompiler.cxx\r\n\r\n\r\n  CMake Error: The source directory\r\n  \"/home/centos/pytorch/build_libtorch/build/CMakeFiles/CMakeTmp/testCXXCompiler.cxx\"\r\n  is a file, not a directory.\r\n\r\n  Specify --help for usage, or press the help button on the CMake GUI.\r\n\r\n  gmake[1]: *** [CMakeFiles/cmTC_53171.dir/testCXXCompiler.cxx.o] Error 1\r\n\r\n  gmake[1]: Leaving directory\r\n  `/home/centos/pytorch/build_libtorch/build/CMakeFiles/CMakeTmp'\r\n\r\n  gmake: *** [cmTC_53171/fast] Error 2\r\n\r\n\r\n\r\n\r\n\r\n  CMake will not be able to correctly generate this project.\r\nCall Stack (most recent call first):\r\n  CMakeLists.txt:23 (project)\r\n\r\n\r\n-- Configuring incomplete, errors occurred!\r\nSee also \"/home/centos/pytorch/build_libtorch/build/CMakeFiles/CMakeOutput.log\".\r\nSee also \"/home/centos/pytorch/build_libtorch/build/CMakeFiles/CMakeError.log\".\r\nTraceback (most recent call last):\r\n  File \"../tools/build_libtorch.py\", line 23, in <module>\r\n    rerun_cmake=True, cmake_only=False, cmake=CMake())\r\n  File \"/home/centos/pytorch/tools/build_pytorch_libs.py\", line 59, in build_caffe2\r\n    rerun_cmake)\r\n  File \"/home/centos/pytorch/tools/setup_helpers/cmake.py\", line 323, in generate\r\n    self.run(args, env=my_env)\r\n  File \"/home/centos/pytorch/tools/setup_helpers/cmake.py\", line 141, in run\r\n    check_call(command, cwd=self.build_dir, env=env)\r\n  File \"/usr/lib64/python3.6/subprocess.py\", line 311, in check_call\r\n    raise CalledProcessError(retcode, cmd)\r\nsubprocess.CalledProcessError: Command '['cmake', '-DBUILD_PYTHON=False', '-DBUILD_TEST=True', '-DCMAKE_BUILD_TYPE=Release', '-DCMAKE_CXX_COMPILER=/usr/bin/cmake', '-DCMAKE_INSTALL_PREFIX=/home/centos/pytorch/torch', '-DCMAKE_PREFIX_PATH=/usr/lib/python3.6/site-packages', '-DNUMPY_INCLUDE_DIR=/home/centos/.local/lib/python3.6/site-packages/numpy/core/include', '-DPYTHON_EXECUTABLE=/usr/bin/python3', '-DPYTHON_INCLUDE_DIR=/usr/include/python3.6m', '-DUSE_NUMPY=True', '/home/centos/pytorch']' returned non-zero exit status 1.\r\n```\r\n\r\n\r\n\r\n## Environment\r\n\r\nCollecting environment information...\r\nIs debug build: No\r\n\r\nOS: CentOS Linux 7 (Core)\r\nGCC version: (GCC) 4.8.5 20150623 (Red Hat 4.8.5-39)\r\nCMake version: version 3.6.2\r\n\r\nPython version: 3.6\r\nIs CUDA available: No\r\nCUDA runtime version: No CUDA\r\nGPU models and configuration: No CUDA\r\nNvidia driver version: No CUDA\r\ncuDNN version: No CUDA\r\n\n\ncc @malfet @yf225 @glaringlee"},{"labels":[null,"api",null,null,null],"text":"##  Bug\r\n\r\nSegment Fault After model inference all images usnig C++ API\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. c++ code load my model\r\n2. do inference \r\n3. input all images\r\n4. before return, error occur\r\n\r\nMy dbg error message:\r\n\r\n```\r\n== Switch to GPU mode\r\n[New Thread 0x7fff215ea700 (LWP 30485)]\r\n[New Thread 0x7fff20de9700 (LWP 30486)]\r\n== ResNet50 loaded!\r\n== Label loaded! Let's try it\r\n== Input image path: [enter Q to exit]\r\n/home/yyh/test/PyTorch-CPP/pic/dog.jpg\r\n[New Thread 0x7fff2d664700 (LWP 30487)]\r\n[New Thread 0x7fff2ce63700 (LWP 30488)]\r\n[New Thread 0x7fff29fff700 (LWP 30489)]\r\n[New Thread 0x7fff297fe700 (LWP 30490)]\r\n[New Thread 0x7fff28ffd700 (LWP 30491)]\r\n[New Thread 0x7fff287fc700 (LWP 30492)]\r\n[New Thread 0x7fff27ffb700 (LWP 30493)]\r\n[New Thread 0x7fff03fff700 (LWP 30494)]\r\n[New Thread 0x7fff0233d700 (LWP 30495)]\r\n[New Thread 0x7fff01b3c700 (LWP 30496)]\r\n[New Thread 0x7ffeeffff700 (LWP 30497)]\r\n[New Thread 0x7ffeef7fe700 (LWP 30498)]\r\n[New Thread 0x7ffeeeffd700 (LWP 30499)]\r\n[New Thread 0x7ffeddfff700 (LWP 30500)]\r\n[New Thread 0x7ffedd7fe700 (LWP 30501)]\r\n[New Thread 0x7ffedcffd700 (LWP 30502)]\r\n[New Thread 0x7ffedc7fc700 (LWP 30503)]\r\n[New Thread 0x7ffedbffb700 (LWP 30504)]\r\n[New Thread 0x7ffedb7fa700 (LWP 30505)]\r\n[New Thread 0x7ffed54e9700 (LWP 30506)]\r\n[New Thread 0x7ffed4ce8700 (LWP 30507)]\r\n[New Thread 0x7ffebbfff700 (LWP 30508)]\r\n[New Thread 0x7ffebb7fe700 (LWP 30509)]\r\n[New Thread 0x7ffebaffd700 (LWP 30510)]\r\n[New Thread 0x7ffeba7fc700 (LWP 30511)]\r\n[New Thread 0x7ffeb9ffb700 (LWP 30512)]\r\n[New Thread 0x7ffeb97fa700 (LWP 30513)]\r\n[New Thread 0x7ffeb8ff9700 (LWP 30514)]\r\n[New Thread 0x7ffeb87f8700 (LWP 30515)]\r\n[New Thread 0x7ffeb7ff7700 (LWP 30516)]\r\n[New Thread 0x7ffeb77f6700 (LWP 30517)]\r\n[New Thread 0x7ffeb6ff5700 (LWP 30518)]\r\n[New Thread 0x7ffeb67f4700 (LWP 30519)]\r\n[New Thread 0x7ffeb5ff3700 (LWP 30520)]\r\n[New Thread 0x7ffeb57f2700 (LWP 30521)]\r\n[New Thread 0x7ffeb4ff1700 (LWP 30522)]\r\n[New Thread 0x7ffeb47f0700 (LWP 30523)]\r\n[New Thread 0x7ffeb3fef700 (LWP 30524)]\r\n[New Thread 0x7ffeb37ee700 (LWP 30525)]\r\n[New Thread 0x7ffeb2fed700 (LWP 30526)]\r\n[New Thread 0x7ffeb27ec700 (LWP 30527)]\r\n[New Thread 0x7ffeb1feb700 (LWP 30528)]\r\n[New Thread 0x7ffeb17ea700 (LWP 30529)]\r\n[New Thread 0x7ffeb0fe9700 (LWP 30530)]\r\n[New Thread 0x7ffeb07e8700 (LWP 30531)]\r\n[New Thread 0x7ffeaffe7700 (LWP 30532)]\r\n== image size: [976 x 549] ==\r\n== simply resize: [224 x 224] ==\r\n============= Top-1 =============\r\nLabel: beagle\r\nWith Probability: 99.1227%\r\n============= Top-2 =============\r\nLabel: Walker hound, Walker foxhound\r\nWith Probability: 0.469355%\r\n============= Top-3 =============\r\nLabel: English foxhound\r\nWith Probability: 0.110916%\r\n== Input image path: [enter Q to exit]\r\nQ\r\n\r\nThread 1 \"classifier\" received signal SIGSEGV, Segmentation fault.\r\n0x00007fffec81723e in ?? () from /usr/local/cuda-10.2/lib64/libcudart.so.10.2\r\nMissing separate debuginfos, use: yum debuginfo-install libgcc-8.3.1-4.5.el8.x86_64 libgomp-8.3.1-4.5.el8.x86_64 libstdc++-8.3.1-4.5.el8.x86_64 zlib-1.2.11-10.el8.x86_64\r\n(gdb) bt\r\n#0 0x00007fffec81723e in ?? () from /usr/local/cuda-10.2/lib64/libcudart.so.10.2\r\n#1 0x00007fffec81c70b in ?? () from /usr/local/cuda-10.2/lib64/libcudart.so.10.2\r\n#2 0x00007fffec8492d0 in cudaStreamDestroy () from /usr/local/cuda-10.2/lib64/libcudart.so.10.2\r\n#3 0x00007fff68f0551d in cudnnDestroy () from /usr/local/lib/libtorch_cuda.so\r\n#4 0x00007fff68207a05 in at::cuda::(anonymous namespace)::DeviceThreadHandlePool<cudnnContext*, &at::native::(anonymous namespace)::createCuDNNHandle, &at::native::(anonymous namespace)::destroyCuDNNHandle>::~DeviceThreadHandlePool() () from /usr/local/lib/libtorch_cuda.so\r\n#5 0x00007fff63e66677 in __cxa_finalize () from /lib64/libc.so.6\r\n#6 0x00007fff65a68a83 in __do_global_dtors_aux () from /usr/local/lib/libtorch_cuda.so\r\n#7 0x00007fffffffe0b0 in ?? ()\r\n#8 0x00007ffff7de4106 in _dl_fini () from /lib64/ld-linux-x86-64.so.2\r\nBacktrace stopped: frame did not save the PC\r\n(gdb)\r\n```\r\n\r\nMy code:\r\n\r\n```\r\n// One-stop header.\r\n#include <torch/script.h>\r\n\r\n// headers for opencv\r\n#include <opencv2/highgui/highgui.hpp>\r\n#include <opencv2/imgproc/imgproc.hpp>\r\n#include <opencv2/opencv.hpp>\r\n\r\n#include <cmath>\r\n#include <iostream>\r\n#include <memory>\r\n#include <string>\r\n#include <vector>\r\n\r\n#define kIMAGE_SIZE 224\r\n#define kCHANNELS 3\r\n#define kTOP_K 3\r\n\r\nbool LoadImage(std::string file_name, cv::Mat &image) {\r\n    image = cv::imread(file_name);  // CV_8UC3\r\n    if (image.empty() || !image.data) {\r\n        return false;\r\n    }\r\n    cv::cvtColor(image, image, cv::COLOR_BGR2RGB);\r\n    std::cout << \"== image size: \" << image.size() << \" ==\" << std::endl;\r\n\r\n    // scale image to fit\r\n    cv::Size scale(kIMAGE_SIZE, kIMAGE_SIZE);\r\n    cv::resize(image, image, scale);\r\n    std::cout << \"== simply resize: \" << image.size() << \" ==\" << std::endl;\r\n\r\n    // convert [unsigned int] to [float]\r\n    image.convertTo(image, CV_32FC3, 1.0f / 255.0f);\r\n\r\n    return true;\r\n}\r\n\r\nbool LoadImageNetLabel(std::string file_name,\r\n                       std::vector<std::string> &labels) {\r\n    std::ifstream ifs(file_name);\r\n    if (!ifs) {\r\n        return false;\r\n    }\r\n    std::string line;\r\n    while (std::getline(ifs, line)) {\r\n        labels.push_back(line);\r\n    }\r\n    return true;\r\n}\r\n\r\nint main(int argc, const char *argv[]) {\r\n    if (argc != 3) {\r\n        std::cerr << \"Usage: classifier <path-to-exported-script-module> \"\r\n                     \"<path-to-lable-file>\"\r\n                  << std::endl;\r\n        return -1;\r\n    }\r\n\r\n    torch::jit::script::Module module = torch::jit::load(argv[1]);\r\n    std::cout << \"== Switch to GPU mode\" << std::endl;\r\n    // to GPU\r\n    module.to(at::kCUDA);\r\n\r\n    std::cout << \"== ResNet50 loaded!\\n\";\r\n    std::vector<std::string> labels;\r\n    if (LoadImageNetLabel(argv[2], labels)) {\r\n        std::cout << \"== Label loaded! Let's try it\\n\";\r\n    } else {\r\n        std::cerr << \"Please check your label file path.\" << std::endl;\r\n        return -1;\r\n    }\r\n\r\n    std::string file_name = \"\";\r\n    cv::Mat image;\r\n    while (true) {\r\n        std::cout << \"== Input image path: [enter Q to exit]\" << std::endl;\r\n        std::cin >> file_name;\r\n        if (file_name == \"Q\") {\r\n            break;\r\n        }\r\n        if (LoadImage(file_name, image)) {\r\n            auto input_tensor = torch::from_blob(\r\n                    image.data, {1, kIMAGE_SIZE, kIMAGE_SIZE, kCHANNELS});\r\n            input_tensor = input_tensor.permute({0, 3, 1, 2});\r\n            input_tensor[0][0] = input_tensor[0][0].sub_(0.485).div_(0.229);\r\n            input_tensor[0][1] = input_tensor[0][1].sub_(0.456).div_(0.224);\r\n            input_tensor[0][2] = input_tensor[0][2].sub_(0.406).div_(0.225);\r\n\r\n            // to GPU\r\n            input_tensor = input_tensor.to(at::kCUDA);\r\n\r\n            torch::Tensor out_tensor = module.forward({input_tensor}).toTensor();\r\n\r\n            auto results = out_tensor.sort(-1, true);\r\n            auto softmaxs = std::get<0>(results)[0].softmax(0);\r\n            auto indexs = std::get<1>(results)[0];\r\n\r\n            for (int i = 0; i < kTOP_K; ++i) {\r\n                auto idx = indexs[i].item<int>();\r\n                std::cout << \"    ============= Top-\" << i + 1\r\n                          << \" =============\" << std::endl;\r\n                std::cout << \"    Label:  \" << labels[idx] << std::endl;\r\n                std::cout << \"    With Probability:  \"\r\n                          << softmaxs[i].item<float>() * 100.0f << \"%\" << std::endl;\r\n            }\r\n\r\n        } else {\r\n            std::cout << \"Can't load the image, please check your path.\" << std::endl;\r\n        }\r\n    }\r\n    std::cout << \"Before return, I'm OK!\" << std::endl; **//This can print out**\r\n    return 0;\r\n}\r\n```\r\n\r\n## Expected behavior\r\n\r\nNo error occur.\r\n\r\n## Environment\r\n\r\nPlease copy and paste the output from our\r\n[environment collection script](https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py)\r\n(or fill out the checklist below manually).\r\n\r\nYou can get the script and run it with:\r\n```\r\nwget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\r\n# For security purposes, please check the contents of collect_env.py before running it.\r\npython collect_env.py\r\n```\r\n\r\n - PyTorch Version (e.g., 1.0): Libtorch-1.5.0\r\n - OS (e.g., Linux): CentOS-8.1-1911\r\n - How you installed PyTorch (`conda`, `pip`, source): \r\n - Build command you used (if compiling from source):\r\n - Python version: 3.7\r\n - CUDA/cuDNN version: 10.2/7.6.5\r\n - GPU models and configuration: Tesla T4\r\n - Any other relevant information:\r\n\r\n## Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n\n\ncc @ezyang @gchanan @zou3519 @yf225 @glaringlee @ngimel"},{"labels":[null,"api",null],"text":"##  Bug\r\n\r\nWhen I compile a simple package (**a** for instance) using cmake, the exported ${TORCH_LIBRARIES}$ is as follows,\r\n```\r\ntorch;torch_library;/usr/lib/libc10.so;/opt/cuda/lib/stubs/libcuda.so;/opt/cuda/lib/libnvrtc.so;/opt/cuda/lib/libnvToolsExt.so;/opt/cuda/lib64/libcudart.so;/usr/lib/libc10_cuda.so\r\n```\r\nPackage **a** compiles successfully even if the linker fails to link **torch_library**. \r\n\r\nThe actual problem arises when I have another package (**b**), dependent on the already created package **a**. When I build, it fails with error\r\n\r\n```\r\nCMake Error at /home/vsury/dev/ros/pytorch-example/devel_isolated/a/share/a/cmake/aConfig.cmake:150 (message):\r\n  Project 'b' tried to find library '-Wl,--no-as-needed,$<TARGET_FILE:torch>\r\n  -Wl,--as-needed'.  The library is neither a target nor built/installed\r\n  properly.  Did you compile project 'a'? Did you find_package() it before\r\n  the subdirectory containing its code is included?\r\n```\r\n\r\nThe reason has to do with **torch_library** because there is no library such as **libtorch_library.so**.\r\n\r\nLooking further, it seems like that ${TORCH_LIBRARIES} is linked to ${Caffe2_MAIN_LIBS},\r\n\r\nhttps://github.com/pytorch/pytorch/blob/master/cmake/TorchConfig.cmake.in#L41\r\n\r\nand  ${Caffe2_MAIN_LIBS} is linked to **torch_library**,\r\n\r\nhttps://github.com/pytorch/pytorch/blob/master/cmake/Caffe2Config.cmake.in#L121\r\n\r\nI do not understand the need for **torch_library** and removing it from $TORCH_LIBRARIES$ fixes the entire problem.\r\n\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Create a package **a** with any script with torch functionalities (basically CMakeLists should contain find_package(Torch REQUIRED) and build target with torch libraries.\r\n2. Create another package **b** and make it depend on **a**.\r\n3. Compile package b to get the error.\r\n\r\n## Expected behavior\r\n\r\nSuccessful build\r\n\r\n## Environment\r\n\r\nPlease copy and paste the output from our\r\n\r\n - PyTorch Version (e.g., 1.0): 1.5.0\r\n - OS (e.g., Linux): Archlinux\r\n - How you installed PyTorch (`conda`, `pip`, source): pacman -S\r\n - Build command you used (if compiling from source): cmake and make\r\n - Python version:\r\n - CUDA/cuDNN version:\r\n - GPU models and configuration:\r\n - Any other relevant information:\r\n\r\n## Additional context\r\n\n\ncc @malfet @yf225 @glaringlee"},{"labels":[null,null,"api",null,null,null],"text":"##  Bug\r\n\r\nDear community,\r\n\r\nI am a dev from [KeOps project](https://github.com/getkeops/keops/) building optimized operations written in C++/Cuda that are compatible with pytorch (among others scientific languages). \r\n\r\nWe successfully build python modules compatible with pyTorch since the pyTorch v0.2... But the last v1.5 broke our modules with a runtime error complaining about [missing symbols](https://github.com/getkeops/keops/issues/59).\r\n\r\n\r\nTo simplify the analysis you may find below a minimal working example that builds a module through pybind11n the spirit of [pytorch doc](https://pytorch.org/tutorials/advanced/cpp_frontend.html#writing-a-basic-application). \r\n\r\nIt should output a file `test_module.cpython-38-x86_64-linux-gnu.so` that can be imported from python. This module works well when building with pytorch 1.4 but raised a runtime error when building with pytorch v1.5. \r\n\r\n\r\n## To Reproduce\r\n\r\nAssuming pyTorch and pybind11 installed (e.g. through conda).  There are 2 files\r\n\r\n`module_test.cpp` contains\r\n\r\n```cpp\r\n#include <torch/extension.h>\r\n#include <pybind11/pybind11.h>\r\n// Main function\r\nat::Tensor foo(int s) {\r\n     return torch::eye(s);\r\n}    \r\n\r\n// PyBind11 entry point \r\nPYBIND11_MODULE(test_module, m) {\r\nm.def(\"foo\", &foo, \"Entry point to test module\");\r\n}\r\n```   \r\nand `CMakeList.txt` contains\r\n```\r\nproject(test_module LANGUAGES CXX)\r\n\r\nfind_package(Torch REQUIRED)\r\nfind_package(pybind11  REQUIRED)\r\n\r\npybind11_add_module(test_module ${CMAKE_CURRENT_SOURCE_DIR}/test_module.cpp)\r\ntarget_link_libraries(test_module PUBLIC \"${TORCH_LIBRARIES}\")\r\n```\r\nit can be compile with\r\n\r\n ```bash\r\n$ mkdir build\r\n$ cd build\r\n$ cmake -DCMAKE_PREFIX_PATH=\"/home/bcharlier/.conda/envs/keops/lib/python3.8/site-packages/torch/\" .. && make\r\n```\r\nand run with (note that `torch` is imported first)\r\n```\r\n$ python -c \"import torch; print(torch.__version__); import test_module; print(test_module.foo(3))\"\r\n\r\n1.5.0\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nImportError: /home/bcharlier/src/test_module/build/test_module.cpython-38-x86_64-linux-gnu.so: undefined symbol: _Z16THPVariable_WrapN2at6TensorE\r\n```\r\nThe missing symbol is not exactly the same when [building a module with the keops library](https://github.com/getkeops/keops/issues/59)... But I guess this is irrelevant.\r\n\r\n## Expected behavior\r\n\r\nIt works fine when compiling with pytorch v1.4\r\n\r\n```bash\r\n$ cmake -DCMAKE_PREFIX_PATH=\"/home/bcharlier/.conda/envs/keops_torch14/lib/python3.8/site-packages/torch/\" .. && make\r\n$ python -c \"import torch; print(torch.__version__); import test_module; print(test_module.foo(3))\"\r\n1.4.0\r\ntensor([[1., 0., 0.],\r\n        [0., 1., 0.],\r\n        [0., 0., 1.]])\r\n```\r\n\r\n## Environment\r\n\r\nThe bug was reported by various users running on linux. Here is my config:\r\n\r\n```\r\nCollecting environment information...\r\nPyTorch version: 1.5.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.2\r\n\r\nOS: Arch Linux\r\nGCC version: (Arch Linux 9.3.0-1) 9.3.0\r\nCMake version: version 3.14.0\r\n\r\nPython version: 3.8\r\nIs CUDA available: Yes\r\nCUDA runtime version: 10.2.89\r\nGPU models and configuration: GPU 0: Quadro T2000\r\nNvidia driver version: 440.82\r\ncuDNN version: /usr/lib/libcudnn.so.7.6.5\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.18.4\r\n[conda] blas                      1.0                         mkl  \r\n[conda] cudatoolkit               10.2.89              hfd86e86_1  \r\n[conda] mkl                       2020.0                      166  \r\n[conda] mkl-service               2.3.0            py38he904b0f_0  \r\n[conda] mkl_fft                   1.0.15           py38ha843d7b_0  \r\n[conda] mkl_random                1.1.0            py38h962f231_0  \r\n[conda] numpy                     1.18.1           py38h4f9e942_0  \r\n[conda] numpy-base                1.18.1           py38hde5b4d6_1  \r\n[conda] pytorch                   1.5.0           py3.8_cuda10.2.89_cudnn7.6.5_0    pytorch\r\n\r\n```\n\ncc @ezyang @gchanan @zou3519 @malfet @yf225 @glaringlee"},{"labels":["api",null],"text":"##  Bug\r\n\r\nHi\r\n\r\nI've encountered a problem with the code in \"c10/utils/variant.h\" while trying to build a C++ application.\r\nI've created a simple test program to explain the problem. \r\nThe code I’m trying to build is the following one\r\n\r\n```cpp\r\n//Include standard libraries\r\n#include <iostream>\r\n\r\n//Define namespace data\r\n//This can be included for example by another header file\r\nnamespace data\r\n{\r\n}\r\n\r\n//Include torch library\r\n#include <torch/torch.h>\r\n\r\nint main(int argc, char* argv[])\r\n{\r\n  std::cout << torch::randn({3, 3}) << std::endl;\r\n  return 0;\r\n}\r\n```\r\n\r\nThe CMakeLists.txt is\r\n\r\n```\r\ncmake_minimum_required(VERSION 3.0 FATAL_ERROR)\r\nproject(test_variant)\r\n\r\nfind_package(Torch REQUIRED)\r\n\r\nadd_executable(test_variant main.cpp)\r\ntarget_link_libraries(test_variant \"${TORCH_LIBRARIES}\")\r\nset_property(TARGET test_variant PROPERTY CXX_STANDARD 14)\r\n```\r\n\r\nI’ve added an empty data namespace to better explain the problem.\r\nWhen I build the example I get a lot of errors like\r\n\r\n```\r\n~/test_variant/libtorch/include/c10/util/variant.h:2519:7: error: invalid use of ‘void’\r\n       AUTO_RETURN(v && holds_alternative<I>(*v)\r\n```\r\n\r\nI’ve looked inside the file and it seems that the problem is the statement (line 1165 c10/utils/variant.h)\r\n\r\n```\r\nAUTO_REFREF_RETURN(recursive_union::get_alt(\r\n              data(lib::forward<V>(v)), in_place_index_t<I>{}))\r\n```\r\n\r\nWhere data is incorrectly detected as the namespace I’ve added before the <torch/torch.h> inclusion.\r\nI think it should refer to the data function which can be found in the same file at line 1743 (I tried to change its name and indeed the error is solved).\r\nCould this be an issue or it’s something I’m doing wrong in my code?\r\n\r\nThank you very much for your help\r\n\r\n## Environment\r\n\r\n - PyTorch Version (e.g., 1.0): LibTorch 1.4.0\r\n - OS (e.g., Linux): Ubuntu 16.04 (default compiler)\r\n - How you installed PyTorch (`conda`, `pip`, source): pre-built libraries\r\n - Build command you used (if compiling from source): N/A\r\n - Python version: N/A\r\n - CUDA/cuDNN version: N/A\r\n - GPU models and configuration: N/A\r\n - Any other relevant information: cpu mode only \n\ncc @yf225"},{"labels":["api",null],"text":"##  Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\nThe output from a traced model using (1) python and (2) c++ are different.  \r\n\r\nxpost: https://discuss.pytorch.org/t/c-and-pytorch-inference-discrepancy/77388?u=jonrbates\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n**1. Create model in python**\r\n```\r\nimport torch\r\nfrom transformers import GPT2LMHeadModel\r\nmodel = GPT2LMHeadModel.from_pretrained(\"distilgpt2\", \r\n           pad_token_id=50256,\r\n           torchscript=True)\r\ntraced_model = torch.jit.trace(model, [torch.tensor([[464, 6842, 1816,  625,  262, 8598,  284,  766]])])\r\ntorch.jit.save(traced_model, \"traced_distilgpt2.pt\")\r\n```\r\n\r\n**2. Inference in pytorch**\r\n```\r\nloaded_model = torch.jit.load(\"traced_distilgpt2.pt\")\r\noutputs = loaded_model(torch.tensor([[464, 6842, 1816,  625,  262, 8598,  284,  766]]))\r\n\r\ntorch.max(outputs[0],2)\r\n>> torch.return_types.max(values=tensor([[-26.7050, -53.3268, -66.3666, -50.1084, -54.8050, -72.4056, -55.2586,-63.5215]], grad_fn=<MaxBackward0>),\r\nindices=tensor([[ 383,  373,  319,  262, 1353,  290,  262,  262]]))\r\n\r\ntorch.min(outputs[0][:, :, :],2)\r\n>>torch.return_types.min(\r\nvalues=tensor([[ -47.3794,  -77.6341,  -95.8365,  -75.3026,  -81.6899, -103.6701, -83.0335,  -93.0259]], grad_fn=<MinBackward0>),\r\nindices=tensor([[  154,  7134, 31204, 22997, 10298, 31204, 22997, 31573]]))\r\n```\r\n\r\n**3. Inference in c**\r\n```\r\nint main(int argc, const char* argv[]) {\r\n\r\n  torch::jit::script::Module module;\r\n  module = torch::jit::load(argv[1]);\r\n  std::cout << \"Model loaded.\\n\";\r\n  module.eval(); // just in case?\r\n\r\n  torch::Tensor x = torch::tensor({464, 6842, 1816,  625,  262, 8598,  284,  766},\r\n    torch::dtype(torch::kInt64)).reshape({8, 1});\r\n  std::vector<torch::jit::IValue> inputs;\r\n  inputs.push_back(x);\r\n\r\n  // Execute the model and turn its output into a tensor (all_encoder_layers).\r\n  torch::Tensor out = module.forward(inputs).toTuple()->elements()[0].toTensor();\r\n\r\n  auto z = torch::max(out, /*dim=*/2);\r\n  std::cout << std::get<0>(z) << '\\n';\r\n  std::cout << std::get<1>(z) << '\\n';\r\n\r\n  z = torch::min(out, /*dim=*/2);\r\n  std::cout << std::get<0>(z) << '\\n';\r\n  std::cout << std::get<1>(z) << '\\n';\r\n\r\n  return 0;\r\n}\r\n```\r\n\r\nOutput from running c exe (with argv[1] = \"traced_distilgpt2.pt\") :\r\n```\r\n-26.7050\r\n-28.0251\r\n-29.0539\r\n-28.2608\r\n-26.3226\r\n-28.0652\r\n-26.8328\r\n-28.5087\r\n[ Variable[CPUFloatType]{8,1} ]\r\n 383\r\n 383\r\n 383\r\n 383\r\n 383\r\n 383\r\n 383\r\n 383\r\n[ Variable[CPULongType]{8,1} ]\r\n-47.3794\r\n-48.2470\r\n-49.5565\r\n-49.0826\r\n-46.3104\r\n-48.5934\r\n-47.3013\r\n-49.1308\r\n[ Variable[CPUFloatType]{8,1} ]\r\n 154\r\n 154\r\n 154\r\n 154\r\n 154\r\n 154\r\n 154\r\n 154\r\n[ Variable[CPULongType]{8,1} ]\r\n```\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## Expected behavior\r\nThe models agree for the first token (position=0) but for positions 1-7 the encoder outputs disagree.  All outputs should be equal. \r\n<!-- -->\r\n\r\n## Environment (Pytorch)\r\nPyTorch version: 1.4.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.1\r\n\r\nOS: Microsoft Windows 10 Pro\r\nGCC version: (x86_64-posix-seh-rev0, Built by MinGW-W64 project) 5.4.0\r\nCMake version: version 3.14.0\r\n\r\nPython version: 3.7\r\nIs CUDA available: Yes\r\nCUDA runtime version: 10.0.130\r\nGPU models and configuration: GPU 0: Quadro M500M\r\nNvidia driver version: 442.23\r\ncuDNN version: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\bin\\cudnn64_7.dll\r\n\r\nVersions of relevant libraries:\r\n[pip] Could not collect\r\n[conda] _tflow_select             2.3.0                       mkl\r\n[conda] blas                      1.0                         mkl\r\n[conda] cudatoolkit               10.1.243             h74a9793_0\r\n[conda] libmklml                  2019.0.5                      0\r\n[conda] mkl                       2019.4                      245\r\n[conda] mkl-include               2020.0                      166\r\n[conda] mkl-service               2.3.0            py37hb782905_0\r\n[conda] mkl_fft                   1.0.14           py37h14836fe_0\r\n[conda] mkl_random                1.1.0            py37h675688f_0\r\n[conda] numpy                     1.16.5           py37h19fb1c0_0\r\n[conda] numpy-base                1.16.5           py37hc3f5095_0\r\n[conda] numpydoc                  0.9.1                      py_0\r\n[conda] pytorch                   1.4.0           py3.7_cuda101_cudnn7_0    pytorch\r\n[conda] tensorflow                2.1.0           mkl_py37ha977152_0\r\n[conda] tensorflow-base           2.1.0           mkl_py37h230818c_0\r\n[conda] torchvision               0.5.0                py37_cu101    pytorch\r\n\r\n## Environment (C++)\r\n\r\nPyTorch version: N/A\r\nIs debug build: N/A\r\nCUDA used to build PyTorch: N/A\r\n\r\nOS: Ubuntu 18.04.4 LTS\r\nGCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\r\nCMake version: version 3.10.2\r\n\r\nPython version: 2.7\r\nIs CUDA available: N/A\r\nCUDA runtime version: Could not collect\r\nGPU models and configuration: Could not collect\r\nNvidia driver version: Could not collect\r\ncuDNN version: Could not collect\r\n\r\nVersions of relevant libraries:\r\n[pip] Could not collect\r\n[conda] Could not collect\r\n\n\ncc @yf225"},{"labels":[null,"api",null],"text":"##  Bug\r\n\r\nLoad pytorch tensor created by torch.save(tensor_name, tensor_path) in c++ libtorch failed.\r\nHow can I save some tensor in python, but load it in libtorch?\r\n## To Reproduce\r\n\r\nusing the following code:\r\n\r\nI save tensor named piror using python, using the code:\r\n```\r\nprior = torch.ones(32145, 4)\r\ntorch.save(prior,  'prior.pth')\r\n```\r\nAnd I load the tensor in libtorch using C++, by the following code:\r\n```\r\ntorch::Tensor priors = torch::ones({32145, 4});\r\ntorch::load(priors , \"/app/model/prior.pth\");\r\n```\r\n\r\n## Expected behavior\r\nload the tensor successfully.\r\nAnd get exact same value as in pytorch python-api.\r\n\r\n## Environment\r\nCollecting environment information...\r\nPyTorch version: N/A\r\nIs debug build: N/A\r\nCUDA used to build PyTorch: N/A\r\n\r\nOS: Ubuntu 16.04.5 LTS\r\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609\r\nCMake version: version 3.13.2\r\n\r\nPython version: 3.5\r\nIs CUDA available: N/A\r\nCUDA runtime version: 10.0.130\r\nGPU models and configuration:\r\nGPU 0: TITAN X (Pascal)\r\nGPU 1: TITAN X (Pascal)\r\n\r\nNvidia driver version: 430.26\r\ncuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.4.2\r\n\r\nVersions of relevant libraries:\r\n[pip] Could not collect\r\n[conda] Could not collect\r\n\r\n## Additional context\r\nBut I got the error:\r\nterminate called after throwing an instance of 'c10::Error'\r\n  what():  `torch::jit::load()` received a file from `torch.save()`, but `torch::jit::load()` can only load files produced by `torch.jit.save()` (load at ../torch/csrc/jit/serialization/import.cpp:285)\r\n\r\nWhy is that? I do not use torch::jit::load but torch::load, so how to load tensor saved in pytorch?\r\n\r\nThanks in advance.\n\ncc @suo @yf225"},{"labels":[null,"api",null],"text":"How can I save some tensor in python, but load it in libtorch:\r\n\r\nI save tensor named piror using python, using the code:\r\n```\r\ntorch.save(prior,  'prior.pth')\r\n```\r\nAnd I load the tensor in libtorch using C++, by the following code:\r\n```\r\nstd::vector<torch::Tensor> tensorVec;\r\ntorch::load(tensorVec, \"/app/model/prior.pth\");\r\ntorch::Tensor priors = tensorVec[0];\r\n```\r\nBut I got the error:\r\nterminate called after throwing an instance of 'c10::Error'\r\n  what():  `torch::jit::load()` received a file from `torch.save()`, but `torch::jit::load()` can only load files produced by `torch.jit.save()` (load at ../torch/csrc/jit/serialization/import.cpp:285)\r\n\r\nWhy is that? And what should I do to solve the issue? Thanks in advance.\n\ncc @suo @yf225"},{"labels":[null,null,"api",null,null,null,null,null],"text":"Hi, I want to use my pretrained model(which is trained on pytorch) in my C++ project. I have saved my network in Python and loaded in C++ using jit.\r\n\r\n```\r\n//Python\r\ntraced_script_module = torch.jit.trace(model, input)\r\ntraced_script_module.save(\"model.pt\")\r\n//C++\r\ntorch::jit::script::Module model =torch::jit::load(file_name);\r\n```\r\n\r\nI am passing CUDAFloatTensor as an input. I am supposed to have three outputs from my model.\r\n\r\n```\r\nauto outputs = model.forward({ input });\r\nauto heatmap= outputs.toTuple()->elements()[0].toTensor(); \r\nauto bbox = outputs.toTuple()->elements()[1].toTensor();\r\nauto scan_rec= outputs.toTuple()->elements()[2].toTensor();\r\n```\r\nI realized forward pass doesn’t always give correct results. Sometimes it gives answer below.(which is the right answer I checked on pytorch and outputs on there are always consistent)\r\n`first three elements of bbox : 0.4311, 0.4620, 0.3915`\r\n\r\nBut most of the times I get values like this in each three output and I am having exception when I am trying to use my outputs.\r\n`first three elements of bbox : = 9.3593e-36, 3.9978e+07,-5.3179e+37`\r\n\r\nWhich is really weird. I am assuming there is some kind of overflow going on. I don’t want to train any network in C++. I just want to use my pretrained model as a deterministic function. I also set these in any case before calling forward pass but it didn’t help. I have no idea what is going on.\r\n\r\n```\r\ntorch::manual_seed(0);\r\ntorch::NoGradGuard no_grad;\r\n\r\n```\r\nEnvironment:\r\nWindows 10\r\nCUDA 10.1\r\nVisual Studio 2019\r\nLibtorch Nightly Release latest\r\n\n\ncc @ezyang @gchanan @zou3519 @suo @yf225 @peterjc123"},{"labels":[null,"api",null],"text":"##  Bug\r\n\r\n(not sure how much of a bug this is, maybe it's expected)\r\nI'm currently working on adapting some [rust bindings](https://github.com/LaurentMazare/tch-rs) for PyTorch and in the process came across the following issue for which I don't have a good solution. The issue can be show on C++ code.\r\n- When linking the final binary with `-ltorch -ltorch_cpu -lc10`, `torch::cuda::is_available()` returns false.\r\n- When linking the final binary with `-Wl,--no-as-needed -ltorch -ltorch_cpu -lc10`, `torch::cuda::is_available()` returns true.\r\n- When linking without `-ltorch_cpu`, I get a missing symbol error for: `c10::Dispatcher::singleton`.\r\n\r\nI tried compiling some C++ pytorch code with cmake and it seems to use --no-as-needed to get this to work.\r\n\r\nIs there a way to get some external code to compile without libtorch_cpu?\r\nOne difficulty is that the rust build system does not let you specify arbitrary linker flags so I cannot easily set `-Wl,--no-as-needed`.\r\n\r\n## To Reproduce\r\n\r\nThe issue can be reproduced using the C++ code below.\r\n\r\n```c++\r\n#include <torch/torch.h>\r\n#include <iostream>\r\n\r\nint main() {\r\n  std::cout << torch::cuda::is_available() << std::endl;\r\n}\r\n```\r\nThen:\r\n- `g++ test.cpp -std=gnu++14 -ltorch -ltorch_cpu -lc10 && ./a.out` prints 0.\r\n- `g++ test.cpp -std=gnu++14 -Wl,--no-as-needed -ltorch -ltorch_cpu -lc10 && ./a.out` prints 1.\r\n\r\n## Expected behavior\r\n\r\nI would have hoped for cuda to be reported as available without the `-Wl,--no-as-needed` flag.\r\n\r\n## Environment\r\n\r\n - PyTorch Version (e.g., 1.0): release/1.5 branch as of 2020-04-11.\r\n - OS (e.g., Linux): Linux (ubuntu 18.04)\r\n - How you installed PyTorch (`conda`, `pip`, source): source, compiled with cuda support\r\n - Build command you used (if compiling from source): `python setup.py build`\r\n - Python version: 3.7.1.\r\n - CUDA/cuDNN version: 10.0/none.\r\n - GPU models and configuration: 1x GeForce RTX 2080.\r\n - Any other relevant information: gcc/g++ 7.5.0, ld 2.3.0\r\n\r\n## Additional context\n\ncc @yf225"},{"labels":["api",null,null,null],"text":"##  Bug\r\n\r\nThere are some minor labelling errors in the default options check in  _optim/adah.h_: \r\n```\r\n     auto betas = defaults.betas();\r\n     TORCH_CHECK(std::get<0>(betas) >= 0, \"Invalid learning rate: \", std::get<0>(betas));\r\n     TORCH_CHECK(std::get<1>(betas) >= 0, \"Invalid learning rate: \", std::get<1>(betas));\r\n     TORCH_CHECK(defaults.weight_decay() >= 0, \"Invalid learning rate: \", defaults.weight_decay());\r\n```\r\nI am also seeing worse convergance on some simple GAN's with MNIST,\r\ne.g. the tutorial example, using the newer adam vs the 1.4 version,\r\nbut I don't have a good way to reproduce this yet.\r\nthe GAN's produce noticeably less convincing digits than using the 1.4 version for the same settings and number of iterations.\r\n\n\ncc @yf225 @vincentqb"},{"labels":["api",null,null],"text":"I build 32bit libtorch myself.And I use torch.jit.trace to convert my python module into c++ module. When I try to load module in vs2017 project , an error occur.There is an unhandled exception at 0x00007ffb0ee5db8e (ucrtbase. DLL) (in libtorch1.3.1. Exe): a serious program exit was requested. \r\n\r\n# Python code\r\n```python\r\ndef package():\r\n    model = BiSINet(p=2, q=8)\r\n    model.load_state_dict(\r\n        weight_convert(torch.load(\"weights/temp/SINetDIS_decoder_360_3c.pth\", \"cpu\")))\r\n    model.cpu()\r\n    model.eval()\r\n    with torch.no_grad():\r\n        model_input = torch.rand(1, 3, 224, 224)\r\n        trace_model_script = torch.jit.trace(model, model_input)\r\n        trace_model_script.save('weights/convert/SINet_decoder_3c_x86.pt')\r\n```\r\n\r\n# C++ code\r\n```c++\r\n#include <torch/script.h>\r\n#include <iostream>\r\n\r\nint main() {\r\n\ttorch::jit::script::Module module;\r\n\ttry {\r\n\t\tmodule = torch::jit::load(\"A:\\\\projects\\\\libtorchs\\\\sinet_50.pt\");\r\n\t}\r\n\tcatch (const c10::Error &e) {\r\n\t\tstd::cerr << \"error loading the model\\n\";\r\n\t\treturn -1;\r\n\t}\r\n\tstd::cout << \"ok\\n\";\r\n\treturn 0;\r\n}\r\n```\r\n\r\n# Error Message\r\n0x00007FFB0EE5DB8E (ucrtbase.dll) (libtorch1.3.1.exe \r\n\r\ncc @yf225 @peterjc123"},{"labels":["api",null],"text":"##  Bug\r\n\r\nI got the following error when calling `optimizer.backward()`.\r\n`one of the variables needed for gradient computation has been modified by an inplace operation: [CPUFloatType [50, 40]], which is output 0 of TBackward, is at version 2; expected version 1 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True). after train`\r\n\r\n## To Reproduce\r\nNot sure, since I can't see which operation that makes my code crash.\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## Expected behavior\r\n\r\nI expected the function that was listed in the error to exist.\r\n\r\n## Environment\r\n\r\n - PyTorch Version (e.g., 1.0): Libtorch 1.4\r\n - OS (e.g., Linux): Windows 7 64 bit\r\n - How you installed PyTorch (`conda`, `pip`, source): source\r\n - Build command you used (if compiling from source): none\r\n - Python version: 3.6\r\n - CUDA/cuDNN version: none\r\n - GPU models and configuration: none\r\n - Any other relevant information: none\r\n\r\n\n\ncc @yf225"},{"labels":[null,"api",null],"text":"##  Bug\r\n\r\nRunning the following code in cuda-enabled libtorch throws error \"CUDA error: driver shutting down\", even though the code doesn't use CUDA. Running the same code in cpu-only libtorch doesn't throw any error.\r\n\r\n```cpp\r\n#include <iostream>\r\n#include <torch/torch.h>\r\n\r\nusing namespace torch::autograd;\r\n\r\nclass MulConstant : public Function<MulConstant> {\r\n public:\r\n  static Variable forward(AutogradContext *ctx, Variable variable, double constant) {\r\n    ctx->saved_data[\"constant\"] = constant;\r\n    return variable * constant;\r\n  }\r\n\r\n  static variable_list backward(AutogradContext *ctx, variable_list grad_outputs) {\r\n    return {grad_outputs[0] * ctx->saved_data[\"constant\"].toDouble(), Variable()};\r\n  }\r\n};\r\n\r\nint main(int argc, char* argv[])\r\n{\r\n  auto x = torch::randn({2}).requires_grad_();\r\n  auto y = MulConstant::apply(x, 5.5);\r\n  y.sum().backward();\r\n  std::cout << x.grad() << std::endl;\r\n}\r\n```\r\nError:\r\n```\r\nterminate called after throwing an instance of 'c10::Error'\r\nterminate called recursively\r\n  what():  CUDA error: driver shutting down (setDevice at /pytorch/c10/cuda/impl/CUDAGuardImpl.h:42)\r\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x46 (0x7fedc6342656 in /data/libtorch/libtorch_nightly_cu92/libtorch/lib/libc10.so)\r\nframe #1: <unknown function> + 0xc6c2 (0x7fed7bad26c2 in /data/libtorch/libtorch_nightly_cu92/libtorch/lib/libc10_cuda.so)\r\nframe #2: torch::autograd::Engine::set_device(int) + 0x159 (0x7fedb9c36b39 in /data/libtorch/libtorch_nightly_cu92/libtorch/lib/libtorch_cpu.so)\r\nframe #3: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x34 (0x7fedb9c39064 in /data/libtorch/libtorch_nightly_cu92/libtorch/lib/libtorch_cpu.so)\r\nframe #4: <unknown function> + 0xc70f (0x7fedc657b70f in /data/libtorch/libtorch_nightly_cu92/libtorch/lib/libtorch.so)\r\nframe #5: <unknown function> + 0x76ba (0x7fed7c3756ba in /lib/x86_64-linux-gnu/libpthread.so.0)\r\nframe #6: clone + 0x6d (0x7fed7c8bc41d in /lib/x86_64-linux-gnu/libc.so.6)\r\nAborted (core dumped)\r\n```\r\nBetter backtrace:\r\n```\r\nThread 4 \"example-app\" hit Catchpoint 1 (exception thrown), 0x00007fffccab38bd in __cxa_throw () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6\r\n(gdb) bt\r\n#0  0x00007fffccab38bd in __cxa_throw () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6\r\n#1  0x00007fffc4d14ab9 in c10::cuda::impl::CUDAGuardImpl::getDevice (this=0x997920) at ../c10/cuda/impl/CUDAGuardImpl.h:37\r\n#2  0x00007fffc4d14ed6 in c10::cuda::impl::CUDAGuardImpl::setDevice (this=0x997920, d=...) at ../c10/cuda/impl/CUDAGuardImpl.h:51\r\n#3  0x00007ffff0f101db in torch::autograd::Engine::set_device (this=0x7ffff7b16bc0 <torch::autograd::Engine::get_base_engine()::engine>, device=1) at ../torch/csrc/autograd/engine.cpp:264\r\n#4  0x00007ffff0f1034d in torch::autograd::Engine::thread_init (this=0x7ffff7b16bc0 <torch::autograd::Engine::get_base_engine()::engine>, device=1, ready_queue=std::shared_ptr (count 2, weak 0) 0x1b33aa0)\r\n    at ../torch/csrc/autograd/engine.cpp:293\r\n#5  0x00007ffff0f3613e in std::_Mem_fn_base<void (torch::autograd::Engine::*)(int, std::shared_ptr<torch::autograd::ReadyQueue> const&), true>::operator()<int, std::shared_ptr<torch::autograd::ReadyQueue>, void>(torch::autograd::Engine*, int&&, std::shared_ptr<torch::autograd::ReadyQueue>&&) const (this=0x1b340d8, __object=0x7ffff7b16bc0 <torch::autograd::Engine::get_base_engine()::engine>) at /usr/include/c++/5/functional:600\r\n#6  0x00007ffff0f360a1 in std::_Bind_simple<std::_Mem_fn<void (torch::autograd::Engine::*)(int, std::shared_ptr<torch::autograd::ReadyQueue> const&)> (torch::autograd::Engine*, int, std::shared_ptr<torch::autograd::ReadyQueue>)>::_M_invoke<0ul, 1ul, 2ul>(std::_Index_tuple<0ul, 1ul, 2ul>) (this=0x1b340b8) at /usr/include/c++/5/functional:1531\r\n#7  0x00007ffff0f35cb8 in std::_Bind_simple<std::_Mem_fn<void (torch::autograd::Engine::*)(int, std::shared_ptr<torch::autograd::ReadyQueue> const&)> (torch::autograd::Engine*, int, std::shared_ptr<torch::autograd::ReadyQueue>)>::operator()() (this=0x1b340b8) at /usr/include/c++/5/functional:1520\r\n#8  0x00007ffff0f35ac8 in std::thread::_Impl<std::_Bind_simple<std::_Mem_fn<void (torch::autograd::Engine::*)(int, std::shared_ptr<torch::autograd::ReadyQueue> const&)> (torch::autograd::Engine*, int, std::shared_ptr<torch::autograd::ReadyQueue>)> >::_M_run() (this=0x1b340a0) at /usr/include/c++/5/thread:115\r\n#9  0x00007fffccadec80 in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6\r\n#10 0x00007fffcbafa6ba in start_thread (arg=0x7fff9cd8d700) at pthread_create.c:333\r\n#11 0x00007fffcc24441d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109\r\n```\r\nUpdate: I noticed that if we initialize a cuda tensor (e.g. `auto cuda_tensor = torch::randn({3, 4}, torch::kCUDA); std::cout << cuda_tensor << std::endl;`) before running the C++ custom autograd function, the whole thing would pass and there is no error.\r\n\r\n## Expected behavior\r\n\r\nIt should just work without throwing any error.\r\n\r\n## Environment\r\n\r\nLatest libtorch nightly\r\n\r\ncc @ezyang @SsnL @albanD @zou3519 @gqchen @yf225"},{"labels":["api",null],"text":"I've tried to run mnist train example (https://github.com/pytorch/examples/tree/master/cpp/mnist)\r\nCode crushes on train_dataset creation whith message \"Unhandled exception at 0x00007FFE7B879179 in MNIST.exe: Microsoft C++ exception: c10::Error at memory location 0x00000068D2EFF4B0. occurred\".\r\n[auto train_dataset = torch::data::datasets::MNIST(kDataRoot)\r\n        .map(torch::data::transforms::Normalize<>(0.1307, 0.3081))\r\n        .map(torch::data::transforms::Stack<>());]\r\nEnvironment:\r\nWin10, VS 2019, Release, CPU.\r\n\r\nI'm not sure if mnist-data prpared correctly. Just put them to ./data catalog\r\n26.03.2020  12:10         1 648 877 t10k-images-idx3-ubyte.gz\r\n26.01.1998  18:07         7 840 016 t10k-images.idx3-ubyte\r\n26.03.2020  12:10             4 542 t10k-labels-idx1-ubyte.gz\r\n26.01.1998  18:07            10 008 t10k-labels.idx1-ubyte\r\n26.03.2020  12:09         9 912 422 train-images-idx3-ubyte.gz\r\n18.11.1996  18:36        47 040 016 train-images.idx3-ubyte\r\n26.03.2020  12:09            28 881 train-labels-idx1-ubyte.gz\r\n18.11.1996  18:36            60 008 train-labels.idx1-ubyte\r\n\r\nWhat is wrong?\n\ncc @yf225"},{"labels":["api",null],"text":"##  Bug\r\n\r\nSince this commit : https://github.com/pytorch/pytorch/commit/76035f050b215d0606fe786901dcd07b5c9544fe#diff-b8c53e7a2010d3dae3200c9911950551\r\nIt's no longer possible to directly access the options variable of Adam in libtorch, making it impossible to change the learning rate on the fly with libtorch.\r\nHow can I change the learning rate ?\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Install the latest nightly of libtorch\r\n2. Create an Adam optimizer\r\n3. Try to access its .options variable to change the learning rate : options does not exist anymore\r\n\n\ncc @yf225"},{"labels":["api",null],"text":"I use ConvTranspose2d in a Sequential, and forward called with one parameter, it invoke above issue. I think it is a bug of libtorch,  ConvTranspose2d need another forward overload function with one parameter.\r\n\n\ncc @yf225"},{"labels":["api",null,null],"text":"When compiling custom-dataset example receive errors:\r\n1) no instance of constructor \"torch::nn::Functional::Functional\" matches the argument list\tCustomDataSet\t...\\CustomDataSet\\CTorch.cpp\t125\t\r\n2) cannot determine which instance of overloaded function \"torch::log_softmax\" is intended\tCustomDataSet\t...\\CustomDataSet\\CTorch.cpp\t125\t\r\n line 125 is: push_back(Functional(torch::log_softmax, 1, torch::nullopt));\r\n\r\nCould anybody help with this?\n\ncc @yf225 @peterjc123"},{"labels":["api",null,null],"text":"##  Bug\r\nresult in memory leak when use libtorch. but i think that it is very strange. because i only define `torch::DeiviceType`  , then got **bug1**\r\n### bug1\r\n```\r\nstill reachable: 884,654 bytes in 13,927 blocks of which reachable via heuristic: stdstring :436062 bytes in 5832 blocks\r\n```\r\n\r\n### bug2\r\n```\r\npossibly lost: 3104 bytes in 22 blocks\r\nstill reachable: 1231592 bytes in 14005 blocks of which reachable via heuristic: stdstring :436062 bytes in 5832 blocks\r\n```\r\n## To Reproduce\r\n### bug1\r\n```c++\r\nint main()\r\n{\r\n torch::DeviceType device_type;\r\n}\r\n```\r\n### bug2\r\n```c++\r\nint main()\r\n{\r\n torch::DeviceType device_type;\r\nif(torch::cuda::is_available())\r\n{\r\ndevice_type = torch::kCUDA;\r\n}\r\nelse\r\n{\r\ndevice_type = torch::kCPU;\r\n}\r\ntorch::Device device(device_type)\r\n}\r\n```\r\n\r\n\r\n## Environment\r\n\r\n - PyTorch Version : 1.4\r\n- libtorch Version: 1.4\r\n - OS (e.g., Linux): Ubuntu 16.04\r\n - How you installed PyTorch (`conda`, `pip`, source): pip\r\n - Python version: 3.5\r\n - CUDA/cuDNN version: 10\r\n\r\n\r\n## update\r\n- the memory leak caused by the `valgrind` tool, not bug for libtorch.\r\n- `cuda-memcheck` is need for detect memory leak instead of `valgrind`\r\n\r\nBut `cuda-memcheck` report this error below:\r\n```shell\r\nProgram hit cudaErrorCudartUnloading (error 4) due to \"driver shutting down\" on CUDA API call to cudaEventDestroy.\r\n=========     Saved host backtrace up to driver entry point at error\r\n=========     Host Frame:/usr/local/nvidia/lib64/libcuda.so.1 [0x377f93]\r\n=========     Host Frame:/xxx/xxx/software/libtorch/lib/libcudart-1b201d85.so.10.1 (cudaEventDestroy + 0x18e) [0x49c8e]\r\n=========     Host Frame:/xxx/xxx/software/libtorch/lib/libtorch.so (_ZN19cublasFixedSizePool8tearDownEv + 0xe4) [0x10a4ac34]\r\n=========     Host Frame:/xxx/xxx/software/libtorch/lib/libtorch.so (_ZN36cublasFixedSizePoolWithGraphSuppport8tearDownEv + 0x16) [0x1083f666]\r\n=========     Host Frame:/xxx/xxx/software/libtorch/lib/libtorch.so (cublasDestroy_v2 + 0xd0) [0xebccfd0]\r\n=========     Host Frame:/xxx/xxx/software/libtorch/lib/libtorch.so (cudnnDestroy + 0x219) [0xf473e99]\r\n=========     Host Frame:/xxx/xxx/software/libtorch/lib/libtorch.so [0x46cc655]\r\n=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__cxa_finalize + 0x9a) [0x3a36a]\r\n=========     Host Frame:/xxx/xxx/software/libtorch/lib/libtorch.so [0x18ab893]\r\n```\r\n\r\n\r\ncc @yf225"},{"labels":["api",null],"text":"##  Bug\r\n\r\nI intend to use libtorch in a plugin project for the VFX compositing software Nuke (https://www.foundry.com/products/nuke). When I include torch using the standard line:\r\n#include <torch/torch.h>\r\nI'm getting a class name ambiguity with the class \"Node\" in Nuke's API. This shouldn't really happen since everything is properly namespaces. I've traced the problem down to these sources in torch: \r\ntorch/csrc/autograd/VariableTypeUtils.h\r\ntorch/csrc/api/include/torch/nn/modules/_functions.h\r\n\r\nThis makes torch::autograd::Node to appear in the root namespace and clashes with a Node from Nuke that is also declared in the root namespace.\r\n\r\nSince Nuke is a commercial product it's hard to make any changes there, so I hope that somebody can correct these sources so they internally just specify the whole namespace to the functions internally so that the \"using namespace\" lines can be removed.\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behaviour:\r\n\r\n1. Start a clean C++ project and write this code snippet:\r\n```\r\n#include <torch/torch.h>\r\nstruct Node{};\r\nvoid bogus(Node *node){}\r\n```\r\n2. struct Node{}; in this case is coming from a third party library that you haven't got control over.\r\n3. Compile, and you will get an ambiguity error\r\n\r\nAlternatively, if you got Nuke available on your system:\r\n\r\n1. Copy one of the example plugins from Nuke\r\n2. Include torch using the standard line \"#include <torch/torch.h>\"\r\n3. Compile, and you will get the following error output:\r\n\r\nScanning dependencies of target ilp_MLTest\r\n[ 72%] Built target py\r\n[ 81%] Built target extension_files\r\n[ 90%] Building CXX object plugins/ilp_MLTest/CMakeFiles/ilp_MLTest.dir/ilp_MLTest.cpp.o\r\n/users/dawa/dev/nuke_ml/plugins/ilp_MLTest/ilp_MLTest.cpp:35:17: error: expected ‘)’ before ‘*’ token\r\n  ilp_MLTest(Node* node) : DD::Image::Iop(node)\r\n                 ^\r\n/users/dawa/dev/nuke_ml/plugins/ilp_MLTest/ilp_MLTest.cpp:63:26: error: reference to ‘Node’ is ambiguous\r\n static Iop* ilp_MLTest_c(Node* node) { return new ilp_MLTest(node); }\r\n                          ^~~~\r\nIn file included from /ice/rez/packages/native/nuke/11.3.6/platform-linux/include/DDImage/Op.h:13:0,\r\n                 from /users/dawa/dev/nuke_ml/plugins/ilp_MLTest/ilp_MLTest.cpp:8:\r\n/ice/rez/packages/native/nuke/11.3.6/platform-linux/include/DDImage/Description.h:15:7: note: candidates are: class Node\r\n class Node;\r\n       ^~~~\r\nIn file included from /ice/rez/packages/native/libtorch/1.4.0/platform-linux/include/torch/csrc/autograd/custom_function.h:3:0,\r\n                 from /ice/rez/packages/native/libtorch/1.4.0/platform-linux/include/torch/csrc/api/include/torch/nn/modules/_functions.h:3,\r\n                 from /ice/rez/packages/native/libtorch/1.4.0/platform-linux/include/torch/csrc/api/include/torch/nn/modules/normalization.h:4,\r\n                 from /ice/rez/packages/native/libtorch/1.4.0/platform-linux/include/torch/csrc/api/include/torch/nn/modules.h:26,\r\n                 from /ice/rez/packages/native/libtorch/1.4.0/platform-linux/include/torch/csrc/api/include/torch/nn.h:7,\r\n                 from /ice/rez/packages/native/libtorch/1.4.0/platform-linux/include/torch/csrc/api/include/torch/all.h:7,\r\n                 from /ice/rez/packages/native/libtorch/1.4.0/platform-linux/include/torch/csrc/api/include/torch/torch.h:3,\r\n                 from /users/dawa/dev/nuke_ml/plugins/ilp_MLTest/ilp_MLTest.cpp:19:\r\n/ice/rez/packages/native/libtorch/1.4.0/platform-linux/include/torch/csrc/autograd/function.h:88:18: note:                 struct torch::autograd::Node\r\n struct TORCH_API Node : std::enable_shared_from_this<Node> {\r\n                  ^~~~\r\n/users/dawa/dev/nuke_ml/plugins/ilp_MLTest/ilp_MLTest.cpp:63:32: error: ‘node’ was not declared in this scope\r\n static Iop* ilp_MLTest_c(Node* node) { return new ilp_MLTest(node); }\r\n                                ^~~~\r\n/users/dawa/dev/nuke_ml/plugins/ilp_MLTest/ilp_MLTest.cpp:63:32: note: suggested alternative: ‘Node’\r\n static Iop* ilp_MLTest_c(Node* node) { return new ilp_MLTest(node); }\r\n                                ^~~~\r\n                                Node\r\n/users/dawa/dev/nuke_ml/plugins/ilp_MLTest/ilp_MLTest.cpp:68:78: error: no matching function for call to ‘DD::Image::Op::Description::Description(const char* const&, const char [18], DD::Image::Iop*&)’\r\n const Iop::Description ilp_MLTest::d(CLASS, \"Filter/ilp_MLTest\", ilp_MLTest_c);\r\n                                                                              ^\r\nIn file included from /users/dawa/dev/nuke_ml/plugins/ilp_MLTest/ilp_MLTest.cpp:8:0:\r\n/ice/rez/packages/native/nuke/11.3.6/platform-linux/include/DDImage/Op.h:1952:9: note: candidate: DD::Image::Op::Description::Description(const char*, const char*, DD::Image::Op::Description::IopConstructor)\r\n         Description(const char* n, const char* /*menu*/, IopConstructor c) :\r\n         ^~~~~~~~~~~\r\n/ice/rez/packages/native/nuke/11.3.6/platform-linux/include/DDImage/Op.h:1952:9: note:   no known conversion for argument 3 from ‘DD::Image::Iop*’ to ‘DD::Image::Op::Description::IopConstructor {aka DD::Image::Iop* (*)(Node*)}’\r\n/ice/rez/packages/native/nuke/11.3.6/platform-linux/include/DDImage/Op.h:1942:9: note: candidate: DD::Image::Op::Description::Description(const char*, const char*, DD::Image::Op::Description::OpConstructor)\r\n         Description(const char* n, const char* /*menu*/, OpConstructor c) :\r\n         ^~~~~~~~~~~\r\n/ice/rez/packages/native/nuke/11.3.6/platform-linux/include/DDImage/Op.h:1942:9: note:   no known conversion for argument 3 from ‘DD::Image::Iop*’ to ‘DD::Image::Op::Description::OpConstructor {aka DD::Image::Op* (*)(Node*)}’\r\n/ice/rez/packages/native/nuke/11.3.6/platform-linux/include/DDImage/Op.h:1932:9: note: candidate: DD::Image::Op::Description::Description(const char*, DD::Image::Op::Description::OpConstructor, DD::Image::Description::NodeBuilder)\r\n         Description(const char* n, OpConstructor c, NodeBuilder nodeBuilder) :\r\n         ^~~~~~~~~~~\r\n/ice/rez/packages/native/nuke/11.3.6/platform-linux/include/DDImage/Op.h:1932:9: note:   no known conversion for argument 2 from ‘const char [18]’ to ‘DD::Image::Op::Description::OpConstructor {aka DD::Image::Op* (*)(Node*)}’\r\n/ice/rez/packages/native/nuke/11.3.6/platform-linux/include/DDImage/Op.h:1925:9: note: candidate: DD::Image::Op::Description::Description(const char*, DD::Image::Op::Description::OpConstructor, DD::Image::License*)\r\n         Description(const char* n, OpConstructor c, License * l = 0) :\r\n         ^~~~~~~~~~~\r\n/ice/rez/packages/native/nuke/11.3.6/platform-linux/include/DDImage/Op.h:1925:9: note:   no known conversion for argument 2 from ‘const char [18]’ to ‘DD::Image::Op::Description::OpConstructor {aka DD::Image::Op* (*)(Node*)}’\r\n/ice/rez/packages/native/nuke/11.3.6/platform-linux/include/DDImage/Op.h:1897:25: note: candidate: constexpr DD::Image::Op::Description::Description(const DD::Image::Op::Description&)\r\n       class DDImage_API Description : public DD::Image::Description\r\n                         ^~~~~~~~~~~\r\n/ice/rez/packages/native/nuke/11.3.6/platform-linux/include/DDImage/Op.h:1897:25: note:   candidate expects 1 argument, 3 provided\r\n/ice/rez/packages/native/nuke/11.3.6/platform-linux/include/DDImage/Op.h:1897:25: note: candidate: constexpr DD::Image::Op::Description::Description(DD::Image::Op::Description&&)\r\n/ice/rez/packages/native/nuke/11.3.6/platform-linux/include/DDImage/Op.h:1897:25: note:   candidate expects 1 argument, 3 provided\r\nmake[2]: *** [plugins/ilp_MLTest/CMakeFiles/ilp_MLTest.dir/build.make:63: plugins/ilp_MLTest/CMakeFiles/ilp_MLTest.dir/ilp_MLTest.cpp.o] Error 1\r\nmake[1]: *** [CMakeFiles/Makefile2:170: plugins/ilp_MLTest/CMakeFiles/ilp_MLTest.dir/all] Error 2\r\nmake: *** [Makefile:130: all] Error 2\r\n11:59:52 ERROR    BuildError: The cmake build system failed.\r\n\r\n\r\n## Expected behavior\r\n\r\nThat the plugin compiles just as normal, with no build errors from including the torch headers.\r\n\r\n## Environment\r\n\r\nPyTorch 1.4.0\r\nOS: CentOS Linux release 7.6.1810 (Core) \r\nGCC version: (GCC) 4.8.5 20150623 (Red Hat 4.8.5-36)\r\nCMake version: version 2.8.12.2\r\n\n\ncc @yf225"},{"labels":["api"],"text":"##  Bug\r\n\r\nI want to make my `current_state`, which is made of `std::vector<double>` to a `torch::Tensor`.\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1: Have a dobule vector, i.e `0.0642382 0.0395936 0 0.219108 0.372894 0.422909 0.554452 0.302765 1`\r\n2: `torch::Tensor current_state = torch::from_blob(current_state.data(), { 9}).to(*device);`\r\n3: std::cout << \"next state is: \\n\" << next_state << std::endl;\r\n\r\nobserve the output: \r\n```\r\nnext state is: \r\n-1.7024e+35\r\n1.3785e+00\r\n-6.2066e+14\r\n1.2834e+00\r\n0.0000e+00\r\n0.0000e+00\r\n-1.0163e+17\r\n1.5941e+00\r\nnan\r\n```\r\n\r\n## Expected behavior\r\n\r\nTo get a tensor with the same values as my vector...\r\n\r\n## Environment\r\n\r\n - PyTorch Version (e.g., 1.0): Libtorch 1.4\r\n - OS (e.g., Linux): Windows 7 64 bit\r\n - How you installed PyTorch (`conda`, `pip`, source): pip\r\n - Build command you used (if compiling from source): `cmake --build . --config Release --target INSTALL`\r\n - Python version: 3.6\r\n - CUDA/cuDNN version: NA\r\n - GPU models and configuration: NA\r\n - Any other relevant information: NA\r\n\r\n## Additional context\r\nThe following line gives me a tensor that looks like I want, however it crashes when I try to feed it through the network...\r\n\r\n`torch::Tensor test_next_state = torch::tensor(current_state);`\r\n\n\ncc @yf225"},{"labels":["api",null,null],"text":"##  Bug\r\n`torch::nn::Linear` without bias throws an error when `to` is called. \r\n\r\n## To Reproduce\r\n```c++\r\n#include<torch/torch.h>\r\nint main(int argc, char* argv[])\r\n{\r\n  torch::Tensor x = torch::ones({100, 4});\r\n  auto lopt       = torch::nn::LinearOptions(4, 4).bias(false);\r\n  auto lin        = torch::nn::Linear(lopt);\r\n  // works\r\n  auto y          = lin->forward(x);\r\n  // error\r\n  lin->to(torch::kFloat64);\r\n  x = torch::ones({100, 4}, torch::kFloat64);\r\n  y = lin->forward(x);\r\n}\r\n```\r\nThis is the output, but this MWE is only executed as a test in a larger project\r\nso the output might differ.\r\n```\r\n terminate called after throwing an instance of 'c10::Error'\r\n  what():  tensor does not have a device (device at /home/nls/gasnew/pytorch/torch/include/c10/core/TensorImpl.h:461)\r\nframe #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x6a (0x7ffff220035a in /home/nls/gasnew/pytorch/torch/lib/libc10.so)\r\nframe #1: c10::TensorImpl::device() const + 0xf8 (0x7ffff7f0e288 in /home/nls/gasnew/gasPyTorch/build/gt/src/libgt.so)\r\nframe #2: at::Tensor::device() const + 0x20 (0x7ffff7f117d4 in /home/nls/gasnew/gasPyTorch/build/gt/src/libgt.so)\r\nframe #3: at::Tensor::options() const + 0x71 (0x7ffff7f5fb41 in /home/nls/gasnew/gasPyTorch/build/gt/src/libgt.so)\r\nframe #4: at::native::to(at::Tensor const&, c10::ScalarType, bool, bool, c10::optional<c10::MemoryFormat>) + 0x6c (0x7ffff368fabc in /home/nls/gasnew/pytorch/torch/lib/libtorch.so)\r\nframe #5: <unknown function> + 0x1714a6b (0x7ffff392aa6b in /home/nls/gasnew/pytorch/torch/lib/libtorch.so)\r\nframe #6: <unknown function> + 0x32572d0 (0x7ffff546d2d0 in /home/nls/gasnew/pytorch/torch/lib/libtorch.so)\r\nframe #7: <unknown function> + 0x173c003 (0x7ffff3952003 in /home/nls/gasnew/pytorch/torch/lib/libtorch.so)\r\nframe #8: at::Tensor c10::KernelFunction::callUnboxedOnly<at::Tensor, at::Tensor const&, c10::ScalarType, bool, bool, c10::optional<c10::MemoryFormat> >(at::Tensor const&, c10::ScalarType, bool, bool, c10::optional<c10::MemoryFormat>) const + 0x141 (0x55555559bfd3 in /home/nls/gasnew/gasPyTorch/build/test/testgt)\r\nframe #9: at::Tensor c10::Dispatcher::callUnboxedOnly<at::Tensor, at::Tensor const&, c10::ScalarType, bool, bool, c10::optional<c10::MemoryFormat> >(c10::OperatorHandle const&, at::Tensor const&, c10::ScalarType, bool, bool, c10::optional<c10::MemoryFormat>) const + 0x16f (0x5555555968c9 in /home/nls/gasnew/gasPyTorch/build/test/testgt)\r\nframe #10: at::Tensor::to(c10::ScalarType, bool, bool, c10::optional<c10::MemoryFormat>) const + 0x1de (0x55555558f6dc in /home/nls/gasnew/gasPyTorch/build/test/testgt)\r\nframe #11: void torch::nn::Module::to_impl<c10::ScalarType&, bool&>(c10::ScalarType&, bool&) + 0x149 (0x7ffff59d5f19 in /home/nls/gasnew/pytorch/torch/lib/libtorch.so)\r\nframe #12: torch::nn::Module::to(c10::ScalarType, bool) + 0x1c (0x7ffff59d2bac in /home/nls/gasnew/pytorch/torch/lib/libtorch.so)\r\n```\r\n## Environment\r\n\r\n - PyTorch Version: 1.4 from source\r\n - OS: Linux\n\ncc @yf225"},{"labels":[null,null,null,"api",null],"text":"##  Bug\r\n\r\nThe library size of torch is very large (~267MB without CUDA, 1.2 GB with CUDA).\r\nThis can be caused by using a library like Intel IPP similar to this opencv bug.\r\nhttps://github.com/opencv/opencv/issues/15177\r\nThis limits the use of pytorch models in small environments (without CUDA).\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n1. Download the libtorch C++ library\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## Expected behavior\r\n\r\nLibrary size without CUDA should be a lot less than that. or at least providing libtorch_tiny or ways to create it.\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n## Environment\r\n - PyTorch Version: 1.4\r\n - OS: Linux\r\n\n\ncc @ezyang @gchanan @zou3519 @seemethere @yf225"},{"labels":["api",null,null],"text":"##  Can't save to ostream\r\n\r\nI want to save my model as a `istream` for later processing.\r\nI found the following on the api:\r\n\r\nhttps://pytorch.org/cppdocs/api/function_namespacetorch_1a99dc9f736064b2179cc58e6436f7a021.html#exhale-function-namespacetorch-1a99dc9f736064b2179cc58e6436f7a021\r\n\r\nhttps://pytorch.org/cppdocs/api/function_namespacetorch_1a4b369494adfb10b9a005aeb0bb6207cb.html#exhale-function-namespacetorch-1a4b369494adfb10b9a005aeb0bb6207cb\r\n\r\n## To Reproduce\r\n`torch::optim::SGD sgd(0.9);` give me error: \r\n\r\n>Error (active)\tE0289\tno instance of constructor \"torch::optim::SGD::SGD\" matches the argument list\r\n\r\n## Environment\r\n\r\n - PyTorch Version (e.g., 1.0): LibTorch 1.4\r\n - OS (e.g., Linux): Windows 7 64 bit\r\n - How you installed PyTorch (`conda`, `pip`, source): source: https://download.pytorch.org/libtorch/cpu/libtorch-win-shared-with-deps-1.4.0.zip\r\n - Build command you used (if compiling from source): cmake --build . --config Release --target INSTALL\r\n - Python version: 3.6\r\n - CUDA/cuDNN version: NA\r\n - GPU models and configuration: NA\r\n - Any other relevant information: NA\r\n\r\n\n\ncc @yf225"},{"labels":["api",null,null],"text":"##  Bug\r\n\r\nModels saved in C++ LibTorch with torch::save, cannot be loaded in python using torch.load. When I save a custom model (a class which inherits from torch::nn::Module) using torch::save(model, filepath), the result is a zip archive (.pt). The archive has the same structure as [it should](https://github.com/pytorch/pytorch/blob/master/torch/csrc/jit/docs/serialization.md) but python comes up with the error \r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Save a class which inherits from the torch::nn::Module class in C++ using torch::save\r\n2. Try to load that saved archive in python using torch.load\r\n3. Find this error below: \r\n\r\n`Traceback (most recent call last):\r\n  File \"torch_plotting.py\", line 59, in <module>\r\n    policy_model, value_model = load_models(containing_path, model_number)\r\n  File \"torch_plotting.py\", line 37, in load_models\r\n    policy_model = torch.load(policy_file)\r\n  File \"/home/jamie/anaconda3/envs/tensorflow/lib/python3.7/site-packages/torch/serialization.py\", line 528, in load\r\n    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)\r\n  File \"/home/jamie/anaconda3/envs/tensorflow/lib/python3.7/site-packages/torch/serialization.py\", line 782, in _load\r\n    result = unpickler.load()\r\nModuleNotFoundError: No module named '__torch__'`\r\n\r\n## Expected behavior\r\n\r\nExpect to have a fully loaded model that behaves the same way as the c++ one which I can use to perform inference.\r\n\r\n## Environment\r\n\r\nPyTorch version: 1.4.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.1\r\n\r\nOS: Ubuntu 19.10\r\nGCC version: (Ubuntu 9.2.1-9ubuntu2) 9.2.1 20191008\r\nCMake version: version 3.16.4\r\n\r\nPython version: 3.7\r\nIs CUDA available: Yes\r\nCUDA runtime version: Could not collect\r\nGPU models and configuration: GPU 0: GeForce GTX 1050 Ti\r\nNvidia driver version: 440.33.01\r\ncuDNN version: Probably one of the following:\r\n/usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5\r\n/usr/local/cuda-10.2/targets/x86_64-linux/lib/libcudnn.so.7.6.5\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.17.2\r\n[pip3] numpydoc==0.9.1\r\n[pip3] torch==1.4.0\r\n[pip3] torchvision==0.5.0\r\n[conda] blas                      1.0                         mkl  \r\n[conda] mkl                       2019.4                      243  \r\n[conda] mkl-service               2.3.0            py37he904b0f_0  \r\n[conda] mkl_fft                   1.0.14           py37ha843d7b_0  \r\n[conda] mkl_random                1.1.0            py37hd6b4f25_0  \r\n[conda] torch                     1.4.0                    pypi_0    pypi\r\n[conda] torchvision               0.5.0                    pypi_0    pypi\r\n\r\n## Additional context\r\n\r\nI am using the libtorch provided by [this link](https://download.pytorch.org/libtorch/cpu/libtorch-shared-with-deps-1.4.0%2Bcpu.zip) and using cmake to build my project. The file to open is \r\n[policy_9999.zip](https://github.com/pytorch/pytorch/files/4255490/policy_9999.zip) (renamed to policy_9999.zip instead of the original policy_9999.pt so it could be uploaded.)\r\n\r\n\r\n\n\ncc @yf225 @glaringlee @SsnL"},{"labels":["api",null,null],"text":"##  Bug\r\n\r\nUsing `torch::var_out` in the C++ API with dimnames instead of the index of the dimension seems to return the standard deviation instead of the variance.\r\n\r\n## To Reproduce\r\n\r\nRunning the following program:\r\n\r\n```\r\n#include <torch/torch.h>\r\n#include <iostream>\r\n\r\nint main() {\r\n    auto d = torch::Dimname::fromSymbol(torch::Symbol::dimname(\"a\"));\r\n    std::vector<torch::Dimname> ds;\r\n    ds.push_back(d);\r\n    \r\n    auto x = torch::rand(100, ds);\r\n    \r\n    auto y = torch::zeros(1);\r\n    torch::var_out(y, x, {0});\r\n    std::cout << y << std::endl;\r\n    \r\n    auto z = torch::zeros(1);\r\n    torch::var_out(z, x, ds);\r\n    std::cout << z << std::endl;\r\n}\r\n```\r\n\r\nReturns: \r\n\r\n```\r\n(base) dfalbel@Daniels-MacBook-Pro build % ./example-app\r\nWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (operator() at ../c10/core/TensorImpl.h:845)\r\n0.073097\r\n[ CPUFloatType{} ]\r\n0.270365\r\n[ CPUFloatType{} ]\r\n```\r\n\r\nSince:\r\n\r\n```\r\nsqrt(0.073097)\r\n[1] 0.2703646\r\n```\r\n\r\nIt seems that when using dimnames `torch_var_out` is returning the standard deviation.\r\n\r\n## Expected behavior\r\n\r\nExpected both values to be identical.\r\n\r\n## Environment\r\n\r\nI am using Pytorch C++ 1.4 - downloaded from here: https://download.pytorch.org/libtorch/cpu/libtorch-macos-1.4.0.zip on MacOS\r\n\n\ncc @yf225 @zou3519"},{"labels":["api",null,null],"text":"in https://github.com/pytorch/pytorch/pull/33189 we switch RREf to be managed by intrusive_ptr, and we made the UserRRef/OwnerRRef public to make `c10::make_intrusive<OwnerRRef>(getWorkerId(), rrefId, type)` work since it does not support private constructor, and `intrusive_ptr<OwnerRRef>(new OwnerRRef())` does not work because of intrusive_ptr limitation. \r\n\r\nWe should figure out a way to make it private again before we announce C++ API for rpc.\n\ncc @yf225 @pietern @mrshenli @pritamdamania87 @zhaojuanmao @satgera @gqchen @aazzolini @rohan-varma @xush6528 @jjlilley @osalpekar"},{"labels":["api",null],"text":"##  Bug\r\n\r\nThe fractional max pooling options for output ratio need to be an expanding array of doubles.\r\ncurrently:\r\n\r\n```\r\ntemplate <size_t D>\r\nstruct FractionalMaxPoolOptions {\r\n  FractionalMaxPoolOptions(ExpandingArray<D> kernel_size)\r\n      : kernel_size_(kernel_size) {}\r\n\r\n  /// the size of the window to take a max over\r\n  TORCH_ARG(ExpandingArray<D>, kernel_size);\r\n\r\n  /// the target output size of the image\r\n  TORCH_ARG(c10::optional<ExpandingArray<D>>, output_size) = c10::nullopt;\r\n\r\n  /// If one wants to have an output size as a ratio of the input size, this option can be given.\r\n  /// This has to be a number or tuple in the range (0, 1)\r\n  TORCH_ARG(c10::optional<ExpandingArray<D>>, output_ratio) = c10::nullopt;\r\n```\r\n\r\nlater, in nn/functional/pooling.h, if no output sizes, output ratios are used:\r\n```\r\n  if (output_size_ == c10::nullopt) {\r\n    TORCH_INTERNAL_ASSERT(output_ratio != c10::nullopt);\r\n    output_size_ = {(int64_t)(input.sizes()[2] * (*output_ratio.value())[0]),\r\n                    (int64_t)(input.sizes()[3] * (*output_ratio.value())[1]),\r\n                    (int64_t)(input.sizes()[4] * (*output_ratio.value())[2])};\r\n  }\r\n```\r\n\r\nthe code compiles with integers, but won't allow for output ratios of 0.5, for example\r\n\r\n\r\n\n\ncc @yf225"},{"labels":[null,"api",null,null],"text":"## Issue description\r\n\r\nI have downloaded the LibTorch zip from [here](https://pytorch.org/get-started/locally/). I used the 1.4 stable build for windows with CUDA 10.1 support. However the torch folder within the include directory does not contain the \"torch.h\" header file used in many [examples](https://pytorch.org/cppdocs/installing.html#minimal-example). This error comes up when I use the line:\r\n`\r\n#include <Torch/torch.h>\r\n`\r\nThe error simply says \"cannot open torch.h\".\r\n\r\nI am using Microsoft Visual Studio 2019 and I have already added the additional include and library directories. The only \"torch.h\" file I can find is at \"....\\include\\torch\\csrc\\api\\include\\torch\\torch.h\" but this does not include all of the other header files I need such as for the torch::nn::Module class etc.\r\n\r\n## System Info\r\n\r\nCollecting environment information...\r\nPyTorch version: N/A\r\nIs debug build: N/A\r\nCUDA used to build PyTorch: N/A\r\n\r\nOS: Microsoft Windows 10 Pro\r\nGCC version: (MinGW.org GCC-6.3.0-1) 6.3.0\r\nCMake version: version 3.15.0-rc2\r\n\r\nPython version: 3.6\r\nIs CUDA available: N/A\r\nCUDA runtime version: 10.0.130\r\nGPU models and configuration: GPU 0: GeForce GTX 1050 Ti\r\nNvidia driver version: 431.36\r\ncuDNN version: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\bin\\cudnn64_7.dll\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.14.3\r\n[pip3] numpydoc==0.8.0\r\n[conda] blas                      1.0                         mkl\r\n[conda] mkl                       2018.0.2                      1\r\n[conda] mkl-service               1.1.2            py36h57e144c_4\r\n[conda] mkl_fft                   1.0.1            py36h452e1ab_0\r\n[conda] mkl_random                1.0.1            py36h9258bd6_0\r\n\n\ncc @ezyang @gchanan @zou3519 @yf225 @peterjc123"},{"labels":[null,"api",null,null],"text":"Currently torch::allclose() fails with\r\n`C++ exception with description \"Subtraction, the `-` operator, with a bool tensor is not supported. If you are trying to invert a mask, use the `~` or `logical_not()` operator instead. (sub_check at ../aten/src/ATen/native/BinaryOps.h:24)`\r\non bool tensors\n\ncc @yf225 @izdeby"},{"labels":["api",null,null,null,null],"text":"##  Bug\r\n\r\nThe `MagmaInitializesCorrectly_CUDA` test case in `test/cpp/api/tensor_cuda.cpp` fails with the following error:\r\n\r\n```\r\n[0;32m[ RUN      ] #[mTensorTest.MagmaInitializesCorrectly_CUDA\r\nunknown file: Failure\r\nC++ exception with description \"inverse_cuda: U(4,4) is zero, singular U. (singleCheckErrors at /home/jenkins/pytorch/aten/src/ATen/native/LinearAlgebraUtils.h:138)\r\nframe #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0xc0 (0x1000135086a0 in /home/jenkins/pytorch/build/lib/libc10.so)\r\nframe #1: <unknown function> + 0x1550eb0 (0x1000058e0eb0 in /home/jenkins/pytorch/build/lib/libtorch_cuda.so)\r\nframe #2: at::native::_inverse_helper_cuda(at::Tensor const&) + 0x9bc (0x1000058e8c1c in /home/jenkins/pytorch/build/lib/libtorch_cuda.so)\r\nframe #3: <unknown function> + 0x3072224 (0x100007402224 in /home/jenkins/pytorch/build/lib/libtorch_cuda.so)\r\nframe #4: <unknown function> + 0xec6f20 (0x100000f46f20 in /home/jenkins/pytorch/build/lib/libtorch_cpu.so)\r\nframe #5: at::native::inverse(at::Tensor const&) + 0x14c (0x1000009f53fc in /home/jenkins/pytorch/build/lib/libtorch_cpu.so)\r\nframe #6: <unknown function> + 0xf9b674 (0x10000101b674 in /home/jenkins/pytorch/build/lib/libtorch_cpu.so)\r\nframe #7: <unknown function> + 0xec6f20 (0x100000f46f20 in /home/jenkins/pytorch/build/lib/libtorch_cpu.so)\r\nframe #8: at::Tensor c10::Dispatcher::callUnboxed<at::Tensor, at::Tensor const&>(c10::OperatorHandle const&, at::Tensor const&) const + 0xd4 (0x10f009ef4 in build/bin/test_api)\r\nframe #9: <unknown function> + 0x2aabffc (0x100002b2bffc in /home/jenkins/pytorch/build/lib/libtorch_cpu.so)\r\nframe #10: <unknown function> + 0xec6f20 (0x100000f46f20 in /home/jenkins/pytorch/build/lib/libtorch_cpu.so)\r\nframe #11: TensorTest_MagmaInitializesCorrectly_CUDA_Test::TestBody() + 0x804 (0x10f398de4 in build/bin/test_api)\r\nframe #12: void testing::internal::HandleExceptionsInMethodIfSupported<testing::Test, void>(testing::Test*, void (testing::Test::*)(), char const*) + 0x78 (0x10f45de48 in build/bin/test_api)\r\nframe #13: <unknown function> + 0x880774 (0x10f450774 in build/bin/test_api)\r\nframe #14: <unknown function> + 0x880cb4 (0x10f450cb4 in build/bin/test_api)\r\nframe #15: <unknown function> + 0x881174 (0x10f451174 in build/bin/test_api)\r\nframe #16: testing::internal::UnitTestImpl::RunAllTests() + 0xeac (0x10f45252c in build/bin/test_api)\r\nframe #17: testing::UnitTest::Run() + 0xb8 (0x10f452938 in build/bin/test_api)\r\nframe #18: main + 0x108 (0x10edc25e8 in build/bin/test_api)\r\nframe #19: <unknown function> + 0x2441c (0x1000139f441c in /lib/powerpc64le-linux-gnu/libc.so.6)\r\nframe #20: __libc_start_main + 0xb8 (0x1000139f4618 in /lib/powerpc64le-linux-gnu/libc.so.6)\r\n\" thrown in the test body.\r\n#[0;31m[  FAILED  ] #[mTensorTest.MagmaInitializesCorrectly_CUDA (288 ms)\r\n```\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Build PyTorch from source, and make sure to build the cpp API tests along with it\r\n2. Run the `tensor_cuda.cpp` tests (probably with `test_api` in the `build/bin` directory)\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## Expected behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\nThe test should pass\r\n\r\n## Environment\r\n\r\nPlease copy and paste the output from our\r\n[environment collection script](https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py)\r\n(or fill out the checklist below manually).\r\n\r\nYou can get the script and run it with:\r\n```\r\nwget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\r\n# For security purposes, please check the contents of collect_env.py before running it.\r\npython collect_env.py\r\n```\r\n\r\n - PyTorch Version (e.g., 1.0): master\r\n - OS (e.g., Linux): RHEL\r\n - How you installed PyTorch (`conda`, `pip`, source): source\r\n - Build command you used (if compiling from source): `python setup.py install`\r\n - Python version: `3.6`\r\n - CUDA/cuDNN version: 10.2\r\n - GPU models and configuration: 4x Tesla V100\r\n - Any other relevant information: Ran on Power architecture\r\n\r\n## Aditional Information\r\n\r\nI've submitted a PR to fix this here: https://github.com/pytorch/pytorch/pull/32547\r\n\n\ncc @yf225 @ngimel"},{"labels":[null,null,null,"api",null],"text":"##  Bug\r\nUse PyTorch model in C++, compilation breaks when using the default route.\r\nCMake `find_package(Torch REQUIRED)` \r\n\r\nreturns corrupted `TORCH_LIBRARIES` list\r\n\r\n```\r\ntorch\r\ntorch_library\r\n/usr/local/lib/python3.6/dist-packages/torch/lib/libc10.so\r\n/usr/local/cuda/lib64/stubs/libcuda.so\r\n/usr/local/cuda/lib64/libnvrtc.so\r\n/usr/local/cuda/lib64/libnvToolsExt.so\r\n/usr/local/cuda/lib64/libcudart.so\r\n/usr/local/lib/python3.6/dist-packages/torch/lib/libc10_cuda.so\r\n```\r\n\r\nIt should not contain absolute paths to the other libraries but rather the lib names.\r\nThe library paths should be added to the environment if necessary\r\n\r\n## Solution\r\n\r\nInstead of \r\n\r\n`target_link_libraries(MyTARGET PUBLIC ${TORCH_LIBRARIES})`\r\n\r\ndo\r\n\r\n```\r\nlink_directories(/usr/local/lib/python3.6/dist-packages/torch/lib/)\r\nlink_directories(/usr/local/cuda/lib64/)\r\nlink_directories(/usr/local/cuda/lib64/stubs)\r\n\r\ntarget_link_libraries(MyTARGET PUBLIC torch torch_library libc10.so libcuda.so libnvrtc.so libnvToolsExt.so libcudart.so libc10_cuda.so)\r\n```\r\n\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Create `CMakeLists.txt`\r\n2.`find_package(Torch REQUIRED)`\r\n3. `message(\"TORCH LIBS ${TORCH_LIBRARIES}\")`\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## Expected behavior\r\n\r\nReturns linker errors as `c10` can not be found\r\n\r\n```\r\n/usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Backend.h:107: undefined reference to `c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'\r\nSunlightNoiseClassifier/libSunlightNoiseClassifier.a(SunlightNoiseClassifier.cpp.o): In function `c10::backendToDeviceType(c10::Backend)':\r\n```\r\n\r\n## Environment\r\n\r\n```\r\ncmake version 3.5.1\r\n\r\npython collect_env.py \r\nCollecting environment information...\r\nPyTorch version: N/A\r\nIs debug build: N/A\r\nCUDA used to build PyTorch: N/A\r\n\r\nOS: Ubuntu 16.04.3 LTS\r\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\nCMake version: version 3.5.1\r\n\r\nPython version: 2.7\r\nIs CUDA available: N/A\r\nCUDA runtime version: 9.2.148\r\nGPU models and configuration: Could not collect\r\nNvidia driver version: Could not collect\r\ncuDNN version: Could not collect\r\n\r\nVersions of relevant libraries:\r\n[pip] msgpack-numpy==0.4.4.2\r\n[pip] numpy==1.16.4\r\n[pip] torch==1.2.0\r\n[pip] torchvision==0.4.0\r\n[conda] Could not collect\r\n```\r\n\n\ncc @ezyang @gchanan @zou3519 @yf225"},{"labels":["api",null],"text":"##  Bug\r\n\r\nCode crashes in C++ API when torch tensor is read from specific buffer\r\n\r\n## To Reproduce\r\n\r\nbuild and run this code in release build\r\n\r\n```c++\r\n#include <iostream>\r\n#include <torch/extension.h>\r\n\r\nint main() {\r\n    std::string buffer;\r\n    buffer.resize((1 << 19) + 128);\r\n    std::memset(buffer.data(), 0, buffer.size());\r\n    size_t start_offset;\r\n    // This would work fine\r\n    start_offset = 1 << 10;\r\n    // This crashes\r\n    start_offset = (1 << 10) - 1;\r\n    size_t element_count = 319;\r\n    std::cerr << buffer.size() << \" vs \" << torch::elementSize(torch::kInt32) * element_count + start_offset;\r\n    auto tensor = torch::from_blob(buffer.data() + start_offset, {element_count}, torch::CPU(torch::kInt32));\r\n    tensor.clone();\r\n}\r\n```\r\n\r\n```cmake\r\ncmake_minimum_required(VERSION 3.12)\r\nproject(from_blob_sigsegv)\r\n\r\n\r\nset(CMAKE_CXX_STANDARD 17)\r\nset(CMAKE_PREFIX_PATH /home/alxmopo3ov/libtorch)\r\n\r\nfind_package(Torch REQUIRED)\r\ninclude_directories(${TORCH_INCLUDE_DIRS})\r\nfind_package(Python3 COMPONENTS Interpreter Development)\r\ninclude_directories(${Python3_INCLUDE_DIRS})\r\n\r\nadd_executable(from_blob_sigsegv main.cpp)\r\ntarget_link_libraries(from_blob_sigsegv ${Python3_LIBRARIES} ${TORCH_LIBRARIES})\r\n```\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## Expected behavior\r\n\r\nDon't crash\r\n\r\n## Environment\r\n\r\nCollecting environment information...\r\nPyTorch version: 1.4.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.1\r\n\r\nOS: Ubuntu 14.04.6 LTS\r\nGCC version: (Ubuntu 7.4.0-1ubuntu1~14.04~ppa1) 7.4.0\r\nCMake version: version 3.12.2\r\n\r\nPython version: 3.7\r\nIs CUDA available: No\r\nCUDA runtime version: No CUDA\r\nGPU models and configuration: No CUDA\r\nNvidia driver version: No CUDA\r\ncuDNN version: No CUDA\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.15.1\r\n[pip3] numpydoc==0.8.0\r\n[pip3] torch==1.4.0\r\n[pip3] torchvision==0.2.1\r\n[conda] blas                      1.0                         mkl  \r\n[conda] mkl                       2019.0                      118  \r\n[conda] mkl-service               1.1.2            py37h90e4bf4_5  \r\n[conda] mkl_fft                   1.0.4            py37h4414c95_1  \r\n[conda] mkl_random                1.0.1            py37h4414c95_1  \r\n[conda] torch                     1.4.0                     <pip>\r\n[conda] torchvision               0.2.1                     <pip>\n\ncc @yf225"},{"labels":["api",null],"text":"##  Bug\r\n\r\nIn Python, we have the following behavior:\r\n```python\r\n>>> torch.set_default_dtype(torch.double)\r\n>>> a = 1.1\r\n>>> t = torch.tensor([a, a])\r\n>>> t.dtype\r\ntorch.float64\r\n```\r\n\r\nHowever, currently in C++, we have the following behavior:\r\n```cpp\r\ntorch::set_default_dtype(torch::scalarTypeToTypeMeta(torch::kDouble));\r\nfloat a = 1.1;\r\ntorch::tensor({a, a}).dtype()  // prints: float\r\n```\r\n\r\nWe should fix the C++ API behavior (by returning a double tensor instead of a float tensor in the above case), to match the Python API.\r\n\r\ncc @yf225"},{"labels":["api",null,null],"text":"##  Bug\r\n\r\nnightly Pytorch cannot compile cpp extension\r\n\r\n## To Reproduce\r\n\r\nExtension [here](https://pytorch.org/tutorials/advanced/cpp_extension.html#writing-a-mixed-c-cuda-extension) defines:\r\n\r\n```c++\r\n#define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n```\r\n\r\nresults in deprecation:\r\n\r\n```text\r\n\r\nwarning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement\r\n\r\n```\r\n\r\nbut there is no `is_cuda` in `options` struct.\r\nThe fix was to call `x.is_cuda()` directly, which is nicer.\r\n\r\n```c++\r\n#define CHECK_CUDA(x) TORCH_CHECK(x.is_cuda(), #x \" must be a CUDA tensor\")\r\n```\r\n\r\n## Expected behavior\r\n\r\nExamples to be tested\r\n\r\n## Environment\r\n\r\nCollecting environment information...\r\nPyTorch version: 1.5.0.dev20200113\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.0\r\n\r\nOS: Ubuntu 16.04.6 LTS\r\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609\r\nCMake version: version 3.14.0\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: Could not collect\r\nGPU models and configuration: GPU 0: GeForce GTX 1070\r\nNvidia driver version: 418.87.01\r\ncuDNN version: /usr/local/lib/libcudnn.so.5.1.10\r\n\r\nVersions of relevant libraries:\r\n[pip] numpy==1.17.4\r\n[pip] torch==1.5.0.dev20200113\r\n[pip] torchvision==0.5.0a0+e50d746\r\n[conda] blas                      1.0                         mkl\r\n[conda] mkl                       2019.4                      243\r\n[conda] mkl-service               2.3.0            py36he904b0f_0\r\n[conda] mkl_fft                   1.0.15           py36ha843d7b_0\r\n[conda] mkl_random                1.1.0            py36hd6b4f25_0\r\n[conda] pytorch                   1.5.0.dev20200113 py3.6_cuda10.0.130_cudnn7.6.3_0    pytorch-nightly\r\n[conda] torchvision               0.5.0.dev20200113      py36_cu100    pytorch-nightly\r\n\r\n\r\n## Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n\n\ncc @yf225"},{"labels":[null,"api",null,null],"text":"A C++ extension calling backward() on a tensor hangs when called from python.\r\n\r\nI've posted this same issue with some back tracing [in the forum](https://discuss.pytorch.org/t/tensor-backward-called-within-c-extension-hangs/65473).\r\n\r\n## To Reproduce\r\nHere is the basic extension, following the tutorial on C++/CUDA extensions. I get the same issue if I install the extension via `load_inline`.\r\n\r\n1. Source `diff.cpp`\r\n```cpp\r\n#include <torch/extension.h>\r\n\r\nvoid backw(torch::Tensor tens) {\r\n    tens.backward({}, true, true);\r\n}\r\n\r\nPYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {\r\n    m.def(\"backw\", &backw, \"DIFF backw\");\r\n}\r\n```\r\n\r\n2. `setup.py` file\r\n```python\r\nfrom setuptools import setup, Extension\r\nfrom torch.utils import cpp_extension\r\n\r\nsetup(name='diff_cpp',\r\n      ext_modules=[cpp_extension.CppExtension('diff_cpp', ['diff.cpp'])],\r\n      cmdclass={'build_ext': cpp_extension.BuildExtension})\r\n```\r\n\r\n3. Install via `python setup.py install`\r\nThe installation proceeds without error, and the extension can subsequently be installed as `diff_cpp`. The following test script hangs at the last line:\r\n```python\r\nimport torch\r\nimport diff_cpp    # fine\r\nx = torch.tensor([1.0, 2.0], requires_grad=True)\r\ny = torch.sum(x)\r\ndiff_cpp.backw(y)  # hangs\r\n```\r\n\r\n## Environment\r\nI have so far tried this on two machines in multiple configurations, each time inside a fresh `python -m venv env` virtual environment and installing pytorch using pip.\r\n- python 3.7, torch 1.3.1, CPU\r\n- python 3.6, torch 1.3.1, CUDA 10.1\r\n- python 3.6, nightly, CUDA 10.1\r\n\r\nHere are the details of one of the environments I've tried this on:\r\n```\r\nPyTorch version: 1.3.1+cpu\r\nIs debug build: No\r\nCUDA used to build PyTorch: None\r\n\r\nOS: Arch Linux\r\nGCC version: (GCC) 9.2.0\r\nCMake version: version 3.16.2\r\n\r\nPython version: 3.7\r\nIs CUDA available: No\r\nCUDA runtime version: No CUDA\r\nGPU models and configuration: No CUDA\r\nNvidia driver version: No CUDA\r\ncuDNN version: No CUDA\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.18.0\r\n[pip3] torch==1.3.1+cpu\r\n[pip3] torchvision==0.4.2+cpu\r\n[conda] Could not collect\r\n```\r\n\n\ncc @ezyang @SsnL @albanD @zou3519 @gqchen @yf225"},{"labels":[null,"api",null,null],"text":"##  Bug\r\n\r\nIt looks like the modules attempt to register undefined tensors without turning off _requires_grad_ and cause a warning when _affine=false_  (default condition for InstanceNorm)\r\n\r\n## To Reproduce\r\n```\r\ntorch::nn::InstanceNorm2d m(64);\r\n\r\nWarning: An undefined tensor cannot require grad. Ignoring the `requires_grad=true` function parameter. (register_parameter at /pytorch/torch/csrc/api/src/nn/module.cpp:316)\r\n```\r\n## Expected behavior\r\n\r\nThere's logic in _nn/modules/batchnorm.h_ that checks the value of affine before attempting to register weight & bias:\r\n```\r\nvoid reset() override {\r\n    if (options.affine()) {\r\n      weight = this->register_parameter(\"weight\", torch::empty({options.num_features()}));\r\n      bias = this->register_parameter(\"bias\", torch::empty({options.num_features()}));\r\n    } else {\r\n      weight = this->register_parameter(\"weight\", Tensor());\r\n      bias = this->register_parameter(\"bias\", Tensor());\r\n    }\r\n```\r\nWhen _affine_ is false, I think the 3rd arg to _register_parameter_ should be false to turn off _requires_grad_ property, or perhaps these parameters need not be registered at all..?\r\n\n\ncc @ezyang @SsnL @albanD @zou3519 @gqchen @yf225"},{"labels":["api",null,null,null,null],"text":"##  Bug\r\n\r\nMy program is suffering from a weird bug. It works well with -O0 optimization but crashes with any higher optimization level (-O, -O2 and -O3).\r\n\r\n## To Reproduce\r\n\r\nMy program load the program with the following code\r\n```\r\n    torch::jit::script::Module module;\r\n    try\r\n    {\r\n        // Deserialize the ScriptModule from a file using torch::jit::load().\r\n        module = torch::jit::load(\"../c_model.th\");\r\n    }\r\n    catch (const c10::Error& e)\r\n    {\r\n        std::cerr << \"error loading the model\\n\";\r\n        return -1;\r\n    }\r\n```\r\n\r\nThen pass it by reference to another function, and work about it with the following code\r\n\r\n```\r\n    torch::IntArrayRef size{1,1,64,256};\r\n    at::TensorOptions options(torch::kFloat32);\r\n    auto tensor = torch::empty(size, options);\r\n    //Sadly we have to write the loop to set the value by ourselves.\r\n    auto accessor = tensor.accessor<float, 4>();\r\n    for(size_t i = 0; const auto &frame : mag)\r\n    {\r\n        for(size_t j = 0; const auto mag_entry : frame)\r\n        {\r\n            accessor[0][0][i][j] = mag_entry;\r\n            j++;\r\n        }\r\n        i++;\r\n    }\r\n\r\n    auto result = module.forward({tensor}).toTensor();\r\n    auto result_accessor = result.accessor<float, 2>();\r\n    float x = result_accessor[0][0];\r\n    float y = result_accessor[0][1];\r\n```\r\n\r\nHowever program crashes with the following info printed to console in -O1 or higher optimization level.\r\n\r\n```\r\nterminate called after throwing an instance of 'c10::Error'\r\n  what():  [enforce fail at CPUAllocator.cpp:47] ((ptrdiff_t)nbytes) >= 0. alloc_cpu() seems to have been called with negative number: 10177264015417475072\r\nframe #0: c10::ThrowEnforceNotMet(char const*, int, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void const*) + 0x6a (0x7ff247458fea in /home/liu/software/pytorch/torch/lib/libc10.so)\r\nframe #1: c10::alloc_cpu(unsigned long) + 0x4f0 (0x7ff2474403f0 in /home/liu/software/pytorch/torch/lib/libc10.so)\r\nframe #2: <unknown function> + 0x179ea (0x7ff2474419ea in /home/liu/software/pytorch/torch/lib/libc10.so)\r\nframe #3: at::native::empty_cpu(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x10b (0x7ff2483c174b in /home/liu/software/pytorch/torch/lib/libtorch.so)\r\nframe #4: <unknown function> + 0x11c0ba0 (0x7ff248632ba0 in /home/liu/software/pytorch/torch/lib/libtorch.so)\r\nframe #5: <unknown function> + 0x11c9dd7 (0x7ff24863bdd7 in /home/liu/software/pytorch/torch/lib/libtorch.so)\r\nframe #6: <unknown function> + 0x16a31 (0x5648e8b7da31 in /home/liu/work/PyTorchCppTest/cmake-build-debug/PyTorchCppTest)\r\nframe #7: <unknown function> + 0x851e (0x5648e8b6f51e in /home/liu/work/PyTorchCppTest/cmake-build-debug/PyTorchCppTest)\r\nframe #8: <unknown function> + 0xa473 (0x5648e8b71473 in /home/liu/work/PyTorchCppTest/cmake-build-debug/PyTorchCppTest)\r\nframe #9: __libc_start_main + 0xeb (0x7ff245714b6b in /lib/x86_64-linux-gnu/libc.so.6)\r\nframe #10: <unknown function> + 0x79aa (0x5648e8b6e9aa in /home/liu/work/PyTorchCppTest/cmake-build-debug/PyTorchCppTest)\r\n```\r\n\r\nI used the debugger to trace down the control flow, it looks like program crashes in ```torch::empty``` function.\r\n\r\n## Expected behavior\r\n\r\nRun correctly in higher optimization level.\r\n\r\n## Environment\r\n\r\nPyTorch version: 1.4.0a0+18ec463\r\nIs debug build: No\r\nCUDA used to build PyTorch: None\r\n\r\nOS: Ubuntu 19.04\r\nGCC version: (Ubuntu 9.2.1-9ubuntu2) 9.2.1 20191008\r\nCMake version: version 3.13.4\r\n\r\nPython version: 3.7\r\nIs CUDA available: No\r\nCUDA runtime version: No CUDA\r\nGPU models and configuration: No CUDA\r\nNvidia driver version: No CUDA\r\ncuDNN version: No CUDA\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.17.4\r\n[pip3] torchsummary==1.5.1\r\n[conda] blas                      1.0                         mkl  \r\n[conda] mkl                       2019.4                      243  \r\n[conda] mkl-service               2.3.0            py37he904b0f_0  \r\n[conda] mkl_fft                   1.0.14           py37ha843d7b_0  \r\n[conda] mkl_random                1.1.0            py37hd6b4f25_0  \r\n[conda] torch                     1.4.0a0+18ec463          pypi_0    pypi\r\n## Additional context\r\n\r\n\n\ncc @ezyang @gchanan @zou3519 @yf225"},{"labels":[null,null,"api",null,null],"text":"##  Bug\r\n\r\nAfter the cmake is done, when compiling .cu files in my project, the following error will occur:\r\n```bash\r\nnvcc fatal   : Unknown option 'Wall'\r\n```\r\nThe `flags.make` shows the following result:\r\n```bash\r\n$cat CMakeFiles/train.dir/flags.make\r\n# CMAKE generated file: DO NOT EDIT!\r\n# Generated by \"Unix Makefiles\" Generator, CMake Version 3.15\r\n\r\n# compile CUDA with /usr/local/cuda-9.2/bin/nvcc\r\n# compile CXX with /usr/bin/c++\r\nCUDA_FLAGS =  -O3   -D_GLIBCXX_USE_CXX11_ABI=1 -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-write-strings -Wno-unknown-pragmas -Wno-missing-braces -fopenmp -std=c++14\r\n\r\nCUDA_DEFINES = -DAT_PARALLEL_OPENMP=1\r\n......\r\n```\r\nThe `-O3` flag was added using `CMAKE_CUDA_FLAGS` in the `CMakeLists.txt`\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Write a .cu file in the project\r\n2. cmake then make\r\n3. The error occurs\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## Expected behavior\r\n\r\nThose -Wxxx flags should not be added as cuda flags.\r\n\r\n## Environment\r\n\r\nPlease copy and paste the output from our\r\n[environment collection script](https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py)\r\n(or fill out the checklist below manually).\r\n\r\nYou can get the script and run it with:\r\n```\r\nwget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\r\n# For security purposes, please check the contents of collect_env.py before running it.\r\npython collect_env.py\r\n```\r\n\r\n - PyTorch Version (e.g., 1.0): Compile from source\r\n - OS (e.g., Linux): Ubuntu 16.04\r\n - How you installed PyTorch (`conda`, `pip`, source): source\r\n - Build command you used (if compiling from source):\r\n```bash\r\nBUILD_TORCH=ON \\\r\nCMAKE_PREFIX_PATH=\"/usr/bin/;/opt/intel/compilers_and_libraries_2018.1.163/linux/mkl/lib/intel64/;/opt/intel/compilers_and_libraries_2018.1.163/linux/mkl/;/opt/intel/compilers_and_libraries_2018.1.163/linux/mkl/include/\" \\\r\nCUDA_BIN_PATH=/usr/local/cuda/bin \\\r\nCUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda/ \\\r\nCUDNN_LIB_DIR=/usr/local/cuda/lib64 \\\r\nUSE_CUDA=1 \\\r\nUSE_NNPACK=1 \\\r\nMAX_JOBS=8 \\\r\npython3 setup.py build\r\n```\r\n - Python version: 3.6\r\n - CUDA/cuDNN version: 9.2/7.5\r\n - GPU models and configuration: NVIDIA GTX Titan\r\n - Any other relevant information:\r\n\r\n\n\ncc @ezyang @gchanan @zou3519 @malfet @yf225 @glaringlee @ngimel"},{"labels":["api",null],"text":"##  Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n## To Reproduce\r\nI'm sharing a minor error. \r\nSteps to reproduce the behavior:\r\n\r\n```c++\r\n/*\r\nimages[index] is C * H * W  : 3 *480*640  2D Image tensor\r\nWhen calling interpolation, unknowexception occurs if the data type is not Kfloat.\r\n*/\r\nimages[index] = F::interpolate(images[index], F::InterpolateFuncOptions().scale_factor({ scale_factor }).mode(torch::kLinear).align_corners(false));\r\nimages[index] = normalizeChannels(images[index]);\r\n\r\n/*\r\nIf change data type, it works normally\r\nimg_tensor = img_tensor.toType(at::kFloat);\t\t\r\n*/\r\n```\r\n\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## Expected behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n## Environment\r\n\r\nPlease copy and paste the output from our\r\n[environment collection script](https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py)\r\n(or fill out the checklist below manually).\r\n\r\nYou can get the script and run it with:\r\n```\r\nwget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\r\n# For security purposes, please check the contents of collect_env.py before running it.\r\npython collect_env.py\r\n```\r\n\r\n - PyTorch Version (e.g., 1.0): Libtorch Nightly build date : 19.11.22\r\n - OS (e.g., Linux): Windows 10\r\n - How you installed PyTorch (`conda`, `pip`, source):\r\n - Build command you used (if compiling from source):\r\n - Python version:\r\n - CUDA/cuDNN version: 10.2 , 7.5\r\n - GPU models and configuration: 2080TI\r\n - Any other relevant information:\r\n\r\n## Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n\n\ncc @yf225"},{"labels":["api",null],"text":"##  Bug\r\n\r\nRunning the c++ example fails when running the forward calculation on the generator:\r\n\r\n`what():  Calculated padded input size per channel: (1 x 1). Kernel size: (4 x 4). Kernel size can't be greater than actual input size (check_shape_forward at /pytorch/aten/src/ATen/native/Convolution.cpp:436)`\r\n\r\nIs this due to recent changes to use NNPACK for strided convolutions..?\r\n\r\n(There's also a warning about batchnorm being deprecated,\r\nbut that's a simpler fix.)\r\n\r\nThanks\n\ncc @yf225"},{"labels":[null,"api",null,null,null],"text":"##  Bug\r\n\r\nWhen trying to compile with VS2019 but targeting v141 toolchain and cuda 10.0 there seems to be some issues with rewrite of dispatching that was done in recent weeks.\r\n\r\nThis snippet was from building using facebook internal Buck, but I was able to reproduce same thing using cmake.\r\n\r\nCompiling with /permissive- fixed the \"no matching overload\" error, but raises some other cuda errors related to `__nv_hdl_create_wrapper_t`\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. checkout pytorch master\r\n1. pass v141 as toolchain to cmake when generating\r\n1. set cuda sdk root to 10.0\r\n1. try and build torch_cuda\r\n\r\nError without /permissive-\r\n```\r\ncaffe2\\aten\\src\\aten\\core\\boxing\\KernelFunction_impl.h(67): error C2672: 'c10::impl::boxAndCallBoxedFunc': no matching overloaded function found\r\ncaffe2/aten/src\\ATen/core/dispatch/Dispatcher.h(180): note: see reference to function template instantiation 'Return c10::KernelFunction::callUnboxed<Return,const at::Tensor&,const at::Tensor&,bool,bool>(const c10::OperatorHandle &,const at::Tensor &,const at::Tensor &,bool,bool) const' being compiled\r\n        with\r\n        [\r\n            Return=void\r\n        ]\r\ncaffe2/aten/src\\ATen/core/dispatch/Dispatcher.h(155): note: see reference to function template instantiation 'Return c10::Dispatcher::callUnboxed<Return,const at::Tensor&,const at::Tensor&,bool,bool>(const c10::OperatorHandle &,const at::Tensor &,const at::Tensor &,bool,bool) const' being compiled\r\n        with\r\n        [\r\n            Return=void\r\n        ]\r\ncaffe2\\ATen/core/TensorMethods.h(66): note: see reference to function template instantiation 'Return c10::OperatorHandle::callUnboxed<void,const at::Tensor&,const at::Tensor&,bool,bool>(const at::Tensor &,const at::Tensor &,bool,bool) const' being compiled\r\n        with\r\n        [\r\n            Return=void\r\n        ]\r\ncaffe2\\aten\\src\\aten\\core\\boxing\\KernelFunction_impl.h(67): error C2770: invalid explicit template argument(s) for 'Result c10::impl::boxAndCallBoxedFunc(c10::KernelFunction::InternalBoxedKernelFunction (__cdecl *),c10::OperatorKernel *,const c10::OperatorHandle &,Args...,enable_if<_Test,_Ty>::type)'\r\n        with\r\n        [\r\n            _Ty=int\r\n        ]\r\ncaffe2/aten/src\\ATen/core/boxing/boxing.h(53): note: see declaration of 'c10::impl::boxAndCallBoxedFunc'\r\ncaffe2\\aten\\src\\aten\\core\\boxing\\KernelFunction_impl.h(67): error C2893: Failed to specialize function template 'Result c10::impl::boxAndCallBoxedFunc(c10::KernelFunction::InternalBoxedKernelFunction (__cdecl *),c10::OperatorKernel *,const c10::OperatorHandle &,Args...,enable_if<_Test,_Ty>::type)'\r\n        with\r\n        [\r\n            _Ty=int\r\n        ]\r\ncaffe2\\aten\\src\\aten\\core\\boxing\\KernelFunction_impl.h(67): note: With the following template arguments:\r\ncaffe2\\aten\\src\\aten\\core\\boxing\\KernelFunction_impl.h(67): note: 'Result=Return'\r\ncaffe2\\aten\\src\\aten\\core\\boxing\\KernelFunction_impl.h(67): note: 'Args={}'\r\n```\r\nError with /permissive-\r\n```\r\nnvcc_internal_extended_lambda_implementation(542): error C3861: 'args': identifier not found\r\ncaffe2/aten/src/ATen/native/cuda/Copy.cu(62): note: see reference to class template instantiation '__nv_hdl_create_wrapper_t<false,true,__nv_dl_tag<void (__cdecl *)(at::TensorIterator &,bool),at::native::copy_device_to_device,1>>' being compiled\r\n```\r\n\r\n## Expected behavior\r\n\r\nfiles compile\r\n\n\ncc @ezyang @gchanan @zou3519 @yf225 @peterjc123"},{"labels":[null,"api",null],"text":"##  Bug\r\n\r\nIf a Linear or Conv module is constructed without bias, a subsequent move to another device fails\r\n\r\n## To Reproduce\r\n\r\n```cpp\r\n#include <torch/torch.h>\r\n\r\nint main(int argc, char** argv) {\r\n  torch::nn::Linear test(torch::nn::LinearOptions(10,20).bias(false));\r\n  test->to(torch::kCUDA);\r\n  return 0;\r\n}\r\n```\r\n\r\n\r\n<details><summary>Stack trace</summary>\r\n<p>\r\n\r\n```\r\nterminate called after throwing an instance of 'c10::Error'\r\n  what():  tensor does not have a device (device at /opt/pytorch/c10/core/TensorImpl.h:463)\r\nframe #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x6a (0x7fffe51c9b1a in /usr/local/torch/lib/libc10.so)\r\nframe #1: <unknown function> + 0x1fd83a6 (0x7fffe73ba3a6 in /usr/local/torch/lib/libtorch.so)\r\nframe #2: at::native::to(at::Tensor const&, c10::TensorOptions const&, bool, bool, c10::optional<c10::MemoryFormat>) + 0xb36 (0x7fffe8c6b1f6 in /usr/local/torch/lib/libtorch.so)\r\nframe #3: <unknown function> + 0x3c22636 (0x7fffe9004636 in /usr/local/torch/lib/libtorch.so)\r\nframe #4: <unknown function> + 0x5882857 (0x7fffeac64857 in /usr/local/torch/lib/libtorch.so)\r\nframe #5: <unknown function> + 0x3c89f2f (0x7fffe906bf2f in /usr/local/torch/lib/libtorch.so)\r\nframe #6: <unknown function> + 0x25e1277 (0x7fffe79c3277 in /usr/local/torch/lib/libtorch.so)\r\nframe #7: void torch::nn::Module::to_impl<c10::Device&, bool&>(c10::Device&, bool&) + 0x196 (0x7fffeb3a8266 in /usr/local/torch/lib/libtorch.so)\r\nframe #8: torch::nn::Module::to(c10::Device, bool) + 0x18 (0x7fffeb3a2fe8 in /usr/local/torch/lib/libtorch.so)\r\nframe #9: main + 0xba (0x4052e8 in /home/tobi/coar_ws/devel/lib/dgcnn/dev_stuff)\r\nframe #10: __libc_start_main + 0xf0 (0x7fffe4855830 in /lib/x86_64-linux-gnu/libc.so.6)\r\nframe #11: _start + 0x29 (0x405049 in /home/tobi/coar_ws/devel/lib/dgcnn/dev_stuff)\r\n\r\n\r\nThread 1 \"dev_stuff\" received signal SIGABRT, Aborted.\r\n0x00007fffe486a428 in __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:54\r\n54      ../sysdeps/unix/sysv/linux/raise.c: No such file or directory.\r\n(gdb) backtrace\r\n#0  0x00007fffe486a428 in __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:54\r\n#1  0x00007fffe486c02a in __GI_abort () at abort.c:89\r\n#2  0x00007fffe4ea484d in __gnu_cxx::__verbose_terminate_handler() () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6\r\n#3  0x00007fffe4ea26b6 in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6\r\n#4  0x00007fffe4ea2701 in std::terminate() () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6\r\n#5  0x00007fffe4ea2919 in __cxa_throw () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6\r\n#6  0x00007fffe73ba3fc in at::Tensor::options() const () from /usr/local/torch/lib/libtorch.so\r\n#7  0x00007fffe8c6b1f6 in at::native::to(at::Tensor const&, c10::TensorOptions const&, bool, bool, c10::optional<c10::MemoryFormat>) () from /usr/local/torch/lib/libtorch.so\r\n#8  0x00007fffe9004636 in at::TypeDefault::to(at::Tensor const&, c10::TensorOptions const&, bool, bool, c10::optional<c10::MemoryFormat>) () from /usr/local/torch/lib/libtorch.so\r\n#9  0x00007fffeac64857 in torch::autograd::VariableType::(anonymous namespace)::to(at::Tensor const&, c10::TensorOptions const&, bool, bool, c10::optional<c10::MemoryFormat>) () from /usr/local/torch/lib/libtorch.so\r\n#10 0x00007fffe906bf2f in c10::detail::wrap_kernel_functor_unboxed_<c10::detail::WrapRuntimeKernelFunctor_<at::Tensor (*)(at::Tensor const&, c10::TensorOptions const&, bool, bool, c10::optional<c10::MemoryFormat>), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, c10::TensorOptions const&, bool, bool, c10::optional<c10::MemoryFormat> > >, at::Tensor (at::Tensor const&, c10::TensorOptions const&, bool, bool, c10::optional<c10::MemoryFormat>)>::call(c10::OperatorKernel*, at::Tensor const&, c10::TensorOptions const&, bool, bool, c10::optional<c10::MemoryFormat>) () from /usr/local/torch/lib/libtorch.so\r\n#11 0x00007fffe79c3277 in at::Tensor::to(c10::TensorOptions const&, bool, bool, c10::optional<c10::MemoryFormat>) const () from /usr/local/torch/lib/libtorch.so\r\n#12 0x00007fffeb3a8266 in void torch::nn::Module::to_impl<c10::Device&, bool&>(c10::Device&, bool&) () from /usr/local/torch/lib/libtorch.so\r\n#13 0x00007fffeb3a2fe8 in torch::nn::Module::to(c10::Device, bool) [clone .localalias.489] () from /usr/local/torch/lib/libtorch.so\r\n#14 0x00000000004052e8 in main (argc=1, argv=0x7fffffffccc8) at /home/tobi/coar_ws/src/dgcnn/src/dev_stuff.cpp:5\r\n```\r\n</p>\r\n</details>\r\n\r\n## Expected behavior\r\n\r\nGetting no error.\r\n\r\n## Environment\r\n\r\n```\r\nCollecting environment information...\r\nCollecting environment information...\r\nPyTorch version: 1.4.0a0+829499e\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.1\r\n\r\nOS: Ubuntu 18.04.3 LTS\r\nGCC version: (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0\r\nCMake version: version 3.15.3\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: Could not collect\r\nGPU models and configuration:\r\nGPU 0: Quadro RTX 6000\r\nGPU 1: Quadro RTX 6000\r\n\r\nNvidia driver version: 418.87.00\r\ncuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.17.4\r\n[pip3] torch==1.4.0a0+94016b1\r\n[conda] Could not collect\r\n\r\n```\r\n\r\n - PyTorch Version (e.g., 1.0): 1.4.0a0+829499e\r\n - OS (e.g., Linux): Ubuntu 18.04.3 LTS\r\n - How you installed PyTorch (`conda`, `pip`, source): compiled from source\r\n - Build command you used (if compiling from source): ```CFLAGS=' -D_GLICXX_USE_CXX11_ABI ' USE_OPENCV=1 USE_CUDA=1 MAX_JOBS=7 BUILD_TEST=0 python3 setup.py install ```\r\n - Python version: 3.6\r\n - CUDA/cuDNN version: CUDA 10.1 / cuDNN 7.6.5\r\n - GPU models and configuration: 2x Quadro RTX 6000\r\n\n\ncc @ezyang @gchanan @zou3519 @jerryzh168 @yf225"},{"labels":["api",null,null],"text":"##  Bug\r\n\r\nHi, maybe I found a bug in LibTorch while run codes in CentOS, the codes are very simplify. I have try it in 2 CentOS Machines and 1 Ubuntu Machine, Ubuntu Machine can run it normally, but all of the CentOS Machines run it like follow outputs.\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. download libtorch and unzip\r\n2. compile the cpp file\r\n3. run\r\n\r\nHere are the codes:\r\n```c++\r\n#include<iostream>\r\n#include<torch/torch.h>\r\n#include <torch/script.h>\r\n\r\nint main() {\r\n\ttorch::Tensor a = torch::ones({2,4});\r\n\tstd::cout << a << std::endl;\r\n\treturn 0;\r\n}\r\n```\r\n\r\nHere is the CMakeList:\r\n```cmake\r\ncmake_minimum_required(VERSION 3.0 FATAL_ERROR)\r\nproject(tr)\r\n\r\nfind_package(Torch REQUIRED)\r\naux_source_directory(. SRC_LIST)\r\nadd_executable(test ${SRC_LIST})\r\nset(CMAKE_CXX_STANDARD 11)\r\ntarget_link_libraries(test \"${TORCH_LIBRARIES}\")\r\nset_property(TARGET test PROPERTY CXX_STANDARD 11)\r\n```\r\n\r\nHere is the output:\r\n```\r\n 1  1  1  1\r\n 1  1  1  1\r\n[ Variable[CPUFloatType]{2,4} ]\r\n*** Error in `./test': free(): invalid pointer: 0x00007f040f871090 ***\r\n======= Backtrace: =========\r\n/lib64/libc.so.6(+0x81679)[0x7f04022b3679]\r\n./test(_ZN9__gnu_cxx13new_allocatorIPNSt8__detail15_Hash_node_baseEE10deallocateEPS3_m+0x20)[0x41fd0e]\r\n./test(_ZNSt10_HashtableISsSt4pairIKSsSsESaIS2_ENSt8__detail10_Select1stESt8equal_toISsESt4hashISsENS4_18_Mod_range_hashingENS4_20_Default_ranged_hashENS4_20_Prime_rehash_policyENS4_17_Hashtable_traitsILb1ELb0ELb1EEEE21_M_deallocate_bucketsEPPNS4_15_Hash_node_baseEm+0x49)[0x41f20f]\r\n./test(_ZNSt10_HashtableISsSt4pairIKSsSsESaIS2_ENSt8__detail10_Select1stESt8equal_toISsESt4hashISsENS4_18_Mod_range_hashingENS4_20_Default_ranged_hashENS4_20_Prime_rehash_policyENS4_17_Hashtable_traitsILb1ELb0ELb1EEEED1Ev+0x36)[0x41df10]\r\n/lib64/libc.so.6(__cxa_finalize+0x9a)[0x7f040226c00a]\r\n/home/yyuser/nlp/codes/bd-nlp/libtorch/lib/libtorch.so(+0x9fa9d3)[0x7f040367e9d3]\r\n======= Memory map: ========\r\n00400000-00429000 r-xp 00000000 fd:02 186000054                          /home/yyuser/nlp/codes/bd-nlp/tr/alg-service/build/test\r\n00628000-00629000 r--p 00028000 fd:02 186000054                          /home/yyuser/nlp/codes/bd-nlp/tr/alg-service/build/test\r\n00629000-0062a000 rw-p 00029000 fd:02 186000054                          /home/yyuser/nlp/codes/bd-nlp/tr/alg-service/build/test\r\n021b1000-02aee000 rw-p 00000000 00:00 0                                  [heap]\r\n7f03fc000000-7f03fc021000 rw-p 00000000 00:00 0 \r\n7f03fc021000-7f0400000000 ---p 00000000 00:00 0 \r\n7f04018fa000-7f04019fb000 r-xp 00000000 fd:02 1548                       /usr/lib64/libm-2.17.so\r\n7f04019fb000-7f0401bfa000 ---p 00101000 fd:02 1548                       /usr/lib64/libm-2.17.so\r\n7f0401bfa000-7f0401bfb000 r--p 00100000 fd:02 1548                       /usr/lib64/libm-2.17.so\r\n7f0401bfb000-7f0401bfc000 rw-p 00101000 fd:02 1548                       /usr/lib64/libm-2.17.so\r\n7f0401bfc000-7f0401bfe000 r-xp 00000000 fd:02 1546                       /usr/lib64/libdl-2.17.so\r\n7f0401bfe000-7f0401dfe000 ---p 00002000 fd:02 1546                       /usr/lib64/libdl-2.17.so\r\n7f0401dfe000-7f0401dff000 r--p 00002000 fd:02 1546                       /usr/lib64/libdl-2.17.so\r\n7f0401dff000-7f0401e00000 rw-p 00003000 fd:02 1546                       /usr/lib64/libdl-2.17.so\r\n7f0401e00000-7f0401e07000 r-xp 00000000 fd:02 1570                       /usr/lib64/librt-2.17.so\r\n7f0401e07000-7f0402006000 ---p 00007000 fd:02 1570                       /usr/lib64/librt-2.17.so\r\n7f0402006000-7f0402007000 r--p 00006000 fd:02 1570                       /usr/lib64/librt-2.17.so\r\n7f0402007000-7f0402008000 rw-p 00007000 fd:02 1570                       /usr/lib64/librt-2.17.so\r\n7f0402008000-7f040202d000 r-xp 00000000 fd:02 352611484                  /home/yyuser/nlp/codes/bd-nlp/libtorch/lib/libgomp-7c85b1e2.so.1\r\n7f040202d000-7f040222c000 ---p 00025000 fd:02 352611484                  /home/yyuser/nlp/codes/bd-nlp/libtorch/lib/libgomp-7c85b1e2.so.1\r\n7f040222c000-7f040222d000 r--p 00024000 fd:02 352611484                  /home/yyuser/nlp/codes/bd-nlp/libtorch/lib/libgomp-7c85b1e2.so.1\r\n7f040222d000-7f0402232000 rw-p 00025000 fd:02 352611484                  /home/yyuser/nlp/codes/bd-nlp/libtorch/lib/libgomp-7c85b1e2.so.1\r\n7f0402232000-7f04023f5000 r-xp 00000000 fd:02 1540                       /usr/lib64/libc-2.17.so\r\n7f04023f5000-7f04025f5000 ---p 001c3000 fd:02 1540                       /usr/lib64/libc-2.17.so\r\n7f04025f5000-7f04025f9000 r--p 001c3000 fd:02 1540                       /usr/lib64/libc-2.17.so\r\n7f04025f9000-7f04025fb000 rw-p 001c7000 fd:02 1540                       /usr/lib64/libc-2.17.so\r\n7f04025fb000-7f0402600000 rw-p 00000000 00:00 0 \r\n7f0402600000-7f0402615000 r-xp 00000000 fd:02 1311741                    /usr/lib64/libgcc_s-4.8.5-20150702.so.1\r\n7f0402615000-7f0402814000 ---p 00015000 fd:02 1311741                    /usr/lib64/libgcc_s-4.8.5-20150702.so.1\r\n7f0402814000-7f0402815000 r--p 00014000 fd:02 1311741                    /usr/lib64/libgcc_s-4.8.5-20150702.so.1\r\n7f0402815000-7f0402816000 rw-p 00015000 fd:02 1311741                    /usr/lib64/libgcc_s-4.8.5-20150702.so.1\r\n7f0402816000-7f040282d000 r-xp 00000000 fd:02 1566                       /usr/lib64/libpthread-2.17.so\r\n7f040282d000-7f0402a2c000 ---p 00017000 fd:02 1566                       /usr/lib64/libpthread-2.17.so\r\n7f0402a2c000-7f0402a2d000 r--p 00016000 fd:02 1566                       /usr/lib64/libpthread-2.17.so\r\n7f0402a2d000-7f0402a2e000 rw-p 00017000 fd:02 1566                       /usr/lib64/libpthread-2.17.so\r\n7f0402a2e000-7f0402a32000 rw-p 00000000 00:00 0 \r\n7f0402a32000-7f0402a77000 r-xp 00000000 fd:02 352611503                  /home/yyuser/nlp/codes/bd-nlp/libtorch/lib/libc10.so\r\n7f0402a77000-7f0402c77000 ---p 00045000 fd:02 352611503                  /home/yyuser/nlp/codes/bd-nlp/libtorch/lib/libc10.so\r\n7f0402c77000-7f0402c78000 r--p 00045000 fd:02 352611503                  /home/yyuser/nlp/codes/bd-nlp/libtorch/lib/libc10.so\r\n7f0402c78000-7f0402c79000 rw-p 00046000 fd:02 352611503                  /home/yyuser/nlp/codes/bd-nlp/libtorch/lib/libc10.so\r\n7f0402c79000-7f0402c7a000 rw-p 00000000 00:00 0 \r\n7f0402c7a000-7f0402c84000 rw-p 0005f000 fd:02 352611503                  /home/yyuser/nlp/codes/bd-nlp/libtorch/lib/libc10.so\r\n7f0402c84000-7f040f47f000 r-xp 00000000 fd:02 352611487                  /home/yyuser/nlp/codes/bd-nlp/libtorch/lib/libtorch.so\r\n7f040f47f000-7f040f67f000 ---p 0c7fb000 fd:02 352611487                  /home/yyuser/nlp/codes/bd-nlp/libtorch/lib/libtorch.so\r\n7f040f67f000-7f040f75d000 r--p 0c7fb000 fd:02 352611487                  /home/yyuser/nlp/codes/bd-nlp/libtorch/lib/libtorch.so\r\n7f040f75d000-7f040f854000 rw-p 0c8d9000 fd:02 352611487                  /home/yyuser/nlp/codes/bd-nlp/libtorch/lib/libtorch.so\r\n7f040f854000-7f040f8a6000 rw-p 00000000 00:00 0 \r\n7f040f8a6000-7f040fb5e000 rw-p 0db6f000 fd:02 352611487                  /home/yyuser/nlp/codes/bd-nlp/libtorch/lib/libtorch.so\r\n7f040fb5e000-7f040fb80000 r-xp 00000000 fd:02 1533                       /usr/lib64/ld-2.17.so\r\n7f040fbe9000-7f040fbff000 rw-p 00000000 00:00 0 \r\n7f040fbff000-7f040fca1000 r--p 00000000 fd:02 9122949                    /usr/lib/libstdc++.so.6.0.26\r\n7f040fca1000-7f040fd20000 r-xp 000a2000 fd:02 9122949                    /usr/lib/libstdc++.so.6.0.26\r\n7f040fd20000-7f040fd61000 r--p 00121000 fd:02 9122949                    /usr/lib/libstdc++.so.6.0.26[1]    14117 abort      ./test\r\n```\r\n\r\n\r\n## Environment\r\n\r\n\r\n - PyTorch Version (e.g., 1.0): 1.3\r\n - OS (e.g., Linux): CentOS Linux release 7.7.1908 (Core) and CentOS Linux release 7.6.1810 (Core) \r\n - How you installed PyTorch (`conda`, `pip`, source): LibTorch(Pre-cxx11 ABI)\r\n - CUDA/cuDNN version: no GPU\r\n - LibTorch download url: [https://download.pytorch.org/libtorch/cpu/libtorch-shared-with-deps-1.3.1%2Bcpu.zip](https://download.pytorch.org/libtorch/cpu/libtorch-shared-with-deps-1.3.1%2Bcpu.zip)\r\n\r\n\n\ncc @ezyang @gchanan @zou3519 @jerryzh168 @yf225"},{"labels":["api",null],"text":"Hello,\r\nI was trying to code example of neural network on CUDA. I have run some examples which they were working on CPU but not on GPU. \r\n\r\nNot sure if it's a bug or my mistake.\r\n\r\nPlease note that CUDA version of [MNIST example](https://github.com/Andrej-sens/libtorch_examples_cpp/blob/master/MNIST_Example_GPU.cpp) is working properly. \r\n\r\nHow to replicate error, just change bias to false. With `bias=true` I am able to move network model to CUDA.\r\n```\r\n#include <torch/torch.h>\r\n\r\n// Define a new Module.\r\nstruct Net : torch::nn::Module {\r\n\tNet() {\r\n\t\ttorch::nn::Conv2d conv = torch::nn::Conv2d(torch::nn::Conv2dOptions(3, 16, 3)\r\n\t\t\t.bias(true)\r\n\t\t\t.stride(1)\r\n\t\t\t.padding(1)\r\n\t\t);\r\n\r\n\t\tmodule->push_back(conv);\r\n\r\n\t\tregister_module(\"Layer\",module);\r\n\t}\r\n\r\n\ttorch::Tensor forward(torch::Tensor x) {\r\n\t\t/**SOME FORWARD**/\r\n\t\treturn x;\r\n\t}\r\n\r\n\ttorch::nn::Sequential module;\r\n};\r\n\r\nint main() {\r\n\tauto net = std::make_shared<Net>();\r\n\tnet->to(at::kCUDA); // It crashes here\r\n}\r\n```\r\n\r\nIt will throw\r\n```\r\nException thrown at 0x00007FFB4A2EA839 in Object_detection.exe: Microsoft C++ exception: c10::Error at memory location 0x000000635F0FDE90.\r\nUnhandled exception at 0x00007FFB4A2EA839 in Object_detection.exe: Microsoft C++ exception: c10::Error at memory location 0x000000635F0FDE90.\r\n```\r\n\r\nThank you very much for any advise.\r\n\n\ncc @ezyang @gchanan @zou3519 @jerryzh168 @yf225"},{"labels":["api",null,null],"text":"##  Bug\r\n\r\nLoads of errors during C++ code compilation due to problems with namespaces in LibTorch files.\r\n\r\n## What helped\r\nChanges in files:\r\n\r\n1. libtorch/include/ATen/detail/CUDAHooksInterface.h \r\n26 line:\r\n```\r\nnamespace at {\r\nusing c10::Allocator;\t///Changed manually\r\n```\r\n2. libtorch/include/ATen/core/TensorBody.h\r\n35 line: \r\n```\r\nnamespace at {\r\n using c10::Scalar; ///Changed manually\r\n```\r\n## Environment\r\nPyTorch version: 1.3.1\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.1.243\r\n\r\nOS: Ubuntu 16.04.6 LTS\r\nGCC version: (Ubuntu 5.3.1-14ubuntu2) 5.3.1 20160413\r\nCMake version: version 3.5.1\r\n\r\nPython version: 3.6\r\nIs CUDA available: No\r\nCUDA runtime version: 9.2.148\r\nGPU models and configuration: GPU 0: Quadro M2000\r\nNvidia driver version: 410.48\r\ncuDNN version: /usr/local/cuda-9.2/lib64/libcudnn.so.7\r\n\r\n\r\n## Additional context\r\n\r\nIt would be great not to have this bug in future versions because original file code change is not the best method of creating robust software. Maybe it is possible to prevent this issue using some commands but I don't know them.\n\ncc @yf225"},{"labels":["api"],"text":"##  Bug\r\nThe following short program does not compile.\r\n\r\n    #include \"torch/torch.h\"\r\n\r\n    int main() {\r\n        torch::Tensor tensor = torch::ones({2, 2});\r\n        tensor.fill_(0); // OK\r\n        tensor = 0; // Gives compile error\r\n    }\r\n\r\n## Expected behavior\r\n\r\nI would expect both the expressions 'tensor.fill_(0)' and 'tensor = 0' to compile and that they would yield the same result.\r\n\r\nLooking at the source code 'aten/src/ATen/TensorOperators.h' the selected assignment operator is defined as follows:\r\n\r\n    inline Tensor & Tensor::operator=(Scalar v) && {\r\n        return fill_(v);\r\n    }\r\n\r\nThat is, it is only defined for rvalues on the lhs of the assignment. I do not understand the rationale behind this restriction.\r\n\r\n## Environment\r\n\r\n```\r\n - PyTorch Version: 1.3.1\r\n - OS: Linux\r\n - How you installed PyTorch:  https://download.pytorch.org/libtorch/cu101/libtorch-cxx11-abi-shared-with-deps-1.3.1.zip\r\n - Build command you used: cmake -DCMAKE_PREFIX_PATH=/absolute/path/to/libtorch .. && make\r\n```\r\nI am building the sample program using the instructions in the [c++ api guide](https://pytorch.org/cppdocs/installing.html)\r\n\n\ncc @yf225"},{"labels":["api",null],"text":"##  Bug\r\n\r\nL-BFGS optimizer will not work if there is one or more registered parameters (tensors) with no grad in the model:\r\n```\r\nterminate called after throwing an instance of 'c10::Error'\r\n  what():  There were no tensor arguments to this function (e.g., you passed an empty list of Tensors), but no fallback function is registered for schema aten::view.  This usually means that this function requires a non-empty list of Tensors.  Available functions are [CUDATensorId, QuantizedCPUTensorId, VariableTensorId, CPUTensorId, MkldnnCPUTensorId] (lookup_ at /pytorch/aten/src/ATen/core/dispatch/DispatchTable.h:245)\r\n```\r\n\r\n## To Reproduce\r\n\r\nCode to reproduce the error:\r\n\r\n```\r\n/* A custom dataset for test */\r\nnamespace torch\r\n{\r\n    namespace data\r\n    {\r\n        namespace datasets\r\n        {\r\n            struct TEST_TensorDataset : public Dataset<TEST_TensorDataset>\r\n            {\r\n                private:\r\n                    torch::Tensor data1, data2;\r\n\r\n                public:\r\n                    explicit TEST_TensorDataset(std::vector<torch::Tensor> tensors):\r\n                        data1(tensors[0]), data2(tensors[1]) \r\n                        {}\r\n\r\n                torch::data::Example<> get(size_t index) override\r\n                {\r\n                    return {data1[index], data2[index]};\r\n                }\r\n\r\n                optional<size_t> size() const override\r\n                {\r\n                    return data1.sizes()[0];\r\n                }\r\n            };\r\n        }\r\n    }\r\n}\r\n\r\n/* Test */\r\nint test()\r\n{\r\n    struct Net : torch::nn::Module\r\n    {\r\n        Net():\r\n        fc1(128, 256),\r\n        fc2(256, 1)\r\n        {\r\n            register_module(\"fc1\", fc1);\r\n            register_module(\"fc2\", fc2);\r\n            /* The following line will cause the error */\r\n            tmp = register_parameter(\"tmp\", torch::ones({1,1}), false);\r\n        }\r\n\r\n        torch::Tensor forward(torch::Tensor x)\r\n        {\r\n            x = torch::tanh(fc1->forward(x));\r\n            x = fc2->forward(x);\r\n            return x;\r\n        }\r\n\r\n        torch::nn::Linear fc1;\r\n        torch::nn::Linear fc2;\r\n        torch::Tensor tmp;\r\n    };\r\n\r\n    Net model;\r\n    int batchsize = 16;\r\n    int stop_epoch = 10;\r\n    torch::Tensor data = torch::randn({32, 128});\r\n    torch::Tensor target = torch::randn({32, 1});\r\n    auto dataset = torch::data::datasets::TEST_TensorDataset({data, target}).map(torch::data::transforms::Stack<>());\r\n    auto data_loader = torch::data::make_data_loader<torch::data::samplers::RandomSampler>(std::move(dataset), torch::data::DataLoaderOptions().batch_size(batchsize));\r\n    torch::optim::LBFGS optimizer_lbfgs = torch::optim::LBFGS(model.parameters(), torch::optim::LBFGSOptions(1E-2));\r\n    for (int epoch = 0; epoch <= stop_epoch - 1; epoch++)\r\n    {\r\n        int batch_idx = 0;\r\n        bool output_loss = true;\r\n        for (auto & batch : *data_loader)\r\n        {\r\n            output_loss = true;\r\n            auto closure = [&]()\r\n            {\r\n                model.zero_grad();\r\n                torch::Tensor target_net = model.forward(batch.data);\r\n                torch::Tensor loss = torch::mse_loss(target_net, batch.target);\r\n                loss.backward();\r\n                if (output_loss)\r\n                {\r\n                    std::cout << \"Epoch: \" << epoch << \" Batch: \" << batch_idx << \" loss: \" << loss << std::endl;\r\n                    output_loss = false;\r\n                }\r\n                return loss;\r\n            };\r\n            optimizer_lbfgs.step(closure);\r\n            batch_idx++;\r\n        }\r\n    }\r\n\r\n    return 0;\r\n}\r\n```\r\n\r\n## Expected behavior\r\n\r\nIf line 12 in the function **test()**: `tmp = register_parameter(\"tmp\", torch::ones({1,1}), false);` is commented out, then everything goes fine.\r\n\r\n## Environment\r\n\r\n - PyTorch Version (e.g., 1.0): 1.2.0\r\n - OS (e.g., Linux): Ubuntu 16.04.6 LTS\r\n - How you installed PyTorch (`conda`, `pip`, source): pip\r\n - Build command you used (if compiling from source):\r\n - Python version: 3.5\r\n - CUDA/cuDNN version: 9.2/7.5\r\n - GPU models and configuration: GeForce GTX TITAN\r\n - Any other relevant information:\r\nGCC version: (Ubuntu 4.9.4-2ubuntu1~16.04) 4.9.4\r\nCMake version: version 3.15.2\r\n\n\ncc @yf225"},{"labels":["api",null],"text":"**Description**\r\nDocker (the service) accepts requests with \"Transfer-encoding: chunked\". However the authorization plugin doesn't: \r\nhttps://github.com/moby/moby/blob/master/pkg/authorization/authz.go#L58\r\nIt expects Content-Length to be set. If that header is not set (i.e. when transfer-encoding: chunked), it wrongly assumes a nil body. \r\n\r\nThis leads to issues with libraries such as docker-java and projects building on top of it such as testcontainers-java. Both supported clients in docker-java (okhttp and apache-http) are sending content with transfer-encoding: chunked. \r\n\r\n**Steps to reproduce the issue:**\r\n1. Setup an authorization plugin, e.g. https://github.com/ad-freiburg/docker-no-trivial-root \r\n2. Issue a create call with transfer-encoding: chunked (here with curl, simulating the docker-java code)\r\n```\r\ncurl -v -H 'Content-type: application/json' -H 'Transfer-encoding: chunked' localhost:2375/containers/create -d '{\"Image\": \"ubuntu:latest\"}'\r\n{\"message\":\"plugin no-trivial-root failed with error: AuthZPlugin.AuthZReq: unexpected end of JSON input\"}\r\n```\r\nAuthZ Request debug dump: \r\n``` (authorization.Request) {\r\n  User: (string) \"\",\r\n  UserAuthNMethod: (string) \"\",\r\n  RequestMethod: (string) (len=4) \"POST\",\r\n  RequestURI: (string) (len=18) \"/containers/create\",\r\n  RequestBody: ([]uint8) <nil>,\r\n  RequestHeaders: (map[string]string) (len=3) {\r\n   (string) (len=12) \"Content-Type\": (string) (len=16) \"application/json\",\r\n   (string) (len=10) \"User-Agent\": (string) (len=11) \"curl/7.47.0\",\r\n   (string) (len=6) \"Accept\": (string) (len=3) \"*/*\"\r\n  },\r\n  RequestPeerCertificates: ([]*authorization.PeerCertificate) <nil>,\r\n  ResponseStatusCode: (int) 0,\r\n  ResponseBody: ([]uint8) <nil>,\r\n  ResponseHeaders: (map[string]string) <nil>\r\n }\r\n```\r\nThe plugin failed to parse the request as it receives a nil request body (while it is not)\r\n\r\n**Expected:** \r\nIf docker is able to process a request, then the authorization plugin should be able to do so in the same way. In this case, I'd expect both calls to work equally (as they do with docker without authorization plugin: \r\n\r\n```\r\ncurl -v -H 'Content-type: application/json' -H 'Transfer-encoding: chunked' localhost:2375/containers/create -d '{\"Image\": \"ubuntu:latest\"}'\r\ncurl -v -H 'Content-type: application/json' localhost:2375/containers/create -d '{\"Image\": \"ubuntu:latest\"}'`\r\n```\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient: Docker Engine - Community\r\n Version:           19.03.8\r\n API version:       1.40\r\n Go version:        go1.12.17\r\n Git commit:        afacb8b7f0\r\n Built:             Wed Mar 11 01:25:58 2020\r\n OS/Arch:           linux/amd64\r\n Experimental:      false\r\n\r\nServer: Docker Engine - Community\r\n Engine:\r\n  Version:          19.03.8\r\n  API version:      1.40 (minimum version 1.12)\r\n  Go version:       go1.12.17\r\n  Git commit:       afacb8b7f0\r\n  Built:            Wed Mar 11 01:24:30 2020\r\n  OS/Arch:          linux/amd64\r\n  Experimental:     false\r\n containerd:\r\n  Version:          1.2.13\r\n  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429\r\n runc:\r\n  Version:          1.0.0-rc10\r\n  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd\r\n docker-init:\r\n  Version:          0.18.0\r\n  GitCommit:        fec3683\r\n```\r\n\r\n**Output of `docker info`:**\r\n```\r\nClient:\r\n Debug Mode: false\r\n\r\nServer:\r\n Containers: 87\r\n  Running: 5\r\n  Paused: 0\r\n  Stopped: 82\r\n Images: 112\r\n Server Version: 19.03.8\r\n Storage Driver: overlay2\r\n  Backing Filesystem: <unknown>\r\n  Supports d_type: true\r\n  Native Overlay Diff: true\r\n Logging Driver: json-file\r\n Cgroup Driver: cgroupfs\r\n Plugins:\r\n  Volume: local\r\n  Network: bridge host ipvlan macvlan null overlay\r\n  Authorization: no-trivial-root\r\n  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog\r\n Swarm: inactive\r\n Runtimes: runc\r\n Default Runtime: runc\r\n Init Binary: docker-init\r\n containerd version: 7ad184331fa3e55e52b890ea95e65ba581ae3429\r\n runc version: dc9208a3303feef5b3839f4323d9beb36df0a9dd\r\n init version: fec3683\r\n Security Options:\r\n  apparmor\r\n  seccomp\r\n   Profile: default\r\n  userns\r\n Kernel Version: 4.4.0-187-generic\r\n Operating System: Ubuntu 16.04.7 LTS\r\n OSType: linux\r\n Architecture: x86_64\r\n CPUs: 2\r\n Total Memory: 3.842GiB\r\n Name: scl000102100\r\n ID: GETQ:2BEO:QTOR:FLGH:BSV4:5MTS:3LD2:7S3U:YFCW:CLIU:ZIRJ:6NLM\r\n Docker Root Dir: /var/lib/docker/16170.100000\r\n Debug Mode: true\r\n  File Descriptors: 53\r\n  Goroutines: 57\r\n  System Time: 2020-09-15T12:03:20.872834075+02:00\r\n  EventsListeners: 0\r\n HTTP Proxy: http://gate-zrh-os.swissre.com:8080/\r\n No Proxy: swissre.com\r\n Username: johannessr\r\n Registry: https://index.docker.io/v1/\r\n Labels:\r\n Experimental: false\r\n Insecure Registries:\r\n  127.0.0.0/8\r\n Live Restore Enabled: false\r\n\r\nWARNING: API is accessible on http://0.0.0.0:2375 without encryption.\r\n         Access to the remote API is equivalent to root access on the host. Refer\r\n         to the 'Docker daemon attack surface' section in the documentation for\r\n         more information: https://docs.docker.com/engine/security/security/#docker-daemon-attack-surface\r\nWARNING: No swap limit support\r\n\r\n```\r\n"},{"labels":["api",null,null],"text":"<!--\r\nIf you are reporting a new issue, make sure that we do not have any duplicates\r\nalready open. You can ensure this by searching the issue list for this\r\nrepository. If there is a duplicate, please close your issue and add a comment\r\nto the existing issue instead.\r\n\r\nIf you suspect your issue is a bug, please edit your issue description to\r\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\r\ninformation within 7 days, we cannot debug your issue and will close it. We\r\nwill, however, reopen it if you later provide the information.\r\n\r\nFor more information about reporting issues, see\r\nhttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues\r\n\r\n---------------------------------------------------\r\nGENERAL SUPPORT INFORMATION\r\n---------------------------------------------------\r\n\r\nThe GitHub issue tracker is for bug reports and feature requests.\r\nGeneral support for **docker** can be found at the following locations:\r\n\r\n- Docker Support Forums - https://forums.docker.com\r\n- Slack - community.docker.com #general channel\r\n- Post a question on StackOverflow, using the Docker tag\r\n\r\nGeneral support for **moby** can be found at the following locations:\r\n\r\n- Moby Project Forums - https://forums.mobyproject.org\r\n- Slack - community.docker.com #moby-project channel\r\n- Post a question on StackOverflow, using the Moby tag\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\n**Description**\r\nIn api document `/version` response looks like wrong.\r\nhttps://github.com/moby/moby/blob/master/docs/api/v1.40.yaml#L7715\r\n\r\n<!--\r\nBriefly describe the problem you are having in a few paragraphs.\r\n-->\r\n\r\n**Steps to reproduce the issue:**\r\n1. `curl --unix-socket /var/run/docker.sock localhost/version`\r\n\r\n**Describe the results you received:**\r\n```\r\n{\r\n  \"Platform\": {\r\n    \"Name\": \"Docker Engine - Community\"\r\n  },\r\n  \"Components\": [\r\n    {\r\n      \"Name\": \"Engine\",\r\n      \"Version\": \"19.03.12\",\r\n      \"Details\": {\r\n        \"ApiVersion\": \"1.40\",\r\n        \"Arch\": \"amd64\",\r\n        \"BuildTime\": \"2020-06-22T15:44:07.000000000+00:00\",\r\n        \"Experimental\": \"false\",\r\n        \"GitCommit\": \"48a66213fe\",\r\n        \"GoVersion\": \"go1.13.10\",\r\n        \"KernelVersion\": \"5.3.0-62-generic\",\r\n        \"MinAPIVersion\": \"1.12\",\r\n        \"Os\": \"linux\"\r\n      }\r\n    },\r\n    ...\r\n  ],\r\n  \"Version\": \"19.03.12\",\r\n  \"ApiVersion\": \"1.40\",\r\n  \"MinAPIVersion\": \"1.12\",\r\n  \"GitCommit\": \"48a66213fe\",\r\n  \"GoVersion\": \"go1.13.10\",\r\n  \"Os\": \"linux\",\r\n  \"Arch\": \"amd64\",\r\n  \"KernelVersion\": \"5.3.0-62-generic\",\r\n  \"BuildTime\": \"2020-06-22T15:44:07.000000000+00:00\"\r\n}\r\n```\r\n\r\n**Describe the results you expected:**\r\nLooks like document is wrong.\r\nWe should update document?\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient: Docker Engine - Community\r\n Version:           19.03.12\r\n API version:       1.40\r\n Go version:        go1.13.10\r\n Git commit:        48a66213fe\r\n Built:             Mon Jun 22 15:45:36 2020\r\n OS/Arch:           linux/amd64\r\n Experimental:      false\r\n\r\nServer: Docker Engine - Community\r\n Engine:\r\n  Version:          19.03.12\r\n  API version:      1.40 (minimum version 1.12)\r\n  Go version:       go1.13.10\r\n  Git commit:       48a66213fe\r\n  Built:            Mon Jun 22 15:44:07 2020\r\n  OS/Arch:          linux/amd64\r\n  Experimental:     false\r\n containerd:\r\n  Version:          1.2.13\r\n  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429\r\n runc:\r\n  Version:          1.0.0-rc10\r\n  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd\r\n docker-init:\r\n  Version:          0.18.0\r\n  GitCommit:        fec3683\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nClient: Docker Engine - Community\r\n Version:           19.03.12\r\n API version:       1.40\r\n Go version:        go1.13.10\r\n Git commit:        48a66213fe\r\n Built:             Mon Jun 22 15:45:36 2020\r\n OS/Arch:           linux/amd64\r\n Experimental:      false\r\n\r\nServer: Docker Engine - Community\r\n Engine:\r\n  Version:          19.03.12\r\n  API version:      1.40 (minimum version 1.12)\r\n  Go version:       go1.13.10\r\n  Git commit:       48a66213fe\r\n  Built:            Mon Jun 22 15:44:07 2020\r\n  OS/Arch:          linux/amd64\r\n  Experimental:     false\r\n containerd:\r\n  Version:          1.2.13\r\n  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429\r\n runc:\r\n  Version:          1.0.0-rc10\r\n  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd\r\n docker-init:\r\n  Version:          0.18.0\r\n  GitCommit:        fec3683\r\n[I] docker.vim )\r\n[I] docker.vim ) docker info\r\nClient:\r\n Debug Mode: false\r\n\r\nServer:\r\n Containers: 2\r\n  Running: 1\r\n  Paused: 0\r\n  Stopped: 1\r\n Images: 52\r\n Server Version: 19.03.12\r\n Storage Driver: overlay2\r\n  Backing Filesystem: extfs\r\n  Supports d_type: true\r\n  Native Overlay Diff: true\r\n Logging Driver: json-file\r\n Cgroup Driver: cgroupfs\r\n Plugins:\r\n  Volume: local\r\n  Network: bridge host ipvlan macvlan null overlay\r\n  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog\r\n Swarm: inactive\r\n Runtimes: runc\r\n Default Runtime: runc\r\n Init Binary: docker-init\r\n containerd version: 7ad184331fa3e55e52b890ea95e65ba581ae3429\r\n runc version: dc9208a3303feef5b3839f4323d9beb36df0a9dd\r\n init version: fec3683\r\n Security Options:\r\n  apparmor\r\n  seccomp\r\n   Profile: default\r\n Kernel Version: 5.3.0-62-generic\r\n Operating System: Ubuntu 18.04.4 LTS\r\n OSType: linux\r\n Architecture: x86_64\r\n CPUs: 8\r\n Total Memory: 31.09GiB\r\n Name: thinkpad\r\n ID: EKKH:UC2C:RDMA:JDP2:KDIG:GW2W:T2H3:S3LT:MWNI:D5YG:X24P:K2DC\r\n Docker Root Dir: /var/lib/docker\r\n Debug Mode: false\r\n Username: skanehira\r\n Registry: https://index.docker.io/v1/\r\n Labels:\r\n Experimental: false\r\n Insecure Registries:\r\n  127.0.0.0/8\r\n Live Restore Enabled: false\r\n\r\nWARNING: No swap limit support\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\nOS: Ubuntu 18.04.01"},{"labels":["api",null,null],"text":"<!--\r\nIf you are reporting a new issue, make sure that we do not have any duplicates\r\nalready open. You can ensure this by searching the issue list for this\r\nrepository. If there is a duplicate, please close your issue and add a comment\r\nto the existing issue instead.\r\n\r\nIf you suspect your issue is a bug, please edit your issue description to\r\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\r\ninformation within 7 days, we cannot debug your issue and will close it. We\r\nwill, however, reopen it if you later provide the information.\r\n\r\nFor more information about reporting issues, see\r\nhttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues\r\n\r\n---------------------------------------------------\r\nGENERAL SUPPORT INFORMATION\r\n---------------------------------------------------\r\n\r\nThe GitHub issue tracker is for bug reports and feature requests.\r\nGeneral support for **docker** can be found at the following locations:\r\n\r\n- Docker Support Forums - https://forums.docker.com\r\n- Slack - community.docker.com #general channel\r\n- Post a question on StackOverflow, using the Docker tag\r\n\r\nGeneral support for **moby** can be found at the following locations:\r\n\r\n- Moby Project Forums - https://forums.mobyproject.org\r\n- Slack - community.docker.com #moby-project channel\r\n- Post a question on StackOverflow, using the Moby tag\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\n**Description**\r\n\r\n<!--\r\nBriefly describe the problem you are having in a few paragraphs.\r\n-->\r\n\r\nHello !\r\n\r\nI have a issue with the Engine API.\r\nWhen I create a service using the API, the service label is created with weird escaped characters instead of my parenthesis. \r\n\r\n**Steps to reproduce the issue:**\r\n1. Create a service with the API (formatted in JSON) and add parenthesis to a label.\r\n\r\n**Received result:**\r\n```\r\n \"traefik.http.routers.test.rule\": \"Headers%28`X-INSTANCE-ID`,`test`%29\",\r\n```\r\n\r\n**Expected result:**\r\n```\r\n \"traefik.http.routers.test.rule\": \"Headers(`X-INSTANCE-ID`,`test`)\",\r\n```\r\n**Additional information:**\r\nI've tried on two different servers, same bug...\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient: Docker Engine - Community\r\n Version:           19.03.3\r\n API version:       1.40\r\n Go version:        go1.12.10\r\n Git commit:        a872fc2f86\r\n Built:             Tue Oct  8 00:59:36 2019\r\n OS/Arch:           linux/amd64\r\n Experimental:      false\r\n\r\nServer: Docker Engine - Community\r\n Engine:\r\n  Version:          19.03.3\r\n  API version:      1.40 (minimum version 1.12)\r\n  Go version:       go1.12.10\r\n  Git commit:       a872fc2f86\r\n  Built:            Tue Oct  8 00:58:08 2019\r\n  OS/Arch:          linux/amd64\r\n  Experimental:     false\r\n containerd:\r\n  Version:          1.2.10\r\n  GitCommit:        b34a5c8af56e510852c35414db4c1f4fa6172339\r\n runc:\r\n  Version:          1.0.0-rc8+dev\r\n  GitCommit:        3e425f80a8c931f88e6d94a8c831b9d5aa481657\r\n docker-init:\r\n  Version:          0.18.0\r\n  GitCommit:        fec3683\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nClient:\r\n Debug Mode: false\r\n\r\nServer:\r\n Containers: 2\r\n  Running: 2\r\n  Paused: 0\r\n  Stopped: 0\r\n Images: 170\r\n Server Version: 19.03.3\r\n Storage Driver: overlay2\r\n  Backing Filesystem: extfs\r\n  Supports d_type: true\r\n  Native Overlay Diff: true\r\n Logging Driver: json-file\r\n Cgroup Driver: cgroupfs\r\n Plugins:\r\n  Volume: local\r\n  Network: bridge host ipvlan macvlan null overlay\r\n  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog\r\n Swarm: active\r\n  NodeID: szgmaj5mz8l5vffvfglf7kwxi\r\n  Is Manager: true\r\n  ClusterID: gqno1oih4phd70sciix2i10t7\r\n  Managers: 1\r\n  Nodes: 1\r\n  Default Address Pool: 10.0.0.0/8\r\n  SubnetSize: 24\r\n  Data Path Port: 4789\r\n  Orchestration:\r\n   Task History Retention Limit: 5\r\n  Raft:\r\n   Snapshot Interval: 10000\r\n   Number of Old Snapshots to Retain: 0\r\n   Heartbeat Tick: 1\r\n   Election Tick: 10\r\n  Dispatcher:\r\n   Heartbeat Period: 5 seconds\r\n  CA Configuration:\r\n   Expiry Duration: 3 months\r\n   Force Rotate: 0\r\n  Autolock Managers: false\r\n  Root Rotation In Progress: false\r\n  Node Address: 192.168.152.129\r\n  Manager Addresses:\r\n   192.168.152.129:2377\r\n Runtimes: runc\r\n Default Runtime: runc\r\n Init Binary: docker-init\r\n containerd version: b34a5c8af56e510852c35414db4c1f4fa6172339\r\n runc version: 3e425f80a8c931f88e6d94a8c831b9d5aa481657\r\n init version: fec3683\r\n Security Options:\r\n  seccomp\r\n   Profile: default\r\n Kernel Version: 4.9.0-7-amd64\r\n Operating System: Debian GNU/Linux 9 (stretch)\r\n OSType: linux\r\n Architecture: x86_64\r\n CPUs: 2\r\n Total Memory: 3.845GiB\r\n Name: bde-backoffice\r\n ID: MPE2:TUTT:TGYF:5XDK:6UQK:RJCG:E2DD:3QW6:DO5Q:UC6V:CNUV:RT6O\r\n Docker Root Dir: /var/lib/docker\r\n Debug Mode: false\r\n Registry: https://index.docker.io/v1/\r\n Labels:\r\n Experimental: false\r\n Insecure Registries:\r\n  127.0.0.0/8\r\n Live Restore Enabled: false\r\n\r\nWARNING: No swap limit support\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n\r\nDebian 9.6 x64\r\n"},{"labels":["api",null],"text":"<!--\r\nIf you are reporting a new issue, make sure that we do not have any duplicates\r\nalready open. You can ensure this by searching the issue list for this\r\nrepository. If there is a duplicate, please close your issue and add a comment\r\nto the existing issue instead.\r\n\r\nIf you suspect your issue is a bug, please edit your issue description to\r\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\r\ninformation within 7 days, we cannot debug your issue and will close it. We\r\nwill, however, reopen it if you later provide the information.\r\n\r\nFor more information about reporting issues, see\r\nhttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues\r\n\r\n---------------------------------------------------\r\nGENERAL SUPPORT INFORMATION\r\n---------------------------------------------------\r\n\r\nThe GitHub issue tracker is for bug reports and feature requests.\r\nGeneral support for **docker** can be found at the following locations:\r\n\r\n- Docker Support Forums - https://forums.docker.com\r\n- Slack - community.docker.com #general channel\r\n- Post a question on StackOverflow, using the Docker tag\r\n\r\nGeneral support for **moby** can be found at the following locations:\r\n\r\n- Moby Project Forums - https://forums.mobyproject.org\r\n- Slack - community.docker.com #moby-project channel\r\n- Post a question on StackOverflow, using the Moby tag\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\n**Description**\r\n\r\nDocker is expected to unshare cgroup namespace by default on cgroup v2 hosts.\r\nHowever, the cgroup namespace is not unshared when a container was created by an older API client.\r\n\r\n\r\n**Steps to reproduce the issue:**\r\nInspect the host cgroup namespace (4026531835):\r\n```console\r\n$ sudo ls -l /proc/1/ns/cgroup\r\nlrwxrwxrwx 1 root root 0 Jun  5 16:36 /proc/1/ns/cgroup -> 'cgroup:[4026531835]'\r\n```\r\n\r\nAPI 1.41 creates a container with a new namespace (4026533000) as expected:\r\n```console\r\n$ DOCKER_API_VERSION=1.41 docker run --rm alpine ls -l /proc/1/ns/cgroup\r\nlrwxrwxrwx    1 root     root             0 Jun  5 07:36 /proc/1/ns/cgroup -> cgroup:[4026533000]\r\n```\r\n\r\nOTOH API 1.40 creates a container with the host cgroup namespace (4026531835):\r\n```console\r\n$ DOCKER_API_VERSION=1.40 docker run --rm alpine ls -l /proc/1/ns/cgroup\r\nlrwxrwxrwx    1 root     root             0 Jun  5 07:36 /proc/1/ns/cgroup -> cgroup:[4026531835]\r\n```\r\n\r\n**Describe the results you received:**\r\nAPI 1.40 creates a container with the host cgroup namespace (4026531835).\r\n\r\n**Describe the results you expected:**\r\nA new cgroup namespace should be always created by default on cgroup v2 hosts..\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:           20.03.0-dev\r\n API version:       1.41\r\n Go version:        go1.13.11\r\n Git commit:        8f14db8df\r\n Built:             Fri Jun  5 07:30:25 2020\r\n OS/Arch:           linux/amd64\r\n Context:           default\r\n Experimental:      true\r\n\r\nServer:\r\n Engine:\r\n  Version:          dev\r\n  API version:      1.41 (minimum version 1.12)\r\n  Go version:       go1.13.11\r\n  Git commit:       fa38a6cd21\r\n  Built:            Fri Jun  5 07:28:36 2020\r\n  OS/Arch:          linux/amd64\r\n  Experimental:     true\r\n containerd:\r\n  Version:          v1.4.0-beta.1-18-g38cb1c1a\r\n  GitCommit:        38cb1c1a54e3180edd29933974d715b69334f0f1\r\n runc:\r\n  Version:          1.0.0-rc10+dev\r\n  GitCommit:        2a0466958d9af23af2ad12bd79d06ed0af4091e2\r\n docker-init:\r\n  Version:          0.18.0\r\n  GitCommit:        fec3683\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nClient:\r\n Context:    default\r\n Debug Mode: false\r\n Plugins:\r\n  buildx: Build with BuildKit (Docker Inc., v0.4.1)\r\n\r\nServer:\r\n Containers: 1\r\n  Running: 1\r\n  Paused: 0\r\n  Stopped: 0\r\n Images: 4\r\n Server Version: dev\r\n Storage Driver: overlay2\r\n  Backing Filesystem: extfs\r\n  Supports d_type: true\r\n  Native Overlay Diff: true\r\n Logging Driver: json-file\r\n Cgroup Driver: systemd\r\n Cgroup Version: 2\r\n Plugins:\r\n  Volume: local\r\n  Network: bridge host ipvlan macvlan null overlay\r\n  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog\r\n Swarm: inactive\r\n Runtimes: runc\r\n Default Runtime: runc\r\n Init Binary: docker-init\r\n containerd version: 38cb1c1a54e3180edd29933974d715b69334f0f1\r\n runc version: 2a0466958d9af23af2ad12bd79d06ed0af4091e2\r\n init version: fec3683\r\n Security Options:\r\n  apparmor\r\n  seccomp\r\n   Profile: default\r\n  cgroupns\r\n Kernel Version: 5.4.0-33-generic\r\n Operating System: Ubuntu 20.04 LTS\r\n OSType: linux\r\n Architecture: x86_64\r\n CPUs: 2\r\n Total Memory: 7.748GiB\r\n Name: suda-ws01\r\n ID: E2YB:EGZO:6BNW:EPHS:4WFQ:EIDV:ZZ6D:QBZK:6673:CIOR:DLZ6:SI3D\r\n Docker Root Dir: /var/lib/docker\r\n Debug Mode: true\r\n  File Descriptors: 32\r\n  Goroutines: 56\r\n  System Time: 2020-06-05T16:42:51.430978282+09:00\r\n  EventsListeners: 0\r\n Username: akihirosuda\r\n Registry: https://index.docker.io/v1/\r\n Labels:\r\n Experimental: true\r\n Insecure Registries:\r\n  127.0.0.0/8\r\n Live Restore Enabled: false\r\n\r\nWARNING: No kernel memory limit support\r\nWARNING: No kernel memory TCP limit support\r\nWARNING: No oom kill disable support\r\nWARNING: Support for cgroup v2 is experimental\r\n```\r\n\r\n"},{"labels":["api",null,null],"text":"---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\n**Description**\r\nCurrently using the Docker SDK for GO to build and push images to ECR on Amazon. Whenever i call ImagePush, if i don't take io.ReadCloser and read from it to the end, my images will not appear on ECR. If i do something simple as:\r\n\r\n```go\r\nio.Copy(ioutil.Discard, imagePushResult)\r\n```\r\nit works. \r\n\r\n**Steps to reproduce the issue:**\r\n1. Call ImagePush to push image to ECR repo (have not tried with other repos)\r\n2. Return after the call and don't bother with the io.ReadCloser returned by ImagePush\r\n3. The image will not appear on the repository\r\n\r\n**Describe the results you received:**\r\n\r\n\r\n**Describe the results you expected:**\r\nI expected the image to be on the repo regardless of how i handle the retured io.ReasCloser. \r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient: Docker Engine - Community\r\n Version:           19.03.5\r\n API version:       1.40\r\n Go version:        go1.12.12\r\n Git commit:        633a0ea\r\n Built:             Wed Nov 13 07:22:34 2019\r\n OS/Arch:           darwin/amd64\r\n Experimental:      false\r\n\r\nServer: Docker Engine - Community\r\n Engine:\r\n  Version:          19.03.5\r\n  API version:      1.40 (minimum version 1.12)\r\n  Go version:       go1.12.12\r\n  Git commit:       633a0ea\r\n  Built:            Wed Nov 13 07:29:19 2019\r\n  OS/Arch:          linux/amd64\r\n  Experimental:     false\r\n containerd:\r\n  Version:          v1.2.10\r\n  GitCommit:        b34a5c8af56e510852c35414db4c1f4fa6172339\r\n runc:\r\n  Version:          1.0.0-rc8+dev\r\n  GitCommit:        3e425f80a8c931f88e6d94a8c831b9d5aa481657\r\n docker-init:\r\n  Version:          0.18.0\r\n  GitCommit:        fec3683\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nClient:\r\n Debug Mode: false\r\n\r\nServer:\r\n Containers: 19\r\n  Running: 0\r\n  Paused: 0\r\n  Stopped: 19\r\n Images: 5\r\n Server Version: 19.03.5\r\n Storage Driver: overlay2\r\n  Backing Filesystem: extfs\r\n  Supports d_type: true\r\n  Native Overlay Diff: true\r\n Logging Driver: json-file\r\n Cgroup Driver: cgroupfs\r\n Plugins:\r\n  Volume: local\r\n  Network: bridge host ipvlan macvlan null overlay\r\n  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog\r\n Swarm: inactive\r\n Runtimes: runc\r\n Default Runtime: runc\r\n Init Binary: docker-init\r\n containerd version: b34a5c8af56e510852c35414db4c1f4fa6172339\r\n runc version: 3e425f80a8c931f88e6d94a8c831b9d5aa481657\r\n init version: fec3683\r\n Security Options:\r\n  seccomp\r\n   Profile: default\r\n Kernel Version: 4.19.76-linuxkit\r\n Operating System: Docker Desktop\r\n OSType: linux\r\n Architecture: x86_64\r\n CPUs: 4\r\n Total Memory: 1.943GiB\r\n Name: docker-desktop\r\n ID: SGU4:RG3S:FZPA:P67C:J3PQ:3WV5:T522:DART:YO5Y:J2VI:MSLA:JY7V\r\n Docker Root Dir: /var/lib/docker\r\n Debug Mode: true\r\n  File Descriptors: 33\r\n  Goroutines: 60\r\n  System Time: 2020-02-22T19:29:09.8248016Z\r\n  EventsListeners: 3\r\n HTTP Proxy: gateway.docker.internal:3128\r\n HTTPS Proxy: gateway.docker.internal:3129\r\n Registry: https://index.docker.io/v1/\r\n Labels:\r\n Experimental: false\r\n Insecure Registries:\r\n  127.0.0.0/8\r\n Live Restore Enabled: false\r\n Product License: Community Engine\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\nPushing the images to AWS.\r\n"},{"labels":["api"],"text":"<!-- Download Docker Desktop 'Edge' (latest build) here: https://hub.docker.com/editions/community/docker-ce-desktop-windows -->\r\n  - [x] I have tried with the latest version of my channel (Stable or Edge)\r\n  - [x] I have uploaded Diagnostics\r\n  - Diagnostics ID: 17E86123-291D-4E3C-8572-433BD0017ADA/20200108195342\r\n\r\n### Expected behavior\r\nchunk contains CRLF at the end of stream\r\n\r\n### Actual behavior\r\nthere is only LF on windows\r\n\r\n### Steps to reproduce the behavior\r\nsee https://github.com/docker-java/docker-java/issues/698#issuecomment-572228590 for steps to reproduce\r\n\r\nEDIT: I have updated original \"docker-java\" issue, seems no problem anymore. Sorry for that."},{"labels":["api",null,null],"text":"<!--\r\nIf you are reporting a new issue, make sure that we do not have any duplicates\r\nalready open. You can ensure this by searching the issue list for this\r\nrepository. If there is a duplicate, please close your issue and add a comment\r\nto the existing issue instead.\r\n\r\nIf you suspect your issue is a bug, please edit your issue description to\r\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\r\ninformation within 7 days, we cannot debug your issue and will close it. We\r\nwill, however, reopen it if you later provide the information.\r\n\r\nFor more information about reporting issues, see\r\nhttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues\r\n\r\n---------------------------------------------------\r\nGENERAL SUPPORT INFORMATION\r\n---------------------------------------------------\r\n\r\nThe GitHub issue tracker is for bug reports and feature requests.\r\nGeneral support for **docker** can be found at the following locations:\r\n\r\n- Docker Support Forums - https://forums.docker.com\r\n- Slack - community.docker.com #general channel\r\n- Post a question on StackOverflow, using the Docker tag\r\n\r\nGeneral support for **moby** can be found at the following locations:\r\n\r\n- Moby Project Forums - https://forums.mobyproject.org\r\n- Slack - community.docker.com #moby-project channel\r\n- Post a question on StackOverflow, using the Moby tag\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\n**Description**\r\n\r\nDocker API v1.37 \"auth\" endpoint return an empty `IdentityToken`\r\n\r\n<!--\r\nBriefly describe the problem you are having in a few paragraphs.\r\n-->\r\nI'm calling the Docker API `auth` endpoint from the local host\r\n\r\n`curl -X POST http://localhost:2375/v1.37/auth -H \"Content-Type: application/json\" -d '{\"username\":\"AWS\", \"password\": \"'$password'\", \"serveraddress\": \"https://<account ID>.dkr.ecr.us-east-2.amazonaws.com/\"}'`\r\nI'm getting the following output back:\r\n\r\n`{\"IdentityToken\":\"\",\"Status\":\"Login Succeeded\"}`\r\n\r\n**Steps to reproduce the issue:**\r\n1.\r\n2.\r\n3.\r\n\r\n**Describe the results you received:**\r\nI'm getting back `{\"IdentityToken\":\"\",\"Status\":\"Login Succeeded\"}`\r\n\r\n**Describe the results you expected:**\r\nI'm expecting to receive back an identity `IdentityToken`\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:           18.09.3\r\n API version:       1.39\r\n Go version:        go1.10.8\r\n Git commit:        774a1f4\r\n Built:             Thu Feb 28 06:40:58 2019\r\n OS/Arch:           linux/amd64\r\n Experimental:      false\r\n\r\nServer: Docker Engine - Community\r\n Engine:\r\n  Version:          18.09.3\r\n  API version:      1.39 (minimum version 1.12)\r\n  Go version:       go1.10.8\r\n  Git commit:       774a1f4\r\n  Built:            Thu Feb 28 05:59:55 2019\r\n  OS/Arch:          linux/amd64\r\n  Experimental:     false\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 1\r\n Running: 0\r\n Paused: 0\r\n Stopped: 1\r\nImages: 2\r\nServer Version: 18.09.3\r\nStorage Driver: overlay2\r\n Backing Filesystem: extfs\r\n Supports d_type: true\r\n Native Overlay Diff: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\n Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog\r\nSwarm: inactive\r\nRuntimes: nvidia runc\r\nDefault Runtime: nvidia\r\nInit Binary: docker-init\r\ncontainerd version: e6b3f5632f50dbc4e9cb6288d911bf4f5e95b18e\r\nrunc version: 12f6a991201fdb8f82579582d5e00e28fba06d0a-dirty\r\ninit version: fec3683\r\nSecurity Options:\r\n apparmor\r\n seccomp\r\n  Profile: default\r\nKernel Version: 4.4.0-1060-aws\r\nOperating System: Ubuntu 16.04.4 LTS\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 2\r\nTotal Memory: 7.795GiB\r\nName: ip-10-220-3-78\r\nID: YZ6T:HXM4:XJNW:GUDY:XA6J:U2KX:R7CJ:TQHE:TPXY:HCNA:R4VL:M3AZ\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): false\r\nRegistry: https://index.docker.io/v1/\r\nLabels:\r\nExperimental: false\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\nProduct License: Community Engine\r\n\r\nWARNING: API is accessible on http://0.0.0.0:2375 without encryption.\r\n         Access to the remote API is equivalent to root access on the host. Refer\r\n         to the 'Docker daemon attack surface' section in the documentation for\r\n         more information: https://docs.docker.com/engine/security/security/#docker-daemon-attack-surface\r\nWARNING: No swap limit support\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\nI'm running on an AWS EC2 instance which has full access to ECR repos through an instance profile"},{"labels":["api",null],"text":"There were two process running. They all used docker python SDK to connect to the local docker engine(18.03). One process would to remove a container which met an error cause the container was running ( this is another issue), almost at the same time, another process would to create a container.  Configs of these two container do not conflict . Then I get an error like this:\r\n\r\n```\r\n Traceback (most recent call last):\r\n  File \"/usr/local/lib/python3.5/dist-packages/docker/api/client.py\", line 229, in _raise_for_status\r\n    response.raise_for_status()\r\n  File \"/usr/local/lib/python3.5/dist-packages/requests/models.py\", line 939, in raise_for_status\r\n    raise HTTPError(http_error_msg, response=self)\r\nrequests.exceptions.HTTPError: 409 Client Error: Conflict for url: http://192.168.1.120:2375/v1.35/containers/create\r\n```\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"worker.py\", line 205, in process_job\r\n    **job.get('other', {}) \r\n  File \"/usr/local/lib/python3.5/dist-packages/docker/api/container.py\", line 411, in create_container\r\n    return self.create_container_from_config(config, name)\r\n  File \"/usr/local/lib/python3.5/dist-packages/docker/api/container.py\", line 422, in create_container_from_config\r\n    return self._result(res, True)\r\n  File \"/usr/local/lib/python3.5/dist-packages/docker/api/client.py\", line 235, in _result\r\n    self._raise_for_status(response)\r\n  File \"/usr/local/lib/python3.5/dist-packages/docker/api/client.py\", line 231, in _raise_for_status\r\n    raise create_api_error_from_http_exception(e)\r\n  File \"/usr/local/lib/python3.5/dist-packages/docker/errors.py\", line 31, in create_api_error_from_http_exception\r\n    raise cls(e, response=response, explanation=explanation)\r\ndocker.errors.APIError: 409 Client Error: Conflict (\"You cannot remove a running container 9c31e308532433a712e9e56792726678ca78ff32e7de116097d27c243ed018a0. Stop the container before attempting removal or force remove\")\r\n```\r\n\r\n It is normal to perform these two operations at different times which only got  an 409 error when to  remove a running container. Looks like the docker engine or the API server doesn't support concurrency, does it?"},{"labels":["api",null],"text":"<!--\r\nIf you are reporting a new issue, make sure that we do not have any duplicates\r\nalready open. You can ensure this by searching the issue list for this\r\nrepository. If there is a duplicate, please close your issue and add a comment\r\nto the existing issue instead.\r\n\r\nIf you suspect your issue is a bug, please edit your issue description to\r\ninclude the BUG REPORT INFORMATION shown below. If you fail to provide this\r\ninformation within 7 days, we cannot debug your issue and will close it. We\r\nwill, however, reopen it if you later provide the information.\r\n\r\nFor more information about reporting issues, see\r\nhttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues\r\n\r\n---------------------------------------------------\r\nGENERAL SUPPORT INFORMATION\r\n---------------------------------------------------\r\n\r\nThe GitHub issue tracker is for bug reports and feature requests.\r\nGeneral support for **docker** can be found at the following locations:\r\n\r\n- Docker Support Forums - https://forums.docker.com\r\n- Slack - community.docker.com #general channel\r\n- Post a question on StackOverflow, using the Docker tag\r\n\r\nGeneral support for **moby** can be found at the following locations:\r\n\r\n- Moby Project Forums - https://forums.mobyproject.org\r\n- Slack - community.docker.com #moby-project channel\r\n- Post a question on StackOverflow, using the Moby tag\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\n**Description**\r\n\r\nWhen attempting to build images using the docker engine API (API v1.39, Docker v18.09.1), I am greeted with a 404 page not found response.\r\n\r\n<!--\r\nBriefly describe the problem you are having in a few paragraphs.\r\n-->\r\n\r\n**Steps to reproduce the issue:**\r\n1. Make an API request to POST `/build` or POST `/v1.39/build`\r\n\r\n**Describe the results you received:**\r\n\r\nI received a 404 status code and a `{ \"message\": \"page not found\" }` response body.\r\n\r\n**Describe the results you expected:**\r\n\r\nI expected docker to start building the image I provided.\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n```\r\nClient:\r\n Version:           18.09.1\r\n API version:       1.39\r\n Go version:        go1.10.6\r\n Git commit:        4c52b90\r\n Built:             Wed Jan  9 19:35:31 2019\r\n OS/Arch:           linux/amd64\r\n Experimental:      false\r\n\r\nServer: Docker Engine - Community\r\n Engine:\r\n  Version:          18.09.1\r\n  API version:      1.39 (minimum version 1.12)\r\n  Go version:       go1.10.6\r\n  Git commit:       4c52b90\r\n  Built:            Wed Jan  9 19:02:44 2019\r\n  OS/Arch:          linux/amd64\r\n  Experimental:     false\r\n\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 2\r\n Running: 0\r\n Paused: 0\r\n Stopped: 2\r\nImages: 25\r\nServer Version: 18.09.1\r\nStorage Driver: overlay2\r\n Backing Filesystem: extfs\r\n Supports d_type: true\r\n Native Overlay Diff: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\n Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: 9754871865f7fe2f4e74d43e2fc7ccd237edcbce\r\nrunc version: 96ec2177ae841256168fcf76954f7177af9446eb\r\ninit version: fec3683\r\nSecurity Options:\r\n apparmor\r\n seccomp\r\n  Profile: default\r\nKernel Version: 4.15.0-43-generic\r\nOperating System: Ubuntu 18.04.1 LTS\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 8\r\nTotal Memory: 15.62GiB\r\nName: printer-MS-7A59\r\nID: VKKZ:CZRV:W4G4:63AX:DQH4:UVIT:GOXU:RCJQ:UTRD:EWZ4:4ILG:Y42I\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): false\r\nRegistry: https://index.docker.io/v1/\r\nLabels:\r\nExperimental: false\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\nProduct License: Community Engine\r\n\r\nWARNING: API is accessible on http://0.0.0.0:4243 without encryption.\r\n         Access to the remote API is equivalent to root access on the host. Refer\r\n         to the 'Docker daemon attack surface' section in the documentation for\r\n         more information: https://docs.docker.com/engine/security/security/#docker-daemon-attack-surface\r\nWARNING: No swap limit support\r\n\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\nphysical"},{"labels":["api",null],"text":"**Description**\r\n\r\nDocker API returns null value for Warnings field.\r\n\r\nAccording to a definition it probably should never be null. It has `x-nullable: false\r\n\r\nhttps://github.com/moby/moby/blob/master/api/swagger.yaml#L4659-L4676\r\n\r\n**Steps to reproduce the issue:**\r\n\r\n1. Send correct, /containers/create request to API https://docs.docker.com/engine/api/v1.37/#operation/ContainerCreate\r\n2. Check response\r\n\r\n\r\nExample response's body:\r\n```json\r\n{\r\n    \"Id\": \"6ce9cb39c1d6a905c0fc7909235b74491d5a0f184ff097bb73ffe9a30cd7743a\",\r\n    \"Warnings\": null\r\n}\r\n```\r\n\r\ninstead of:\r\n```json\r\n{\r\n    \"Id\": \"6ce9cb39c1d6a905c0fc7909235b74491d5a0f184ff097bb73ffe9a30cd7743a\",\r\n    \"Warnings\": []\r\n}\r\n```\r\n"},{"labels":["api",null,null],"text":"I'd like to propose eventually adding a new Engine REST API which exposes buildkit's `Solve` more directly than `/build` which is focused around the dockerfile frontend specific use case and has some quirks due to that (and for legacy/historical reasons).\r\n\r\nI've prototyped running a custom frontend via the `/build` API but it's a bit hacky and not terribly satisfactory (injecting a stub `Dockerfile` with a `syntax` directive in it, passing options by mapping to various `Dockerfile`-ish options etc). \r\n\r\nOther potentially interesting things  to expose are local exporter, debugger, shared session, multiple local sources and the ability to run a frontend client side (cf `Build` rather than `Solve` in the buildkit control API).\r\n\r\nIt's possible we could just extend on the current `/build` API to cover more underlying functionality (e.g. add a `Frontend` field to it), enhance the format of the returned body to remove the legacy framing etc.\r\n\r\nOr we could perhaps expose a new endpoint mapping the underlying `Solve` call a little more directly that the `/build` endpoint, with most of the options passed through or lightly adjusted/filtered (e.g maybe the full set of `Exporter`/`ExporterAttrs` flexibility shouldn't be exposed?). The `Session` side would be the same as with `/build` (an upgraded conn to `/session`). The body returned would be the Status stream, I guess as a direct JSON stream of `StatusResponse` rather than wrapping in a `JSONMessage` like `/build` had to do (for compat reasons I suppose). I'm not entirely sure about `SolveResponse`, so I guess maybe there needs to be a little more structure to the body stream, but ideally not `JSONMessage`, just a simple union type map.\r\n\r\nA possibly simple (but IMHO not at all ideal) would be a simple API end point which opens the entire control API gRPC via a /session-like endpoint. I don't think that is really what we want though (control API is not considered stable, might be too much low level power being exposed).\r\n\r\n/cc @tonistiigi @tiborvass "},{"labels":["api",null,null,null],"text":"There are a HostConfig.DiskQuota option with description \"Disk limit (in bytes).\" on https://docs.docker.com/engine/api/v1.37/#operation/ContainerCreate.\r\n\r\nBut, unfortunately, I can't find any other information about what does it mean. What constrains of use does it have? Is it can be used on all platfroms/storage drivers? What would be if this limit will be exceeded?"},{"labels":["api",null,null,null,null],"text":"(as reported by @waseemshahwan in https://github.com/moby/moby/issues/31909#issuecomment-435742609)\r\n\r\nLooks like a regression was introduced somewhere between Docker 17.07 and 17.09.1, causing the status code for a \"conflict\" to change from a 409 to a 500;\r\n\r\n\r\nTo reproduce; run a \"service create\" request _twice_ (second time should return a \"conflict\";\r\n\r\n```bash\r\ncurl -v \\\r\n  --unix-socket /var/run/docker.sock \\\r\n  -X POST \\\r\n  \"http://localhost/v1.30/services/create\" \\\r\n  -H \"Content-Type: application/json\" \\\r\n  -d '{\"EndpointSpec\":{\"Mode\":\"vip\"},\"Labels\":{},\"Mode\":{\"Replicated\":{}},\"Name\":\"testing\",\"TaskTemplate\":{\"ContainerSpec\":{\"DNSConfig\":{},\"Image\":\"nginx:alpine@sha256:ae5da813f8ad7fa785d7668f0b018ecc8c3a87331527a61d83b3b5e816a0f03c\",\"Init\":false},\"ForceUpdate\":0,\"Placement\":{\"Platforms\":[{\"Architecture\":\"amd64\",\"OS\":\"linux\"},{\"OS\":\"linux\"},{\"Architecture\":\"arm64\",\"OS\":\"linux\"},{\"Architecture\":\"386\",\"OS\":\"linux\"},{\"Architecture\":\"ppc64le\",\"OS\":\"linux\"},{\"Architecture\":\"s390x\",\"OS\":\"linux\"}]},\"Resources\":{\"Limits\":{},\"Reservations\":{}}}}'\r\n```\r\n\r\n\r\nOn Docker 17.07.0-ce\r\n\r\n```\r\n> POST /v1.30/services/create HTTP/1.1\r\n> Host: localhost\r\n> User-Agent: curl/7.61.1\r\n> Accept: */*\r\n> Content-Type: application/json\r\n> Content-Length: 536\r\n> \r\n* upload completely sent off: 536 out of 536 bytes\r\n< HTTP/1.1 409 Conflict\r\n< Api-Version: 1.31\r\n< Content-Type: application/json\r\n< Docker-Experimental: false\r\n< Ostype: linux\r\n< Server: Docker/17.07.0-ce (linux)\r\n< Date: Mon, 05 Nov 2018 16:10:58 GMT\r\n< Content-Length: 86\r\n< \r\n{\"message\":\"rpc error: code = Unknown desc = name conflicts with an existing object\"}\r\n```\r\n\r\nOn Docker 17.09.1-ce\r\n\r\n```\r\n> POST /v1.30/services/create HTTP/1.1\r\n> Host: localhost\r\n> User-Agent: curl/7.61.1\r\n> Accept: */*\r\n> Content-Type: application/json\r\n> Content-Length: 536\r\n> \r\n* upload completely sent off: 536 out of 536 bytes\r\n< HTTP/1.1 500 Internal Server Error\r\n< Api-Version: 1.32\r\n< Content-Type: application/json\r\n< Docker-Experimental: false\r\n< Ostype: linux\r\n< Server: Docker/17.09.1-ce (linux)\r\n< Date: Mon, 05 Nov 2018 16:11:59 GMT\r\n< Content-Length: 86\r\n< \r\n{\"message\":\"rpc error: code = Unknown desc = name conflicts with an existing object\"}\r\n```\r\n\r\nOn 18.06.1-ce (still reproduces)\r\n\r\n```\r\n*   Trying /var/run/docker.sock...\r\n* Connected to localhost (/var/run/docker.sock) port 80 (#0)\r\n> POST /v1.30/services/create HTTP/1.1\r\n> Host: localhost\r\n> User-Agent: curl/7.61.1\r\n> Accept: */*\r\n> Content-Type: application/json\r\n> Content-Length: 536\r\n> \r\n* upload completely sent off: 536 out of 536 bytes\r\n< HTTP/1.1 500 Internal Server Error\r\n< Api-Version: 1.38\r\n< Content-Type: application/json\r\n< Docker-Experimental: false\r\n< Ostype: linux\r\n< Server: Docker/18.06.1-ce (linux)\r\n< Date: Mon, 05 Nov 2018 10:31:29 GMT\r\n< Content-Length: 86\r\n< \r\n{\"message\":\"rpc error: code = Unknown desc = name conflicts with an existing object\"}\r\n* Connection #0 to host localhost left intact\r\n```\r\n\r\n"},{"labels":["api",null],"text":"**Description**\r\n\r\nWhen volume inspect command is fired by the user and the volume plugin fails for some reason and tries to report the error by setting \"Err\" in the response, the error message is not displayed by Docker CLI. Instead, it always displays\r\n\r\n```sh\r\n[]\r\nError: No such volume: xxx\r\n```\r\n\r\nAs per the documentation for Docker REST API [/VolumeDriver.Get](https://docs.docker.com/engine/extend/plugins_volume/#volumedriverget), the response can contain error as below:\r\n\r\n```sh\r\n{\r\n  \"Volume\": {\r\n    \"Name\": \"volume_name\",\r\n    \"Mountpoint\": \"/path/under/PropagatedMount\",\r\n    \"Status\": {}\r\n  },\r\n  \"Err\": \"\"\r\n}\r\n```\r\n\r\n**Steps to reproduce the issue:**\r\n1. In the implementation of [/VolumeDriver.Get](https://docs.docker.com/engine/extend/plugins_volume/#volumedriverget), return error message in the response.\r\n\r\n**Describe the results you received:**\r\n```sh\r\n[]\r\nError: No such volume: xxx\r\n```\r\n\r\n**Describe the results you expected:**\r\nError message set by the volume plugin within the response is expected to be displayed by the Docker CLI\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nDocker version 17.06.2-ee-16, build 9ef4f0a\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 14\r\n Running: 1\r\n Paused: 0\r\n Stopped: 13\r\nImages: 1247\r\nServer Version: 17.06.2-ee-16\r\nStorage Driver: aufs\r\n Root Dir: /var/lib/docker/aufs\r\n Backing Filesystem: extfs\r\n Dirs: 786\r\n Dirperm1 Supported: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\n Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslog\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: 6e23458c129b551d5c9871e5174f6b1b7f6d1170\r\nrunc version: 462c82662200a17ee39e74692f536067a3576a50\r\ninit version: 949e6fa\r\nSecurity Options:\r\n apparmor\r\n seccomp\r\n  Profile: default\r\nKernel Version: 4.4.0-21-generic\r\nOperating System: Ubuntu 16.04.5 LTS\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 40\r\nTotal Memory: 62.79GiB\r\nName: xxxxxxxxxxxxx\r\nID: OWR5:HJYY:KAO5:H6GT:2NEU:JHHQ:YZ3G:67GJ:BKRV:SZ4P:Q3WJ:FDXS\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): false\r\nUsername: xxxxxxxxx\r\nRegistry: https://index.docker.io/v1/\r\nExperimental: false\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n\r\nWARNING: No swap limit support\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n"},{"labels":["api",null,null,null],"text":"While attaching a a container to an overlay network I get the following logs. There are two distinct issues here:\r\n- an error isn't handled properly which causes a FIXME to trigger\r\n- there is an error attempting to connect a task to an overlay network using API version 1.24\r\n\r\nUsing API 1.34 it works.\r\n\r\nThe logs for API 1.24 (generated using the docker-py python package):\r\n```\r\nDec 28 11:14:35 swarm-1 dockerd[588]: time=\"2017-12-28T11:14:35.145284405+01:00\" level=debug msg=\"Calling POST /v1.24/networks/testnet/connect\"\r\nDec 28 11:14:35 swarm-1 dockerd[588]: time=\"2017-12-28T11:14:35.145510531+01:00\" level=debug msg=\"form data: {\\\"Container\\\":\\\"65caedc6bf67\\\",\\\"EndpointConfig\\\":{}}\"\r\nDec 28 11:14:35 swarm-1 dockerd[588]: time=\"2017-12-28T11:14:35.174343060+01:00\" level=debug msg=\"RequestAddress(GlobalDefault/10.0.0.0/24, <nil>, map[com.docker.network.ipam.serial:true])\"\r\nDec 28 11:14:35 swarm-1 dockerd[588]: time=\"2017-12-28T11:14:35.177173023+01:00\" level=debug msg=\"Successfully attached to network testnet with task id yaciegbxsj47ntrqym2r9mcsm\"\r\nDec 28 11:14:35 swarm-1 ntpd[595]: Listen normally on 54 vethd3fa572 fe80::f4cc:73ff:fe5a:b1fc UDP 123\r\nDec 28 11:14:35 swarm-1 ntpd[595]: peers refreshed\r\nDec 28 11:14:38 swarm-1 dockerd[588]: time=\"2017-12-28T11:14:38.766448656+01:00\" level=debug msg=\"memberlist: Stream connection from=10.1.54.13:52630\"\r\nDec 28 11:14:38 swarm-1 dockerd[588]: time=\"2017-12-28T11:14:38.769253102+01:00\" level=info msg=\"Node join event for 41aeb0ed7cf7/10.1.54.13\"\r\nDec 28 11:14:55 swarm-1 dockerd[588]: time=\"2017-12-28T11:14:55.157261962+01:00\" level=debug msg=\"ReleaseAddress(GlobalDefault/10.0.0.0/24, 10.0.0.35)\"\r\nDec 28 11:14:55 swarm-1 dockerd[588]: time=\"2017-12-28T11:14:55.159347612+01:00\" level=debug msg=\"FIXME: Got an API for which error does not match any expected type!!!: attaching to network \r\nfailed, make sure your network options are correct and check manager logs: context deadline exceeded\" error_type=\"*errors.errorString\" module=api\r\nDec 28 11:14:55 swarm-1 dockerd[588]: time=\"2017-12-28T11:14:55.160099338+01:00\" level=error msg=\"Handler for POST /v1.24/networks/testnet/connect returned error: attaching to network failed\r\n, make sure your network options are correct and check manager logs: context deadline exceeded\"\r\nDec 28 11:14:55 swarm-1 dockerd[588]: time=\"2017-12-28T11:14:55.161338714+01:00\" level=debug msg=\"FIXME: Got an API for which error does not match any expected type!!!: attaching to network \r\nfailed, make sure your network options are correct and check manager logs: context deadline exceeded\" error_type=\"*errors.errorString\" module=api\r\nDec 28 11:15:02 swarm-1 dockerd[588]: time=\"2017-12-28T11:15:02.512053576+01:00\" level=debug msg=\"memberlist: Stream connection from=10.1.54.13:52634\"\r\n```\r\n\r\nWhen using the docker command tool you get the following logs (it works):\r\n```\r\nDec 28 11:31:00 swarm-1 dockerd[588]: time=\"2017-12-28T11:31:00.115209171+01:00\" level=debug msg=\"Calling POST /v1.34/networks/testnet/connect\"\r\nDec 28 11:31:00 swarm-1 dockerd[588]: time=\"2017-12-28T11:31:00.115456767+01:00\" level=debug msg=\"form data: {\\\"Container\\\":\\\"65caedc6bf67\\\",\\\"EndpointConfig\\\":{\\\"Aliases\\\":[],\\\"DriverOpts\\\":null,\\\"EndpointID\\\":\\\"\\\",\\\"Gateway\\\":\\\"\\\",\\\"GlobalIPv6Address\\\":\\\"\\\",\\\"GlobalIPv6PrefixLen\\\":0,\\\"IPAMConfig\\\":{},\\\"IPAddress\\\":\\\"\\\",\\\"IPPrefixLen\\\":0,\\\"IPv6Gateway\\\":\\\"\\\",\\\"Links\\\":null,\\\"MacAddress\\\":\\\"\\\",\\\"NetworkID\\\":\\\"\\\"}}\"\r\nDec 28 11:31:00 swarm-1 dockerd[588]: time=\"2017-12-28T11:31:00.119363648+01:00\" level=debug msg=\"Assigning addresses for endpoint cranky_booth's interface on network testnet\"\r\nDec 28 11:31:00 swarm-1 dockerd[588]: time=\"2017-12-28T11:31:00.121522694+01:00\" level=debug msg=\"RequestAddress(LocalDefault/10.0.0.0/24, <nil>, map[])\"\r\nDec 28 11:31:00 swarm-1 dockerd[588]: time=\"2017-12-28T11:31:00.147177068+01:00\" level=debug msg=\"Assigning addresses for endpoint cranky_booth's interface on network testnet\"\r\nDec 28 11:31:00 swarm-1 dockerd[588]: time=\"2017-12-28T11:31:00.199794382+01:00\" level=debug msg=\"checkEncryption(bfg309z, <nil>, 4096, true)\"\r\nDec 28 11:31:00 swarm-1 dockerd[588]: time=\"2017-12-28T11:31:00.334967494+01:00\" level=debug msg=\"Creating service for vip 10.0.0.13 fwMark 262 ingressPorts []*libnetwork.PortConfig(nil) in sbox 9027cf8 (65caedc)\"\r\nDec 28 11:31:00 swarm-1 dockerd[588]: time=\"2017-12-28T11:31:00.462069418+01:00\" level=debug msg=\"EnableService 65caedc6bf673cd1773d123d84752d4eff7ad8439d50c2b78d2b5d19d9bfe525 START\"\r\nDec 28 11:31:00 swarm-1 dockerd[588]: time=\"2017-12-28T11:31:00.463087411+01:00\" level=debug msg=\"addServiceInfoToCluster START for  b92fb52f32575289b8b925e6f5f99b0672907067d75531525f7abeb065389cb1\"\r\nDec 28 11:31:00 swarm-1 dockerd[588]: time=\"2017-12-28T11:31:00.463963840+01:00\" level=debug msg=\"addContainerNameResolution b92fb52f32575289b8b925e6f5f99b0672907067d75531525f7abeb065389cb1 65caedc6bf67\"\r\nDec 28 11:31:00 swarm-1 dockerd[588]: time=\"2017-12-28T11:31:00.464915615+01:00\" level=debug msg=\"b92fb52f32575289b8b925e6f5f99b0672907067d75531525f7abeb065389cb1 (bfg309z).addSvcRecords(65caedc6bf67, 10.0.0.2, <nil>, true) addServiceInfoToCluster sid:b92fb52f32575289b8b925e6f5f99b0672907067d75531525f7abeb065389cb1\"\r\nDec 28 11:31:00 swarm-1 dockerd[588]: time=\"2017-12-28T11:31:00.465904144+01:00\" level=debug msg=\"b92fb52f32575289b8b925e6f5f99b0672907067d75531525f7abeb065389cb1 (bfg309z).addSvcRecords(65caedc6bf67, 10.0.0.2, <nil>, true) addServiceInfoToCluster sid:b92fb52f32575289b8b925e6f5f99b0672907067d75531525f7abeb065389cb1\"\r\nDec 28 11:31:00 swarm-1 dockerd[588]: time=\"2017-12-28T11:31:00.467076144+01:00\" level=debug msg=\"addServiceInfoToCluster END for  b92fb52f32575289b8b925e6f5f99b0672907067d75531525f7abeb065389cb1\"\r\nDec 28 11:31:00 swarm-1 dockerd[588]: time=\"2017-12-28T11:31:00.467121412+01:00\" level=debug msg=\"EnableService 65caedc6bf673cd1773d123d84752d4eff7ad8439d50c2b78d2b5d19d9bfe525 DONE\"\r\n```\r\n\r\nSituation:\r\n- \r\n- Normal container on the first node, trying to attach to an overlay network\r\n\r\n**Steps to reproduce the issue:**\r\n1. Swarm with three nodes: manager with availability drain, worker, normal manager\r\n2. Normal container on the first node, trying to attach to an overlay network\r\n3. Use docker-py 2.0.2 to attach container to network.\r\n\r\n**Describe the results you received:**\r\n\r\nTimeout plus failure\r\n\r\n**Describe the results you expected:**\r\n\r\nContainer attached to network\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      17.11.0-ce\r\n API version:  1.34\r\n Go version:   go1.8.3\r\n Git commit:   1caf76c\r\n Built:        Mon Nov 20 18:36:33 2017\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      17.11.0-ce\r\n API version:  1.34 (minimum version 1.12)\r\n Go version:   go1.8.3\r\n Git commit:   1caf76c\r\n Built:        Mon Nov 20 18:35:05 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: false\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 34\r\n Running: 5\r\n Paused: 0\r\n Stopped: 29\r\nImages: 20\r\nServer Version: 17.11.0-ce\r\nStorage Driver: overlay2\r\n Backing Filesystem: extfs\r\n Supports d_type: true\r\n Native Overlay Diff: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\n Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslog\r\nSwarm: active\r\n NodeID: 2hpr816nia1fi7afdkq6135ti\r\n Is Manager: true\r\n ClusterID: ciep4cws4f9al3i8dxvosidkm\r\n Managers: 2\r\n Nodes: 3\r\n Orchestration:\r\n  Task History Retention Limit: 5\r\n Raft:\r\n  Snapshot Interval: 10000\r\n  Number of Old Snapshots to Retain: 0\r\n  Heartbeat Tick: 1\r\n  Election Tick: 3\r\n Dispatcher:\r\n  Heartbeat Period: 5 seconds\r\n CA Configuration:\r\n  Expiry Duration: 3 months\r\n  Force Rotate: 0\r\n Autolock Managers: false\r\n Root Rotation In Progress: false\r\n Node Address: 10.1.54.13\r\n Manager Addresses:\r\n  10.1.54.11:2377\r\n  10.1.54.13:2377\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: 992280e8e265f491f7a624ab82f3e238be086e49\r\nrunc version: 0351df1c5a66838d0c392b4ac4cf9450de844e2d\r\ninit version: 949e6fa\r\nKernel Version: 4.9.0-0.bpo.4-amd64\r\nOperating System: Debian GNU/Linux 8 (jessie)\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 1\r\nTotal Memory: 1.957GiB\r\nName: swarm-3\r\nID: SGID:6EJY:JKNE:F4LM:R434:4EB6:IMXC:PV5O:77LI:6MAR:S3DO:AD6J\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 119\r\n Goroutines: 261\r\n System Time: 2017-12-28T11:38:41.64341161+01:00\r\n EventsListeners: 5\r\nRegistry: https://index.docker.io/v1/\r\nExperimental: false\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n"},{"labels":["api",null,null],"text":"Originally filed in https://github.com/docker/for-mac/issues/2300, but moved to here as it's a problem within Moby.\r\n\r\n**Description**\r\n\r\nWhen a container creation request provides an `EndpointSettings` value of nil in the `NetworkConfig.EndpointConfig`, the API will respond with `bad response from Docker engine`. Either this error should not be happening in the first place, or an error that is more clear should be returned.\r\n\r\n**Steps to reproduce the issue:**\r\n\r\nA minimum example that will exhibit the problem is the following client code:\r\n\r\n\r\n```go\r\npackage main\r\n\r\nimport (\r\n\t\"context\"\r\n\t\"log\"\r\n\r\n\t\"github.com/moby/moby/client\"\r\n\r\n\t\"github.com/docker/docker/api/types\"\r\n\t\"github.com/docker/docker/api/types/container\"\r\n\t\"github.com/docker/docker/api/types/network\"\r\n)\r\n\r\nfunc main() {\r\n\tclient, err := client.NewEnvClient()\r\n\tif err != nil {\r\n\t\tlog.Fatal(err)\r\n\t}\r\n\tnetworkName := \"mynetwork\"\r\n\tendpoints := make(map[string]*network.EndpointSettings, 1)\r\n\tendpoints[networkName] = nil\r\n\t// If the above line is replaced with the following line, everything works fine.\r\n\t// endpoints[networkName] = &network.EndpointSettings{}\r\n\tresp, err := client.ContainerCreate(\r\n\t\tcontext.TODO(),\r\n\t\t&container.Config{\r\n\t\t\tImage: \"myimage\",\r\n\t\t},\r\n\t\tnil,\r\n\t\t&network.NetworkingConfig{\r\n\t\t\tEndpointsConfig: endpoints,\r\n\t\t},\r\n\t\t\"\",\r\n\t)\r\n\tif err != nil {\r\n\t\tlog.Fatal(err)\r\n\t}\r\n\tif err := client.ContainerStart(context.TODO(), resp.ID, types.ContainerStartOptions{}); err != nil {\r\n\t\tlog.Fatal(err)\r\n\t}\r\n}\r\n```\r\n\r\n**Describe the results you received:**\r\n- A container is created, and when attempting to start it an engine error is returned.\r\n\r\n**Describe the results you expected:**\r\n- A container is created and started.\r\n\r\n**Output of `docker version`:** \r\n\r\n```\r\nlient:\r\n Version:      17.09.0-ce\r\n API version:  1.32\r\n Go version:   go1.8.3\r\n Git commit:   afdb6d4\r\n Built:        Tue Sep 26 22:40:09 2017\r\n OS/Arch:      darwin/amd64\r\n\r\nServer:\r\n Version:      17.09.0-ce\r\n API version:  1.32 (minimum version 1.12)\r\n Go version:   go1.8.3\r\n Git commit:   afdb6d4\r\n Built:        Tue Sep 26 22:45:38 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: true\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 2\r\n Running: 0\r\n Paused: 0\r\n Stopped: 2\r\nImages: 9\r\nServer Version: 17.09.0-ce\r\nStorage Driver: overlay2\r\n Backing Filesystem: extfs\r\n Supports d_type: true\r\n Native Overlay Diff: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host ipvlan macvlan null overlay\r\n Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslog\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: 06b9cb35161009dcb7123345749fef02f7cea8e0\r\nrunc version: 3f2f8b84a77f73d38244dd690525642a72156c64\r\ninit version: 949e6fa\r\nSecurity Options:\r\n seccomp\r\n  Profile: default\r\nKernel Version: 4.9.49-moby\r\nOperating System: Alpine Linux v3.5\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 4\r\nTotal Memory: 1.952GiB\r\nName: moby\r\nID: Z6L4:JUOG:LGE3:VTWQ:TXTA:545D:33JF:R4EQ:NIN5:NVXF:FLDM:NWMG\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 19\r\n Goroutines: 32\r\n System Time: 2017-12-09T01:38:05.1673997Z\r\n EventsListeners: 1\r\nNo Proxy: *.local, 169.254/16\r\nRegistry: https://index.docker.io/v1/\r\nExperimental: true\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n```"},{"labels":["api",null],"text":"**Description**\r\n\r\n`HostConfig` in swagger spec declares PortBindings as an object with Map/Dictionary properties https://github.com/moby/moby/blob/master/api/swagger.yaml#L608\r\nNested tuple object (HostIp, HostPort) is declared here as an Object, but the API actually returns an array (see https://groups.google.com/forum/#!topic/docker-dev/Ydz6-YcaSG0 if you wonder why)\r\n\r\n**Steps to reproduce the issue:**\r\n1. generate model form swagger spec.\r\n2. use it to inspect a container\r\n3. \r\n\r\n**Describe the results you received:**\r\n\r\n`Expected BEGIN_OBJECT but was BEGIN_ARRAY at line 1 column 1402 path $.HostConfig.PortBindings.`\r\n\r\n**Describe the results you expected:**\r\n\r\ninspect response object mapped\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nServer:\r\n Version:      17.11.0-ce-rc3\r\n API version:  1.34 (minimum version 1.12)\r\n Go version:   go1.8.5\r\n Git commit:   5b4af4f\r\n Built:        Wed Nov  8 03:09:46 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: true\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n\r\nI'm using swagger-codegen to generate java model : https://github.com/Dockins/jocker/blob/master/pom.xml#L55\r\n"},{"labels":["api",null,null],"text":"**Description**\r\n\r\nRemote API: rename container responds with HTTP 400, should be HTTP 409. This happens on both 17.10 and 17.09.\r\n\r\n**Steps to reproduce the issue:**\r\nCreate two containers.\r\nRename one container. (For example, to \"foo\".)\r\nUsing the remote API, POST to /containers/(id or name)/rename?name=foo, i.e. rename the second container to the same name as the first.\r\n\r\n**Describe the results you received:**\r\nThe request fails with HTTP 400 bad request.\r\n\r\n{\"message\":\"Error when allocating new name: Conflict. The container name \\\"/1afabc65711aace8-6bf9bc24d807db13\\\" is already in use by container \\\"ca4a1c2132f5debe445c791216bae7c7d0ecacee62b1f5393df2ec21501b37e5\\\". You have to remove (or rename) that container to be able to reuse that name.\"}\r\n\r\n\r\n**Describe the results you expected:**\r\nThe request fails with HTTP 409 Conflict, message name already assigned, as described in the [remote API docs][api-doc].\r\n\r\n  [api-doc]: https://docs.docker.com/engine/api/v1.33/#operation/ContainerRename\r\n\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      17.10.0-ce\r\n API version:  1.33\r\n Go version:   go1.8.3\r\n Git commit:   f4ffd25\r\n Built:        Tue Oct 17 19:00:43 2017\r\n OS/Arch:      darwin/amd64\r\n\r\nServer:\r\n Version:      17.10.0-ce\r\n API version:  1.33 (minimum version 1.12)\r\n Go version:   go1.8.3\r\n Git commit:   f4ffd25\r\n Built:        Tue Oct 17 19:05:23 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: false\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 288\r\n Running: 1\r\n Paused: 0\r\n Stopped: 287\r\nImages: 121\r\nServer Version: 17.10.0-ce\r\nStorage Driver: aufs\r\n Root Dir: /mnt/sda1/var/lib/docker/aufs\r\n Backing Filesystem: extfs\r\n Dirs: 729\r\n Dirperm1 Supported: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\n Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslog\r\nSwarm: active\r\n NodeID: lpzh1yir70ysu8q5y5h1pzug1\r\n Is Manager: true\r\n ClusterID: rxvk8l7smfzkcfy99g03q91ce\r\n Managers: 1\r\n Nodes: 1\r\n Orchestration:\r\n  Task History Retention Limit: 5\r\n Raft:\r\n  Snapshot Interval: 10000\r\n  Number of Old Snapshots to Retain: 0\r\n  Heartbeat Tick: 1\r\n  Election Tick: 3\r\n Dispatcher:\r\n  Heartbeat Period: 5 seconds\r\n CA Configuration:\r\n  Expiry Duration: 3 months\r\n  Force Rotate: 0\r\n Autolock Managers: true\r\n Root Rotation In Progress: false\r\n Node Address: 127.0.0.1\r\n Manager Addresses:\r\n  127.0.0.1:2377\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: 06b9cb35161009dcb7123345749fef02f7cea8e0\r\nrunc version: 0351df1c5a66838d0c392b4ac4cf9450de844e2d\r\ninit version: 949e6fa\r\nSecurity Options:\r\n seccomp\r\n  Profile: default\r\nKernel Version: 4.4.93-boot2docker\r\nOperating System: Boot2Docker 17.10.0-ce (TCL 7.2); HEAD : 34fe485 - Wed Oct 18 17:16:34 UTC 2017\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 2\r\nTotal Memory: 1.955GiB\r\nName: 17.10.0\r\nID: ORAB:O2DJ:HFXW:BCAA:RCAU:3UTJ:JTY2:3G4Z:VMQJ:4DY3:425W:HM5A\r\nDocker Root Dir: /mnt/sda1/var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 216\r\n Goroutines: 331\r\n System Time: 2017-11-13T01:24:12.130585157Z\r\n EventsListeners: 0\r\nRegistry: https://index.docker.io/v1/\r\nLabels:\r\n provider=virtualbox\r\nExperimental: false\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n```\r\n\r\nA similar issue was [reported here ](https://github.com/moby/moby/issues/21016) before."},{"labels":["api",null],"text":"**Description**\r\nCreating containers with duplicated name used to return a 409 HTTP response, however, since 17.09 release it now returns a 400 response breaking compatibility for API users. \r\n\r\n**Steps to reproduce the issue:**\r\n1. Create a container `docker create --name c1 busybox`\r\n2. Run `curl -v -XPOST -H\"Content-Type: application/json\" -d'{\"Image\":\"busybox\"}' http://localhost:2375/containers/create?name=c1`\r\n\r\n**Describe the results you received:**\r\n\r\nThe HTTP response will be 400 Bad Request.\r\n\r\n**Describe the results you expected:**\r\n\r\nPrior to 17.09 the response would be 409 Conflict\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      17.09.0-ce\r\n API version:  1.32\r\n Go version:   go1.8.3\r\n Git commit:   afdb6d4\r\n Built:        Tue Sep 26 22:42:18 2017\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      17.09.0-ce\r\n API version:  1.32 (minimum version 1.12)\r\n Go version:   go1.8.3\r\n Git commit:   afdb6d4\r\n Built:        Tue Sep 26 22:40:56 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: false\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 7\r\n Running: 6\r\n Paused: 0\r\n Stopped: 1\r\nImages: 18\r\nServer Version: 17.09.0-ce\r\nStorage Driver: aufs\r\n Root Dir: /var/lib/docker/aufs\r\n Backing Filesystem: extfs\r\n Dirs: 55\r\n Dirperm1 Supported: true\r\nLogging Driver: syslog\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\n Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslog\r\nSwarm: active\r\n NodeID: ug3ojsrrreyxeq63nbwyikv3f\r\n Is Manager: true\r\n ClusterID: n2efj7ylwed1onrdxy0sp4dp1\r\n Managers: 1\r\n Nodes: 1\r\n Orchestration:\r\n  Task History Retention Limit: 5\r\n Raft:\r\n  Snapshot Interval: 10000\r\n  Number of Old Snapshots to Retain: 0\r\n  Heartbeat Tick: 1\r\n  Election Tick: 3\r\n Dispatcher:\r\n  Heartbeat Period: 5 seconds\r\n CA Configuration:\r\n  Expiry Duration: 3 months\r\n  Force Rotate: 0\r\n Autolock Managers: false\r\n Root Rotation In Progress: false\r\n Node Address: 192.168.50.4\r\n Manager Addresses:\r\n  192.168.50.4:2377\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: 06b9cb35161009dcb7123345749fef02f7cea8e0\r\nrunc version: 3f2f8b84a77f73d38244dd690525642a72156c64\r\ninit version: 949e6fa\r\nSecurity Options:\r\n apparmor\r\n seccomp\r\n  Profile: default\r\nKernel Version: 4.4.0-31-generic\r\nOperating System: Ubuntu 16.04.2 LTS\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 1\r\nTotal Memory: 2.915GiB\r\nName: vagrant\r\nID: QCSK:UDNT:AMC2:P6TV:M4LV:UZQE:7Z2W:TEHN:VJ75:YQTG:QIBD:TYJC\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 85\r\n Goroutines: 180\r\n System Time: 2017-09-28T14:10:12.894604072Z\r\n EventsListeners: 1\r\nUsername: cezarsa\r\nRegistry: https://index.docker.io/v1/\r\nExperimental: false\r\nInsecure Registries:\r\n 127.0.0.1:5000\r\nLive Restore Enabled: false\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n\r\nVirtualbox"},{"labels":["api",null,null,null],"text":"If the base64url or json decoding of the X-Registry-Auth header fails, the error is swallowed and the credentials are taken as empty.\r\nhttps://github.com/moby/moby/blob/4bf8714fac11e95e835cf78eb15ba5a518c67c4b/api/server/router/image/image_routes.go#L98-L107\r\n\r\nThe code comments states:\r\n```\r\n\t// for a pull it is not an error if no auth was given\r\n\t// to increase compatibility with the existing api it is defaulting to be empty\r\n```\r\n\r\nBut this situation is not that no auth was given, but that it was badly encoded. If there is a backward compatibility issue, there should be a better way to tackle it than ignoring the header entirely on error."},{"labels":["api",null,null],"text":"**Description**\r\n\r\nWhile calling `docker volume prune`, the pruning of a volume doesn't create an event entry.\r\n\r\n**Steps to reproduce the issue:**\r\n1. `docker events > events.log &` to listen docker events\r\n2. `docker volume create chazam` to create a test volume\r\n3. `docker volume prune` to delete volumes\r\n\r\n**Describe the results you received:**\r\nOn the events.log file you should, only, see the creation event:\r\n`2017-09-23T07:10:44.965370986Z volume create chazam (driver=local)`\r\n\r\n**Describe the results you expected:**\r\nI should expect to have an event entry on the volume deletion.\r\n\r\n**Problem localisation**\r\nThe problem is on the `daemon/prune.go` file. More precisely the `VolumesPrune` function, line `143`.\r\nWe should call `err = daemon.VolumeRm(v.Name(), false)` instead of the actual `err = daemon.volumes.Remove(v)`.\r\n\r\n**Output of `docker version`:**\r\n```\r\nClient:\r\n Version:      17.06.0-ce\r\n API version:  1.30\r\n Go version:   go1.8.3\r\n Git commit:   02c1d87\r\n Built:        Fri Jun 23 21:15:15 2017\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      17.06.0-dev\r\n API version:  1.32 (minimum version 1.12)\r\n Go version:   go1.8.3\r\n Git commit:   c982ee8\r\n Built:        Sat Sep 23 07:09:43 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: false\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 0\r\n Running: 0\r\n Paused: 0\r\n Stopped: 0\r\nImages: 0\r\nServer Version: 17.06.0-dev\r\nStorage Driver: overlay2\r\n Backing Filesystem: extfs\r\n Supports d_type: true\r\n Native Overlay Diff: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\n Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslog\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: 06b9cb35161009dcb7123345749fef02f7cea8e0\r\nrunc version: 1c81e2a794c6e26a4c650142ae8893c47f619764\r\ninit version: 949e6fa\r\nSecurity Options:\r\n seccomp\r\n  Profile: default\r\nKernel Version: 4.9.41-moby\r\nOperating System: Debian GNU/Linux 9 (stretch) (containerized)\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 4\r\nTotal Memory: 1.952GiB\r\nName: 977aaa405be0\r\nID: K6M2:ALHJ:AVJ5:XVW7:E4X5:W34D:35XQ:K6HK:YVOF:EA2N:U4BO:6QRT\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 17\r\n Goroutines: 28\r\n System Time: 2017-09-23T07:12:39.720242284Z\r\n EventsListeners: 1\r\nRegistry: https://index.docker.io/v1/\r\nExperimental: false\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n```\r\n"},{"labels":["api",null,null,null,null],"text":"\r\n**Description**\r\n\r\nWhen create a network with name already existed using docker-py, and set arg `check_duplicated=True`, the error should be `409 Conflict`, but `500 Internal Server Error` returns.\r\n\r\n**Steps to reproduce the issue:**\r\nIn python console\r\n```\r\n>>> import docker\r\n>>> c = docker.from_env()\r\n>>> c.networks.create('net1')\r\n<Network: 4c7d2d08e3>\r\n>>> c.networks.create('net1', check_duplicate=True)\r\n```\r\n\r\n**Describe the results you received:**\r\n\r\n```\r\n>>> c.networks.create('net1', check_duplicate=True)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/lib/python2.7/site-packages/docker/models/networks.py\", line 144, in create\r\n    resp = self.client.api.create_network(name, *args, **kwargs)\r\n  File \"/usr/lib/python2.7/site-packages/docker/utils/decorators.py\", line 35, in wrapper\r\n    return f(self, *args, **kwargs)\r\n  File \"/usr/lib/python2.7/site-packages/docker/api/network.py\", line 134, in create_network\r\n    return self._result(res, json=True)\r\n  File \"/usr/lib/python2.7/site-packages/docker/api/client.py\", line 220, in _result\r\n    self._raise_for_status(response)\r\n  File \"/usr/lib/python2.7/site-packages/docker/api/client.py\", line 216, in _raise_for_status\r\n    raise create_api_error_from_http_exception(e)\r\n  File \"/usr/lib/python2.7/site-packages/docker/errors.py\", line 30, in create_api_error_from_http_exception\r\n    raise cls(e, response=response, explanation=explanation)\r\ndocker.errors.APIError: 500 Server Error: Internal Server Error for url: http+docker://localunixsocket/v1.24/networks/create (\"network with name net1 already exists\")\r\n>>> \r\n```\r\n\r\n**Describe the results you expected:**\r\n\r\n```\r\n>>> c.networks.create('net1', check_duplicate=True)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/lib/python2.7/site-packages/docker/models/networks.py\", line 144, in create\r\n    resp = self.client.api.create_network(name, *args, **kwargs)\r\n  File \"/usr/lib/python2.7/site-packages/docker/utils/decorators.py\", line 35, in wrapper\r\n    return f(self, *args, **kwargs)\r\n  File \"/usr/lib/python2.7/site-packages/docker/api/network.py\", line 134, in create_network\r\n    return self._result(res, json=True)\r\n  File \"/usr/lib/python2.7/site-packages/docker/api/client.py\", line 220, in _result\r\n    self._raise_for_status(response)\r\n  File \"/usr/lib/python2.7/site-packages/docker/api/client.py\", line 216, in _raise_for_status\r\n    raise create_api_error_from_http_exception(e)\r\n  File \"/usr/lib/python2.7/site-packages/docker/errors.py\", line 30, in create_api_error_from_http_exception\r\n    raise cls(e, response=response, explanation=explanation)\r\ndocker.errors.APIError: 409 Client Error: Conflict for url: http+docker://localunixsocket/v1.24/networks/create (\"network with name net1 already exists\")\r\n>>> \r\n```\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      17.06.0-ce\r\n API version:  1.30\r\n Go version:   go1.8.3\r\n Git commit:   02c1d87\r\n Built:        Fri Jun 23 21:20:36 2017\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      17.06.0-ce\r\n API version:  1.30 (minimum version 1.12)\r\n Go version:   go1.8.3\r\n Git commit:   02c1d87\r\n Built:        Fri Jun 23 21:21:56 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: false\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 0\r\n Running: 0\r\n Paused: 0\r\n Stopped: 0\r\nImages: 1\r\nServer Version: 17.06.0-ce\r\nStorage Driver: overlay\r\n Backing Filesystem: xfs\r\n Supports d_type: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins: \r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\n Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslog\r\nSwarm: active\r\n NodeID: 7ty93f9vgo9gb2nmwk4km10hb\r\n Is Manager: true\r\n ClusterID: fofqp1rgom60nftnc5fwkz1st\r\n Managers: 1\r\n Nodes: 1\r\n Orchestration:\r\n  Task History Retention Limit: 5\r\n Raft:\r\n  Snapshot Interval: 10000\r\n  Number of Old Snapshots to Retain: 0\r\n  Heartbeat Tick: 1\r\n  Election Tick: 3\r\n Dispatcher:\r\n  Heartbeat Period: 5 seconds\r\n CA Configuration:\r\n  Expiry Duration: 3 months\r\n  Force Rotate: 0\r\n Root Rotation In Progress: false\r\n Node Address: 192.168.249.129\r\n Manager Addresses:\r\n  192.168.249.129:2377\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: cfb82a876ecc11b5ca0977d1733adbe58599088a\r\nrunc version: 2d41c047c83e09a6d61d464906feb2a2f3c52aa4\r\ninit version: 949e6fa\r\nSecurity Options:\r\n seccomp\r\n  Profile: default\r\nKernel Version: 3.10.0-514.el7.x86_64\r\nOperating System: CentOS Linux 7 (Core)\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 2\r\nTotal Memory: 472.5MiB\r\nName: swarm_manager\r\nID: YRD2:DTIW:AKEF:RXJY:RKXM:OJU2:N7B6:K7JK:XDOG:4E5S:NWFU:SGWY\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 40\r\n Goroutines: 184\r\n System Time: 2017-08-08T14:20:57.288514678+08:00\r\n EventsListeners: 0\r\nRegistry: https://index.docker.io/v1/\r\nExperimental: false\r\nInsecure Registries:\r\n 10.27.37.40:5000\r\n 10.37.210.125:5001\r\n 127.0.0.0/8\r\nRegistry Mirrors:\r\n https://2h3po24q.mirror.aliyuncs.com/\r\nLive Restore Enabled: false\r\n\r\nWARNING: bridge-nf-call-ip6tables is disabled\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n```\r\ndocker-py version 2.1.0\r\n```"},{"labels":["api",null,null],"text":"**Description**\r\n\r\n`NetworkSettings.Networks[*].Aliases` content is shown with `docker inspect` but not with `moby/client.`\r\n\r\n**Steps to reproduce the issue:**\r\n1. Create the following `docker-compose.yml`:\r\n```\r\nversion: '2'\r\n\r\nservices:\r\n  compcont:\r\n    image: friendlyhello\r\n    networks:\r\n      default:\r\n      builds:\r\n        aliases: [ \"mycompcont\" ]\r\n\r\nnetworks:\r\n  default:\r\n    external:\r\n      name: othernet\r\n  builds:\r\n    external:\r\n      name: mynet\r\n```\r\n2. Create both networks and bring compose up:\r\n```\r\n$ docker network create mynet\r\n$ docker network create othernet\r\n$ docker-compose up\r\n```\r\n3. Inspect the container:\r\n```\r\n$ docker inspect test_compcont_1\r\n...\r\n        \"NetworkSettings\": {\r\n...\r\n            \"Networks\": {\r\n                \"mynet\": {\r\n...\r\n                    \"Aliases\": [\r\n                        \"compcont\",\r\n                        \"b41fa65b66dc\",\r\n                        \"mycompcont\"\r\n                    ],\r\n...\r\n                    \"Gateway\": \"172.18.0.1\",\r\n                    \"IPAddress\": \"172.18.0.2\",\r\n                },\r\n                \"othernet\": {\r\n...\r\n                    \"Aliases\": [\r\n                        \"compcont\",\r\n                        \"b41fa65b66dc\"\r\n                    ],\r\n...\r\n                    \"Gateway\": \"172.19.0.1\",\r\n                    \"IPAddress\": \"172.19.0.2\",\r\n                }\r\n            }\r\n        }\r\n...\r\n```\r\n4. Write a simple app with the client library:\r\n```\r\npackage main\r\n\r\nimport (\r\n  \"context\"\r\n  \"fmt\"\r\n  \"github.com/docker/docker/api/types\"\r\n  \"github.com/docker/docker/client\"\r\n)\r\n\r\nfunc main() {\r\n  cli, err := client.NewEnvClient()\r\n  if err != nil { panic(err) }\r\n\t\r\n  conts, err := cli.ContainerList(context.Background(), types.ContainerListOptions{All:true})\r\n  if err != nil { panic(err) }\r\n\t\r\n  for _, cont := range conts {\r\n    fmt.Println(cont.Names)\r\n    for k, n := range cont.NetworkSettings.Networks {\r\n      fmt.Println(\"\\t\", k, \"\\t\", n.Gateway, \"\\t\", n.IPAddress, \"\\t\", n.Aliases)\r\n    }\r\n  }\r\n}\r\n```\r\n5. `go run main.go`\r\n\r\n**Describe the results you received:**\r\n\r\n```\r\n$ go run main.go\r\n[/test_compcont_1]\r\n         othernet   172.19.0.1  172.19.0.2   []\r\n         mynet       172.18.0.1  172.18.0.2  []\r\n```\r\n\r\n**Describe the results you expected:**\r\n\r\n```\r\n$ go run main.go\r\n[/test_compcont_1]\r\n         othernet   172.19.0.1  172.19.0.2   [\"compcont\", \"b41fa65b66dc\"]\r\n         mynet       172.18.0.1  172.18.0.2  [\"compcont\", \"b41fa65b66dc\", \"mycompcont\"]\r\n```\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\nI cannot switch from `docker/docker/client` to `moby/moby/client`:\r\n\r\n```\r\n$ go get github.com/moby/moby/client\r\n# github.com/moby/moby/client\r\nC:\\Users\\eine\\go\\src\\github.com\\moby\\moby\\client\\service_create.go:38: cannot use distributionInspect.Descriptor.Digest (type \"github.com/docker/docker/vendor/github.com/opencontainers/go-digest\".Digest) as type \"github.com/moby/moby/vendor/github.com/opencontainers/go-digest\".Digest in argument to imageWithDigestString\r\nC:\\Users\\eine\\go\\src\\github.com\\moby\\moby\\client\\service_update.go:50: cannot use distributionInspect.Descriptor.Digest (type \"github.com/docker/docker/vendor/github.com/opencontainers/go-digest\".Digest) as type \"github.com/moby/moby/vendor/github.com/opencontainers/go-digest\".Digest in argument to imageWithDigestString\r\n```\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      17.03.1-ce\r\n API version:  1.27\r\n Go version:   go1.7.5\r\n Git commit:   c6d412e\r\n Built:        Tue Mar 28 00:40:02 2017\r\n OS/Arch:      windows/amd64\r\n\r\nServer:\r\n Version:      17.03.1-ce\r\n API version:  1.27 (minimum version 1.12)\r\n Go version:   go1.7.5\r\n Git commit:   c6d412e\r\n Built:        Fri Mar 24 00:00:50 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: true\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 1\r\n Running: 1\r\n Paused: 0\r\n Stopped: 0\r\nImages: 22\r\nServer Version: 17.03.1-ce\r\nStorage Driver: overlay2\r\n Backing Filesystem: extfs\r\n Supports d_type: true\r\n Native Overlay Diff: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host ipvlan macvlan null overlay\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: 4ab9917febca54791c5f071a9d1f404867857fcc\r\nrunc version: 54296cf40ad8143b62dbcaa1d90e520a2136ddfe\r\ninit version: 949e6fa\r\nSecurity Options:\r\n seccomp\r\n  Profile: default\r\nKernel Version: 4.9.27-moby\r\nOperating System: Alpine Linux v3.5\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 2\r\nTotal Memory: 1.934 GiB\r\nName: moby\r\nID: LDKB:3CJT:OB3Q:KFV3:5VPW:P63T:KGBQ:CWKE:O2AU:5Q54:7N2Y:DJA7\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 26\r\n Goroutines: 51\r\n System Time: 2017-06-22T06:24:06.3841556Z\r\n EventsListeners: 1\r\nRegistry: https://index.docker.io/v1/\r\nExperimental: true\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n```\r\n"},{"labels":["api",null,null,null,null],"text":"**Description**\r\n\r\nMaking an API request to start a container with an empty JSON string in the body will return the following error:\r\n`{\"message\":\"starting container with non-empty request body was deprecated since v1.10 and removed in v1.12\"}`\r\n\r\nThis functionality worked in all previous versions of docker but is now broken in 17.06.0-rc1\r\n\r\n**Steps to reproduce the issue:**\r\n1. Create a container\r\n2. Send a request to start the container via the API and an empty JSON string `{}`\r\n3. Get the above error\r\n\r\n```\r\n$ docker create --name my-test alpine top\r\n$ curl -vvv --unix-socket /var/run/docker.sock -X POST -H 'Content-Type: application/json' -d '{}' http://1.29/containers/my-test/start\r\nNote: Unnecessary use of -X or --request, POST is already inferred.\r\n*   Trying /var/run/docker.sock...\r\n...\r\n> POST /containers/my-test/start HTTP/1.1\r\n> Host: 1.29\r\n> User-Agent: curl/7.51.0\r\n> Accept: */*\r\n> Content-Type: application/json\r\n> Content-Length: 2\r\n>\r\n* upload completely sent off: 2 out of 2 bytes\r\n< HTTP/1.1 400 Bad Request\r\n< Api-Version: 1.30\r\n< Content-Length: 109\r\n< Content-Type: application/json\r\n< Date: Fri, 02 Jun 2017 21:57:20 GMT\r\n< Docker-Experimental: true\r\n< Ostype: linux\r\n< Server: Docker/17.06.0-ce-rc1 (linux)\r\n<\r\n{\"message\":\"starting container with non-empty request body was deprecated since v1.10 and removed in v1.12\"}\r\n* Curl_http_done: called premature == 0\r\n* Connection #0 to host 1.29 left intact\r\n```\r\nTo make it work:\r\n```\r\n$ curl --unix-socket /var/run/docker.sock -X POST -H 'Content-Type: application/json' -d '' http://1.29/containers/my-test/start\r\n```\r\n\r\n**Describe the results you received:**\r\n`{\"message\":\"starting container with non-empty request body was deprecated since v1.10 and removed in v1.12\"}`\r\n\r\n**Describe the results you expected:**\r\nFor the container to start\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\nhttps://github.com/moby/moby/blob/master/api/server/router/container/container_routes.go#L144\r\n\r\n\r\n\r\n**Output of `docker version`:**\r\n\r\n```                                                                                                                                          \r\nClient:\r\n Version:      17.06.0-ce-rc1\r\n API version:  1.30\r\n Go version:   go1.8.1\r\n Git commit:   7f8486a\r\n Built:        Wed May 31 02:56:01 2017\r\n OS/Arch:      darwin/amd64\r\n\r\nServer:\r\n Version:      17.06.0-ce-rc1\r\n API version:  1.30 (minimum version 1.12)\r\n Go version:   go1.8.1\r\n Git commit:   7f8486a\r\n Built:        Wed May 31 03:00:14 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: true\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\nVersion 17.06.0-rc1-ce-mac13 (18169)\r\n"},{"labels":["api",null,null],"text":"**Description**\r\n\r\nDocker prune commands are not taking `reference` into account when filtering.  I have tested with the volume and image subcommands, there may be others.\r\n\r\n**Steps to reproduce the issue:**\r\n\r\n1. Run a prune command\r\n\r\n`docker pull alpine`\r\n`docker image prune --filter reference=alpine`\r\n`docker image ls`\r\n\r\n**Describe the results you received:**\r\n\r\nThe filter isn't picking up the reference specified.\r\n\r\n**Describe the results you expected:**\r\n\r\nExpect the prune command to remove only the alpine image, but it doesn't remove any.\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\nHere's the full output of the image prune command:\r\n\r\n```\r\ndocker image prune --filter reference=alpine\r\nWARNING! This will remove all dangling images.\r\nAre you sure you want to continue? [y/N] y\r\nTotal reclaimed space: 0B\r\n```\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\n docker version                                                                                                                                                                                      joshuareichardt@Joshuas-MacBook-Pro\r\nClient:\r\n Version:      17.05.0-ce-rc1\r\n API version:  1.29\r\n Go version:   go1.7.5\r\n Git commit:   2878a85\r\n Built:        Tue Apr 11 20:55:05 2017\r\n OS/Arch:      darwin/amd64\r\n\r\nServer:\r\n Version:      17.05.0-ce-rc1\r\n API version:  1.29 (minimum version 1.12)\r\n Go version:   go1.7.5\r\n Git commit:   2878a85\r\n Built:        Tue Apr 11 20:55:05 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: true\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\ndocker info                                                                                                                                                                                         joshuareichardt@Joshuas-MacBook-Pro\r\nContainers: 0\r\n Running: 0\r\n Paused: 0\r\n Stopped: 0\r\nImages: 11\r\nServer Version: 17.05.0-ce-rc1\r\nStorage Driver: overlay2\r\n Backing Filesystem: extfs\r\n Supports d_type: true\r\n Native Overlay Diff: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host ipvlan macvlan null overlay\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: 9048e5e50717ea4497b757314bad98ea3763c145\r\nrunc version: 9c2d8d184e5da67c95d601382adf14862e4f2228\r\ninit version: 949e6fa\r\nSecurity Options:\r\n seccomp\r\n  Profile: default\r\nKernel Version: 4.9.21-moby\r\nOperating System: Alpine Linux v3.5\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 4\r\nTotal Memory: 1.952GiB\r\nName: moby\r\nID: R663:ASEF:JLSY:ZWUY:D46M:3X47:K4SY:67GO:2QGQ:NML4:JKEW:XIJV\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 19\r\n Goroutines: 29\r\n System Time: 2017-05-10T17:14:49.298869229Z\r\n EventsListeners: 1\r\nNo Proxy: *.local, 169.254/16\r\nRegistry: https://index.docker.io/v1/\r\nExperimental: true\r\nInsecure Registries:\r\n localhost:5000\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):** Docker for mac (17.05.0-ce-rc1-mac8)\r\n"},{"labels":["api",null,null,null],"text":"Some error messages returned by the daemon / API are referring to CLI flags not being valid, for example;\r\n\r\n- [runconfig/hostconfig_windows.go#L34](https://github.com/moby/moby/blob/4af3389d43d93f50d9b4fa217de148ec45abf8cb/runconfig/hostconfig_windows.go#L34)\r\n- [hostconfig_windows.go#L49](https://github.com/moby/moby/blob/4af3389d43d93f50d9b4fa217de148ec45abf8cb/runconfig/hostconfig_windows.go#L49)\r\n\r\nGiven that these are returned by the API, not the CLI, and we cannot assume that the _docker_ CLI is used as a client (it can be any (API) client), we should make these messages more generic and have them refer to the API-option that is not supported, not the CLI flag."},{"labels":["api",null,null,null],"text":"Hello,\r\n\r\ni have an error using this page (click into \"Labels\" menù):\r\n\r\nhttps://docs.docker.com/engine/api/v1.28/#operation/ServiceCreate\r\n\r\nJS Console stacktrace:\r\n\r\nError: Can't load component schema at /paths/~1services~1create/post/parameters/0/schema/properties/Labels\r\n    at d (redoc.1.11.0.min.js:43)\r\n    at e.init (redoc.1.11.0.min.js:17)\r\n    at e.t.preinit (redoc.1.11.0.min.js:9)\r\n    at e.preinit (redoc.1.11.0.min.js:9)\r\n    at e.ngOnInit (redoc.1.11.0.min.js:17)\r\n    at t.ngDoCheck (redoc.1.11.0.min.js:15)\r\n    at e.detectChangesInternal (redoc.1.11.0.min.js:15)\r\n    at e.t.detectChanges (redoc.1.11.0.min.js:7)\r\n    at t.detectChangesInNestedViews (redoc.1.11.0.min.js:7)\r\n    at e.detectChangesInternal (redoc.1.11.0.min.js:16)\r\n    at e.t.detectChanges (redoc.1.11.0.min.js:7)\r\n    at t.detectChangesInNestedViews (redoc.1.11.0.min.js:7)\r\n    at e.detectChangesInternal (redoc.1.11.0.min.js:16)\r\n    at e.t.detectChanges (redoc.1.11.0.min.js:7)\r\n    at t.detectChangesInNestedViews (redoc.1.11.0.min.js:7)"},{"labels":["api",null],"text":"Docker REST API 1.27 cannot be loaded with the SwaggerUI. It gives the error:\r\n\r\n```\r\n{\r\n\"messages\": [\r\n\"attribute definitions.RestartPolicy.default is not of type `string`\"\r\n]\r\n}\r\n```\r\n\r\nThe error can be seen at https://online.swagger.io/validator/debug?url=https://docs.docker.com/engine/api/v1.27/swagger.yaml.\r\n"},{"labels":["api",null,null,null,null],"text":"**Description**\r\n\r\nI foundt that SwarmKit in docker does not validate health check parameters in a service create request.\r\n\r\n**Steps to reproduce the issue:**\r\n1. use api to create a service, in the service spec, we add parameter of HealthCheck.\r\n2. in parameter, we add an invalid value, like `timeout -1s, retries -1`, valid timeout should be larger than 1s, and valid retires should be a positive integer.\r\n3. send the request to create this service\r\n\r\nrequest like the following pic:\r\n![wechatimg8](https://cloud.githubusercontent.com/assets/9465626/24639949/eb42ecb8-1925-11e7-8154-6f05a47ad069.jpeg)\r\n\r\n\r\n\r\n**Describe the results you received:**\r\nService created OK\r\n\r\n**Describe the results you expected:**\r\nparameter invalid\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nroot@ubuntu:~# docker version\r\nClient:\r\n Version:      17.03.0-ce\r\n API version:  1.26\r\n Go version:   go1.7.5\r\n Git commit:   60ccb22\r\n Built:        Thu Feb 23 10:57:47 2017\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      17.03.0-ce\r\n API version:  1.26 (minimum version 1.12)\r\n Go version:   go1.7.5\r\n Git commit:   60ccb22\r\n Built:        Thu Feb 23 10:57:47 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: false\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nroot@ubuntu:~# docker info\r\nContainers: 3\r\n Running: 3\r\n Paused: 0\r\n Stopped: 0\r\nImages: 116\r\nServer Version: 17.03.0-ce\r\nStorage Driver: aufs\r\n Root Dir: /var/lib/docker/aufs\r\n Backing Filesystem: extfs\r\n Dirs: 148\r\n Dirperm1 Supported: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\nSwarm: active\r\n NodeID: vfb7vr7wp1dirmop8fbvmmgh7\r\n Is Manager: true\r\n ClusterID: mzzbi2s44h4vesargizzywryz\r\n Managers: 1\r\n Nodes: 2\r\n Orchestration:\r\n  Task History Retention Limit: 5\r\n Raft:\r\n  Snapshot Interval: 10000\r\n  Number of Old Snapshots to Retain: 0\r\n  Heartbeat Tick: 1\r\n  Election Tick: 3\r\n Dispatcher:\r\n  Heartbeat Period: 5 seconds\r\n CA Configuration:\r\n  Expiry Duration: 3 months\r\n Node Address: 192.168.59.103\r\n Manager Addresses:\r\n  192.168.59.103:2377\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: 977c511eda0925a723debdc94d09459af49d082a\r\nrunc version: a01dafd48bc1c7cc12bdb01206f9fea7dd6feb70\r\ninit version: 949e6fa\r\nSecurity Options:\r\n apparmor\r\nKernel Version: 3.19.0-25-generic\r\nOperating System: Ubuntu 14.04.3 LTS\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 1\r\nTotal Memory: 1.954 GiB\r\nName: ubuntu\r\nID: FXOY:JCOY:HKDI:VO5U:FYDM:UEXV:YIFN:AISM:NR6U:VMW5:V4MZ:RQWF\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 52\r\n Goroutines: 154\r\n System Time: 2017-03-27T14:28:38.061668428+08:00\r\n EventsListeners: 3\r\nRegistry: https://index.docker.io/v1/\r\nWARNING: No swap limit support\r\nExperimental: false\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n"},{"labels":["api"],"text":"In the gRPC API, `NetworkAttachmentConfig.Target` is always a network ID. In the REST API, the client inserts network names in this field, and they are converted in the daemon before submitting the spec over gRPC.\r\n\r\nI thought this should be filed as an issue because differences between the two APIs are very confusing and lead to bugs. Ideally, we should not be mutating the spec inside the daemon, because that hacks around the declarative nature of the API. The client should be resolving the network IDs and inserting them in the spec."},{"labels":["api",null,null,null,null],"text":"The markdown API docs are missing any description for the `NetworkingConfig` object that is included in the config to create a container. This object is included in the example JSON that gets POSTed to `/containers/create` in the 1.22, 1.23, and 1.24 docs, but is not mentioned in the following \"JSON Parameters\" section. In particular, its child object `EndpointsConfig` is not fully defined.\r\n\r\nThis issue only affects the older markdown API docs. The objects mentioned above are defined in more detail in `api/swagger.yaml`. For the most part, the various places in the swagger description of the API that accept or produce information about networks refer to `#/definitions/EndpointSettings`.\r\n\r\n"},{"labels":["api",null,null,null],"text":"**Description**\r\nOur monitoring detected docker performance problems rising slowly - checked with `docker ps`, `docker info` and `docker run` calls. At the same time about 100 processes with \"D\" state were detected in the system. Increasing number of \"D\" processes eventually renders docker daemon unresponsive. This was confirmed on multiple occasions (at least 5 times).\r\n\r\n**Steps to reproduce the issue:**\r\n1. Make some processes running within container stuck in \"D\" (like on a read from failed remote file system)\r\n2. Observe docker API performance as the number of \"D\" processes increases.\r\n\r\n**Describe the results you received:**\r\nDocker API response time grow and eventually render the whole daemon unresponsive.\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\nIs repeatable, happens every time the number of \"D\" processes on the host rises.\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      1.12.3-cs4\r\n API version:  1.24\r\n Go version:   go1.6.3\r\n Git commit:   65c6c4c\r\n Built:        Fri Nov 11 16:23:03 2016\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      1.12.3-cs4\r\n API version:  1.24\r\n Go version:   go1.6.3\r\n Git commit:   65c6c4c\r\n Built:        Fri Nov 11 16:23:03 2016\r\n OS/Arch:      linux/amd64\r\n\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 464\r\n Running: 363\r\n Paused: 0\r\n Stopped: 101\r\nImages: 761\r\nServer Version: 1.12.3-cs4\r\nStorage Driver: aufs\r\n Root Dir: /opt/io1/docker/aufs\r\n Backing Filesystem: extfs\r\n Dirs: 3837\r\n Dirperm1 Supported: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge null host overlay\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nSecurity Options: apparmor seccomp\r\nKernel Version: 4.4.0-62-generic\r\nOperating System: Ubuntu 16.04.2 LTS\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 128\r\nTotal Memory: 1.876 TiB\r\nName: ip-10-69-11-89\r\nID: UGZS:UFD3:GB4C:W5MX:JU2L:K7PH:6ZWS:4GPM:27Q5:UNNN:X3DC:YDT7\r\nDocker Root Dir: /opt/io1/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 2410\r\n Goroutines: 2766\r\n System Time: 2017-02-22T13:10:59.794584753Z\r\n EventsListeners: 1\r\nRegistry: https://index.docker.io/v1/\r\nWARNING: No swap limit support\r\nInsecure Registries:\r\n 127.0.0.0/8\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n* instance type: x1.32\r\n* host: docker-linux-1\r\n* OS: ubuntu 16.04 LTS\r\n* kernel version: `Linux ip-10-69-11-89 4.4.0-59-generic #80-Ubuntu SMP Fri Jan 6 17:47:47 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux`"},{"labels":["api",null,null,null],"text":"**Description**\r\n\r\nThe `ContainerStatPath` method in the client library returns different errors than the error reported by the API.\r\nThe first case is when running the method on a container ID that doesn't exist, the other one if the container ID does exist, but the path does not exist.\r\n\r\n**Steps to reproduce the issue:**\r\n_case 1_\r\n\r\nCompile and run the following program:\r\n\r\n```go\r\nfunc TestContainerStatPathIssue(t *testing.T) {\r\n\tcli, err := client.NewEnvClient()\r\n\tif err != nil {\r\n\t\tt.Fatal(err)\r\n\t}\r\n\t_, err = cli.ContainerStatPath(context.TODO(), \"foo\", \"bar\")\r\n\tif err != nil {\r\n\t\tt.Fatal(err)\r\n\t}\r\n}\r\n```\r\n\r\n_case 2_\r\nRun command `docker create --name=foo alpine:latest /bin/sh` and run the program from case 1 again.\r\n\r\n**Describe the results you received:**\r\nCase 1 returns:\r\n> Error: request returned Not Found for API route and version http://<ip>:4243/v1.24/containers/foo/archive?path=bar, check if the server supports the requested API version\r\n\r\nRunning `curl` on that URL returns:\r\n```json\r\n{\"message\":\"No such container: foo\"}\r\n```\r\n\r\nCase 2 returns:\r\n> Error: request returned Not Found for API route and version http://<ip>:4243/v1.24/containers/foo/archive?path=bar, check if the server supports the requested API version\r\n\r\nRunning `curl` on that URL returns:\r\n```json\r\n{\"message\":\"lstat /var/lib/docker/overlay/116c08d9b5aedea0fa868effeaa4562ed28cc8f8d2e06dcd1e557fca48815026/merged/bar: no such file or directory\"}\r\n```\r\n\r\n**Describe the results you expected:**\r\nIn both cases I expect an error that is more in line with the error returned from the API.\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\nThe docker version I'm running supports API version `1.25`, setting `DOCKER_API_VERSION=1.25` results in the same behavior as above.\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      1.13.0\r\n API version:  1.25\r\n Go version:   go1.7.3\r\n Git commit:   49bf474\r\n Built:        Tue Jan 17 09:55:28 2017\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      1.13.0\r\n API version:  1.25 (minimum version 1.12)\r\n Go version:   go1.7.3\r\n Git commit:   49bf474\r\n Built:        Tue Jan 17 09:55:28 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: false\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 3\r\n Running: 0\r\n Paused: 0\r\n Stopped: 3\r\nImages: 9\r\nServer Version: 1.13.0\r\nStorage Driver: overlay\r\n Backing Filesystem: xfs\r\n Supports d_type: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: 03e5862ec0d8d3b3f750e19fca3ee367e13c090e\r\nrunc version: 2f7393a47307a16f8cee44a37b262e8b81021e3e\r\ninit version: 949e6fa\r\nSecurity Options:\r\n seccomp\r\n  Profile: default\r\nKernel Version: 3.10.0-514.6.1.el7.x86_64\r\nOperating System: CentOS Linux 7 (Core)\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 1\r\nTotal Memory: 992.7 MiB\r\nName: localhost.localdomain\r\nID: MFQW:WT3K:SL5H:LVNK:NCRK:MMAV:YLUG:XCCG:LTO6:KXMN:2GBN:52TN\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): false\r\nRegistry: https://index.docker.io/v1/\r\nExperimental: false\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\nRunning on VirtualBox."},{"labels":["api",null,null,null],"text":"**Description**\r\n\r\nRepeatedly calling `docker service update` may trigger an `update out of sequence` error. This seems to happen because the api call to service inspect (`GET /services/{id}`) returns an old `Version.Index` even after the successful return of previous a call to service update (`POST /services/{id}/update`).\r\n\r\n**Steps to reproduce the issue:**\r\n```\r\ndocker swarm init\r\ndocker service create --name test busybox tail -f /dev/null\r\nwhile docker service update test --constraint-add \"node.labels.a != b\"; do true; done\r\n```\r\n\r\n**Describe the results you received:**\r\n\r\nAfter some time repeatedly updating the service (~30s on my machine) the last command will fail with the error `Error response from daemon: rpc error: code = 2 desc = update out of sequence`.\r\n\r\n**Describe the results you expected:**\r\n\r\nI expected that successful calls to `POST /service/{id}/update` would guarantee that subsequent calls to `GET /service/{id}` returned an updated `Version.Index`. This seems not to be the case. I'm not sure if this behavior is intended or not, if this is working as expected I think a clarification in the API documentation would be nice.\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\n$ docker version\r\nClient:\r\n Version:      1.13.1-rc1\r\n API version:  1.25\r\n Go version:   go1.7.4\r\n Git commit:   2527cfc\r\n Built:        Fri Jan 27 21:54:54 2017\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      1.13.1-rc1\r\n API version:  1.25 (minimum version 1.12)\r\n Go version:   go1.7.4\r\n Git commit:   2527cfc\r\n Built:        Fri Jan 27 21:54:54 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: false\r\n```\r\nThe problem also happens with `1.13.0` and `1.12.6`\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\n$ docker info\r\nContainers: 26\r\n Running: 4\r\n Paused: 0\r\n Stopped: 22\r\nImages: 264\r\nServer Version: 1.13.1-rc1\r\nStorage Driver: aufs\r\n Root Dir: /var/lib/docker/aufs\r\n Backing Filesystem: extfs\r\n Dirs: 397\r\n Dirperm1 Supported: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\nSwarm: active\r\n NodeID: n2osx48m66gag48ggoyg1w1pc\r\n Is Manager: true\r\n ClusterID: 66490aoqoo9cdx00t5n95hw34\r\n Managers: 1\r\n Nodes: 1\r\n Orchestration:\r\n  Task History Retention Limit: 5\r\n Raft:\r\n  Snapshot Interval: 10000\r\n  Number of Old Snapshots to Retain: 0\r\n  Heartbeat Tick: 1\r\n  Election Tick: 3\r\n Dispatcher:\r\n  Heartbeat Period: 5 seconds\r\n CA Configuration:\r\n  Expiry Duration: 3 months\r\n Node Address: 192.168.50.4\r\n Manager Addresses:\r\n  192.168.50.4:2377\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: 03e5862ec0d8d3b3f750e19fca3ee367e13c090e\r\nrunc version: 2f7393a47307a16f8cee44a37b262e8b81021e3e\r\ninit version: 949e6fa\r\nSecurity Options:\r\n apparmor\r\n seccomp\r\n  Profile: default\r\nKernel Version: 4.4.0-31-generic\r\nOperating System: Ubuntu 16.04.1 LTS\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 1\r\nTotal Memory: 2.915 GiB\r\nName: vagrant\r\nID: XXOL:4PPB:VZV3:W7ZD:QRDT:FY6D:L2WN:OI5T:3Z3I:HZS5:TI6Z:BXJN\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 58\r\n Goroutines: 153\r\n System Time: 2017-02-07T17:31:31.46294919Z\r\n EventsListeners: 1\r\nUsername: cezarsa\r\nRegistry: https://index.docker.io/v1/\r\nWARNING: No swap limit support\r\nExperimental: false\r\nLive Restore Enabled: false\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n\r\nTested on Vagrant + Virtualbox and also on Ubuntu 14.04 on private Cloudstack."},{"labels":["api",null,null],"text":"**docker run --rm reports an error when attempting to remove container in version 1.13 with 1.24 API**\r\n\r\nThis appears to be a side effect of [PR #20848](https://github.com/docker/docker/pull/20848). When using a newer client and server, but reverting the API to something before 1.25, I'm seeing an error from a failed attempt to remove a container. This is generating nuisance errors with the classic swarm as seen in [issue #2620](https://github.com/docker/swarm/issues/2620).\r\n\r\n**Steps to reproduce the issue:**\r\n```\r\n$ # normal result\r\n$ docker run -it --rm busybox echo hello\r\nhello\r\n\r\n$ # error when using an older api version\r\n$ DOCKER_API_VERSION=1.24 docker run -it --rm busybox echo hello\r\nhello\r\nERRO[0002] error removing container: Error response from daemon: removal of container dc8b9e47ddfdea3c8d5c6abfd5b6fd4d703a5aa43fd5a712be3dcc8d730a163c is already in progress\r\n```\r\n\r\n**Describe the results you received:**\r\nThe container is removed by the docker daemon and then the docker client attempts to also remove the container, resulting in the error message.\r\n\r\n**Describe the results you expected:**\r\nWhen using an API before 1.25, the docker server should not perform the auto remove, it should instead be performed by the client. I'm not sure if this change needs to be made as part of the client request or the daemon processing of the request.\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\nI've reproduced this issue in multiple environments\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      1.13.0\r\n API version:  1.25\r\n Go version:   go1.7.3\r\n Git commit:   49bf474\r\n Built:        Tue Jan 17 09:44:08 2017\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      1.13.0\r\n API version:  1.25 (minimum version 1.12)\r\n Go version:   go1.7.3\r\n Git commit:   49bf474\r\n Built:        Tue Jan 17 09:44:08 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: false\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 4\r\n Running: 3\r\n Paused: 0\r\n Stopped: 1\r\nImages: 233\r\nServer Version: 1.13.0\r\nStorage Driver: aufs\r\n Root Dir: /home/var-docker/aufs\r\n Backing Filesystem: extfs\r\n Dirs: 578\r\n Dirperm1 Supported: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\nSwarm: active\r\n NodeID: w4dwja2i927qhe4tbuuirwhkg\r\n Is Manager: true\r\n ClusterID: am788rn0mc5vdqtqna79g237a\r\n Managers: 1\r\n Nodes: 1\r\n Orchestration:\r\n  Task History Retention Limit: 5\r\n Raft:\r\n  Snapshot Interval: 10000\r\n  Number of Old Snapshots to Retain: 0\r\n  Heartbeat Tick: 1\r\n  Election Tick: 3\r\n Dispatcher:\r\n  Heartbeat Period: 5 seconds\r\n CA Configuration:\r\n  Expiry Duration: 3 months\r\n Node Address: 192.168.234.174\r\n Manager Addresses:\r\n  192.168.234.174:2377\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: 03e5862ec0d8d3b3f750e19fca3ee367e13c090e\r\nrunc version: 2f7393a47307a16f8cee44a37b262e8b81021e3e\r\ninit version: 949e6fa\r\nKernel Version: 3.16.0-4-amd64\r\nOperating System: Debian GNU/Linux 8 (jessie)\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 4\r\nTotal Memory: 5.75 GiB\r\nName: bmitch-asusr556l\r\nID: LTRH:V6W7:3UHO:4AV2:OSYM:6G4R:WKJR:2BRK:MGCO:Z4KJ:UPTF:LTRU\r\nDocker Root Dir: /home/var-docker\r\nDebug Mode (client): false\r\nDebug Mode (server): false\r\nUsername: bmitch3020\r\nRegistry: https://index.docker.io/v1/\r\nWARNING: No kernel memory limit support\r\nWARNING: No cpu cfs quota support\r\nWARNING: No cpu cfs period support\r\nLabels:\r\n foo=bar\r\n env=laptop\r\nExperimental: false\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\nSeen on physical and virtual machines, Debian and RHEL."},{"labels":["api",null],"text":"**Description**\r\n\r\nincorrect images/create API call returns response 200 OK and 2 json messages, one of them is error description\r\n\r\n**Steps to reproduce the issue:**\r\n`$ curl -v --unix-socket /var/run/docker.sock -X POST \"http:/v1.25/images/create?repo=acme.com%2Ftest&fromSrc=%2Fdata%2Ffile.tar\"`\r\nor\r\n```\r\nimport docker\r\nd = docker.from_env()\r\nprint(d.images.client.api.import_image(\"/data/file.tar\", \"acme.com/test\"))\r\n```\r\n\r\n**Describe the results you received:**\r\n```\r\n*   Trying /var/run/docker.sock...\r\n* Connected to http (/var/run/docker.sock) port 80 (#0)\r\n> POST /v1.25/images/create?repo=acme.com%2Ftest&fromSrc=%2Fdata%2Ffile.tar HTTP/1.1\r\n> Host: http\r\n> User-Agent: curl/7.47.0\r\n> Accept: */*\r\n>\r\n< HTTP/1.1 200 OK\r\n< Api-Version: 1.25\r\n< Content-Type: application/json\r\n< Docker-Experimental: true\r\n< Server: Docker/1.13.0 (linux)\r\n< Date: Fri, 03 Feb 2017 15:03:38 GMT\r\n< Transfer-Encoding: chunked\r\n<\r\n{\"status\":\"Downloading from http://%2Fdata%2Ffile.tar\"}\r\n{\"errorDetail\":{\"message\":\"parse http://%2Fdata%2Ffile.tar: invalid URL escape \\\"%2F\\\"\"},\"error\":\"parse http://%2Fdata%2Ffile.tar: invalid URL escape \\\"%2F\\\"\"}\r\n* Connection #0 to host http left intact\r\n```\r\nor\r\n```\r\n{\"status\":\"Downloading from http://%2Fdata%2Ffile.tar\"}\r\n{\"errorDetail\":{\"message\":\"parse http://%2Fdata%2Ffile.tar: invalid URL escape \\\"%2F\\\"\"},\"error\":\"parse http://%2Fdata%2Ffile.tar: invalid URL escape \\\"%2F\\\"\"}\r\n```\r\n\r\n**Describe the results you expected:**\r\nI would expect non 200 response and single json message, so response could be parsed.\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\nI'm using python docker API which does not raise exception on this incorrect request, as response code is 200. Also python API returns response as text and could not parse response if I specify json response type as there are 2 messages in response.\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      1.13.0\r\n API version:  1.25\r\n Go version:   go1.7.3\r\n Git commit:   49bf474\r\n Built:        Tue Jan 17 09:58:26 2017\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      1.13.0\r\n API version:  1.25 (minimum version 1.12)\r\n Go version:   go1.7.3\r\n Git commit:   49bf474\r\n Built:        Tue Jan 17 09:58:26 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: true\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 19\r\n Running: 14\r\n Paused: 0\r\n Stopped: 5\r\nImages: 102\r\nServer Version: 1.13.0\r\nStorage Driver: aufs\r\n Root Dir: /var/lib/docker/aufs\r\n Backing Filesystem: extfs\r\n Dirs: 110\r\n Dirperm1 Supported: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host ipvlan macvlan null overlay\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: 03e5862ec0d8d3b3f750e19fca3ee367e13c090e\r\nrunc version: 2f7393a47307a16f8cee44a37b262e8b81021e3e\r\ninit version: 949e6fa\r\nSecurity Options:\r\n apparmor\r\n seccomp\r\n  Profile: default\r\nKernel Version: 4.4.0-59-generic\r\nOperating System: Ubuntu 16.04.1 LTS\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 30\r\nTotal Memory: 31.42 GiB\r\nName: jbuild\r\nID: TNIU:DAHP:PAIG:EGPV:HVX4:E4P6:KENQ:TOAX:QDEP:A3VD:JSPL:JQME\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): false\r\nRegistry: https://index.docker.io/v1/\r\nWARNING: No swap limit support\r\nExperimental: true\r\nInsecure Registries:\r\n docker.acme.com\r\n registry-proxy.acme.com\r\n 127.0.0.0/8\r\nRegistry Mirrors:\r\n registry-proxy.acme.com\r\nLive Restore Enabled: true\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\nDocker daemon running in Ubuntu 16.04 VM on ESXi 6 host. Client is docker python API 2.0.2 running on physical Windows 10 host."},{"labels":["api",null,null],"text":"**Description**\r\n\r\nSometimes he delete container API returns a 400. Retrying the same request after waiting for 2 seconds fixes the issue. The same code that was running for a month all of a sudden started having this error show up fairly frequently.\r\n\r\nHere is a log of the behavior from my client code.\r\n\r\n```\r\n2017-01-12T20:29:00.344289890+00:00 DEBUG volcano_agent - Removing container 491f5859c671db6d809a46c54631ef7b3ef207126b2a530ce361b534d905fa7c\r\n2017-01-12T20:29:00.344489346+00:00 DEBUG hyper::http::h1 - request line: Delete \"/containers/491f5859c671db6d809a46c54631ef7b3ef207126b2a530ce361b534d905fa7c?v=false\" Http11\r\n2017-01-12T20:29:00.344534623+00:00 DEBUG hyper::http::h1 - headers=Headers { Content-Length: 0, Host: ///var/run/docker.sock:0, }\r\n2017-01-12T20:29:00.344782407+00:00 DEBUG hyper::client::response - version=Http11, status=BadRequest\r\n2017-01-12T20:29:00.344804377+00:00 DEBUG hyper::client::response - headers=Headers { Content-Type: text/plain, Connection: close, }\r\n2017-01-12T20:29:00.344851455+00:00 DEBUG volcano_agent - remove container error 1\r\n2017-01-12T20:29:01.345225504+00:00 DEBUG hyper::http::h1 - request line: Delete \"/containers/491f5859c671db6d809a46c54631ef7b3ef207126b2a530ce361b534d905fa7c?v=false\" Http11\r\n2017-01-12T20:29:01.345325732+00:00 DEBUG hyper::http::h1 - headers=Headers { Content-Length: 0, Host: ///var/run/docker.sock:0, }\r\n2017-01-12T20:29:01.345600473+00:00 DEBUG hyper::client::response - version=Http11, status=BadRequest\r\n2017-01-12T20:29:01.345634780+00:00 DEBUG hyper::client::response - headers=Headers { Content-Type: text/plain, Connection: close, }\r\n2017-01-12T20:29:01.345682352+00:00 DEBUG volcano_agent - remove container error 2\r\n2017-01-12T20:29:02.346634708+00:00 DEBUG hyper::http::h1 - request line: Delete \"/containers/491f5859c671db6d809a46c54631ef7b3ef207126b2a530ce361b534d905fa7c?v=false\" Http11\r\n2017-01-12T20:29:02.346882532+00:00 DEBUG hyper::http::h1 - headers=Headers { Host: ///var/run/docker.sock:0, Content-Length: 0, }\r\n2017-01-12T20:29:02.357925431+00:00 DEBUG hyper::client::response - version=Http11, status=NoContent\r\n2017-01-12T20:29:02.358021182+00:00 DEBUG hyper::client::response - headers=Headers { Date: Thu, 12 Jan 2017 20:29:02 GMT, Server: Docker/1.12.3 (linux), Connection: close, }\r\n```\r\n\r\nI would show the docker log, but even though I turned on `--debug` and I could see detail on all other API requests, nothing showed up in the docker logs!\r\n\r\nI am just using the docker socket.\r\n\r\n\r\n**Describe the results you received:**\r\n\r\nThe delete container API returns a 400. Waiting for more than 1 second and retrying fixes the issue. \r\n\r\n**Describe the results you expected:**\r\n\r\nEither a 50x HTTP error code or a successful delete\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nDocker version 1.12.6, build 7392c3b/1.12.6\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 10\r\n Running: 6\r\n Paused: 0\r\n Stopped: 4\r\nImages: 6\r\nServer Version: 1.12.6\r\nStorage Driver: overlay\r\n Backing Filesystem: extfs\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: null host overlay bridge\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nSecurity Options:\r\nKernel Version: 4.4.41-35.53.amzn1.x86_64\r\nOperating System: Amazon Linux AMI 2016.09\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 32\r\nTotal Memory: 58.97 GiB\r\nName: ip-10-40-4-50\r\nID: XUZT:PPPI:W7PD:ENFJ:NKSX:M63C:F4DT:FRJG:MZOB:VUA4:IIEW:EVXR\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): false\r\nRegistry: https://index.docker.io/v1/\r\nInsecure Registries:\r\n 127.0.0.0/8\r\n```\r\n\r\nAbove information is a production system on AWS. I have also re-produced this behavior on my Local LInux computer, information below:\r\n\r\n```\r\nDocker version 1.12.3, build 6b644ec\r\n```\r\n\r\n```\r\nContainers: 4\r\n Running: 2\r\n Paused: 0\r\n Stopped: 2\r\nImages: 397\r\nServer Version: 1.12.3\r\nStorage Driver: aufs\r\n Root Dir: /var/lib/docker/aufs\r\n Backing Filesystem: extfs\r\n Dirs: 594\r\n Dirperm1 Supported: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge null overlay host\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nSecurity Options: apparmor seccomp\r\nKernel Version: 4.4.0-57-generic\r\nOperating System: Ubuntu 16.04.1 LTS\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 8\r\nTotal Memory: 15.6 GiB\r\nName: greg-Galago-UltraPro\r\nID: 3IGP:EOTD:QI7P:YIK5:RFY7:UE7S:HNEC:7ZVB:5ITE:AFWR:PETC:P3RG\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 24\r\n Goroutines: 38\r\n System Time: 2017-01-13T21:16:20.300684426-08:00\r\n EventsListeners: 1\r\nUsername: gregweber\r\nRegistry: https://index.docker.io/v1/\r\nWARNING: No swap limit support\r\nInsecure Registries:\r\n 127.0.0.0/8\r\n```"},{"labels":["api"],"text":"Hello, in preparation for Go1.8, I detected this misuse of the `http.Hijacker` API.\r\n\r\nThe following uses of `Hijack`:\r\n* [api/server/router/container/container_routes.go](https://github.com/docker/docker/blob/a6be56b54e871c4e7a6e72881770a64676c27c3c/api/server/router/container/container_routes.go#L440)\r\n* [api/server/httputils/httputils.go](https://github.com/docker/docker/blob/64981b9f095459ae65954ca80a86c8f4a735ef24/api/server/httputils/httputils.go#L24)\r\n\r\nmake calls to `Hijack`, but ignores the returned `bufio.ReadWriter` and proceeds to directly use the connection. In Go1.8, the probability that data is buffered in the `bufio.Reader` is increased, such that there is a higher change that this logic fails. The proper fix is probably to handle the data in the read buffer (accessed via `brw.Reader.Peek(brw.Reader.Buffered())`) and create a wrapped `net.Conn` that reads the buffered data before calling `net.Conn.Read`.\r\n\r\n```go\r\ntype rbufConn struct {\r\n\tnet.Conn\r\n\trbuf []byte\r\n}\r\n\r\nfunc (c *rbufConn) Read(p []byte) (int, error) {\r\n\tif len(c.rbuf) > 0 {\r\n\t\tn := copy(p, c.rbuf)\r\n\t\tc.rbuf = c.rbuf[n:]\r\n\t\treturn n, nil\r\n\t}\r\n\treturn c.Conn.Read(p)\r\n}\r\n\r\nfunc (c *rbufConn) Close() error {\r\n\tc.rbuf = nil\r\n\treturn c.Conn.Close()\r\n}\r\n```"},{"labels":["api",null,null],"text":"When the server is running Docker 1.13.0-rc5, when the client runs `docker images` the sizes will be reported as -1\r\n\r\n```\r\n$ docker version\r\nClient:\r\n Version:      1.11.1\r\n API version:  1.23\r\n Go version:   go1.5.4\r\n Git commit:   5604cbe\r\n Built:        Wed Apr 27 00:34:20 2016\r\n OS/Arch:      darwin/amd64\r\n\r\nServer:\r\n Version:      1.13.0-rc5\r\n API version:  1.25\r\n Go version:   go1.7.3\r\n Git commit:   43cc971\r\n Built:        Thu Jan  5 03:07:30 2017\r\n OS/Arch:      linux/amd64\r\n```\r\n\r\n```\r\n$ docker images\r\nREPOSITORY                        TAG                 IMAGE ID            CREATED             SIZE\r\nkatacoda/docker-http-server       large               1e023cfd8ba8        18 hours ago        -1 B\r\nkatacoda/docker-http-server       latest              c6dfc1d5003f        18 hours ago        -1 B\r\nkatacoda/docker-http-server       v1                  c6dfc1d5003f        18 hours ago        -1 B\r\n```\r\n\r\nUpgrading the client to Docker 1.13 fixes the issue.\r\n\r\n```\r\n$ docker version\r\nClient:\r\n Version:      1.13.0-rc5\r\n API version:  1.25\r\n Go version:   go1.7.3\r\n Git commit:   43cc971\r\n Built:        Thu Jan  5 03:07:30 2017\r\n OS/Arch:      darwin/amd64\r\n\r\nServer:\r\n Version:      1.13.0-rc5\r\n API version:  1.25 (minimum version 1.12)\r\n Go version:   go1.7.3\r\n Git commit:   43cc971\r\n Built:        Thu Jan  5 03:07:30 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: false\r\n```\r\n\r\n```\r\n$ docker images\r\nREPOSITORY                        TAG                 IMAGE ID            CREATED             SIZE\r\nkatacoda/docker-http-server       large               1e023cfd8ba8        18 hours ago        771 MB\r\nkatacoda/docker-http-server       latest              c6dfc1d5003f        18 hours ago        7.59 MB\r\nkatacoda/docker-http-server       v1                  c6dfc1d5003f        18 hours ago        7.59 MB\r\n```"},{"labels":["api",null,null],"text":"**Description**\r\n\r\nWhen I call networks API with filter type=custom docker API returns response 200 with body null.\r\nIt happens when no custom networks exist.\r\n\r\n**Steps to reproduce the issue:**\r\n1. Ensure no custom networks exist in a system. E.g. **docker network ls** returns bridge, host, none only.\r\n2. Execute \r\n```\r\ncurl localhost:2375/v1.20/networks?filters=%7B%22type%22:%5B%22custom%22%5D%7D\r\n```\r\n\r\n**Describe the results you received:**\r\nDocker returns response 200 with body\r\n```\r\nnull\\n\r\n```\r\n\r\n**Describe the results you expected:**\r\nDocker returns response 200 with body\r\n```\r\n[]\r\n```\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\nVersion:      1.12.1\r\nAPI version:  1.24\r\nGo version:   go1.6.3\r\nGit commit:   23cf638\r\nBuilt:        \r\nOS/Arch:      linux/amd64\r\n\r\nServer:\r\nVersion:      1.12.1\r\nAPI version:  1.24\r\nGo version:   go1.6.3\r\nGit commit:   23cf638\r\nBuilt:        \r\nOS/Arch:      linux/amd64\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 6\r\nRunning: 3\r\nPaused: 0\r\nStopped: 3\r\nImages: 9\r\nServer Version: 1.12.1\r\nStorage Driver: devicemapper\r\nPool Name: docker-253:0-2097431-pool\r\nPool Blocksize: 65.54 kB\r\nBase Device Size: 10.74 GB\r\nBacking Filesystem: xfs\r\nData file: /dev/loop0\r\nMetadata file: /dev/loop1\r\nData Space Used: 2.911 GB\r\nData Space Total: 107.4 GB\r\nData Space Available: 85.6 GB\r\nMetadata Space Used: 4.801 MB\r\nMetadata Space Total: 2.147 GB\r\nMetadata Space Available: 2.143 GB\r\nThin Pool Minimum Free Space: 10.74 GB\r\nUdev Sync Supported: true\r\nDeferred Removal Enabled: false\r\nDeferred Deletion Enabled: false\r\nDeferred Deleted Device Count: 0\r\nData loop file: /var/lib/docker/devicemapper/devicemapper/data\r\nWARNING: Usage of loopback devices is strongly discouraged for production use. Use `--storage-opt dm.thinpooldev` to specify a custom block storage device.\r\nMetadata loop file: /var/lib/docker/devicemapper/devicemapper/metadata\r\nLibrary Version: 1.02.122 (2016-04-09)\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\nVolume: local\r\nNetwork: null bridge host overlay\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nSecurity Options: seccomp\r\nKernel Version: 4.7.6-200.fc24.x86_64\r\nOperating System: Fedora 24 (Workstation Edition)\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 4\r\nTotal Memory: 31.39 GiB\r\nName: *******************************************\r\nID: XZ57:ZSSX:MXN6:OX6H:WM54:BL5T:46ZT:OOFV:2FCP:CWF2:HAQ2:ZBFY\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): false\r\nRegistry: https://index.docker.io/v1/\r\nInsecure Registries:\r\n127.0.0.0/8\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\nphysical\r\nReproduced on several distributions, such as CentOS, Fedora, Ubuntu.\r\nReproduced on Docker 1.12.1, 1.12.5."},{"labels":["api",null,null,null],"text":"I have the same issu like #28528 but with1.13.0-rc4:\r\nError response from daemon: rpc error: code = 3 desc = driver name: if driver is specified name is required.\r\nI get the error when i'm trying to define a static IP address for a container.\r\n**My version is:**\r\nClient:\r\nVersion: 1.13.0-rc4\r\nAPI version: 1.25\r\nGo version: go1.7.3\r\nGit commit: 88862e7\r\nBuilt: Fri Dec 16 22:55:47 2016\r\nOS/Arch: linux/amd64\r\n\r\nServer:\r\nVersion: 1.13.0-rc4\r\nAPI version: 1.25 (minimum version 1.12)\r\nGo version: go1.7.3\r\nGit commit: 88862e7\r\nBuilt: Fri Dec 16 22:55:47 2016\r\nOS/Arch: linux/amd64\r\nExperimental: true\r\n\r\n**My compose file is (i'm using docker stacks):**\r\n```yaml\r\nnetworks:\r\ndefault_network:\r\ndriver: overlay\r\nipam:\r\nconfig:\r\n- subnet: 10.5.0.0/16\r\ngateway: 10.5.0.1\r\n```"},{"labels":["api"],"text":"Pull request https://github.com/docker/docker/pull/28532 changed the status code for Swarm API endpoints from `406 Not Acceptable` to `503 Service Unavailable`\r\n\r\nThere are two issues with this change currently, that **must** be addressed / decided on before 1.13 GA\r\n\r\n\r\n1. **The change in status code must be versioned**\r\n\r\n    (see https://github.com/docker/docker/pull/28349#issuecomment-262236124); currently, a docker 1.13 daemon returns status `503 Service Unavailable` for all API versions, including for API 1.24, whereas a docker 1.12 daemon returns status `406`. Given that we cannot change a versioned API, we should update the code to return `406` for API 1.24, and `503` (or what we decide on, see `2.`) for API 1.25 and up\r\n\r\n    I don't think there are discussions about this change, it just needs to be implemented.\r\n\r\n2. **We must decide on the correct status code**\r\n\r\n     See https://github.com/docker/docker/pull/28532#issuecomment-265839863; it is disputed that a `5xx` status code is correct; reasoning there is that if Swarm mode is inactive, the Swarm API endpoints are not implemented, hence \"not available\". For that reason a `404` status code is suggested. \r\n\r\n    w.r.t. https://github.com/docker/docker/pull/28532#issuecomment-265868008;\r\n    > \"It also allows a client to differentiate between missing and not part of the server at all.\" \r\n\r\n   we should look if there _are_ other actions to be taken by the client; what other actions do we expect the client to take if swarm mode is not enabled; if it's just \"print the error message\", then this may not be a problem.\r\n\r\n\r\nping @stevvooe @justincormack @vieux @bfirsh PTAL. I made this a P0 so that we make the required changes before GA"},{"labels":["api",null,null],"text":"**Description**\r\n\r\nIn Docker 1.12, making a POST request to the `/v1.24/swarm/leave` endpoint to an engine not part of a Swarm would respond with status code `406 (NOT ACCEPTABLE)`. \r\nIn Docker 1.13, the same POST request now responds with status code `503 (SERVICE UNAVAILABLE)`.\r\n\r\nThis is a breaking change for this endpoint at a pre-existing API version.\r\n\r\n**Steps to reproduce the issue:**\r\n1. Set up a Docker engine node that is not part of a Swarm and exposes the API over HTTP (e.g. `sudo docker -H 127.0.0.1:2375 daemon`)\r\n2. Make a POST request to the `/v1.24/swarm/leave` endpoint:\r\n```\r\ncurl -v -d '' http://127.0.0.1:2375/v1.24/swarm/leave\r\n```\r\n\r\n**Describe the results you received:**\r\n\r\n```\r\n$ curl -v -d '' http://127.0.0.1:2375/v1.24/swarm/leave\r\n*   Trying 127.0.0.1...\r\n* Connected to 127.0.0.1 (127.0.0.1) port 2375 (#0)\r\n> POST /v1.24/swarm/leave HTTP/1.1\r\n> Host: 127.0.0.1:2375\r\n> User-Agent: curl/7.47.0\r\n> Accept: */*\r\n> Content-Length: 0\r\n> Content-Type: application/x-www-form-urlencoded\r\n> \r\n< HTTP/1.1 503 Service Unavailable\r\n< Api-Version: 1.25\r\n< Content-Type: application/json\r\n< Docker-Experimental: false\r\n< Server: Docker/1.13.0-rc3 (linux)\r\n< Date: Tue, 06 Dec 2016 20:07:31 GMT\r\n< Content-Length: 47\r\n* HTTP error before end of send, stop sending\r\n< \r\n{\"message\":\"This node is not part of a swarm\"}\r\n```\r\n\r\n**Describe the results you expected:**\r\n\r\n`HTTP/1.1 406 Not Acceptable`, as indicated in the [Remote API 1.24 reference](https://docs.docker.com/engine/reference/api/docker_remote_api_v1.24/#leave-a-swarm)\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      1.13.0-rc3\r\n API version:  1.25\r\n Go version:   go1.7.3\r\n Git commit:   4d92237\r\n Built:        Mon Dec  5 19:05:57 2016\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      1.13.0-rc3\r\n API version:  1.25 (minimum version 1.12)\r\n Go version:   go1.7.3\r\n Git commit:   4d92237\r\n Built:        Mon Dec  5 19:05:57 2016\r\n OS/Arch:      linux/amd64\r\n Experimental: false\r\n```\r\n\r\n"},{"labels":["api",null],"text":"I'm using docker in mas OS with TLS and CORS enabled. I'm connecting to the docker daemon from javascript, but I get following error in the browser:\r\nNo 'Access-Control-Allow-Origin' header is present on the requested resource\r\n\r\nI'm using following curl commands to check docker behaviour (I've previously created the container and the images):\r\n1. I create a process with exec:\r\n\r\n```\r\ncurl -v -X POST -H \"Content-Type: application/json\" --cert ..../cert.p12 --pass XXXX --key ..../key.pem --cacert ..../ca.pem https://192.168.99.100:2376/containers/ba88fb9efcce4962dbd9faaed1e7580df6d33d8778f08e1f469a57b7a4fee118/exec -d '{                 \r\n\"AttachStdin\" : false,\r\n\"AttachStdout\" : true,\r\n\"AttachStderr\" : true,\r\n\"Tty\" : false,\r\n\"Cmd\" : [\"/bin/date\"]}'\r\n\r\nNote: Unnecessary use of -X or --request, POST is already inferred.\r\n*   Trying 192.168.99.100...\r\n* Connected to 192.168.99.100 (192.168.99.100) port 2376 (#0)\r\n* WARNING: SSL: CURLOPT_SSLKEY is ignored by Secure Transport. The private key must be in the Keychain.\r\n* WARNING: SSL: Certificate type not set, assuming PKCS#12 format.\r\n* Client certificate: mmiguel.<bootstrap>\r\n* WARNING: using IP address, SNI is being disabled by the OS.\r\n* TLS 1.2 connection using TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\r\n* Server certificate: XXXX\r\n* Server certificate: XXXX\r\n> POST /containers/ba88fb9efcce4962dbd9faaed1e7580df6d33d8778f08e1f469a57b7a4fee118/exec HTTP/1.1\r\n> Host: 192.168.99.100:2376\r\n> User-Agent: curl/7.49.1\r\n> Accept: */*\r\n> Content-Type: application/json\r\n> Content-Length: 108\r\n> \r\n* upload completely sent off: 108 out of 108 bytes\r\n< HTTP/1.1 201 Created\r\n< Access-Control-Allow-Headers: Origin, X-Requested-With, Content-Type, Accept, X-Registry-Auth\r\n< Access-Control-Allow-Methods: HEAD, GET, POST, DELETE, PUT, OPTIONS\r\n< Access-Control-Allow-Origin: *\r\n< Content-Type: application/json\r\n< Server: Docker/1.12.3 (linux)\r\n< Date: Fri, 02 Dec 2016 12:21:30 GMT\r\n< Content-Length: 74\r\n< \r\n{\"Id\":\"6b2f0da5b53fc60d9ab87256bc2c625fdde77ead838daa3c1902db7405885a6c\"}\r\n* Connection #0 to host 192.168.99.100 left intact\r\n```\r\n\r\nWhen I execute the create exec command I receive the Access-Control-Allow-Origin header, and the process id.\r\n\r\n2. Then I start the exec process:\r\n\r\n```\r\ncurl -v -X POST -H \"Content-Type: application/json\" --cert ..../cert.p12 --pass XXXX --key ..../key.pem --cacert .... /ca.pem https://192.168.99.100:2376/exec/6b2f0da5b53fc60d9ab87256bc2c625fdde77ead838daa3c1902db7405885a6c/start -d '{\"Detach\" : false, \"Tty\" : false}'\r\n\r\nNote: Unnecessary use of -X or --request, POST is already inferred.\r\n*   Trying 192.168.99.100...\r\n* Connected to 192.168.99.100 (192.168.99.100) port 2376 (#0)\r\n* WARNING: SSL: CURLOPT_SSLKEY is ignored by Secure Transport. The private key must be in the Keychain.\r\n* WARNING: SSL: Certificate type not set, assuming PKCS#12 format.\r\n* Client certificate: mmiguel.<bootstrap>\r\n* WARNING: using IP address, SNI is being disabled by the OS.\r\n* TLS 1.2 connection using TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\r\n* Server certificate: xxxx\r\n* Server certificate: xxxx\r\n> POST /exec/6b2f0da5b53fc60d9ab87256bc2c625fdde77ead838daa3c1902db7405885a6c/start HTTP/1.1\r\n> Host: 192.168.99.100:2376\r\n> User-Agent: curl/7.49.1\r\n> Accept: */*\r\n> Content-Type: application/json\r\n> Content-Length: 33\r\n> \r\n* upload completely sent off: 33 out of 33 bytes\r\n< HTTP/1.1 200 OK\r\n< Content-Type: application/vnd.docker.raw-stream\r\n* no chunk, no close, no size. Assume close to signal end\r\n< \r\nFri Dec  2 12:25:06 UTC 2016\r\n* Closing connection 0\r\n```\r\n\r\nThis executes the command (/bin/date), I receive the output, but the header doesn't includes Access-Control-Allow-Origin header (previous execution with the same configuration included the header).\r\nBecause of that I can't get the execution result, when I execute the same thing from javascript in the client browser.\r\n\r\nDo I need to make any cors configuration for the process that we create with the exec command?\r\n(I haven't found anything about this in the rest api doc)."},{"labels":["api",null],"text":"since https://github.com/docker/docker/pull/28840/ got merged, the swagger generation is not working as expected.\r\n\r\n* doing a `make swagger-gen` now generated a `api/types/containers` with an `s` owned by root instead of updating the files in `api/types/container`\r\n* `rm api/types/volume/volumes_create.go && make swagger-gen` doesn't' generate the missing file.\r\n\r\nlooks like tags have a effect on the folder where the types are generated and the above PR changed them.\r\n\r\n/cc @bfirsh @dnephin \r\n\r\nit blocks https://github.com/docker/docker/pull/29002"},{"labels":["api",null,null,null,null],"text":"**Description**\r\n**Steps to reproduce the issue:**\r\n1. Get docker v1.13 on Docker for Mac\r\n2. `docker run -d --restart=on-failure nginx`\r\n\r\n**Describe the results you received:**\r\n```\r\ndocker: Error response from daemon: maximum restart count must be a positive integer.\r\nSee 'docker run --help'.\r\n```\r\n\r\n**Describe the results you expected:**\r\n* Container is started without a problem.\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\n$ docker version\r\nClient:\r\n Version:      1.13.0-rc2\r\n API version:  1.25\r\n Go version:   go1.7.3\r\n Git commit:   1f9b3ef\r\n Built:        Wed Nov 23 17:40:58 2016\r\n OS/Arch:      darwin/amd64\r\n\r\nServer:\r\n Version:             1.13.0-rc2\r\n API version:         1.25\r\n Minimum API version: 1.12\r\n Go version:          go1.7.3\r\n Git commit:          1f9b3ef\r\n Built:               Wed Nov 23 17:40:58 2016\r\n OS/Arch:             linux/amd64\r\n Experimental:        true\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\nhttp://pastebin.com/raw/ckKsKLNh\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n* Docker for Mac\r\n* The same thing works with docker v1.12.\r\n"},{"labels":["api",null,null,null,null],"text":"This is a continuation of #27275\r\n\r\nIn 1.11 a change was introduced to validate that hostnames are RFC compliant (#20566, https://tools.ietf.org/html/rfc1123).\r\nThis change did not follow the normal deprecation policy and broke users using non-RFC compliant hostnames.\r\n\r\nAffected versions are Docker 1.11 - 1.13-rc2\r\n\r\nPing @thaJeztah \r\n@vdemeester who I believe introduced version checking at least in the API to only valid in api versions >= 1.24 (1.12+)"},{"labels":["api",null],"text":"**Description**\r\n\r\nThe Docker client API from tag v1.13.0-rc2 breaks the ImageList API when used with a Docker server below 1.25.\r\n\r\n**Steps to reproduce the issue:**\r\n\r\n1. Create a client with version 1.24: ```client := NewClient(socket, \"1.24\", nil, header))```\r\n2. Build an ImageListOptions object with a ```reference``` filter (replaces the MatchName property from previous versions of the API):\r\n```\r\n    filter := filters.NewArgs()\r\n    filter.Add(\"reference\", imageName)\r\n    options := types.ImageListOptions{All: false, Filters: filter}\r\n```\r\n3. Use the ImageList object with these options: ```list, err := client.ImageList(ctx, options)```\r\n4. Test the client against a 1.12.3 Docker engine\r\n\r\n**Describe the results you received:**\r\n\r\nThe Docker engine complains about an unknown filter:\r\nError response from daemon: Invalid filter 'reference'\r\n\r\n**Describe the results you expected:**\r\n\r\nThe API should adapt (based on the version passed to NewClient) and provide the proper parameters to the server.\r\n"},{"labels":["api",null,null,null,null],"text":"I think there's a 1.13.0-rc1 (client) / 1.12.3 (server) incompatibility.\r\n\r\n**Steps to reproduce the issue:**\r\n\r\n1. `docker deploy --bundle-file .\\iv.dab iv`\r\n\r\n**Describe the results you received:**\r\n\r\nLoading bundle from .\\iv.dab\r\nCreating network iv_back-tier\r\nError response from daemon: rpc error: code = 3 desc = driver name: if driver is specified name is required\r\n\r\n**Describe the results you expected:**\r\n\r\nDAB file deployed\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\nThis works with 1.12.3 client\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      1.13.0-rc1\r\n API version:  1.24 (downgraded from 1.25)\r\n Go version:   go1.7.3\r\n Git commit:   75fd88b\r\n Built:        Fri Nov 11 22:32:34 2016\r\n OS/Arch:      windows/amd64\r\n\r\nServer:\r\n Version:             1.12.3\r\n API version:         1.24\r\n Minimum API version:\r\n Go version:          go1.6.3\r\n Git commit:          6b644ec\r\n Built:               Thu Oct 27 00:09:21 2016\r\n OS/Arch:             linux/amd64\r\n Experimental:        true\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n\r\nRunning Windows client and Docker for AWS.\r\n\r\nDAB file below:\r\n\r\n```\r\n{\r\n  \"services\": {\r\n    \"db\": {\r\n      \"Image\": \"postgres@sha256:f76245b04ddbcebab5bb6c28e76947f49222c99fec4aadb0bb1c24821a9e83ef\", \r\n      \"Networks\": [\r\n        \"back-tier\"\r\n      ]\r\n    }, \r\n    \"redis\": {\r\n      \"Image\": \"redis@sha256:2e75b1750a11e1bb060b3af6a80f8f5c536a2b16bc85c02e006ffc2f93ec8ba6\", \r\n      \"Networks\": [\r\n        \"back-tier\"\r\n      ], \r\n      \"Ports\": [\r\n        {\r\n          \"Port\": 6379, \r\n          \"Protocol\": \"tcp\"\r\n        }\r\n      ]\r\n    }, \r\n    \"result\": {\r\n      \"Image\": \"docker4x/demo-result@sha256:9932a45ccc04447430659acb88243ddf3ff207efc8cd28f6cda03da0c9d4a426\", \r\n      \"Networks\": [\r\n        \"front-tier\", \r\n        \"back-tier\"\r\n      ], \r\n      \"Ports\": [\r\n        {\r\n          \"Port\": 80, \r\n          \"Protocol\": \"tcp\"\r\n        }\r\n      ]\r\n    }, \r\n    \"vote\": {\r\n      \"Image\": \"docker4x/demo-vote@sha256:c961faf9a715176f09fe10104fd763b96cf8341d274031cf477b0dfd1fe2af32\", \r\n      \"Networks\": [\r\n        \"front-tier\", \r\n        \"back-tier\"\r\n      ], \r\n      \"Ports\": [\r\n        {\r\n          \"Port\": 80, \r\n          \"Protocol\": \"tcp\"\r\n        }\r\n      ]\r\n    }, \r\n    \"worker\": {\r\n      \"Image\": \"docker4x/demo-worker@sha256:df16d85fba95eef19d2d53f1ee5367c22aa4956fab0977ed9a187d69ec15dab0\", \r\n      \"Networks\": [\r\n        \"back-tier\"\r\n      ]\r\n    }\r\n  }, \r\n  \"version\": \"0.1\"\r\n}\r\n```\r\n\r\ncc @vieux @mavenugo "},{"labels":["api",null,null],"text":"**Description**\r\n\r\n`docker info` yields the following error message, and doesn't display the info:\r\n```\r\nError reading remote info: json: cannot unmarshal object into Go value of type string\r\n```\r\n\r\nAlso, pulling an image yields the following warning (but the pull proceeds anyway):\r\n```\r\nWarning: failed to get default registry endpoint from daemon (Error reading remote info: json: cannot unmarshal object into Go value of type string). Using system default: https://index.docker.io/v1/\r\n```\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nClient:\r\n Version:      1.12.1\r\n API version:  1.25\r\n Go version:   go1.6.3\r\n Git commit:   23cf638\r\n Built:        Thu Aug 18 05:32:35 2016\r\n OS/Arch:      linux/amd64\r\n Experimental: true\r\n\r\nServer:\r\n Version:      1.13.0-rc1\r\n API version:  1.25\r\n Go version:   go1.7.3\r\n Git commit:   75fd88b\r\n Built:        Fri Nov 11 19:47:07 2016\r\n OS/Arch:      linux/amd64\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nError reading remote info: json: cannot unmarshal object into Go value of type string\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n\r\nFWIW I provisioned the Engine with `docker-machine` 0.9.0-rc1 on AWS."},{"labels":["api",null,null],"text":"**Description**\r\n\r\nThe WebSocket container attach endpoint at `/containers/<container ID>/attach/ws` always sends text frames, but the data contained within those frames is just the bytestream from the container's stdout or stderr. This means that the text frames may not contain valid UTF-8 data, but the WebSocket spec requires that text frames only contain valid UTF-8:\r\n\r\nhttps://tools.ietf.org/html/rfc6455#section-8.1\r\n\r\nWeb browsers such as Chrome, for instance, will automatically close a WebSocket connection if they get invalid UTF-8 data in a text frame.\r\n\r\n**Steps to reproduce the issue:**\r\nOne can create a container that creates invalid UTF-8 data by simply doing:\r\n\r\n```\r\ndocker run -it busybox sh -c \"while true; do echo -e '\\\\xc3\\\\x28'; done\"\r\n```\r\n\r\n**Describe the results you received:**\r\nGot invalid UTF-8 bytes in a WebSocket text frame.\r\n\r\n**Describe the results you expected:**\r\nThe frames would either be marked as binary frames or their contents would be sanitized somehow.\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n**Output of `docker version`:**\r\n\r\n```\r\nServer:\r\n Version:      1.12.2-cs2\r\n API version:  1.24\r\n Go version:   go1.6.3\r\n Git commit:   d5fda6e\r\n Built:        Wed Oct 12 22:55:42 2016\r\n OS/Arch:      linux/amd64\r\n```\r\n\r\n**Output of `docker info`:**\r\n\r\n```\r\nContainers: 0\r\n Running: 0\r\n Paused: 0\r\n Stopped: 0\r\nImages: 73\r\nServer Version: 1.12.2-cs2\r\nStorage Driver: aufs\r\n Root Dir: /mnt/sda1/var/lib/docker/aufs\r\n Backing Filesystem: extfs\r\n Dirs: 77\r\n Dirperm1 Supported: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge null host overlay\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nSecurity Options: seccomp\r\nKernel Version: 4.4.24-boot2docker\r\nOperating System: Boot2Docker 1.12.1 (TCL 7.2); master : 4b170dc - Fri Oct  7 22:28:40 UTC 2016\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 1\r\nTotal Memory: 1.955 GiB\r\nName: default-cs\r\nID: AMY7:2Q4A:QOPC:LLOK:7C5O:OOTV:Q7OS:5RZN:QBQR:DC3B:DFXB:MPL6\r\nDocker Root Dir: /mnt/sda1/var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): true\r\n File Descriptors: 31\r\n Goroutines: 125\r\n System Time: 2016-11-08T19:52:31.989430161Z\r\n EventsListeners: 0\r\nUsername: wsongdocker\r\nRegistry: https://index.docker.io/v1/\r\nLabels:\r\n provider=virtualbox\r\nInsecure Registries:\r\n 127.0.0.0/8\r\n```\r\n\r\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\r\n"},{"labels":["api",null,null,null],"text":"**Description**\n\nThe Docker Remote API response to `GET /containers/(id or name)/json` changed in version 1.20 and 1.21 from prior versions, changing the location of some fields.  Docker attempts to maintain compatibility by dispatching to [a versioned function](https://github.com/docker/docker/blob/v1.12.2/daemon/inspect.go#L16-L27), which functions properly [on Linux](https://github.com/docker/docker/blob/v1.12.2/daemon/inspect_unix.go#L23) (with logic to provide the expected values of old fields).  However, on Windows, that function [just calls the current version](https://github.com/docker/docker/blob/v1.12.2/daemon/inspect_windows.go#L29-L32) instead of the requested compatibility version.\n\n**Steps to reproduce the issue:**\n1. Call the inspect API with the current API version on Linux\n2. Call the inspect API with an old (pre-1.20) version on Linux\n3. Call the inspect API with the current API version on Windows\n4. Call the inspect API with an old (pre-1.20) version on Windows\n5. Observe that a Linux daemon returns an appropriate response for the requested version while a Windows daemon returns the current API version response regardless of requested version\n\n**Describe the results you received:**\n\nA Windows daemon ignores the requested API version and just returns a response appropriate for the current version of the API.\n\n**Describe the results you expected:**\n\nExpected the Windows daemon to either return an appropriate response for the requested API version or to reject the request for an unsupported API version.\n\n**Output of `docker version`:**\n\n```\nClient:\n Version:      1.12.2-cs2-ws-beta\n API version:  1.25\n Go version:   go1.7.1\n Git commit:   050b611\n Built:        Tue Oct 11 02:35:40 2016\n OS/Arch:      windows/amd64\n\nServer:\n Version:      1.12.2-cs2-ws-beta\n API version:  1.25\n Go version:   go1.7.1\n Git commit:   050b611\n Built:        Tue Oct 11 02:35:40 2016\n OS/Arch:      windows/amd64\n```\n\n**Output of `docker info`:**\n\n```\nPS C:\\Users\\Administrator> docker info\nContainers: 0\n Running: 0\n Paused: 0\n Stopped: 0\nImages: 0\nServer Version: 1.12.2-cs2-ws-beta\nStorage Driver: windowsfilter\n Windows:\nLogging Driver: json-file\nPlugins:\n Volume: local\n Network: nat null overlay\nSwarm: inactive\nDefault Isolation: process\nKernel Version: 10.0 14393 (14393.321.amd64fre.rs1_release_inmarket.161004-2338)\nOperating System: Windows Server 2016 Datacenter\nOSType: windows\nArchitecture: x86_64\nCPUs: 8\nTotal Memory: 32 GiB\nName: EC2AMAZ-T211LER\nID: 6JSQ:WIFX:QJ25:TM5T:JBOG:CR7M:NSOW:X2AJ:QJXR:PRID:CLE2:6Q67\nDocker Root Dir: C:\\ProgramData\\docker\nDebug Mode (client): false\nDebug Mode (server): false\nRegistry: https://index.docker.io/v1/\nInsecure Registries:\n 127.0.0.0/8\nLive Restore Enabled: false\n```\n\n**Additional environment details (AWS, VirtualBox, physical, etc.):** On EC2, using Microsoft Windows Server 2016 Base with Containers - ami-5e6bce3e\n"},{"labels":["api",null],"text":"**Description**\nThe below is the response body for a `POST (uri)/containers/create?name=(name)` and it is malformed JSON but valid JS. This is an issue because `JSON.parse` cannot handle the response. Instead we have to resort to using `eval()` on the response.\n\nActual repsonse:\n\n``` json\n{ Id: '604e48f4b7a650340b43c0bbb139d334edf63fe3476f2e503877b3e2c8cc1a2a',\n  Warnings: null }\n```\n\nShould be:\n\n``` json\n{ \"Id\": \"604e48f4b7a650340b43c0bbb139d334edf63fe3476f2e503877b3e2c8cc1a2a\",\n  \"Warnings\": null }\n```\n\n**Steps to reproduce the issue:**\n1. Make any valid `/containers/create` request to a engine remote\n2. Run JSON.parse on the response's body\n3. Handle error `SyntaxError: Unexpected token o in JSON at position 1`\n\n**Describe the results you received:**\nI received invalid JSON on a http response that should yield valid JSON for the content-type \"application/json\"\n\n**Describe the results you expected:**\nValid json that meets RFC7159 specification  https://tools.ietf.org/html/rfc7159 \nSpecifically the part that says **\"A string begins and ends with quotation marks.\"**\n\n**Additional information you deem important (e.g. issue happens only occasionally):**\n\n**Output of `docker version`:**\n\n```\nDocker version 1.12.1, build 23cf638\n```\n\n**Output of `docker info`:**\n\n```\nContainers: 8\n Running: 0\n Paused: 0\n Stopped: 8\nImages: 10\nServer Version: 1.12.1\nStorage Driver: devicemapper\n Pool Name: docker-253:0-202281288-pool\n Pool Blocksize: 65.54 kB\n Base Device Size: 10.74 GB\n Backing Filesystem: xfs\n Data file: /dev/loop0\n Metadata file: /dev/loop1\n Data Space Used: 932.2 MB\n Data Space Total: 107.4 GB\n Data Space Available: 33.4 GB\n Metadata Space Used: 2.22 MB\n Metadata Space Total: 2.147 GB\n Metadata Space Available: 2.145 GB\n Thin Pool Minimum Free Space: 10.74 GB\n Udev Sync Supported: true\n Deferred Removal Enabled: false\n Deferred Deletion Enabled: false\n Deferred Deleted Device Count: 0\n Data loop file: /var/lib/docker/devicemapper/devicemapper/data\n Metadata loop file: /var/lib/docker/devicemapper/devicemapper/metadata\n Library Version: 1.02.107-RHEL7 (2016-06-09)\nLogging Driver: json-file\nCgroup Driver: cgroupfs\nPlugins:\n Volume: local\n Network: bridge null host overlay\nSwarm: inactive\nRuntimes: runc\nDefault Runtime: runc\nSecurity Options: seccomp\nKernel Version: 3.10.0-327.36.1.el7.x86_64\nOperating System: CentOS Linux 7 (Core)\nOSType: linux\nArchitecture: x86_64\nCPUs: 2\nTotal Memory: 3.703 GiB\nName: vm\nID: RPLT:DWEL:LJBT:54Z6:H2KO:44F5:2NQB:BL6K:L7IT:UCMJ:OYQH:UT6Z\nDocker Root Dir: /var/lib/docker\nDebug Mode (client): false\nDebug Mode (server): true\n File Descriptors: 17\n Goroutines: 26\n System Time: 2016-10-16T09:59:17.159342406-04:00\n EventsListeners: 0\nRegistry: https://index.docker.io/v1/\nInsecure Registries:\n 127.0.0.0/8\n```\n\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\nI'm running Centos 7 in VirtualBox Version 5.1.6 r110634 (Qt5.5.1)\nI can replicate this on my DigitalOcean VPS running Centos7 as well.\nI encountered this while writing a NodeJS library https://github.com/matutter/docker-as-promised/tree/dev  \n"},{"labels":["api",null,null,null],"text":"First time daemon is booted (no `docker0` bridge present, no or empty `/var/lib/docker/network/files/local-kv.db` file), IPAM.Config structure in network inspect output will not contain the Gateway field\n\n```\n$ docker network inspect bridge\n[\n    {\n        \"Name\": \"bridge\",\n        \"Id\": \"2b5cc5f97b6de6a5e0533b1e2d5bec6284d900a9a82632ce782320a19db8b9e0\",\n        \"Scope\": \"local\",\n        \"Driver\": \"bridge\",\n        \"EnableIPv6\": false,\n        \"IPAM\": {\n            \"Driver\": \"default\",\n            \"Options\": null,\n            \"Config\": [\n                {\n                    \"Subnet\": \"172.17.0.0/16\"\n                }\n            ]\n        },\n\n```\n\nVerified problem exists in `1.11.2`, `1.12.0` and in current master (`1.13.0`).\n\nGiven the `IPAM.Config` filed currently used to carry both configuration and operational data, the gateway address should always be there.\n\n**Note:**\nA daemon reload will fix the issue\n"},{"labels":["api",null,null],"text":"The following change that was merged yesterday broke some of our tests:\n\nhttps://github.com/docker/docker/commit/53774423ff0db50cb0934e7b1e5ce507363e8147#diff-5251fbdfab3c1500c0c76ec0d8adf746R78\n\nIt's a backwards incompatible API change and prevents older docker clients from running containers on newer daemons. I think it should be reverted unless a compatibility layer is added for older engines.\n"},{"labels":["api",null],"text":"**Description**\nThanks for the work on this project. \n\nAttempting to pull an image (by sending a request to the remote API) fails depending on the whitespace present in the unencoded auth config. Here are examples:\n\n``` shell\n# WORKS\nAUTH=`echo -n \"{ \\\"username\\\": \\\"$DOCKER_USERNAME\\\",\n     \\\"password\\\": \\\"$DOCKER_PASSWORD\\\",\n     \\\"serveraddress\\\": \\\"$DOCKER_REGISTRY\\\"\n}\" | perl -pe 's/\\r\\n|\\n|\\r/\\r\\n/g' | base64`;\ncurl -X POST -H \"X-Registry-Auth: $AUTH\" -H \"Cache-Control: no-cache\" \\\nhttps://$DOCKER_HOST_IP:2376/images/create\\?fromImage\\=$DOCKER_REGISTRY%2Fcassandra\\&tag\\=latest \\\n--cert $DOCKER_CERT_PATH/cert.p12 --pass mypass --key $DOCKER_CERT_PATH/key.pem --cacert $DOCKER_CERT_PATH/ca.pem\n\n# {\"status\":\"Pulling from cassandra\",\"id\":\"latest\"}\n# . . . \n```\n\n``` shell\n# FAILS\nAUTH=`echo -n \"{\\\"username\\\": \\\"$DOCKER_USERNAME\\\",\n     \\\"password\\\": \\\"$DOCKER_PASSWORD\\\",\n     \\\"serveraddress\\\": \\\"$DOCKER_REGISTRY\\\"\n}\" | perl -pe 's/\\r\\n|\\n|\\r/\\r\\n/g' | base64`;\ncurl -X POST -H \"X-Registry-Auth: $AUTH\" -H \"Cache-Control: no-cache\" \\\nhttps://$DOCKER_HOST_IP:2376/images/create\\?fromImage\\=$DOCKER_REGISTRY%2Fcassandra\\&tag\\=latest \\\n--cert $DOCKER_CERT_PATH/cert.p12 --pass mypass --key $DOCKER_CERT_PATH/key.pem --cacert $DOCKER_CERT_PATH/ca.pem\n\n# {\"message\":\"Get https://my-registry.com/v2/cassandra/manifests/latest: unauthorized: authentication required\"}\n```\n\nNote:\n- The only difference between the two is the space after the opening `{` of the auth json. No space breaks it.\n- I needed to use DOS line endings to get anything to work at all.\n\n**Output of `docker version`:**\n\n```\nClient:\n Version:      1.12.1\n API version:  1.24\n Go version:   go1.6.3\n Git commit:   23cf638\n Built:        Thu Aug 18 17:52:38 2016\n OS/Arch:      darwin/amd64\n\nServer:\n Version:      1.12.1\n API version:  1.24\n Go version:   go1.6.3\n Git commit:   23cf638\n Built:        Thu Aug 18 17:52:38 2016\n OS/Arch:      linux/amd64\n```\n\n**Output of `docker info`:**\n\n```\nContainers: 9\n Running: 2\n Paused: 0\n Stopped: 7\nImages: 13\nServer Version: 1.12.1\nStorage Driver: aufs\n Root Dir: /mnt/sda1/var/lib/docker/aufs\n Backing Filesystem: extfs\n Dirs: 180\n Dirperm1 Supported: true\nLogging Driver: json-file\nCgroup Driver: cgroupfs\nPlugins:\n Volume: local\n Network: host bridge null overlay\nSwarm: inactive\nRuntimes: runc\nDefault Runtime: runc\nSecurity Options: seccomp\nKernel Version: 4.4.17-boot2docker\nOperating System: Boot2Docker 1.12.1 (TCL 7.2); HEAD : ef7d0b4 - Thu Aug 18 21:18:06 UTC 2016\nOSType: linux\nArchitecture: x86_64\nCPUs: 1\nTotal Memory: 3.858 GiB\nName: default\nID: SLVU:TD74:RZM6:KB5M:7IXK:PEVM:7QWW:NDLB:MYTY:BY6D:BFGM:CKHF\nDocker Root Dir: /mnt/sda1/var/lib/docker\nDebug Mode (client): false\nDebug Mode (server): true\n File Descriptors: 25\n Goroutines: 48\n System Time: 2016-09-15T14:16:52.261023938Z\n EventsListeners: 0\nRegistry: https://index.docker.io/v1/\nLabels:\n provider=virtualbox\nInsecure Registries:\n 127.0.0.0/8\n```\n\n**Additional environment details (AWS, VirtualBox, physical, etc.):**\nDocker Machine is running in VirtualBox Version 5.1.4 r110228 (Qt5.5.1)\n"},{"labels":["api",null,null,null],"text":"**Description**\n\nWhen trying to create a network using the remote API, according to the documentation 1.24 (https://docs.docker.com/engine/reference/api/docker_remote_api_v1.24/#/create-a-network)\nthe IPAM field is an optional parameter, but if not provided, the following error is returned:\n\"rpc error: code = 3 desc = driver name: if driver is specified name is required\" which does not seem correct either.\n\n**Steps to reproduce the issue:**\nJust use the remote API to create a network, using curl or whatever you feel comfortable with.\n**Describe the results you received:**\n\"rpc error: code = 3 desc = driver name: if driver is specified name is required\"\n\n**Describe the results you expected:**\nstatus = 201\n\n**Output of `docker version`:**\n\n```\nClient:\n Version:      1.12.0\n API version:  1.24\n Go version:   go1.6.3\n Git commit:   8eab29e\n Built:        Thu Jul 28 23:54:00 2016\n OS/Arch:      darwin/amd64\n\nServer:\n Version:      1.12.1\n API version:  1.24\n Go version:   go1.6.3\n Git commit:   23cf638\n Built:        Thu Aug 18 05:33:38 2016\n OS/Arch:      linux/amd64\n```\n\n**Output of `docker info`:**\n\n```\nContainers: 158\n Running: 8\n Paused: 0\n Stopped: 150\nImages: 258\nServer Version: 1.12.1\nStorage Driver: aufs\n Root Dir: /var/lib/docker/aufs\n Backing Filesystem: extfs\n Dirs: 577\n Dirperm1 Supported: true\nLogging Driver: json-file\nCgroup Driver: cgroupfs\nPlugins:\n Volume: local\n Network: bridge overlay host null\nSwarm: active\n NodeID: cbq5d7h0cigpzulcfyqvaomlq\n Is Manager: true\n ClusterID: 070qemaxhu18hg3tvatjlh602\n Managers: 1\n Nodes: 1\n Orchestration:\n  Task History Retention Limit: 5\n Raft:\n  Snapshot interval: 10000\n  Heartbeat tick: 1\n  Election tick: 3\n Dispatcher:\n  Heartbeat period: 5 seconds\n CA configuration:\n  Expiry duration: 3 months\n Node Address: 138.201.132.20\nRuntimes: runc\nDefault Runtime: runc\nSecurity Options: apparmor seccomp\nKernel Version: 4.4.0-36-generic\nOperating System: Ubuntu 16.04.1 LTS\nOSType: linux\nArchitecture: x86_64\nCPUs: 8\nTotal Memory: 62.75 GiB\nName: caturra\nID: 46TP:5YN6:AVJS:7CAZ:JZJO:SFJY:H5R7:JVJR:OCQU:NW4Y:5WL7:UDLX\nDocker Root Dir: /var/lib/docker\nDebug Mode (client): false\nDebug Mode (server): false\nUsername: manast\nRegistry: https://index.docker.io/v1/\nWARNING: No swap limit support\nLabels:\n provider=generic\nInsecure Registries:\n 127.0.0.0/8\n```\n"},{"labels":["api",null,null,null],"text":"Somewhat frequently users see this error when trying to `docker rm foo`: `device or resource busy`.\nThis error is returned from the kernel when trying to remove container rw layers and/or the container config root... typically due to mounts leaked into other namespaces.\nWhen this happens the container gets flagged as `Dead` and they can re-try later... or if the user specified `-f` it'll just get removed from the container list by force even if the underlying files are still there... this may leak disk space.\n\nI propose instead of erroring out we add these paths to a deferred deletion queue where we can re-try unmounting and removing them every X amount of time.\n\nPaths in this state should be visible to the data management command proposed here: #26108\nAnd a call to `docker prune` would also cause a forced GC run of these deferred removals out-of-band from the normal run.\n\n`Dead` containers should not be seen by end users... except maybe in the aforementioned data management command.\n\nping @mlaventure \n"},{"labels":["api",null,null],"text":"# Problem statement\n\nThe API/CLI version compatibility requirement is a pain for a huge number of users, and is only getting worse as we have Docker deployed on more and more heterogeneous environments. On the daemon-side, that logic is implemented in the [`VersionMiddleware`](https://github.com/docker/docker/blob/master/api/server/middleware/version.go).\n\n```\n        if versions.GreaterThan(apiVersion, v.defaultVersion) {\n            return badRequestError{fmt.Errorf(\"client is newer than server (client API version: %s, server API version: %s)\", apiVersion, v.defaultVersion)}\n        }\n        if versions.LessThan(apiVersion, v.minVersion) {\n            return badRequestError{fmt.Errorf(\"client version %s is too old. Minimum supported API version is %s, please upgrade your client to a newer version\", apiVersion, v.minVersion)}\n        }\n```\n\nToday, the only possible workaround is a horrific hack that simply overrides the version string using the [`DOCKER_API_VERSION`](https://github.com/docker/docker/blob/7c8780ea6327b1d403b13c8b144d9557b5e655e5/api/client/cli.go#L221-L223) environment variable.\n# Possible solution\n\nCreate a Go package capable of detecting the remote version and accommodating for that (up to its own capabilities, of course). Perhaps we could create a repository that packages multiple versions of the [`docker/engine-api`](https://github.com/docker/engine-api) project and would be \"version-aware\"? It would expose the latest Go interface, and could provide policies on ways to deal with unsolvable incompatibilities (e.g., the server you're interacting with doesn't implement feature X).\n\nAny idea is welcome on the best way to tackle this!\n\nCc @vdemeester @fermayo @crosbymichael.\n"},{"labels":["api",null,null],"text":"In Rancher we've been following docker-compose format for naming containers \"stackName_serviceName_number\" (\"foo_bar_1\"). With docker 1.12 change for hostname validation, the containers can no longer be started due to \"Invalid hostname format\". \n\n@thaJeztah commented on https://github.com/rancher/rancher/issues/5195:\n\n> Could you open an issue in the Docker issue tracker as well, to discus this? Although validating the hostname may be a good thing, possibly it's too much of a breaking change\n"},{"labels":["api",null],"text":"See docker/engine-api#279\n\n> # 151 broke backward compat, since StorageOpt is unused most of a time, let's put an omitempty to prevent unmarshalling error.\n\nWe need to bump docker/engine-api for 1.12.0-RC2 and fix this issue.\n"},{"labels":["api",null,null],"text":"I use docker go api read docker log   (docker.LogsOptions{\n        Container:    id,\n        OutputStream: outwr,\n        ErrorStream:  errwr,\n        Stdout:       true,\n        Stderr:       true,\n        Follow:       true,\n        Tail:         \"0\",\n    }), when the pressure is too large,output read have a error: buf readstring stop: read/write on closed pipe,what is wrong?\n"},{"labels":["api"],"text":"As of API 1.17, creating a container with `POST /containers/create`, you could set some cpu and memory params on the top level of the posted object. These were `Memory`, `MemorySwap`, `CpuShares`, and `CpuSet`. See the [example request](https://github.com/docker/docker/blame/master/docs/reference/api/docker_remote_api_v1.17.md#L126); the params' respective [description texts](https://github.com/docker/docker/blame/master/docs/reference/api/docker_remote_api_v1.17.md#L192) were correctly placed at the top level with the other descriptions.\n\nIn API 1.18, these CPU and memory parameters were moved into `HostConfig`. However, the description text kept the parameters at the top level, i.e. they did not move into the corresponding `HostConfig` section of the description. See the [example object](https://github.com/docker/docker/blame/master/docs/reference/api/docker_remote_api_v1.18.md#L168), where the params are inside `HostConfig`, and the [description text](https://github.com/docker/docker/blame/master/docs/reference/api/docker_remote_api_v1.18.md#L209), where they are not.\n\nThis should be a pretty easy fix, right? Just move those descriptions under the `HostConfig` section. But it gets a little funnier than that.\n\nIn API 1.19, some new CPU params—`CpuPeriod`, `CpuQuota`, `CpusetMems`—were added that could be set in the `HostConfig` (see [example object](https://github.com/docker/docker/blame/master/docs/reference/api/docker_remote_api_v1.19.md#L170)). But their descriptions (brand new in this version, so they should go in the right place, right?) were added [next to the other incorrectly placed parameters](https://github.com/docker/docker/blame/master/docs/reference/api/docker_remote_api_v1.19.md#L216). :joy:\n\n...Ok, well, I think it's funny.\n\nThis problem just keeps growing with each API version. New parameters get added to `HostConfig`, and the container creation documentation shows them inside `HostConfig` for the example request, but not under `HostConfig` in the descriptions. I haven't made a comprehensive survey of exactly which parameters' descriptions should be moved in each version of the docs, but it will be a lot, and more in recent versions than older versions.\n\nLastly, while I'm pointing out issues with these parameter descriptions, I noticed another small problem that could be cleaned up at the same time. `Cpuset` has been deprecated since API 1.18, and yet it still gets documented in every version of the API docs as \n\n> **Cpuset** - Deprecated please don't use. Use `CpusetCpus` instead. \n\nCould this just be removed from the docs? At least the more recent versions. It has been deprecated for several versions now.\n"},{"labels":["api",null],"text":"There are many times when the Docker version on a client can differ to that on a server.\n\nThis is typically because that end users are faster to update their clients whereas hosted Docker services or servers in production are slower to upgrade.\n\nThis issue can be much worse when attempting to RC test the new version of Docker as you need to switch Docker Client versions or set `DOCKER_API_VERSION`. The latter can have consequences e.g newer client features and flags failing against older engine versions.\n## Today\n\nAttempting to connect to older server:\n\n```\n$ docker ps\nError response from daemon: client is newer than server (client API version: 1.23, server API version: 1.22)\n```\n\nAttempting to create an IPv6 network\n\n```\n$ DOCKER_API_VERSION=1.22 docker network create --ipv6 foo\n2d6a8ce8e8303d27fbfdc19cb1d2a73328d5d278a1dea173d31ec4b9d586e8ca\n$ DOCKER_API_VERSION=1.22 docker network inspect foo\n[\n    {\n        \"Name\": \"foo\",\n        \"Id\": \"2d6a8ce8e8303d27fbfdc19cb1d2a73328d5d278a1dea173d31ec4b9d586e8ca\",\n        \"Scope\": \"local\",\n        \"Driver\": \"bridge\",\n        \"EnableIPv6\": false,\n        \"IPAM\": {\n            \"Driver\": \"default\",\n            \"Options\": {},\n            \"Config\": [\n                {\n                    \"Subnet\": \"172.18.0.0/16\",\n                    \"Gateway\": \"172.18.0.1/16\"\n                }\n            ]\n        },\n        \"Internal\": false,\n        \"Containers\": {},\n        \"Options\": {},\n        \"Labels\": null\n    }\n]\n```\n\nThe command succeeds, but IPv6 wasn't enabled as this is only available in a newer API version!\n## Tomorrow\n\nRegardless of version, commands should work:\n\n```\n$ docker ps\nCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES\n```\n\nHandling of unsupported operations\n\n```\n$ docker network create --ipv6 foo\nError: `--ipv6` is not available on your server\nClient Version: 1.23 \nServer Version: 1.22\n```\n## Suggestion\n\nIf the Docker Client were able to maintain some form of session state, it could detect and preserve the Docker API version for a session. It should also be possible to prevent newer client features from being used on servers that do not support them to avoid inconsistencies like the example noted above\n"},{"labels":["api",null,null],"text":"Wrong HTTP-Status codes in many API-Docs, needs review\n\n**Describe the results you received:**\n\n```\ngrep \"201 OK\" docs/reference/api/*\ndocs/reference/api/docker_remote_api_v1.14.md:        HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.15.md:        HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.15.md:        HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.15.md:        HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.15.md:        HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.16.md:        HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.16.md:        HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.16.md:        HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.16.md:        HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.17.md:        HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.17.md:        HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.17.md:        HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.17.md:        HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.18.md:        HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.18.md:        HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.18.md:        HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.18.md:        HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.19.md:    HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.19.md:    HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.19.md:    HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.19.md:    HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.20.md:    HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.20.md:    HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.20.md:    HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.20.md:    HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.21.md:    HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.21.md:    HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.21.md:    HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.21.md:    HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.22.md:    HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.22.md:    HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.23.md:    HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.23.md:    HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.24.md:    HTTP/1.1 201 OK\ndocs/reference/api/docker_remote_api_v1.24.md:    HTTP/1.1 201 OK\n```\n\n**Describe the results you expected:**\nExpected \"HTTP/1.1 201 Created\" as per RFC2616\n\n**Additional information you deem important (e.g. issue happens only occasionally):**\nSometimes wrong responsetype (\"OK\" instead of \"Created\"), sometimes wrong HTTP-Status Code number \"201\" instead of \"200\" documented)\n\nThere may be other statuscode deviations in the api docs\n"},{"labels":["api"],"text":"Originally reported in https://github.com/docker/docker-py/issues/978\n\nExpected result: HTTP status 400 \"Bad request\", (ideally) with explicit error message about invalid parameter.\n\nObserved result: Connection aborted - Connection reset by peer.\n"},{"labels":["api",null,null],"text":"We have a tool that interacts with the docker API directly and it started failing on master (aka 1.10, aka 723be0a3325799fd6b2a6b689af54f5a07edf992). It tries to start containers with a custom network using the `NetworkMode` parameter in the `start` API. There is a warning that this will be removed in 1.12, but it looks like it already doesn't work for `NetworkMode`.\n\nExample docker log when this fails:\n\n```\nDEBU[0061] Calling POST /v1.13/containers/create        \nDEBU[0061] POST /v1.13/containers/create?name=(redacted) \nDEBU[0061] form data: {\"AttachStderr\":false,\"AttachStdin\":false,\"AttachStdout\":false,\"Env\":[\"NO_PROXY=(redacted)\",\"HTTPS_PROXY=\",\"HTTP_PROXY=\"],\"Image\":\"(redacted):(redacted)\",\"Memory\":0,\"MemorySwap\":0,\"NetworkDisabled\":false,\"OpenStdin\":false,\"StdinOnce\":false,\"Tty\":false}\nDEBU[0061] container mounted via layerStore: /var/lib/docker/overlay/a231abd7438a8a6dc86f68fe0e7abba14a63f89a00aa8076f3b88a0f23c2bb90/merged \nDEBU[0061] Incrementing volume reference: driver local, name cc80f3f57a0a9b57e3d787c5062f37497732f0cc2da1874c031fc3290bb85e3c \nDEBU[0061] Calling GET /v1.13/containers/json           \nDEBU[0061] GET /v1.13/containers/json?all=1&limit=-1&trunc_cmd=1&size=0 \nDEBU[0061] Calling GET /v1.13/containers/json           \nDEBU[0061] GET /v1.13/containers/json?all=0&limit=-1&trunc_cmd=1&size=0 \nDEBU[0061] Calling POST /v1.13/containers/(redacted)/start \nDEBU[0061] POST /v1.13/containers/(redacted)/start \nDEBU[0061] form data: {\"Binds\":[\"/var/(redacted):/var/(redacted):rw\"],\"NetworkMode\":\"(redacted)\",\"PortBindings\":{},\"RestartPolicy\":{\"MaximumRetryCount\":0,\"Name\":\"always\"},\"SecurityOpt\":[\"label:type:(redacted)\"]} \nWARN[0061] DEPRECATED: Setting host configuration options when the container starts is deprecated and will be removed in Docker 1.12 \nDEBU[0061] Decrementing volume reference: driver local, name cc80f3f57a0a9b57e3d787c5062f37497732f0cc2da1874c031fc3290bb85e3c \nDEBU[0061] container mounted via layerStore: /var/lib/docker/overlay/a231abd7438a8a6dc86f68fe0e7abba14a63f89a00aa8076f3b88a0f23c2bb90/merged \nDEBU[0061] Assigning addresses for endpoint (redacted)'s interface on network bridge \nDEBU[0061] RequestAddress(LocalDefault/172.17.0.0/16, <nil>, map[])\n```\n\nExpected result: Container starts attached to the custom network\nActual result: Container starts on the default \"bridge\" network\n"},{"labels":["api",null,null,null],"text":"When Docker daemon is exiting, request to retrieve containers returns container JSON without names. This may cause tooling failure. For example, swarm decides named containers do not exist, instead of engine unreachable. I think docker daemon should reject requests during shutdown. \n\nThe problem is easy to reproduce under swarm setup. Reproduce steps: \n- start a swarm manager with 1 second refresh interval\n- start a docker engine on another machine, join the swarm \n- create a container with name thru swarm, validate container name exists\n- stop Docker engine with ^C\n- send `docker ps -a` to swarm, validate container without name\n\nActual Results thru swarm:\n\n```\ndchen@vm4:~$ docker -H 192.168.56.202:2372 ps -a \nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                                            NAMES\n475f6d2008a4        busybox             \"/bin/sh -c 'echo hel\"   2 weeks ago         Host Down                                                            \n4b40a7988c1f        ubuntu              \"/bin/bash -c 'while \"   3 weeks ago         Host Down                                                            \ndd32d46a1892        nginx               \"nginx -g 'daemon off\"   3 weeks ago         Host Down           80/tcp, 443/tcp, 192.168.56.203:8080->8080/tcp   \n```\n\nExpected Results:\n\n```\ndchen@vm4:~$ docker  -H 192.168.56.202:2372 ps -a \nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                                            NAMES\n475f6d2008a4        busybox             \"/bin/sh -c 'echo hel\"   2 weeks ago         Host Down                                                            vm3/test_container1\n4b40a7988c1f        ubuntu              \"/bin/bash -c 'while \"   3 weeks ago         Host Down                                                            vm3/evil_cray\ndd32d46a1892        nginx               \"nginx -g 'daemon off\"   3 weeks ago         Host Down           80/tcp, 443/tcp, 192.168.56.203:8080->8080/tcp   vm3/tiny_euclid\n\n```\n\nDocker information. \n\n```\ndchen@vm3:~/go/src/github.com/docker/swarm$ docker version\nClient:\n Version:      1.10.0-dev\n API version:  1.22\n Go version:   go1.5.1\n Git commit:   9c1006c\n Built:        Wed Nov  4 12:36:27 UTC 2015\n OS/Arch:      linux/amd64\n\nServer:\n Version:      1.10.0-dev\n API version:  1.22\n Go version:   go1.5.1\n Git commit:   9c1006c\n Built:        Wed Nov  4 12:36:27 UTC 2015\n OS/Arch:      linux/amd64\n\ndchen@vm3:~/go/src/github.com/docker/swarm$ docker info\nContainers: 3\nImages: 259\nServer Version: 1.10.0-dev\nStorage Driver: aufs\n Root Dir: /var/lib/docker/aufs\n Backing Filesystem: extfs\n Dirs: 265\n Dirperm1 Supported: true\nExecution Driver: native-0.2\nLogging Driver: json-file\nKernel Version: 3.19.0-25-generic\nOperating System: Ubuntu 14.04.3 LTS\nCPUs: 2\nTotal Memory: 3.86 GiB\nName: vm3\nID: QCAK:VVFW:GTEN:RF4O:O5EF:4AAT:RXDM:2FIJ:FVIF:CJBL:IDUU:2DG4\nWARNING: No swap limit support\nCluster store: consul://192.168.56.204:8500/swarm\n\ndchen@vm3:~/go/src/github.com/docker/swarm$ uname -a\nLinux vm3 3.19.0-25-generic #26~14.04.1-Ubuntu SMP Fri Jul 24 21:16:20 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\n```\n"},{"labels":["api",null,null],"text":"Description of problem:\nUsing pull API to pull an image. But sometime it response detail information with `total:-1`.\n\n`docker version`:\n\n```\nClient:\n Version:      1.9.1\n API version:  1.21\n Go version:   go1.4.1\n Git commit:   d997753\n Built:        Thu Nov 26 02:31:23 UTC 2015\n OS/Arch:      linux/amd64\n\nServer:\n Version:      1.9.1\n API version:  1.21\n Go version:   go1.4.1\n Git commit:   d997753\n Built:        Thu Nov 26 02:31:23 UTC 2015\n OS/Arch:      linux/amd64\n```\n\n`docker info`:\n\n```\nContainers: 0\nImages: 116\nServer Version: 1.9.1\nStorage Driver: aufs\n Root Dir: /var/lib/docker/aufs\n Backing Filesystem: extfs\n Dirs: 116\n Dirperm1 Supported: false\nExecution Driver: native-0.2\nLogging Driver: json-file\nKernel Version: 3.13.0-65-generic\n```\n\n`uname -a`:\nLinux trusty-64abced 3.13.0-65-generic #106-Ubuntu SMP Fri Oct 2 22:08:27 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\n\nEnvironment details: VirtualBox\n\nHow reproducible:\nJust pull images by docker-py\n\nSteps to Reproduce:\n1. Pull image by docker-py\n2. Check the stream output\n\nActual Results:\n\n```\n{u'id': u'379cc190f32e',\n u'progress': u'7.395 MB',\n u'progressDetail': {u'current': 7395421, u'total': -1},\n u'status': u'Downloading'}\n```\n\nExpected Results:\ntotal without -1\n\nAdditional info:\n"},{"labels":["api",null],"text":"As of docker 1.8,\nDocker uses invalid JSON format in some API functions, as they reply with header `Content-Type: application/json`. So I expect they reply valid JSON.\n- /build\n- /images/create\n- /images/(name)/push\n- /events\n\nThis make parsing the output of these functions troublesome.\n"},{"labels":["api",null,null],"text":"Description of problem:\n\nAs described in the docs for [`/containers/(id)/logs`](https://docs.docker.com/reference/api/docker_remote_api_v1.20/#get-container-logs), the response Content-Type should be `application/vnd.docker.raw-stream`. Actually, it is always `text/plain`, using the current Docker 1.8.2 release.\n\nThings become a bit more complex, though, because plain text works well as long as the container isn't running in detached mode (Config.Tty = false). Only for a detached container the logs will be a raw stream, supporting multiplexing on stdout and stderr.\n\nFor consistency with `../attach`, it would be nice to always return the raw stream (and declare it correctly via `Content-Type`), with disabled multiplexing for attached containers.\n\nIf you like, I can try to create a PR, but I was a bit lost in the different router/cli/daemon source files... any pointer or suggestions how to tackle this would help!\n\n`docker version`:\n\n```\nClient:\n Version:      1.8.2\n API version:  1.20\n Go version:   go1.4.2\n Git commit:   0a8c2e3\n Built:        Thu Sep 10 19:10:10 UTC 2015\n OS/Arch:      darwin/amd64\n\nServer:\n Version:      1.8.2\n API version:  1.20\n Go version:   go1.4.2\n Git commit:   0a8c2e3\n Built:        Thu Sep 10 19:10:10 UTC 2015\n OS/Arch:      linux/amd64\n```\n\n`docker info`:\n\n```\nContainers: 3\nImages: 97\nStorage Driver: aufs\n Root Dir: /mnt/sda1/var/lib/docker/aufs\n Backing Filesystem: extfs\n Dirs: 103\n Dirperm1 Supported: true\nExecution Driver: native-0.2\nLogging Driver: json-file\nKernel Version: 4.0.9-boot2docker\nOperating System: Boot2Docker 1.8.2 (TCL 6.4); master : aba6192 - Thu Sep 10 20:58:17 UTC 2015\nCPUs: 1\nTotal Memory: 1.956 GiB\nName: default\nID: BDI6:3E4G:RBCP:BURV:FYFE:GEPK:J4QI:53U4:HKG4:ZUJW:XFCL:7A72\nDebug mode (server): true\nFile Descriptors: 14\nGoroutines: 23\nSystem Time: 2015-10-09T15:50:19.097175534Z\nEventsListeners: 0\nInit SHA1: \nInit Path: /usr/local/bin/docker\nDocker Root Dir: /mnt/sda1/var/lib/docker\nUsername: gesellix\nRegistry: https://index.docker.io/v1/\nLabels:\n provider=virtualbox\n```\n\n`uname -a`:\n\n```\nDarwin foo.bar 15.0.0 Darwin Kernel Version 15.0.0: Wed Aug 26 16:57:32 PDT 2015; root:xnu-3247.1.106~1/RELEASE_X86_64 x86_64\n```\n\nEnvironment details (AWS, VirtualBox, physical, etc.):\nMac w/ Docker Toolbox\n\nHow reproducible:\nalways\n\nSteps to Reproduce:\n1. run the Docker daemon\n2. `docker run -d --name container-id busybox:latest ping 127.0.0.1`\n3. `GET https://docker.host:2376/containers/container-id/logs?follow=true&stdout=true&stderr=true&timestamps=false&since=0`\n\nActual Results:\n\n```\nHTTP/1.1 200 OK\nContent-Type: text/plain; charset=utf-8\nDate: Fri, 09 Oct 2015 15:55:53 GMT\nServer: Docker/1.8.2 (linux)\nTransfer-Encoding: chunked\n```\n\nExpected Results:\n\n```\nHTTP/1.1 101 UPGRADED\nConnection: Upgrade\nContent-Type: application/vnd.docker.raw-stream\nDate: Fri, 09 Oct 2015 15:55:53 GMT\nUpgrade: tcp\nServer: Docker/1.8.2 (linux)\n```\n\nAdditional info:\n"},{"labels":["api",null,null,null],"text":"I have created an image from a running container - all good so far.\n\n```\nroot@scw-ec24f6:~# docker images\nREPOSITORY               TAG                 IMAGE ID            CREATED             VIRTUAL SIZE\nkapolos/armhf-arangodb   2.7.0-devel         6515245edb56        3 minutes ago       1.564 GB\n[...skipped...]\n```\n\nI realize I forgot to clean some files, I remove them on the still running container and commit again\n\n```\nroot@scw-ec24f6:~# docker commit hopeful_bose kapolos/armhf-arangodb:2.7.0-devel\n0bbc0ce06368e8a923737b4c8505d4157d43399495a72cf6a39b606a1b24e9ed\n```\n\nAnd then...\n\n```\nroot@scw-ec24f6:~# docker images\nREPOSITORY               TAG                 IMAGE ID            CREATED             VIRTUAL SIZE\nkapolos/armhf-arangodb   2.7.0-devel         0bbc0ce06368        44 seconds ago      -1.956e+09 B\n```\n\nNegative volume is awesome but might be slightly problematic :) Pushing the image to the hub, I see the actual size is 938MB, which sounds right.\n\n```\nDocker version 1.8.1, build d12ea79-dirty\n```\n\n```\narmhf arch\n```\n"},{"labels":["api",null],"text":"**Description of problem**:\nHas the spec for this endpoint been changed in docker 1.7? Using the latest version of https://github.com/fsouza/go-dockerclient against https://master.dockerproject.com/ results in `Unrecognized input header` being returned when calling `client.Stats()`. Works correctly in 1.6. I can dig deeper if this isn't already a known issue.\n\n``` console\n$ docker version\nClient version: 1.6.0\nClient API version: 1.18\nGo version (client): go1.4.2\nGit commit (client): 4749651\nOS/Arch (client): darwin/amd64\nServer version: 1.7.0-dev\nServer API version: 1.19\nGo version (server): go1.4.2\nGit commit (server): 4bcfa47\nOS/Arch (server): linux/amd64\n```\n\n``` console\n$ docker info\nContainers: 5\nImages: 12\nStorage Driver: aufs\n Root Dir: /mnt/sda/var/lib/docker/aufs\n Backing Filesystem: extfs\n Dirs: 22\n Dirperm1 Supported: true\nExecution Driver: native-0.2\nKernel Version: 3.16.1-tinycore64\nOperating System: Boot2Docker 1.2.0 (TCL 5.3); 3.16.1-config-file : e75396e - Fri Aug 22 06:45:30 UTC 2014\nCPUs: 1\nTotal Memory: 495.1 MiB\nName: boot2docker\nID: 4MLS:BGLV:7FJH:UIG7:EOH5:FEME:W6LK:535D:JGRT:JXQI:JZUH:ROXH\nDebug mode (server): true\nDebug mode (client): false\nFds: 81\nGoroutines: 89\nSystem Time: Sat May 23 05:10:21 UTC 2015\nEventsListeners: 13\nInit Path: /usr/local/bin/docker\nDocker Root Dir: /mnt/sda/var/lib/docker\nHttp Proxy:\nHttps Proxy:\nNo Proxy:\nUsername: ejholmes\nRegistry: [https://index.docker.io/v1/]\n```\n\n``` console\n$ uname -a\nLinux boot2docker 3.16.1-tinycore64 #1 SMP Fri Aug 22 06:40:10 UTC 2014 x86_64 GNU/Linux\n```\n\n**Environment details (AWS, VirtualBox, physical, etc.)**:\nAble to reproduce in boot2docker and also on AWS EC2 instances.\n\n**How reproducible**:\n100%\n\n**Steps to Reproduce**:\n1. Run docker 1.7 daemon\n2. Run a container: `docker run -d alpine:3.1 /bin/sh -c \"while true; do echo hello; sleep 1; done\"`\n3. Issue a request to stream the stats for the container with telnet:\n\n``` console\n$ telnet <docker host> <port>\nTrying ::1...\ntelnet: connect to address ::1: Connection refused\nTrying 127.0.0.1...\nConnected to localhost.\nEscape character is '^]'.\nGET /containers/4cda41c21e8d0e41e6da635b12f9e8e13b61f4dc62f7b65a05ff9d60d5393fdb/stats HTTP/1.1\n```\n\n**Actual Results**:\n\nOne stat message is streamed, then a 0 is sent and no more stats are sent after that:\n\n``` console\nHTTP/1.1 200 OK\nDate: Sat, 23 May 2015 05:06:25 GMT\nContent-Type: text/plain; charset=utf-8\nTransfer-Encoding: chunked\n\n560\n{\"read\":\"2015-05-23T05:06:24.831430951Z\",\"network\":{\"rx_bytes\":0,\"rx_packets\":0,\"rx_errors\":0,\"rx_dropped\":0,\"tx_bytes\":0,\"tx_packets\":0,\"tx_errors\":0,\"tx_dropped\":0},\"cpu_stats\":{\"cpu_usage\":{\"total_usage\":847371027,\"percpu_usage\":[847371027],\"usage_in_kernelmode\":50000000,\"usage_in_usermode\":170000000},\"system_cpu_usage\":1878570000000,\"throttling_data\":{\"periods\":0,\"throttled_periods\":0,\"throttled_time\":0}},\"memory_stats\":{\"usage\":163840,\"max_usage\":1179648,\"stats\":{\"active_anon\":65536,\"active_file\":0,\"cache\":4096,\"hierarchical_memory_limit\":18446744073709551615,\"hierarchical_memsw_limit\":18446744073709551615,\"inactive_anon\":0,\"inactive_file\":0,\"mapped_file\":0,\"pgfault\":58722,\"pgmajfault\":0,\"pgpgin\":19824,\"pgpgout\":19800,\"rss\":94208,\"rss_huge\":0,\"swap\":0,\"total_active_anon\":65536,\"total_active_file\":0,\"total_cache\":4096,\"total_inactive_anon\":0,\"total_inactive_file\":0,\"total_mapped_file\":0,\"total_pgfault\":58722,\"total_pgmajfault\":0,\"total_pgpgin\":19824,\"total_pgpgout\":19800,\"total_rss\":94208,\"total_rss_huge\":0,\"total_swap\":0,\"total_unevictable\":0,\"total_writeback\":0,\"unevictable\":0,\"writeback\":0},\"failcnt\":0,\"limit\":519147520},\"blkio_stats\":{\"io_service_bytes_recursive\":[],\"io_serviced_recursive\":[],\"io_queue_recursive\":[],\"io_service_time_recursive\":[],\"io_wait_time_recursive\":[],\"io_merged_recursive\":[],\"io_time_recursive\":[],\"sectors_recursive\":[]}}\n\n0\n```\n\n**Expected Results**:\n\nI expect a continuous stream of stats to be sent, like below, which was captured against docker 1.6.\n\n``` console\nHTTP/1.1 200 OK\nContent-Type: application/json\nDate: Sat, 23 May 2015 05:03:14 GMT\nTransfer-Encoding: chunked\n\n582\n{\"read\":\"2015-05-23T05:03:14.412287818Z\",\"network\":{\"rx_bytes\":648,\"rx_packets\":8,\"rx_errors\":0,\"rx_dropped\":0,\"tx_bytes\":648,\"tx_packets\":8,\"tx_errors\":0,\"tx_dropped\":0},\"cpu_stats\":{\"cpu_usage\":{\"total_usage\":327891630,\"percpu_usage\":[61105665,115203059,53758803,97824103],\"usage_in_kernelmode\":130000000,\"usage_in_usermode\":20000000},\"system_cpu_usage\":75857340000000,\"throttling_data\":{\"periods\":0,\"throttled_periods\":0,\"throttled_time\":0}},\"memory_stats\":{\"usage\":454656,\"max_usage\":655360,\"stats\":{\"active_anon\":61440,\"active_file\":4096,\"cache\":8192,\"hierarchical_memory_limit\":18446744073709551615,\"hierarchical_memsw_limit\":18446744073709551615,\"inactive_anon\":0,\"inactive_file\":0,\"mapped_file\":0,\"pgfault\":6277,\"pgmajfault\":0,\"pgpgin\":2199,\"pgpgout\":2161,\"rss\":147456,\"rss_huge\":0,\"swap\":0,\"total_active_anon\":61440,\"total_active_file\":4096,\"total_cache\":8192,\"total_inactive_anon\":0,\"total_inactive_file\":0,\"total_mapped_file\":0,\"total_pgfault\":6277,\"total_pgmajfault\":0,\"total_pgpgin\":2199,\"total_pgpgout\":2161,\"total_rss\":147456,\"total_rss_huge\":0,\"total_swap\":0,\"total_unevictable\":0,\"total_writeback\":0,\"unevictable\":0,\"writeback\":0},\"failcnt\":0,\"limit\":2105860096},\"blkio_stats\":{\"io_service_bytes_recursive\":[],\"io_serviced_recursive\":[],\"io_queue_recursive\":[],\"io_service_time_recursive\":[],\"io_wait_time_recursive\":[],\"io_merged_recursive\":[],\"io_time_recursive\":[],\"sectors_recursive\":[]}}\n\n582\n{\"read\":\"2015-05-23T05:03:15.412531749Z\",\"network\":{\"rx_bytes\":648,\"rx_packets\":8,\"rx_errors\":0,\"rx_dropped\":0,\"tx_bytes\":648,\"tx_packets\":8,\"tx_errors\":0,\"tx_dropped\":0},\"cpu_stats\":{\"cpu_usage\":{\"total_usage\":329912723,\"percpu_usage\":[61402741,116102576,53758803,98648603],\"usage_in_kernelmode\":130000000,\"usage_in_usermode\":20000000},\"system_cpu_usage\":75861300000000,\"throttling_data\":{\"periods\":0,\"throttled_periods\":0,\"throttled_time\":0}},\"memory_stats\":{\"usage\":401408,\"max_usage\":655360,\"stats\":{\"active_anon\":53248,\"active_file\":4096,\"cache\":8192,\"hierarchical_memory_limit\":18446744073709551615,\"hierarchical_memsw_limit\":18446744073709551615,\"inactive_anon\":0,\"inactive_file\":0,\"mapped_file\":0,\"pgfault\":6326,\"pgmajfault\":0,\"pgpgin\":2216,\"pgpgout\":2174,\"rss\":163840,\"rss_huge\":0,\"swap\":0,\"total_active_anon\":53248,\"total_active_file\":4096,\"total_cache\":8192,\"total_inactive_anon\":0,\"total_inactive_file\":0,\"total_mapped_file\":0,\"total_pgfault\":6326,\"total_pgmajfault\":0,\"total_pgpgin\":2216,\"total_pgpgout\":2174,\"total_rss\":163840,\"total_rss_huge\":0,\"total_swap\":0,\"total_unevictable\":0,\"total_writeback\":0,\"unevictable\":0,\"writeback\":0},\"failcnt\":0,\"limit\":2105860096},\"blkio_stats\":{\"io_service_bytes_recursive\":[],\"io_serviced_recursive\":[],\"io_queue_recursive\":[],\"io_service_time_recursive\":[],\"io_wait_time_recursive\":[],\"io_merged_recursive\":[],\"io_time_recursive\":[],\"sectors_recursive\":[]}}\n```\n\n**Additional info**:\n"},{"labels":["api",null,null],"text":"**Problem**\n\nThe docker api logs are lacking and can be verbose and not useful.\n\n**Solution**\n\nReview the logging calls in https://github.com/docker/docker/tree/master/api/server and use our standard log package `github.com/Sirupsen/logrus` to make meaningful log messages.\n\nIt could be helpful to remove all existing log calls and then go through and log meaning requests, warnings, errors, and debug messages for the API.\n"},{"labels":["api",null,null],"text":"According to the wikipedia example, DELETE on a resource with no parameters should delete all instances of that resource. Currently, it throws an error saying the null id could not be found:\n\n```\ncloudscaling@mngmt2:~> curl -X DELETE http://localhost:2375/images/\nNo such image:\ncloudscaling@mngmt2:~> curl -X DELETE http://localhost:2375/containers/\nNo such container:\n```\n\n[Wiki](http://en.wikipedia.org/wiki/Representational_state_transfer#Example)\n"},{"labels":["api",null,null],"text":"It is bizarre to me that there is a containers/resize endpoint, but that those parameters are not available to be set on container creation or start. In addition, _calling resize doesn't even work_ - you need to restart the container as well, making the whole flow for creating a TTY of a certain size nigh impossible in the usual Docker flow.\n"},{"labels":["api",null,null,null],"text":"I use the Docker API, and when I run this request, the tags doesn't return.\n\n```\nGET /images/{id}/json\n```\n\nThis information is given when I list all images.\n\nWhat's the best practices to get image's tags information ?\n"},{"labels":["api",null,null],"text":"Sometimes you have really important containers, like data only containers, that you don't want accidentally deleted.  `docker rm -f $(docker ps -qa)` is just too easy to type sometimes and then, \"oh !@#!\", it's all gone.  (Well not really because you can find your data in `/var/lib/docker/vfs`).  Anyhow, I propose we add the following:\n\n`docker run/create --lock=true ...`\n`docker lock CID`\n`docker unlock CID`\n\nIf one was to do `docker rm CID` and CID was locked it wouldn't delete and exit with an error code.  Start/stop/restart should still work.  This flag is the equivalent of EC2's `DisableApiTermination` flag.  In order to delete a locked container you must first run `docker unlock CID`.\n"},{"labels":["api"],"text":"I'm trying to mount volumes from other containers. The example format in the [ v1.15 docs](https://docs.docker.com/reference/api/docker_remote_api_v1.15/#start-a-container) doesn't seem to work:\n\n```\nPOST /containers/(id)/start\n{\n    \"VolumesFrom\": [\"data\"],\n    ...\n}\n```\n\nHowever, following the same pattern as `/containers/create` does work:\n\n```\nPOST /containers/(id)/start\n{\n    \"HostConfig\": {\n        \"VolumesFrom\": [\"data\"]\n    }\n    ...\n}\n```\n\nLet me know if I'm missing something obvious here, thanks.\nOther info:\n\n```\n$ uname -a\nDarwin CRP10795M 13.4.0 Darwin Kernel Version 13.4.0: Sun Aug 17 19:50:11 PDT 2014; root:xnu-2422.115.4~1/RELEASE_X86_64 x86_64\n```\n\n```\n$ docker version\nClient version: 1.3.1\nClient API version: 1.15\nGo version (client): go1.3.3\nGit commit (client): 4e9bbfa\nOS/Arch (client): darwin/amd64\nServer version: 1.3.1\nServer API version: 1.15\nGo version (server): go1.3.3\nGit commit (server): 4e9bbfa\n```\n\n```\n$ docker -D info\nContainers: 4\nImages: 116\nStorage Driver: aufs\n Root Dir: /mnt/sda1/var/lib/docker/aufs\n Dirs: 124\nExecution Driver: native-0.2\nKernel Version: 3.16.4-tinycore64\nOperating System: Boot2Docker 1.3.1 (TCL 5.4); master : 9a31a68 - Fri Oct 31 03:14:34 UTC 2014\nDebug mode (server): true\nDebug mode (client): true\nFds: 21\nGoroutines: 18\nEventsListeners: 0\nInit Path: /usr/local/bin/docker\n```\n"},{"labels":["api"],"text":"With docker 1.11, a POST to /containers/$id/start with {\"PublishAllPorts\": true} would start the container and bind exposed ports as expected.\n\nAfter upgrading to 1.12, the container no longer binds any ports.\n\nAPI docs show no changes in this area - did something change, or is this a regression?\n"},{"labels":["api",null,null],"text":"Here are some calls and their endpoints:\n- List images: `/images/json`\n- Get image: `/images/{{image}}/json`\n- Get image history `/images/{{image}}/history`\n\nFirst of all having `json` in the URL does not make sense. Either get that json/xml information from `Accept-Type` header or a query string like `?output=json` (or even worse, use `.json` extension at the end of the URI).\n\nBy having URLs like I listed above you just made `history` a same-level or same-type of  thing as `json`, which is not correct. (and \"get image history\" does not end with `.../json` either.)\n\nIf this would be my API I would go for:\n- List images: `/images`\n- Get image: `/images/{{image}}`\n- Get image history `/images/{{image}}/history`\n\nI just looked at these 3 calls in the entire API and found that problem, I will be updating this issue as I go.\n\nFixing this would be a breaking API change, just leaving this here for future reference.\n"},{"labels":["api"],"text":"I am using the [Dockerode](https://github.com/apocas/dockerode) npm module to interface with the Docker API on a local machine.\n\nIf I specify an integer PortBindings value when calling the API to start an existing container (i.e. POST /containers/(id)/start), it fails to take effect. For instance, if my passed config is:\n\n``` javascript\n{ \"Binds\":[\"/var/lib/mongo/data:/data/db\"],\"PortBindings\":{\"27017/tcp\":[{\"HostPort\":27017}]} }\n```\n\nthen it fails, but if it is:\n\n``` javascript\n{ \"Binds\":[\"/var/lib/mongo/data:/data/db\"],\"PortBindings\":{\"27017/tcp\":[{\"HostPort\":\"27017\"}]} }\n```\n\nthen it works (notice the 27017 is a string in the second version). This was confusing because I expected that the port number, being a native integer, would be valid and correct. \n\nI had to cast my Integer to a String in order to have it take effect (but not before spending a large amount of time narrowing down the issue).\n"},{"labels":["api"],"text":"When calling the `build` endpoint (in 1.12), the returned string is a sequence of json objects rather than a json array.  This causes problems when using some generic http libraries, which detect the content type (sent as \"application/json\") and parse the response body automatically, causing them to return only the first json object or to report an error.\n\nExample response:\n\n``` json\n{\"stream\":\"Step 1...\"}\n{\"stream\":\"...\"}\n{\"error\":\"Error...\", \"errorDetail\":{\"code\": 123, \"message\": \"Error...\"}}\n```\n\nValid json would be:\n\n``` json\n[{\"stream\":\"Step 1...\"},\n {\"stream\":\"...\"},\n {\"error\":\"Error...\", \"errorDetail\":{\"code\": 123, \"message\": \"Error...\"}}]\n```\n"},{"labels":["api",null],"text":"Using gradle-docker I have the option of using either the REST API to build an image or the `docker` command line tool.  When I choose the REST API option I am able to create images tagged with capital letters.  However, when I attempt the same operation using the client I see:\n\n```\nCommand line [docker build -t tc.you.pds/dropwizardBase /home/ubuntu/github.com/pds-deployment/common/build/docker/dropwizardBase] returned:\n  2014/07/10 23:58:25 Invalid repository name (dropwizardBase), only [a-z0-9-_.] are allowed\n```\n\nWhile I'm not sure I completely understand why capital letters are forbidden, at the very least it seems that the behavior should be consistent.\n"},{"labels":["api"],"text":"Hi,\n\nthe Docker cli supports image names like `<registry>:<port>/<image>:<tag>`. This established a common pattern to specify images like that.\nSince Docker only parse the registry when providing ImageSrc parameter but requires the tag as additional parameter, pretty much all docker clients need to implement the parsing. I was about to add this to kubernetes.\nThis is not only bad because the duplicated work but even pushes out the interpretation of that string to clients which might cause lots of confusing in case this will ever change.\n"},{"labels":["api"],"text":"While trying to automatically digest the api with ActiveRecord I ran into an issue with the number first hash keys. rails/activeresource#138\n\n```\n\"Ports\":{\n  \"4500/tcp\":[\n    {\n      \"HostIp\":\"0.0.0.0\",\n      \"HostPort\":\"4500\"\n    }\n  ]\n}\n```\n\nIt seems to me that ActiveRecord is/will not be the only thing thats going to have this issue. While this will not effect everything, I do think its of some importance to have an API layer that is easily digestible and programmatically object mappable. \n\nSomething kinda like this?\n\n```\n\"Ports\":{\n  \"tcp\":[\n    {\n      \"SourcePort\":\"4500\",\n      \"HostIp\":\"0.0.0.0\",\n      \"HostPort\":\"4500\"\n    }\n  ]\n}\n```\n"},{"labels":["api"],"text":"I use the API/1.5 to handle docker issues.And i need to start many different dockers with port direction(localhost:hostPort==>dockerInnerIP:GuestPort),every second time the operation will must be fail, the Error description in my application reports that the connection to localhost:hostPort is reset by peer,it seems that the port direction doesn't works well?\n"}
]
