[{"classified_as": "api", "text": "Issue description:\r\n\r\nThere is a small bug in ContractAbi -> validateMethods\r\n\r\n\r\nassert(unknownKeys.length === 0, Unknown keys ${unknownKeys.join(', ')} found in ABI args for messages.${name});\r\n\r\n\r\nUnder node or RN env,  this will throw error name is undefined\r\n\r\nSolution:\r\n\r\nChange messages.${name} to ${method.name}\r\n"}, {"classified_as": "bug", "text": "**OS:**\r\nDistributor ID: Ubuntu\r\nDescription:    Ubuntu 18.04.1 LTS\r\nRelease:        18.04\r\nCodename:       bionic\r\n\r\n**Environment config:**\r\n\r\nnodejs -v\r\nv10.9.0\r\n\r\nnpm -v\r\n6.2.0\r\n\r\nmongod --version\r\ndb version v4.0.1\r\ngit version: 54f1582fc6eb01de4d4c42f26fc133e623f065fb\r\nOpenSSL version: OpenSSL 1.1.0g  2 Nov 2017\r\nallocator: tcmalloc\r\nmodules: none\r\nbuild environment:\r\n    distmod: ubuntu1804\r\n    distarch: x86_64\r\n    target_arch: x86_64\r\n\r\n**Strapi using deprecated sprintf package:**\r\n\r\nnpm install strapi@alpha -g\r\nnpm WARN deprecated sprintf@0.1.5: The sprintf package is deprecated in favor of sprintf-js.\r\n\r\n**Comment:**\r\nCan you replace _sprintf_ package with _sprintf-js_ package? Thank you."}, {"classified_as": "bug", "text": "Not a big deal, but it was slightly odd to see the Strapi UI capitalize Every Single Word in titles, even when in English, those words should not be capitalized. For example, \"Create An Entry\" should be \"Create an entry\" (or at most \"Create an Entry\", but I don't see the point of capitalizing all nouns), because \"an\" is a preposition and those don't get capitalized when title casing.\r\n\r\n![image](https://user-images.githubusercontent.com/33569/67192567-6c1f4a00-f3b9-11e9-879f-de1f190b8ac2.png)\r\n\r\nSee https://titlecase.com/:\r\n\r\n![image](https://user-images.githubusercontent.com/33569/67192592-79d4cf80-f3b9-11e9-8bb4-24467e6265a2.png)\r\n\r\nI would suggest capitalizing only the first letter, but if the AP Style is desired, the [titlecase](https://www.npmjs.com/package/titlecase) package does the job."}, {"classified_as": "api", "text": "### Introduction\r\nI create this issue to avoid other issues related to the same topic.\r\n\r\n## Description\r\nCurrently, if you are adding a min / max limit or default value,  will not be applied in the REST routes.\r\nOnly required and unique constraints work.\r\n\r\nmin / max will only be applied in the admin panel.\r\n\r\n## Contribution\r\n\r\nIf you want to work on this topic, I suggest you open an RFC on the following repo [strapi/rfcs](https://github.com/strapi/rfcs)"}, {"classified_as": "api", "text": "I just want to mention something I found strange when working with the @polkadot/api and registering custom types. For some reason await ApiPromise.create({ types}) doesn\u2019t work for me instead I need to use getTypeRegistry().register(types);\r\n\r\nawait ApiPromise.create({ types}) creates the following errors in the chrome console:\r\n2019-03-13 16:39:17        RPC-CORE: getMetadata (block: Hash): Customtype:: Number can only safely store up to 53 bits\r\n2019-03-13 16:39:17   API/DECORATOR: loadMeta a: getMetadata (block: Hash): Customtype:: Number can only safely store up to 53 bits"}, {"classified_as": "api", "text": "If the function of your Substrate extrinsic contains usize arguments, the API seems to throw InvalidSignature(0) errors. Changing these to u32 fixes the issue.\r\n\r\nNonetheless, these errors are caught at the API level before the extrinsics with usize function arguments ever touch the chain. Therefore, my intuition is the API cannot parse or serialize usize arguments."}, {"classified_as": "api", "text": "From Riot -\r\n\r\nI'm using the polkadot-js/api to build an API. When I consume a Struct type that has an Option.with(BlockNumber) field, and then try to call .toString() on it, I get the error: \"Number can only safely store up to 53 bits\". Any idea why this might be/how to fix?"}, {"classified_as": "api", "text": "Refer to this thread https://groups.google.com/forum/#!topic/swagger-swaggersocket/akJxBdyqJNg\n\nCurrently it is not possible to use the same field name in both path and formdata.\n\nIf you have different fields with the same name in path and formdata, then one will disappear.\n\nIt should be possible to do so.\n"}, {"classified_as": "bug", "text": "CircleCI allows much more power and storage space compared to travis.\n\nWe should use it to build docs and run example.\n\nWe just did it in nilearn (massive doc downloads and build times):\nhttps://github.com/nilearn/nilearn/pull/679\n"}, {"classified_as": "bug", "text": "<!--\r\nHello \ud83d\udc4b Thank you for submitting an issue.\r\n\r\nBefore you start, please make sure your issue is understandable and reproducible.\r\nTo make your issue readable make sure you use valid Markdown syntax.\r\n\r\nhttps://guides.github.com/features/mastering-markdown/\r\n-->\r\n\r\n**Describe the bug**\r\nStrapi is not using the configured host when spinning up the server\r\n\r\n**Steps to reproduce the behavior**\r\nEven the host that you want to launch your server is configurable but actually Strapi in not using it.\r\nIn [Strapi.js](https://github.com/strapi/strapi/blob/master/packages/strapi/lib/Strapi.js#L236), Strapi launches the sever by doing this.server.listen(this.config.port, async err instead of this.server.listen(this.config.port, this.config.host, async err, which means Node will listen to 0.0.0.0 by [default](https://nodejs.org/api/net.html#net_server_listen_port_host_backlog_callback).\r\nThere was an issue #3525 opened but closed without a fix.\r\n\r\n**Expected behavior**\r\nStrapi should use the host value in config when launching the server.\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n"}, {"classified_as": "bug", "text": "**What is the current behavior?**\r\nI am using GraphQL plugin and the query 'me' doesn't have for example a related content by the user, just the basics, id, username, email e.t.c..\r\n\r\nfor example I have to do this way, \r\n\r\n\r\nquery {\r\n  user(id: \"5c38667108f3c10d9fe2981f\") {\r\n    articles {\r\n      posts\r\n    }\r\n  }\r\n}\r\n\r\nwhich means I have to allow a user to access /user:_id which also exposes that the user can get other users content! \r\n\r\n**Steps to reproduce the problem**\r\nCreate a content add a field and relation to a user and do a query \"me\" with the related content\r\n\r\n**Suggested solutions**\r\nIt will be nice to have a way we can do this\r\n\r\n\r\nquery {\r\n  me {\r\n    articles {\r\n      posts\r\n    }\r\n  }\r\n}\r\n\r\n\r\nwhich means a user has access to only his/her content.\r\n\r\n"}, {"classified_as": "bug", "text": "<!--\r\nHello \ud83d\udc4b Thank you for submitting an issue.\r\n\r\nBefore you start, please make sure your issue is understandable and reproducible.\r\nTo make your issue readable make sure you use valid Markdown syntax.\r\n\r\nhttps://guides.github.com/features/mastering-markdown/\r\n-->\r\n\r\n**Describe the bug**\r\n\r\nThe browser autofill the username and password when create a new user:\r\n\r\n<img width=\"925\" alt=\"Screenshot 2020-01-22 at 11 59 45\" src=\"https://user-images.githubusercontent.com/1007051/72888972-f788de00-3d0e-11ea-9218-37729e6f0c2a.png\">\r\n\r\n\r\n**Steps to reproduce the behavior**\r\n1. Go to Users content type\r\n2. Click on Add new User\r\n3. The browser autofill the username and password  \r\n\r\n**Expected behavior**\r\n\r\nThe browser not autofill the username and password.\r\n\r\n**System**\r\n- Node.js version: v12\r\n- NPM version: v6\r\n- Strapi version: v3.0.0-beta.18.5\r\n- Database: MongoDB\r\n- Operating system: macOS\r\n"}, {"classified_as": "api", "text": "i think it would be nice if the option to stop or resume emulation shortcuts were awailable again, for me it was convenient and i dont know why it got rid of it (it was ctrl + s/ctrl + e for stop and continue)\n"}, {"classified_as": "bug", "text": "When Dennis Ritchie came up with the shebang in 1979, he did not consider Node.js v12.0.0\r\n\r\nSo on the shebang line **#!/usr/bin/env node** you cannot provide arguments\r\n\r\nIf you do a different shebang line, it is no longer portable to macOS or Android\r\n\r\nTherefore, adding type:module to package.json should enable every reasonable experimental module feature, in particular **experimental-json-modules** if it doesn't break us, it will make us stronger\r\n\r\nPeople who do not want this behavior should use an intermediate script or custom command-line like json importers have to do now\r\n\r\nnode -v && uname -a\r\nv13.11.0\r\nDarwin c87m1.local 19.3.0 Darwin Kernel Version 19.3.0: Thu Jan  9 20:58:23 PST 2020; root:xnu-6153.81.5~1/RELEASE_X86_64 x86_64"}, {"classified_as": "api", "text": "Current master, effectively block don't show up in the apps UI atm"}, {"classified_as": "bug", "text": "<!--\r\nIf you want to propose a new algorithm, please refer first to the scikit-learn\r\ninclusion criterion:\r\nhttps://scikit-learn.org/stable/faq.html#what-are-the-inclusion-criteria-for-new-algorithms\r\n-->\r\n\r\n#### Describe the workflow you want to enable\r\nNow, sklearn LDA only supports normalized transform output, which is the transform  method. But I still need to use the non-normalized output, so could you please open this feature?\r\n\r\n#### Describe your proposed solution\r\nopen this _unnormalized_transform as an official method.\r\n\r\nThanks\r\n"}, {"classified_as": "bug", "text": "1. Would it be worthwhile to add parameters to control missingness in dataset generators?\n   \n   I need this for benchmarking #5974. Thought this might come in handy for teaching too.\n   \n   Typically I would like to add missing_rate, target_correlation_rate, feature_correlation_rate and missing_values.\n   \n   The target_correlation_rate would control the extent to which the dataset is MNAR<sup>*</sup> and feature_correlation_rate would control the extent to which the dataset is MAR<sup>\u2020</sup>.\n   \n   target_correlation_rate + feature_correlation_rate <= 1\n   \n   1 - (target_correlation_rate + feature_correlation_rate) would control the extent to which the dataset is MCAR<sup>\u2021</sup>.\n   \n   Does this sound good?\n2. Either as an addition or as an alternative to **1**, could we have missing transformers with the above described params?\n\n<hr/>\n\n\\* - Missing Not At Random (Missingness is correlated with the target)\n\n\u2020 - Missing At Random but correlated with the other feature values.\n\n\u2021 - Missing Completely At Random (No correlation with either the target or parameters)\n\nPing @agramfort @glouppe @GaelVaroquaux\n"}, {"classified_as": "bug", "text": "- [x] **I have created my request on the Product Board before I submitted this issue**\r\n- [x] **I have looked at all the other requests on the Product Board before I submitted this issue**\r\n\r\n**Please describe your feature request:**\r\nThe title pretty much covers it. The specific example of how I ran into this was I had a request interceptor in my front-end app that was errantly adding a \"Content-Type: application/x-www-form-urlencoded\" header to a login request, which should be \"application/json\". When this happens, Strapi responds with a generic 400 Bad Request rather than the appropriate 415."}, {"classified_as": "api", "text": "... logging in here since, well, need to think about this.\r\n\r\nBasically, this doesn't work - \r\n\r\n- https://github.com/polkadot-js/api/blob/master/packages/api/src/Base.ts#L577\r\n- https://github.com/polkadot-js/api/pull/1284/files#diff-95597f67ed68d7dffc27ba1f0501e5b1R585\r\n\r\nThe issue is the the types are injected, registered and anything dependent has a created type with the initial locked-in class."}, {"classified_as": "api", "text": "Vulkan compute descriptor allocation is suboptimal, making large RSX captures impossible to replay. Either the compute-based texture decoder should be possible to disable or the allocation should be dynamic to avoid this situation."}, {"classified_as": "api", "text": "\r\nHello,\r\n\r\nIs there a REST endpoint for resending verification of emails?  I don't see anything in the documentation.\r\n\r\nThanks."}, {"classified_as": "api", "text": "Currently \"int\" data type defaults to \"0\" in Model Schema sample value while both \"long\" and \"float\" default to \"0.1\".\n\nSince both \"int\" and \"long\" data types are whole numbers, they should both default to \"0\".\nOnly \"float\" and \"double\" (floating point numbers) should default to \"0.1\".\n"}, {"classified_as": "bug", "text": "Implement job queue adapters."}, {"classified_as": "bug", "text": "<!--\r\nHello \ud83d\udc4b Thank you for submitting a feature request.\r\n\r\nWe are using ProductBoard to manage our roadmap and feature requests.\r\n\r\nCan you please submit your feature request here: https://portal.productboard.com/strapi\r\n-->\r\n\r\n- [x] **I have created my request on the Product Board before I submitted this issue**\r\n- [ ] **I have looked at all the other requests on the Product Board before I submitted this issue**\r\n\r\n**Please describe your feature request:**\r\n\r\nWhen saving content types, users can still click multiple times anywhere on the application before they are redirected on the listing page.\r\n\r\nThis is problematic when you have for example build hooks to trigger upon save.\r\n\r\nAs discussed with @soupette I am posting the feature request for this behaviour.\r\nhere is a link for the slack thread to have some context\r\nhttps://strapi.slack.com/archives/C0BNGCDNH/p1588232998490000"}, {"classified_as": "api", "text": "This may seem a dumb issue but when trying to fetch metadata from Edgeware via yarn run chain:info --ws  wss://mainnet1.edgewa.re, the connection is always rejected with error message: API-WS: disconnected from wss://mainnet1.edgewa.re code: '1006' reason: 'connection failed'. This is not the case with any of the other hosted nodes (Kusama, Flaming Fir, etc.) nor with a local node.\r\n\r\nWeird part is that I'm able to connect to Edgeware on apps and get the metadata through the apps toolbox no problem. "}, {"classified_as": "bug", "text": "<!-- Thanks for contributing to Calypso! Pick a clear title (\"Editor: add spell check\") and proceed. -->\r\n\r\n#### Steps to reproduce\r\n1. Starting at URL https://wordpress.com/theme/modern-business or other child theme (right now there are only 2019 child themes).\r\n2. Scroll to the bottom of the theme page.\r\n3. Download the theme.\r\n4. Install theme on a .org site.\r\n5. Try to activate theme.\r\n\r\n#### What I expected\r\nTo be able to activate the Modern Business, or other WP.com Twenty Nineteen business themes.\r\n\r\n#### What happened instead\r\nYou have to specifically install the WP.com version of Twenty Nineteen, which is confusing.\r\n\r\nWe do have a warning message, but users often ignore the guides.\r\n\r\n#### Browser / OS version\r\nChrome OS Version 75.0.3770.102 (Official Build) beta (64-bit)\r\n\r\n#### Screenshot / Video\r\nOriginal theme page (text explaining 2019 is needed is hard to distinguish from normal tutorial text).\r\n\r\n![screen-shot-on-2019-06-18-at-14_20_41 (1)](https://user-images.githubusercontent.com/10121835/60039421-4b99ea00-967c-11e9-8a2a-152294dc0f0c.png)\r\n\r\nA workaround button was added to make it stand out more:\r\n![screen-shot-2019-06-18-at-1 29 38-pm](https://user-images.githubusercontent.com/10121835/60039493-74ba7a80-967c-11e9-991a-51819097e29d.png)\r\n\r\n#### Context / Source\r\n<!-- Optional: share your unique context to help us understand your perspective. You can add context tags such as: #journey #anecdote #narrative #context #empathy #perspective #reallife #dogfooding #livesharing #flowsharing #anxiety #anxiety-flow #stresscase #painpoint.\r\n\r\nWe'd also love to know how you found the bug: #dogfooding, #manual-testing, #automated-testing, or #user-report if applicable.\r\n\r\nIf requesting a new feature, explain why you'd like to see it added.\r\n-->\r\nIt would be more clear if when we have a child theme in our gallery, there was a download button for the parent theme as well clearly displayed next to the child theme's download button.\r\n\r\nThat, or the versions we make available for download should be designed to work with the .org 2019. That way when you get the child theme error you can just DL Twenty Nineteen from the repository.\r\n\r\n<!--\r\nPLEASE NOTE\r\n- These comments won't show up when you submit the issue.\r\n- Everything is optional, but try to add as many details as possible.\r\n\r\nDocs & troubleshooting:\r\nhttps://github.com/Automattic/wp-calypso/blob/master/.github/CONTRIBUTING.md\r\nhttps://github.com/Automattic/wp-calypso/blob/master/docs/troubleshooting.md\r\n\r\nHelpful tips for screenshots:\r\nhttps://en.support.wordpress.com/make-a-screenshot/\r\n-->\r\n"}, {"classified_as": "bug", "text": "I'm having trouble replicating, e.g., Chrome on a Pixel. I tried\r\n\r\njs\r\nawait page.setViewport({\r\n  width: 1080,\r\n  height: 1920,\r\n  isMobile: true,\r\n  hasTouch: true,\r\n  deviceScaleFactor: 2\r\n});\r\n\r\n\r\nbut this doesn't replicate what I actually see on a Pixel. (User agent also needs to be set.)"}, {"classified_as": "api", "text": "Not able to decode DigestItem that returned from RPC\r\n\r\nRelated: https://github.com/paritytech/substrate/pull/1478\r\n\r\nI think the JSON codec needs some better thoughts to avoid those breaking changes"}, {"classified_as": "bug", "text": "There should be a capability to ignore certificate errors during navigation. See https://github.com/GoogleChrome/puppeteer/issues/66 for proposal and https://github.com/cyrus-and/chrome-remote-interface/issues/183 for original discussion.\r\n\r\nFor example, we can add ignoreSSL navigation option:\r\n\r\njs\r\npage.navigate('https://example.com', { ignoreSSL: true })\r\n"}, {"classified_as": "bug", "text": "**Information**\r\n- **Node.js version**: 9.11.2\r\n- **npm version**: 5.6.0\r\n- **Strapi version**: 3.0.0-alpha.13.1\r\n- **Database**: Mongo\r\n- **Operating system**: MacOS High Sierra\r\n\r\n**What is the current behavior?**\r\nUpgraded from 12.7 to 13.1, and got a missing packages/strapi-admin/admin/src/config/manifest.json file error when running npm run setup:build.\r\n\r\nI checked my repo and it's not there, checked strapi's repo and it IS there https://github.com/strapi/strapi/tree/master/packages/strapi-admin/admin/src/config/manifest.json. So I added it, and npm run setup:build worked, but when I went to commit it, it says it's ignored by .gitignore here https://github.com/strapi/strapi/blob/master/packages/strapi-admin/admin/.gitignore#L4 \r\n\r\n**Steps to reproduce the problem**\r\ndelete packages/strapi-admin/admin/src/config/manifest.json, run npm run setup:build\r\n\r\n\r\n**What is the expected behavior?**\r\nnpm run setup:build should generate the manifest file if it does not exist\r\n\r\n\r\n**Suggested solutions**\r\nDetermine if it does need to be committed, if so remove it from .gitignore, or determine why it's not auto generating if it doesn't need to be committed. \r\n"}, {"classified_as": "api", "text": "Serialization fails. Would normally just fix (instead of log), but need to decode the Opaque system again to see what is up here."}, {"classified_as": "bug", "text": "# Problem\r\nI see there is an API for starting and stoping a timeline recording await page.tracing.start({path: 'trace.json'}); but I would like to request the ability to take a memory heap snapshot and the ability  to write expectations on the snapshot data.\r\n\r\nMy use case is roughly:\r\n - load a page\r\n - load a component & do stuff\r\n - remove the component\r\n - force a garbage collection (would love a method for this as well!)\r\n - take a heap snapshot\r\n - Verify that the component is not retained in memory somehow\r\n\r\nThis would be amazing to be able to have automated headless memory leak regression testing!\r\n\r\nMaybe something like:\r\n\r\nvar heapsnap = await page.heap.snapshot('heap1.snapshot');\r\nexpect(!heapsnap.contains('SomeClassName'))\r\n\r\n\r\nBonus points for an API for the memory allocation timeline that you could query for the number of objects of a type added / removed during the timeline.\r\n"}, {"classified_as": "api", "text": "Since the new upgrade check (#6385) we're getting a significant flood of upgrade requests. The problem is that some clients are stuck in restart loops, for various reasons, and hammer the upgrade server. We can of course offload this in various ways (CDNs and whatnot) but it still seems like an oversight that we should handle better...\r\n\r\nServer side rate limiting at the HTTPS level isn't enormously useful as the main cost is in the TLS handshake to begin with."}, {"classified_as": "bug", "text": "This is a list of missing translation keys. Feel free to submit a PR to help us.\r\n\r\n\r\n\r\n\ud83d\udce6 strapi-admin - [/packages/strapi-admin/admin/src/translations/pl.json](https://github.com/strapi/strapi/blob/master/packages/strapi-admin/admin/src/translations/pl.json)\r\n\r\n\r\n| Translation key | English default value |\r\n|-----------------|:---------------------:|\r\n|app.utils.delete | Delete|"}, {"classified_as": "bug", "text": ":+1: :pizza: :cake: :beer: :beers: :wine_glass: :curry: :sake: :fireworks: :rice_cracker: :100: \n"}, {"classified_as": "bug", "text": "<!--\nIf your issue is a usage question, submit it here instead:\n- StackOverflow with the scikit-learn tag: http://stackoverflow.com/questions/tagged/scikit-learn\n- Mailing List: https://mail.python.org/mailman/listinfo/scikit-learn\nFor more information, see User Questions: http://scikit-learn.org/stable/support.html#user-questions\n-->\n\n<!-- Instructions For Filing a Bug: https://github.com/scikit-learn/scikit-learn/blob/master/CONTRIBUTING.md#filing-bugs -->\n#### Description\n\n<!-- Example: Joblib Error thrown when calling fit on LatentDirichletAllocation with evaluate_every > 0-->\n\nSometimes it is convenient to first build a model on a recent dataset, save it as a .pkl file and then apply the model to the new dataset. However, in the last project, my friends and I found that the results turned quite wired after applying the .pkl file on the new dataset. Actually, we implemented a binary classifier. We found the probability distribution turned from unimodal distribution to bimodal distribution. Finally, we found out the problem was that the column order of the new dataset was different from the old one. Thus the predictions were totally wrong. \nI have checked the source code and discovered that the fit function of sklean didn't save the column values during the process of model training. Thus there was no mean to check whether the column values were consistent during the processing of prediction. We thought it would be better if the column values could be saved during training and then be used to check the column values during predicting.\n#### Steps/Code to Reproduce\n\n<!--\nExample:\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.decomposition import LatentDirichletAllocation\n\ndocs = [\"Help I have a bug\" for i in range(1000)]\n\nvectorizer = CountVectorizer(input=docs, analyzer='word')\nlda_features = vectorizer.fit_transform(docs)\n\nlda_model = LatentDirichletAllocation(\n    n_topics=10,\n    learning_method='online',\n    evaluate_every=10,\n    n_jobs=4,\n)\nmodel = lda_model.fit(lda_features)\n\nIf the code is too long, feel free to put it in a public gist and link\nit in the issue: https://gist.github.com\n-->\n\n python\n#for simplification, consider a very simple case\nfrom sklearn.datasets import load_iris\nimport pandas as pd\n\n#make a dataframe\niris = load_iris()\nX, y = iris.data[:-1,:], iris.target[:-1]\niris_pd = pd.DataFrame(X)\niris_pd.columns = iris.feature_names\niris_pd['target'] = y\n\nfrom sklearn.cross_validation import train_test_split\ntrain, test = train_test_split(iris_pd, test_size= 0.3)\n\nfeature_columns_train = ['sepal length (cm)','sepal width (cm)','petal length (cm)','petal width (cm)']\nfeature_columns_test = ['sepal length (cm)','sepal width (cm)','petal width (cm)','petal length (cm)']\n\nfrom sklearn.linear_model import LogisticRegression\nlg = LogisticRegression(n_jobs=4, random_state=123, verbose=0, penalty='l1', C=1.0)\nlg.fit(train[feature_columns_train], train['target'])\n\nprob1 = lg.predict_proba(test[feature_columns_train])\nprob2 = lg.predict_proba(test[feature_columns_test])\n\n#### Expected Results\n\n<!-- Example: No error is thrown. Please paste or describe the expected results.-->\n\nBecause feature_columns_test is different from feature_columns_train, it is not surprised that prob1 is totally different from prob2 and prob1 should be the right result.\n\n python\nprob1[:5] = \narray([[  3.89507414e-04,   3.20099743e-01,   6.79510750e-01],\n         [  4.63256526e-04,   4.65385156e-01,   5.34151587e-01],\n         [  8.79704318e-01,   1.20295572e-01,   1.10268420e-07],\n         [  7.80611983e-01,   2.19385827e-01,   2.19046022e-06],\n         [  2.78898454e-02,   7.77243988e-01,   1.94866167e-01]])\n\n#### Actual Results\n\n<!-- Please paste or specifically describe the actual output or traceback. -->\n\n python\nprob2[:5] = \narray([[  4.36321678e-01,   2.25057553e-04,   5.63453265e-01],\n         [  4.92513658e-01,   1.76391882e-05,   5.07468703e-01],\n         [  9.92946715e-01,   7.05167151e-03,   1.61346947e-06],\n         [  9.83726756e-01,   1.62387090e-02,   3.45348884e-05],\n         [  5.01392274e-01,   5.37144591e-04,   4.98070581e-01]])\n\n#### Versions\n\n<!--\nPlease run the following snippet and paste the output below.\nimport platform; print(platform.platform())\nimport sys; print(\"Python\", sys.version)\nimport numpy; print(\"NumPy\", numpy.__version__)\nimport scipy; print(\"SciPy\", scipy.__version__)\nimport sklearn; print(\"Scikit-Learn\", sklearn.__version__)\n-->\n\n python\nLinux-2.6.32-642.1.1.el6.x86_64-x86_64-with-redhat-6.7-Santiago\n('Python', '2.7.11 |Anaconda 2.4.1 (64-bit)| (default, Dec  6 2015, 18:08:32) \\n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]')\n('NumPy', '1.10.1')\n('SciPy', '0.16.0')\n('Scikit-Learn', '0.17')\n\n\n<!-- Thanks for contributing! -->\n## The probable solution\n\nI also implement a very simple solution. Hope this would help. :)\n\n python\nclass SafeLogisticRegression(LogisticRegression):\n    def fit(self, X, y, sample_weight=None):\n        self.columns = X.columns\n        LogisticRegression.fit(self, X, y, sample_weight=None)\n    def predict_proba(self, X):\n        new_columns = list(X.columns)\n        old_columns = list(self.columns)\n        if new_columns != old_columns:\n            if len(new_columns) == len(old_columns):\n                try:\n                    X = X[old_columns]\n                    print \"The order of columns has changed. Fixed.\"\n                except:\n                    raise ValueError('The columns has changed. Please check.')\n            else:\n                raise ValueError('The number of columns has changed.')\n        return LogisticRegression.predict_proba(self, X)\n\n\nThen apply this new class:\n\n python\nslg = SafeLogisticRegression(n_jobs=4, random_state=123, verbose=0, penalty='l1', C=1.0)\nslg.fit(train[feature_columns_train], train['target']) \n\n#### Test one: if the column order is changed\n\n python\nprob1 = slg.predict_proba(test[feature_columns_train])\nprob2 = slg.predict_proba(test[feature_columns_test])\n\n#The order of columns has changed. Fixed.\n\n\nResult for test one:\n\n python\nprob1[:5] =\narray([[  3.89507414e-04,   3.20099743e-01,   6.79510750e-01],\n       [  4.63256526e-04,   4.65385156e-01,   5.34151587e-01],\n       [  8.79704318e-01,   1.20295572e-01,   1.10268420e-07],\n       [  7.80611983e-01,   2.19385827e-01,   2.19046022e-06],\n       [  2.78898454e-02,   7.77243988e-01,   1.94866167e-01]])\n\nprob2[:5] =\narray([[  3.89507414e-04,   3.20099743e-01,   6.79510750e-01],\n       [  4.63256526e-04,   4.65385156e-01,   5.34151587e-01],\n       [  8.79704318e-01,   1.20295572e-01,   1.10268420e-07],\n       [  7.80611983e-01,   2.19385827e-01,   2.19046022e-06],\n       [  2.78898454e-02,   7.77243988e-01,   1.94866167e-01]])\n\n#### Test two: if the columns are different (different columns)\n\nSimulate by changing one of the column names\n\n python\nprob3 = slg.predict_proba(test[feature_columns_train].rename(columns={'sepal width (cm)': 'sepal wid (cm)'}))\n\n\nerror message:\n\n python\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n<ipython-input-47-84cea68536fe> in <module>()\n----> 1 prob3 = slg.predict_proba(test[feature_columns_train].rename(columns={'sepal width (cm)': 'sepal wid (cm)'}))\n\n<ipython-input-21-c3000b030a21> in predict_proba(self, X)\n     12                     print \"The order of columns has changed. Fixed.\"\n     13                 except:\n---> 14                     raise ValueError('The columns has changed. Please check.')\n     15             else:\n     16                 raise ValueError('The number of columns has changed.')\n\nValueError: The columns has changed. Please check.\n\n#### Test three: if the number of columns changes\n\nSimulate by dropping one column\n\n python\nprob4 = slg.predict_proba(test[feature_columns_train].drop(['sepal width (cm)'], axis=1))\n\n\nerror message:\n\n python\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n<ipython-input-48-47c63ae1ac22> in <module>()\n----> 1 prob4 = slg.predict_proba(test[feature_columns_train].drop(['sepal width (cm)'], axis=1))\n\n<ipython-input-21-c3000b030a21> in predict_proba(self, X)\n     14                     raise ValueError('The columns has changed. Please check.')\n     15             else:\n---> 16                 raise ValueError('The number of columns has changed.')\n     17         return LogisticRegression.predict_proba(self, X)\n\nValueError: The number of columns has changed.\n\n"}, {"classified_as": "api", "text": "Almost all textures are black now.\n"}, {"classified_as": "api", "text": "Looks like the UI is not showing the accurate reward amount for validators with a commission greater than 0.\r\n\r\nFor instance, the message for this tx https://polkascan.io/pre/kusama/transaction/0x342d516e1f99a7ce92bc5f98aa95ef4566b4f40b70d11367deb75cc9d5d2d8de was Payout rewards (0.000 KSM), the validator has set a 100% commission."}, {"classified_as": "api", "text": "When trying to call api.tx.system.setCode() with a large code example (eb 262146 or 131072 bytes),  the transaction starts is return Finalized, but the extrinsic fails:\r\n {\"ApplyExtrinsic\":2} : system.ExtrinsicFailed []\r\n\r\nThis happens both wrapped in an democracy proposal or called directly via sudo.\r\n<img width=\"1391\" alt=\"Screenshot 2019-07-24 at 11 10 05\" src=\"https://user-images.githubusercontent.com/125398/61781915-773bfb80-ae05-11e9-96f5-a31089d13857.png\">\r\n\r\nThe behaviour can be reproduced by uploading this file (262146 bytes) https://github.com/polkadot-js/api/blob/b1b4530bf13ab6ef2480e42ac0b71bde14a0e707/packages/api/test/mock-data/randomAsHexRaw in the PolkadotJS UI https://polkadot.js.org/apps/#/democracy/propose\r\n\r\nor by running this test https://github.com/polkadot-js/api/blob/b1b4530bf13ab6ef2480e42ac0b71bde14a0e707/packages/api/test/e2e/api/promise-tx.spec.ts#L112\r\n\r\nBoth the UI and the e2e tests are working fine with smaller code examples."}, {"classified_as": "api", "text": "In my mind, the bug is that STGUIASSETS should no longer point to the same hierachy that we compile in, and that the behavior is different when overriding vs when not. It used to be very simple (assuming $PATH has been requested):\n1. $STGUIASSETS/$PATH\n2. Compiled in asset $PATH\n\nNow we're instead looking for\n1. $STGUIASSETS/$PATH\n2. Compiled in asset $THEME/$PATH\n3. Compiled in asset default/$PATH\n\nI think it would be cleaner if we instead looked for\n1. $STGUIASSETS/$THEME/$PATH\n2. Compiled in asset $THEME/$PATH\n3. $STGUIASSETS/default/$PATH\n4. Compiled in asset default/$PATH\n\nThen we'd get back the old behavior of just being able to override the whole hierarchy and then hack on the dark theme or whatever as @lkwg82 also mentions. A (small) complication is that the theme selector would need to pick up themes present both in the compiled in assets and in the potential overridden assetsDir.\n\nFrom a development point of view, I think pointing STGUIASSETS at the gui dir in the source checkout should result in it working exactly as normal, except that anything in there can be overridden regardless of theme etc. It's just that I haven't noticed this is not the case because I haven't done nay GUI dev work lately :)\n\n(https://github.com/syncthing/docs/pull/132)\n"}, {"classified_as": "bug", "text": "The underlying CV functions in both cross_val_score and GridSearchCV have an option to shuffle inputs but these aren't exposed.  This requires the user to shuffle their examples ahead of time.  This is somewhat inconsistent with train_test_split that uses ShuffleSplit and, for the uninformed user, might cause confusion in output results in cases where the underlying inputs have some order (like in the wine quality dataset for example).\n\nWould it be possible to expose shuffle as a parameter in both cross_val_score and GridSearchCV and simply pass it through to _check_cv and on to StratifiedKFold and KFold?\n"}, {"classified_as": "bug", "text": "\r\n![screen shot 2017-09-21 at 7 37 02 pm](https://user-images.githubusercontent.com/12194969/30693950-6bde622a-9e97-11e7-8b2c-9f3ae0fd6e93.png)\r\n"}, {"classified_as": "api", "text": "https://github.com/polkadot-js/api/blob/master/packages/api-derive/src/imOnline/receivedHeartbeats.ts#L24\r\n\r\nHowever the imOnline query takes the . index, not the addres \r\n\r\n![image](https://user-images.githubusercontent.com/1424473/66158720-bddc7c00-e626-11e9-9277-9a1e6d41245b.png)\r\n\r\n- retrieve session index & keys\r\n- lookup keys in the array\r\n- then do the query based on index (not address)"}, {"classified_as": "api", "text": "Commit 4599d5841353fdf8096191c30a592fedc844efce an incomplete/incorrect fix.\r\n\r\nIn IdManager.h, id_traits has its static variables assigned inline, right where they are declared.  This is incorrect unless the inline keyword is used.  I'm not a C++ expert but the current code may violate the One Definition Rule.  Without the inline keyword, the linkage works strangely, which is the source of the undefined reference error on debug builds.\r\n\r\nOne solution besides inline would be out-of line declarations of the static variables, but this is tricky because of the void_t.  Once implemented, this solution causes gcc to complain about the use of non-contexpr variables in the static_assert, so it does not work.\r\n\r\nThe best solution IMO is to replace the const keyword with constexpr for base, step, count, and invalid in both specializations of id_traits.  This makes the static_assert in the second class template valid, and it also fixes the undefined reference error.\r\n\r\nRegardless, a new local variable in the destructor of sys_vm_t is not a good fix."}, {"classified_as": "api", "text": "- ::Proposal is returned\r\n- T :: AccountId is returned\r\n- Related https://github.com/paritytech/substrate/issues/1244"}, {"classified_as": "bug", "text": "<!-- Thanks for contributing to Calypso! Pick a clear title (\"Editor: add spell check\") and proceed. -->\r\n\r\n#### Steps to reproduce\r\n1. Go to the Customizer\r\n2. Add a new Tag or Category Cloud Widget\r\n3. Try to exclude some categories by using the ad hoc _Exclude_ box.\r\n\r\n#### What I expected\r\nI expected to be able to **use term slugs** there, not just the IDs\r\n\r\n#### What happened instead\r\nUnless I entered the ID for that term, the exclude functionality would not work. Additionally:\r\n- The input field did not show any **validation warning** such as _\"you need to enter a number here\"_.\r\n- It offered **no help**, for instance a _\"read more on how to find the ID for your category\"_ link or option.\r\n\r\n![](https://cld.wthms.co/LhiKKI+)\r\nImage link: https://cld.wthms.co/LhiKKI\r\n\r\n#### Context / Source\r\n2183150-ZEN"}, {"classified_as": "bug", "text": "<!--\r\nHello \ud83d\udc4b Thank you for submitting a feature request.\r\n\r\nWe are using ProductBoard to manage our roadmap and feature requests.\r\n\r\nCan you please submit your feature request here: https://portal.productboard.com/strapi\r\n-->\r\n\r\n- [x] **I have created my request on the Product Board before I submitted this issue**\r\n- [x] **I have looked at all the other requests on the Product Board before I submitted this issue**\r\n\r\n**Please describe your feature request:**\r\nStrapi main bundle size is around 6.6 MB for just viewing 'login' page on fast net it takes around 6 sec time. \r\nIt would be great If some components can be lazy loaded & main bundle size can be reduced.\r\n\r\n<img width=\"825\" alt=\"Screenshot 2020-08-12 at 4 58 24 PM\" src=\"https://user-images.githubusercontent.com/2557058/90010521-941bc900-dcbd-11ea-845c-ace3bcdb8d26.png\">\r\n"}, {"classified_as": "bug", "text": "<!-- Please only use this template for submitting enhancement requests -->\r\n\r\n**What would you like to be added**:\r\nI would like the default for enableServiceLinks to be changed from true to false \r\n\r\n**Why is this needed**:\r\n\r\nI think the default behaviour is unexpected for new users. Having this be an opt-in feature may be more predictable. \r\n\r\nReferences:\r\nhttps://github.com/kubernetes/kubernetes/issues/60099\r\nhttps://github.com/elastic/cloud-on-k8s/issues/2030\r\nhttps://github.com/knative/serving/issues/6074\r\nhttps://stackoverflow.com/questions/45323958/is-it-possible-to-disable-service-discovery-with-environment-variables-in-kubern\r\nhttps://twitter.com/fredbrancz/status/1201937181230686208"}, {"classified_as": "bug", "text": "**Describe the bug**\r\nthe floating round button with \"?\" that opens the \"GET STARTED VIDEOS\" covers the pagination arrow \r\n\r\n**Steps to reproduce the behavior**\r\n1. insert more than 20 documents in the collection\r\n2. set 20 ( or more ) entries per page\r\n3. Scroll down to the end of the table\r\n4. See the help button covering the pagination arrow and can't click on it\r\n\r\n**Expected behavior**\r\nbutton on a higher place than pagination\r\n\r\n**Screenshots**\r\n![screen](https://user-images.githubusercontent.com/16583356/88924046-f8c53580-d272-11ea-8620-3d4c5d90740a.JPG)\r\n\r\n\r\n**System**\r\n- Node.js version: 14.5.0\r\n- NPM version: 6.14.5\r\n- Strapi version: 3.1.0\r\n- Database: mongoDb\r\n- Operating system: Windows 10\r\n\r\n"}, {"classified_as": "api", "text": "I am trying to find a way to document our current API using swagger.  It looks like a great tool and I am excited to get it working.  But I think I have a misunderstanding about how it works or perhaps simply a mismatch between our API structure and how Swagger expects to structure APIs.\n# My API\n\nOur APIs have a structure like this:\n- Groups: way to organize related resources (ex: authentication, documents, analytics, ...)\n  - Resource/Handler: base handlers for a specific resource root path\n    - Operations: the actual HTTP operations on the resource (each handler may have GET, PUT, POST, DELETE)\n\nAs a more concrete (but contrived) example we may have something like:\n- Group: Document Processing\n  - Resource: Blog List\n    - path: /blog\n    - GET: return list of blog entries\n    - POST: create new blog entry\n  - Resource: Blog Entries\n    - path: /blog/{id}\n    - GET: return contents of blog entry\n    - PUT: update blog entry\n  - Resource: Chat List\n    - path: /comment\n    - GET: return list of chat entries\n  - Resource: Chat Entry\n    - path: /comment/{id}\n    - GET: return contents of chat entry\n- Group: User Management\n  - Resource: User List\n    - path: /user\n    - GET: return list of users\n  - Resource: User Details\n    - path: /user/{id}\n    - GET: return details of user\n# Swagger Mapping\n\nI am trying to determine how to document this in Swagger.\n\nAs I understand swagger from reading the spec and looking at the code for swagger-client and swagger-ui, the data model is something like this (with fields of note in []'s):\n- API Listing (also called Resource Listing) - [version, basepath]\n  - API Declaration (also called Resource) - [description (from listing), version, resourcePath, ...]\n    - API (also called endpoint) - [path, description, ...]\n      - Operation: [method, summary, notes, params, responses]\n\nMy idea for mapping our API to this structure was to map:\n- Group --> API Declaration\n  - Put overall documentation about the group into API declaration description in API Listing.\n- Resource/Handler --> API\n  - Put resource documentation/description in as API description\n  - Put resource path in as API path\n- Handler method --> Operation\n  - Put method documentation in as operation summary and notes\n\nI have all the code working generating this type of mapping, but as I try to use it in swagger ui (and customize the interface) I am running into a couple of issues I can't seem to resolve.\n1. Swagger client doesn't not make the API/endpoint level of the swagger hierarchy available.\n   \n   As best as I can tell, the swagger.js code pulls all operations up under the API Declaration / Resource level without the extra level of grouping supported by the spec.\n2. Swagger UI does not appear to support grouping operations based upon API Declaration / Resource.\n   \n   This is likely due to the first item, but means I need to restructure the user interface a bit to get my items structured correctly.\n# Question\n\nWith all that background in place, my question is am I mapping our API incorrectly or am I just missing something about how to use swagger to document it?\n"}, {"classified_as": "api", "text": "From https://polkadot.js.org/api/types/\r\n\r\n- Metadata (and it looks the same as others) is not creating a link\r\n- Other links (e.g. AccountId), try to load the .md file instead of the generated HTML - well, actually HTML is not generated\r\n\r\nNeed a solution that does not entail adding all these to SUMMARY.md"}, {"classified_as": "api", "text": "We have not migrated and are still using a combination of development and production databases on Parse. We have an array of pointers column on our _User class. It used to be that calling Parse.addUnique(\"students\", StudentObj); would save a reference pointer to the students but now the server seems to be populating the array with the full objects of each \"student\" _User class.\n\nAdditionally, this is causing a series of problems because calling \"include\" on _User for the students array of pointers is now simply returning an assorted array with some rows only having an ObjectID and some having a full (but out of date) object. What happened to the proper reference pointer logic?\n"}, {"classified_as": "api", "text": "For api-observable, I try  unsubscribe bestNumber, but it not send chain_unsubscribeNewHead request"}, {"classified_as": "bug", "text": "e.g.\r\n\r\njs\r\n// Fill an element \r\nawait browser.fill('#username', 'myUser')\r\n\r\n// set an element's value value\r\nawait browser.setValue('#comment', 'my feelings')\r\n\r\n// Type in an element \r\nawait browser.type('#password', 'Yey!ImAPassword!')\r\n"}, {"classified_as": "bug", "text": "**What is the expected behavior?**\r\nStrapi uses Knexjs for manage DB connections, but it's not using all the options available.\r\n\r\n---\r\n\r\nThis story begins with me trying to deploy Strapi on [Pivotal](https://pivotal.io/)'s [Could Foundry](https://www.cloudfoundry.org/) using the free MySQL service plan with a limitation up to 4 connections:\r\n![capture](https://user-images.githubusercontent.com/5768813/46105799-9bef2480-c19c-11e8-999e-2c05e194196d.PNG)\r\n\r\nApparently, Strapi is using more that than just for starting according the logs:\r\n\r\n[APP/PROC/WEB/0] ERR (node:147) UnhandledPromiseRejectionWarning: Error: ER_USER_LIMIT_REACHED: User 'bf662ec45746cc' has exceeded the 'max_user_connections' resource (current value: 4)\r\n\r\n\r\nLooking for a solution, I see [Knexjs allows to configure the pool connection](https://knexjs.org/#Installation-pooling):\r\n\r\n> To change the config settings for the pool, pass a pool option as one of the keys in the initialize block\r\n\r\nBut seeing the code:\r\n\r\n1. Strapi pick just [some specific options](https://github.com/strapi/strapi/blob/bf355c89110dde969cdc1648d1f959cb1cf3dc7e/packages/strapi-hook-knex/lib/index.js#L104)\r\n 2. Some options are limited by engine ([like this, the pool one](https://github.com/strapi/strapi/blob/bf355c89110dde969cdc1648d1f959cb1cf3dc7e/packages/strapi-hook-knex/lib/index.js#L113)]\r\n\r\n\r\n**Question**: Wouldn't it be better to make this configuration match Knexjs? The Strapi database configuration should match Knexjs available options.\r\n\r\nRequest for comments before begin to work with a patch."}, {"classified_as": "api", "text": ":8ball: \n"}, {"classified_as": "api", "text": "- swagger-ui version : 3.0.13 \r\n\r\nSome oAuth2 clients are registred with option **token_endpoint_auth_method = client_secret_post**. That means when they are trying to get token using **/token** endpoint they have to provide client_secret and client_id using request body instead of Authorization header.\r\nCurrent implementation supporting only clients registered with option **token_endpoint_auth_method = client_secret_basic**. \r\n\r\nMore about this here: https://tools.ietf.org/html/rfc7591#section-2\r\n\r\nIt would be nice to have way to control which method will swagger-ui use to get token. As nothing was mentioned in OpenAPI spec maybe we can just add dropdown so user can pick desired method.\r\n\r\n"}, {"classified_as": "api", "text": "Since #6336 there's an issue where metadata gets doubled if a recalculation is deemed necessary. The reason is that we will have loaded the existing metadata, then do a recalc by adding all files without clearing it first."}, {"classified_as": "api", "text": "When saving a new PFUser on iOS, the SDK(?) throws this error:\n\nCaught \"NSInternalInconsistencyException\" with reason \"User cannot be saved unless they are already signed up. Call signUp first.\"\nWhen saving a new PFUser via Cloud Code, it does not throw that error but simply mimics a \"signUp\", which creates a session token for the server... in Cloud Code! (actually, read #3 as this may be a bug with the pfuser handling)\n\nFor sake of flexibility and consistency (with PFObjects), I think there should be an option to \"save\" a PFUser without having a session token created, or restricting (iOS) apps to always use PFUser.signUp. There are many use-cases for such a feature, and I feel that it is a meaningless restriction.\n\nPersonal use-case: I have some special logic to replace the standard \"signUp\" flow, which has me creating a PFUser via Cloud Code + MasterKey. But with how the \"save\" function is behaving, it's creating a session token for the server!\n\nRef #1490 \n"}, {"classified_as": "bug", "text": "**Informations**\r\n- **Node.js version**: Node v10\r\n- **NPM version**: NPM v6\r\n- **Strapi version**: 3.0.0-alpha.17\r\n- **Database**: MariaDB 10.2\r\n- **Operating system**: Ubuntu 18.04\r\n- **(Optional) Link to your Project**: [Link](https://github.com/canonn-science/CAPIv2-Strapi/tree/update/autoDocsUpdate)\r\n\r\n\r\n**What is the current behavior?**\r\n\r\nCurrently the model level overrides generate the openapi schema file based on their alphabetical ordering (model name), this can make for an \"ugly\" view on the swaggerUI because even if you define the tags in the core override for the docs the models will force the listing to follow their order. (confused yet?)\r\n\r\n**Steps to reproduce the problem**\r\n\r\nDifficult to describe on reproduction, you can follow my project to see what I'm doing.\r\n\r\nExample image:\r\n\r\n![image](https://user-images.githubusercontent.com/8593673/50218033-c7228380-0347-11e9-9317-7c1799c8599c.png)\r\n\r\nAs you can see in the image above two of my models aren't following the rest because the model Guardian Beacons ranks higher in the alphabetical sorting system than the related Report model.\r\n\r\n**What is the expected behavior?**\r\n\r\nSee Suggestion\r\n\r\n**Suggested solutions**\r\n\r\nIn addition to the core documentation settings.json file I think another should be included basically like tags.json. The order in which the overrides should happen:\r\n\r\n1. Core settings.json\r\n2. Model overrides\r\n3. Core tags.json\r\n\r\nIn this case the user can define the \"sort\" order of how the swagger/openapi doc file is laid out."}, {"classified_as": "api", "text": "javascript\r\napi.queryMulti([\r\n  [api.query.session.nextKeyFor, controllerId],\r\n  [api.query.staking.ledger, controllerId],\r\n], callback)\r\n\r\n\r\nFirst result: [something1, something2],\r\n\r\n**Expected:** \r\n\r\nsecond result: [something1, something3]\r\n\r\n**Actual:**\r\n\r\nsecond result: [null, something3]\r\n\r\n"}, {"classified_as": "api", "text": "With https://crrev.com/683391, chrome no longer throws exceptions when not executing inline script tags due to CSP.\r\n\r\nWe can fix this with probing runtime first - checking if inline scripts have any power. Alternatively, we might want to check current page CSP policy."}]