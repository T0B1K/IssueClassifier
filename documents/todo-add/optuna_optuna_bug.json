[{"labels":["bug"],"text":"<!-- Please write a clear and concise description of what the bug is. -->\r\n\r\n## Expected behavior\r\n\r\nI use LightGBMTuner to find params, but each run on the same dataset has different results\r\n<!-- Please write a clear and concise description of what you expected to happen. -->\r\n\r\n## Environment\r\n\r\n- Optuna version: 2.1.0\r\n- Python version: 3.8.5\r\n- OS: Linux\r\n- (Optional) Other libraries and their versions:\r\n\r\n## Error messages, stack traces, or logs\r\n\r\n```\r\n# error messages, stack traces, or logs\r\n```\r\n\r\n## Steps to reproduce\r\n\r\n1.\r\n2.\r\n3.\r\n\r\n## Reproducible examples (optional)\r\n\r\n```python\r\n# python code\r\n```\r\n\r\n## Additional context (optional)\r\n\r\n<!-- Please add any other context or screenshots about the problem here. -->\r\n"},{"labels":["bug"],"text":"<!-- Please write a clear and concise description of what the bug is. -->\r\n\r\n## Problem details\r\n\r\nThis bug is reported by @maartenpants on gitter. Original report is here:\r\n\r\n> Hi there, has anyone else experienced this issue with CmaEsSampler and the PostgreSQL storage backend:\r\n> ```\r\n> (psycopg2.errors.StringDataRightTruncation) value too long for type character varying(2048)\r\n> [SQL: INSERT INTO trial_system_attributes (trial_id, key, value_json) VALUES (%(trial_id)s, %(key)s, %(value_json)s) RETURNING trial_system_attributes.trial_system_attribute_id]\r\n> ```\r\n> It seems the serialized version of the CMA class is too large to fit in the 2048 character column. This code is the culprit:\r\n> ```\r\n> optimizer_str = pickle.dumps(optimizer).hex()\r\n> study._storage.set_trial_system_attr(trial._trial_id, \"cma:optimizer\", optimizer_str)\r\n> ```\r\n\r\nhttps://gitter.im/optuna/optuna?at=5f484dea36e6f709fd08a5fa\r\n\r\nI checked the length of serialized CMA object.\r\n\r\n```python\r\nimport pickle\r\n\r\nimport numpy as np\r\nfrom cmaes import CMA\r\n\r\n\r\ndef get_cma_object_size(dim: int) -> int:\r\n    optimizer = CMA(mean=np.zeros(dim), sigma=1.3)\r\n    optimizer_str = pickle.dumps(optimizer).hex()\r\n    return len(optimizer_str)\r\n\r\n\r\nif __name__ == '__main__':\r\n    for i in range(2, 32, 2):\r\n        print(f\"dim={i} size={get_cma_object_size(i)}\")\r\n```\r\n\r\n```\r\n$ python examples/cma_size.py \r\ndim=2 size=2516\r\ndim=4 size=2916\r\ndim=6 size=3364\r\ndim=8 size=3850\r\ndim=10 size=4442\r\ndim=12 size=5018\r\ndim=14 size=5738\r\ndim=16 size=6378\r\ndim=18 size=7194\r\ndim=20 size=8074\r\ndim=22 size=8906\r\ndim=24 size=9916\r\ndim=26 size=10956\r\ndim=28 size=12092\r\ndim=30 size=13148\r\n```\r\n\r\nThis result means that the bug is raised even on low-dimensional search space.\r\n\r\n## Additional context (optional)\r\n\r\nI've ever tested on SQLite3 but never bumped into this bug. The reason why is:\r\n\r\n> (9) What is the maximum size of a VARCHAR in SQLite?\r\n> SQLite does not enforce the length of a VARCHAR. You can declare a VARCHAR(10) and SQLite will be happy to store a 500-million character string there. And it will keep all 500-million characters intact. Your content is never truncated. SQLite understands the column type of \"VARCHAR(N)\" to be the same as \"TEXT\", regardless of the value of N.\r\n> https://www.sqlite.org/faq.html#:~:text=(9)%20What%20is%20the%20maximum,all%20500%2Dmillion%20characters%20intact.\r\n\r\n"},{"labels":["bug"],"text":"<!-- Please write a clear and concise description of what the bug is. -->\r\n\r\nUsing the \"pytorch_lightning_simple.py\" example and adding the distributed_backend='ddp' option in pl.Trainer. It isn't working on one or more GPU's\r\n\r\n<!-- Please write a clear and concise description of what you expected to happen. -->\r\n\r\n## Environment\r\n\r\n- Optuna version: optuna (2.0.0)\r\n- Python version: 3.7\r\n- OS: Linux Ubuntu\r\n- (Optional) Other libraries and their versions: pytorch-lightning (0.9.0), torch (1.6.0), torchvision (0.4.2) \r\n\r\n## Error messages, stack traces, or logs\r\n\r\n```\r\nGPU available: True, used: True\r\nTPU available: False, using: 0 TPU cores\r\nCUDA_VISIBLE_DEVICES: [0]\r\n/home/bart.michiels/test_optuna/.venv/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: WORLD_SIZE environment variable (2) is not equal to the computed world size (1). Ignored.\r\n  warnings.warn(*args, **kwargs)\r\ninitializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\r\n----------------------------------------------------------------------------------------------------\r\ndistributed_backend=ddp\r\nAll DDP processes registered. Starting ddp with 1 processes\r\n----------------------------------------------------------------------------------------------------\r\n\r\n  | Name  | Type | Params\r\n-------------------------------\r\n0 | model | Net  | 3 K   \r\n/home/bart.michiels/test_optuna/.venv/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\r\n  warnings.warn(*args, **kwargs)\r\n/home/bart.michiels/test_optuna/.venv/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\r\n  warnings.warn(*args, **kwargs)\r\nEpoch 2: 100%|████████████████Saving latest checkpoint..████████████████████████████████████████████████████████████████████████████████████████| 476/476 [00:07<00:00, 63.27it/s, loss=1.923]\r\nEpoch 2: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 476/476 [00:07<00:00, 63.26it/s, loss=1.923]\r\n[I 2020-08-30 19:43:02,990] Trial 0 finished with value: 0.3950892984867096 and parameters: {'n_layers': 3, 'dropout': 0.4634065756224022, 'n_units_l0': 4, 'n_units_l1': 16, 'n_units_l2': 13}. Best is trial 0 with value: 0.3950892984867096.\r\nGPU available: True, used: True\r\nTPU available: False, using: 0 TPU cores\r\nUsing environment variable NODE_RANK for node rank (0).\r\nCUDA_VISIBLE_DEVICES: [0]\r\ninitializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\r\n[W 2020-08-30 19:43:02,996] Trial 1 failed because of the following error: RuntimeError('Address already in use',)\r\nTraceback (most recent call last):\r\n  File \"/home/bart.michiels/test_optuna/.venv/lib/python3.6/site-packages/optuna/study.py\", line 709, in _run_trial\r\n    result = func(trial)\r\n  File \"test.py\", line 153, in objective\r\n    trainer.fit(model)\r\n  File \"/home/bart.michiels/test_optuna/.venv/lib/python3.6/site-packages/pytorch_lightning/trainer/states.py\", line 48, in wrapped_fn\r\n    result = fn(self, *args, **kwargs)\r\n  File \"/home/bart.michiels/test_optuna/.venv/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 1058, in fit\r\n    results = self.accelerator_backend.spawn_ddp_children(model)\r\n  File \"/home/bart.michiels/test_optuna/.venv/lib/python3.6/site-packages/pytorch_lightning/accelerators/ddp_backend.py\", line 123, in spawn_ddp_children\r\n    results = self.ddp_train(local_rank, mp_queue=None, model=model, is_master=True)\r\n  File \"/home/bart.michiels/test_optuna/.venv/lib/python3.6/site-packages/pytorch_lightning/accelerators/ddp_backend.py\", line 164, in ddp_train\r\n    self.trainer.is_slurm_managing_tasks\r\n  File \"/home/bart.michiels/test_optuna/.venv/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\", line 908, in init_ddp_connection\r\n    torch_distrib.init_process_group(torch_backend, rank=global_rank, world_size=world_size)\r\n  File \"/home/bart.michiels/test_optuna/.venv/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py\", line 422, in init_process_group\r\n    store, rank, world_size = next(rendezvous_iterator)\r\n  File \"/home/bart.michiels/test_optuna/.venv/lib/python3.6/site-packages/torch/distributed/rendezvous.py\", line 172, in _env_rendezvous_handler\r\n    store = TCPStore(master_addr, master_port, world_size, start_daemon, timeout)\r\nRuntimeError: Address already in use\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 172, in <module>\r\n    study.optimize(objective, n_trials=100, timeout=600)\r\n  File \"/home/bart.michiels/test_optuna/.venv/lib/python3.6/site-packages/optuna/study.py\", line 292, in optimize\r\n    func, n_trials, timeout, catch, callbacks, gc_after_trial, None\r\n  File \"/home/bart.michiels/test_optuna/.venv/lib/python3.6/site-packages/optuna/study.py\", line 654, in _optimize_sequential\r\n    self._run_trial_and_callbacks(func, catch, callbacks, gc_after_trial)\r\n  File \"/home/bart.michiels/test_optuna/.venv/lib/python3.6/site-packages/optuna/study.py\", line 685, in _run_trial_and_callbacks\r\n    trial = self._run_trial(func, catch, gc_after_trial)\r\n  File \"/home/bart.michiels/test_optuna/.venv/lib/python3.6/site-packages/optuna/study.py\", line 709, in _run_trial\r\n    result = func(trial)\r\n  File \"test.py\", line 153, in objective\r\n    trainer.fit(model)\r\n  File \"/home/bart.michiels/test_optuna/.venv/lib/python3.6/site-packages/pytorch_lightning/trainer/states.py\", line 48, in wrapped_fn\r\n    result = fn(self, *args, **kwargs)\r\n  File \"/home/bart.michiels/test_optuna/.venv/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 1058, in fit\r\n    results = self.accelerator_backend.spawn_ddp_children(model)\r\n  File \"/home/bart.michiels/test_optuna/.venv/lib/python3.6/site-packages/pytorch_lightning/accelerators/ddp_backend.py\", line 123, in spawn_ddp_children\r\n    results = self.ddp_train(local_rank, mp_queue=None, model=model, is_master=True)\r\n  File \"/home/bart.michiels/test_optuna/.venv/lib/python3.6/site-packages/pytorch_lightning/accelerators/ddp_backend.py\", line 164, in ddp_train\r\n    self.trainer.is_slurm_managing_tasks\r\n  File \"/home/bart.michiels/test_optuna/.venv/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\", line 908, in init_ddp_connection\r\n    torch_distrib.init_process_group(torch_backend, rank=global_rank, world_size=world_size)\r\n  File \"/home/bart.michiels/test_optuna/.venv/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py\", line 422, in init_process_group\r\n    store, rank, world_size = next(rendezvous_iterator)\r\n  File \"/home/bart.michiels/test_optuna/.venv/lib/python3.6/site-packages/torch/distributed/rendezvous.py\", line 172, in _env_rendezvous_handler\r\n    store = TCPStore(master_addr, master_port, world_size, start_daemon, timeout)\r\nRuntimeError: Address already in use\r\n```\r\n\r\n## Steps to reproduce\r\n\r\nUsing the \"pytorch_lightning_simple.py\" example and adding the distributed_backend='ddp' option in pl.Trainer. It isn't working on one or more GPU's\r\n\r\n"},{"labels":["bug"],"text":"![image](https://user-images.githubusercontent.com/20265321/91530606-fa4f4f80-e93d-11ea-9653-946a3c7e653e.png)\r\n"},{"labels":["bug"],"text":"---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-57-4d0f80b09927> in <module>\r\n----> 1 import optuna.integration.lightgbm as lgb\r\n\r\n~/anaconda3/lib/python3.7/site-packages/optuna/integration/lightgbm.py in <module>\r\n      4 \r\n      5 from optuna._imports import try_import\r\n----> 6 from optuna.integration import _lightgbm_tuner as tuner\r\n      7 \r\n      8 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/optuna/integration/_lightgbm_tuner/__init__.py in <module>\r\n      1 from typing import Any\r\n      2 \r\n----> 3 from optuna.integration._lightgbm_tuner.optimize import _imports as _imports\r\n      4 from optuna.integration._lightgbm_tuner.optimize import LightGBMTuner\r\n      5 from optuna.integration._lightgbm_tuner.optimize import LightGBMTunerCV  # NOQA\r\n\r\n~/anaconda3/lib/python3.7/site-packages/optuna/integration/_lightgbm_tuner/optimize.py in <module>\r\n    631 \r\n    632 \r\n--> 633 class LightGBMTuner(_LightGBMBaseTuner):\r\n    634     \"\"\"Hyperparameter tuner for LightGBM.\r\n    635 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/optuna/integration/_lightgbm_tuner/optimize.py in LightGBMTuner()\r\n    759         \"1.4.0\",\r\n    760         text=(\r\n--> 761             \"Please get the best booster via \"\r\n    762             \":class:`~optuna.integration.lightgbm.LightGBMTuner.get_best_booster` instead.\"\r\n    763         ),\r\n\r\n~/anaconda3/lib/python3.7/site-packages/optuna/_deprecated.py in deprecated(deprecated_version, removed_version, name, text)\r\n     75     _validate_version(deprecated_version)\r\n     76     if removed_version is None:\r\n---> 77         removed_version = _get_removed_version_from_deprecated_version(deprecated_version)\r\n     78     _validate_version(removed_version)\r\n     79     _validate_two_version(deprecated_version, removed_version)\r\n\r\n~/anaconda3/lib/python3.7/site-packages/optuna/_deprecated.py in _get_removed_version_from_deprecated_version(deprecated_version)\r\n     37     parsed_deprecated_version = version.parse(deprecated_version)\r\n     38     assert isinstance(parsed_deprecated_version, version.Version)  # Required for mypy.\r\n---> 39     return \"{}.0.0\".format(parsed_deprecated_version.major + 2)\r\n     40 \r\n     41 \r\n\r\nAttributeError: 'Version' object has no attribute 'major'"},{"labels":["bug"],"text":"<!-- Please write a clear and concise description of what the bug is. -->\r\nNo module named 'optuna.storages.in_memory' when loading in-memory studies.\r\n## Expected behavior\r\n<!-- Please write a clear and concise description of what you expected to happen. -->\r\nIn-memory studies should be able to be loaded again by joblib or pickle.\r\n## Environment\r\n\r\n- Optuna version: 2.0.0\r\n- Python version: 3.7.3\r\n- OS: Linux\r\n- (Optional) Other libraries and their versions:\r\njoblib\r\n\r\n## Error messages, stack traces, or logs\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nModuleNotFoundError                       Traceback (most recent call last)\r\n<ipython-input-15-450c43275578> in <module>\r\n----> 1 study = joblib.load('node2vec_optimization/study100.pkl')\r\n\r\n~/anaconda3/envs/cada/lib/python3.7/site-packages/joblib/numpy_pickle.py in load(filename, mmap_mode)\r\n    583                     return load_compatibility(fobj)\r\n    584 \r\n--> 585                 obj = _unpickle(fobj, filename, mmap_mode)\r\n    586     return obj\r\n\r\n~/anaconda3/envs/cada/lib/python3.7/site-packages/joblib/numpy_pickle.py in _unpickle(fobj, filename, mmap_mode)\r\n    502     obj = None\r\n    503     try:\r\n--> 504         obj = unpickler.load()\r\n    505         if unpickler.compat_mode:\r\n    506             warnings.warn(\"The file '%s' has been generated with a \"\r\n\r\n~/anaconda3/envs/cada/lib/python3.7/pickle.py in load(self)\r\n   1086                     raise EOFError\r\n   1087                 assert isinstance(key, bytes_types)\r\n-> 1088                 dispatch[key[0]](self)\r\n   1089         except _Stop as stopinst:\r\n   1090             return stopinst.value\r\n\r\n~/anaconda3/envs/cada/lib/python3.7/pickle.py in load_global(self)\r\n   1374         module = self.readline()[:-1].decode(\"utf-8\")\r\n   1375         name = self.readline()[:-1].decode(\"utf-8\")\r\n-> 1376         klass = self.find_class(module, name)\r\n   1377         self.append(klass)\r\n   1378     dispatch[GLOBAL[0]] = load_global\r\n\r\n~/anaconda3/envs/cada/lib/python3.7/pickle.py in find_class(self, module, name)\r\n   1424             elif module in _compat_pickle.IMPORT_MAPPING:\r\n   1425                 module = _compat_pickle.IMPORT_MAPPING[module]\r\n-> 1426         __import__(module, level=0)\r\n   1427         if self.proto >= 4:\r\n   1428             return _getattribute(sys.modules[module], name)[0]```\r\n---------------------------------------------------------------------------\r\nNo module named 'optuna.storages.in_memory'\r\n\r\n## Steps to reproduce\r\n\r\n1. create a study\r\n2. dump it using joblib.dump\r\n3. load it again with joblib.load\r\n## Reproducible examples (optional)\r\n\r\n```python\r\nstudy = optuna.create_study()\r\njoblib.dump(study, 'study.pkl')\r\nstudy = joblib.load('study.pkl')\r\n\r\n```\r\n\r\n## Additional context (optional)\r\n\r\n<!-- Please add any other context or screenshots about the problem here. -->\r\n"},{"labels":["bug"],"text":"I am working with a customized Pendulum-v0 environment which has a maximum timestep attribute to allow early resets and therefore reward tracking and also uses rgb-array's for observation. I am trying to use the hyperparameter optimization for that environment and therefore registered the environment to gym. I can not run train.py with n_jobs larger than 1. \r\n \r\n\r\ntrain.py:\r\n```\r\n\r\nimport os\r\nimport time\r\nimport uuid\r\nimport difflib\r\nimport argparse\r\nimport importlib\r\nimport warnings\r\nfrom pprint import pprint\r\nfrom collections import OrderedDict\r\n\r\n# numpy warnings because of tensorflow\r\nwarnings.filterwarnings(\"ignore\", category=FutureWarning, module='tensorflow')\r\nwarnings.filterwarnings(\"ignore\", category=UserWarning, module='gym')\r\n\r\nimport gym\r\nimport numpy as np\r\nimport yaml\r\n# Optional dependencies\r\nimport utils.import_envs  # pytype: disable=import-error\r\ntry:\r\n    import mpi4py\r\n    from mpi4py import MPI\r\nexcept ImportError:\r\n    mpi4py = None\r\n\r\nfrom stable_baselines.common import set_global_seeds\r\nfrom stable_baselines.common.cmd_util import make_atari_env\r\nfrom stable_baselines.common.vec_env import VecFrameStack, SubprocVecEnv, VecNormalize, DummyVecEnv, VecEnv\r\nfrom stable_baselines.common.noise import AdaptiveParamNoiseSpec, NormalActionNoise, OrnsteinUhlenbeckActionNoise\r\nfrom stable_baselines.common.schedules import constfn\r\nfrom stable_baselines.common.callbacks import CheckpointCallback, EvalCallback\r\nfrom stable_baselines.her import HERGoalEnvWrapper\r\nfrom stable_baselines.common.base_class import _UnvecWrapper\r\n\r\nfrom utils import make_env, ALGOS, linear_schedule, get_latest_run_id, get_wrapper_class\r\nfrom utils.hyperparams_opt import hyperparam_optimization\r\nfrom utils.callbacks import SaveVecNormalizeCallback\r\nfrom utils.noise import LinearNormalActionNoise\r\nfrom utils.utils import StoreDict\r\n\r\n\r\nif __name__ == '__main__':\r\n    parser = argparse.ArgumentParser()\r\n    parser.add_argument('--env', type=str, default=\"CartPole-v1\", help='environment ID')\r\n    parser.add_argument('-tb', '--tensorboard-log', help='Tensorboard log dir', default='', type=str)\r\n    parser.add_argument('-i', '--trained-agent', help='Path to a pretrained agent to continue training',\r\n                        default='', type=str)\r\n    parser.add_argument('--algo', help='RL Algorithm', default='ppo2',\r\n                        type=str, required=False, choices=list(ALGOS.keys()))\r\n    parser.add_argument('-n', '--n-timesteps', help='Overwrite the number of timesteps', default=-1,\r\n                        type=int)\r\n    parser.add_argument('--log-interval', help='Override log interval (default: -1, no change)', default=-1,\r\n                        type=int)\r\n    parser.add_argument('--eval-freq', help='Evaluate the agent every n steps (if negative, no evaluation)',\r\n                        default=10000, type=int)\r\n    parser.add_argument('--eval-episodes', help='Number of episodes to use for evaluation',\r\n                        default=5, type=int)\r\n    parser.add_argument('--save-freq', help='Save the model every n steps (if negative, no checkpoint)',\r\n                        default=-1, type=int)\r\n    parser.add_argument('-f', '--log-folder', help='Log folder', type=str, default='logs')\r\n    parser.add_argument('--seed', help='Random generator seed', type=int, default=0)\r\n    parser.add_argument('--n-trials', help='Number of trials for optimizing hyperparameters', type=int, default=10)\r\n    parser.add_argument('-optimize', '--optimize-hyperparameters', action='store_true', default=False,\r\n                        help='Run hyperparameters search')\r\n    parser.add_argument('--n-jobs', help='Number of parallel jobs when optimizing hyperparameters', type=int, default=1)\r\n    parser.add_argument('--sampler', help='Sampler to use when optimizing hyperparameters', type=str,\r\n                        default='tpe', choices=['random', 'tpe', 'skopt'])\r\n    parser.add_argument('--pruner', help='Pruner to use when optimizing hyperparameters', type=str,\r\n                        default='median', choices=['halving', 'median', 'none'])\r\n    parser.add_argument('--verbose', help='Verbose mode (0: no output, 1: INFO)', default=1,\r\n                        type=int)\r\n    parser.add_argument('--gym-packages', type=str, nargs='+', default=[],\r\n                        help='Additional external Gym environemnt package modules to import (e.g. gym_minigrid)')\r\n    parser.add_argument('-params', '--hyperparams', type=str, nargs='+', action=StoreDict,\r\n                        help='Overwrite hyperparameter (e.g. learning_rate:0.01 train_freq:10)')\r\n    parser.add_argument('-uuid', '--uuid', action='store_true', default=False,\r\n                        help='Ensure that the run has a unique ID')\r\n    parser.add_argument('--env-kwargs', type=str, nargs='+', action=StoreDict,\r\n                        help='Optional keyword argument to pass to the env constructor')\r\n    args = parser.parse_args()\r\n\r\n    # Going through custom gym packages to let them register in the global registory\r\n    for env_module in args.gym_packages:\r\n        importlib.import_module(env_module)\r\n\r\n    env_id = args.env\r\n    registered_envs = set(gym.envs.registry.env_specs.keys())\r\n\r\n    # If the environment is not found, suggest the closest match\r\n    if env_id not in registered_envs:\r\n        try:\r\n            closest_match = difflib.get_close_matches(env_id, registered_envs, n=1)[0]\r\n        except IndexError:\r\n            closest_match = \"'no close match found...'\"\r\n        raise ValueError('{} not found in gym registry, you maybe meant {}?'.format(env_id, closest_match))\r\n\r\n    # Unique id to ensure there is no race condition for the folder creation\r\n    uuid_str = '_{}'.format(uuid.uuid4()) if args.uuid else ''\r\n    if args.seed < 0:\r\n        # Seed but with a random one\r\n        args.seed = np.random.randint(2**32 - 1)\r\n\r\n    set_global_seeds(args.seed)\r\n\r\n    if args.trained_agent != \"\":\r\n        valid_extension = args.trained_agent.endswith('.pkl') or args.trained_agent.endswith('.zip')\r\n        assert valid_extension and os.path.isfile(args.trained_agent), \\\r\n            \"The trained_agent must be a valid path to a .zip/.pkl file\"\r\n\r\n    rank = 0\r\n    if mpi4py is not None and MPI.COMM_WORLD.Get_size() > 1:\r\n        print(\"Using MPI for multiprocessing with {} workers\".format(MPI.COMM_WORLD.Get_size()))\r\n        rank = MPI.COMM_WORLD.Get_rank()\r\n        print(\"Worker rank: {}\".format(rank))\r\n\r\n        args.seed += rank\r\n        if rank != 0:\r\n            args.verbose = 0\r\n            args.tensorboard_log = ''\r\n\r\n    tensorboard_log = None if args.tensorboard_log == '' else os.path.join(args.tensorboard_log, env_id)\r\n\r\n    is_atari = False\r\n    if 'NoFrameskip' in env_id:\r\n        is_atari = True\r\n\r\n    print(\"=\" * 10, env_id, \"=\" * 10)\r\n    print(\"Seed: {}\".format(args.seed))\r\n\r\n    # Load hyperparameters from yaml file\r\n    with open('hyperparams/{}.yml'.format(args.algo), 'r') as f:\r\n        hyperparams_dict = yaml.safe_load(f)\r\n        if env_id in list(hyperparams_dict.keys()):\r\n            hyperparams = hyperparams_dict[env_id]\r\n        elif is_atari:\r\n            hyperparams = hyperparams_dict['atari']\r\n        else:\r\n            raise ValueError(\"Hyperparameters not found for {}-{}\".format(args.algo, env_id))\r\n\r\n    if args.hyperparams is not None:\r\n        # Overwrite hyperparams if needed\r\n        hyperparams.update(args.hyperparams)\r\n\r\n    # Sort hyperparams that will be saved\r\n    saved_hyperparams = OrderedDict([(key, hyperparams[key]) for key in sorted(hyperparams.keys())])\r\n\r\n    algo_ = args.algo\r\n    # HER is only a wrapper around an algo\r\n    if args.algo == 'her':\r\n        algo_ = saved_hyperparams['model_class']\r\n        assert algo_ in {'sac', 'ddpg', 'dqn', 'td3'}, \"{} is not compatible with HER\".format(algo_)\r\n        # Retrieve the model class\r\n        hyperparams['model_class'] = ALGOS[saved_hyperparams['model_class']]\r\n        if hyperparams['model_class'] is None:\r\n            raise ValueError('{} requires MPI to be installed'.format(algo_))\r\n\r\n    if args.verbose > 0:\r\n        pprint(saved_hyperparams)\r\n\r\n    n_envs = hyperparams.get('n_envs', 1)\r\n\r\n    if args.verbose > 0:\r\n        print(\"Using {} environments\".format(n_envs))\r\n\r\n    # Create learning rate schedules for ppo2 and sac\r\n    if algo_ in [\"ppo2\", \"sac\", \"td3\"]:\r\n        for key in ['learning_rate', 'cliprange', 'cliprange_vf']:\r\n            if key not in hyperparams:\r\n                continue\r\n            if isinstance(hyperparams[key], str):\r\n                schedule, initial_value = hyperparams[key].split('_')\r\n                initial_value = float(initial_value)\r\n                hyperparams[key] = linear_schedule(initial_value)\r\n            elif isinstance(hyperparams[key], (float, int)):\r\n                # Negative value: ignore (ex: for clipping)\r\n                if hyperparams[key] < 0:\r\n                    continue\r\n                hyperparams[key] = constfn(float(hyperparams[key]))\r\n            else:\r\n                raise ValueError('Invalid value for {}: {}'.format(key, hyperparams[key]))\r\n\r\n    # Should we overwrite the number of timesteps?\r\n    if args.n_timesteps > 0:\r\n        if args.verbose:\r\n            print(\"Overwriting n_timesteps with n={}\".format(args.n_timesteps))\r\n        n_timesteps = args.n_timesteps\r\n    else:\r\n        n_timesteps = int(hyperparams['n_timesteps'])\r\n\r\n    normalize = False\r\n    normalize_kwargs = {}\r\n    if 'normalize' in hyperparams.keys():\r\n        normalize = hyperparams['normalize']\r\n        if isinstance(normalize, str):\r\n            normalize_kwargs = eval(normalize)\r\n            normalize = True\r\n        del hyperparams['normalize']\r\n\r\n    # Convert to python object if needed\r\n    if 'policy_kwargs' in hyperparams.keys() and isinstance(hyperparams['policy_kwargs'], str):\r\n        hyperparams['policy_kwargs'] = eval(hyperparams['policy_kwargs'])\r\n\r\n    # Delete keys so the dict can be pass to the model constructor\r\n    if 'n_envs' in hyperparams.keys():\r\n        del hyperparams['n_envs']\r\n    del hyperparams['n_timesteps']\r\n\r\n    # obtain a class object from a wrapper name string in hyperparams\r\n    # and delete the entry\r\n    env_wrapper = get_wrapper_class(hyperparams)\r\n    if 'env_wrapper' in hyperparams.keys():\r\n        del hyperparams['env_wrapper']\r\n\r\n    log_path = \"{}/{}/\".format(args.log_folder, args.algo)\r\n    save_path = os.path.join(log_path, \"{}_{}{}\".format(env_id, get_latest_run_id(log_path, env_id) + 1, uuid_str))\r\n    params_path = \"{}/{}\".format(save_path, env_id)\r\n    os.makedirs(params_path, exist_ok=True)\r\n\r\n    callbacks = []\r\n    if args.save_freq > 0:\r\n        # Account for the number of parallel environments\r\n        args.save_freq = max(args.save_freq // n_envs, 1)\r\n        callbacks.append(CheckpointCallback(save_freq=args.save_freq,\r\n                                            save_path=save_path, name_prefix='rl_model', verbose=1))\r\n\r\n    env_kwargs = {} if args.env_kwargs is None else args.env_kwargs\r\n\r\n    def create_env(n_envs, eval_env=False):\r\n        \"\"\"\r\n        Create the environment and wrap it if necessary\r\n        :param n_envs: (int)\r\n        :param eval_env: (bool) Whether is it an environment used for evaluation or not\r\n        :return: (Union[gym.Env, VecEnv])\r\n        :return: (gym.Env)\r\n        \"\"\"\r\n        global hyperparams\r\n        global env_kwargs\r\n\r\n        # Do not log eval env (issue with writing the same file)\r\n        log_dir = None if eval_env else save_path\r\n\r\n        if is_atari:\r\n            if args.verbose > 0:\r\n                print(\"Using Atari wrapper\")\r\n            env = make_atari_env(env_id, num_env=n_envs, seed=args.seed)\r\n            # Frame-stacking with 4 frames\r\n            env = VecFrameStack(env, n_stack=4)\r\n        elif algo_ in ['dqn', 'ddpg']:\r\n            if hyperparams.get('normalize', False):\r\n                print(\"WARNING: normalization not supported yet for DDPG/DQN\")\r\n            env = gym.make(env_id, **env_kwargs)\r\n            env.seed(args.seed)\r\n            if env_wrapper is not None:\r\n                env = env_wrapper(env)\r\n        else:\r\n            if n_envs == 1:\r\n                env = DummyVecEnv([make_env(env_id, 0, args.seed, wrapper_class=env_wrapper, log_dir=log_dir, env_kwargs=env_kwargs)])\r\n            else:\r\n                # env = SubprocVecEnv([make_env(env_id, i, args.seed) for i in range(n_envs)])\r\n                # On most env, SubprocVecEnv does not help and is quite memory hungry\r\n                env = DummyVecEnv([make_env(env_id, i, args.seed, log_dir=log_dir,\r\n                                            wrapper_class=env_wrapper, env_kwargs=env_kwargs) for i in range(n_envs)])\r\n            if normalize:\r\n                if args.verbose > 0:\r\n                    if len(normalize_kwargs) > 0:\r\n                        print(\"Normalization activated: {}\".format(normalize_kwargs))\r\n                    else:\r\n                        print(\"Normalizing input and reward\")\r\n                env = VecNormalize(env, **normalize_kwargs)\r\n        # Optional Frame-stacking\r\n        if hyperparams.get('frame_stack', False):\r\n            n_stack = hyperparams['frame_stack']\r\n            env = VecFrameStack(env, n_stack)\r\n            print(\"Stacking {} frames\".format(n_stack))\r\n            del hyperparams['frame_stack']\r\n        if args.algo == 'her':\r\n            # Wrap the env if need to flatten the dict obs\r\n            if isinstance(env, VecEnv):\r\n                env = _UnvecWrapper(env)\r\n            env = HERGoalEnvWrapper(env)\r\n        return env\r\n\r\n\r\n    env = create_env(n_envs)\r\n    # Create test env if needed, do not normalize reward\r\n    eval_env = None\r\n    if args.eval_freq > 0:\r\n        # Account for the number of parallel environments\r\n        args.eval_freq = max(args.eval_freq // n_envs, 1)\r\n\r\n        # Do not normalize the rewards of the eval env\r\n        old_kwargs = None\r\n        if normalize:\r\n            if len(normalize_kwargs) > 0:\r\n                old_kwargs = normalize_kwargs.copy()\r\n                normalize_kwargs['norm_reward'] = False\r\n            else:\r\n                normalize_kwargs = {'norm_reward': False}\r\n\r\n        if args.verbose > 0:\r\n            print(\"Creating test environment\")\r\n\r\n        save_vec_normalize = SaveVecNormalizeCallback(save_freq=1, save_path=params_path)\r\n        eval_callback = EvalCallback(create_env(1, eval_env=True), callback_on_new_best=save_vec_normalize,\r\n                                     best_model_save_path=save_path, n_eval_episodes=args.eval_episodes,\r\n                                     log_path=save_path, eval_freq=args.eval_freq)\r\n        callbacks.append(eval_callback)\r\n\r\n        # Restore original kwargs\r\n        if old_kwargs is not None:\r\n            normalize_kwargs = old_kwargs.copy()\r\n\r\n\r\n    # Stop env processes to free memory\r\n    if args.optimize_hyperparameters and n_envs > 1:\r\n        env.close()\r\n\r\n    # Parse noise string for DDPG and SAC\r\n    if algo_ in ['ddpg', 'sac', 'td3'] and hyperparams.get('noise_type') is not None:\r\n        noise_type = hyperparams['noise_type'].strip()\r\n        noise_std = hyperparams['noise_std']\r\n        n_actions = env.action_space.shape[0]\r\n        if 'adaptive-param' in noise_type:\r\n            assert algo_ == 'ddpg', 'Parameter is not supported by SAC'\r\n            hyperparams['param_noise'] = AdaptiveParamNoiseSpec(initial_stddev=noise_std,\r\n                                                                desired_action_stddev=noise_std)\r\n        elif 'normal' in noise_type:\r\n            if 'lin' in noise_type:\r\n                hyperparams['action_noise'] = LinearNormalActionNoise(mean=np.zeros(n_actions),\r\n                                                                      sigma=noise_std * np.ones(n_actions),\r\n                                                                      final_sigma=hyperparams.get('noise_std_final', 0.0) * np.ones(n_actions),\r\n                                                                      max_steps=n_timesteps)\r\n            else:\r\n                hyperparams['action_noise'] = NormalActionNoise(mean=np.zeros(n_actions),\r\n                                                                sigma=noise_std * np.ones(n_actions))\r\n        elif 'ornstein-uhlenbeck' in noise_type:\r\n            hyperparams['action_noise'] = OrnsteinUhlenbeckActionNoise(mean=np.zeros(n_actions),\r\n                                                                       sigma=noise_std * np.ones(n_actions))\r\n        else:\r\n            raise RuntimeError('Unknown noise type \"{}\"'.format(noise_type))\r\n        print(\"Applying {} noise with std {}\".format(noise_type, noise_std))\r\n        del hyperparams['noise_type']\r\n        del hyperparams['noise_std']\r\n        if 'noise_std_final' in hyperparams:\r\n            del hyperparams['noise_std_final']\r\n\r\n    if ALGOS[args.algo] is None:\r\n        raise ValueError('{} requires MPI to be installed'.format(args.algo))\r\n\r\n    if os.path.isfile(args.trained_agent):\r\n        # Continue training\r\n        print(\"Loading pretrained agent\")\r\n        # Policy should not be changed\r\n        del hyperparams['policy']\r\n\r\n        model = ALGOS[args.algo].load(args.trained_agent, env=env,\r\n                                      tensorboard_log=tensorboard_log, verbose=args.verbose, **hyperparams)\r\n\r\n        exp_folder = args.trained_agent[:-4]\r\n        if normalize:\r\n            print(\"Loading saved running average\")\r\n            stats_path = os.path.join(exp_folder, env_id)\r\n            if os.path.exists(os.path.join(stats_path, 'vecnormalize.pkl')):\r\n                env = VecNormalize.load(os.path.join(stats_path, 'vecnormalize.pkl'), env)\r\n            else:\r\n                # Legacy:\r\n                env.load_running_average(exp_folder)\r\n\r\n    elif args.optimize_hyperparameters:\r\n\r\n        if args.verbose > 0:\r\n            print(\"Optimizing hyperparameters\")\r\n\r\n        def create_model(*_args, **kwargs):\r\n            \"\"\"\r\n            Helper to create a model with different hyperparameters\r\n            \"\"\"\r\n            return ALGOS[args.algo](env=create_env(n_envs), tensorboard_log=tensorboard_log,\r\n                                    verbose=0, **kwargs)\r\n\r\n        data_frame = hyperparam_optimization(args.algo, create_model, create_env, n_trials=args.n_trials,\r\n                                             n_timesteps=n_timesteps, hyperparams=hyperparams,\r\n                                             n_jobs=args.n_jobs, seed=args.seed,\r\n                                             sampler_method=args.sampler, pruner_method=args.pruner,\r\n                                             verbose=args.verbose)\r\n\r\n        report_name = \"report_{}_{}-trials-{}-{}-{}_{}.csv\".format(env_id, args.n_trials, n_timesteps,\r\n                                                                args.sampler, args.pruner, int(time.time()))\r\n\r\n        log_path = os.path.join(args.log_folder, args.algo, report_name)\r\n\r\n        if args.verbose:\r\n            print(\"Writing report to {}\".format(log_path))\r\n\r\n        os.makedirs(os.path.dirname(log_path), exist_ok=True)\r\n        data_frame.to_csv(log_path)\r\n        exit()\r\n    else:\r\n        # Train an agent from scratch\r\n        model = ALGOS[args.algo](env=env, tensorboard_log=tensorboard_log, verbose=args.verbose, **hyperparams)\r\n\r\n    kwargs = {}\r\n    if args.log_interval > -1:\r\n        kwargs = {'log_interval': args.log_interval}\r\n\r\n    if len(callbacks) > 0:\r\n        kwargs['callback'] = callbacks\r\n\r\n    # Save hyperparams\r\n    with open(os.path.join(params_path, 'config.yml'), 'w') as f:\r\n        yaml.dump(saved_hyperparams, f)\r\n\r\n    print(\"Log path: {}\".format(save_path))\r\n\r\n    try:\r\n        model.learn(n_timesteps, **kwargs)\r\n    except KeyboardInterrupt:\r\n        pass\r\n\r\n    # Only save worker of rank 0 when using mpi\r\n    if rank == 0:\r\n        print(\"Saving to {}\".format(save_path))\r\n\r\n        model.save(\"{}/{}\".format(save_path, env_id))\r\n\r\n    if normalize:\r\n        # Important: save the running average, for testing the agent we need that normalization\r\n        model.get_vec_normalize_env().save(os.path.join(params_path, 'vecnormalize.pkl'))\r\n        # Deprecated saving:\r\n        # env.save_running_average(params_path)\r\n\r\n```\r\nThe error:  \r\n\r\n```                                                                                                                             \r\n(pioneer) \r\nC:\\Users\\meric\\OneDrive\\Masaüstü\\TUM\\Thesis\\Code\\Zoo\\rl-baselines-zoo>python train.py --algo ppo2 --env PendulumIMG-v0 -n 50000 -optimize --n-trials 100 --n-jobs 2 --sampler random --pruner median\r\n                                            \r\n2020-08-24 16:48:55.212835: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll\r\n                                                                                                          \r\nWARNING:tensorflow: The TensorFlow contrib module will not be included in TensorFlow 2.0.                                                        For more information, please see:                                                                                              \r\n* https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md                                        \r\n* https://github.com/tensorflow/addons                                                                                       \r\n* https://github.com/tensorflow/io (for I/O related ops)                                                                   \r\nIf you depend on functionality not listed there, please file an issue.                                                                                                                                                                                    WARNING:tensorflow:From C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\stable_baselines\\common\\misc_util.py:26: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.                                                                                                                                                                   ========== PendulumIMG-v0 ==========                                                                                         \r\nSeed: 0                                                                                                                      \r\nOrderedDict([('cliprange', 0.2),                                                                                                          \r\n('ent_coef', 0.0),                                                                                                           \r\n('gamma', 0.99),                                                                                                             \r\n('lam', 0.95),                                                                                                               \r\n('learning_rate', 0.0003),                                                                                                   \r\n('n_steps', 2048),                                                                                                           \r\n('n_timesteps', 2000000.0),                                                                                                  \r\n('nminibatches', 32),                                                                                                        \r\n('noptepochs', 10),                                                                                                          \r\n('policy', 'MlpPolicy')])                                                                                       \r\nUsing 1 environments                                                                                                         \r\nOverwriting n_timesteps with n=50000                                                                                         \r\nCreating test environment                                                                                                    \r\nOptimizing hyperparameters                                                                                                   \r\nSampler: random - Pruner: median                                                                                             \r\nWARNING:tensorflow:From C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\stable_baselines\\common\\tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.                                                                                                                                                                            WARNING:tensorflow:From C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\stable_baselines\\common\\tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.                                                                                                                                                                                    2020-08-24 16:48:58.804156: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2                                                                                 \r\n2020-08-24 16:48:58.808697: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll                                                                                                                \r\n2020-08-24 16:48:59.234388: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties:         name: GeForce GTX 1050 major: 6 minor: 1 memoryClockRate(GHz): 1.493                                                         \r\npciBusID: 0000:01:00.0                                                                                                       \r\n2020-08-24 16:48:59.234620: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll                                                                                                          \r\n2020-08-24 16:48:59.239386: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll                                                                                                          \r\n2020-08-24 16:48:59.243933: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll                                                                                                           \r\n2020-08-24 16:48:59.246060: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll                                                                                                          \r\n2020-08-24 16:48:59.250758: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll                                                                                                        \r\n2020-08-24 16:48:59.253638: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll                                                                                                        \r\n2020-08-24 16:48:59.263978: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll                                                                                                             \r\n2020-08-24 16:48:59.264324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0           2020-08-24 16:48:59.909666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:                                                                                                      \r\n2020-08-24 16:48:59.910059: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0                                  \r\n2020-08-24 16:48:59.911490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N                                  \r\n2020-08-24 16:48:59.912589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3001 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1)                                                                                               \r\n2020-08-24 16:48:59.914510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties:         name: GeForce GTX 1050 major: 6 minor: 1 memoryClockRate(GHz): 1.493                                                         \r\npciBusID: 0000:01:00.0                                                                                                       \r\n2020-08-24 16:48:59.914730: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll                                                                                                          \r\n2020-08-24 16:48:59.915234: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll                                                                                                          \r\n2020-08-24 16:48:59.915871: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll                                                                                                           \r\n2020-08-24 16:48:59.916369: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll                                                                                                          \r\n2020-08-24 16:48:59.917129: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll                                                                                                        \r\n2020-08-24 16:48:59.917621: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll                                                                                                        \r\n2020-08-24 16:48:59.918279: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll                                                                                                             \r\n2020-08-24 16:48:59.918792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0           2020-08-24 16:48:59.919268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:                                                                                                      \r\n2020-08-24 16:48:59.919664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0                                  \r\n2020-08-24 16:48:59.920011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N                                  \r\n2020-08-24 16:48:59.920561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3001 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1)                                                                                               WARNING:tensorflow:From C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\stable_baselines\\common\\policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.                                                                                                                                                                     WARNING:tensorflow:From C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\stable_baselines\\common\\input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.                                                                                                                                                                               WARNING:tensorflow:From C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\stable_baselines\\common\\policies.py:561: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.                              \r\nInstructions for updating:                                                                                                   \r\nUse keras.layers.flatten instead.                                                                                            \r\nWARNING:tensorflow:From C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\tensorflow_core\\python\\layers\\core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.            \r\nInstructions for updating:                                                                                                   \r\nPlease use `layer.__call__` method instead.                                                                                  \r\nWARNING:tensorflow:From C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\stable_baselines\\common\\tf_layers.py:123: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.                                                                                                                                                                        WARNING:tensorflow:From C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\stable_baselines\\common\\distributions.py:418: The name tf.random_normal is deprecated. Please use tf.random.normal instead.                                                                                                                                                                            WARNING:tensorflow:From C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\stable_baselines\\ppo2\\ppo2.py:190: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.                                                                                                                                                                           WARNING:tensorflow:From C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\stable_baselines\\ppo2\\ppo2.py:198: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.                                                                                                                                                                 WARNING:tensorflow:From C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.                         \r\nInstructions for updating:                                                                                                   Use tf.where in 2.0, which has the same broadcast rule as np.where                                                           WARNING:tensorflow:From C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\stable_baselines\\ppo2\\ppo2.py:206: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.                                                                                                                                                                 WARNING:tensorflow:From C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\stable_baselines\\ppo2\\ppo2.py:240: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.                                                                                                                                               WARNING:tensorflow:From C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\stable_baselines\\ppo2\\ppo2.py:242: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.                                                                                                                                                                     [W 2020-08-24 16:49:01,386] Setting status of trial#0 as TrialState.FAIL because of the following error: MissingFunctionException('wglChoosePixelFormatARB is not exported by the available OpenGL driver.  ARB_pixel_format is required for this functionality.')                                                                                                                     \r\nTraceback (most recent call last):                                                                                             \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\optuna\\study.py\", line 734, in _run_trial                        \r\nresult = func(trial)                                                                                                       \r\nFile \"C:\\Users\\meric\\OneDrive\\Masaüstü\\TUM\\Thesis\\Code\\Zoo\\rl-baselines-zoo\\utils\\hyperparams_opt.py\", line 108, in objective                                                                                                                               \r\nmodel.learn(n_timesteps, callback=eval_callback)                                                                           \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\stable_baselines\\ppo2\\ppo2.py\", line 336, in learn               rollout = self.runner.run(callback)                                                                                        \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\stable_baselines\\common\\base_class.py\", line 794, in runner      self._runner = self._make_runner()                                                                                         \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\stable_baselines\\ppo2\\ppo2.py\", line 101, in _make_runner        gamma=self.gamma, lam=self.lam)                                                                                            \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\stable_baselines\\ppo2\\ppo2.py\", line 449, in __init__            super().__init__(env=env, model=model, n_steps=n_steps)                                                                    \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\stable_baselines\\common\\runners.py\", line 31, in __init__        self.obs[:] = env.reset()                                                                                                  \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\stable_baselines\\common\\vec_env\\dummy_vec_env.py\", line 61, in reset                                                                                                                          \r\nobs = self.envs[env_idx].reset()                                                                                           \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\stable_baselines\\bench\\monitor.py\", line 80, in reset            return self.env.reset(**kwargs)                                                                                            \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\gym\\wrappers\\time_limit.py\", line 25, in reset                   \r\nreturn self.env.reset(**kwargs)                                                                                            \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\gym\\envs\\classic_control\\pendulum_IMG.py\", line 84, in reset     return self._get_obs()                                                                                                     \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\gym\\envs\\classic_control\\pendulum_IMG.py\", line 88, in _get_obs                                                                                                                               \r\nimg = self.render('rgb_array')                                                                                             \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\gym\\envs\\classic_control\\pendulum_IMG.py\", line 100, in render                                                                                                                                self.viewer = rendering.Viewer(50, 50)                                                                                     \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 70, in __init__     self.window = get_window(width=width, height=height, display=display)                                                      \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 59, in get_window                                                                                                                                config = screen[0].get_best_config() #selecting the first screen                                                           \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\pyglet\\canvas\\base.py\", line 187, in get_best_config             configs = self.get_matching_configs(template_config)                                                                       \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\pyglet\\canvas\\win32.py\", line 69, in get_matching_configs        configs = template.match(canvas)                                                                                           \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\pyglet\\gl\\win32.py\", line 57, in match                           \r\nreturn self._get_arb_pixel_format_matching_configs(canvas)                                                                 \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\pyglet\\gl\\win32.py\", line 128, in _get_arb_pixel_format_matching_configs                                                                                                                      wglext_arb.wglChoosePixelFormatARB(canvas.hdc, attrs, None, nformats, pformats, nformats)                                  \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\pyglet\\gl\\lib_wgl.py\", line 103, in __call__                     \r\nreturn self.func(*args, **kwargs)                                                                                          \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\pyglet\\gl\\lib.py\", line 60, in MissingFunction                   \r\nraise MissingFunctionException(name, requires, suggestions)                                                              pyglet.gl.lib.MissingFunctionException: wglChoosePixelFormatARB is not exported by the available OpenGL driver.  ARB_pixel_format is required for this functionality.                                                                                     \r\n2020-08-24 16:49:01.467203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties:         name: GeForce GTX 1050 major: 6 minor: 1 memoryClockRate(GHz): 1.493                                                         \r\npciBusID: 0000:01:00.0                                                                                                       \r\n2020-08-24 16:49:01.467503: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll                                                                                                          \r\n2020-08-24 16:49:01.469300: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll                                                                                                          \r\n2020-08-24 16:49:01.470278: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll                                                                                                           \r\n2020-08-24 16:49:01.472895: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll                                                                                                          \r\n2020-08-24 16:49:01.476622: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll                                                                                                        \r\n2020-08-24 16:49:01.478698: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll                                                                                                        \r\n2020-08-24 16:49:01.479360: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll                                                                                                             \r\n2020-08-24 16:49:01.480079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0           2020-08-24 16:49:01.480605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:                                                                                                      \r\n2020-08-24 16:49:01.481265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0                                  \r\n2020-08-24 16:49:01.481671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N                                  \r\n2020-08-24 16:49:01.482168: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3001 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1)                                                                                               \r\nTraceback (most recent call last):                                                                                             \r\nFile \"train.py\", line 385, in <module>                                                                                         \r\nverbose=args.verbose)                                                                                                      \r\nFile \"C:\\Users\\meric\\OneDrive\\Masaüstü\\TUM\\Thesis\\Code\\Zoo\\rl-baselines-zoo\\utils\\hyperparams_opt.py\", line 130, in hyperparam_optimization                                                                                                                 \r\nstudy.optimize(objective, n_trials=n_trials, n_jobs=n_jobs)                                                                \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\optuna\\study.py\", line 382, in optimize                          \r\nfor _ in _iter                                                                                                             \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\joblib\\parallel.py\", line 1042, in __call__                      self.retrieve()                                                                                                            \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\joblib\\parallel.py\", line 921, in retrieve                       self._output.extend(job.get(timeout=self.timeout))                                                                         \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\multiprocessing\\pool.py\", line 657, in get                                     \r\nraise self._value                                                                                                          \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\multiprocessing\\pool.py\", line 121, in worker                                  \r\nresult = (True, func(*args, **kwds))                                                                                       \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__             \r\nreturn self.func(*args, **kwargs)                                                                                          \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\joblib\\parallel.py\", line 253, in __call__                       \r\nfor func, args, kwargs in self.items]                                                                                      \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\joblib\\parallel.py\", line 253, in <listcomp>                     \r\nfor func, args, kwargs in self.items]                                                                                      \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\optuna\\study.py\", line 648, in _reseed_and_optimize_sequential                                                                                                                                func, n_trials, timeout, catch, callbacks, gc_after_trial, time_start                                                      \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\optuna\\study.py\", line 682, in _optimize_sequential              self._run_trial_and_callbacks(func, catch, callbacks, gc_after_trial)                                                      \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\optuna\\study.py\", line 713, in _run_trial_and_callbacks          \r\ntrial = self._run_trial(func, catch, gc_after_trial)                                                                       \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\optuna\\study.py\", line 734, in _run_trial                        \r\nresult = func(trial)                                                                                                       \r\nFile \"C:\\Users\\meric\\OneDrive\\Masaüstü\\TUM\\Thesis\\Code\\Zoo\\rl-baselines-zoo\\utils\\hyperparams_opt.py\", line 108, in objective                                                                                                                               \r\nmodel.learn(n_timesteps, callback=eval_callback)                                                                           \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\stable_baselines\\ppo2\\ppo2.py\", line 336, in learn               rollout = self.runner.run(callback)                                                                                        \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\stable_baselines\\common\\base_class.py\", line 794, in runner      self._runner = self._make_runner()                                                                                         \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\stable_baselines\\ppo2\\ppo2.py\", line 101, in _make_runner        gamma=self.gamma, lam=self.lam)                                                                                            \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\stable_baselines\\ppo2\\ppo2.py\", line 449, in __init__            super().__init__(env=env, model=model, n_steps=n_steps)                                                                  \r\n2020-08-24 16:49:01.655738: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll                                                                                                            \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\stable_baselines\\common\\runners.py\", line 31, in __init__        self.obs[:] = env.reset()                                                                                                  \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\stable_baselines\\common\\vec_env\\dummy_vec_env.py\", line 61, in reset                                                                                                                          \r\nobs = self.envs[env_idx].reset()                                                                                           \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\stable_baselines\\bench\\monitor.py\", line 80, in reset            return self.env.reset(**kwargs)                                                                                            \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\gym\\wrappers\\time_limit.py\", line 25, in reset                   \r\nreturn self.env.reset(**kwargs)                                                                                            \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\gym\\envs\\classic_control\\pendulum_IMG.py\", line 84, in reset     return self._get_obs()                                                                                                     \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\gym\\envs\\classic_control\\pendulum_IMG.py\", line 88, in _get_obs                                                                                                                               \r\nimg = self.render('rgb_array')                                                                                             \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\gym\\envs\\classic_control\\pendulum_IMG.py\", line 100, in render                                                                                                                                self.viewer = rendering.Viewer(50, 50)                                                                                     \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 70, in __init__     self.window = get_window(width=width, height=height, display=display)                                                      \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 59, in get_window                                                                                                                                config = screen[0].get_best_config() #selecting the first screen                                                           \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\pyglet\\canvas\\base.py\", line 187, in get_best_config             configs = self.get_matching_configs(template_config)                                                                       \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\pyglet\\canvas\\win32.py\", line 69, in get_matching_configs        configs = template.match(canvas)                                                                                           \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\pyglet\\gl\\win32.py\", line 57, in match                           \r\nreturn self._get_arb_pixel_format_matching_configs(canvas)                                                                 \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\pyglet\\gl\\win32.py\", line 128, in _get_arb_pixel_format_matching_configs                                                                                                                      wglext_arb.wglChoosePixelFormatARB(canvas.hdc, attrs, None, nformats, pformats, nformats)                                  \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\pyglet\\gl\\lib_wgl.py\", line 103, in __call__                     \r\nreturn self.func(*args, **kwargs)                                                                                          \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\pyglet\\gl\\lib.py\", line 60, in MissingFunction                   \r\nraise MissingFunctionException(name, requires, suggestions)                                                              pyglet.gl.lib.MissingFunctionException: wglChoosePixelFormatARB is not exported by the available OpenGL driver.  ARB_pixel_format is required for this functionality.                                                                                     \r\nException ignored in: <function Viewer.__del__ at 0x0000021B8CE99318>                                                        \r\nTraceback (most recent call last):                                                                                             \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 162, in __del__   \r\nFile \"C:\\Users\\meric\\Anaconda3\\envs\\pioneer\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 81, in close    AttributeError: 'Viewer' object has no attribute 'window' \r\n```\r\n\r\n\r\nError 1:\r\n\r\n\r\nAny suggestion would be greatly appreciated!\r\n\r\n**System Info**\r\nDescribe the characteristic of your environment:\r\n * Describe how stable baselines was installed (pip, docker, source, ...): pip install stable-baselines[mpi]\r\n * GPU models and configuration: NVIDIA GTX 1050\r\n * Python version: 3.7\r\n * Tensorflow version: 1.15"},{"labels":["bug"],"text":"`LightGBMTunerCV.run()` got LightGBMError after updating `lightgbm` version==`3.0.0rc1`. \r\nWhile it's performing stepwise tuning, `lightgbm.basic` raised below error message at the step of `min_data_in_leaf` and tuning is interrupted. \r\nA workaround seems to be adding `feature_pre_filter=false` like following as the error message suggests:\r\n```\r\nparams = {\r\n    \"objective\": \"binary\",\r\n    \"metric\": \"binary_logloss\",\r\n    \"verbosity\": -1,\r\n    \"boosting_type\": \"gbdt\",\r\n    \"feature_pre_filter\": False,\r\n}\r\n``` \r\n## Environment\r\n\r\n- Optuna version: 2.0.0\r\n- Python version: 3.7\r\n- OS: linux/amd64 (Docker image: optuna/optuna:v2.0.0-py3.7)\r\n- Lightgbm version: 3.0.0rc\r\n\r\n## Error messages, stack traces, or logs\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/optuna/study.py\", line 709, in _run_trial\r\n    result = func(trial)\r\n  File \"/usr/local/lib/python3.6/dist-packages/optuna/integration/_lightgbm_tuner/optimize.py\", line 302, in __call__\r\n    cv_results = lgb.cv(self.lgbm_params, self.train_set, **self.lgbm_kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py\", line 554, in cv\r\n    train_set._update_params(params) \\\r\n  File \"/usr/local/lib/python3.6/dist-packages/lightgbm/basic.py\", line 1436, in _update_params\r\n    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\r\nlightgbm.basic.LightGBMError: Reducing `min_data_in_leaf` with `feature_pre_filter=true` may cause unexpected behaviour for features that were pre-filtered by the larger `min_data_in_leaf`.\r\nYou need to set `feature_pre_filter=false` to dynamically change the `min_data_in_leaf`.\r\n```\r\n\r\n## Steps to reproduce\r\n\r\n1. Update lightgbm to version==`3.0.0rc1`\r\n2. Execute the example code in https://github.com/optuna/optuna/blob/master/examples/lightgbm_tuner_cv.py\r\n3. The error occurs at \r\nhttps://github.com/optuna/optuna/blob/4680f36a470ffb9ead89abf65dcc7e7533fd789f/examples/lightgbm_tuner_cv.py#L24-L28"},{"labels":["bug",null],"text":"## Expected behavior\r\n\r\nWhen users specify training and validation folds in the manner that the basic lightgbm.cv function accepts, this should (from what I understand work)\r\n\r\n## Environment\r\n\r\n- Optuna version: 2.0.0\r\n- Python version: 3.6.9\r\n- OS: Google Collab/Linux\r\n- (Optional) Other libraries and their versions: LightGBM 2.3.1\r\n\r\n## Error messages, stack traces, or logs\r\n\r\n```\r\n0%|          | 0/7 [00:00<?, ?it/s]\r\nfeature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s][W 2020-08-24 15:41:09,973] Trial 0 failed because of the following error: ValueError('For early stopping, at least one dataset and eval metric is required for evaluation',)\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/optuna/study.py\", line 709, in _run_trial\r\n    result = func(trial)\r\n  File \"/usr/local/lib/python3.6/dist-packages/optuna/integration/_lightgbm_tuner/optimize.py\", line 302, in __call__\r\n    cv_results = lgb.cv(self.lgbm_params, self.train_set, **self.lgbm_kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py\", line 576, in cv\r\n    evaluation_result_list=res))\r\n  File \"/usr/local/lib/python3.6/dist-packages/lightgbm/callback.py\", line 221, in _callback\r\n    _init(env)\r\n  File \"/usr/local/lib/python3.6/dist-packages/lightgbm/callback.py\", line 191, in _init\r\n    raise ValueError('For early stopping, '\r\nValueError: For early stopping, at least one dataset and eval metric is required for evaluation\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-18-0ec8edbe946a> in <module>()\r\n      2                      label = np.array( data['target'] ).flatten())\r\n      3 tuner = lgb.LightGBMTunerCV(params, dtrain, verbose_eval=100, early_stopping_rounds=100, folds=folds)\r\n----> 4 tuner.run()\r\n\r\n10 frames\r\n/usr/local/lib/python3.6/dist-packages/lightgbm/callback.py in _init(env)\r\n    189             return\r\n    190         if not env.evaluation_result_list:\r\n--> 191             raise ValueError('For early stopping, '\r\n    192                              'at least one dataset and eval metric is required for evaluation')\r\n    193 \r\n\r\nValueError: For early stopping, at least one dataset and eval metric is required for evaluation\r\n```\r\n\r\nAs well as (on the second version without early stopping, which I think is an issue that's already reported in another issue?):\r\n```\r\n0%|          | 0/7 [00:00<?, ?it/s]\r\n\r\n\r\nfeature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s][W 2020-08-24 15:42:03,262] Trial 0 failed because of the following error: KeyError('l1-mean',)\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/optuna/study.py\", line 709, in _run_trial\r\n    result = func(trial)\r\n  File \"/usr/local/lib/python3.6/dist-packages/optuna/integration/_lightgbm_tuner/optimize.py\", line 304, in __call__\r\n    val_scores = self._get_cv_scores(cv_results)\r\n  File \"/usr/local/lib/python3.6/dist-packages/optuna/integration/_lightgbm_tuner/optimize.py\", line 294, in _get_cv_scores\r\n    val_scores = cv_results[\"{}-mean\".format(metric)]\r\nKeyError: 'l1-mean'\r\n---------------------------------------------------------------------------\r\nKeyError                                  Traceback (most recent call last)\r\n<ipython-input-21-942a30076787> in <module>()\r\n      1 tuner = lgb.LightGBMTunerCV(params, dtrain, verbose_eval=100, folds=folds)\r\n----> 2 tuner.run()\r\n\r\n8 frames\r\n/usr/local/lib/python3.6/dist-packages/optuna/integration/_lightgbm_tuner/optimize.py in _get_cv_scores(self, cv_results)\r\n    292 \r\n    293         metric = self._get_metric_for_objective()\r\n--> 294         val_scores = cv_results[\"{}-mean\".format(metric)]\r\n    295         return val_scores\r\n    296 \r\n\r\nKeyError: 'l1-mean'\r\n```\r\n## Steps to reproduce\r\n\r\n1. Get a Google Collab, then run the code below (extra installations beyond default collab explicitly via !pip below)\r\n\r\n## Reproducible examples (optional)\r\n\r\n```python\r\n!pip install lightgbm==2.3.1\r\nimport numpy as np\r\nimport pandas as pd\r\nfrom sklearn.model_selection import GroupKFold\r\n\r\nimport lightgbm as lgb\r\nlgb.__version__\r\nnp.random.seed(123)\r\ndata = pd.DataFrame({'var1': np.random.normal(loc=0, scale=1, size=100),\r\n                    'var2': np.random.normal(loc=0, scale=1, size=100),\r\n                    'var3': np.random.normal(loc=0, scale=1, size=100),\r\n                     'testfold': np.random.choice(a=np.repeat([x for x in range(5)], 20), size=100, replace=False)})\r\ndata['target'] = 7 + 0.1*data['var1'] + 1.0*data['var2'] + 5.0*data['var3'] - 2.0*data['var1']*data['var2'] + np.random.normal(loc=0, scale=0.5, size=100)\r\ndata.head()\r\nparams = {\r\n    'objective': 'l1',\r\n    'metric': 'l1',    \r\n    \"verbosity\": -1,\r\n    \"boosting_type\": \"gbdt\",\r\n    'seed': 1979\r\n    }\r\n\r\ndtrain = lgb.Dataset(data= np.array( data[ ['var1', 'var2', 'var3'] ] ),\r\n                     label = np.array( data['target'] ).flatten())\r\n\r\nfolds = GroupKFold().split(np.array( data[ ['var1', 'var2', 'var3'] ] ),\r\n                            np.array( data['target'] ).flatten(), \r\n                            np.array(data['testfold']).flatten())\r\nlgb.cv(params, dtrain, folds=folds, verbose_eval=100) # This is how base lightgbm does this, and it works fine\r\n\r\n\r\n!pip install optuna\r\nimport optuna.integration.lightgbm as lgb\r\n\r\ndtrain = lgb.Dataset(data= np.array( data[ ['var1', 'var2', 'var3'] ] ),\r\n                     label = np.array( data['target'] ).flatten())\r\ntuner = lgb.LightGBMTunerCV(params, dtrain, verbose_eval=100, early_stopping_rounds=100, folds=folds)\r\ntuner.run()\r\n\r\ntuner = lgb.LightGBMTunerCV(params, dtrain, verbose_eval=100, folds=folds)\r\ntuner.run()\r\n```\r\n\r\n## Additional context (optional)\r\n\r\nSame issue in Kaggle kernels, but thought it would be easier to share a simplified Collab example.\r\n"},{"labels":["bug",null],"text":"`max_iter` in `OptunaSearchCV` doesn't work with LightGBM because there's no `partial_fit`. [This](https://github.com/microsoft/LightGBM/issues/2718) could be a potential fix"},{"labels":["bug"],"text":"Use of CmaEsSampler throws an exception, \r\n`infer_relative_search_space is missing required positional argument: 'trial'`\r\n\r\n## Expected behavior\r\n\r\nBelow is code that contrasts use of CmaEsSampler vs. the default sampler\r\n\r\n## Environment\r\n\r\n- Optuna version: 2.0\r\n- Python version: 3.7.7\r\n- OS: MacOSX 10.15\r\n- (Optional) Other libraries and their versions:\r\n\r\n## Error messages, stack traces, or logs\r\n\r\n```\r\n[I 2020-08-17 09:23:18,345] A new study created with name: cmaesTst\r\nTraceback (most recent call last):\r\n  File \"/Users/Shared/Relocated Items/Security/Data/virtualenv/covasim/src/cmaesTst.py\", line 82, in <module>\r\n    study.optimize(op_objective, n_trials=20)\r\n  File \"/Users/Shared/Relocated Items/Security/Data/virtualenv/covasim/lib/python3.7/site-packages/optuna/study.py\", line 292, in optimize\r\n    func, n_trials, timeout, catch, callbacks, gc_after_trial, None\r\n  File \"/Users/Shared/Relocated Items/Security/Data/virtualenv/covasim/lib/python3.7/site-packages/optuna/study.py\", line 654, in _optimize_sequential\r\n    self._run_trial_and_callbacks(func, catch, callbacks, gc_after_trial)\r\n  File \"/Users/Shared/Relocated Items/Security/Data/virtualenv/covasim/lib/python3.7/site-packages/optuna/study.py\", line 685, in _run_trial_and_callbacks\r\n    trial = self._run_trial(func, catch, gc_after_trial)\r\n  File \"/Users/Shared/Relocated Items/Security/Data/virtualenv/covasim/lib/python3.7/site-packages/optuna/study.py\", line 705, in _run_trial\r\n    trial = trial_module.Trial(self, trial_id)\r\n  File \"/Users/Shared/Relocated Items/Security/Data/virtualenv/covasim/lib/python3.7/site-packages/optuna/trial/_trial.py\", line 65, in __init__\r\n    self._init_relative_params()\r\n  File \"/Users/Shared/Relocated Items/Security/Data/virtualenv/covasim/lib/python3.7/site-packages/optuna/trial/_trial.py\", line 74, in _init_relative_params\r\n    self.relative_search_space = self.study.sampler.infer_relative_search_space(study, trial)\r\nTypeError: infer_relative_search_space() missing 1 required positional argument: 'trial'\r\n```\r\n\r\n## Steps to reproduce\r\n\r\n1. Run code, observe error using CmaEsSampler\r\n2. Comment out call to `make_study()` using CmaEsSampler\r\n3. Un-comment line below using  call to `make_study()` with default sampler\r\n\r\n## Reproducible examples (optional)\r\n\r\n```python\r\nimport numpy as np\r\nimport optuna as op\r\nimport sciris as sc\r\n\r\nfrom optuna.samplers import CmaEsSampler\r\n\r\ndef objective(trial):\r\n\tx = trial[0]\r\n\ty = trial[1]\r\n\treturn x ** 2 + y\r\n\r\n\r\n\r\ndef op_objective(trial):\r\n\r\n\tSIMparam = dict(beta = dict(lb=0.003, ub=0.008),\r\n\t\t \t\t    pop_infected = dict(lb=1000,   ub=10000) )\r\n\r\n\tx = np.zeros(len(SIMparam))\r\n\tfor k,key in enumerate(SIMparam.keys()):\r\n\t\tlb = SIMparam[key]['lb']\r\n\t\tub = SIMparam[key]['ub']\r\n\t\tx[k] = trial.suggest_uniform(key, lb, ub )\r\n\r\n\treturn objective(x)\r\n\r\ndef make_study(storage,name,sampler=None):\r\n\ttry: \r\n\t\top.delete_study(storage=storage, study_name=name)\r\n\texcept: \r\n\t\tpass\r\n\tif sampler == None:\r\n\t\treturn op.create_study(storage=storage, study_name=name)\r\n\telse:\r\n\t\treturn op.create_study(storage=storage, study_name=name,sampler=sampler)\r\n\r\n\r\nif __name__ == '__main__':\r\n\t\r\n\tname = 'cmaesTst'\r\n\tstorage   = f'sqlite:///{name}.db'\r\n\tstudy = make_study(storage, 'cmaesTst', sampler=CmaEsSampler)\r\n\t# study = make_study(storage,'cmaesTst')\r\n\tstudy.optimize(op_objective, n_trials=20)\r\n```\r\n\r\n## Additional context (optional)\r\n\r\n<!-- Please add any other context or screenshots about the problem here. -->\r\n"},{"labels":["bug"],"text":"When using the optuna built in functions for visualization, most of them cause an Attribute Error, OR the few that do run will not show you the actual graphic. Instead they will just print the script to the terminal. This happens both when running it as a python script in the shell, or when using a python notebook. \r\n\r\n## Expected behavior\r\n\r\nAs shown on the optuna website, I would expect to see graphs when I pass my study object to the functions. \r\n(https://optuna.readthedocs.io/en/stable/reference/visualization.html)\r\n\r\n## Environment\r\n\r\n- Optuna version: 0.13.0\r\n- Python version: 3.6\r\n- OS: macOS Mojave v10.14.6 \r\n- (Optional) Other libraries and their versions: Python Plotly version 4.9.0\r\n\r\n## Error messages, stack traces, or logs\r\nThe following function (and most others of the visualization api don't run and cause an Attribute error)\r\n`visualization.plot_param_importances(study)\r\n`Traceback (most recent call last):\r\n\r\n  File \"<ipython-input-19-7f3a5f83c732>\", line 1, in <module>\r\n    visualization.plot_param_importances(study)\r\n\r\nAttributeError: module 'optuna.visualization' has no attribute 'plot_param_importances'\r\n```\r\n# error messages, stack traces, or logs\r\n```\r\n`optuna.visualization.plot_intermediate_values(study)`\r\nthrows does not throw an error. Instead it will print the script and not show a visual. The following output is obtained: \r\n`{'text/html': '        <script type=\"text/javascript\">\\n        window.PlotlyConfig = {MathJaxConfig: \\'local\\'};\\n        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\\n        if (typeof require !== \\'undefined\\') {\\n        require.undef(\"plotly\");\\n        requirejs.config({\\n            paths: {\\n                \\'plotly\\': [\\'https://cdn.plot.ly/plotly-latest.min\\']\\n            }\\n        });\\n        require([\\'plotly\\'], function(Plotly) {\\n            window._Plotly = Plotly;\\n        });\\n        }\\n        </script>\\n        '}\r\n{'application/vnd.plotly.v1+json': {'config': {'linkText': 'Export to plot.ly', 'plotlyServerURL': 'https://plot.ly', 'showLink': False}, 'data': [], 'layout': {'showlegend': False, 'template': {'data': {'bar': [{'error_x': {'color': '#2a3f5f'}, 'error_y': {'color': '#2a3f5f'}, 'marker': {'line': {'color': '#E5ECF6', 'width': 0.5}}, 'type': 'bar'}], 'barpolar': [{'marker': {'line': {'color': '#E5ECF6', 'width': 0.5}}, 'type': 'barpolar'}], 'carpet': [{'aaxis': {'endlinecolor': '#2a3f5f', 'gridcolor': 'white', 'linecolor': 'white', 'minorgridcolor': 'white', 'startlinecolor': '#2a3f5f'}, 'baxis': {'endlinecolor': '#2a3f5f', 'gridcolor': 'white', 'linecolor': 'white', 'minorgridcolor': 'white', 'startlinecolor': '#2a3f5f'}, 'type': 'carpet'}], 'choropleth': [{'colorbar': {'outlinewidth': 0, 'ticks': ''}, 'type': 'choropleth'}], 'contour': [{'colorbar': {'outlinewidth': 0, 'ticks': ''}, 'colorscale': [[0.0, '#0d0887'], [0.1111111111111111, '#46039f'], [0.2222222222222222, '#7201a8'], [0.3333333333333333, '#9c179e'], [0.4444444444444444, '#bd3786'], [0.5555555555555556, '#d8576b'], [0.6666666666666666, '#ed7953'], [0.7777777777777778, '#fb9f3a'], [0.8888888888888888, '#fdca26'], [1.0, '#f0f921']], 'type': 'contour'}], 'contourcarpet': [{'colorbar': {'outlinewidth': 0, 'ticks': ''}, 'type': 'contourcarpet'}], 'heatmap': [{'colorbar': {'outlinewidth': 0, 'ticks': ''}, 'colorscale': [[0.0, '#0d0887'], [0.1111111111111111, '#46039f'], [0.2222222222222222, '#7201a8'], [0.3333333333333333, '#9c179e'], [0.4444444444444444, '#bd3786'], [0.5555555555555556, '#d8576b'], [0.6666666666666666, '#ed7953'], [0.7777777777777778, '#fb9f3a'], [0.8888888888888888, '#fdca26'], [1.0, '#f0f921']], 'type': 'heatmap'}], 'heatmapgl': [{'colorbar': {'outlinewidth': 0, 'ticks': ''}, 'colorscale': [[0.0, '#0d0887'], [0.1111111111111111, '#46039f'], [0.2222222222222222, '#7201a8'], [0.3333333333333333, '#9c179e'], [0.4444444444444444, '#bd3786'], [0.5555555555555556, '#d8576b'], [0.6666666666666666, '#ed7953'], [0.7777777777777778, '#fb9f3a'], [0.8888888888888888, '#fdca26'], [1.0, '#f0f921']], 'type': 'heatmapgl'}], 'histogram': [{'marker': {'colorbar': {'outlinewidth': 0, 'ticks': ''}}, 'type': 'histogram'}], 'histogram2d': [{'colorbar': {'outlinewidth': 0, 'ticks': ''}, 'colorscale': [[0.0, '#0d0887'], [0.1111111111111111, '#46039f'], [0.2222222222222222, '#7201a8'], [0.3333333333333333, '#9c179e'], [0.4444444444444444, '#bd3786'], [0.5555555555555556, '#d8576b'], [0.6666666666666666, '#ed7953'], [0.7777777777777778, '#fb9f3a'], [0.8888888888888888, '#fdca26'], [1.0, '#f0f921']], 'type': 'histogram2d'}], 'histogram2dcontour': [{'colorbar': {'outlinewidth': 0, 'ticks': ''}, 'colorscale': [[0.0, '#0d0887'], [0.1111111111111111, '#46039f'], [0.2222222222222222, '#7201a8'], [0.3333333333333333, '#9c179e'], [0.4444444444444444, '#bd3786'], [0.5555555555555556, '#d8576b'], [0.6666666666666666, '#ed7953'], [0.7777777777777778, '#fb9f3a'], [0.8888888888888888, '#fdca26'], [1.0, '#f0f921']], 'type': 'histogram2dcontour'}], 'mesh3d': [{'colorbar': {'outlinewidth': 0, 'ticks': ''}, 'type': 'mesh3d'}], 'parcoords': [{'line': {'colorbar': {'outlinewidth': 0, 'ticks': ''}}, 'type': 'parcoords'}], 'pie': [{'automargin': True, 'type': 'pie'}], 'scatter': [{'marker': {'colorbar': {'outlinewidth': 0, 'ticks': ''}}, 'type': 'scatter'}], 'scatter3d': [{'line': {'colorbar': {'outlinewidth': 0, 'ticks': ''}}, 'marker': {'colorbar': {'outlinewidth': 0, 'ticks': ''}}, 'type': 'scatter3d'}], 'scattercarpet': [{'marker': {'colorbar': {'outlinewidth': 0, 'ticks': ''}}, 'type': 'scattercarpet'}], 'scattergeo': [{'marker': {'colorbar': {'outlinewidth': 0, 'ticks': ''}}, 'type': 'scattergeo'}], 'scattergl': [{'marker': {'colorbar': {'outlinewidth': 0, 'ticks': ''}}, 'type': 'scattergl'}], 'scattermapbox': [{'marker': {'colorbar': {'outlinewidth': 0, 'ticks': ''}}, 'type': 'scattermapbox'}], 'scatterpolar': [{'marker': {'colorbar': {'outlinewidth': 0, 'ticks': ''}}, 'type': 'scatterpolar'}], 'scatterpolargl': [{'marker': {'colorbar': {'outlinewidth': 0, 'ticks': ''}}, 'type': 'scatterpolargl'}], 'scatterternary': [{'marker': {'colorbar': {'outlinewidth': 0, 'ticks': ''}}, 'type': 'scatterternary'}], 'surface': [{'colorbar': {'outlinewidth': 0, 'ticks': ''}, 'colorscale': [[0.0, '#0d0887'], [0.1111111111111111, '#46039f'], [0.2222222222222222, '#7201a8'], [0.3333333333333333, '#9c179e'], [0.4444444444444444, '#bd3786'], [0.5555555555555556, '#d8576b'], [0.6666666666666666, '#ed7953'], [0.7777777777777778, '#fb9f3a'], [0.8888888888888888, '#fdca26'], [1.0, '#f0f921']], 'type': 'surface'}], 'table': [{'cells': {'fill': {'color': '#EBF0F8'}, 'line': {'color': 'white'}}, 'header': {'fill': {'color': '#C8D4E3'}, 'line': {'color': 'white'}}, 'type': 'table'}]}, 'layout': {'annotationdefaults': {'arrowcolor': '#2a3f5f', 'arrowhead': 0, 'arrowwidth': 1}, 'coloraxis': {'colorbar': {'outlinewidth': 0, 'ticks': ''}}, 'colorscale': {'diverging': [[0, '#8e0152'], [0.1, '#c51b7d'], [0.2, '#de77ae'], [0.3, '#f1b6da'], [0.4, '#fde0ef'], [0.5, '#f7f7f7'], [0.6, '#e6f5d0'], [0.7, '#b8e186'], [0.8, '#7fbc41'], [0.9, '#4d9221'], [1, '#276419']], 'sequential': [[0.0, '#0d0887'], [0.1111111111111111, '#46039f'], [0.2222222222222222, '#7201a8'], [0.3333333333333333, '#9c179e'], [0.4444444444444444, '#bd3786'], [0.5555555555555556, '#d8576b'], [0.6666666666666666, '#ed7953'], [0.7777777777777778, '#fb9f3a'], [0.8888888888888888, '#fdca26'], [1.0, '#f0f921']], 'sequentialminus': [[0.0, '#0d0887'], [0.1111111111111111, '#46039f'], [0.2222222222222222, '#7201a8'], [0.3333333333333333, '#9c179e'], [0.4444444444444444, '#bd3786'], [0.5555555555555556, '#d8576b'], [0.6666666666666666, '#ed7953'], [0.7777777777777778, '#fb9f3a'], [0.8888888888888888, '#fdca26'], [1.0, '#f0f921']]}, 'colorway': ['#636efa', '#EF553B', '#00cc96', '#ab63fa', '#FFA15A', '#19d3f3', '#FF6692', '#B6E880', '#FF97FF', '#FECB52'], 'font': {'color': '#2a3f5f'}, 'geo': {'bgcolor': 'white', 'lakecolor': 'white', 'landcolor': '#E5ECF6', 'showlakes': True, 'showland': True, 'subunitcolor': 'white'}, 'hoverlabel': {'align': 'left'}, 'hovermode': 'closest', 'mapbox': {'style': 'light'}, 'paper_bgcolor': 'white', 'plot_bgcolor': '#E5ECF6', 'polar': {'angularaxis': {'gridcolor': 'white', 'linecolor': 'white', 'ticks': ''}, 'bgcolor': '#E5ECF6', 'radialaxis': {'gridcolor': 'white', 'linecolor': 'white', 'ticks': ''}}, 'scene': {'xaxis': {'backgroundcolor': '#E5ECF6', 'gridcolor': 'white', 'gridwidth': 2, 'linecolor': 'white', 'showbackground': True, 'ticks': '', 'zerolinecolor': 'white'}, 'yaxis': {'backgroundcolor': '#E5ECF6', 'gridcolor': 'white', 'gridwidth': 2, 'linecolor': 'white', 'showbackground': True, 'ticks': '', 'zerolinecolor': 'white'}, 'zaxis': {'backgroundcolor': '#E5ECF6', 'gridcolor': 'white', 'gridwidth': 2, 'linecolor': 'white', 'showbackground': True, 'ticks': '', 'zerolinecolor': 'white'}}, 'shapedefaults': {'line': {'color': '#2a3f5f'}}, 'ternary': {'aaxis': {'gridcolor': 'white', 'linecolor': 'white', 'ticks': ''}, 'baxis': {'gridcolor': 'white', 'linecolor': 'white', 'ticks': ''}, 'bgcolor': '#E5ECF6', 'caxis': {'gridcolor': 'white', 'linecolor': 'white', 'ticks': ''}}, 'title': {'x': 0.05}, 'xaxis': {'automargin': True, 'gridcolor': 'white', 'linecolor': 'white', 'ticks': '', 'title': {'standoff': 15}, 'zerolinecolor': 'white', 'zerolinewidth': 2}, 'yaxis': {'automargin': True, 'gridcolor': 'white', 'linecolor': 'white', 'ticks': '', 'title': {'standoff': 15}, 'zerolinecolor': 'white', 'zerolinewidth': 2}}}}}, 'text/html': '<div>\\n        \\n        \\n            <div id=\"4a651fc8-efe1-4bfc-8a5e-523e6d703e62\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\\n            <script type=\"text/javascript\">\\n                require([\"plotly\"], function(Plotly) {\\n                    window.PLOTLYENV=window.PLOTLYENV || {};\\n                    \\n                if (document.getElementById(\"4a651fc8-efe1-4bfc-8a5e-523e6d703e62\")) {\\n                    Plotly.newPlot(\\n                        \\'4a651fc8-efe1-4bfc-8a5e-523e6d703e62\\',\\n                        [],\\n                        {\"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\\n                        {\"responsive\": true}\\n                    ).then(function(){\\n                            \\nvar gd = document.getElementById(\\'4a651fc8-efe1-4bfc-8a5e-523e6d703e62\\');\\nvar x = new MutationObserver(function (mutations, observer) {{\\n        var display = window.getComputedStyle(gd).display;\\n        if (!display || display === \\'none\\') {{\\n            console.log([gd, \\'removed!\\']);\\n            Plotly.purge(gd);\\n            observer.disconnect();\\n        }}\\n}});\\n\\n// Listen for the removal of the full notebook cells\\nvar notebookContainer = gd.closest(\\'#notebook-container\\');\\nif (notebookContainer) {{\\n    x.observe(notebookContainer, {childList: true});\\n}}\\n\\n// Listen for the clearing of the current output cell\\nvar outputEl = gd.closest(\\'.output\\');\\nif (outputEl) {{\\n    x.observe(outputEl, {childList: true});\\n}}\\n\\n                        })\\n                };\\n                });\\n            </script>\\n        </div>'}`\r\n## Steps to reproduce\r\n\r\n1. Create a study \r\n2. Run the experiment\r\n3. Try to visualize the study after running it with the above mentioned functions\r\n\r\n"},{"labels":["bug",null],"text":"<!-- Please write a clear and concise description of what the bug is. -->\r\n\r\nWhen use PercentilePruner, if all trails' step are small and a new trail's step may too big, then _get_percentile_intermediate_result_over_trials will return None. And raise RuntimeWarning: Mean of empty slice   return np.nanmean(a, axis, out=out, keepdims=keepdims).\r\n\r\n<!-- Please write a clear and concise description of what you expected to happen. -->\r\n\r\n## Environment\r\n\r\n- Optuna version:\r\n- Python version:\r\n- OS:\r\n- (Optional) Other libraries and their versions:\r\n\r\n## Error messages, stack traces, or logs\r\n\r\n```\r\n# error messages, stack traces, or logs\r\n```\r\n\r\n## Steps to reproduce\r\n\r\n1.\r\n2.\r\n3.\r\n\r\n## Reproducible examples (optional)\r\n\r\n```python\r\n# python code\r\n```\r\n\r\n## Additional context (optional)\r\n\r\n<!-- Please add any other context or screenshots about the problem here. -->\r\n"},{"labels":["bug",null],"text":"The script https://github.com/optuna/optuna/blob/master/examples/lightgbm_tuner_cv.py runs just fine as it is. However, I get a `KeyError: 'mse-mean'` if I change the `objective` to `regression` and `metric` to `mse`. Similar erro happens to other metrics as well when the `objective` is set to `regression`.\r\n\r\n## Environment\r\n\r\n- Optuna version: 2.0.0\r\n- Python version: 3.7\r\n- OS: MacOS Catalina\r\n\r\n## Error messages, stack traces, or logs\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nKeyError                                  Traceback (most recent call last)\r\n<ipython-input-11-7753103b8251> in <module>\r\n     15 )\r\n     16 \r\n---> 17 tuner.run()\r\n     18 \r\n     19 print(\"Best score:\", tuner.best_score)\r\n\r\n/usr/local/lib/python3.7/site-packages/optuna/integration/_lightgbm_tuner/optimize.py in run(self)\r\n    461         self.sample_train_set()\r\n    462 \r\n--> 463         self.tune_feature_fraction()\r\n    464         self.tune_num_leaves()\r\n    465         self.tune_bagging()\r\n\r\n/usr/local/lib/python3.7/site-packages/optuna/integration/_lightgbm_tuner/optimize.py in tune_feature_fraction(self, n_trials)\r\n    486 \r\n    487         sampler = optuna.samplers.GridSampler({param_name: param_values})\r\n--> 488         self._tune_params([param_name], len(param_values), sampler, \"feature_fraction\")\r\n    489 \r\n    490     def tune_num_leaves(self, n_trials: int = 20) -> None:\r\n\r\n/usr/local/lib/python3.7/site-packages/optuna/integration/_lightgbm_tuner/optimize.py in _tune_params(self, target_param_names, n_trials, sampler, step_name)\r\n    567                 timeout=_timeout,\r\n    568                 catch=(),\r\n--> 569                 callbacks=self._optuna_callbacks,\r\n    570             )\r\n    571 \r\n\r\n/usr/local/lib/python3.7/site-packages/optuna/study.py in optimize(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\r\n    290             if n_jobs == 1:\r\n    291                 self._optimize_sequential(\r\n--> 292                     func, n_trials, timeout, catch, callbacks, gc_after_trial, None\r\n    293                 )\r\n    294             else:\r\n\r\n/usr/local/lib/python3.7/site-packages/optuna/study.py in _optimize_sequential(self, func, n_trials, timeout, catch, callbacks, gc_after_trial, time_start)\r\n    652                     break\r\n    653 \r\n--> 654             self._run_trial_and_callbacks(func, catch, callbacks, gc_after_trial)\r\n    655 \r\n    656             self._progress_bar.update((datetime.datetime.now() - time_start).total_seconds())\r\n\r\n/usr/local/lib/python3.7/site-packages/optuna/study.py in _run_trial_and_callbacks(self, func, catch, callbacks, gc_after_trial)\r\n    683         # type: (...) -> None\r\n    684 \r\n--> 685         trial = self._run_trial(func, catch, gc_after_trial)\r\n    686         if callbacks is not None:\r\n    687             frozen_trial = copy.deepcopy(self._storage.get_trial(trial._trial_id))\r\n\r\n/usr/local/lib/python3.7/site-packages/optuna/study.py in _run_trial(self, func, catch, gc_after_trial)\r\n    707 \r\n    708         try:\r\n--> 709             result = func(trial)\r\n    710         except exceptions.TrialPruned as e:\r\n    711             message = \"Trial {} pruned. {}\".format(trial_number, str(e))\r\n\r\n/usr/local/lib/python3.7/site-packages/optuna/integration/_lightgbm_tuner/optimize.py in __call__(self, trial)\r\n    302         cv_results = lgb.cv(self.lgbm_params, self.train_set, **self.lgbm_kwargs)\r\n    303 \r\n--> 304         val_scores = self._get_cv_scores(cv_results)\r\n    305         val_score = val_scores[-1]\r\n    306         elapsed_secs = time.time() - start_time\r\n\r\n/usr/local/lib/python3.7/site-packages/optuna/integration/_lightgbm_tuner/optimize.py in _get_cv_scores(self, cv_results)\r\n    292 \r\n    293         metric = self._get_metric_for_objective()\r\n--> 294         val_scores = cv_results[\"{}-mean\".format(metric)]\r\n    295         return val_scores\r\n    296 \r\n\r\nKeyError: 'mse-mean'\r\n```\r\n\r\n## Steps to reproduce\r\n\r\n1. Run [this script](https://github.com/optuna/optuna/blob/master/examples/lightgbm_tuner_cv.py) with objective = regression and metric = mse. \r\n"},{"labels":["bug"],"text":"<!-- Please write a clear and concise description of what the bug is. -->\r\nCurrent ```setup.py``` does not specify the version of [packaging](https://pypi.org/project/packaging/).\r\nHowever, ```packaging.version.Version.major``` which is used in [_deprecated.py](https://github.com/optuna/optuna/blob/master/optuna/_deprecated.py#L39) was introduced in version 20.0.\r\n\r\nc.f.)\r\nhttps://github.com/pypa/packaging/blob/19.2/packaging/version.py\r\nhttps://github.com/pypa/packaging/blob/20.0/packaging/version.py\r\n\r\nThis caused an error ```AttributeError: 'Version' object has no attribute 'major'``` when we call ```study.optimize``` if pacakaging is older than 20.0.\r\n\r\n## Expected behavior\r\n```study.optimize``` runs without aforementioned error. ([Gist](https://gist.github.com/Isa-rentacs/8aeb0b3506b2f72dd204c93380b377ce))\r\n<!-- Please write a clear and concise description of what you expected to happen. -->\r\n\r\n## Environment\r\n- Optuna version: 2.0.0\r\n- Python version: 3.7\r\n- OS: Ubuntu 18.04\r\n- (Optional) Other libraries and their versions:\r\n  * packaging == 19.2\r\n  * lightgbm == 2.2.3\r\n\r\n## Error messages, stack traces, or logs\r\nGist with reproduce steps and error logs is [here](https://gist.github.com/Isa-rentacs/2151551016245cfae0a7ca92c868681e)\r\n\r\n## Steps to reproduce\r\n1. Install ```packaging``` == 19.2\r\n2. Setup ```study``` that uses LightGBM \r\n3. Call ```optimize```\r\n"},{"labels":["bug",null],"text":"<!-- Please write a clear and concise description of what the bug is. -->\r\nAll my parameters are using trial.suggest_int.\r\nTried optuna.samplers.CmaEsSampler but performance really bad. Many parameters used RandomSampler and objective score, R2 was very low and seemed static, R2 = 0.30\r\nTried optuna.integration.CmaEsSampler and performance was slightly better, R2 = 0.58 - 0.60 but also many parameters was sampled using RandomSampler.\r\nThe same study using TPESampler gives R2 = 0.749, no problems.\r\n\r\nSome representative codes:\r\n\r\ndef objective (trial):\r\n    params_list =[]\r\n    n_params = trial.suggest_int('n_params', 3, 5)\r\n    param1 = trial.suggest_int('param1', 0, 1200)\r\n    param2 = trial.suggest_int('param2', 0, 1199)\r\n    params_list.append(param1)\r\n    params_list.append(param2) \r\n    if n_params >=3: \r\n            param3 = trial.suggest_int('param3', 0, 1198)\r\n            params_list.append(param3)\r\n    if n_params >=4:\r\n            param4 = trial.suggest_int('param4', 0, 1197)\r\n            params_list.append(param4)\r\n   if n_params >=5:\r\n          param5 = trial.suggest_int('param5', 0, 1196)\r\n          params_list.append(param5)\r\n    model = model(params_list)\r\n    score = model.evaluate(x_test, y_test)   # R2 score\r\n    return score\r\n \r\nstudy = optuna.create_study(direction='maximize', sampler=optuna.samplers.CmaEsSampler)\r\nstudy.optimize(objective, n_trials=10000, n_jobs=-1)\r\n\r\nI have noticed that **RandomSampler is always used on params 3, 4, 5 i.e. those that were in the conditional if statements.** \r\n\r\n<!-- Please write a clear and concise description of what you expected to happen. -->\r\n\r\nI expect performance to be comparable to TPESampler and sampling is done using the CmaEsSampler.\r\n\r\n## Environment\r\n\r\n- Optuna version: 2.0\r\n- Python version: 3.7\r\n- OS: win10 64-bit\r\n- (Optional) Other libraries and their versions: \r\n\r\n## Error messages, stack traces, or logs\r\n\r\n```\r\n# error messages, stack traces, or logs\r\nExample error messages:\r\n[W 2020-07-29 20:58:44,714] The parameter 'param3' in trial#9993 is sampled independently by using `RandomSampler` instead of `CmaEsSampler` (optimization performance may be degraded). You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler`, if this independent sampling is intended behavior.\r\n[W 2020-07-29 20:58:44,714] The parameter 'param4' in trial#9994 is sampled independently by using `RandomSampler` instead of `CmaEsSampler` (optimization performance may be degraded). You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler`, if this independent sampling is intended behavior.\r\n[W 2020-07-29 20:58:44,714] The parameter 'param5' in trial#9996 is sampled independently by using `RandomSampler` instead of `CmaEsSampler` (optimization performance may be degraded). You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler`, if this independent sampling is intended behavior.\r\n\r\n"},{"labels":["bug"],"text":"<!-- Please write a clear and concise description of what the bug is. -->\r\n\r\n## Expected behavior\r\n\r\n<!-- Please write a clear and concise description of what you expected to happen. -->\r\n\r\nSometimes, independent sampler is triggered though the search space is clearly not dynamic.\r\n\r\n```python\r\nimport numpy as np\r\nimport optuna\r\n\r\n\r\nclass Rastrigin:\r\n    \"\"\"\r\n    https://www.sfu.ca/~ssurjano/rastr.html\r\n    \"\"\"\r\n    def __init__(self, n):\r\n        self.n = n\r\n\r\n    def __call__(self, trial):\r\n        x = np.array([trial.suggest_uniform(f\"x{i}\", -5.12, 5.12) for i in range(self.n)])\r\n        return 10 * self.n + np.sum(x ** 2 - 10 * np.cos(2 * np.pi * x))\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    optuna.logging.set_verbosity(optuna.logging.WARNING)\r\n    objective = Rastrigin(8)\r\n\r\n    for seed in range(10):\r\n        study = optuna.create_study(\r\n            sampler=optuna.samplers.CmaEsSampler(seed=seed)\r\n        )\r\n        study.optimize(objective, n_trials=1500)\r\n        print(\"Best value: {} (params: {})\\n\".format(study.best_value, study.best_params))\r\n```\r\n\r\n\r\n## Environment\r\n\r\n- Optuna version: master (rev: 278034a9)\r\n- Python version: 3.8.2\r\n- OS:macOS\r\n- (Optional) Other libraries and their versions:\r\n\r\n## Error messages, stack traces, or logs\r\n\r\n```\r\n$ python examples/quadratic_simple.py \r\n[W 2020-07-26 22:51:19,360] The parameter 'x6' in trial#1328 is sampled independently by using `RandomSampler` instead of `CmaEsSampler` (optimization performance may be degraded). You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler`, if this independent sampling is intended behavior.\r\nBest value: 40.1899514495306 (params: {'x0': 0.995858149009119, 'x1': -1.1351238915698543, 'x2': -0.1801230004399368, 'x3': 1.9177514176898494, 'x4': 0.1605867098097168, 'x5': -2.0070995883976925, 'x6': 1.2348466691400497, 'x7': -1.1301172829126584})\r\n\r\nBest value: 32.4631637787495 (params: {'x0': -0.1888686495274782, 'x1': -0.8994779770534349, 'x2': 0.1759863776573024, 'x3': 0.08718985952421743, 'x4': -0.21347527704332003, 'x5': 0.1533930220554347, 'x6': -0.15323426159592224, 'x7': -0.009436181675708921})\r\n\r\nBest value: 31.91496288803713 (params: {'x0': 0.02690799189465823, 'x1': 0.9301003789280453, 'x2': -0.9063281146700595, 'x3': -0.11441781075028418, 'x4': 0.8908104409619761, 'x5': -0.55904514348641, 'x6': -1.0243546160884258, 'x7': 1.0191798909768646})\r\n\r\n[W 2020-07-26 22:51:26,492] The parameter 'x3' in trial#1483 is sampled independently by using `RandomSampler` instead of `CmaEsSampler` (optimization performance may be degraded). You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler`, if this independent sampling is intended behavior.\r\n[W 2020-07-26 22:51:26,492] The parameter 'x4' in trial#1483 is sampled independently by using `RandomSampler` instead of `CmaEsSampler` (optimization performance may be degraded). You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler`, if this independent sampling is intended behavior.\r\n[W 2020-07-26 22:51:26,493] The parameter 'x5' in trial#1483 is sampled independently by using `RandomSampler` instead of `CmaEsSampler` (optimization performance may be degraded). You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler`, if this independent sampling is intended behavior.\r\n[W 2020-07-26 22:51:26,515] The parameter 'x1' in trial#1492 is sampled independently by using `RandomSampler` instead of `CmaEsSampler` (optimization performance may be degraded). You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler`, if this independent sampling is intended behavior.\r\n[W 2020-07-26 22:51:26,515] The parameter 'x3' in trial#1492 is sampled independently by using `RandomSampler` instead of `CmaEsSampler` (optimization performance may be degraded). You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler`, if this independent sampling is intended behavior.\r\n[W 2020-07-26 22:51:26,516] The parameter 'x6' in trial#1492 is sampled independently by using `RandomSampler` instead of `CmaEsSampler` (optimization performance may be degraded). You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler`, if this independent sampling is intended behavior.\r\n[W 2020-07-26 22:51:26,524] The parameter 'x2' in trial#1495 is sampled independently by using `RandomSampler` instead of `CmaEsSampler` (optimization performance may be degraded). You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler`, if this independent sampling is intended behavior.\r\n[W 2020-07-26 22:51:26,525] The parameter 'x3' in trial#1495 is sampled independently by using `RandomSampler` instead of `CmaEsSampler` (optimization performance may be degraded). You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler`, if this independent sampling is intended behavior.\r\nBest value: 42.284741734204616 (params: {'x0': 0.8611571722449447, 'x1': -1.0202710839736775, 'x2': -0.9161870092865121, 'x3': 1.1074296676201707, 'x4': 2.020475272523612, 'x5': 2.6341278204885925, 'x6': -0.961020444464636, 'x7': -1.075404689687082})\r\n\r\nBest value: 35.837188844247734 (params: {'x0': 0.16491643650172522, 'x1': -0.9135554351547925, 'x2': -0.15711841139753724, 'x3': -0.7403737469975655, 'x4': 0.9699238273692735, 'x5': -0.9646192974710259, 'x6': -0.24383102905966858, 'x7': -0.9980549047856908})\r\n\r\n[W 2020-07-26 22:51:30,744] The parameter 'x7' in trial#1187 is sampled independently by using `RandomSampler` instead of `CmaEsSampler` (optimization performance may be degraded). You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler`, if this independent sampling is intended behavior.\r\n[W 2020-07-26 22:51:31,066] The parameter 'x3' in trial#1324 is sampled independently by using `RandomSampler` instead of `CmaEsSampler` (optimization performance may be degraded). You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler`, if this independent sampling is intended behavior.\r\n[W 2020-07-26 22:51:31,067] The parameter 'x4' in trial#1324 is sampled independently by using `RandomSampler` instead of `CmaEsSampler` (optimization performance may be degraded). You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler`, if this independent sampling is intended behavior.\r\n[W 2020-07-26 22:51:31,067] The parameter 'x7' in trial#1324 is sampled independently by using `RandomSampler` instead of `CmaEsSampler` (optimization performance may be degraded). You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler`, if this independent sampling is intended behavior.\r\n[W 2020-07-26 22:51:31,398] The parameter 'x2' in trial#1478 is sampled independently by using `RandomSampler` instead of `CmaEsSampler` (optimization performance may be degraded). You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler`, if this independent sampling is intended behavior.\r\n[W 2020-07-26 22:51:31,435] The parameter 'x3' in trial#1492 is sampled independently by using `RandomSampler` instead of `CmaEsSampler` (optimization performance may be degraded). You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler`, if this independent sampling is intended behavior.\r\n[W 2020-07-26 22:51:31,435] The parameter 'x7' in trial#1492 is sampled independently by using `RandomSampler` instead of `CmaEsSampler` (optimization performance may be degraded). You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler`, if this independent sampling is intended behavior.\r\nBest value: 29.19879250598784 (params: {'x0': 2.0770115850339996, 'x1': 1.0571498004291093, 'x2': 1.0843035099445237, 'x3': 1.0745606517288824, 'x4': -1.8806912321660192, 'x5': -0.9559137545222565, 'x6': -1.193838173651328, 'x7': -0.09452242291271634})\r\n\r\nBest value: 29.34525115041371 (params: {'x0': 1.0355545841547409, 'x1': -0.14212348444599865, 'x2': -0.09354311427862283, 'x3': -0.10414346874509228, 'x4': -1.1537474227287918, 'x5': 0.9559745956916987, 'x6': 0.21069559289098455, 'x7': -1.1597322728811668})\r\n\r\n: (omit)\r\n```\r\n\r\n## Additional context (optional)\r\n\r\n<!-- Please add any other context or screenshots about the problem here. -->\r\n\r\n"},{"labels":["bug",null],"text":"Can I set search condition based on number of trials? For example, I want to explore certain value range for the first 5,000 trials, then change after 5,000 trials:\r\n\r\nIf trials <= 5,000:\r\n    param1 = trial.suggest_int('param1', 0, 50)\r\n    param2 = trial.suggest_int('param2', 0, 50)\r\nelif trials > 5,000:\r\n    param1 = trials.suggest_int('param1', 100, 200)\r\n    param2 = trials.suggest_int('param2', 100, 200)\r\n\r\nIs there a way to access the number of trials completed in the conditional statement? \r\n"},{"labels":["bug",null],"text":"<!-- Please write a clear and concise description of what the bug is. -->\r\nIt seems the sampling behavior differs between the cases where the trial has been pruned or where the trial failed with an exception.\r\n\r\n## Expected behavior\r\n\r\n<!-- Please write a clear and concise description of what you expected to happen. -->\r\nThe sets of samples produced by the sampler should remain similar, independent of whether the trial was pruned or the trial failed due to an exception?\r\n\r\n## Environment\r\n\r\n- Optuna version: 1.5.0 (from pip install)\r\n- Python version: 3.6\r\n- OS: Windows\r\n- (Optional) Other libraries and their versions: Pytorch\r\n\r\n## Steps to reproduce\r\nRunning this\r\n```python\r\n    def obj(trial):\r\n        x = trial.suggest_uniform(\"x\", -5, 5)\r\n        y = trial.suggest_uniform(\"y\", -5, 5)\r\n        if not(abs(x) > abs(y) or y < 0):\r\n            raise optuna.TrialPruned()\r\n        return (abs(x) + abs(y)) ** 2\r\n\r\n    study = optuna.create_study(direction=\"minimize\")\r\n    study.optimize(obj, n_trials=200, catch=(Exception,))\r\n```\r\nand running this:\r\n```python\r\n    def obj(trial):\r\n        x = trial.suggest_uniform(\"x\", -5, 5)\r\n        y = trial.suggest_uniform(\"y\", -5, 5)\r\n        if not(abs(x) > abs(y) or y < 0):\r\n            raise Exception(\"invalid config\")\r\n        return (abs(x) + abs(y)) ** 2\r\n\r\n    study = optuna.create_study(direction=\"minimize\")\r\n    study.optimize(obj, n_trials=200, catch=(Exception,))\r\n```\r\ngives very different sets of samples. \r\n\r\nThe completed samples produced for the TrialPruned() version are: \r\n![afbeelding](https://user-images.githubusercontent.com/1732910/88421155-53304300-cde8-11ea-8175-6fded3c04887.png)\r\nThe completed samples produced for the Exception() version are:\r\n![afbeelding](https://user-images.githubusercontent.com/1732910/88421188-680cd680-cde8-11ea-9cf8-7edec4efebb6.png)\r\nover different runs.\r\n\r\nIn the case of a failure due to an exception, the sampler seems to retry other values in the neighbourhood of the failed sample.\r\n\r\nIs this behavior expected? It might be bad in some cases, where a portion of the search space leads to memory errors (or other problems). If the sampler keeps resampling very closely, only few experiments will actually be properly run (even a 1000 trial run had only the first 10-20 runs complete, while the remaining all failed).\r\n\r\nIs using `TrialPruned()` the correct way to exclude a portion of the search space without further influence on the search behavior (such as the sampler getting discouraged to sample closer to the pruned space)?"},{"labels":["bug"],"text":"<!-- Please write a clear and concise description of what the bug is. -->\r\n\r\nRunning distributed parallel processing with postgresql.\r\nStarted 20 instances. \r\nThen noticed multiple trials having same parameters:\r\nTrial **13443 finished with value: 0.7391443119806878** and parameters: {'model_index': 7, 'band1_index': 25, 'band2_index': 17, 'band3_index': 16}. Best is trial 551 with value: 0.7406389004521836.\r\nTrial **13444 finished with value: 0.7391443119806878** and parameters: {'model_index': 7, 'band1_index': 25, 'band2_index': 17, 'band3_index': 16}. Best is trial 810 with value: 0.7406389004521836.\r\nTrial **13445 finished with value: 0.7391443119806878** and parameters: {'model_index': 7, 'band1_index': 25, 'band2_index': 17, 'band3_index': 16}. Best is trial 551 with value: 0.7406389004521836.\r\nTrial **13446 finished with value: 0.7391443119806878** and parameters: {'model_index': 7, 'band1_index': 25, 'band2_index': 17, 'band3_index': 16}. Best is trial 551 with value: 0.7406389004521836.\r\nTrial **13447 finished with value: 0.7391443119806878** and parameters: {'model_index': 7, 'band1_index': 25, 'band2_index': 17, 'band3_index': 16}. Best is trial 551 with value: 0.7406389004521836.\r\n\r\nSometimes up to 8 trials in a row will have same parameters and scores. It pretty consistent throughout the run.\r\n\r\n## Expected behavior\r\nEach trial to test different hyperparameter combination?\r\n\r\n## Environment\r\n\r\n- Optuna version: 1.5\r\n- Python version: 3.7\r\n- OS: Win10 Pro 64-bit\r\n- (Optional) Other libraries and their versions:\r\n\r\n## Error messages, stack traces, or logs\r\nNone\r\n```\r\n"},{"labels":["bug"],"text":"<!-- Please write a clear and concise description of what the bug is. -->\r\nI encountered a weird outcome whilst optimizing my AllenNLP model, which might be tough to reproduce. I miss some rows in `trial_params`. Surprisingly the table `trials` contains results for the missing parameters which suggests that the runs were successful.\r\n\r\n### Table `trials`\r\n![Values](https://user-images.githubusercontent.com/31375424/87988567-d8fa7880-cae0-11ea-8738-43c703a5d12b.png)\r\n\r\n### Table `trial_params`\r\n\r\n![Params](https://user-images.githubusercontent.com/31375424/87988620-f0396600-cae0-11ea-859c-dcfb3ba8edf7.png)\r\nMissing `trial_id` == 2, `trial_id` == 3, `trial_id` == 4. All other rows up to `trial_id` == 40 are fine.\r\n\r\n## Expected behavior\r\n\r\n<!-- Please write a clear and concise description of what you expected to happen. -->\r\nA table `trial_params` is filled correctly.\r\n\r\n## Environment\r\n\r\n- Optuna version: 1.5.0 (https://github.com/mateuszpieniak/optuna)\r\nI removed only `allennlp.common.params.infer_and_cast` in `AllenNLPExecutor`. It doesn't work with `null` values in jsonnet. In addition, I believe that such casting is not needed anyway since jsonnet was designed in such way that a user is responsible for types casting e.g. `parseInt`, `parseJson` (https://jsonnet.org/ref/stdlib.html)\r\n- Python version: 3.6.9\r\n- OS: Ubuntu 18.04.4 LTS\r\n- AllenNLP 1.0.0 \r\nI know it wasn't supported officially in Optuna 1.5.0 & experimental, but it should work anyway as there is no modification in subsequent versions of Optuna\r\n\r\n## Steps to reproduce\r\nI have 4 GPUs, thus I have 4 runs and I want them all to share my SQLite database.\r\n1. Open 4 terminal tabs.\r\n2. In each tab type `export CUDA_DEVICE=0`, `export CUDA_DEVICE=1`, and so on (https://optuna.readthedocs.io/en/stable/faq.html#how-can-i-use-two-gpus-for-evaluating-two-trials-simultaneously).\r\n3. In each tab type `python optuna_code.py`\r\n\r\n## Reproducible examples (optional)\r\n\r\n### optuna_code.py\r\n```\r\nfrom optuna import Trial, create_study\r\nfrom optuna.integration.allennlp import AllenNLPExecutor\r\n\r\n\r\ndef objective(trial: Trial) -> float:\r\n    # Requires to define CUDA_DEVICE & DEBUG env variable externally to support multi GPU\r\n    trial.suggest_categorical(\"POOLING\", [\"mean\", \"cls\"])\r\n    trial.suggest_float(\"DROPOUT\", 0.0, 0.8)\r\n    trial.suggest_float(\"ALPHA\", 0.0, 1.0)\r\n    trial.suggest_float(\"GAMMA\", 0.0, 5.0)\r\n    trial.suggest_float(\"LEARNING_RATE\", 2e-7, 2e-5, log=True)\r\n    trial.suggest_float(\"WEIGHT_DECAY\", 1e-5, 1e5, log=True)\r\n\r\n    executor = AllenNLPExecutor(\r\n        trial=trial,\r\n        config_file=\"./configs/config_name.jsonnet\",\r\n        serialization_dir=f\"/experiments/optuna/{trial.number}\",\r\n        metrics=\"best_validation_roc_auc\",\r\n        include_package=[\"my_package\"],\r\n    )\r\n\r\n    return executor.run()\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    study = create_study(\r\n        study_name=\"study_name\"\r\n        storage=\"sqlite:///results.db\",\r\n        direction=\"maximize\",\r\n        load_if_exists=True,\r\n    )\r\n\r\n    study.optimize(func=objective, n_jobs=1, n_trials=5, show_progress_bar=True)\r\n\r\n```\r\n\r\n## Additional context (optional)\r\n<!-- Please add any other context or screenshots about the problem here. -->\r\n1) I believe that such bug is hard debug since the next time I run the code it can be fine. It looks like some race condition to me.\r\n2) Missing rows causes hyperparameters importance to fail:\r\n\r\n![Importance](https://user-images.githubusercontent.com/31375424/87990059-89697c00-cae3-11ea-97ed-bedbf549ff4d.png)\r\n"},{"labels":["bug"],"text":"I am trying the distributed processing with Postgresql.\r\nAs per instructions, I have created a study 'optuna_exp' with storage in postgresql database 'Optuna'.\r\nI then execute optimisation script in terminal with the code:\r\nif __name__ == '__main__':\r\n    study = optuna.load_study(study_name='optuna_exp', storage='postgresql+psycopg2://postgres:password@localhost:5432/Optuna')\r\nstudy.optimize(objective, n_trials=5000)\r\n\r\nI am launching 12 terminals and executing the optimization script (32 cores).\r\n\r\nThe study starts fine on each of the instances but after a while, some instance starts to fail and terminate:\r\n\r\nRuntimeError: Trial#5329 has already finished and can not be updated.\r\nRuntimeError: Trial#10154 has already finished and can not be updated.\r\n\r\nThis repeats randomly with sometimes more than half of the instances terminated due to the RuntimeError. \r\n\r\n## Expected behavior\r\nAll instances to complete without error.\r\n\r\n## Environment\r\n- Optuna version: 1.5\r\n- Python version: 3.7\r\n- OS: Windows Pro 64-bit\r\n- (Optional) Other libraries and their versions: IDE PyCharm 2020.1.3 Pro.\r\n\r\n"},{"labels":["bug"],"text":"<!-- Please write a clear and concise description of what the bug is. -->\r\nTrial's intermediate_values are overwritten by other new trial when running multiple experiments in parallel\r\n## Expected behavior\r\nEach trial has its own intermediate_values that can be used for pruner correctly when running Optuna in parallel. This is important because otherwise the pruner logic will be wrong because of incorrect intermediate_values.\r\n\r\n<!-- Please write a clear and concise description of what you expected to happen. -->\r\n\r\n## Environment\r\nUbuntu 1604\r\n\r\n- Optuna version: 1.14, 1.15\r\n- Python version: 3.6, 3.7\r\n- OS: Ubuntu 1604\r\n- (Optional) Other libraries and their versions:\r\n\r\n## Error messages, stack traces, or logs\r\n\r\n```\r\n# error messages, stack traces, or logs\r\n```\r\n\r\n## Steps to reproduce\r\nAssume you have a training code with Optuna as hyper-parameter optimizer\r\n1. run the first instance of train code with optuna;\r\n2. run the second instance of train code with optuna;\r\n3. observe the trial.intermediate_values dict, the first instance's intermediate_values are overwritten by the second. However if you check the database file all intermediate values and steps are correctly logged in the database. Only the runtime value is wrong.\r\n\r\nIt happens on both sqlite and mysql.\r\n\r\n## Reproducible examples (optional)\r\n\r\n```python\r\n# python code\r\n```\r\n\r\n## Additional context (optional)\r\n\r\n<!-- Please add any other context or screenshots about the problem here. -->\r\n"},{"labels":["bug",null],"text":"The lgb.LightGBMTuner seems to run for a number of trials and then breaks unexpectedly. The strange thing is that it runs without problems for a number of steps before the error occurs.\r\n\r\n## Expected behavior\r\n\r\nThis is my code piece:\r\n\r\n```python\r\nself._parameters_set_2 = {\r\n                \"objective\": \"regression\",\r\n                \"metric\": \"rmse\", \r\n                \"verbosity\": -1,\r\n                \"boosting_type\": \"gbdt\"\r\n}\r\n\r\ndata_train_lgb = lgb.Dataset(\r\n                self._pipeline_prepare.fit_transform(self._data[\"training\"][\"X\"]), \r\n                label = self._data[\"training\"][\"y\"]\r\n)\r\n\r\ntuner_lgb = lgb.LightGBMTunerCV(\r\n                    self._parameters_set_2, \r\n                    data_train_lgb,  \r\n                    verbose_eval = 1,\r\n                    num_boost_round = 100, \r\n                    early_stopping_rounds = 10, \r\n                    time_budget = 10,\r\n                    folds = self._data[\"validation_time_cv\"]\r\n                )\r\n```\r\n\r\n## Environment\r\n\r\n- Optuna version: 1.5.0  \r\n- Python version: 3.7\r\n- OS: MacOS 10.15.3 (19D76)\r\n\r\n## Error messages, stack traces, or logs\r\n\r\n```\r\n[I 2020-07-09 11:33:03,956] Finished trial#29 with value: 0.07808463369078895 with parameters: {'bagging_fraction': 0.9527650536197096, 'bagging_freq': 2}. Best is trial#29 with value: 0.07808463369078895.\r\nbagging, val_score: 0.078085:  30%|######################################1                                                                                        | 3/10 [00:01<00:02,  2.38it/s][1]     cv_agg's rmse: 0.0783785 + 0.039904\r\n[2]     cv_agg's rmse: 0.0783836 + 0.0398658\r\n[3]     cv_agg's rmse: 0.0783535 + 0.0397835\r\n[4]     cv_agg's rmse: 0.0783261 + 0.0398097\r\n[5]     cv_agg's rmse: 0.0783087 + 0.0398446\r\n[6]     cv_agg's rmse: 0.0782265 + 0.0396464\r\n[7]     cv_agg's rmse: 0.0783195 + 0.0393913\r\n[8]     cv_agg's rmse: 0.0783578 + 0.0392715\r\n[9]     cv_agg's rmse: 0.0783393 + 0.0391258\r\n[10]    cv_agg's rmse: 0.0784091 + 0.0390127\r\n[11]    cv_agg's rmse: 0.0785363 + 0.0389685\r\n[12]    cv_agg's rmse: 0.0785213 + 0.0386974\r\n[13]    cv_agg's rmse: 0.0784512 + 0.0386922\r\n[14]    cv_agg's rmse: 0.0784105 + 0.0385913\r\n[15]    cv_agg's rmse: 0.0784307 + 0.0385545\r\n[16]    cv_agg's rmse: 0.078539 + 0.0384206\r\nbagging, val_score: 0.078085:  40%|##################################################8                                                                            | 4/10 [00:01<00:02,  2.44it/s][I 2020-07-09 11:33:04,344] Finished trial#30 with value: 0.07822653355517642 with parameters: {'bagging_fraction': 0.5620285231108505, 'bagging_freq': 2}. Best is trial#29 with value: 0.07808463369078895.\r\nbagging, val_score: 0.078085:  40%|##################################################8                                                                            | 4/10 [00:01<00:02,  2.44it/s][1]     cv_agg's rmse: 0.0783772 + 0.0399073\r\n[2]     cv_agg's rmse: 0.0783782 + 0.0398754\r\n[3]     cv_agg's rmse: 0.0781955 + 0.0395771\r\n[4]     cv_agg's rmse: 0.0782144 + 0.0395464\r\n[5]     cv_agg's rmse: 0.0782016 + 0.0395846\r\n[6]     cv_agg's rmse: 0.0781716 + 0.0395182\r\n[7]     cv_agg's rmse: 0.0782204 + 0.0394778\r\n[8]     cv_agg's rmse: 0.0782837 + 0.039339\r\n[9]     cv_agg's rmse: 0.0783296 + 0.0392405\r\n[10]    cv_agg's rmse: 0.0783967 + 0.0391217\r\n[11]    cv_agg's rmse: 0.0786546 + 0.0390099\r\n[12]    cv_agg's rmse: 0.078685 + 0.0387856\r\n[13]    cv_agg's rmse: 0.0786055 + 0.0387932\r\n[14]    cv_agg's rmse: 0.0785633 + 0.0386666\r\n[15]    cv_agg's rmse: 0.0784939 + 0.0384941\r\n[16]    cv_agg's rmse: 0.0785136 + 0.0383061\r\nbagging, val_score: 0.078085:  50%|###############################################################5                                                               | 5/10 [00:02<00:01,  2.52it/s][I 2020-07-09 11:33:04,711] Finished trial#31 with value: 0.0781716160037223 with parameters: {'bagging_fraction': 0.5886098133062734, 'bagging_freq': 4}. Best is trial#29 with value: 0.07808463369078895.\r\nbagging, val_score: 0.078085:  50%|###############################################################5                                                               | 5/10 [00:02<00:01,  2.52it/s][1]     cv_agg's rmse: 0.078378 + 0.0399054\r\n[2]     cv_agg's rmse: 0.0783789 + 0.0398714\r\n[3]     cv_agg's rmse: 0.0783394 + 0.0398052\r\n[4]     cv_agg's rmse: 0.0783081 + 0.0398094\r\n[5]     cv_agg's rmse: 0.0782946 + 0.0398459\r\n[6]     cv_agg's rmse: 0.0782345 + 0.0396868\r\n[7]     cv_agg's rmse: 0.0782768 + 0.0394813\r\n[8]     cv_agg's rmse: 0.0783277 + 0.0393536\r\n[9]     cv_agg's rmse: 0.0783678 + 0.0392847\r\n[10]    cv_agg's rmse: 0.0784627 + 0.0391973\r\n[11]    cv_agg's rmse: 0.0785918 + 0.0391482\r\n[12]    cv_agg's rmse: 0.0785799 + 0.0388465\r\n[13]    cv_agg's rmse: 0.0785052 + 0.0388237\r\n[14]    cv_agg's rmse: 0.0785005 + 0.0387125\r\n[15]    cv_agg's rmse: 0.078562 + 0.0386594\r\n[16]    cv_agg's rmse: 0.0786887 + 0.0385622\r\nbagging, val_score: 0.078085:  60%|############################################################################2                                                  | 6/10 [00:02<00:01,  2.56it/s][I 2020-07-09 11:33:05,084] Finished trial#32 with value: 0.07823448856454775 with parameters: {'bagging_fraction': 0.5748529547945029, 'bagging_freq': 2}. Best is trial#29 with value: 0.07808463369078895.\r\nbagging, val_score: 0.078085:  60%|############################################################################2                                                  | 6/10 [00:02<00:01,  2.42it/s]\r\n  0%|                                                                                                                                                                      | 0/6 [00:00<?, ?it/s]\r\n  0%|                                                                                                                                                                     | 0/20 [00:00<?, ?it/s]\r\n  0%|                                                                                                                                                                      | 0/5 [00:00<?, ?it/s]\r\nBest score: 0.07808463369078895\r\nBest params: {'objective': 'regression', 'metric': 'rmse', 'verbosity': -1, 'boosting_type': 'gbdt', 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'num_leaves': 101, 'feature_fraction': 0.5, 'bagging_fraction': 0.9527650536197096, 'bagging_freq': 2, 'min_child_samples': 20}\r\n  Params: \r\n    objective: regression\r\n    metric: rmse\r\n    verbosity: -1\r\n    boosting_type: gbdt\r\n    lambda_l1: 0.0\r\n    lambda_l2: 0.0\r\n    num_leaves: 101\r\n    feature_fraction: 0.5\r\n    bagging_fraction: 0.9527650536197096\r\n    bagging_freq: 2\r\n    min_child_samples: 20\r\n[W 2020-07-09 11:33:05,134] Setting status of trial#9 as TrialState.FAIL because the returned value from the objective function cannot be casted to float. Returned value is: {'objective': 'regression', 'metric': 'rmse', 'verbosity': -1, 'boosting_type': 'gbdt', 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'num_leaves': 101, 'feature_fraction': 0.5, 'bagging_fraction': 0.9527650536197096, 'bagging_freq': 2, 'min_child_samples': 20}\r\nTraceback (most recent call last):\r\n    print(f\"Second stage | best parameters are: {self._study_stage_2.best_params}\")\r\n  File \"/Users/konradsemsch/.local/share/virtualenvs/Package-21BxfxdE/lib/python3.7/site-packages/optuna/study.py\", line 72, in best_params\r\n    return self.best_trial.params\r\n  File \"/Users/konradsemsch/.local/share/virtualenvs/Package-21BxfxdE/lib/python3.7/site-packages/optuna/study.py\", line 97, in best_trial\r\n    return copy.deepcopy(self._storage.get_best_trial(self._study_id))\r\n  File \"/Users/konradsemsch/.local/share/virtualenvs/Package-21BxfxdE/lib/python3.7/site-packages/optuna/storages/in_memory.py\", line 293, in get_best_trial\r\n    raise ValueError(\"No trials are completed yet.\")\r\nValueError: No trials are completed yet.\r\n```\r\n\r\n## Steps to reproduce\r\n\r\nNot sure if it can be fully reproduced as I can't share the data that I'm using for this. Into which direction is this error pointing so that I could further validate?\r\n"},{"labels":["bug",null],"text":"## Expected behavior\r\n\r\nOptuna handles MySQL errors.\r\n\r\n## Environment\r\n\r\n- Optuna version: 1.5.0\r\n- Python version: 3.7\r\n- OS: mac OS Catalina\r\n- (Optional) Other libraries and their versions: MySQL + pymysql\r\n\r\n## Error messages, stack traces, or logs\r\n\r\n```\r\nsqlalchemy.exc.InvalidRequestError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (raised as a result of Query-invoked autoflush; consider using a session.no_autoflush block if this flush is occurring prematurely)\r\n(pymysql.err.OperationalError) (1213, 'Deadlock found when trying to get lock; try restarting transaction')\r\n[SQL: INSERT INTO trial_user_attributes (trial_id, `key`, value_json) VALUES (%(trial_id)s, %(key)s, %(value_json)s)]\r\n[parameters: {'trial_id': 2998, 'key': 'nodename', 'value_json': '\"anoanymized\"'}]\r\n(Background on this error at: http://sqlalche.me/e/13/e3q8) (Background on this error at: http://sqlalche.me/e/13/7s2a)\r\n```\r\n\r\n## Steps to reproduce\r\n\r\n1. Parallel optimization with MySQL backend.\r\n\r\n## Reproducible examples (optional)\r\n\r\n<details><summary>Code</summary>\r\n<p>\r\n\r\n```python\r\nimport os\r\nimport optuna\r\nfrom multiprocessing import Pool\r\n\r\n\r\ndef f(x):\r\n    return (x - 3) ** 2\r\n\r\n\r\n# Objective function\r\ndef optuna_objective(trial):\r\n    x = trial.suggest_uniform(\"x\", -10, 10)\r\n    y = f(x)\r\n\r\n    nodename = os.uname().nodename\r\n    trial.set_user_attr(\"nodename\", nodename)\r\n\r\n    print(\"x=%8.3f, y=%8.3f\" % (x, y))\r\n\r\n    return y\r\n\r\n\r\n# Entry point\r\ndef main(args):\r\n    rank, = args\r\n    # Create a study\r\n    ECHO=False\r\n    storage = optuna.storages.RDBStorage(os.environ[\"OPTUNA_SQL\"], engine_kwargs=dict(echo=ECHO))\r\n    study = optuna.create_study(\r\n        study_name=\"test_optuna_collision_01\",\r\n        storage=storage,\r\n        load_if_exists=True,\r\n        direction=\"minimize\"\r\n    )\r\n\r\n    # Run optimization\r\n    study.optimize(optuna_objective, n_trials=20)\r\n\r\n    import time\r\n    time.sleep(10)\r\n\r\n    # Visualize the result\r\n    if rank == 0:\r\n        print(\"  #  %8s  %8s  %8s  %28s\" % (\"x\", \"y\", \"NODENAME\", \"STARTED\"))\r\n    for trial in study.trials:\r\n        try:\r\n            x = \"%8.3f\" % trial.params[\"x\"]\r\n            y = \"%8.3f\" % (trial.value or -1)\r\n            if trial.value is None:\r\n                print(\"NO_VALUE: \", trial.number)\r\n            nodename = trial.user_attrs[\"nodename\"]\r\n            started = trial.datetime_start\r\n        except (KeyError, AttributeError):\r\n            x = \"\"\r\n            y = \"\"\r\n            nodename = \"\"\r\n            started = \"\"\r\n        if rank == 0:\r\n            print(\"%3d: %s  %s  %8s  %28s\" % (trial.number, x, y, nodename, started))\r\n\r\n\r\nif __name__ == '__main__':\r\n    with Pool(10) as pool:\r\n        pool.map(main, [(i,) for i in range(10)])\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n## Additional context (optional)\r\n\r\nSee #1496 \r\n\r\nI'll create a follow-up PR after #1490 and #1498 are merged."},{"labels":["bug"],"text":"When I run multiple Optuna processes on cloud servers that have job scheduler, Optuna occasionally assigns duplicate trial numbers (`trial.number`) to multiple trials that started at almost the same time.\r\n\r\n## Expected behavior\r\n\r\nEach trial obtains a different number; as a result, the trial numbers among a study become sequential.\r\n\r\n## Environment\r\n\r\n- Optuna version: 1.5.0\r\n- Python version: 3.8.3\r\n- OS: A CentOS 7.7 container running on Singularity on a SUSE Linux Enterprise Server 12 SP4 host\r\n- Other software versions: PostgreSQL 9.5.21, psycopg 2.8.5\r\n\r\n## Error messages, stack traces, or logs\r\n\r\nA simplified copy of the below-mentioned test program's output looks like:\r\n\r\n```\r\n[I 2020-07-07 00:07:24,134] Using an existing study with name 'test_optuna_collision_01' instead of creating a new one.\r\n\r\n......\r\n\r\n\r\n  #         x         y  NODENAME                       STARTED\r\n  0:   -7.260   105.276    r6i5n2    2020-07-06 23:42:14.603784\r\n  1:    8.803    33.677    r6i5n2    2020-07-06 23:42:14.776819\r\n  2:   -1.653    21.654    r6i5n2    2020-07-06 23:42:14.887652\r\n  3:    0.024     8.856    r6i5n2    2020-07-06 23:42:14.993142\r\n  4:    6.834    14.701    r6i5n2    2020-07-06 23:42:15.106251\r\n  5:   -4.047    49.663    r6i5n2    2020-07-06 23:42:15.215284\r\n  6:    7.026    16.205    r6i5n2    2020-07-06 23:42:15.325813\r\n  7:   -1.137    17.117    r6i5n2    2020-07-06 23:42:15.432296\r\n  8:    0.887     4.466    r6i5n2    2020-07-06 23:42:15.539958\r\n  9:   -9.392   153.554    r6i5n2    2020-07-06 23:42:15.692091\r\n 10:    2.665     0.112    r6i5n2    2020-07-06 23:42:15.836753\r\n 11:    3.273     0.074    r6i5n2    2020-07-06 23:42:15.986390\r\n 12:    3.699     0.489    r6i5n2    2020-07-06 23:42:16.100333\r\n 13:    3.481     0.232    r6i5n2    2020-07-06 23:42:16.216604\r\n 14:    3.461     0.213    r6i5n2    2020-07-06 23:42:16.331074\r\n 15:    5.481     6.154    r6i5n2    2020-07-06 23:42:16.445370\r\n 16:    1.499     2.253    r6i5n2    2020-07-06 23:42:16.560353\r\n 17:   -3.628    43.933    r6i5n2    2020-07-06 23:42:16.674461\r\n 18:    8.431    29.496    r6i5n2    2020-07-06 23:42:16.788654\r\n 19:    5.046     4.185    r6i5n2    2020-07-06 23:42:16.948887\r\n 20:    2.154     0.716    r3i5n6    2020-07-06 23:42:50.112204\r\n 20:    2.096     0.817    r3i5n6    2020-07-06 23:42:50.112892\r\n 20:    2.785     0.046    r2i2n5    2020-07-06 23:42:50.112536\r\n 20:    2.213     0.620    r2i2n5    2020-07-06 23:42:50.113374\r\n 20:    2.237     0.582    r3i5n6    2020-07-06 23:42:50.116946\r\n 25:    2.402     0.358    r3i5n6    2020-07-06 23:42:50.150646\r\n 25:    1.886     1.240    r3i5n6    2020-07-06 23:42:50.151986\r\n 26:    2.022     0.957    r2i2n5    2020-07-06 23:42:50.157673\r\n 28:    4.172     1.374    r2i2n5    2020-07-06 23:42:50.362914\r\n 28:    4.986     3.944    r2i2n5    2020-07-06 23:42:50.364238\r\n 28:    3.871     0.759    r3i5n6    2020-07-06 23:42:50.364441\r\n 28:    4.373     1.885    r3i5n6    2020-07-06 23:42:50.365054\r\n 28:    4.017     1.035    r3i5n6    2020-07-06 23:42:50.365227\r\n 28:    4.861     3.462    r3i5n6    2020-07-06 23:42:50.366699\r\n 28:    4.673     2.799    r3i5n6    2020-07-06 23:42:50.367405\r\n 35:    4.054     1.110    r2i2n5    2020-07-06 23:42:50.373785\r\n 36:    6.775    14.250    r2i2n5    2020-07-06 23:42:50.561707\r\n 36:   -2.051    25.517    r2i2n5    2020-07-06 23:42:50.567540\r\n 37:    6.959    15.676    r3i5n6    2020-07-06 23:42:50.569821\r\n 38:    7.065    16.527    r3i5n6    2020-07-06 23:42:50.574569\r\n 38:   -1.866    23.675    r3i5n6    2020-07-06 23:42:50.575655\r\n 39:    7.005    16.040    r3i5n6    2020-07-06 23:42:50.576151\r\n 39:    6.789    14.358    r3i5n6    2020-07-06 23:42:50.580927\r\n 40:    7.048    16.385    r2i2n5    2020-07-06 23:42:50.581646\r\n 44:    0.104     8.389    r2i2n5    2020-07-06 23:42:50.773439\r\n 45:    2.705     0.087    r2i2n5    2020-07-06 23:42:50.782284\r\n 46:    0.418     6.667    r3i5n6    2020-07-06 23:42:50.798938\r\n 47:    2.871     0.017    r2i2n5    2020-07-06 23:42:50.823891\r\n 47:    9.736    45.379    r3i5n6    2020-07-06 23:42:50.825717\r\n 47:    3.280     0.079    r3i5n6    2020-07-06 23:42:50.826783\r\n 47:    3.098     0.010    r3i5n6    2020-07-06 23:42:50.828179\r\n 51:    3.010     0.000    r3i5n6    2020-07-06 23:42:50.836315\r\n 52:    5.367     5.601    r2i2n5    2020-07-06 23:42:50.949296\r\n 53:    5.591     6.714    r2i2n5    2020-07-06 23:42:50.958469\r\n 54:    5.738     7.497    r3i5n6    2020-07-06 23:42:50.969918\r\n 55:    9.213    38.595    r2i2n5    2020-07-06 23:42:51.028821\r\n 56:   -1.009    16.075    r3i5n6    2020-07-06 23:42:51.046327\r\n 56:   -0.770    14.213    r3i5n6    2020-07-06 23:42:51.047563\r\n 56:   -0.897    15.188    r3i5n6    2020-07-06 23:42:51.050477\r\n 56:    2.905     0.009    r3i5n6    2020-07-06 23:42:51.050697\r\n 60:   -0.883    15.076    r2i2n5    2020-07-06 23:42:51.138237\r\n 61:   -0.566    12.719    r2i2n5    2020-07-06 23:42:51.153265\r\n 62:    1.074     3.708    r3i5n6    2020-07-06 23:42:51.162551\r\n 63:   -0.529    12.457    r2i2n5    2020-07-06 23:42:51.204287\r\n......\r\n```\r\n\r\nIn this result, five `trial`'s got the number 20.\r\n\r\n## Steps to reproduce\r\n\r\n1. Run parallel exploration on multiple nodes using a remote PostgreSQL storage.\r\n2. When multiple `trial`'s are generated in very short time duration (e.g. < 10 ms), they may have the same `number`.\r\n\r\nI ran the following script on 32 nodes as a tiny test.\r\n\r\n```python:\r\nimport os\r\nimport optuna\r\n\r\n\r\ndef f(x):\r\n    return (x - 3) ** 2\r\n\r\n\r\n# Objective function\r\ndef optuna_objective(trial):\r\n    x = trial.suggest_uniform(\"x\", -10, 10)\r\n    y = f(x)\r\n\r\n    nodename = os.uname().nodename\r\n    trial.set_user_attr(\"nodename\", nodename)\r\n\r\n    print(\"x=%8.3f, y=%8.3f\" % (x, y))\r\n\r\n    return y\r\n\r\n\r\n# Entry point\r\ndef main():\r\n    # Create a study\r\n    study = optuna.create_study(\r\n        study_name=\"test_optuna_collision_01\",\r\n        storage=os.environ[\"OPTUNA_SQL\"],  # Set a remote PostgreSQL server\r\n        load_if_exists=True,\r\n        direction=\"minimize\"\r\n    )\r\n\r\n    # Run optimization\r\n    study.optimize(optuna_objective, n_trials=20)\r\n\r\n    # Visualize the result\r\n    print(\"  #  %8s  %8s  %8s  %28s\" % (\"x\", \"y\", \"NODENAME\", \"STARTED\"))\r\n    for trial in study.trials:\r\n        try:\r\n            x = \"%8.3f\" % trial.params[\"x\"]\r\n            y = \"%8.3f\" % trial.value\r\n            nodename = trial.user_attrs[\"nodename\"]\r\n            started = trial.datetime_start\r\n        except (KeyError, AttributeError):\r\n            x = \"\"\r\n            y = \"\"\r\n            nodename = \"\"\r\n            started = \"\"\r\n        print(\"%3d: %s  %s  %8s  %28s\" % (trial.number, x, y, nodename, started))\r\n\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n```\r\n\r\n## Additional context (optional)\r\n\r\nI guess this is caused by a non-atomic operation of the RDB storage.\r\nHere, Optuna assigns `number` to a newly created `trial` by counting the existing `trial`'s on the storage.  \r\n\r\nhttps://github.com/optuna/optuna/blob/69ee3ae5477dc6526b5c62320e4ad0393674cfd5/optuna/storages/rdb/storage.py#L517"},{"labels":["bug",null],"text":"When you do parallel execution in `study.optimize` (when `n_jobs=-1` for example). You say `with Parallel(n_jobs=n_jobs, prefer=\"threads\") as parallel:`. See here:\r\n\r\nhttps://github.com/optuna/optuna/blob/61c6a0acb22338789a83a02bb147326159f41d1e/optuna/study.py#L317\r\n\r\nIMO this just opens (threading) which suffers from the Python Global Interpreter Lock. See here: https://joblib.readthedocs.io/en/latest/generated/joblib.Parallel.html\r\n\r\nThis would not lead to real parallel execution and is useless with CPU bound problems. I suggest to use this: `with Parallel(n_jobs=n_jobs, backend=\"multiprocessing\") as parallel:`\r\n\r\nIf you want to I can provide a PR."},{"labels":["bug",null],"text":"I am running optuna to optimize large-scale detailed models of cortical circuits on Google Cloud supercomputers. I integrated optuna within our modeling tool NetPyNE:  https://github.com/Neurosim-lab/netpyne/blob/optuna/netpyne/batch/optuna_parallel.py \r\n\r\nI was running 50 parallel processes on the controller node of a Google Cloud Platform (GCP) Slurm-based cluster. Each process is an optuna instance (run via 'screen') where the objective function submits a Slurm job to run a cortical simulation on 96-core compute job. Optuna was set up so the 50 processes exchange info via an sqlite db file:\r\n\r\n```\r\n    study = optuna.create_study(study_name=self.batchLabel, storage='sqlite:///%s/%s_storage.db' % (self.saveFolder, self.batchLabel), load_if_exists=True, direction=args['direction'])\r\n    study.optimize(lambda trial: objective(trial, args), n_trials=args['maxiters'], timeout=args['maxtime'])\r\n```\r\n\r\nAt around trial 1000 I got the error `sqlite3.OperationalError: too many SQL variables` on all processes (see detailed error below). \r\n\r\nI know that the doc suggests using PostgreSQL or MySQL for large distributed optimization, particularly if using NFS drives (as do the compute nodes in the cluster). Unfortunately, I have no idea how to replace SQLite with PostgresSQL or MySQL. My question is, do you have any examples of how to set that up? Or have any other suggestions on how to fix this error?\r\n\r\nThanks!\r\n\r\nFull error: \r\n`[I 2020-06-30 00:53:40,502] Finished trial#996 with value: 409.0361137631617 with parameters: {'EEGain': 1.2190444451070857, 'EIGain': 1.810497756045793, \"('IELayerGain', '1-3')\": 1.087901880175065, \"('IELayerGain', '4')\": 1.7309720923711636, \"('IELayerGain', '5')\": 0.5960648412842655, \"('IELayerGain', '6')\": 0.7978043150339824, \"('IILayerGain', '1-3')\": 1.1688903007202631, \"('IILayerGain', '4')\": 0.672447638702098, \"('IILayerGain', '5')\": 0.8073360248421282, \"('IILayerGain', '6')\": 1.8855740649714237, 'thalamoCorticalGain': 1.08285373691784, 'intraThalamicGain': 1.7758770967297166, 'corticoThalamicGain': 1.6566204337609691}. Best is trial#375 with value: 294.2097451307643.\r\n[W 2020-06-30 00:53:40,703] Setting status of trial#1046 as TrialState.FAIL because of the following error: OperationalError('(sqlite3.OperationalError) too many SQL variables',)\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib64/python3.6/site-packages/sqlalchemy/engine/base.py\", line 1278, in _execute_context\r\n    cursor, statement, parameters, context\r\n  File \"/usr/local/lib64/python3.6/site-packages/sqlalchemy/engine/default.py\", line 593, in do_execute\r\n    cursor.execute(statement, parameters)\r\nsqlite3.OperationalError: too many SQL variables\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/ext_salvadordura_gmail_com/.local/lib/python3.6/site-packages/optuna/study.py\", line 734, in _run_trial\r\n    result = func(trial)\r\n  File \"/home/ext_salvadordura_gmail_com/netpyne/netpyne/batch/optuna_parallel.py\", line 387, in <lambda>\r\n    study.optimize(lambda trial: objective(trial, args), n_trials=args['maxiters'], timeout=args['maxtime'])\r\n  File \"/home/ext_salvadordura_gmail_com/netpyne/netpyne/batch/optuna_parallel.py\", line 130, in objective\r\n    candidate.append(trial.suggest_uniform(str(paramLabel), minVal, maxVal))\r\n  File \"/home/ext_salvadordura_gmail_com/.local/lib/python3.6/site-packages/optuna/trial/_trial.py\", line 221, in suggest_uniform\r\n    return self._suggest(name, distribution)\r\n  File \"/home/ext_salvadordura_gmail_com/.local/lib/python3.6/site-packages/optuna/trial/_trial.py\", line 650, in _suggest\r\n    param_value = self.study.sampler.sample_independent(study, trial, name, distribution)\r\n  File \"/home/ext_salvadordura_gmail_com/.local/lib/python3.6/site-packages/optuna/samplers/tpe/sampler.py\", line 174, in sample_independent\r\n    values, scores = _get_observation_pairs(study, param_name, trial)\r\n  File \"/home/ext_salvadordura_gmail_com/.local/lib/python3.6/site-packages/optuna/samplers/tpe/sampler.py\", line 618, in _get_observation_pairs\r\n    for trial in study.get_trials(deepcopy=False):\r\n  File \"/home/ext_salvadordura_gmail_com/.local/lib/python3.6/site-packages/optuna/study.py\", line 145, in get_trials\r\n    return self._storage.get_all_trials(self._study_id, deepcopy=deepcopy)\r\n  File \"/home/ext_salvadordura_gmail_com/.local/lib/python3.6/site-packages/optuna/storages/cached_storage.py\", line 363, in get_all_trials\r\n    study_id, excluded_trial_ids=study.owned_or_finished_trial_ids\r\n  File \"/home/ext_salvadordura_gmail_com/.local/lib/python3.6/site-packages/optuna/storages/rdb/storage.py\", line 951, in _get_trials\r\n    models.TrialModel.study_id == study_id,\r\n  File \"/usr/local/lib64/python3.6/site-packages/sqlalchemy/orm/query.py\", line 3341, in all\r\n    return list(self)\r\n  File \"/usr/local/lib64/python3.6/site-packages/sqlalchemy/orm/query.py\", line 3503, in __iter__\r\n    return self._execute_and_instances(context)\r\n  File \"/usr/local/lib64/python3.6/site-packages/sqlalchemy/orm/query.py\", line 3528, in _execute_and_instances\r\n    result = conn.execute(querycontext.statement, self._params)\r\n  File \"/usr/local/lib64/python3.6/site-packages/sqlalchemy/engine/base.py\", line 1014, in execute\r\n    return meth(self, multiparams, params)\r\n  File \"/usr/local/lib64/python3.6/site-packages/sqlalchemy/sql/elements.py\", line 298, in _execute_on_connection\r\n    return connection._execute_clauseelement(self, multiparams, params)\r\n  File \"/usr/local/lib64/python3.6/site-packages/sqlalchemy/engine/base.py\", line 1133, in _execute_clauseelement\r\n    distilled_params,\r\n  File \"/usr/local/lib64/python3.6/site-packages/sqlalchemy/engine/base.py\", line 1318, in _execute_context\r\n    e, statement, parameters, cursor, context\r\n  File \"/usr/local/lib64/python3.6/site-packages/sqlalchemy/engine/base.py\", line 1512, in _handle_dbapi_exception\r\n    sqlalchemy_exception, with_traceback=exc_info[2], from_=e\r\n  File \"/usr/local/lib64/python3.6/site-packages/sqlalchemy/util/compat.py\", line 178, in raise_\r\n    raise exception\r\n  File \"/usr/local/lib64/python3.6/site-packages/sqlalchemy/engine/base.py\", line 1278, in _execute_context\r\n    cursor, statement, parameters, context\r\n  File \"/usr/local/lib64/python3.6/site-packages/sqlalchemy/engine/default.py\", line 593, in do_execute\r\n    cursor.execute(statement, parameters)\r\nsqlalchemy.exc.OperationalError: (sqlite3.OperationalError) too many SQL variables\r\n[SQL: SELECT trials.trial_id AS trials_trial_id, trials.number AS trials_number, trials.study_id AS trials_study_id, trials.state AS trials_state, trials.value AS trials_value, trials.datetime_start AS trials_datetime_start, trials.datetime_complete AS trials_datetime_complete \r\nFROM trials \r\nWHERE trials.trial_id NOT IN (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?) AND trials.study_id = ?]\r\n[parameters: (1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755`"},{"labels":["bug"],"text":"Optuna's AllenNLP integration evaluates the jsonnet config that you give it, passing in the trial parameters as the `ext_vars`. AllenNLP's default behavior when loading a configuration is a little different, in that it also passes through environment variables: \r\n\r\nhttps://github.com/allenai/allennlp/blob/4de68a42a0df89df01a999ee48f361f24c8c19d4/allennlp/common/params.py#L488\r\n\r\nSo if you rely on specifying e.g. a path to a file as an environment variable, that configuration won't load as expected when using the integration\r\n\r\n## Expected behavior\r\n\r\nOptuna should pass environment variables through when the jsonnet is interpreted. Ideally, it'd just use the AllenNLP config loading code directly so that all behavior is identical, just overriding whatever the trial needs to override.\r\n\r\n## Environment\r\n\r\n- Optuna version: 1.5.0\r\n- Python version: 3.6\r\n- OS: Ubuntu 18.04.4\r\n- (Optional) Other libraries and their versions: AllenNLP 1.0\r\n\r\n## Error messages, stack traces, or logs\r\n\r\nYou'll get `RuntimeError: undefined external variable` during the interpretation of the jsonnet here:\r\n\r\nhttps://github.com/optuna/optuna/blob/9f5c5cf5c36df1628567f0b4a9873892d148ad40/optuna/integration/allennlp.py#L108\r\n\r\n## Steps to reproduce\r\n\r\n1. Use a AllenNLP configuration that expects to be able to use an environment variable to fill an extVar"},{"labels":["bug",null],"text":"I've only been using pytorch lightning and optuna for a few days (kudos, it literally took less than 30 minutes to implement with optuna, I've been using hyperopt and optuna has a much nicer API).\r\n\r\nIt seems to me though that `PyTorchLightningPruningCallback` implements `on_epoch_end` when it should in fact implement `on_validation_end`. Otherwise, the `MedianPruner` doesn't appear to get invoked. \r\n\r\n\r\n## Expected behavior\r\n\r\n`PyTorchLightningPruningCallback` to be invoked on each epoch, if you rename the `PyTorchLightningPruningCallback.on_epoch_end` to `PyTorchLightningPruningCallback.on_validation_end` the `MedianPruner` is invoked.\r\n\r\nAlternatively I just removed the `early_stop_callback` - then pruning does work, but I'm not sure what strategy it's using, I'm pretty sure it's not the `optuna.pruners.MedianPruner`, I guess it's a default pytorch_lightning pruner?\r\n\r\n## Environment\r\n\r\n- Optuna version: 1.5.0\r\n- Python version: 3.7\r\n- OS: Ubuntu 18.04\r\n- (Optional) Other libraries and their versions:\r\n\r\npytorch-lightning 0.8.1\r\n\r\n## Additional context (optional)\r\n\r\nI simplified my objective (the example doesn't log to tensorboard, I found that by commenting out much of the code it started logging correctly). I'm training a TCN with only 1 batch per epoch. I also modified the example so as to not pass the trial object into my `LightningModule`\r\n\r\n```\r\ndef objective(trial):\r\n    metrics_callback = MetricsCallback()\r\n    trainer = pl.Trainer(\r\n        callbacks=[metrics_callback],\r\n        early_stop_callback=PyTorchLightningPruningCallback(trial, monitor=\"avg_val_loss\"),\r\n    )\r\n\r\n    layers = trial.suggest_int(\"layers\", 1, 8)\r\n    filters = trial.suggest_int(\"filters\", 1, 32)\r\n    kernel_size = trial.suggest_int(\"kernel_size\", 2, 3)\r\n    dropout = trial.suggest_uniform(\"dropout\", 0.2, 0.5)\r\n    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\r\n    model = TCN(PATH, layers, filters, kernel_size, dropout, learning_rate)\r\n    trainer.fit(model)\r\n\r\n    return metrics_callback.metrics[-1][\"avg_val_loss\"].item()\r\n```\r\n\r\npretty sure the main code is essentially the same as the example\r\n\r\n```\r\n    hparams = vars(args)\r\n    tcn = TCN(**hparams)\r\n    pruner = optuna.pruners.MedianPruner()\r\n\r\n    trainer = pl.Trainer.from_argparse_args(args, pruner=pruner)\r\n    trainer.fit(tcn)\r\n```"},{"labels":["bug"],"text":"<!-- Please write a clear and concise description of what the bug is. -->\r\n\r\n## Expected behavior\r\n\r\n<!-- Please write a clear and concise description of what you expected to happen. -->\r\n\r\nWhen we run a method or class has [deprecated decorator](https://github.com/optuna/optuna/blob/879009b95b03988e5cd1f2e335f3bf1c6367aa87/optuna/_deprecated.py#L36) of optuna, we expect a warning message is shown. But the current implementation does not show any warning message.\r\n\r\n## Environment\r\n\r\n- Optuna version: [the lastest version](https://github.com/optuna/optuna/tree/879009b95b03988e5cd1f2e335f3bf1c6367aa87) & [additional commit](https://github.com/nzw0301/optuna/commit/0981f3f4eaed012b744a465f27d4534654fd19d7)\r\n- Python version: 3.8.4\r\n- OS: MacOSX 10.15.5\r\n\r\n## Error messages, stack traces, or logs\r\n\r\n```\r\n# error messages, stack traces, or logs\r\n```\r\n\r\n## Steps to reproduce\r\n\r\n1. `pip install git+https://github.com/nzw0301/optuna.git@deprecated-test`\r\n2. Run the following examples: they do not show anything.\r\n\r\n## Reproducible examples (optional)\r\n\r\nBy the [additional commit](https://github.com/nzw0301/optuna/commit/0981f3f4eaed012b744a465f27d4534654fd19d7), `IntLogUniformDistribution` and  `IntLogUniformDistribution.single` have deprecated decorators. But no warning messages appear when they are called:\r\n\r\n```python\r\nimport optuna\r\nfrom optuna.distributions import IntLogUniformDistribution\r\n\r\ndist = IntLogUniformDistribution(1, 10)\r\ndist.single()\r\n```\r\n\r\nOr\r\n\r\n```python\r\nimport optuna\r\nfrom optuna.distributions import IntLogUniformDistribution\r\n\r\noptuna.logging.set_verbosity(optuna.logging.WARNING)\r\n\r\ndist = IntLogUniformDistribution(1, 10)\r\ndist.single()\r\n```\r\n\r\n## Additional context (optional)\r\n\r\n<!-- Please add any other context or screenshots about the problem here. -->\r\n\r\nOther optuna's codes such that it contains `DeprecatedWarning` such as [`optuna.structs.py`](https://github.com/optuna/optuna/blob/879009b95b03988e5cd1f2e335f3bf1c6367aa87/optuna/structs.py) show the warning message by default when we use them.\r\n\r\nFor example, if I run the following line,\r\n\r\n```python\r\nfrom optuna.structs import FrozenTrial\r\n```\r\n\r\nthen the following warning message is printed:\r\n\r\n```bash\r\n[W 2020-06-24 01:11:56,553] `structs` is deprecated. Classes have moved to the following modules. `structs.StudyDirection`->`study.StudyDirection`, `structs.StudySummary`->`study.StudySummary`, `structs.FrozenTrial`->`trial.FrozenTrial`, `structs.TrialState`->`trial.TrialState`, `structs.TrialPruned`->`exceptions.TrialPruned`.\r\n```\r\n\r\n---\r\n\r\nThank you @HideakiImamura for investigating this issue."},{"labels":["bug"],"text":"## Expected behavior\r\n\r\nPruner does the pruning.\r\n\r\n## Environment\r\n\r\n- Optuna version: 1.5.0\r\n- Python version: 3.7.7\r\n- OS: Ubuntu 18.04\r\n- (Optional) Other libraries and their versions: AllenNLP 1.0.0\r\n\r\n## Reproducible examples\r\n\r\n```python\r\nimport optuna\r\n\r\n\r\nstudy = optuna.study.create_study()\r\ntrial = optuna.trial.Trial(study, study._storage.create_new_trial(study._study_id))\r\npruner = optuna.pruners.ThresholdPruner(upper=2.0, n_warmup_steps=0, interval_steps=1)\r\n\r\ntrial.report(3.0, 1)\r\nassert pruner.prune(study=study, trial=study._storage.get_trial(trial._trial_id))  # prune!\r\n\r\ntrial.report(3.0, 0)\r\nassert pruner.prune(study=study, trial=study._storage.get_trial(trial._trial_id))  # doesn't prune!\r\n```\r\n\r\nIt's a small bug but some libraries (e.g. AllenNLP) report metrics from `epoch==0`.\r\nFor the input `epoch==0`, pruner never prunes a trial because it satisfies `step <= n_warmup_steps`.\r\n- https://github.com/optuna/optuna/blob/master/optuna/pruners/_threshold.py#L121\r\n- https://github.com/optuna/optuna/blob/master/optuna/pruners/_percentile.py#L170\r\n\r\nI think it doesn't have a strong impact, as almost pruner doesn't prune trial at the beginning of training.\r\nHowever, for `ThresholdPruner`, it could be matter."},{"labels":["bug"],"text":"## Expected behavior\r\n\r\nTests should pass.\r\n\r\n## Error messages, stack traces, or logs\r\n\r\nhttps://app.circleci.com/pipelines/github/optuna/optuna/1171/workflows/41e626df-8501-46ca-a724-9b1c27079253/jobs/45897\r\n\r\n## Additional context (optional)\r\n\r\nSeems to be specific to Python 3.5 and only happen randomly."},{"labels":["bug"],"text":"## Expected behavior\r\n\r\nDocs should be built properly without warnings/errors. Following warnings are raised by `sphinx`'s latests release `3.1.1`.\r\n\r\n## Environment\r\n\r\n- `sphinx==3.1.1`\r\n\r\n## Error messages, stack traces, or logs\r\n\r\n```\r\nWARNING: Failed to update signature for <function MLflowCallback.__init__ at 0x7feea1b4e280>: parameter not found: 'args'\r\n \r\nWARNING: Failed to update signature for <function GridSampler.__init__ at 0x7feeabb5edc0>: parameter not found: 'args'\r\n \r\nWARNING: Failed to update signature for <function RedisStorage.__init__ at 0x7feeabb4ce50>: parameter not found: 'args'\r\n \r\nWARNING: Failed to update signature for <function Study.enqueue_trial at 0x7feeabb4ec10>: parameter not found: 'kwargs'\r\n```\r\n\r\n## Steps to reproduce\r\n\r\n1. `pip install sphinx -U`\r\n2. `cd docs`\r\n3. `make clean`\r\n4. `make html`"},{"labels":["bug",null,null],"text":"<!-- Please write a clear and concise description of what the bug is. -->\r\n\r\n## Expected behavior\r\nI got an error when using custom metrics in optuna.integration.lightgbm.\r\n\r\n<!-- Please write a clear and concise description of what you expected to happen. -->\r\n\r\n## Environment\r\n\r\n- Optuna version: 1.5.0\r\n- Python version: 3.7.7\r\n- OS: MacOS Catalina 10.15.5\r\n- Anaconda\r\n- (Optional) Other libraries and their versions:\r\n[conda_list.txt](https://github.com/optuna/optuna/files/4757062/conda_list.txt)\r\n\r\n\r\n## Error messages, stack traces, or logs\r\n```\r\n Early stopping, best iteration is:\r\n [113]\ttraining's custom_metrics: 0.73954\tvalid_1's custom_metrics: 2.25621\r\n\r\nKeyError                                  Traceback (most recent call last)\r\n<ipython-input-45-c87e652c308e> in <module>\r\n      1 best_params = {}\r\n      2 model = lgb_tuner.train(params, train_set, num_boost_round = 2500, early_stopping_rounds = 50,\r\n----> 3                   valid_sets = [train_set, val_set], verbose_eval = 100, feval= custom_metrics)\r\n\r\n~/opt/anaconda3/envs/dev-python37/lib/python3.7/site-packages/optuna/_experimental.py in new_func(*args, **kwargs)\r\n     62                 )\r\n     63 \r\n---> 64                 return func(*args, **kwargs)  # type: ignore\r\n     65 \r\n     66             return new_func\r\n\r\n~/opt/anaconda3/envs/dev-python37/lib/python3.7/site-packages/optuna/integration/lightgbm_tuner/__init__.py in train(*args, **kwargs)\r\n     44 \r\n     45     auto_booster = LightGBMTuner(*args, **kwargs)\r\n---> 46     auto_booster.run()\r\n     47     return auto_booster.get_best_booster()\r\n\r\n~/opt/anaconda3/envs/dev-python37/lib/python3.7/site-packages/optuna/integration/lightgbm_tuner/optimize.py in run(self)\r\n    483         self.sample_train_set()\r\n    484 \r\n--> 485         self.tune_feature_fraction()\r\n    486         self.tune_num_leaves()\r\n    487         self.tune_bagging()\r\n\r\n~/opt/anaconda3/envs/dev-python37/lib/python3.7/site-packages/optuna/integration/lightgbm_tuner/optimize.py in tune_feature_fraction(self, n_trials)\r\n    511             warnings.simplefilter(\"ignore\", category=optuna.exceptions.ExperimentalWarning)\r\n    512             sampler = optuna.samplers.GridSampler({param_name: param_values})\r\n--> 513         self.tune_params([param_name], len(param_values), sampler, \"feature_fraction\")\r\n    514 \r\n    515     def tune_num_leaves(self, n_trials: int = 20) -> None:\r\n\r\n~/opt/anaconda3/envs/dev-python37/lib/python3.7/site-packages/optuna/integration/lightgbm_tuner/optimize.py in tune_params(self, target_param_names, n_trials, sampler, step_name)\r\n    862 \r\n    863         objective = super(LightGBMTuner, self).tune_params(\r\n--> 864             target_param_names, n_trials, sampler, step_name\r\n    865         )\r\n    866 \r\n\r\n~/opt/anaconda3/envs/dev-python37/lib/python3.7/site-packages/optuna/integration/lightgbm_tuner/optimize.py in tune_params(self, target_param_names, n_trials, sampler, step_name)\r\n    595                     timeout=_timeout,\r\n    596                     catch=(),\r\n--> 597                     callbacks=self._optuna_callbacks,\r\n    598                 )\r\n    599             except ValueError:\r\n\r\n~/opt/anaconda3/envs/dev-python37/lib/python3.7/site-packages/optuna/study.py in optimize(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\r\n    337             if n_jobs == 1:\r\n    338                 self._optimize_sequential(\r\n--> 339                     func, n_trials, timeout, catch, callbacks, gc_after_trial, None\r\n    340                 )\r\n    341             else:\r\n\r\n~/opt/anaconda3/envs/dev-python37/lib/python3.7/site-packages/optuna/study.py in _optimize_sequential(self, func, n_trials, timeout, catch, callbacks, gc_after_trial, time_start)\r\n    680                     break\r\n    681 \r\n--> 682             self._run_trial_and_callbacks(func, catch, callbacks, gc_after_trial)\r\n    683 \r\n    684             self._progress_bar.update((datetime.datetime.now() - time_start).total_seconds())\r\n\r\n~/opt/anaconda3/envs/dev-python37/lib/python3.7/site-packages/optuna/study.py in _run_trial_and_callbacks(self, func, catch, callbacks, gc_after_trial)\r\n    711         # type: (...) -> None\r\n    712 \r\n--> 713         trial = self._run_trial(func, catch, gc_after_trial)\r\n    714         if callbacks is not None:\r\n    715             frozen_trial = copy.deepcopy(self._storage.get_trial(trial._trial_id))\r\n\r\n~/opt/anaconda3/envs/dev-python37/lib/python3.7/site-packages/optuna/study.py in _run_trial(self, func, catch, gc_after_trial)\r\n    732 \r\n    733         try:\r\n--> 734             result = func(trial)\r\n    735         except exceptions.TrialPruned as e:\r\n    736             message = \"Setting status of trial#{} as {}. {}\".format(\r\n\r\n~/opt/anaconda3/envs/dev-python37/lib/python3.7/site-packages/optuna/integration/lightgbm_tuner/optimize.py in __call__(self, trial)\r\n    247         booster = lgb.train(self.lgbm_params, self.train_set, **self.lgbm_kwargs)\r\n    248 \r\n--> 249         val_score = self._get_booster_best_score(booster)\r\n    250         elapsed_secs = time.time() - start_time\r\n    251         average_iteration_time = elapsed_secs / booster.current_iteration()\r\n\r\n~/opt/anaconda3/envs/dev-python37/lib/python3.7/site-packages/optuna/integration/lightgbm_tuner/optimize.py in _get_booster_best_score(self, booster)\r\n    119             raise NotImplementedError\r\n    120 \r\n--> 121         val_score = booster.best_score[valid_name][metric]\r\n    122         return val_score\r\n    123 \r\n\r\nKeyError: 'None'\r\n\r\n```\r\n\r\n## Steps to reproduce\r\n\r\n1.create custom_metric\r\n2.set params : params = {'metric' = 'None', ...}\r\n3.optuna.integration.lightgbm.train(params = params, feval = custom_metrics, ...)\r\n\r\n## Reproducible examples (optional)\r\n\r\n```python\r\n# python code\r\n```\r\n\r\n## Additional context (optional)\r\n\r\n<!-- Please add any other context or screenshots about the problem here. -->\r\n"},{"labels":["bug",null],"text":"<!-- Please write a clear and concise description of what the bug is. -->\r\n\r\n## Expected behavior\r\n\r\nI need to build many, fast-training models. For this i'm using multiprocessing.Pool:\r\n```\r\nwith Pool(maxtasksperchild=10) as pool:\r\n    res=pool.map(task,iter)\r\n```\r\nIn each task i'm creating stydy with unique name  and run optimize. As storage is used Postgres 12.\r\n\r\nAfter a few cycle, i get error from psycopg2: \"too many client\"\r\nHow I can manualy close connection for finished task and study. Or exist anotherway?\r\nP.S. I know about the possibility to шncrease quantity of clients on Postgres, but It only test data. Real task is much more.\r\n\r\n## Environment\r\n\r\n- Optuna version: 1.5.0\r\n- Python version: 3.7.7\r\n- OS: Ubuntu 20.04\r\n-  psycopg2-binary: 2.8.5\r\n- Postgres version: 12\r\n\r\n## Error messages, stack traces, or logs\r\n\r\n```\r\n# error messages, stack traces, or logs\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/ilya/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\r\n    result = (True, func(*args, **kwds))\r\n  File \"/home/ilya/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 44, in mapstar\r\n    return list(map(*args))\r\n  File \"<ipython-input-11-68b9f5f269e0>\", line 3, in task\r\n    df:pd.DataFrame=pd.read_sql_query(select_query.format(pan=pan),connect_string)\r\n  File \"/home/ilya/anaconda3/lib/python3.7/site-packages/pandas/io/sql.py\", line 332, in read_sql_query\r\n    chunksize=chunksize,\r\n  File \"/home/ilya/anaconda3/lib/python3.7/site-packages/pandas/io/sql.py\", line 1218, in read_query\r\n    result = self.execute(*args)\r\n  File \"/home/ilya/anaconda3/lib/python3.7/site-packages/pandas/io/sql.py\", line 1087, in execute\r\n    return self.connectable.execute(*args, **kwargs)\r\n  File \"/home/ilya/anaconda3/lib/python3.7/site-packages/sqlalchemy/engine/base.py\", line 2243, in execute\r\n    connection = self._contextual_connect(close_with_result=True)\r\n  File \"/home/ilya/anaconda3/lib/python3.7/site-packages/sqlalchemy/engine/base.py\", line 2311, in _contextual_connect\r\n    self._wrap_pool_connect(self.pool.connect, None),\r\n  File \"/home/ilya/anaconda3/lib/python3.7/site-packages/sqlalchemy/engine/base.py\", line 2349, in _wrap_pool_connect\r\n    e, dialect, self\r\n  File \"/home/ilya/anaconda3/lib/python3.7/site-packages/sqlalchemy/engine/base.py\", line 1591, in _handle_dbapi_exception_noconnection\r\n    sqlalchemy_exception, with_traceback=exc_info[2], from_=e\r\n  File \"/home/ilya/anaconda3/lib/python3.7/site-packages/sqlalchemy/util/compat.py\", line 178, in raise_\r\n    raise exception\r\n  File \"/home/ilya/anaconda3/lib/python3.7/site-packages/sqlalchemy/engine/base.py\", line 2345, in _wrap_pool_connect\r\n    return fn()\r\n  File \"/home/ilya/anaconda3/lib/python3.7/site-packages/sqlalchemy/pool/base.py\", line 364, in connect\r\n    return _ConnectionFairy._checkout(self)\r\n  File \"/home/ilya/anaconda3/lib/python3.7/site-packages/sqlalchemy/pool/base.py\", line 778, in _checkout\r\n    fairy = _ConnectionRecord.checkout(pool)\r\n  File \"/home/ilya/anaconda3/lib/python3.7/site-packages/sqlalchemy/pool/base.py\", line 495, in checkout\r\n    rec = pool._do_get()\r\n  File \"/home/ilya/anaconda3/lib/python3.7/site-packages/sqlalchemy/pool/impl.py\", line 140, in _do_get\r\n    self._dec_overflow()\r\n  File \"/home/ilya/anaconda3/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py\", line 69, in __exit__\r\n    exc_value, with_traceback=exc_tb,\r\n  File \"/home/ilya/anaconda3/lib/python3.7/site-packages/sqlalchemy/util/compat.py\", line 178, in raise_\r\n    raise exception\r\n  File \"/home/ilya/anaconda3/lib/python3.7/site-packages/sqlalchemy/pool/impl.py\", line 137, in _do_get\r\n    return self._create_connection()\r\n  File \"/home/ilya/anaconda3/lib/python3.7/site-packages/sqlalchemy/pool/base.py\", line 309, in _create_connection\r\n    return _ConnectionRecord(self)\r\n  File \"/home/ilya/anaconda3/lib/python3.7/site-packages/sqlalchemy/pool/base.py\", line 440, in __init__\r\n    self.__connect(first_connect_check=True)\r\n  File \"/home/ilya/anaconda3/lib/python3.7/site-packages/sqlalchemy/pool/base.py\", line 661, in __connect\r\n    pool.logger.debug(\"Error on connect(): %s\", e)\r\n  File \"/home/ilya/anaconda3/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py\", line 69, in __exit__\r\n    exc_value, with_traceback=exc_tb,\r\n  File \"/home/ilya/anaconda3/lib/python3.7/site-packages/sqlalchemy/util/compat.py\", line 178, in raise_\r\n    raise exception\r\n  File \"/home/ilya/anaconda3/lib/python3.7/site-packages/sqlalchemy/pool/base.py\", line 656, in __connect\r\n    connection = pool._invoke_creator(self)\r\n  File \"/home/ilya/anaconda3/lib/python3.7/site-packages/sqlalchemy/engine/strategies.py\", line 114, in connect\r\n    return dialect.connect(*cargs, **cparams)\r\n  File \"/home/ilya/anaconda3/lib/python3.7/site-packages/sqlalchemy/engine/default.py\", line 490, in connect\r\n    return self.dbapi.connect(*cargs, **cparams)\r\n  File \"/home/ilya/anaconda3/lib/python3.7/site-packages/psycopg2/__init__.py\", line 127, in connect\r\n    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)\r\nsqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already\r\n\r\n(Background on this error at: http://sqlalche.me/e/e3q8)\r\n```\r\n\r\n"},{"labels":["bug"],"text":"## Motivation\r\nWhen using the `MLflowCallback` it is possible that the user added `user_attrs` (like lists of float) that are longer then 5000 characters when converted to a `str`. This causes problems with MLflow which limits the length to 5000. See example below:\r\n\r\n``` bash\r\n[...]\r\n  File \"/home/smay/miniconda3/envs/py38/lib/python3.8/site-packages/mlflow/utils/validation.py\", line 136, in _validate_length_limit\r\n    raise MlflowException(\r\nmlflow.exceptions.MlflowException: Tag value '[0.8562690322984875, 0.8544098885636596, 0.8544098885636596, 0.8544098885636596, 0.8544098885636596, 0.859181214773054, 0.86273086038245, 0.86273086038245, 0.86273086038245, 0.86273086038245, 0.86273086038245, 0.8562690322984875, 0.8544098885636596, ' had length 5276, which exceeded length limit of 5000\r\n```\r\n\r\n## Description\r\nI suggest to check the strings if they are `len() > 5000` and cut them if needed. If this happens a warning should be printed.\r\n\r\nI can provide a PR if wanted. Just give me feedback to my proposal please.\r\n"},{"labels":["bug",null],"text":"Optuna 1.5.0, Python 3.7.7\r\n\r\n`optuna dashboard  --storage \"postgres://postgres@localhost:5444/optuna\" --study-name test --out optunadashboard.html`\r\n\r\n```\r\n[W 2020-06-03 06:30:19,131] Optuna dashboard is still highly experimental. Please use with caution!\r\nusage: bokeh [-h] [-v]\r\n             {build,info,init,json,sampledata,secret,serve,static} ...\r\nbokeh: error: invalid choice: 'html' (choose from 'build', 'info', 'init', 'json', 'sampledata', 'secret', 'serve', 'static')\r\n```"},{"labels":["bug",null],"text":"Optuna 1.5.0, Python 3.7.7\r\n\r\nThe following command\r\n`optuna dashboard  --storage \"postgres://postgres@localhost:5444/optuna\" --study-name test\r\n`the http server starts up and the web page opens to a blank page. Refresh the page produces another blank page. Any ideas on where I should look to resolve the issue?\r\n\r\nThank you for a great package and documentation!\r\n\r\n```\r\n[W 2020-06-03 06:27:42,079] Optuna dashboard is still highly experimental. Please use with caution!\r\n[I 2020-06-03 06:27:42,087] Starting Bokeh server version 2.0.2 (running on Tornado 6.0.4)\r\n[I 2020-06-03 06:27:42,089] User authentication hooks NOT provided (default user enabled)\r\n[I 2020-06-03 06:27:42,092] Bokeh app running at: http://localhost:5006/dashboard\r\n[I 2020-06-03 06:27:42,093] Starting Bokeh server with process id: 31360\r\n[I 2020-06-03 06:27:43,014] 200 GET /dashboard (::1) 117.69ms\r\n[I 2020-06-03 06:27:43,670] 200 GET /static/js/bokeh.min.js?v=57d29d5936e494351385d736f792154c (::1) 612.41ms\r\n[I 2020-06-03 06:27:43,684] 200 GET /static/js/bokeh-widgets.min.js?v=fdb1f42cceaade9062de57963cac654c (::1) 11.93ms\r\n[I 2020-06-03 06:27:43,697] 200 GET /static/js/bokeh-tables.min.js?v=0a7f930d4b0805283dfba427bb3d0dae (::1) 24.89ms\r\n[I 2020-06-03 06:27:43,702] 200 GET /static/js/bokeh-gl.min.js?v=c376f0736800259be44cb1aed39a6cc3 (::1) 28.89ms\r\n[I 2020-06-03 06:27:43,787] 101 GET /dashboard/ws (::1) 0.00ms\r\n[I 2020-06-03 06:27:43,788] WebSocket connection opened\r\n[I 2020-06-03 06:27:43,790] ServerConnection created\r\n[W 2020-06-03 06:27:43,798] 404 GET /favicon.ico (::1) 1.00ms\r\n[I 2020-06-03 06:28:38,374] 200 GET /dashboard (::1) 3.96ms\r\n[I 2020-06-03 06:28:38,381] WebSocket connection closed: code=1001, reason=None\r\n[I 2020-06-03 06:28:38,510] 101 GET /dashboard/ws (::1) 1.00ms\r\n[I 2020-06-03 06:28:38,510] WebSocket connection opened\r\n[I 2020-06-03 06:28:38,511] ServerConnection created\r\n```\r\n![2020-06-03T093802_465_455](https://user-images.githubusercontent.com/1430861/83643384-f51c7780-a57d-11ea-9b0a-ab6ee0624afc.png)\r\n\r\n![2020-06-03T093812_683_381](https://user-images.githubusercontent.com/1430861/83643416-fd74b280-a57d-11ea-981d-d1f7da5e2535.png)\r\n"},{"labels":["bug",null],"text":"The following code performs 500 optimization trials with TPE sampler and then another 500 optimization trials with CMA-ES sampler. Sometimes the optimization continues from the same point after the sampler switch and sometimes it starts from scratch. \r\n\r\nsmp = optuna.samplers.TPESampler()\r\nstudy = optuna.create_study(sampler=smp)\r\nstudy.optimize(objective, n_trials=500)\r\nstudy.sampler = optuna.integration.CmaEsSampler()\r\nstudy.optimize(objective, n_trials=500)\r\n\r\n![Figure_1 TPE CMA combined params 2](https://user-images.githubusercontent.com/28355894/83610866-cce64600-a588-11ea-9fe2-ffa7564bbd9e.png)\r\n\r\n## Expected behavior\r\n\r\nI expect the optimization process to take in account the optimization achievements so far, after switching the sampler\r\n\r\n## Environment\r\n\r\n- Optuna version: 1.2.0\r\n- Python version: 3.7\r\n- OS: windows 10\r\n\r\n"},{"labels":["bug"],"text":"The `experimental` decorator used on classes break documentation. This could be one manifestation but there is an issue with how the documentation including type hints are propagated to the decorated class. This does not apply for free functions.\r\n\r\nSee https://github.com/optuna/optuna/pull/1265#issuecomment-633195955 for how it may break.\r\n\r\n## Expected behavior\r\n\r\nClass documentation should not be altered by applying the experimental decorator.\r\n\r\n## Steps to reproduce\r\n\r\n1. Apply the experimental decorator to a class.\r\n1. Build the document (`cd docs && make html`) \r\n1. Open the rendered documentation and note that the class signatures is broken.\r\n\r\n## Additional context (optional)\r\n\r\n- An issue regarding the indentation https://github.com/optuna/optuna/issues/1213.\r\n"},{"labels":["bug",null],"text":"In the current implementation, the `optuna.samplers.CmaEsSampler` uses the independent sampler for `trial.suggest_loguniform`. This is not intentional. It should be sampled by CMA-ES algorithm.\r\n\r\n# Environment\r\n\r\n- Optuna version: 1.4.0\r\n- Python version: 3.6.5\r\n- OS: macOS Catalina 10.15.4\r\n\r\n# Code \r\n```python\r\nimport optuna\r\n\r\n# Define a simple 2-dimensional objective function whose minimum value is -1 when (x, y) = (0, -1).\r\ndef objective(trial):\r\n    w = trial.suggest_discrete_uniform(\"w\", 1.0, 10.0, 1.0)\r\n    x = trial.suggest_uniform(\"x\", -100, 100)\r\n    y = trial.suggest_categorical(\"y\", [-1, 0, 1])\r\n    z = trial.suggest_loguniform(\"z\", 0.01, 1.0)\r\n    return w ** 2 + x ** 2 + y + z ** 2\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    # Let us minimize the objective function above.\r\n    sampler = optuna.samplers.CmaEsSampler(n_startup_trials=1)\r\n    print(\"Running 2 trials...\")\r\n    study = optuna.study.create_study(sampler=sampler)\r\n    study.optimize(objective, n_trials=2)\r\n    print(\"Best value: {} (params: {})\\n\".format(study.best_value, study.best_params))\r\n```\r\n\r\n# Result\r\n```\r\n$ python test.py \r\npython3.6/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\r\n  warnings.warn(msg)\r\nRunning 2 trials...\r\n[I 2020-05-14 15:12:08,382] Finished trial#0 with value: 729.7092383151211 with parameters: {'w': 8.0, 'x': 25.807829185276148, 'y': -1, 'z': 0.8155924587254163}. Best is trial#0 with value: 729.7092383151211.\r\n[W 2020-05-14 15:12:08,384] The parameter 'y' in trial#1 is sampled independently by using `RandomSampler` instead of `CmaEsSampler` (optimization performance may be degraded). You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler`, if this independent sampling is intended behavior.\r\n[W 2020-05-14 15:12:08,385] The parameter 'z' in trial#1 is sampled independently by using `RandomSampler` instead of `CmaEsSampler` (optimization performance may be degraded). You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler`, if this independent sampling is intended behavior.\r\n[I 2020-05-14 15:12:08,442] Finished trial#1 with value: 65.0908323918039 with parameters: {'w': 8.0, 'x': -1.0440794535810325, 'y': 0, 'z': 0.027027512165087225}. Best is trial#1 with value: 65.0908323918039.\r\nBest value: 65.0908323918039 (params: {'w': 8.0, 'x': -1.0440794535810325, 'y': 0, 'z': 0.027027512165087225})\r\n\r\n```"},{"labels":["bug"],"text":"## Expected behavior\r\n\r\nThe following test should succeed.\r\n```bash\r\ncircleci build --job doctest\r\n```\r\n\r\n## Environment\r\n\r\nPlease refer `.circleci/config.yml` and `setup.py`.\r\n\r\n## Error messages, stack traces, or logs\r\n\r\n```\r\n    ImportError: Scikit-Optimize is not available. Please install it to use this feature. Scikit-Optimize can be installed by executing `$ pip install scikit-optimize`. For further information, please refer to the installation guide of Scikit-Optimize. (The actual import error is as follows: cannot import name 'MaskedArray' from 'sklearn.utils.fixes' (/home/docs/project/venv/lib/python3.8/site-packages/sklearn/utils/fixes.py))\r\n```\r\n\r\n## Steps to reproduce\r\n\r\n1. ```pip install scikit-learn==0.23.0```\r\n2. ```pip install scikit-optimize```\r\n3. ```python -c \"import skopt\"```\r\n"},{"labels":["bug"],"text":"I cannot run the sample code for the CME-ES algorithm provided [here](https://optuna.readthedocs.io/en/stable/reference/samplers.html). It runs for one trial and then it outputs an out of bounds error.\r\n\r\n## Expected behavior\r\n\r\nTo perform optimization of the given objective function using the CMA-ES algorithm.\r\n\r\n## Environment\r\n\r\n- Optuna version: 1.4.0\r\n- Python version: 3.6.8\r\n- OS: Windows 10 x64\r\n- Other libraries and their versions: conda 4.8.2\r\n\r\n## Error messages, stack traces, or logs\r\n\r\n```\r\nTraceback (most recent call last):\r\n\r\n  File \"C:\\Users\\User\\work\\untitled0.py\", line 10, in <module>\r\n    study.optimize(objective, n_trials=20)\r\n\r\n  File \"C:\\Users\\User\\Anaconda3\\envs\\base_clone\\lib\\site-packages\\optuna\\study.py\", line 334, in optimize\r\n    func, n_trials, timeout, catch, callbacks, gc_after_trial, None\r\n\r\n  File \"C:\\Users\\User\\Anaconda3\\envs\\base_clone\\lib\\site-packages\\optuna\\study.py\", line 648, in _optimize_sequential\r\n    self._run_trial_and_callbacks(func, catch, callbacks, gc_after_trial)\r\n\r\n  File \"C:\\Users\\User\\Anaconda3\\envs\\base_clone\\lib\\site-packages\\optuna\\study.py\", line 678, in _run_trial_and_callbacks\r\n    trial = self._run_trial(func, catch, gc_after_trial)\r\n\r\n  File \"C:\\Users\\User\\Anaconda3\\envs\\base_clone\\lib\\site-packages\\optuna\\study.py\", line 695, in _run_trial\r\n    trial = trial_module.Trial(self, trial_id)\r\n\r\n  File \"C:\\Users\\User\\Anaconda3\\envs\\base_clone\\lib\\site-packages\\optuna\\trial.py\", line 409, in __init__\r\n    self._init_relative_params()\r\n\r\n  File \"C:\\Users\\User\\Anaconda3\\envs\\base_clone\\lib\\site-packages\\optuna\\trial.py\", line 420, in _init_relative_params\r\n    self.study, trial, self.relative_search_space\r\n\r\n  File \"C:\\Users\\User\\Anaconda3\\envs\\base_clone\\lib\\site-packages\\optuna\\samplers\\cmaes.py\", line 175, in sample_relative\r\n    optimizer = self._restore_or_init_optimizer(completed_trials, search_space, ordered_keys)\r\n\r\n  File \"C:\\Users\\User\\Anaconda3\\envs\\base_clone\\lib\\site-packages\\optuna\\samplers\\cmaes.py\", line 251, in _restore_or_init_optimizer\r\n    seed=self._cma_rng.randint(1, 2 ** 32),\r\n\r\n  File \"mtrand.pyx\", line 745, in numpy.random.mtrand.RandomState.randint\r\n\r\n  File \"_bounded_integers.pyx\", line 1360, in numpy.random._bounded_integers._rand_int32\r\n\r\nValueError: high is out of bounds for int32\r\n```\r\n\r\n## Steps to reproduce\r\n\r\n1. Run the code provided below.\r\n\r\n## Reproducible examples\r\n\r\n```python\r\nimport optuna\r\n\r\ndef objective(trial):\r\n    x = trial.suggest_uniform('x', -1, 1)\r\n    y = trial.suggest_int('y', -1, 1)\r\n    return x ** 2 + y\r\n\r\nsampler = optuna.samplers.CmaEsSampler()\r\nstudy = optuna.create_study(sampler=sampler)\r\nstudy.optimize(objective, n_trials=20)\r\n```\r\n"},{"labels":["bug"],"text":"Setting status of trial#28 as TrialState.FAIL because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 88.00 MiB (GPU 0; 10.76 GiB total capacity; 9.77 GiB already allocated; 9.25 MiB free; 9.67 MiB cached)',)\r\n"},{"labels":["bug",null],"text":"An extra indent appears in the docs when the [`experimental`](https://github.com/optuna/optuna/blob/2d5f24b06eed56ece72b8dfa878135bb4bb63779/optuna/_experimental.py#L60) decorator is added to a method of a class. This does not happen with a top level (i.e., not nested) class or function.\r\n\r\n## Steps to reproduce\r\n\r\n1. add an `experimental` decorator to a method of a class\r\n2. make the document\r\n\r\n## Reproducible examples\r\nThe following figure shows the docs of [`Study.enqueue_trial`](https://optuna.readthedocs.io/en/latest/reference/study.html#optuna.study.Study.enqueue_trial). An extra indent appears after the second paragraph.\r\n\r\n![image](https://user-images.githubusercontent.com/1061922/81144389-e6f32f80-8fae-11ea-8dd2-33368293dafa.png)\r\n\r\n## Expected behavior\r\nno extra indent is shown after the second paragraph\r\n\r\nFor example, the docs of [`Study.get_trials`](https://optuna.readthedocs.io/en/latest/reference/study.html#optuna.study.Study.get_trials), which does not have the `experimental` decorator, appears as expected.\r\n\r\n![image](https://user-images.githubusercontent.com/1061922/81143489-f1142e80-8fac-11ea-9896-e56086228168.png)\r\n\r\nThe following figure shows another example. The docs of the [`train`](https://optuna.readthedocs.io/en/latest/reference/integration.html#optuna.integration.lightgbm.train) function of LightGBMTuner has no extra indent. Although the function has an `experimental` decorator, it belongs to the top level classes.\r\n\r\n![image](https://user-images.githubusercontent.com/1061922/81146606-98945f80-8fb3-11ea-8d67-5cf1cfbf8768.png)\r\n"},{"labels":["bug"],"text":"<!-- Please write a clear and concise description of what the bug is. -->\r\n\r\nWhen passing multiple callbacks to `MultiObjectiveStudy.optimize`, it uses only the last callback.\r\n\r\n```python\r\nimport optuna\r\n\r\n\r\nn_objectives = 2\r\ndirections = [\"minimize\" for _ in range(n_objectives)]\r\nstudy = optuna.multi_objective.create_study(directions)\r\n\r\n\r\ndef objective(trial):\r\n    return [trial.suggest_uniform(\"v{}\".format(i), 0, 5) for i in range(n_objectives)]\r\n\r\n\r\ncallbacks = [\r\n    lambda a, b: print(\"first callback\"),\r\n    lambda a, b: print(\"second callback\"),\r\n]\r\n\r\nstudy.optimize(objective, n_trials=10, callbacks=callbacks)\r\n```\r\n\r\nThis code outputs:\r\n\r\n```\r\n[I 2020-05-06 12:56:02,205] Finished trial#0 with values: [0.030503339013888686, 0.457606610954287] with parameters: {'v0': 0.030503339013888686, 'v1': 0.457606610954287}.\r\nsecond callback\r\nsecond callback\r\n[I 2020-05-06 12:56:02,243] Finished trial#1 with values: [3.7186248349736672, 1.8148814699741478] with parameters: {'v0': 3.7186248349736672, 'v1': 1.8148814699741478}.\r\nsecond callback\r\nsecond callback\r\n[I 2020-05-06 12:56:02,283] Finished trial#2 with values: [4.386752523520264, 1.180154220379264] with parameters: {'v0': 4.386752523520264, 'v1': 1.180154220379264}.\r\nsecond callback\r\nsecond callback\r\n...\r\n```\r\n\r\nColab notebook that reproduces this bug:\r\nhttps://colab.research.google.com/drive/1YeT8ItU9IO65wXsqY9k-_ATCrCBW0BRZ?usp=sharing\r\n\r\n\r\n## Expected behavior\r\n\r\nThe output is expected to be:\r\n\r\n```\r\n[I 2020-05-06 12:56:02,205] Finished trial#0 with values: [0.030503339013888686, 0.457606610954287] with parameters: {'v0': 0.030503339013888686, 'v1': 0.457606610954287}.\r\nfirst callback\r\nsecond callback\r\n[I 2020-05-06 12:56:02,243] Finished trial#1 with values: [3.7186248349736672, 1.8148814699741478] with parameters: {'v0': 3.7186248349736672, 'v1': 1.8148814699741478}.\r\nfirst callback\r\nsecond callback\r\n[I 2020-05-06 12:56:02,283] Finished trial#2 with values: [4.386752523520264, 1.180154220379264] with parameters: {'v0': 4.386752523520264, 'v1': 1.180154220379264}.\r\nfirst callback\r\nsecond callback\r\n...\r\n```\r\n## Environment\r\n\r\n- Optuna version: master branch\r\n- Python version: 3.6.9\r\n- OS: linux\r\n- (Optional) Other libraries and their versions:\r\n\r\n## Error messages, stack traces, or logs\r\n\r\n```\r\n# error messages, stack traces, or logs\r\n```\r\n\r\n## Steps to reproduce\r\n\r\n1.\r\n2.\r\n3.\r\n\r\n## Reproducible examples (optional)\r\n\r\n\r\n## Additional context (optional)\r\n\r\n<!-- Please add any other context or screenshots about the problem here. -->\r\n\r\nI found this bug on https://lgtm.com/projects/g/optuna/optuna/?mode=list"},{"labels":["bug",null],"text":"After finished study.optimize call to `get_param_importances` returns different (and seems to be random) values each call.\r\n\r\n## Expected behavior\r\nThe values of importances must be the same.\r\n\r\n## Environment\r\n- Optuna version: 1.3.0\r\n- Python version: 3.7.5\r\n- OS: ubuntu 19.10\r\n\r\n## Reproducible examples (based on examples/sklearn_simple.py)\r\n```import sklearn.datasets\r\nimport sklearn.ensemble\r\nimport sklearn.model_selection\r\nimport sklearn.svm\r\nimport optuna\r\n\r\niris = sklearn.datasets.load_iris()\r\nx, y = iris.data, iris.target\r\n\r\ndef objective(trial):\r\n    classifier = trial.suggest_categorical(\"classifier\", [\"SVC\", \"RandomForest\"]),\r\n    value = trial.suggest_loguniform(\"value\", 2, 100)\r\n        \r\n    if classifier == \"SVC\":\r\n        svc_c = value\r\n        classifier_obj = sklearn.svm.SVC(C=svc_c, gamma=\"auto\")\r\n        \r\n    else:\r\n        rf_max_depth = int(value)\r\n        classifier_obj = sklearn.ensemble.RandomForestClassifier(max_depth=rf_max_depth, n_estimators=10)\r\n\r\n    score = sklearn.model_selection.cross_val_score(classifier_obj, x, y, n_jobs=16, cv=3)\r\n    accuracy = score.mean()\r\n    return accuracy\r\n\r\nif __name__ == \"__main__\":\r\n    study = optuna.create_study(direction=\"maximize\")\r\n    study.optimize(objective, n_trials=100, show_progress_bar=True)\r\n    print(study.best_trial)\r\n\r\n    # this calls must return same values each time\r\n    print (optuna.importance.get_param_importances(study))\r\n    print (optuna.importance.get_param_importances(study))\r\n```\r\nOrderedDict([('value', 0.7264216630695697), ('classifier', 0.2735783369304302)])\r\nOrderedDict([('value', 0.5280329436543916), ('classifier', 0.47196705634560837)])\r\n"},{"labels":["bug"],"text":"I have tried to run the code from the [pytorch_lightning_simple](https://github.com/optuna/optuna/blob/master/examples/pytorch_lightning_simple.py) example for my own model, but get attribute errors with the `LightningModule`.\r\n\r\n## Expected behavior\r\n\r\nI expect the code from the example to run without errors.\r\n## Environment\r\n\r\n- Optuna version: 1.3.0\r\n- Python version: 3.7\r\n- OS: macOS Catalina Version 10.15.3 \r\n- (Optional) Other libraries and their versions: pytorch_lightning : 0.7.5\r\n\r\n## Error messages, stack traces, or logs\r\n```\r\n[W 2020-04-29 14:29:15,613] Setting status of trial#0 as TrialState.FAIL because of the following error: TypeError(\"Can't instantiate abstract class LightningNet with abstract methods forward\")\r\nTraceback (most recent call last):\r\n  File \"/Users/Hendrik/opt/anaconda3/lib/python3.7/site-packages/optuna/study.py\", line 677, in _run_trial\r\n    result = func(trial)\r\n  File \"/Users/Hendrik/Desktop/larry1/min_working.py\", line 172, in objective\r\n    model = LightningNet(train_dataset, val_dataset, trial)\r\nTypeError: Can't instantiate abstract class LightningNet with abstract methods forward\r\nTraceback (most recent call last):\r\n  File \"/Users/Hendrik/opt/anaconda3/lib/python3.7/site-packages/optuna/study.py\", line 331, in optimize\r\n    func, n_trials, timeout, catch, callbacks, gc_after_trial, None\r\n  File \"/Users/Hendrik/opt/anaconda3/lib/python3.7/site-packages/optuna/study.py\", line 626, in _optimize_sequential\r\n    self._run_trial_and_callbacks(func, catch, callbacks, gc_after_trial)\r\n  File \"/Users/Hendrik/opt/anaconda3/lib/python3.7/site-packages/optuna/study.py\", line 656, in _run_trial_and_callbacks\r\n    trial = self._run_trial(func, catch, gc_after_trial)\r\n  File \"/Users/Hendrik/opt/anaconda3/lib/python3.7/site-packages/optuna/study.py\", line 677, in _run_trial\r\n    result = func(trial)\r\n  File \"/Users/Hendrik/Desktop/larry1/min_working.py\", line 172, in objective\r\n    model = LightningNet(train_dataset, val_dataset, trial)\r\nTypeError: Can't instantiate abstract class LightningNet with abstract methods forward\r\n\r\n```\r\n## Steps to reproduce\r\nRun the minimal working example to reproduce the error.\r\n## Reproducible examples (optional)\r\n\r\n```python\r\nimport os\r\n\r\nimport numpy as np\r\nimport optuna\r\nimport pkg_resources\r\nimport pytorch_lightning as pl\r\nimport torch\r\nfrom optuna.integration import PyTorchLightningPruningCallback\r\nfrom pytorch_lightning.logging import LightningLoggerBase\r\nfrom torch.utils.data import DataLoader, Dataset\r\n\r\n\r\nclass MyDataset(Dataset):\r\n    def __init__(self, data, labels):\r\n        super(MyDataset, self).__init__()\r\n        self.data = data\r\n        self.labels = labels\r\n\r\n    def __len__(self):\r\n        return len(self.data)\r\n\r\n    def __getitem__(self, item):\r\n        return torch.from_numpy(self.data[item][None, ...]).float(), torch.from_numpy(self.labels[item]).float()\r\n\r\nx_train = x_val = [np.ones((12,35)) for i in range(5)]\r\ny_train = y_val = [np.ones((1,11)) for i in range(5)]\r\n\r\ntrain_dataset = MyDataset(x_train, y_train)\r\nval_dataset = MyDataset(x_val, y_val)\r\n\r\nif pkg_resources.parse_version(pl.__version__) < pkg_resources.parse_version(\"0.6.0\"):\r\n    raise RuntimeError(\"PyTorch Lightning>=0.6.0 is required for this example.\")\r\n\r\nclass DictLogger(LightningLoggerBase):\r\n    \"\"\"PyTorch Lightning `dict` logger.\"\"\"\r\n\r\n    def __init__(self, version):\r\n        super(DictLogger, self).__init__()\r\n        self.metrics = []\r\n        self._version = version\r\n\r\n    def log_metrics(self, metrics, step=None):\r\n        self.metrics.append(metrics)\r\n\r\n    @property\r\n    def version(self):\r\n        return self._version\r\n\r\n    @property\r\n    def experiment(self):\r\n        \"\"\"Return the experiment object associated with this logger.\"\"\"\r\n\r\n    def log_hyperparams(self, params):\r\n        \"\"\"\r\n        Record hyperparameters.\r\n        Args:\r\n            params: :class:`~argparse.Namespace` containing the hyperparameters\r\n        \"\"\"\r\n\r\n    @property\r\n    def name(self):\r\n        \"\"\"Return the experiment name.\"\"\"\r\n        return 'optuna'\r\n\r\nclass Flatten(torch.nn.Module):\r\n    def __init__(self):\r\n        super(Flatten, self).__init__()\r\n\r\n    def forward(self, x):\r\n        batch_size = x.shape[0]\r\n        return x.view(batch_size, -1)\r\n\r\nclass Net1(torch.nn.Module):\r\n    def __init__(self, trial):\r\n        super(Net1, self).__init__()\r\n\r\n        kernel_size1 = trial.suggest_int('kernel_size1', 2, 7)\r\n        kernel_size2 = trial.suggest_int('kernel_size2', 1, 16)\r\n        num_params = ((12 - kernel_size1 + 1) // 2) * ((35 - kernel_size2 + 1) // 1) * 64\r\n        self.network = torch.nn.Sequential(\r\n            torch.nn.Conv2d(1, 64, kernel_size=(kernel_size1, kernel_size2), stride=1, padding=0),\r\n            torch.nn.ReLU(inplace=True),\r\n            torch.nn.MaxPool2d((2, 1)),\r\n            Flatten(),\r\n            torch.nn.Linear(num_params, 50),\r\n            torch.nn.ReLU(inplace=True),\r\n            torch.nn.Linear(50, 11),\r\n            torch.nn.Sigmoid()\r\n        )\r\n\r\n    def forward(self, x):\r\n        return self.network(x)\r\n\r\nclass LightningNet(pl.LightningModule):\r\n    def __init__(self, train_dataset, val_dataset, trial):\r\n        super(LightningNet, self).__init__()\r\n        self.train_dataset = train_dataset\r\n        self.val_dataset = val_dataset\r\n        # Be careful not to overwrite `pl.LightningModule` attributes such as `self.model`.\r\n        self._model = Net1(trial)\r\n    def train_dataloader(self):\r\n        return DataLoader(self.train_dataset, batch_size=2048, num_workers=16)\r\n\r\n    def val_dataloader(self):\r\n        return DataLoader(self.val_dataset, batch_size=2048, num_workers=16)\r\n\r\n    def configure_optimizers(self):\r\n        return torch.optim.Adam(self.parameters(), lr=1e-4)\r\n\r\n    def training_step(self, batch, batch_index):\r\n        data, target = batch\r\n        output = self.forward(data)\r\n        loss = self.dice_loss(output, target)\r\n        logs = {'train_loss': loss}\r\n        return {'loss': loss, 'log': logs}\r\n\r\n    def validation_step(self, batch, batch_index):\r\n        data, target = batch\r\n        output = self.forward(data)\r\n        loss = self.dice_loss(output, target)\r\n        return {'val_loss': loss}\r\n\r\n    def validation_epoch_end(self, outputs):\r\n        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\r\n        tensorboard_logs = {'val_loss': avg_loss}\r\n        self.val_loss = avg_loss\r\n        return {'val_loss': avg_loss, 'log': tensorboard_logs}\r\n\r\n    def dice_loss(self, input, target):\r\n        smooth = 1.\r\n\r\n        iflat = input.view(-1)\r\n        tflat = target.view(-1)\r\n        intersection = (iflat * tflat).sum()\r\n\r\n        return 1 - ((2. * intersection + smooth) /\r\n                    (iflat.sum() + tflat.sum() + smooth))\r\n\r\n    # def forward(self, x):\r\n    #     return self._model(x)\r\n    #\r\n    # def get(self, item):\r\n    #     return self.__dict__[item]\r\n\r\nif not os.path.exists('optuna_dir'):\r\n    os.mkdir('optuna_dir')\r\n\r\nEPOCHS = 100\r\nDIR = 'optuna_dir'\r\nMODEL_DIR = os.path.join(DIR, \"result\")\r\n\r\n\r\ndef objective(trial):\r\n    # PyTorch Lightning will try to restore model parameters from previous trials if checkpoint\r\n    # filenames match. Therefore, the filenames for each trial must be made unique.\r\n    checkpoint_callback = pl.callbacks.ModelCheckpoint(\r\n        os.path.join(MODEL_DIR, \"trial_{}\".format(trial.number)), monitor=\"val_loss\"\r\n    )\r\n\r\n    # The default logger in PyTorch Lightning writes to event files to be consumed by\r\n    # TensorBoard. We create a simple logger instead that holds the log in memory so that the\r\n    # final accuracy can be obtained after optimization. When using the default logger, the\r\n    # final accuracy could be stored in an attribute of the `Trainer` instead.\r\n    logger = DictLogger(trial.number)\r\n\r\n    trainer = pl.Trainer(\r\n        logger=logger,\r\n        checkpoint_callback=checkpoint_callback,\r\n        max_epochs=EPOCHS,\r\n        gpus=0 if torch.cuda.is_available() else None,\r\n        early_stop_callback = PyTorchLightningPruningCallback(trial, monitor=\"val_loss\"),\r\n    )\r\n    model = LightningNet(train_dataset, val_dataset, trial)\r\n    trainer.fit(model)\r\n    return logger.metrics[-1][\"val_loss\"]\r\n\r\n\r\npruner = optuna.pruners.MedianPruner()\r\n\r\nstudy = optuna.create_study(direction=\"minimize\", pruner=pruner)\r\nstudy.optimize(objective, n_trials=100, timeout=600)\r\n\r\nprint(\"Number of finished trials: {}\".format(len(study.trials)))\r\n\r\nprint(\"Best trial:\")\r\ntrial = study.best_trial\r\n\r\nprint(\"  Value: {}\".format(trial.value))\r\n\r\nprint(\"  Params: \")\r\nfor key, value in trial.params.items():\r\n    print(\"    {}: {}\".format(key, value))\r\n```\r\n\r\n## Additional context (optional)\r\n\r\nResolving the abstract class conflicts by adding a `forward` and a `get` function to the LightningNet class (commented out in the minimal working example) results in following errors:\r\n```\r\n[W 2020-04-29 14:35:40,296] Setting status of trial#0 as TrialState.FAIL because of the following error: TypeError(\"'<' not supported between instances of 'Trainer' and 'int'\")\r\nTraceback (most recent call last):\r\n  File \"/Users/Hendrik/opt/anaconda3/lib/python3.7/site-packages/optuna/study.py\", line 677, in _run_trial\r\n    result = func(trial)\r\n  File \"/Users/Hendrik/Desktop/larry1/min_working.py\", line 174, in objective\r\n    trainer.fit(model)\r\n  File \"/Users/Hendrik/opt/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 793, in fit\r\n    self.run_pretrain_routine(model)\r\n  File \"/Users/Hendrik/opt/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 913, in run_pretrain_routine\r\n    self.train()\r\n  File \"/Users/Hendrik/opt/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\", line 347, in train\r\n    self.run_training_epoch()\r\n  File \"/Users/Hendrik/opt/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\", line 453, in run_training_epoch\r\n    self.call_early_stop_callback()\r\n  File \"/Users/Hendrik/opt/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\", line 793, in call_early_stop_callback\r\n    self.early_stop_callback.on_epoch_end(self, self.get_model())\r\n  File \"/Users/Hendrik/opt/anaconda3/lib/python3.7/site-packages/optuna/integration/pytorch_lightning.py\", line 61, in on_epoch_end\r\n    self._trial.report(current_score, step=epoch)\r\n  File \"/Users/Hendrik/opt/anaconda3/lib/python3.7/site-packages/optuna/trial.py\", line 597, in report\r\n    if step < 0:\r\nTypeError: '<' not supported between instances of 'Trainer' and 'int'\r\nTraceback (most recent call last):\r\n  File \"/Users/Hendrik/opt/anaconda3/lib/python3.7/site-packages/optuna/study.py\", line 331, in optimize\r\n    func, n_trials, timeout, catch, callbacks, gc_after_trial, None\r\n  File \"/Users/Hendrik/opt/anaconda3/lib/python3.7/site-packages/optuna/study.py\", line 626, in _optimize_sequential\r\n    self._run_trial_and_callbacks(func, catch, callbacks, gc_after_trial)\r\n  File \"/Users/Hendrik/opt/anaconda3/lib/python3.7/site-packages/optuna/study.py\", line 656, in _run_trial_and_callbacks\r\n    trial = self._run_trial(func, catch, gc_after_trial)\r\n  File \"/Users/Hendrik/opt/anaconda3/lib/python3.7/site-packages/optuna/study.py\", line 677, in _run_trial\r\n    result = func(trial)\r\n  File \"/Users/Hendrik/Desktop/larry1/min_working.py\", line 174, in objective\r\n    trainer.fit(model)\r\n  File \"/Users/Hendrik/opt/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 793, in fit\r\n    self.run_pretrain_routine(model)\r\n  File \"/Users/Hendrik/opt/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 913, in run_pretrain_routine\r\n    self.train()\r\n  File \"/Users/Hendrik/opt/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\", line 347, in train\r\n    self.run_training_epoch()\r\n  File \"/Users/Hendrik/opt/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\", line 453, in run_training_epoch\r\n    self.call_early_stop_callback()\r\n  File \"/Users/Hendrik/opt/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\", line 793, in call_early_stop_callback\r\n    self.early_stop_callback.on_epoch_end(self, self.get_model())\r\n  File \"/Users/Hendrik/opt/anaconda3/lib/python3.7/site-packages/optuna/integration/pytorch_lightning.py\", line 61, in on_epoch_end\r\n    self._trial.report(current_score, step=epoch)\r\n  File \"/Users/Hendrik/opt/anaconda3/lib/python3.7/site-packages/optuna/trial.py\", line 597, in report\r\n    if step < 0:\r\nTypeError: '<' not supported between instances of 'Trainer' and 'int'\r\n\r\n```"},{"labels":["bug",null],"text":"I noticed `optuna.visualization.plot_contour` show a plot without its title.\r\n\r\n<img width=\"913\" alt=\"Screen Shot 2020-04-28 at 10 49 53\" src=\"https://user-images.githubusercontent.com/5164000/80437965-01d5fc00-893e-11ea-896a-343b2e51bc90.png\">\r\n\r\nI think it's better to show a title to be consistent with other plot features such as `optuna.visualization.plot_optimization_history` and `optuna.visualization.plot_slice`.\r\n\r\nWe can reproduce this behavior in the [official quickstart](https://colab.research.google.com/github/optuna/optuna/blob/master/examples/quickstart.ipynb)\r\n\r\n## Expected behavior\r\n\r\nShow title of a figure in the contour plot.\r\n\r\n## Environment\r\n\r\n- Optuna version: 1.3.0\r\n- Python version: 3.6.9\r\n- OS: Ubuntu 18.04.3 LTS\r\n\r\n## Steps to reproduce\r\n\r\nRun notebook on [Google Colab](https://colab.research.google.com/github/optuna/optuna/blob/master/examples/quickstart.ipynb)."},{"labels":[null,"bug"],"text":"<!-- Please write a clear and concise description of what the bug is. -->\r\nCI failed to install pytorch CPU 1.4.0 in https://github.com/optuna/optuna/pull/1086/commits/f52aebb2f11147e903d0014b7b384e705b631bc1's CI.\r\n\r\n## Error messages, stack traces, or logs\r\n[build_36874_step_103_container_0.txt](https://github.com/optuna/optuna/files/4495905/build_36874_step_103_container_0.txt)\r\n\r\nCI: https://circleci.com/gh/optuna/optuna/36874?utm_campaign=vcs-integration-link&utm_medium=referral&utm_source=github-build-link\r\n\r\nIt might be due to the version specification introduced by #1118 and/or #1124.\r\n\r\n\r\n<!-- Please add any other context or screenshots about the problem here. -->\r\n\r\nCC: @hvy "},{"labels":["bug"],"text":"Error message running https://github.com/optuna/optuna/blob/master/examples/pruning/simple.py\r\nOn Optuna 1.3\r\n\r\n```Traceback (most recent call last):\r\n  File \"simple.py\", line 52, in <module>\r\n    pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\r\n  File \"simple.py\", line 52, in <listcomp>\r\n    pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\r\nAttributeError: module 'optuna.trial' has no attribute 'TrialState'\r\n```\r\n\r\nShould be `optuna.structs.TrialState.PRUNED`?"},{"labels":["bug",null],"text":"## Expected behavior\r\n\r\nFinished studies do not consume database resources.\r\n\r\n## Environment\r\n\r\n- Optuna version: 1.3.0\r\n- Python version: 3.5\r\n- OS: Ubuntu 18.04\r\n- MySQL (docker): `mysql:8.0.19` (localhost)\r\n\r\n## Error messages, stack traces, or logs\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"path/to/venv/lib/python3.5/site-packages/sqlalchemy/engine/base.py\", line 2285, in _wrap_pool_connect\r\n    return fn()\r\n  File \"path/to/venv/lib/python3.5/site-packages/sqlalchemy/pool/base.py\", line 363, in connect\r\n    return _ConnectionFairy._checkout(self)\r\n  File \"path/to/venv/lib/python3.5/site-packages/sqlalchemy/pool/base.py\", line 773, in _checkout\r\n    fairy = _ConnectionRecord.checkout(pool)\r\n  File \"path/to/venv/lib/python3.5/site-packages/sqlalchemy/pool/base.py\", line 492, in checkout\r\n    rec = pool._do_get()\r\n  File \"path/to/venv/lib/python3.5/site-packages/sqlalchemy/pool/impl.py\", line 139, in _do_get\r\n    self._dec_overflow()\r\n  File \"path/to/venv/lib/python3.5/site-packages/sqlalchemy/util/langhelpers.py\", line 69, in __exit__\r\n    exc_value, with_traceback=exc_tb,\r\n  File \"path/to/venv/lib/python3.5/site-packages/sqlalchemy/util/compat.py\", line 178, in raise_\r\n    raise exception\r\n  File \"path/to/venv/lib/python3.5/site-packages/sqlalchemy/pool/impl.py\", line 136, in _do_get\r\n    return self._create_connection()\r\n  File \"path/to/venv/lib/python3.5/site-packages/sqlalchemy/pool/base.py\", line 308, in _create_connection\r\n    return _ConnectionRecord(self)\r\n  File \"path/to/venv/lib/python3.5/site-packages/sqlalchemy/pool/base.py\", line 437, in __init__\r\n    self.__connect(first_connect_check=True)\r\n  File \"path/to/venv/lib/python3.5/site-packages/sqlalchemy/pool/base.py\", line 657, in __connect\r\n    pool.logger.debug(\"Error on connect(): %s\", e)\r\n  File \"path/to/venv/lib/python3.5/site-packages/sqlalchemy/util/langhelpers.py\", line 69, in __exit__\r\n    exc_value, with_traceback=exc_tb,\r\n  File \"path/to/venv/lib/python3.5/site-packages/sqlalchemy/util/compat.py\", line 178, in raise_\r\n    raise exception\r\n  File \"path/to/venv/lib/python3.5/site-packages/sqlalchemy/pool/base.py\", line 652, in __connect\r\n    connection = pool._invoke_creator(self)\r\n  File \"path/to/venv/lib/python3.5/site-packages/sqlalchemy/engine/strategies.py\", line 114, in connect\r\n    return dialect.connect(*cargs, **cparams)\r\n  File \"path/to/venv/lib/python3.5/site-packages/sqlalchemy/engine/default.py\", line 488, in connect\r\n    return self.dbapi.connect(*cargs, **cparams)\r\n  File \"path/to/venv/lib/python3.5/site-packages/pymysql/__init__.py\", line 94, in Connect\r\n    return Connection(*args, **kwargs)\r\n  File \"path/to/venv/lib/python3.5/site-packages/pymysql/connections.py\", line 325, in __init__\r\n    self.connect()\r\n  File \"path/to/venv/lib/python3.5/site-packages/pymysql/connections.py\", line 598, in connect\r\n    self._get_server_information()\r\n  File \"path/to/venv/lib/python3.5/site-packages/pymysql/connections.py\", line 975, in _get_server_information\r\n    packet = self._read_packet()\r\n  File \"path/to/venv/lib/python3.5/site-packages/pymysql/connections.py\", line 684, in _read_packet\r\n    packet.check_error()\r\n  File \"path/to/venv/lib/python3.5/site-packages/pymysql/protocol.py\", line 220, in check_error\r\n    err.raise_mysql_exception(self._data)\r\n  File \"path/to/venv/lib/python3.5/site-packages/pymysql/err.py\", line 109, in raise_mysql_exception\r\n    raise errorclass(errno, errval)\r\npymysql.err.OperationalError: (1040, 'Too many connections')\r\n```\r\n\r\n## Steps to reproduce\r\n\r\n1. Use MySQL backend.\r\n2. Create multiple studies from a single process. \r\n\r\n## Reproducible examples (optional)\r\n\r\n```python\r\nimport argparse\r\nimport math\r\nimport sys\r\n\r\nimport sqlalchemy\r\nfrom sqlalchemy.sql import text\r\n\r\nimport optuna\r\n\r\n\r\nN_STUDY = 10000\r\nN_TRIAL = 2\r\n\r\n\r\ndef objective(trial):\r\n    ret = 0.0\r\n    for i in range(10):\r\n        ret += math.sin(\r\n            trial.suggest_float('param-{}'.format(i), 0, math.pi * 2))\r\n    return ret\r\n\r\n\r\ndef run(storage, i):\r\n    study = optuna.create_study(\r\n        storage=storage, study_name=\"study-{}\".format(i), load_if_exists=True)\r\n    study.optimize(objective, n_trials=N_TRIAL, show_progress_bar=False)\r\n\r\n\r\ndef define_flags(parser):\r\n    parser.add_argument('mysql_user', type=str)\r\n    parser.add_argument('mysql_password', type=str)\r\n    parser.add_argument('mysql_host', type=str)\r\n    parser.add_argument('mysql_database', type=str)\r\n    return parser\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    parser = define_flags(argparse.ArgumentParser())\r\n    args = parser.parse_args()\r\n\r\n    storage = 'mysql+pymysql://{}:{}@{}/{}'.format(\r\n        args.mysql_user,\r\n        args.mysql_password,\r\n        args.mysql_host,\r\n        args.mysql_database,\r\n    )\r\n    engine = sqlalchemy.create_engine(storage)\r\n    conn = engine.connect()\r\n    # mysql specific\r\n    get_connection_cnt = text(\"show status where `Variable_name` = 'Threads_connected'\")\r\n\r\n    for t in range(N_STUDY):\r\n        conn_cnt = conn.execute(get_connection_cnt).fetchall()\r\n        sys.stdout.write(\r\n            '\\r{:0>5}/{:0>5} studies finished. Current connection: {}'.format(\r\n                t, N_STUDY, conn_cnt\r\n            ))\r\n        run(storage, t)\r\n    print('All studies successfully finished.' + ' ' * 20)\r\n\r\n    conn.close()\r\n```\r\n\r\n## Additional context (optional)\r\n\r\nCalling `study._storage.engine.dispose()` at the end of the `run` function prevents the increase of connections.\r\n"},{"labels":["bug"],"text":"When spawning multiple studies with the same postgres backend,\r\nthe script crashes because each process tries to create the db table.\r\n\r\n## Expected behavior\r\n\r\ndb lock, no crash.\r\n\r\n## Environment\r\n\r\n- Optuna version: 1.2.0\r\n- Python version: 3.8\r\n\r\n## Error messages, stack traces, or logs\r\n\r\n```\r\n..\r\nsqlalchemy.exc.ProgrammingError: ... relation \"alembic_version\" already exists\r\n..\r\nsqlalchemy.exc.IntegrityError: ... duplicate key value violates unique constraint \"pg_type_typename_nsp_index\"\r\n..\r\n```\r\n\r\n## Steps to reproduce\r\n\r\n```\r\n[delete optuna db tables]\r\npython exp.py exp1 &\r\npython exp.py exp2 &\r\npython exp.py exp3 &\r\n```\r\n\r\n## Additional context (optional)\r\nonly tried postgres"},{"labels":["bug",null],"text":"## Environment\r\n\r\n- Optuna version: 1.2.0\r\n- Python version: 3.7.2\r\n- OS: macOS 10.13.6\r\n- (Optional) Other libraries and their versions: pytorch_lightning==0.7.1\r\n\r\n## Error messages, stack traces, or logs\r\n\r\n```console\r\npytest tests/test_cli.py\r\n```\r\n\r\n```console\r\ntests/test_cli.py:224: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\npopenargs = (['optuna', 'dashboard', '--study', 'no-name-eeca02bc-68ac-4d96-9805-370fc70e13ac', '--out', '/tmp/tmpzkcptkmq', ...],)\r\nkwargs = {}, retcode = 2\r\ncmd = ['optuna', 'dashboard', '--study', 'no-name-eeca02bc-68ac-4d96-9805-370fc70e13ac', '--out', '/tmp/tmpzkcptkmq', ...]\r\n\r\n    def check_call(*popenargs, **kwargs):\r\n        \"\"\"Run command with arguments.  Wait for command to complete.  If\r\n        the exit code was zero then return, otherwise raise\r\n        CalledProcessError.  The CalledProcessError object will have the\r\n        return code in the returncode attribute.\r\n    \r\n        The arguments are the same as for the call function.  Example:\r\n    \r\n        check_call([\"ls\", \"-l\"])\r\n        \"\"\"\r\n        retcode = call(*popenargs, **kwargs)\r\n        if retcode:\r\n            cmd = kwargs.get(\"args\")\r\n            if cmd is None:\r\n                cmd = popenargs[0]\r\n>           raise CalledProcessError(retcode, cmd)\r\nE           subprocess.CalledProcessError: Command '['optuna', 'dashboard', '--study', 'no-name-eeca02bc-68ac-4d96-9805-370fc70e13ac', '--out', '/tmp/tmpzkcptkmq', '--storage', 'sqlite:////tmp/tmp19f50p6m']' returned non-zero exit status 2.\r\n\r\n/usr/local/lib/python3.8/subprocess.py:364: CalledProcessError\r\n----------------------------- Captured stderr call -----------------------------\r\n[I 2020-03-09 03:53:42,580] A new study created with name: no-name-eeca02bc-68ac-4d96-9805-370fc70e13ac\r\n[W 2020-03-09 03:53:43,790] Optuna dashboard is still highly experimental. Please use with caution!\r\nusage: bokeh [-h] [-v]\r\n             {build,info,init,json,sampledata,secret,serve,static} ...\r\nbokeh: error: invalid choice: 'html' (choose from 'build', 'info', 'init', 'json', 'sampledata', 'secret', 'serve', 'static')\r\n```\r\n\r\n## Additional context (optional)\r\n\r\n- The dashboard is in the beta-phase. Do we update the current implementation? Or do we create a new one?"},{"labels":["bug",null,null],"text":"## Environment\r\n\r\n- Optuna version: 1.2.0\r\n- Python version: 3.7.2\r\n- OS: macOS 10.13.6\r\n- (Optional) Other libraries and their versions: pytorch_lightning==0.7.1\r\n\r\n## Error messages, stack traces, or logs\r\n\r\nCommand\r\n```console\r\npytest tests/integration_tests/test_pytorch_lightning.py\r\n```\r\n\r\nError message:\r\n```console\r\nself = <optuna.integration.pytorch_lightning.PyTorchLightningPruningCallback object at 0x7f2194069a20>\r\nlogs = {'accuracy': 0.0}\r\n\r\n    def check_metrics(self, logs):\r\n        monitor_val = logs.get(self.monitor)\r\n        error_msg = (f'Early stopping conditioned on metric `{self.monitor}`'\r\n                     f' which is not available. Available metrics are:'\r\n                     f' `{\"`, `\".join(list(logs.keys()))}`')\r\n    \r\n        if monitor_val is None:\r\n            if self.strict:\r\n>               raise RuntimeError(error_msg)\r\nE               RuntimeError: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: `accuracy`\r\n\r\nvenv/lib/python3.6/site-packages/pytorch_lightning/callbacks/early_stopping.py:81: RuntimeError\r\n\r\n```\r\n\r\n## Additional context\r\n\r\nThe base class of `PyTorchLightningPruningCallback` (i.e., `EarlyStopping`) is updated by 0.7.x.\r\nFor example,\r\n1. the `check_metrics` method is newly added, and\r\n1. the arguments of `on_epoch_end` are changed.\r\n\r\nFor further details, please refer to the following code:\r\n- https://github.com/PyTorchLightning/pytorch-lightning/blob/0.7.1/pytorch_lightning/callbacks/early_stopping.py\r\n- https://github.com/PyTorchLightning/pytorch-lightning/blob/0.5.3.3/pytorch_lightning/callbacks/pt_callbacks.py\r\n\r\nTo resolve this issue, we may need to consider backward compatibility. Do we support both v0.7.x and 0.5.x?"},{"labels":["bug"],"text":"<!-- Please write a clear and concise description of what the bug is. -->\r\n\r\n\r\n## Reproducible examples (optional)\r\n\r\n```python\r\nimport optuna\r\n\r\n# Define a simple 2-dimensional objective function whose minimum value is -1 when (x, y) = (0, -1).\r\ndef objective(trial):\r\n    x = trial.suggest_uniform('x', -100, 100)\r\n    y = trial.suggest_categorical('y', [-1, 0, 1])\r\n    return x**2 + y\r\n\r\n\r\nif __name__ == '__main__':\r\n    # Let us minimize the objective function above.\r\n    print('Running 10 trials...')\r\n    study = optuna.create_study(storage=\"sqlite:///db.sqlite3\")\r\n    study.optimize(objective, n_trials=10)\r\n    print('Best value: {} (params: {})\\n'.format(study.best_value, study.best_params))\r\n```\r\n\r\n## Expected behavior\r\n\r\ntag: v1.1.0\r\n\r\n```console\r\n$ git co v1.1.0\r\n$ python examples/quadratic_simple.py \r\nRunning 10 trials...\r\n[I 2020-02-18 14:05:57,875] A new study created with name: no-name-a2889f9d-79d7-40cc-aff4-f4021183b6aa\r\n[I 2020-02-18 14:05:57,977] Finished trial#0 resulted in value: 78.25382960871015. Current best value is 78.25382960871015 with parameters: {'x': -8.78941577175128, 'y': 1}.\r\n[I 2020-02-18 14:05:58,067] Finished trial#1 resulted in value: 1601.2080527969047. Current best value is 78.25382960871015 with parameters: {'x': -8.78941577175128, 'y': 1}.\r\n[I 2020-02-18 14:05:58,159] Finished trial#2 resulted in value: 155.3355136572432. Current best value is 78.25382960871015 with parameters: {'x': -8.78941577175128, 'y': 1}.\r\n[I 2020-02-18 14:05:58,252] Finished trial#3 resulted in value: 4928.445801453334. Current best value is 78.25382960871015 with parameters: {'x': -8.78941577175128, 'y': 1}.\r\n[I 2020-02-18 14:05:58,349] Finished trial#4 resulted in value: 5494.046052713425. Current best value is 78.25382960871015 with parameters: {'x': -8.78941577175128, 'y': 1}.\r\n[I 2020-02-18 14:05:58,451] Finished trial#5 resulted in value: 7.806334896764313. Current best value is 7.806334896764313 with parameters: {'x': -2.793981907021646, 'y': 0}.\r\n[I 2020-02-18 14:05:58,540] Finished trial#6 resulted in value: 3581.7294062867. Current best value is 7.806334896764313 with parameters: {'x': -2.793981907021646, 'y': 0}.\r\n[I 2020-02-18 14:05:58,633] Finished trial#7 resulted in value: 6157.892248662727. Current best value is 7.806334896764313 with parameters: {'x': -2.793981907021646, 'y': 0}.\r\n[I 2020-02-18 14:05:58,729] Finished trial#8 resulted in value: 538.9770074142994. Current best value is 7.806334896764313 with parameters: {'x': -2.793981907021646, 'y': 0}.\r\n[I 2020-02-18 14:05:58,824] Finished trial#9 resulted in value: 2453.3913002520094. Current best value is 7.806334896764313 with parameters: {'x': -2.793981907021646, 'y': 0}.\r\nBest value: 7.806334896764313 (params: {'x': -2.793981907021646, 'y': 0})\r\n```\r\n\r\n## Error log\r\n\r\nrev: 7344ee0f\r\n\r\n```console\r\n$ git co master\r\n$ rm db.sqlite3 | true && python examples/quadratic_simple.py \r\nRunning 10 trials...\r\n[I 2020-02-18 14:06:51,506] A new study created with name: no-name-32a1bb2f-64c7-4faa-8834-0bbdbaff508b\r\n[I 2020-02-18 14:06:51,635] Finished trial#0 resulted in value: 2420.888780807176. Current best value is 2420.888780807176 with parameters: {'x': -49.192365066208964, 'y': 1}.\r\n[I 2020-02-18 14:06:51,746] Finished trial#1 resulted in value: 145.24171551709355. Current best value is 145.24171551709355 with parameters: {'x': 12.093044096384233, 'y': -1}.\r\n[I 2020-02-18 14:06:51,857] Finished trial#2 resulted in value: 1.014598248626613. Current best value is 1.014598248626613 with parameters: {'x': -0.12082321228395188, 'y': 1}.\r\n[I 2020-02-18 14:06:51,957] Finished trial#3 resulted in value: 8577.24930691218. Current best value is 1.014598248626613 with parameters: {'x': -0.12082321228395188, 'y': 1}.\r\n[I 2020-02-18 14:06:52,068] Finished trial#4 resulted in value: 8417.027436775961. Current best value is 1.014598248626613 with parameters: {'x': -0.12082321228395188, 'y': 1}.\r\n[I 2020-02-18 14:06:52,181] Finished trial#5 resulted in value: 319.0475577707139. Current best value is 1.014598248626613 with parameters: {'x': -0.12082321228395188, 'y': 1}.\r\n[I 2020-02-18 14:06:52,288] Finished trial#6 resulted in value: 4.4949007058993296. Current best value is 1.014598248626613 with parameters: {'x': -0.12082321228395188, 'y': 1}.\r\n[I 2020-02-18 14:06:52,391] Finished trial#7 resulted in value: 2865.4595762936938. Current best value is 1.014598248626613 with parameters: {'x': -0.12082321228395188, 'y': 1}.\r\n[I 2020-02-18 14:06:52,500] Finished trial#8 resulted in value: 2027.0173870485705. Current best value is 1.014598248626613 with parameters: {'x': -0.12082321228395188, 'y': 1}.\r\n[I 2020-02-18 14:06:52,605] Finished trial#9 resulted in value: 7283.744078340451. Current best value is 1.014598248626613 with parameters: {'x': -0.12082321228395188, 'y': 1}.\r\nBest value: 1.014598248626613 (params: {'x': -0.12082321228395188, 'y': 1})\r\n\r\nException ignored in: <function RDBStorage.__del__ at 0x130bd7ca0>\r\nTraceback (most recent call last):\r\n  File \"/Users/a14737/src/github.com/pfnet/optuna/optuna/storages/rdb/storage.py\", line 943, in __del__\r\n  File \"/Users/a14737/src/github.com/pfnet/optuna/optuna/storages/rdb/storage.py\", line 932, in remove_session\r\n  File \"/Users/a14737/src/github.com/pfnet/optuna/venv/lib/python3.8/site-packages/SQLAlchemy-1.3.12-py3.8-macosx-10.15-x86_64.egg/sqlalchemy/orm/scoping.py\", line 94, in remove\r\n  File \"/Users/a14737/src/github.com/pfnet/optuna/venv/lib/python3.8/site-packages/SQLAlchemy-1.3.12-py3.8-macosx-10.15-x86_64.egg/sqlalchemy/orm/session.py\", line 1298, in close\r\n  File \"/Users/a14737/src/github.com/pfnet/optuna/venv/lib/python3.8/site-packages/SQLAlchemy-1.3.12-py3.8-macosx-10.15-x86_64.egg/sqlalchemy/orm/session.py\", line 1334, in _close_impl\r\n  File \"/Users/a14737/src/github.com/pfnet/optuna/venv/lib/python3.8/site-packages/SQLAlchemy-1.3.12-py3.8-macosx-10.15-x86_64.egg/sqlalchemy/orm/session.py\", line 1352, in expunge_all\r\nAttributeError: 'NoneType' object has no attribute 'InstanceState'\r\n\r\n```\r\n\r\n## Environment\r\n\r\n- Optuna version: 1.2.0 (master branch, rev: 7344ee0f).\r\n- Python version: 3.8.1\r\n- OS: macOS\r\n- (Optional) Other libraries and their versions:\r\n\r\n## Steps to reproduce\r\n\r\n1. Optimize with RDB storage backend.\r\n\r\n\r\n## Additional context (optional)\r\n\r\n<!-- Please add any other context or screenshots about the problem here. -->\r\n"},{"labels":["bug"],"text":"I suspect that the implementation of TPE with `DiscreteUniformDistribution` has a problem when building its surrogate model. To check the problem, I prepare the following simple snippet:\r\n\r\n```python\r\nimport optuna\r\nimport pprint\r\n\r\n\r\ndef objective(trial):\r\n    x = trial.suggest_discrete_uniform('x', -10, 10, q=2.0)\r\n    y = trial.suggest_discrete_uniform('y', -10, 10, q=2.0)\r\n    return (x-8)**2 + (y+8)**2\r\n\r\n\r\nif __name__ == '__main__':\r\n    study = optuna.create_study(sampler=optuna.samplers.TPESampler(seed=0))\r\n    study.optimize(objective, n_trials=40)\r\n    pprint.pprint([t.params for t in study.trials])\r\n    print('Best value: {} (params: {})\\n'.format(study.best_value, study.best_params))\r\n```\r\n\r\nThe best_params is `Best value: 8.0 (params: {'x': 6.0, 'y': -10.0})`. And the execution log is following.\r\n\r\n<details>\r\n\r\n<summary>execution log</summary>\r\n\r\n```console\r\n $ python examples/quadratic_simple.py \r\n[I 2020-02-12 12:26:48,488] Finished trial#0 resulted in value: 180.0. Current best value is 180.0 with parameters: {'x': 2.0, 'y': 4.0}.\r\n[I 2020-02-12 12:26:48,510] Finished trial#1 resulted in value: 100.0. Current best value is 100.0 with parameters: {'x': 2.0, 'y': 0.0}.\r\n[I 2020-02-12 12:26:48,533] Finished trial#2 resulted in value: 244.0. Current best value is 100.0 with parameters: {'x': 2.0, 'y': 0.0}.\r\n[I 2020-02-12 12:26:48,555] Finished trial#3 resulted in value: 356.0. Current best value is 100.0 with parameters: {'x': 2.0, 'y': 0.0}.\r\n[I 2020-02-12 12:26:48,579] Finished trial#4 resulted in value: 40.0. Current best value is 40.0 with parameters: {'x': 10.0, 'y': -2.0}.\r\n[I 2020-02-12 12:26:48,601] Finished trial#5 resulted in value: 68.0. Current best value is 40.0 with parameters: {'x': 10.0, 'y': -2.0}.\r\n[I 2020-02-12 12:26:48,624] Finished trial#6 resulted in value: 360.0. Current best value is 40.0 with parameters: {'x': 10.0, 'y': -2.0}.\r\n[I 2020-02-12 12:26:48,648] Finished trial#7 resulted in value: 328.0. Current best value is 40.0 with parameters: {'x': 10.0, 'y': -2.0}.\r\n[I 2020-02-12 12:26:48,670] Finished trial#8 resulted in value: 580.0. Current best value is 40.0 with parameters: {'x': 10.0, 'y': -2.0}.\r\n[I 2020-02-12 12:26:48,693] Finished trial#9 resulted in value: 260.0. Current best value is 40.0 with parameters: {'x': 10.0, 'y': -2.0}.\r\n[I 2020-02-12 12:26:48,719] Finished trial#10 resulted in value: 256.0. Current best value is 40.0 with parameters: {'x': 10.0, 'y': -2.0}.\r\n[I 2020-02-12 12:26:48,746] Finished trial#11 resulted in value: 328.0. Current best value is 40.0 with parameters: {'x': 10.0, 'y': -2.0}.\r\n[I 2020-02-12 12:26:48,772] Finished trial#12 resulted in value: 256.0. Current best value is 40.0 with parameters: {'x': 10.0, 'y': -2.0}.\r\n[I 2020-02-12 12:26:48,799] Finished trial#13 resulted in value: 328.0. Current best value is 40.0 with parameters: {'x': 10.0, 'y': -2.0}.\r\n[I 2020-02-12 12:26:48,827] Finished trial#14 resulted in value: 200.0. Current best value is 40.0 with parameters: {'x': 10.0, 'y': -2.0}.\r\n[I 2020-02-12 12:26:48,853] Finished trial#15 resulted in value: 324.0. Current best value is 40.0 with parameters: {'x': 10.0, 'y': -2.0}.\r\n[I 2020-02-12 12:26:48,881] Finished trial#16 resulted in value: 328.0. Current best value is 40.0 with parameters: {'x': 10.0, 'y': -2.0}.\r\n[I 2020-02-12 12:26:48,907] Finished trial#17 resulted in value: 8.0. Current best value is 8.0 with parameters: {'x': 6.0, 'y': -10.0}.\r\n[I 2020-02-12 12:26:48,935] Finished trial#18 resulted in value: 328.0. Current best value is 8.0 with parameters: {'x': 6.0, 'y': -10.0}.\r\n[I 2020-02-12 12:26:48,965] Finished trial#19 resulted in value: 328.0. Current best value is 8.0 with parameters: {'x': 6.0, 'y': -10.0}.\r\n[I 2020-02-12 12:26:48,999] Finished trial#20 resulted in value: 328.0. Current best value is 8.0 with parameters: {'x': 6.0, 'y': -10.0}.\r\n[I 2020-02-12 12:26:49,034] Finished trial#21 resulted in value: 256.0. Current best value is 8.0 with parameters: {'x': 6.0, 'y': -10.0}.\r\n[I 2020-02-12 12:26:49,063] Finished trial#22 resulted in value: 260.0. Current best value is 8.0 with parameters: {'x': 6.0, 'y': -10.0}.\r\n[I 2020-02-12 12:26:49,092] Finished trial#23 resulted in value: 212.0. Current best value is 8.0 with parameters: {'x': 6.0, 'y': -10.0}.\r\n[I 2020-02-12 12:26:49,120] Finished trial#24 resulted in value: 272.0. Current best value is 8.0 with parameters: {'x': 6.0, 'y': -10.0}.\r\n[I 2020-02-12 12:26:49,148] Finished trial#25 resulted in value: 260.0. Current best value is 8.0 with parameters: {'x': 6.0, 'y': -10.0}.\r\n[I 2020-02-12 12:26:49,177] Finished trial#26 resulted in value: 272.0. Current best value is 8.0 with parameters: {'x': 6.0, 'y': -10.0}.\r\n[I 2020-02-12 12:26:49,203] Finished trial#27 resulted in value: 272.0. Current best value is 8.0 with parameters: {'x': 6.0, 'y': -10.0}.\r\n[I 2020-02-12 12:26:49,232] Finished trial#28 resulted in value: 212.0. Current best value is 8.0 with parameters: {'x': 6.0, 'y': -10.0}.\r\n[I 2020-02-12 12:26:49,260] Finished trial#29 resulted in value: 212.0. Current best value is 8.0 with parameters: {'x': 6.0, 'y': -10.0}.\r\n[I 2020-02-12 12:26:49,291] Finished trial#30 resulted in value: 212.0. Current best value is 8.0 with parameters: {'x': 6.0, 'y': -10.0}.\r\n[I 2020-02-12 12:26:49,318] Finished trial#31 resulted in value: 8.0. Current best value is 8.0 with parameters: {'x': 6.0, 'y': -10.0}.\r\n[I 2020-02-12 12:26:49,347] Finished trial#32 resulted in value: 20.0. Current best value is 8.0 with parameters: {'x': 6.0, 'y': -10.0}.\r\n[I 2020-02-12 12:26:49,378] Finished trial#33 resulted in value: 272.0. Current best value is 8.0 with parameters: {'x': 6.0, 'y': -10.0}.\r\n[I 2020-02-12 12:26:49,409] Finished trial#34 resulted in value: 340.0. Current best value is 8.0 with parameters: {'x': 6.0, 'y': -10.0}.\r\n[I 2020-02-12 12:26:49,441] Finished trial#35 resulted in value: 212.0. Current best value is 8.0 with parameters: {'x': 6.0, 'y': -10.0}.\r\n[I 2020-02-12 12:26:49,471] Finished trial#36 resulted in value: 320.0. Current best value is 8.0 with parameters: {'x': 6.0, 'y': -10.0}.\r\n[I 2020-02-12 12:26:49,501] Finished trial#37 resulted in value: 232.0. Current best value is 8.0 with parameters: {'x': 6.0, 'y': -10.0}.\r\n[I 2020-02-12 12:26:49,532] Finished trial#38 resulted in value: 212.0. Current best value is 8.0 with parameters: {'x': 6.0, 'y': -10.0}.\r\n[I 2020-02-12 12:26:49,562] Finished trial#39 resulted in value: 212.0. Current best value is 8.0 with parameters: {'x': 6.0, 'y': -10.0}.\r\n[{'x': 2.0, 'y': 4.0},\r\n {'x': 2.0, 'y': 0.0},\r\n {'x': -2.0, 'y': 4.0},\r\n {'x': -2.0, 'y': 8.0},\r\n {'x': 10.0, 'y': -2.0},\r\n {'x': 6.0, 'y': 0.0},\r\n {'x': 2.0, 'y': 10.0},\r\n {'x': -10.0, 'y': -10.0},\r\n {'x': -10.0, 'y': 8.0},\r\n {'x': 6.0, 'y': 8.0},\r\n {'x': 8.0, 'y': 8.0},\r\n {'x': 6.0, 'y': 10.0},\r\n {'x': 8.0, 'y': 8.0},\r\n {'x': 6.0, 'y': 10.0},\r\n {'x': 6.0, 'y': 6.0},\r\n {'x': 8.0, 'y': 10.0},\r\n {'x': 6.0, 'y': 10.0},\r\n {'x': 6.0, 'y': -10.0},\r\n {'x': 6.0, 'y': 10.0},\r\n {'x': 6.0, 'y': 10.0},\r\n {'x': 6.0, 'y': 10.0},\r\n {'x': 8.0, 'y': 8.0},\r\n {'x': 6.0, 'y': 8.0},\r\n {'x': 4.0, 'y': 6.0},\r\n {'x': 4.0, 'y': 8.0},\r\n {'x': 6.0, 'y': 8.0},\r\n {'x': 4.0, 'y': 8.0},\r\n {'x': 4.0, 'y': 8.0},\r\n {'x': 4.0, 'y': 6.0},\r\n {'x': 4.0, 'y': 6.0},\r\n {'x': 4.0, 'y': 6.0},\r\n {'x': 6.0, 'y': -10.0},\r\n {'x': 4.0, 'y': -10.0},\r\n {'x': 4.0, 'y': 8.0},\r\n {'x': 4.0, 'y': 10.0},\r\n {'x': 4.0, 'y': 6.0},\r\n {'x': 0.0, 'y': 8.0},\r\n {'x': 2.0, 'y': 6.0},\r\n {'x': 4.0, 'y': 6.0},\r\n {'x': 4.0, 'y': 6.0}]\r\nBest value: 8.0 (params: {'x': 6.0, 'y': -10.0})\r\n```\r\n\r\n</details>\r\n\r\nThen I optimized the same objective function with `suggest_uniform()`.  This means the search space is wider than the previous example. But the best_value is improved (`Best value: 0.7501865899326501 (params: {'x': 8.754039799517779, 'y': -8.426157917532736})`).\r\n\r\n```python\r\nimport optuna\r\nimport pprint\r\n\r\n\r\ndef objective(trial):\r\n    x = trial.suggest_uniform('x', -10, 10)\r\n    y = trial.suggest_uniform('y', -10, 10)\r\n    return (x-8)**2 + (y+8)**2\r\n\r\n\r\nif __name__ == '__main__':\r\n    study = optuna.create_study(sampler=optuna.samplers.TPESampler(seed=0))\r\n    study.optimize(objective, n_trials=40)\r\n    pprint.pprint([t.params for t in study.trials])\r\n    print('Best value: {} (params: {})\\n'.format(study.best_value, study.best_params))\r\n```\r\n\r\n<details>\r\n\r\n<summary>execution log</summary>\r\n\r\n```console\r\n$ python examples/quadratic_simple.py \r\n[I 2020-02-12 12:31:24,246] Finished trial#0 resulted in value: 200.71596460860084. Current best value is 200.71596460860084 with parameters: {'x': 0.9762700785464951, 'y': 4.30378732744839}.\r\n[I 2020-02-12 12:31:24,266] Finished trial#1 resulted in value: 114.50826284711097. Current best value is 114.50826284711097 with parameters: {'x': 2.055267521432878, 'y': 0.8976636599379368}.\r\n[I 2020-02-12 12:31:24,289] Finished trial#2 resulted in value: 209.9620531494761. Current best value is 114.50826284711097 with parameters: {'x': 2.055267521432878, 'y': 0.8976636599379368}.\r\n[I 2020-02-12 12:31:24,310] Finished trial#3 resulted in value: 336.2920287821092. Current best value is 114.50826284711097 with parameters: {'x': 2.055267521432878, 'y': 0.8976636599379368}.\r\n[I 2020-02-12 12:31:24,332] Finished trial#4 resulted in value: 33.75681666755005. Current best value is 33.75681666755005 with parameters: {'x': 9.273255210020587, 'y': -2.3311696234844455}.\r\n[I 2020-02-12 12:31:24,355] Finished trial#5 resulted in value: 78.26972782722031. Current best value is 33.75681666755005 with parameters: {'x': 9.273255210020587, 'y': -2.3311696234844455}.\r\n[I 2020-02-12 12:31:24,377] Finished trial#6 resulted in value: 316.7216890317852. Current best value is 33.75681666755005 with parameters: {'x': 9.273255210020587, 'y': -2.3311696234844455}.\r\n[I 2020-02-12 12:31:24,401] Finished trial#7 resulted in value: 274.938748693708. Current best value is 33.75681666755005 with parameters: {'x': 9.273255210020587, 'y': -2.3311696234844455}.\r\n[I 2020-02-12 12:31:24,422] Finished trial#8 resulted in value: 524.2990025172612. Current best value is 33.75681666755005 with parameters: {'x': 9.273255210020587, 'y': -2.3311696234844455}.\r\n[I 2020-02-12 12:31:24,445] Finished trial#9 resulted in value: 243.10579431471123. Current best value is 33.75681666755005 with parameters: {'x': 9.273255210020587, 'y': -2.3311696234844455}.\r\n[I 2020-02-12 12:31:24,470] Finished trial#10 resulted in value: 12.946457192708332. Current best value is 12.946457192708332 with parameters: {'x': 9.686243082413295, 'y': -4.821471809198219}.\r\n[I 2020-02-12 12:31:24,496] Finished trial#11 resulted in value: 10.701478253650269. Current best value is 10.701478253650269 with parameters: {'x': 9.708212252178804, 'y': -5.210109472549776}.\r\n[I 2020-02-12 12:31:24,522] Finished trial#12 resulted in value: 9.579557306645803. Current best value is 9.579557306645803 with parameters: {'x': 9.73750894101814, 'y': -5.438629275850951}.\r\n[I 2020-02-12 12:31:24,548] Finished trial#13 resulted in value: 1.9905991172634114. Current best value is 1.9905991172634114 with parameters: {'x': 6.787220711670441, 'y': -8.720947650708608}.\r\n[I 2020-02-12 12:31:24,573] Finished trial#14 resulted in value: 2.787134442293085. Current best value is 1.9905991172634114 with parameters: {'x': 6.787220711670441, 'y': -8.720947650708608}.\r\n[I 2020-02-12 12:31:24,599] Finished trial#15 resulted in value: 6.0477201513659615. Current best value is 1.9905991172634114 with parameters: {'x': 6.787220711670441, 'y': -8.720947650708608}.\r\n[I 2020-02-12 12:31:24,624] Finished trial#16 resulted in value: 15.744300260899426. Current best value is 1.9905991172634114 with parameters: {'x': 6.787220711670441, 'y': -8.720947650708608}.\r\n[I 2020-02-12 12:31:24,649] Finished trial#17 resulted in value: 200.40208368776987. Current best value is 1.9905991172634114 with parameters: {'x': 6.787220711670441, 'y': -8.720947650708608}.\r\n[I 2020-02-12 12:31:24,674] Finished trial#18 resulted in value: 24.631226446395882. Current best value is 1.9905991172634114 with parameters: {'x': 6.787220711670441, 'y': -8.720947650708608}.\r\n[I 2020-02-12 12:31:24,699] Finished trial#19 resulted in value: 20.985445341007892. Current best value is 1.9905991172634114 with parameters: {'x': 6.787220711670441, 'y': -8.720947650708608}.\r\n[I 2020-02-12 12:31:24,724] Finished trial#20 resulted in value: 4.353657092311067. Current best value is 1.9905991172634114 with parameters: {'x': 6.787220711670441, 'y': -8.720947650708608}.\r\n[I 2020-02-12 12:31:24,751] Finished trial#21 resulted in value: 3.812984233887978. Current best value is 1.9905991172634114 with parameters: {'x': 6.787220711670441, 'y': -8.720947650708608}.\r\n[I 2020-02-12 12:31:24,775] Finished trial#22 resulted in value: 3.457795936864317. Current best value is 1.9905991172634114 with parameters: {'x': 6.787220711670441, 'y': -8.720947650708608}.\r\n[I 2020-02-12 12:31:24,800] Finished trial#23 resulted in value: 20.221676496873553. Current best value is 1.9905991172634114 with parameters: {'x': 6.787220711670441, 'y': -8.720947650708608}.\r\n[I 2020-02-12 12:31:24,825] Finished trial#24 resulted in value: 30.31779566726328. Current best value is 1.9905991172634114 with parameters: {'x': 6.787220711670441, 'y': -8.720947650708608}.\r\n[I 2020-02-12 12:31:24,852] Finished trial#25 resulted in value: 149.0040196902956. Current best value is 1.9905991172634114 with parameters: {'x': 6.787220711670441, 'y': -8.720947650708608}.\r\n[I 2020-02-12 12:31:24,876] Finished trial#26 resulted in value: 26.723021729686693. Current best value is 1.9905991172634114 with parameters: {'x': 6.787220711670441, 'y': -8.720947650708608}.\r\n[I 2020-02-12 12:31:24,902] Finished trial#27 resulted in value: 2.1115754122144383. Current best value is 1.9905991172634114 with parameters: {'x': 6.787220711670441, 'y': -8.720947650708608}.\r\n[I 2020-02-12 12:31:24,926] Finished trial#28 resulted in value: 26.303366365533872. Current best value is 1.9905991172634114 with parameters: {'x': 6.787220711670441, 'y': -8.720947650708608}.\r\n[I 2020-02-12 12:31:24,952] Finished trial#29 resulted in value: 96.84561930745205. Current best value is 1.9905991172634114 with parameters: {'x': 6.787220711670441, 'y': -8.720947650708608}.\r\n[I 2020-02-12 12:31:24,978] Finished trial#30 resulted in value: 5.378089726755739. Current best value is 1.9905991172634114 with parameters: {'x': 6.787220711670441, 'y': -8.720947650708608}.\r\n[I 2020-02-12 12:31:25,004] Finished trial#31 resulted in value: 0.9351018565830189. Current best value is 0.9351018565830189 with parameters: {'x': 8.679579471197588, 'y': -8.687948834514476}.\r\n[I 2020-02-12 12:31:25,030] Finished trial#32 resulted in value: 0.7501865899326501. Current best value is 0.7501865899326501 with parameters: {'x': 8.754039799517779, 'y': -8.426157917532736}.\r\n[I 2020-02-12 12:31:25,056] Finished trial#33 resulted in value: 1.0895754508080087. Current best value is 0.7501865899326501 with parameters: {'x': 8.754039799517779, 'y': -8.426157917532736}.\r\n[I 2020-02-12 12:31:25,082] Finished trial#34 resulted in value: 1.7738376171795691. Current best value is 0.7501865899326501 with parameters: {'x': 8.754039799517779, 'y': -8.426157917532736}.\r\n[I 2020-02-12 12:31:25,107] Finished trial#35 resulted in value: 123.81710895410804. Current best value is 0.7501865899326501 with parameters: {'x': 8.754039799517779, 'y': -8.426157917532736}.\r\n[I 2020-02-12 12:31:25,133] Finished trial#36 resulted in value: 59.49247852436665. Current best value is 0.7501865899326501 with parameters: {'x': 8.754039799517779, 'y': -8.426157917532736}.\r\n[I 2020-02-12 12:31:25,158] Finished trial#37 resulted in value: 2.885303195813565. Current best value is 0.7501865899326501 with parameters: {'x': 8.754039799517779, 'y': -8.426157917532736}.\r\n[I 2020-02-12 12:31:25,184] Finished trial#38 resulted in value: 16.217465431118043. Current best value is 0.7501865899326501 with parameters: {'x': 8.754039799517779, 'y': -8.426157917532736}.\r\n[I 2020-02-12 12:31:25,209] Finished trial#39 resulted in value: 107.70758732187842. Current best value is 0.7501865899326501 with parameters: {'x': 8.754039799517779, 'y': -8.426157917532736}.\r\n[{'x': 0.9762700785464951, 'y': 4.30378732744839},\r\n {'x': 2.055267521432878, 'y': 0.8976636599379368},\r\n {'x': -1.5269040132219054, 'y': 2.917882261333123},\r\n {'x': -1.2482557747461502, 'y': 7.835460015641594},\r\n {'x': 9.273255210020587, 'y': -2.3311696234844455},\r\n {'x': 5.834500761653292, 'y': 0.5778983950580887},\r\n {'x': 1.3608912218786458, 'y': 8.51193276585322},\r\n {'x': -8.579278836042262, 'y': -8.257414005969185},\r\n {'x': -9.595632051193485, 'y': 6.65239691095876},\r\n {'x': 5.563135018997009, 'y': 7.400242964936382},\r\n {'x': 9.686243082413295, 'y': -4.821471809198219},\r\n {'x': 9.708212252178804, 'y': -5.210109472549776},\r\n {'x': 9.73750894101814, 'y': -5.438629275850951},\r\n {'x': 6.787220711670441, 'y': -8.720947650708608},\r\n {'x': 6.932136180360886, 'y': -9.28327756350637},\r\n {'x': 5.86952095650934, 'y': -9.228323734449955},\r\n {'x': 4.396721132406469, 'y': -9.661529916448485},\r\n {'x': -6.140848102960068, 'y': -7.337807719177768},\r\n {'x': 7.780221277778199, 'y': -3.0418830429633434},\r\n {'x': 3.534170967640166, 'y': -6.979305925000093},\r\n {'x': 7.394374857709929, 'y': -9.996716123873696},\r\n {'x': 7.450676982452702, 'y': -9.87382722156572},\r\n {'x': 7.99125233686058, 'y': -9.859494397747387},\r\n {'x': 3.50928554973873, 'y': -7.765137863655795},\r\n {'x': 7.976201068280483, 'y': -2.493891639450574},\r\n {'x': -4.080157449530058, 'y': -6.246769928144339},\r\n {'x': 4.886793566658666, 'y': -3.8731407301570338},\r\n {'x': 6.689677338837612, 'y': -8.628195778287912},\r\n {'x': 2.8931056709758196, 'y': -8.472225240446267},\r\n {'x': 0.5220111812144719, 'y': -1.6027113138790838},\r\n {'x': 6.390455176664282, 'y': -6.3304326343543575},\r\n {'x': 8.679579471197588, 'y': -8.687948834514476},\r\n {'x': 8.754039799517779, 'y': -8.426157917532736},\r\n {'x': 9.027289623466064, 'y': -8.185071554613238},\r\n {'x': 8.733823550159512, 'y': -6.888541222351967},\r\n {'x': 8.85090784797788, 'y': 3.0947313977562207},\r\n {'x': 9.940965948888914, 'y': -0.5350733620737829},\r\n {'x': 8.778125908009237, 'y': -6.490091636191664},\r\n {'x': 8.674918898054859, 'y': -4.029867771450621},\r\n {'x': -2.3740564859617095, 'y': -7.705824290679498}]\r\nBest value: 0.7501865899326501 (params: {'x': 8.754039799517779, 'y': -8.426157917532736})\r\n```\r\n\r\n</details>\r\n\r\n\r\n## Expected behavior\r\n\r\n`suggest_discrete_uniform` should be the same or better performance with `suggest_uniiform` in the example.\r\n\r\n## Environment\r\n\r\n- Optuna version: 1.1.0\r\n- Python version: 3.8.1\r\n- OS: macOS\r\n- (Optional) Other libraries and their versions:\r\n\r\n\r\n## Additional context (optional)\r\n\r\nI found this issue while reviewing https://github.com/optuna/optuna/pull/910"},{"labels":["bug",null],"text":"The behavior is different between 0.19.0 and 1.x.x.\r\n\r\n## Environment\r\n\r\n- Python version: 3.6.5\r\n- OS: Windows 10\r\n\r\n## Examples\r\n\r\n```python\r\nimport copy\r\n\r\nimport optuna\r\n\r\n\r\ndef objective(trial):\r\n    x = trial.suggest_uniform('x', -10, 10)\r\n\r\n    return (x - 2) ** 2\r\n\r\n\r\nstudy = optuna.create_study(sampler=optuna.samplers.TPESampler(seed=0))\r\nstudy.optimize(objective, n_trials=1)\r\n\r\nstudy = optuna.create_study(sampler=optuna.samplers.TPESampler(seed=0))\r\nstudy = copy.deepcopy(study)\r\nstudy.optimize(objective, n_trials=1)\r\n```\r\n\r\n## Logs\r\n\r\n### v0.19.0\r\n\r\n```\r\n[I 2020-02-12 02:37:41,933] Finished trial#0 resulted in value: 1.0480229520791995. Current best value is 1.0480229520791995 with parameters: {'x': 0.9762700785464951}.\r\n[I 2020-02-12 02:37:41,990] Finished trial#0 resulted in value: 1.0480229520791995. Current best value is 1.0480229520791995 with parameters: {'x': 0.9762700785464951}.\r\n```\r\n\r\n### v1.0.0\r\n\r\n```\r\n[I 2020-02-12 02:38:44,010] Finished trial#0 resulted in value: 1.0480229520791995. Current best value is 1.0480229520791995 with parameters: {'x': 0.9762700785464951}.\r\n[I 2020-02-12 02:38:44,067] Finished trial#0 resulted in value: 46.90638356377688. Current best value is 46.90638356377688 with parameters: {'x': 8.848823516763801}.\r\n```\r\n\r\n### v1.1.0\r\n\r\n```\r\n[I 2020-02-12 02:39:39,168] Finished trial#0 resulted in value: 1.0480229520791995. Current best value is 1.0480229520791995 with parameters: {'x': 0.9762700785464951}.\r\n[I 2020-02-12 02:39:39,226] Finished trial#0 resulted in value: 2.756825098011473. Current best value is 2.756825098011473 with parameters: {'x': 3.6603689644207016}.\r\n```\r\n"},{"labels":["bug"],"text":" When I set 'ndcg' as metric, ligbtgbm_tuner raise key error at `booster.best_score[valid_name][metric]`\r\n\r\n## Expected behavior\r\n\r\n Probably, 'metric' variable at the tuner is 'ndcg' but `booster.best_score` dictionary at the booster class stores 'ndcg@20'. So the  KeyError has raised.\r\n\r\n## Environment\r\n\r\n- Optuna version: 1.1.0\r\n- Python version: 3.5.3\r\n- OS: Debian GNU/Linux 9\r\n- (Optional) Other libraries and their versions:\r\n\r\n## Error messages, stack traces, or logs\r\n\r\n```\r\nFile \"<ipython-input-8-44094cd56040>\", line 32, in train_lgbm_ranking\r\n    early_stopping_rounds=early_stopping_rounds, callbacks=None, best_params=best_params, tuning_history=tuning_history)\r\n  File \"/home/user/.local/lib/python3.5/site-packages/optuna/integration/lightgbm_tuner/__init__.py\", line 23, in train\r\n    booster = auto_booster.run()\r\n  File \"/home/user/.local/lib/python3.5/site-packages/optuna/integration/lightgbm_tuner/optimize.py\", line 379, in run\r\n    self.tune_feature_fraction()\r\n  File \"/home/user/.local/lib/python3.5/site-packages/optuna/integration/lightgbm_tuner/optimize.py\", line 425, in tune_feature_fraction\r\n    self.tune_params([param_name], len(param_values), sampler)\r\n  File \"/home/user/.local/lib/python3.5/site-packages/optuna/integration/lightgbm_tuner/optimize.py\", line 487, in tune_params\r\n    study.optimize(objective, n_trials=n_trials, catch=())\r\n  File \"/home/user/.local/lib/python3.5/site-packages/optuna/study.py\", line 302, in optimize\r\n    gc_after_trial, None)\r\n  File \"/home/user/.local/lib/python3.5/site-packages/optuna/study.py\", line 538, in _optimize_sequential\r\n    self._run_trial_and_callbacks(func, catch, callbacks, gc_after_trial)\r\n  File \"/home/user/.local/lib/python3.5/site-packages/optuna/study.py\", line 550, in _run_trial_and_callbacks\r\n    trial = self._run_trial(func, catch, gc_after_trial)\r\n  File \"/home/user/.local/lib/python3.5/site-packages/optuna/study.py\", line 569, in _run_trial\r\n    result = func(trial)\r\n  File \"/home/user/.local/lib/python3.5/site-packages/optuna/integration/lightgbm_tuner/optimize.py\", line 240, in __call__\r\n    val_score = self._get_booster_best_score(booster)\r\n  File \"/home/user/.local/lib/python3.5/site-packages/optuna/integration/lightgbm_tuner/optimize.py\", line 142, in _get_booster_best_score\r\n    val_score = booster.best_score[valid_name][metric]\r\nKeyError: 'ndcg'\r\n```\r\n\r\n## Steps to reproduce\r\n\r\n1. set \"ndcg\" as metric, \"lambdarank\" as objective.\r\n2. set 20 as \"ndcg_eval_at\" \r\n3. train start\r\n\r\n\r\n"},{"labels":["bug",null],"text":"Due to the bug the title describes, [the current API reference doc](https://optuna.readthedocs.io/en/latest/) doesn't contain the entry of `optuna.integration.lightgbm.train` function.\r\n\r\n# Expected behavior\r\n\r\nThe build of the function doc should be succeeded even if LightGBM isn't installed in the build environment.\r\n\r\n## Error messages, stack traces, or logs\r\n\r\n```console\r\n$ cd optuna/docs\r\n$ make html\r\n...\r\nWARNING: autodoc: failed to import function 'train' from module 'optuna.integration.lightgbm'; the following exception was raised:\r\nTraceback (most recent call last):\r\n  File \"/home/docs/checkouts/readthedocs.org/user_builds/optuna/envs/latest/lib/python3.7/site-packages/sphinx/util/inspect.py\", line 225, in safe_getattr\r\n    return getattr(obj, name, *defargs)\r\nAttributeError: module 'optuna.integration.lightgbm' has no attribute 'train'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/docs/checkouts/readthedocs.org/user_builds/optuna/envs/latest/lib/python3.7/site-packages/sphinx/ext/autodoc/importer.py\", line 193, in import_object\r\n    obj = attrgetter(obj, attrname)\r\n  File \"/home/docs/checkouts/readthedocs.org/user_builds/optuna/envs/latest/lib/python3.7/site-packages/sphinx/ext/autodoc/__init__.py\", line 290, in get_attr\r\n    return autodoc_attrgetter(self.env.app, obj, name, *defargs)\r\n  File \"/home/docs/checkouts/readthedocs.org/user_builds/optuna/envs/latest/lib/python3.7/site-packages/sphinx/ext/autodoc/__init__.py\", line 1563, in autodoc_attrgetter\r\n    return safe_getattr(obj, name, *defargs)\r\n  File \"/home/docs/checkouts/readthedocs.org/user_builds/optuna/envs/latest/lib/python3.7/site-packages/sphinx/util/inspect.py\", line 241, in safe_getattr\r\n    raise AttributeError(name)\r\nAttributeError: train\r\n...\r\n```\r\n\r\n## Steps to reproduce\r\n\r\n1. Ensure that LightGBM isn't installed in the built environment.\r\n2. `$ git clone git://github.com/optuna/optuna.git`\r\n3. `$ cd optuna/docs`\r\n4. `$ make html`\r\n\r\n\r\n"},{"labels":["bug",null],"text":"<!-- Please write a clear and concise description of what the bug is. -->\r\nDuring distributed optimization with five workers, one crashed with the following error:\r\n```\r\nsqlalchemy.exc.InvalidRequestError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (pymysql.err.InternalError) (1205, 'Lock wait timeout exceeded; try restarting transaction')\r\n[SQL: INSERT INTO trial_system_attributes (trial_id, `key`, value_json) VALUES (%(trial_id)s, %(key)s, %(value_json)s)]\r\n[parameters: {'trial_id': 4530, 'key': '_number', 'value_json': '16'}]\r\n(Background on this error at: http://sqlalche.me/e/2j85) (Background on this error at: http://sqlalche.me/e/7s2a)\r\n```\r\nFull log with all stack traced here: [failure.log](https://github.com/optuna/optuna/files/4133355/failure.log)\r\n\r\nIt looks like some problem with the pymysql driver which is of course not your fault. However it would be nice if such errors were caught and the trial dropped instead of crashing the entire worker.\r\n\r\nMight be related to #386\r\n\r\n## Expected behavior\r\n\r\n<!-- Please write a clear and concise description of what you expected to happen. -->\r\nNo crashes of the entire application in spite of database errors. Rather repeated retries.\r\n\r\n## Environment\r\n\r\n- Optuna version: 1.0.0\r\n- Python version: 3.6\r\n- OS: ubuntu:18.04\r\n- Other libraries and their versions: PyMySQL 0.9.3, sqlalchemy-1.3.13\r\n\r\n## Error messages, stack traces, or logs\r\n\r\nToo long. Look  [here](https://github.com/optuna/optuna/files/4133355/failure.log).\r\n\r\n## Steps to reproduce\r\n\r\nUnfortunately very hard to reproduce since the other workers are still running just fine.\r\n"},{"labels":["bug"],"text":"LightGBM tuner raises exception while tuning if initial lgbm parameters contain `max_depth=-1`.\r\n\r\nThis error is caused by the following code:\r\n\r\nhttps://github.com/optuna/optuna/blob/master/optuna/integration/lightgbm_tuner/optimize.py#L215-L218\r\n```python\r\nmax_depth = self.lgbm_params.get('max_depth', 8)\r\nself.lgbm_params['num_leaves'] = trial.suggest_int(\r\n    'num_leaves', 2, 2 ** max_depth)\r\n```\r\n\r\n## Expected behavior\r\n-1 is a default parameter in LightGBM.\r\nhttps://github.com/optuna/optuna/issues/870#issue-556544694\r\n\r\nIf `max_depth<=0` is specified, optuna should fallback to its internal default (=8).\r\n\r\n## Environment\r\n\r\n- Optuna version: 1.0.0\r\n- Python version: 3.7\r\n- OS: Mac OS\r\n\r\n## Error messages, stack traces, or logs\r\n\r\n```\r\nValueError: The `low` value must be smaller than or equal to the `high` value (low=2, high=0.5).\r\n```\r\n\r\n## Reproducible examples\r\n\r\n```python\r\nimport optuna\r\nimport optuna.integration.lightgbm as lgb\r\nfrom sklearn.datasets import make_classification\r\nfrom sklearn.model_selection import train_test_split\r\n\r\nX, y = make_classification()\r\nX_train, X_valid, y_train, y_valid = train_test_split(X, y)\r\n\r\ndtrain = lgb.Dataset(X_train, y_train)\r\ndvalid = lgb.Dataset(X_valid, y_valid)\r\n\r\nparams = {\r\n    'objective': 'binary',\r\n    'max_depth': -1\r\n}\r\n\r\nlgb.train(params, dtrain, valid_sets=[dvalid], verbose_eval=-1)\r\n```"},{"labels":["bug"],"text":"## Problem\r\nUsing a call like:\r\n```colsample_bytree = trial.suggest_uniform('colsample_bytree', 0.1, 0.9)```\r\nproduces a highly skewed distribution:\r\n![image](https://user-images.githubusercontent.com/30508983/72634339-9f6d6880-3917-11ea-9c49-fb5190d04d7b.png)\r\n\r\n## Expected behavior\r\nThe distribution should be closer to uniform\r\n\r\n\r\n## Environment\r\n\r\n- Optuna version:\r\n```\r\noptuna.__version__  \r\nOut[47]: '0.19.0'\r\n```\r\n- Python version:\r\n```\r\npython                    3.6.9                h5500b2f_0\r\n```\r\n\r\n- OS:\r\n```\r\nOS Name             : Microsoft Windows 10 Home\r\nOS Version          : 10.0.18362 N/A Build 18362\r\nOS Manufacturer     : Microsoft Corporation\r\nOS Configuration    : Standalone Workstation\r\nOS Build Type       : Multiprocessor Free\r\nSystem Boot Time    : 1/15/2020, 5:34:36 PM\r\nSystem Manufacturer : LENOVO\r\nSystem Model        : 20349\r\nSystem Type         : x64-based PC\r\nSystem Directory    : C:\\Windows\\system32\r\nSystem Locale       : en-us;English (United States)\r\nHotfix(s)           : 11 Hotfix(s) Installed.,[01]: KB4532938,[02]: KB4497165,[03]: KB4498523,[04]: KB4503308,[05]: KB4515383,[06]: KB4516115,[07]: KB4520390,[08]: KB4521863,[09]: KB4524569,[10]:\r\n                      KB4528759,[11]: KB4528760\r\n```\r\n\r\n- (Optional) Other libraries and their versions:\r\n```\r\nxgb.__version__\r\nOut[50]: '0.90'\r\n```\r\n## Error messages, stack traces, or logs\r\nNone\r\n\r\n## Steps to reproduce\r\n```\r\ndef train_model(trial,\r\n                train_X,\r\n                train_Y,\r\n                val_X,\r\n                val_Y,\r\n                n_iters,\r\n                params,\r\n                n_class = None):\r\n    colsample_bytree = trial.suggest_uniform('colsample_bytree', 0.1, 0.9)\r\n```\r\n\r\n"},{"labels":["bug"],"text":"Visualizations don't work in Jupyter Lab. I see just empty (white) plots. In Jupyter Notebook everything is OK.\r\n\r\n## Expected behavior\r\n\r\nVisualizations should be available from Jupyter Lab.\r\n\r\n## Environment\r\n\r\n- Optuna version: 1.0.0\r\n- Python version: 3.7.4\r\n- OS: Ubuntu 18.04.3\r\n- (Optional) Other libraries and their versions:\r\nplotly==4.4.1\r\njupyterlab==1.2.4\r\njupyterlab-server==1.0.6\r\n\r\n## Steps to reproduce\r\n\r\n1. Create a study object. \r\n2. Run study.optimize\r\n3. Plot any visualization.\r\n\r\n## Reproducible examples (optional)\r\n\r\n```python\r\noptuna.visualization.plot_slice(study)\r\n```\r\nOr any other plot.\r\n## Additional context (optional)\r\n\r\nScreenshot of empty visualization:\r\n![image](https://user-images.githubusercontent.com/3490922/72460097-d6873100-37d4-11ea-9433-62a4824622aa.png)\r\nThere is an error in the browser console:\r\n![Screenshot from 2020-01-15 20-26-45](https://user-images.githubusercontent.com/3490922/72460658-e6ebdb80-37d5-11ea-9b0e-8077ad5eee90.png)\r\n![Screenshot from 2020-01-15 20-27-13](https://user-images.githubusercontent.com/3490922/72460675-efdcad00-37d5-11ea-9283-4f70b860830d.png)"},{"labels":["bug"],"text":"## Expected behavior\r\n\r\n\r\nThe `OptunaSearchCV` does not work with the latest scikit-learn (v0.22.1). This is due to the update of the internal interface in [this commit](https://github.com/scikit-learn/scikit-learn/commit/46001e7cfb163b73a83d5adf73fb454e8a3c64b6).  More concretely, it removed `sklearn.model_selection._validation._index_param_value` which is used in `OptunaSearchCV` and added `sklearn.utils.validation._check_fit_params` instead.\r\n\r\n`OptunaSearchCV` uses some other internal interface of scikit-learn, and I think it would be better to stop using them to avoid similar issues.\r\n\r\n## Environment\r\n\r\n- Optuna version: 0.19.0\r\n- Python version: 3.7.5\r\n- OS : `Linux 75b723335ed2 4.9.184-linuxkit #1 SMP Tue Jul 2 22:58:16 UTC 2019 x86_64 GNU/Linux`\r\n- scikit-learn versions: `scikit-learn==0.22.1`\r\n\r\n\r\n## Reproducible examples\r\n\r\nSetup\r\n```bash\r\n$ docker run -it --rm python:3.7 bash\r\n$ pip install scikit-learn\r\n$ pip install optuna\r\n```\r\n\r\nReproducible code\r\n```python\r\n>>> import sklearn\r\n>>> import optuna.integration.sklearn\r\n\r\n# The following line raises import error even if sklearn has been installed.\r\n>>> optuna.integration.sklearn._check_sklearn_availability()\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python3.8/site-packages/optuna/integration/sklearn.py\", line 65, in _check_sklearn_availability\r\n    raise ImportError(\r\nImportError: scikit-learn is not available. Please install scikit-learn to use this feature. scikit-learn can be installed by executing `$ pip install scikit-learn>=0.19.0`. For further information, please refer to the installation guide of scikit-learn. (The actual import error is as follows: cannot import name '_index_param_value' from 'sklearn.model_selection._validation' (/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py))\r\n\r\n# The actual cause of the above error.\r\n>>> from sklearn.model_selection._validation import _index_param_value\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nImportError: cannot import name '_index_param_value' from 'sklearn.model_selection._validation' (/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_validation.py)\r\n\r\n```\r\n"},{"labels":["bug",null,null,null],"text":"I'm deploying optuna on a single machine through a script that looks like this:\r\n\r\n```\r\noptuna create-study […]\r\n\r\nfor i in $(seq \"$1\")\r\ndo\r\n    optuna study optimize […] &\r\ndone\r\n\r\nwait\r\n\r\n# (copy trials.db from scratch to shared storage)\r\n[…]\r\n```\r\n\r\n\r\nI got some `sqlite3.OperationalError: database is locked` errors on start (on 7 processes out of 32).\r\n\r\nI think that launching all processes at the same time causes them to make requests at the same time (*collide*). I'm lucky that my hyperparameters also control the computation time so that the processes have very low probability to *collide* after starting, but I guess this could also be a source of problems in other workflows that are massively parallel.\r\n\r\nI believe this could be fixed by increasing the timeout of the sqlite3 backend. There should be an option to do that from the command line and the API of optuna.\r\n\r\n## Alternatives\r\n\r\nI added a sleep in my loop.\r\n\r\n```\r\nfor i in $(seq \"$1\")\r\ndo\r\n    optuna study optimize […] &\r\n    sleep 5\r\ndone\r\n```"},{"labels":["bug"],"text":"When launching multiple instances of `optuna study optimize` ~in rapid succession (but by hand)~, I get the following error: \r\n\r\n    [W 2019-12-26 08:12:45,772] Setting status of trial#13 as TrialState.FAIL because of the following error: DatabaseError('(sqlite3.DatabaseError) database disk image is malformed')\r\n\r\n## Expected behavior\r\n\r\nNo error.\r\n\r\n## Environment\r\n\r\n- Optuna version: 0.19.0\r\n- Python version: Python 3.7.4\r\n- OS: CentOS Linux release 7.5.1804 (Core)\r\n\r\n\r\n## Error messages, stack traces, or logs\r\n\r\nhttps://pastebin.com/UPaiAm5t\r\n\r\n## Steps to reproduce\r\n\r\nLaunch multiple instances of  `optuna study optimize` ~in rapid succession~.\r\n\r\n## Additional context (optional)\r\n\r\nI'm launching the tasks over LSF on a cluster with a shared file system.\r\n\r\n**EDIT**: the tasks keep failing (even after executing some trials) so it probably isn't related to launching them in rapid succession."},{"labels":["bug"],"text":"XGBoostPruningCallback is not compatible with xgboost cross validation function cv().\r\n\r\nThe Optuna pruner is expecting only two elements in each tuple of the evaluation_result_list, but XGBoost.cv is also providing a third element: the stddev of the metric across the cross-valdation folds.\r\n\r\n## Expected behavior\r\nNo exception\r\n\r\n## Environment\r\n- Optuna version: 0.19.0\r\n- Python version: Python 3.7.5\r\n- OS: Windows 10\r\n\r\n## Error messages, stack traces, or logs\r\nFile \"C:\\Users\\me\\.conda\\envs\\feature-tools-ve\\lib\\site-packages\\optuna\\integration\\xgboost.py\", line 50, in __call__\r\n    current_score = dict(env.evaluation_result_list)[self.observation_key]\r\nValueError: dictionary update sequence element #0 has length 3; 2 is required\r\n\r\n## Additional context (optional)\r\nHere is a workaround callback:\r\n```\r\ndef remove_std_from_evaluation_result_list(xgb_callback_env):\r\n    \"\"\"Custom XGBoost callback adapter to fix compatibility with Optuna pruner.\r\n    The Optuna pruner is expecting only two elements in each tuple of the evaluation_result_list.\r\n    It expects the observation_key and the evaluation metric only, but XGBoost is also providing\r\n    a third element: the stddev of the metric across the cross-valdation folds.\r\n    \"\"\"\r\n    # drop the 3rd element (stddev) from each evaluation_result_list item.\r\n    erl_orig = xgb_callback_env.evaluation_result_list\r\n    erl_no_std = [(observation_key, metric) for observation_key, metric, std in erl_orig]\r\n    erl_orig.clear()\r\n    erl_orig.extend(erl_no_std)\r\n\r\nmetrics = [\"error\", \"logloss\"]\r\npruning_callback = optuna.integration.XGBoostPruningCallback(trial, \"test-logloss\")\r\ncallbacks = [remove_std_from_evaluation_result_list, pruning_callback]\r\ndf_rounds = xgb.cv(params, dtrain, metrics=metrics, callbacks=callbacks)\r\n```\r\n\r\n"},{"labels":["bug"],"text":"## Environment\r\n\r\n- Optuna version: master (https://github.com/optuna/optuna/commit/b7cf4d68b9b00ca6f28929a80f9db4ce691dff8e)\r\n- Python version: 3.5, 3.6, 3.7\r\n- OS: Linux (in CircleCI VM)\r\n\r\n## Error messages, stack traces, or logs\r\n\r\nThe CI jobs  `tests-python35`, `tests-python36`, `tests-python37` and `codecov` failed due to the segmentation fault.\r\n\r\n[The error message](https://circleci.com/gh/optuna/optuna/24674) is as follows:\r\n\r\n```\r\n#!/bin/bash -eo pipefail\r\n. venv/bin/activate\r\npytest tests\r\n============================= test session starts ==============================\r\nplatform linux -- Python 3.7.5, pytest-5.3.2, py-1.8.0, pluggy-0.13.1\r\nrootdir: /home/circleci/project\r\ncollecting 223 items                                                           Fatal Python error: Segmentation fault\r\n\r\nCurrent thread 0x00007fcfd1270740 (most recent call first):\r\n  File \"<frozen importlib._bootstrap>\", line 219 in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap_external>\", line 1043 in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 583 in module_from_spec\r\n  File \"<frozen importlib._bootstrap>\", line 670 in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 967 in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 983 in _find_and_load\r\n...\r\n  File \"/home/circleci/project/venv/lib/python3.7/site-packages/_pytest/config/__init__.py\", line 92 in main\r\n  File \"/home/circleci/project/venv/bin/pytest\", line 8 in <module>\r\n\r\nReceived \"segmentation fault\" signal\r\n```\r\n\r\nThis error is reproducible in the local environment by \r\n```console\r\ncircleci build --job tests-python37 \r\n```\r\n\r\nThe CI jobs completed properly yesterday as can be seen in https://circleci.com/gh/optuna/optuna/24654. \r\n\r\nI'm not sure but I'm thinking some updates in `scipy==1.4.0` caused this error."},{"labels":["bug"],"text":"## Expected behavior\r\n\r\nI have a study with a few thousand trials. It takes a few minutes to simply load the best trial. It looks like not only is this query happening in the application layer, but the number of queries executed is `O(n)` instead of `O(1)`.\r\n\r\n## Environment\r\n\r\n- Optuna version: 0.19.0\r\n- Python version: 3.6.8\r\n- OS: Ubuntu 18.04\r\n\r\n## Steps to reproduce\r\n\r\n1. Use postgres backend\r\n2. Create a study with thousands of trials\r\n3. In a new process, attempt to access the studies best_trial\r\n\r\nIt takes similar amounts of time to do things like get a data frame with all trial information, render visualizations, etc."},{"labels":["bug"],"text":"Cannot import optuna.exceptions\r\n\r\n## Expected behavior\r\n\r\nIt should import optuna.exceptions as shown in [examples](https://github.com/pfnet/optuna/blob/cf6aba4b7ecd2d97aa9460c06ea353d8e72570a5/tests/samplers_tests/tpe_tests/test_sampler.py).\r\n\r\n## Environment\r\n\r\n- Optuna version: I installed 0.18.1 using Conda but if I list env dependancies it show 0.17.1\r\n- Python version: 3.7\r\n- OS: MacOS\r\n- (Optional) Other libraries and their versions:\r\n\r\n## Error messages, stack traces, or logs\r\n\r\n```\r\nModuleNotFoundError: No module named 'optuna.exceptions'\r\n```\r\n\r\n## Reproducible examples (optional)\r\n\r\n```python\r\nfrom optuna.exceptions import TrialPruned\r\n```"},{"labels":["bug"],"text":"`time_budget` option on `lightgbm_tuner.train()`  is not working well with stepwise optimization.\r\nIMHO, Isn't the direction of the comparison operator reversed the following?\r\n\r\nhttps://github.com/pfnet/optuna/blob/v0.18.0/optuna/integration/lightgbm_tuner/optimize.py#L378,L407\r\n\r\n## Expected behavior\r\n\r\nI expected `time_budget` to behave like `timeout` option of `Study#optimize()`.\r\nIn other words, it is specified for the time allowed for optimization.\r\nBut current `time_budget` does not behave that so.\r\nIf large value is set, only `feature_fraction` is optimized and exited.\r\nNOTE: `feature_fraction` is the first parameter of lightgbm_tuner step-wise optimization, I expect.\r\n\r\nSorry if the above expectation is fundamentally wrong...\r\n\r\n## Environment\r\n\r\n- Optuna version: 0.18.0\r\n- Python version: 3.7.5\r\n- OS: macOS Mojave (10.14.6)\r\n- LightGBM version: 2.3.0\r\n\r\n## Error messages, stack traces, or logs\r\n\r\n- Output of step 1 (set a large value to `time_budget`)\r\n\r\n```\r\n$ python3 lgbtune.py\r\n...\r\ntune_feature_fraction, val_score: 0.109507:  86%|########5 | 6/7 [00:00<00:00, 17.63it/s][I 2019-11-08 13:03:10,975] Finished trial#6 resulted in value: 0.11621424018474308. Current best value is 0.10950685788917311 with parameters: {'feature_fraction': 0.7}.\r\ntune_feature_fraction, val_score: 0.109507: 100%|##########| 7/7 [00:00<00:00, 16.58it/s]\r\n\r\n(Process finished with exit code 0)\r\n```\r\n\r\n- Output of step 3 (comment out `time_budget`)\r\n\r\n```\r\n$ python3 lgbtune.py\r\n...\r\n...\r\ntune_min_child_samples, val_score: 0.066915:  80%|########  | 4/5 [00:00<00:00, 21.78it/s][I 2019-11-08 13:27:24,351] Finished trial#4 resulted in value: 1.4095717272810777. Current best value is 0.08811113641629516 with parameters: {'min_child_samples': 10}.\r\ntune_min_child_samples, val_score: 0.066915: 100%|##########| 5/5 [00:00<00:00, 19.24it/s]\r\n\r\n(Process finished with exit code 0)\r\n```\r\n\r\n## Steps to reproduce\r\n\r\n1. run the following code (set large value to`time_budget`)\r\n2. edit the following code. (comment out or set to zero: `time_budget`)\r\n3. re-run\r\n\r\n## Reproducible examples (optional)\r\n\r\n```python\r\n#!/usr/bin/env python3\r\n# -*- coding: utf-8 -*-\r\n\r\nfrom sklearn import datasets\r\nfrom sklearn.model_selection import train_test_split\r\nfrom optuna.integration import lightgbm_tuner\r\nimport lightgbm as lgb\r\n\r\n\r\ndef main():\r\n    dataset = datasets.load_iris()\r\n    X, y = dataset.data, dataset.target\r\n    X_train, X_test, y_train, y_test = train_test_split(X, y,\r\n                                                        shuffle=True,\r\n                                                        random_state=42)\r\n\r\n    lgb_train = lgb.Dataset(X_train, y_train)\r\n    lgb_valid = lgb.Dataset(X_test, y_test, reference=lgb_train)\r\n\r\n    lgb_params = {\r\n        'objective': 'regression',\r\n        'metric': 'rmse',\r\n    }\r\n\r\n    lightgbm_tuner.train(lgb_params, lgb_train,\r\n                         valid_sets=lgb_valid,\r\n                         num_boost_round=1000,\r\n                         early_stopping_rounds=100,\r\n                         verbose_eval=10,\r\n                         time_budget=10000,\r\n                         )\r\n\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n```\r\n"},{"labels":["bug"],"text":"While using Optuna with Keras (from Tensorflow 1.13 or 1.14), I cannot make it work with MySql or Postgre.  It seems Optuna is passing a numpy.float32 for sqlalchemy, which is causing problems (I have tried pymysql or mysqldb connectors, as well as some connectors for pg).\r\n\r\nit seems on trial.py, line 378, there should be some handling of value param being passed to sqlalchemy.\r\n\r\nself.storage.set_trial_value(self._trial_id, value)\r\n\r\nThis is the error I m getting:\r\nAttributeError: 'numpy.float32' object has no attribute 'translate'\r\n\r\nSince this function is called from inside a keras callback, there is no easy way for the Optuna user to change this, afaik.\r\n"},{"labels":["bug"],"text":"The following code plots a contour plot:\r\n```python\r\nimport optuna \r\n\r\ndef objective(trial):\r\n    x = trial.suggest_uniform('x', -10, 10)\r\n    y = trial.suggest_uniform('y', -10, 10)\r\n    return (x - 2) ** 2 + (y + 5) ** 2\r\n\r\nstudy = optuna.create_study(direction='minimize')\r\nstudy.optimize(objective, n_trials=100)\r\n\r\noptuna.visualization.plot_contour(study)\r\n```\r\n![image](https://user-images.githubusercontent.com/181413/66903062-b791cb00-f03c-11e9-9410-b8bcf56035ad.png)\r\n\r\n\r\nThe labels of the colorbar in this plot indicates that the darker the area, the worse (i.e., higher) the objective value.\r\nHowever, actually, the darker region mean that there are better (i.e., lower) objective values.\r\nI think this is a bug of `plot_contour()` method.\r\n\r\nLibrary version\r\n----------------\r\n\r\n- optuna: 0.17.1\r\n- plotly: 4.1.1\r\n"},{"labels":["bug",null,null],"text":"When a dashboard page is loaded, a new thread is spawned for rendering the page (https://github.com/pfnet/optuna/blob/v0.5.0/optuna/dashboard.py#L208). However, this thread never dies even after the page is closed (maybe). Thus, each time a user reloads the dashboard page, the number of threads increases.\r\nA thread will issue a query each second. So, this may overload the backend storage."}]