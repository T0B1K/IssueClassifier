[
  {
    "labels": ["documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/reinforcement_learning/actor_critic.ipynb\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\nAt the second cell, we want to install additional packages for visualization.\r\nMaybe should be added \"sudo apt-get update\" before the line \"sudo apt-get install -y xvfb python-opengl > /dev/null 2>&1\".\r\nLet the xvfb package can be installed normally.\r\n\r\n### Usage example\r\nCorrect the second cell as below:\r\n%%bash\r\n\r\nsudo apt-get update\r\nsudo apt-get install -y xvfb python-opengl > /dev/null 2>&1\r\npip install pyvirtualdisplay > /dev/null 2>&1\r\npip install git+https://github.com/tensorflow/docs > /dev/null 2>&1\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "The documentation is becoming too undecipherable for any practical applications using Tensorflow.\r\n\r\nLook at this one, https://www.tensorflow.org/guide/data\r\n\r\nHow would anyone learn anything for a streaming data from Disk ? Not many how-tos for data that don't fit into memory. And that page.. just like a man-page for API. We end up wasting many man hours without good documentation."
  },
  {
    "labels": [null, "documentation"],
    "text": "when i run: \r\nimport tensorflow_datasets as tfds\r\nmnist_train = tfds.load(name=\"mnist\", split=\"train\")\r\nwrong occured like this:\r\n2020-08-20 09:52:45.879679: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"Not found: Could not locate the credentials file.\". Retrieving token from GCE failed with \"Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'\".\r\n2020-08-20 09:53:46.902189: E tensorflow/core/platform/cloud/curl_http_request.cc:596] The transmission  of request 0x56396edb1ff0 (URI: https://www.googleapis.com/storage/v1/b/tfds-data/o/dataset_info%2Fmnist%2F3.0.1?fields=size%2Cgeneration%2Cupdated) has been stuck at 0 of 0 bytes for 61 seconds and will be aborted. CURL timing information: lookup time: 0.038829 (No error), connect time: 0 (No error), pre-transfer time: 0 (No error), start-transfer time: 0 (No error)\r\n2020-08-20 09:54:48.722926: E tensorflow/core/platform/cloud/curl_http_request.cc:596] The transmission  of request 0x56396eeb1ef0 (URI: https://www.googleapis.com/storage/v1/b/tfds-data/o/dataset_info%2Fmnist%2F3.0.1?fields=size%2Cgeneration%2Cupdated) has been stuck at 0 of 0 bytes for 61 seconds and will be aborted. CURL timing information: lookup time: 0.070107 (No error), connect time: 0 (No error), pre-transfer time: 0 (No error), start-transfer time: 0 (No error)\r\n2020-08-20 09:55:50.452114: E tensorflow/core/platform/cloud/curl_http_request.cc:596] The transmission  of request 0x56396edee160 (URI: https://www.googleapis.com/storage/v1/b/tfds-data/o/dataset_info%2Fmnist%2F3.0.1?fields=size%2Cgeneration%2Cupdated) has been stuck at 0 of 0 bytes for 61 seconds and will be aborted. CURL timing information: lookup time: 0.039491 (No error), connect time: 0 (No error), pre-transfer time: 0 (No error), start-transfer time: 0 (No error)\r\n2020-08-20 09:56:57.020900: E tensorflow/core/platform/cloud/curl_http_request.cc:596] The transmission  of request 0x56396efbecd0 (URI: https://www.googleapis.com/storage/v1/b/tfds-data/o/dataset_info%2Fmnist%2F3.0.1?fields=size%2Cgeneration%2Cupdated) has been stuck at 0 of 0 bytes for 61 seconds and will be aborted. CURL timing information: lookup time: 5.08334 (No error), connect time: 0 (No error), pre-transfer time: 0 (No error), start-transfer time: 0 (No error)\r\n2020-08-20 09:57:59.414296: E tensorflow/core/platform/cloud/curl_http_request.cc:596] The transmission  of request 0x56396f20f780 (URI: https://www.googleapis.com/storage/v1/b/tfds-data/o/dataset_info%2Fmnist%2F3.0.1?fields=size%2Cgeneration%2Cupdated) has been stuck at 0 of 0 bytes for 61 seconds and will be aborted. CURL timing information: lookup time: 0.039584 (No error), connect time: 0 (No error), pre-transfer time: 0 (No error), start-transfer time: 0 (No error)\r\ni want to know how can i solve it , thank you"
  },
  {
    "labels": ["documentation"],
    "text": "I think it's a bug\r\n![image](https://user-images.githubusercontent.com/7847271/84676251-f498bf00-af35-11ea-8bd4-845697e447e0.png)\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "%tensorboard --logdir {logdir}/sizes　を実行すると　UsageError: Line magic function `%tensorboard` not found.　となる。"
  },
  {
    "labels": ["documentation"],
    "text": "「初心者のためのTensorFlow 2.0 入門」のチュートリアルにある「overfit and underfit」で日本語版では、Google Colabで実行するとメモリ不足でクラッシュする。"
  },
  {
    "labels": ["documentation"],
    "text": "'head' 不是内部或外部命令，也不是可运行的程序\r\n或批处理文件。"
  },
  {
    "labels": ["documentation"],
    "text": "Hello,\r\n\r\nPlease sync the ko notebooks to the source of truth notebooks using the nb_code_sync tool here( https://github.com/tensorflow/docs-l10n/blob/master/tools/nb_code_sync.py).\r\n\r\nCurrently, many of them are failing."
  },
  {
    "labels": ["documentation"],
    "text": "https://github.com/tensorflow/docs-l10n/blob/master/site/ru/guide/migrate.ipynb\r\n\r\n```\r\nnbconvert.preprocessors.execute.CellExecutionError: An error occurred while executing the following cell:\r\n------------------\r\n  import tensorflow.compat.v2 as tf\r\nexcept Exception:\r\n  pass\r\ntf.enable_v2_behavior()\r\n\r\n\r\nimport tensorflow_datasets as tfds\r\n------------------\r\n\r\n  File \"<ipython-input-2-affb36bccd73>\", line 2\r\n    except Exception:\r\n         ^\r\nSyntaxError: invalid syntax\r\n\r\nSyntaxError: invalid syntax (<ipython-input-2-affb36bccd73>, line 2)\r\n```\r\n\r\nhttps://github.com/tensorflow/docs-l10n/blob/master/site/ru/tutorials/keras/save_and_load.ipynb\r\n```\r\nnbconvert.preprocessors.execute.CellExecutionError: An error occurred while executing the following cell:\r\n------------------\r\nimport time\r\nsaved_model_path = \"./saved_models/{}\".format(int(time.time()))\r\n\r\ntf.keras.experimental.export_saved_model(model, saved_model_path)\r\nsaved_model_path\r\n------------------\r\n\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-20-9d5aff309515> in <module>\r\n      2 saved_model_path = \"./saved_models/{}\".format(int(time.time()))\r\n      3 \r\n----> 4 tf.keras.experimental.export_saved_model(model, saved_model_path)\r\n      5 saved_model_path\r\n\r\nAttributeError: module 'tensorflow_core.python.keras.api._v2.keras.experimental' has no attribute 'export_saved_model'\r\nAttributeError: module 'tensorflow_core.python.keras.api._v2.keras.experimental' has no attribute 'export_saved_model'\r\n```\r\n\r\nhttps://github.com/tensorflow/docs-l10n/blob/master/site/ru/tutorials/keras/text_classification_with_hub.ipynb\r\n```\r\nnbconvert.preprocessors.execute.CellExecutionError: An error occurred while executing the following cell:\r\n------------------\r\n# Разобьем обучающую выборку в пропорции 60% на 40%, и у нас будет 15,000 примеров\r\n# для обучения, 10,000 примеров для валидации и 25,000 примеров для проверки.\r\ntrain_validation_split = tfds.Split.TRAIN.subsplit([6, 4])\r\n\r\n(train_data, validation_data), test_data = tfds.load(\r\n    name=\"imdb_reviews\", \r\n    split=(train_validation_split, tfds.Split.TEST),\r\n    as_supervised=True)\r\n------------------\r\n\r\n---------------------------------------------------------------------------\r\nAssertionError                            Traceback (most recent call last)\r\n<ipython-input-3-ecc6d6ac73cf> in <module>\r\n      6     name=\"imdb_reviews\",\r\n      7     split=(train_validation_split, tfds.Split.TEST),\r\n----> 8     as_supervised=True)\r\n\r\n~/.local/lib/python3.6/site-packages/tensorflow_datasets/core/api_utils.py in disallow_positional_args_dec(fn, instance, args, kwargs)\r\n     50     _check_no_positional(fn, args, ismethod, allowed=allowed)\r\n     51     _check_required(fn, kwargs)\r\n---> 52     return fn(*args, **kwargs)\r\n     53 \r\n     54   return disallow_positional_args_dec(wrapped)  # pylint: disable=no-value-for-parameter\r\n\r\n...\r\n\r\n~/.local/lib/python3.6/site-packages/tensorflow_datasets/core/tfrecords_reader.py in _str_to_relative_instruction(spec)\r\n    354   res = _SUB_SPEC_RE.match(spec)\r\n    355   if not res:\r\n--> 356     raise AssertionError('Unrecognized instruction format: %s' % spec)\r\n    357   unit = '%' if res.group('from_pct') or res.group('to_pct') else 'abs'\r\n    358   return ReadInstruction(\r\n\r\nAssertionError: Unrecognized instruction format: NamedSplit('train')(tfds.percent[0:60])\r\nAssertionError: Unrecognized instruction format: NamedSplit('train')(tfds.percent[0:60])\r\n```\r\n\r\nhttps://github.com/tensorflow/docs-l10n/blob/master/site/ru/tutorials/load_data/text.ipynb\r\n```\r\nnbconvert.preprocessors.execute.CellExecutionError: An error occurred while executing the following cell:\r\n------------------\r\ntrain_data = all_encoded_data.skip(TAKE_SIZE).shuffle(BUFFER_SIZE)\r\ntrain_data = train_data.padded_batch(BATCH_SIZE)\r\n\r\ntest_data = all_encoded_data.take(TAKE_SIZE)\r\ntest_data = test_data.padded_batch(BATCH_SIZE)\r\n------------------\r\n\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-13-be2cd799459e> in <module>\r\n      1 train_data = all_encoded_data.skip(TAKE_SIZE).shuffle(BUFFER_SIZE)\r\n----> 2 train_data = train_data.padded_batch(BATCH_SIZE)\r\n      3 \r\n      4 test_data = all_encoded_data.take(TAKE_SIZE)\r\n      5 test_data = test_data.padded_batch(BATCH_SIZE)\r\n\r\nTypeError: padded_batch() missing 1 required positional argument: 'padded_shapes'\r\nTypeError: padded_batch() missing 1 required positional argument: 'padded_shapes'\r\n```\r\n"
  },
  {
    "labels": ["documentation"],
    "text": " padded_batch() missing 1 required positional argument: 'padded_shapes' in line train_data = train_data.padded_batch(BATCH_SIZE)"
  },
  {
    "labels": ["documentation"],
    "text": "### site/zh-cn/tutorials/distribute/multi_worker_with_keras.ipynb\r\n\r\n```\r\nnbconvert.preprocessors.execute.CellExecutionError: An error occurred while executing the following cell:\r\n------------------\r\noptions = tf.data.Options()\r\noptions.experimental_distribute.auto_shard = False\r\ntrain_datasets_no_auto_shard = train_datasets.with_options(options)\r\n------------------\r\n\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-9-540e26d88b40> in <module>\r\n      1 options = tf.data.Options()\r\n----> 2 options.experimental_distribute.auto_shard = False\r\n      3 train_datasets_no_auto_shard = train_datasets.with_options(options)\r\n\r\n/tmpfs/src/tf_docs_env/lib/python3.6/site-packages/tensorflow_core/python/data/util/options.py in __setattr__(self, name, value)\r\n     54     else:\r\n     55       raise AttributeError(\r\n---> 56           \"Cannot set the property %s on %s.\" % (name, type(self).__name__))\r\n     57 \r\n     58 \r\n\r\nAttributeError: Cannot set the property auto_shard on DistributeOptions.\r\n```\r\n\r\n###  site/zh-cn/tutorials/generative/style_transfer.ipynb\r\n\r\n```\r\nnbconvert.preprocessors.execute.CellExecutionError: An error occurred while executing the following cell:\r\n------------------\r\nfile_name = 'kadinsky-turtle.png'\r\nmpl.image.imsave(file_name, image[0])\r\n\r\ntry:\r\n  from google.colab import files\r\nexcept ImportError:\r\n   pass\r\nelse:\r\n  files.download(file_name)\r\n------------------\r\n\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-35-aea7d0ffa719> in <module>\r\n      1 file_name = 'kadinsky-turtle.png'\r\n----> 2 mpl.image.imsave(file_name, image[0])\r\n      3 \r\n      4 try:\r\n      5   from google.colab import files\r\n\r\n~/.local/lib/python3.6/site-packages/matplotlib/image.py in imsave(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\r\n   1548         if origin == \"lower\":\r\n   1549             arr = arr[::-1]\r\n-> 1550         rgba = sm.to_rgba(arr, bytes=True)\r\n   1551         if format == \"png\" and pil_kwargs is None:\r\n   1552             with cbook.open_file_cm(fname, \"wb\") as file:\r\n\r\n~/.local/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba(self, x, alpha, bytes, norm)\r\n    215                         alpha = np.uint8(alpha * 255)\r\n    216                     m, n = x.shape[:2]\r\n--> 217                     xx = np.empty(shape=(m, n, 4), dtype=x.dtype)\r\n    218                     xx[:, :, :3] = x\r\n    219                     xx[:, :, 3] = alpha\r\n\r\nTypeError: data type not understood\r\n```\r\n\r\n### site/zh-cn/tutorials/keras/text_classification_with_hub.ipynb\r\n\r\n```\r\nnbconvert.preprocessors.execute.CellExecutionError: An error occurred while executing the following cell:\r\n------------------\r\n# 将训练集按照 6:4 的比例进行切割，从而最终我们将得到 15,000\r\n# 个训练样本, 10,000 个验证样本以及 25,000 个测试样本\r\ntrain_validation_split = tfds.Split.TRAIN.subsplit([6, 4])\r\n\r\n(train_data, validation_data), test_data = tfds.load(\r\n    name=\"imdb_reviews\", \r\n    split=(train_validation_split, tfds.Split.TEST),\r\n    as_supervised=True)\r\n------------------\r\n\r\n---------------------------------------------------------------------------\r\nAssertionError                            Traceback (most recent call last)\r\n<ipython-input-3-fd9cf994df99> in <module>\r\n      6     name=\"imdb_reviews\",\r\n      7     split=(train_validation_split, tfds.Split.TEST),\r\n----> 8     as_supervised=True)\r\n\r\n~/.local/lib/python3.6/site-packages/tensorflow_datasets/core/api_utils.py in disallow_positional_args_dec(fn, instance, args, kwargs)\r\n     50     _check_no_positional(fn, args, ismethod, allowed=allowed)\r\n     51     _check_required(fn, kwargs)\r\n---> 52     return fn(*args, **kwargs)\r\n     53 \r\n     54   return disallow_positional_args_dec(wrapped)  # pylint: disable=no-value-for-parameter\r\n\r\n...\r\n\r\n~/.local/lib/python3.6/site-packages/tensorflow_datasets/core/tfrecords_reader.py in _str_to_relative_instruction(spec)\r\n    354   res = _SUB_SPEC_RE.match(spec)\r\n    355   if not res:\r\n--> 356     raise AssertionError('Unrecognized instruction format: %s' % spec)\r\n    357   unit = '%' if res.group('from_pct') or res.group('to_pct') else 'abs'\r\n    358   return ReadInstruction(\r\n\r\nAssertionError: Unrecognized instruction format: NamedSplit('train')(tfds.percent[0:60])\r\n```\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "The `tf-nightly-2.0-preview` package does not exist anymore. Please upgrade all notebooks to use `%tensorflow_version 2.x` like:\r\n\r\n```\r\ntry:\r\n  # %tensorflow_version only exists in Colab.\r\n  %tensorflow_version 2.x\r\nexcept Exception:\r\n  pass\r\n```\r\n\r\nAffects:\r\n\r\n* [/site/ko/tutorials/keras/text_classification.ipynb](https://github.com/tensorflow/docs-l10n/blob/master/site/ko/tutorials/keras/text_classification.ipynb)\r\n* [/site/ko/tutorials/keras/overfit_and_underfit.ipynb](https://github.com/tensorflow/docs-l10n/blob/master/site/ko/tutorials/keras/overfit_and_underfit.ipynb)\r\n* [/site/ko/tutorials/structured_data/feature_columns.ipynb](https://github.com/tensorflow/docs-l10n/blob/master/site/ko/tutorials/structured_data/feature_columns.ipynb)\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "The `tf-nightly-2.0-preview` package does not exist anymore. Please upgrade all notebooks to use `%tensorflow_version 2.x` like:\r\n\r\n```\r\ntry:\r\n  # %tensorflow_version only exists in Colab.\r\n  %tensorflow_version 2.x\r\nexcept Exception:\r\n  pass\r\n```\r\n\r\nAffects:\r\n\r\n* [/site/zh-cn/lite/convert/python_api.md](https://github.com/tensorflow/docs-l10n/blob/master/site/zh-cn/lite/convert/python_api.md)\r\n* [/site/zh-cn/tutorials/estimator/boosted_trees.ipynb](https://github.com/tensorflow/docs-l10n/blob/master/site/zh-cn/tutorials/estimator/boosted_trees.ipynb)\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "The `tf-nightly-2.0-preview` package does not exist anymore. Please upgrade all notebooks to use `%tensorflow_version 2.x` like:\r\n\r\n```\r\ntry:\r\n  # %tensorflow_version only exists in Colab.\r\n  %tensorflow_version 2.x\r\nexcept Exception:\r\n  pass\r\n```\r\n\r\nAffects:\r\n\r\n* [/site/ja/lite/convert/python_api.md](https://github.com/tensorflow/docs-l10n/blob/master/site/ja/lite/convert/python_api.md)\r\n* [/site/ja/guide/function.ipynb](https://github.com/tensorflow/docs-l10n/blob/master/site/ja/guide/function.ipynb)\r\n* [/site/ja/tutorials/load_data/csv.ipynb](https://github.com/tensorflow/docs-l10n/blob/master/site/ja/tutorials/load_data/csv.ipynb)\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "This tutorials is currently broken (also needs a `%tensorflow_version 2.x`):\r\n\r\nhttps://github.com/tensorflow/docs-l10n/blob/master/site/ja/tutorials/load_data/csv.ipynb"
  },
  {
    "labels": ["documentation"],
    "text": "This package does not exist anymore. Please upgrade all notebooks to use `%tensorflow_version 2x`.\r\n\r\nhttps://github.com/tensorflow/docs-l10n/search?q=tf-nightly-2.0-preview&unscoped_q=tf-nightly-2.0-preview"
  },
  {
    "labels": ["documentation"],
    "text": "https://github.com/tensorflow/docs-l10n/search?q=%22keras.experimental.export_saved_model%22&unscoped_q=%22keras.experimental.export_saved_model%22\r\n\r\n```\r\n# Exportar el modelo a 'SavedModel'\r\nkeras.experimental.export_saved_model(model, 'path_to_saved_model')\r\n\r\n# Recrea exactamente el mismo modelo\r\nnew_model = keras.experimental.load_from_saved_model('path_to_saved_model')\r\n```\r\n\r\nThese should just be `model.save('path_to_saved_model')`, and `keras.models.load_model('path_to_saved_model')`."
  },
  {
    "labels": ["documentation"],
    "text": "I found issues about after convert to docs that generated extra notebook cell.\r\n\r\n- https://www.tensorflow.org/tutorials/keras/classification in Japanesse version\r\n\r\n![image](https://user-images.githubusercontent.com/2786333/77142134-896c5780-6ac2-11ea-94f8-8e97e35c7521.png)\r\n\r\n- Original: notebook \r\n- https://github.com/masa-ita/tf-docs/blob/b8cd622e042ce322345d5fa30858087ee1abcab1/site/ja/tutorials/keras/basic_classification.ipynb\r\n\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "Is it possible to correct some Portuguese notebooks, as they have some typos? I'm a Portuguese native speaker."
  },
  {
    "labels": ["documentation"],
    "text": "## URL(s) with the issue \r\n\r\nhttps://www.tensorflow.org/install?hl=ko\r\n\r\n## Description of issue (what needs changing)\r\n\r\nOn installation document/windows build from source page, it tells that \"TensorFlow를 컴파일하는 데 사용되는 빌드 도구인 Bazel 0.23.0을 설치합니다. C++를 빌드하도록 Bazel을 설정합니다.\" which means install Bazel 0.23.0 to compile Tensorflow. However, most recent version of Tensorflow which is r2.1, doesn't support Bazel 0.23.0. Instead, it uses 0.27.0~0.29.0. I checked English document and it tells me the version of Bazel that is needed. So, I think the Korean page should be renewed like this.\r\n\r\n## Bazel 설치\r\n\r\nTensorFlow를 컴파일하는 데 사용되는 빌드 도구인 [Bazel](https://docs.bazel.build/versions/master/install.html)을 설치합니다. tensorflow/configure.py에 명시된 _TF_MIN_BAZEL_VERSION과 _TF_MAX_BAZEL_VERSION 사이의 지원되는 버전을 사용합니다.\r\n\r\nBazel 실행 파일의 위치를 %PATH% 환경 변수에 추가합니다."
  },
  {
    "labels": ["documentation"],
    "text": "The default Matplotlib setup in Colab doesn't include Chinese or Korean fonts, so these characters don't render.\r\n\r\nI believe this is one of the reasons we have not been translating figure text.\r\n\r\nI can get the browser to render this text by outputting svg-text:\r\n\r\n```\r\nfrom IPython.display import set_matplotlib_formats\r\nset_matplotlib_formats('svg')\r\nmatplotlib.rcParams['svg.fonttype'] = 'none'\r\n```\r\n\r\nBut that messes up a lot of the formatting.\r\n\r\nSome searching shows that it might just be a matter of installing the right fonts and adding them to the `matplotlib.rc` configuration, but I haven't found a end-to-end setup that works yet. \r\n\r\nDoes anyone have experience setting this up?\r\n\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/lite/api_docs/cc\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe C++ API references for TFLite are missing many important components on tensorflow.org. For example, the docs for `tflite::FlatBufferModel` and `tflite::InterpreterBuilder` are completely gone, which used to be there the last time I checked, about two months ago.\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "@tensorflow/micro\r\n\r\n**Describe the problem**\r\n\r\nIn the quantize kernel the calculation of the effective scale differs slightly between TFLite and TFLu. We found that in some cases this results in single bit differences in output. Is this difference in implementation intentional?\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/de1a269b21cbad035faa095d8ce88fc2d680cf4a/tensorflow/lite/kernels/quantize.cc#L129-L133\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/de1a269b21cbad035faa095d8ce88fc2d680cf4a/tensorflow/lite/micro/kernels/quantize.cc#L75-L79\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "https://www.tensorflow.org/install/lang_java\r\n\r\n\r\nThe JNI download link on the Java page is still points to 1.14.0, it should be updated to 2.3.0.\r\n\r\npage source:\r\n```\r\n<td>Linux CPU only</td>\r\n  | <td class=\"devsite-click-to-copy\"><a href=\"https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow_jni-cpu-linux-x86_64-1.14.0.tar.gz\">https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow_jni-cpu-linux-x86_64-2.3.0.tar.gz</a></td>\r\n  | </tr>\r\n  | <tr>\r\n  | <td>Linux GPU support</td>\r\n  | <td class=\"devsite-click-to-copy\"><a href=\"https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow_jni-gpu-linux-x86_64-1.14.0.tar.gz\">https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow_jni-gpu-linux-x86_64-2.3.0.tar.gz</a></td>\r\n  | </tr>\r\n ```"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/xla/operation_semantics#conv_convolution\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/5f2e159a58d1ef3414b2c34339266449574d8f94/tensorflow/compiler/tf2xla/python/xla.py#L239:L269\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\n [tf2xla.python.xla.conv](https://github.com/tensorflow/tensorflow/blob/5f2e159a58d1ef3414b2c34339266449574d8f94/tensorflow/compiler/tf2xla/python/xla.py#L239:L269) points to the operation semantics for `ConvWithGeneralPadding` but actually wraps the more general `ConvGeneralDilated`. It would make sense to actually have documentation about the operation semantics of this more general operation.\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "The issue is for this page: https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/resource-apply-centered-r-m-s-prop\r\n\r\n`momentum` is missing from the list of arguments.\r\n\r\nCurrent doc has this:\r\n\r\n```\r\nscope: A Scope object\r\nvar: Should be from a Variable().\r\nmg: Should be from a Variable().\r\nms: Should be from a Variable().\r\nmom: Should be from a Variable().\r\nlr: Scaling factor. Must be a scalar.\r\nrho: Decay rate. Must be a scalar.\r\nepsilon: Ridge term. Must be a scalar.\r\ngrad: The gradient.\r\n```\r\n\r\nThis should be instead like this (momentum added after rho):\r\n\r\n```\r\nscope: A Scope object\r\nvar: Should be from a Variable().\r\nmg: Should be from a Variable().\r\nms: Should be from a Variable().\r\nmom: Should be from a Variable().\r\nlr: Scaling factor. Must be a scalar.\r\nrho: Decay rate. Must be a scalar.\r\nmomentum: momentum scale. Must be a scalar.\r\nepsilon: Ridge term. Must be a scalar.\r\ngrad: The gradient.\r\n```\r\n\r\n### Clear description\r\nThis could be due to a bug in the scripts that auto-generate the api-def.\r\n\r\nThis is the op registration from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/ops/training_ops.cc#L1056-L1069 \r\n\r\n```\r\nREGISTER_OP(\"ResourceApplyCenteredRMSProp\")\r\n    .Input(\"var: resource\")\r\n    .Input(\"mg: resource\")\r\n    .Input(\"ms: resource\")\r\n    .Input(\"mom: resource\")\r\n    .Input(\"lr: T\")\r\n    .Input(\"rho: T\")\r\n    .Input(\"momentum: T\")\r\n    .Input(\"epsilon: T\")\r\n    .Input(\"grad: T\")\r\n    .Attr(\"T: numbertype\")\r\n    .Attr(\"use_locking: bool = false\")\r\n    .SetShapeFn(\r\n        ApplyCenteredRMSPropShapeFn</*is_sparse=*/false, /*is_resource=*/true>);\r\n```\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/losses/CosineSimilarity\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\n\"Note that it is a negative quantity between -1 and 0\" should be changed to \"Note that it is a negative quantity between -1 and 1\"\r\n\r\n### Correct links\r\n\r\n### Parameters defined\r\n\r\n### Returns defined\r\n\r\n### Raises listed and defined\r\n\r\n### Usage example\r\n\r\n### Request visuals, if applicable\r\n\r\n### Submit a pull request?\r\n\r\nDon't plan to submit pull request\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/guide/graph_optimization\r\n\r\n## Description of issue (what needs changing):\r\nIt should be cleared which optimizers Grappler applies by default. \r\nFor now it's not clear if i should turn on a lot of features by myself\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly? - No.\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\n<https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer#call>\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nThe `call` method is listed as `call(inputs, **kwargs)`, and documents\r\nthat `inputs` is an “Input tensor, or list/tuple of input tensors.” But\r\nactual code usage shows that `call` may accept multiple positional\r\narguments depending on the actual layer implementation. For instance:\r\n\r\n  - <https://www.tensorflow.org/guide/keras/custom_layers_and_models#the_add_metric_method>\r\n  - <https://github.com/tensorflow/models/blob/27bda1fc2d3557555ee8a48bbf1fb04f5c2f59e8/official/nlp/bert/bert_models.py#L68-L73>\r\n\r\nThis is confusing when reviewing code that defines a custom layer,\r\nbecause the docs for `call` don’t reflect the actual usage.\r\n\r\n\r\n### Submit a pull request?\r\n\r\n> Are you planning to also submit a pull request to fix the issue?\r\n\r\nNo; I don’t have enough domain expertise to be confident about the\r\ndetails.\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\nhttps://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/classification.ipynb\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\nUnder Load using Keras.preprocessing > Create Dataset, the percentage under training_ds for validation_split is set to 0.2. I believe is supposed to be 0.8.\r\n\r\n\r\n### Clear description\r\n\r\nWhen you used 0.8 on the number of images in the directory, it will result to 2936, but 0.2 is way smaller. \r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/device\r\n\r\n## Description of issue (what needs changing):\r\n\r\nAt least on 2.3.0, it seems to me that \r\n```\r\nimport numpy.random as npr\r\nimport tensorflow as tf\r\nwith tf.device(\"GPU\"):\r\n  A=tf.convert_to_tensor(npr.randn(500))\r\n```\r\nwill create an eager tensor `A` on the CPU device (it will not allocate ram on the gpu).  This is counter-intuitive to someone who has only read the doc as it is written.  My understanding is that this happens because tf.convert_to_tensor isn't an op, and tf.device only deals with ops.  \r\n\r\n### Clear description\r\n\r\nThe doc is pretty short now, and I don't think it would hurt to add a little remark, something like this:\r\n\r\n*Note* -- `tf.convert_to_tensor` does not create an op.  As such, it ignores the contexts created by tf.device.  To ensure a given tensor is assigned memory on a particular device, one can wrap convert_to_tensor inside a `tf.identity` op.\r\n\r\nThoughts?"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue: https://www.tensorflow.org/guide/data_performance_analysis\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/guide/data_performance_analysis#3_are_you_reaching_high_cpu_utilization\r\n\r\n## Description of issue (what needs changing):\r\n\r\nReferring to the following line:\r\n\r\n> tf.data achieves high throughput by trying to make the best possible use of available resources. In general, even when running your model on an accelerator like a GPU or TPU, the tf.data pipelines are run on the CPU. You can check your utilization with tools like sar and htop, or in the cloud monitoring console if you’re running on GCP.\r\n\r\nThe link attached to \"cloud monitoring console\" is invalid.\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "### Description:\r\n\r\nHey @lamberta @MarkDaoust @yashk2810, \r\n\r\nI've put together a few small commits to update the TensorFlow docs for more inclusive language. It's to do with ~~”Native”~~ -> “Built-in”. (Source: an a11y [presentation](https://docs.google.com/presentation/d/1UVHzuMo5Ef1zUCZ3qdFwDQh-aVHpkYnY73TrJ2yHt3E/edit#slide=id.g6fe49527a0_0_334) by @heyawhite—a tech writer at Google). \r\n\r\n[Link to diffs](https://github.com/tensorflow/docs/compare/master...8bitmp3:master).\r\n\r\nIf you're OK with these changes, I can submit a PR.\r\n\r\n### Submit a pull request?\r\n\r\nYes, can do\r\n\r\n### Affected docs:\r\n\r\n- TF testing best practices guide\r\n- TensorFlow (R1) C++ API guide\r\n- TF 1.x Eager mode notebook\r\n- TensorFlow Customization basics notebook\r\n- Build TensorFlow on Windows guide\r\n- TensorFlow 2 migration notebook\r\n- tf.function notebook\r\n- TF create an op in C++ guide\r\n- TF (R1) Adding a new op in C++ guide"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.3.0\r\n- Python version: 3.7\r\n\r\n**Describe the current behavior**\r\n\r\nCurrently https://www.tensorflow.org/api_docs/python/tf/nn/ctc_beam_search_decoder says it expects input to be logits, whereas it acutally expects softmax already applied.\r\n\r\nSee https://www.tensorflow.org/api_docs/python/tf/keras/backend/ctc_decode, which expects output of softmax, and it directly passes the input to https://www.tensorflow.org/api_docs/python/tf/nn/ctc_beam_search_decoder - see https://github.com/tensorflow/tensorflow/blob/7b301123019d2b4bbd9c597916ba032f05854074/tensorflow/python/keras/backend.py#L6037-L6088\r\n\r\n**Describe the expected behavior**\r\n\r\nThe documentation of https://www.tensorflow.org/api_docs/python/tf/nn/ctc_beam_search_decoder should say it expects softmax output.\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.3.0\r\n- Python version: 3.7\r\n\r\n**Describe the current behavior**\r\n\r\nCurrently https://www.tensorflow.org/api_docs/python/tf/nn/ctc_loss and https://www.tensorflow.org/api_docs/python/tf/nn/ctc_beam_search_decoder has different default blank index.\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/nn/ctc_loss sets default blank index to be 0.\r\n\r\nWhreas https://www.tensorflow.org/api_docs/python/tf/nn/ctc_beam_search_decoder doesn't have an API for setting blank index, and it assumes to be `num_category - 1` (see https://github.com/tensorflow/tensorflow/blob/cd7da16dd6c17df428dc9ec105c0c8f11e5fd4f5/tensorflow/core/kernels/ctc_decoder_ops.cc#L331)\r\n\r\n**Describe the expected behavior**\r\n\r\nThis is very unexpected - I would assume they have the same default value since they both work with CTC. Or at least both should provide API to change the blank index. \r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/install/source\r\n\r\n## Description of issue (what needs changing):\r\nAproximately the RAM that used when compiling. IMO, \"Building TensorFlow from source can use **a lot of** RAM\", is not clear how \"a lot of\" is how many GB. I have VM with 6vCPU 10GB RAM and I frequently run out of memory. This run out of memory is not only slowing down the compiling, but also make system freeze/unresponsive, Every this happens, I need to increase the RAM by 500MB to unlock the system.\r\n\r\n### Clear description\r\nWhy we need this? Because we don't want to sleep with the machine compiling overnight. And when we wakes up, it turns out the compiling failed, or the machine frozen, and it's really waste of time. This \"aproximately RAM usage\" should help anticipate this though.\r\n\r\n### How about `--local_ram_resources`?\r\nWell, I already tried with this flag `--local_ram_resources=HOST_RAM*.2` as described from [here](https://docs.bazel.build/versions/master/user-manual.html#flag--local_{ram,cpu}_resources). Is this mean the building process will only take 20% RAM? Is this global or for every thread? Is this flag supported on the `v2.3.0` tag on this repo? I watched `htop` and seen many tasks at once using more than 20%. I run out of memory again even with this, this is ridiculous. 😭 \r\n\r\n### Submit a pull request?\r\nTo this [repo](https://github.com/tensorflow/docs)? Yes if I can get how aproximately the RAM usage... I think it's max around 3GB per CPU core? Correct me if I'm wrong.\r\n\r\n### Other information\r\nWell it seems I got a lot of RAM, but I running out of memory. The VM is live CD (not installed), and also the swap.... yeah it's zram (5GB) instead of swapfile. Because... uh..., I don't want to kill the SSD :(\r\n\r\n### Related issue\r\n#30047"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nhttps://tensorflow.google.cn/guide/autodiff\r\n\r\n## Description of issue (what needs changing):\r\n\r\nWhen listing the reason of the \"None\" gradient (Chapter of \"Getting a gradient of None\"), the text  \"**3. Took gradients through an integer or string**\" is followed by order number \"5\", which is \"**5. Took gradients through a stateful object**\". Suggest to correct it to  \"**4. Took gradients through a stateful object**\"\r\n\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "This is the same issue mentioned [here](https://github.com/tensorflow/tensorflow/issues/41413).\r\n\r\nCurrently [here](https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/tf2_text_classification.ipynb#scrollTo=zXXx5Oc3pOmN) under 'Loss function and optimizer' it says:\r\n\r\n```\r\nmodel.compile(optimizer='adam',\r\n              loss=tf.losses.BinaryCrossentropy(from_logits=True),\r\n              metrics=['accuracy'])\r\n```\r\n\r\nThis needs to be corrected to:\r\n\r\n\r\n`model.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=[tf.metrics.BinaryAccuracy(threshold=0.0, name='accuracy')])`\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "I'm following the [GPU install instructions](https://www.tensorflow.org/install/gpu) for Ubuntu 18.04 and getting the following after running this:\r\n```\r\nsudo apt-get install --no-install-recommends \\\r\n    cuda-10-1 \\\r\n    libcudnn7=7.6.5.32+cuda10.1  \\\r\n    libcudnn7-dev=7.6.5.32-1+cuda10.1\r\n```\r\nI'm getting this:\r\n```\r\nReading package lists... Done\r\nBuilding dependency tree       \r\nReading state information... Done\r\nE: Version '7.6.5.32+cuda10.1' for 'libcudnn7' was not found\r\n```\r\n `7.6.5.32+cuda10.1` may need to be changed to  `7.6.5.32-1+cuda10.1`  since the latter works.\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "https://www.tensorflow.org/tutorials/structured_data/time_series#part_2_forecast_a_multivariate_time_series\r\n\r\nI do not understand how this can be time series ? The data is \"equidistant\" with each other. And the time itself is not considered in predicting the values, but rather just as a series. When you include TIME AS A VECTOR, i would accept that it is a Timeseries.\r\n\r\nThe title is MISLEADING and also we need an example for vectorizing Time... for an actual Timeseries."
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\n- https://github.com/tensorflow/tensorflow/releases/tag/v2.3.0\r\n- https://www.tensorflow.org/tutorials/distribute/input#partial_batches\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe release note states \r\n> tf.distribute.experimental.MultiWorkerMirroredStrategy adds support for partial batches.\r\n\r\nHowever the documentation/tutorial states\r\n> Currently this is supported for all strategies except tf.distribute.experimental.MultiWorkerMirroredStrategy.\r\n> [...] Partial batches are supported for all strategies except tf.distribute.experimental.MultiWorkerMirroredStrategy.\r\n\r\nThis sounds like those contradict each other. What is the actual reality? Can the documentation or the release notes be updated to clarify?"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\n[https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv1DTranspose]()\r\n\r\n## Description of issue (what needs changing):\r\nConv1DTranspose - Dilation - Does not inform uses that dilation doesn't work for any value  of `Dilation>1` because it isn't implemented yet. \r\n### Clear description\r\nCurrently documentation says:\r\n_\"an integer, specifying the dilation rate to use for dilated convolution. Currently, specifying a dilation_rate value != 1 is incompatible with specifying a stride value != 1.\"_\r\n\r\nThis may not be implemented yet in the newest of nightly build, but with my tf-nightly==2.5.0dev20200629 build this didn't work. I fear updating to new nightly builds in case in breaks my research code which relies on nightly builds until Conv1DTranspose is released in a supported build.\r\n```\r\nInvalidArgumentError:  Current libxsmm and customized CPU implementations do not yet support dilation rates larger than 1.\r\n\t [[node test1_AE/decoder/conv1d_transpose/conv1d_transpose (defined at D:\\Users\\[username]\\Desktop\\libs_python\\nn4n_autoencoder4.py:120) ]] [Op:__inference_train_function_2185]\r\n\r\nFunction call stack:\r\ntrain_function\r\n```\r\nThis is with stride == 1.\r\n### Correct links\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/convolutional.py\r\n\r\n### Parameters defined\r\n\r\nYes, setting my dilation to 1 gets rid of the issue.\r\n\r\n### Returns defined\r\n\r\nNot necessary. (I'm not sure if you are asking if I have define returns in my code or if my code returns a defined value, or if the documentation claims to return something)\r\n\r\n### Raises listed and defined\r\n```\r\nInvalidArgumentError:  Current libxsmm and customized CPU implementations do not yet support dilation rates larger than 1.\r\n\t [[node test1_AE/decoder/conv1d_transpose/conv1d_transpose (defined at D:\\Users\\[username]\\Desktop\\libs_python\\nn4n_autoencoder4.py:120) ]] [Op:__inference_train_function_2185]\r\n\r\nFunction call stack:\r\ntrain_function\r\n```\r\n\r\n### Usage example\r\n\r\nNightly build, so no.\r\n\r\n### Request visuals, if applicable\r\n No.\r\n\r\n### Submit a pull request?\r\nI will not be doing so.\r\n\r\n\r\n### Test Code\r\n\r\nNote 1: This is built with tf-nightly==2.5.0dev20200626 which was removed from the PyPi archive for unknown reasons.\r\n\r\nNote 2: model.fit must be called for the error to occur. Simpy constructing and compiling the network was not enough to reproduce the error.\r\n\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow.keras as krs\r\nimport numpy as np\r\n\r\ntrain_data = np.random.uniform(-1,1,(20,20))\r\n\r\ninputs = krs.Input((20,1))\r\n\r\nx = inputs\r\n\r\nx = krs.layers.Conv1D(1,3,strides = 1,padding='same',dilation_rate=2,activation='relu')(x)\r\nx = krs.layers.Flatten()(x)\r\nx = krs.layers.Dense(10,activation='relu')(x)\r\nx = krs.layers.Dense(2,activation='relu')(x)\r\nx = krs.layers.Dense(10,activation='relu')(x)\r\nx = krs.layers.Dense(20,activation='relu')(x)\r\nx = krs.layers.Reshape(target_shape=(20,1))(x)\r\nx = krs.layers.Conv1DTranspose(1,3,strides=1,dilation_rate=2,padding='same',activation='relu',output_padding=0)(x)\r\noutput = krs.layers.Flatten()(x)\r\n\r\nmodel = krs.Model(inputs,output,name='test')\r\n\r\nmodel.compile(optimizer='adam',loss='MSE')\r\n\r\nmodel.summary()\r\n\r\nmodel.fit(train_data,train_data)\r\n```"
  },
  {
    "labels": [null, "documentation"],
    "text": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1.  It must be a bug, a feature request, or a significant problem with the\r\n    documentation (for small docs fixes please send a PR instead).\r\n2.  The form below must be filled out.\r\n3.  It shouldn't be a TensorBoard issue. Those go\r\n    [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n\r\nUbuntu 18.04, system with two GPUs, tensorflow 2.2\r\n\r\n### Describe the problem\r\n\r\nThe guide, near the top, includes the following:\r\n\r\nphysical_devices = tf.config.experimental.list_physical_devices('GPU')\r\nif physical_devices:\r\n  tf.config.experimental.set_memory_growth(physical_devices[0], True)\r\n\r\nand on a multi-GPU system, this will lead to problems later because memory growth will only be managed on one of the GPUs.  It should instead be:\r\n\r\nphysical_devices = tf.config.experimental.list_physical_devices('GPU')\r\nfor device in physical_devices:\r\n  tf.config.experimental.set_memory_growth(device, True)\r\n\r\nI am aware that this is really a minor documentation issue, and would prefer to simply upload the fix myself.  Unfortunately, I am not willing to sign the Contributor License Agreement.  I have many friends at Google with whom I have many technical discussions.  I don't want those discussions to automatically grant licenses to Google if I forget to say \"not a contribution\" at the beginning of them.\r\n### Source code / logs\r\n\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/api_docs/python/tf/linalg/inv\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe first paragraph says\r\n\r\n> Computes the inverse of one or more square invertible matrices or their\r\n\r\ninstead of \r\n\r\n> Computes the inverse of one or more square invertible matrices or their adjoints (conjugate transposes).\r\n\r\n![image](https://user-images.githubusercontent.com/552629/88276649-b2eef700-ccdf-11ea-9b32-1eb450ffc57a.png)\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "### Affected Doc URL\r\nhttps://github.com/tensorflow/models/blob/master/research/slim/README.md#pre-trained-models\r\n\r\n### Description\r\n\r\nBoth tf-slim VGG and Inception preprocessing cause the ResNet v1 models in the above link to have incorrect outputs.  The other ImageNet models run correctly with either the VGG or Inception preprocessing, however under the same code path, ResNet v1 models produce incorrect outputs.  This issue is also documented in [this unresolved issue](https://github.com/tensorflow/tensorflow/issues/17426).\r\n\r\nAre we aware of the correct steps to take to correctly run slim's ResNet v1 models and could this be updated in the documentation?\r\n\r\nThank you."
  },
  {
    "labels": [null, "documentation"],
    "text": "Here is the guide to Tensorflow Lite Support Library:\r\nhttps://www.tensorflow.org/lite/guide/lite_support\r\n\r\nAn exert:\r\n\r\n> The [TensorFlow Lite Android Support Library](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/experimental/support/java) is designed to help process the input and output of TensorFlow Lite models, and make the TensorFlow Lite interpreter easier to use.\r\n\r\nWhich links to:\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/experimental/support/java\r\n\r\nwhich is 404 Page not found.\r\n "
  },
  {
    "labels": ["documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/guide/tensor\r\nhttps://www.tensorflow.org/guide/tensor#multi-axis_indexing\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe left side image in the figure called \"Selecting the last feature across all locations in each example in the batch\" has batches 1 (blue) and 2 (green) swapped. The right side image and the surrounding code example show the correct order.\r\n\r\nThe image that needs an edit is: https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/index1.png\r\n\r\n### Submit a pull request?\r\n\r\nNo. I do not have a way to edit the image."
  },
  {
    "labels": [null, "documentation"],
    "text": "https://www.tensorflow.org/api_docs/python/tf/image/rgb_to_yuv\r\n\r\nThe documentation says this function is only well defined if the values are between 0 and 1, but the example uses an input with values greater than 1."
  },
  {
    "labels": [null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/lite/tutorials/model_maker_image_classification\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe tutorial for Tensorflow Model Maker says that on export, there will be a model.tflite file and then a labels.txt file. However, when I export the model using the instructions, it only outputs a single model.tflite. The console output says that it is stored in a temp directory (which appears to be subsequently deleted), and that the labels are merged into the model.tflite file. Would I still be able to use this on mobile or is there any way I can extract labels.txt?\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint\r\n\r\n## Description of issue (what needs changing):\r\n\r\n1. `mode`: \"{auto, min, max}\" should be `{auto, min, max}`, I guess (minor)\r\n2.  `save_best_only`: I believe the description is incomplete. With `save_best_only=True`, not only will \"the latest best model [...] not be overwritten\": but also the current model is not written at all, even if it has another filename than the \"latest best model\". This is kind of implied by the name of the parameter, but the description should include that, too."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "This is mainly a documentation bug (official tensorflow tutorial), but it is a \"dangerous trap\" and might also happen in general to users, so see below my last sentence this could also be fixed in Tensorflow that it detects this automatically.\r\n\r\nIn this [tutorial](https://www.tensorflow.org/tutorials/images/transfer_learning) raw prediction values (form_logit=True) are used. So we have negative values and positive values, while \r\n\r\n> \r\n\"prediction will be treated as a logit, or a raw prediction value. **Positive numbers predict class 1, negative numbers predict class 0.**\"\r\n\r\nHowever, the model.compile statement is as follows:\r\n\r\n```\r\nbase_learning_rate = 0.0001\r\nmodel.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),\r\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\r\n              metrics=['accuracy'])\r\n\r\n```\r\n\r\nThis is wrong, as per default, threshold value to classify is 0.5:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/metrics/binary_accuracy\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/metrics/BinaryAccuracy\r\n```\r\ntf.keras.metrics.binary_accuracy(\r\n    y_true, y_pred, threshold=0.5\r\n)\r\n```\r\n```\r\ntf.keras.metrics.BinaryAccuracy(\r\n    name='binary_accuracy', dtype=None, threshold=0.5\r\n)\r\n```\r\n\r\n> threshold | (Optional) Float representing the threshold for deciding whether prediction values are 1 or 0.\r\n> -- | --\r\n\r\n\r\n\r\n\r\nThis leads to the wrong classifications. model.evaluate will also give false accuracy measure. Reason is that predicted values in range [0,0.49999] are wrongly classified as 0 (I am not sure what happens to a value of exactly 0.5), whereas they actually should be classified as 1!\r\n\r\nSo it needs to be corrected to:\r\n\r\n> model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),\r\n>               loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\r\n>               metrics=tf.keras.metrics.BinaryAccuracy(threshold=0.0))\r\n\r\nWould be even better if this is corrected inside Tensorflow that it automatically detects that from_logits=True was set and then assumes that default threshold is not 0.5 anymore, but 0.0 (and maybe additional WARNING output)."
  },
  {
    "labels": [null, "documentation"],
    "text": "I think the doc-string [here](https://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/python/ops/math_ops.py#L2758):\r\n```python\r\n  `output[i, j, k, ..., l] = trace(x[i, j, i, ..., l, :, :])`\r\n```\r\n\r\nshould be:\r\n\r\n```python\r\n  `output[i, j, k, ..., l] = trace(x[i, j, k, ..., l, :, :])`\r\n```\r\n\r\n\r\n"
  },
  {
    "labels": [null, null, null, "documentation", null],
    "text": "A tracking bug for migrating the [TF1 Speech Recognition example](https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md) to TF 2"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "The documentation for tf.image.rgb_to_yuv says \"Outputs a tensor of the same shape as the images tensor, containing the YUV value of the pixels. The output is only well defined if the value in images are in [0,1].\" Does that mean the RGB values should be [0,1]?\r\n\r\nIf so, the usage example added confusion:\r\n```\r\nx = [[[1.0, 2.0, 3.0],\r\n      [4.0, 5.0, 6.0]],\r\n    [[7.0, 8.0, 9.0],\r\n      [10.0, 11.0, 12.0]]]\r\ntf.image.rgb_to_yuv(x)\r\n```\r\n\r\nClearly, x does not lie in [0,1]\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n\r\nhttps://www.tensorflow.org/lite/performance/gpu_advanced\r\n\r\n\r\n## Description of issue (what needs changing):\r\n\r\n    bazel build -c opt --config android_arm64 tensorflow/lite/delegates/gpu:gl_delegate                  # for static library\r\n    bazel build -c opt --config android_arm64 tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_gl.so  # for dynamic library\r\n\r\nshould be changed to,\r\n\r\n    bazel build -c opt --config android_arm64 tensorflow/lite/delegates/gpu:delegate                  # for static library\r\n    bazel build -c opt --config android_arm64 tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so  # for dynamic library\r\n\r\nbecause gl_delegate is not GPU delegate runtime library, it is for OpenGL delegate, right?\r\n\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/Permute\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nPermute layer is quite picky about its dims argument despite docs clearly saying \r\n\r\n`dims: Tuple of integers. Permutation pattern, does not include the samples dimension. Indexing starts at 1. For instance, (2, 1) permutes the first and second dimensions of the input. `\r\n\r\n It does not actually follow from this documentation that the dims input MUST have all the dimensions clearly listed without misses -  as per check actually present in the code:\r\n``` python\r\n   if sorted(dims) != list(range(1, len(dims) + 1)):\r\n      raise ValueError(\r\n          'Invalid permutation `dims` for Permute Layer: %s. '\r\n          'The set of indices in `dims` must be consecutive and start from 1.' %\r\n          (dims,))\r\n```\r\nThe next hurdle is that the error message thrown by runtime is kind of inconsistent:\r\n\r\n``` python\r\nkeras.layers.Permute((3, 2), input_shape=[30, 6, 8], name=f\"Permute_layer\")\r\n>>> Invalid permutation `dims` for Permute Layer: (3, 2). The set of indices in `dims` must be consecutive and start from 1.\r\n```\r\nIt does not say in the doc that the dims must start with 1, it just says indexing starts with 1! Ok now the user knows it must start with 1, but how does one actually get dimensions 2 and 3 swapped? At that point it's just a mess from there on.\r\n\r\n### Suggest following changes:\r\nto the docs: please make example use 3D tensor, rather than 2D. Then it would be clear that all dims must be listed, even if they are not to be permuted, e.g.\r\n``` python\r\ntmp = keras.layers.Permute((1, 3, 2), name=f\"Permute_input\")(tmp)\r\n```\r\n\r\nAnother note that docs do not make is that the len(ndim) must match the  input_shape dimensions, which is however checked by the __init__, again possibly conflicting with the doc that says that input_shape can be whatever (clearly not whatever, it is coupled with ndim argument.\r\n\r\n\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/RMSprop"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "https://www.tensorflow.org/resources/learn-ml\r\n-> The four areas of machine learning education\r\n-> Build your own projects\r\n-> [colab]\r\n-> https://colab.research.google.com/github/tensorflow/docs/blob/r2.0rc/site/en/r2/tutorials/keras/basic_classification.ipynb\r\n\r\nGives me \"Notebook not found\"\r\nFetch for https://api.github.com/repos/tensorflow/docs/contents/site/en/r2/tutorials/keras?per_page=100&ref=r2.0rc failed: {\r\n  \"message\": \"No commit found for the ref r2.0rc\",\r\n  \"documentation_url\": \"https://developer.github.com/v3/repos/contents/\"\r\n}\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "TensorFlow documentation issue. \r\n\r\n## URL(s) with the issue:\r\nThe link/page not found(404); \"images -> object detection API\" under https://www.tensorflow.org/tutorials/\r\nnamely: https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb\r\n\r\n## Description of issue (what needs changing):\r\nMaterial was moved to https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/object_detection_tutorial.ipynb"
  },
  {
    "labels": ["documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/community/contribute/code_style\r\n\r\n## Description of issue (what needs changing):\r\n\r\nDocs say to install `clang-tidy` but the example given says to run `clang-format`. Is this intended? I would have expected to run `clang-tidy`."
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/api_docs/python/tf/where#args_1\r\n\r\n## Description of issue (what needs changing):\r\nFor Args \"x\".\r\nOriginal:\r\nIf provided, a Tensor which is of the same type as y, and has a shape broadcastable with condition and y.\r\nShould be:\r\nIf provided, a Tensor which is of the same type as **x**, and has a shape broadcastable with condition and y.\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "If we search `tf.argmax` in [tensorflow r1.15 documentation](https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/math/argmax), no result get for tf 1.x\r\n\r\nHowever, if search \"tf.math.argmax\", you will get it.\r\n\r\nBut they're both annations:\r\n```Python\r\n# pylint: disable=redefined-builtin\r\n@tf_export(v1=[\"math.argmax\", \"argmax\"])         # !!!! This line\r\n@deprecation.deprecated_args(None, \"Use the `axis` argument instead\",\r\n                             \"dimension\")\r\n@_set_doc(\r\n    gen_math_ops.arg_max.__doc__.replace(\"dimensions\", \"axes\").replace(\r\n        \"dimension\", \"axis\"))\r\ndef argmax(input,\r\n           axis=None,\r\n           name=None,\r\n           dimension=None,\r\n           output_type=dtypes.int64):\r\n  axis = deprecation.deprecated_argument_lookup(\r\n      \"axis\", axis, \"dimension\", dimension)\r\n  return argmax_v2(input, axis, output_type, name)\r\n```\r\n\r\nWhy only show the first aliased annotation in documentation? "
  },
  {
    "labels": ["documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/install/pip#windows_1\r\n\r\n## Description of issue (what needs changing): The documentation gives a command to \"verify the install\"... but NO clear indication of what should be the result. I get a list of 9 warnings (all CUDA-related) interspersed with 8 information messages. Finally there is a \"tf.tensor(72.93745, shape=(), dtype=float32)\" at the end. Is this correct? How would I know?\r\n\r\n### Clear description\r\n\r\nSee above\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct? n/a\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly? n/a\r\n\r\n### Returns defined\r\n\r\nAre return values defined? n/a\r\n\r\n### Raises listed and defined\r\n\r\nn/a\r\n\r\n### Usage example\r\n\r\nIs there a usage example? Half of one - it lacks any output to check against, or instructions on how to interpret the result\r\n\r\n### Request visuals, if applicable\r\n\r\nn/a\r\n\r\n### Submit a pull request?\r\n\r\nNo - I am far too new to github/tensorflow to ask sensible questions, let alone give sensible answers\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nThis link is broken https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb\r\n\r\n![image](https://user-images.githubusercontent.com/6630197/85917788-7c979680-b85d-11ea-8d93-0fae5b8d9bf2.png)\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\nYes, this one [https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/object_detection_tutorial.ipynb](https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/object_detection_tutorial.ipynb)\r\n\r\n\r\n### Submit a pull request?\r\n\r\nNo.\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/models/model_from_config\r\n\r\n## Description of issue (what needs changing):\r\n\r\ntf.keras.models.model_from_config function can create only layers, not the complete model as it is described in documentation. Correct usage is mentioned at https://www.tensorflow.org/guide/keras/save_and_serialize, but not described in the main documenation for tf.keras.Model class.\r\n\r\n> Calling config = model.get_config() will return a Python dict containing the configuration of the model. The same model can then be reconstructed via Sequential.from_config(config) (for a Sequential model) or Model.from_config(config) (for a Functional API model).\r\n\r\n### Clear description\r\nThe behavior of tf.keras.models.model_from_config does not correspond to the documentation.\r\nMoreover, it is even more confusing when compared with similar methods, like\r\n\r\n`tf.keras.models.model_from_json(model.to_json())`\r\n\r\n> <tensorflow.python.keras.engine.training.Model at 0x7fa2e443aa20>\r\n\r\n`tf.keras.models.model_from_yaml(model.to_yaml())`\r\n\r\n> <tensorflow.python.keras.engine.training.Model at 0x7fa2e443ca40>\r\n\r\nwhile model_from_config \r\n\r\n`tf.keras.models.model_from_config(model.get_config())`\r\n\r\n> > ---------------------------------------------------------------------------\r\n> KeyError                                  Traceback (most recent call last)\r\n> <ipython-input-99-f3b4bb685ac8> in <module>\r\n> ----> 1 tf.keras.models.model_from_config(model.get_config())\r\n> \r\n> ~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/saving/model_config.py in model_from_config(config, custom_objects)\r\n>      53                     '`Sequential.from_config(config)`?')\r\n>      54   from tensorflow.python.keras.layers import deserialize  # pylint: disable=g-import-not-at-top\r\n> ---> 55   return deserialize(config, custom_objects=custom_objects)\r\n>      56 \r\n>      57 \r\n> \r\n> ~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/serialization.py in deserialize(config, custom_objects)\r\n>      99   globs['SequenceFeatures'] = sfc.SequenceFeatures\r\n>     100 \r\n> --> 101   layer_class_name = config['class_name']\r\n>     102   if layer_class_name in _DESERIALIZATION_TABLE:\r\n>     103     config['class_name'] = _DESERIALIZATION_TABLE[layer_class_name]\r\n> \r\n> KeyError: 'class_name'\r\n> \r\n\r\n### Correct usage\r\n\r\n`tf.keras.Model().from_config(model.get_config())`\r\n\r\n> <tensorflow.python.keras.engine.training.Model at 0x7fa2e4480080>"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/signal/fft\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/api_docs/python/tf/signal/fft\r\n\r\n## Description of issue (what needs changing):\r\nThe description is simply \"Fast Fourier transform.\" which isn't fully-specified. What is the exact function computed? Is there a normalization term of 1/sqrt(N) or 1/N? Or is the normalization constant entirely in the inverse FFT (which has equally underspecified documentation)?\r\n\r\n### Clear description\r\nA mathematical formula that specifies what `tf.signal.fft` implements would be nice. Likewise with the other FFT methods, the inverse FFT methods, and STFT methods."
  },
  {
    "labels": [null, null, null, null, null, "documentation", null],
    "text": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\ncolab tensorflow 2\r\n\r\n\r\n`v2.2.0-0-g2b96f3662b 2.2.0`\r\ntested on both CPU and GPU (GPU is much worse!)\r\n\r\n**Describe the current behavior**\r\n\r\nwhen timing a simple tf.function that uses a loop, `tf.range` is much slower than using `range`.\r\nBUT `tf.range` is recommended in the docs, moreover is says that looping over non-tensor will be rolled during tracing (which does not happen. normal `range` is being traced as a loop)\r\n\r\n```\r\n@tf.function(input_signature=[tf.TensorSpec(shape=[None], dtype=tf.float32)])\r\ndef test(x):\r\n  for i in tf.range(100):\r\n    x = x * tf.constant(1.1)\r\n  return x\r\n```\r\n\r\n```\r\n%%timeit\r\ntest(tf.range(1000, dtype='float32'))\r\n```\r\nprints `100 loops, best of 3: 2.12 ms per loop`\r\nprints `10 loops, best of 3: 70.2 ms per loop` on GPU!\r\nwhile using `range` or `np.arange` is about 300 micro seconds in both CPU and GPU\r\n\r\n**Describe the expected behavior**\r\n\r\n1 there is a documentation issue where it currently always recommends `tf.range`.\r\n2 the documentation should specify when python loops are not rolled\r\n3 tf.range performance should be the same as range when used in a traced loop\r\n(also note the `np.arange` is faster than `tf.range` and comparable to `range`)"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\n\r\n[https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv1DTranspose](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv1DTranspose)\r\n\r\n## Description of issue (what needs changing):\r\nThe documentation claims that padding options {\"valid\" and \"same\"} are supported, but when following the code path to deconv_output_length at line 140 [here](https://github.com/tensorflow/tensorflow/blob/0c227aed65e62f741a88c9915923d262710fc8c9/tensorflow/python/keras/utils/conv_utils.py#L140) there is the option for {\"full\"} as well.\r\n\r\nAdditionally, the equation provided for calculating output shape merely says \"padding\" for a variable which is represented as a string in the API. This makes for a guessing game of how to achieve the desired output shape.\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n[https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/convolutional.py#L16](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/convolutional.py#L16l)\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/signal/rfft\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/signal/rfft2d\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/signal/rfft3d\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nIn the `Args` section, there are inputs `input` and `Tcomplex`. `Treal` no longer exist, and `input` should be `input_tensor`.\r\n\r\nRunning code\r\n\r\n~~~python\r\ntf.signal.rfft(1, Tcomplex=tf.complex64)\r\n~~~\r\n\r\ngot exception:\r\n\r\n~~~python\r\nTypeError: _rfft() got an unexpected keyword argument 'Tcomplex'\r\n~~~\r\n\r\n### Parameters defined\r\n\r\nYes\r\n\r\n### Returns defined\r\n\r\nYes\r\n\r\n### Raises listed and defined\r\n\r\nNo\r\n\r\n## System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS Mojave 10.14\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 2.2.0-rc3\r\n- **Python version**: 3.8.2\r\n\r\n\r\n## Related Issue:\r\n#39520"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/signal/irfft\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/signal/irfft2d\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/signal/irfft3d\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nIn the `Args` section, there are inputs `input` and `Treal`. `Treal` no longer exist, and `input` should be `input_tensor`.\r\n\r\nRunning code:\r\n\r\n~~~python\r\ntf.signal.irfft(1, Treal=tf.float32) \r\n~~~\r\n\r\ngot exception:\r\n\r\n~~~python\r\nTypeError: _irfft() got an unexpected keyword argument 'Treal'\r\n~~~\r\n\r\nAnd if run code:\r\n\r\n~~~python\r\ntf.signal.irfft(input=1)\r\n~~~\r\n\r\ngot exception:\r\n\r\n~~~python\r\nTypeError: _irfft() got an unexpected keyword argument 'input'\r\n~~~\r\n\r\n### Parameters defined\r\n\r\nYes\r\n\r\n### Returns defined\r\n\r\nYes\r\n\r\n### Raises listed and defined\r\n\r\nNo\r\n\r\n## System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS Mojave 10.14\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 2.2.0-rc3\r\n- **Python version**: 3.8.2\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/compat/v1/losses/sigmoid_cross_entropy\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nUnclear rank dependency of input `weights`. According to the document, `weights` could have the same rank as `labels`, and must be broadcastable to `labels`, but it is unclear what `labels` is. \r\n\r\n### Parameters defined\r\n\r\nYes\r\n\r\n### Returns defined\r\n\r\nYes\r\n\r\n### Raises listed and defined\r\n\r\nYes\r\n\r\n\r\n## System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS Mojave 10.14\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 2.2.0-rc3\r\n- **Python version**: 3.8.2"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/nn/swish\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nIn the \"Args\" section, there is an input ` name`, but it is not in the signature, and the function doesn't accept the argument.\r\n\r\nRunning code:\r\n\r\n~~~python\r\ntf.nn.swish(1, name=None)\r\n~~~\r\n\r\ngot exception:\r\n\r\n~~~python\r\nTypeError: swish() got an unexpected keyword argument 'name'\r\n~~~\r\n\r\n### Parameters defined\r\n\r\nYes\r\n\r\n### Returns defined\r\n\r\nYes\r\n\r\n### Raises listed and defined\r\n\r\nNo\r\n\r\n## System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS Mojave 10.14\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 2.2.0-rc3\r\n- **Python version**: 3.8.2\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "Link to 'Tensorflow Roadmap' in README is broken: https://www.tensorflow.org/community/roadmap\r\n\r\nThis template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "# Documentation for state in AbstractRNNCell could be more clear.\r\n\r\nIn the documentation for the `AbstractRNNCell` it does not make it clear that the state is a tuple. https://www.tensorflow.org/api_docs/python/tf/keras/layers/AbstractRNNCell\r\n\r\nThis was a gotcha for me when I defined a custom RNN cell that had a single state. It kept adding an axis to that state whenever I performed an operation on it.\r\n\r\nFor example, the code within the call method the class implementing `AbstractRNNCell`\r\n```logging.info(f'states: {states}')\r\nlogging.info(f'state_update: {state_update}')\r\nnew_states = tf.math.add(states, state_update)\r\nlogging.info(f'new_states: {new_states}')\r\n```\r\n\r\nleads to the confusing output\r\n\r\n```06-12 12:28 root         INFO     states: (<tf.Tensor 'Placeholder_3:0' shape=(32, 4) dtype=float32>,)\r\n06-12 12:28 root         INFO     state_update: Tensor(\"add_1:0\", shape=(32, 4), dtype=float32)\r\n06-12 12:28 root         INFO     new_states: Tensor(\"Add_2:0\", shape=(1, 32, 4), dtype=float32)\r\n```\r\n\r\nUpon implementing the state as a tuple of length one, the issue was solved. I think this could be made more clear in the documentation.\r\n\r\nMany thanks."
  },
  {
    "labels": [null, "documentation"],
    "text": "I'm trying to implement the code in this notebook https://github.com/tensorflow/docs/blob/master/site/en/guide/tpu.ipynb\r\n\r\nThe lines for updating the training loss and accuracy are incorrect:\r\n```python\r\ntraining_loss.update_state(loss * strategy.num_replicas_in_sync)\r\ntraining_accuracy.update_state(labels, logits)\r\n```\r\nI don't understand the intent behind updating the loss with the product of the number of replicas and the batch loss but it gives the wrong result. Changing the line to\r\n```python\r\ntraining_loss.update_state(labels, logits)\r\n```\r\nappears to solve the bug.\r\n\r\nI also changed the definition of `training_loss` from a `metrics.Mean` to a `metrics.SparseCategoricalCrossentropy`. "
  },
  {
    "labels": [null, null, "documentation"],
    "text": "OS: Ubuntu 18.04\r\nGraphics card: Nvidia 1050Ti\r\n\r\n**Problem**\r\nFollowing the instructions under https://www.tensorflow.org/install/gpu#install_cuda_with_apt gives the following error: \r\n\r\n```ssh\r\n...\r\n\r\nUnpacking libcudnn7-dev (7.6.4.38-1+cuda10.1) ...\r\nErrors were encountered while processing:\r\n /tmp/apt-dpkg-install-fjAi3S/55-libnvidia-compute-450_450.36.06-0ubuntu1_amd64.deb\r\nE: Sub-process /usr/bin/dpkg returned an error code (1)\r\n```\r\nafter executing this step\r\n```ssh\r\nsudo apt-get install --no-install-recommends \\\r\n>     cuda-10-1 \\\r\n>     libcudnn7=7.6.4.38-1+cuda10.1  \\\r\n>     libcudnn7-dev=7.6.4.38-1+cuda10.1\r\n```\r\n\r\n**Additional Info**\r\nThe complete message after running the above command is\r\n\r\n```ssh\r\nReading package lists... Done\r\nBuilding dependency tree       \r\nReading state information... Done\r\nThe following packages were automatically installed and are no longer required:\r\n  libnvidia-common-440 libnvidia-extra-440\r\nUse 'sudo apt autoremove' to remove them.\r\nThe following additional packages will be installed:\r\n  cuda-command-line-tools-10-1 cuda-compiler-10-1 cuda-cudart-10-1\r\n  cuda-cudart-dev-10-1 cuda-cufft-10-1 cuda-cufft-dev-10-1 cuda-cuobjdump-10-1\r\n  cuda-cupti-10-1 cuda-curand-10-1 cuda-curand-dev-10-1 cuda-cusolver-10-1\r\n  cuda-cusolver-dev-10-1 cuda-cusparse-10-1 cuda-cusparse-dev-10-1\r\n  cuda-demo-suite-10-1 cuda-documentation-10-1 cuda-driver-dev-10-1\r\n  cuda-drivers cuda-drivers-450 cuda-gdb-10-1 cuda-gpu-library-advisor-10-1\r\n  cuda-libraries-10-1 cuda-libraries-dev-10-1 cuda-license-10-1\r\n  cuda-license-10-2 cuda-memcheck-10-1 cuda-misc-headers-10-1 cuda-npp-10-1\r\n  cuda-npp-dev-10-1 cuda-nsight-10-1 cuda-nsight-compute-10-1\r\n  cuda-nsight-systems-10-1 cuda-nvcc-10-1 cuda-nvdisasm-10-1 cuda-nvgraph-10-1\r\n  cuda-nvgraph-dev-10-1 cuda-nvjpeg-10-1 cuda-nvjpeg-dev-10-1\r\n  cuda-nvml-dev-10-1 cuda-nvprof-10-1 cuda-nvprune-10-1 cuda-nvrtc-10-1\r\n  cuda-nvrtc-dev-10-1 cuda-nvtx-10-1 cuda-nvvp-10-1 cuda-runtime-10-1\r\n  cuda-samples-10-1 cuda-sanitizer-api-10-1 cuda-toolkit-10-1 cuda-tools-10-1\r\n  cuda-visual-tools-10-1 default-jre default-jre-headless libcublas-dev\r\n  libcublas10 libnvidia-cfg1-450 libnvidia-common-450 libnvidia-compute-450\r\n  libnvidia-decode-450 libnvidia-encode-450 libnvidia-fbc1-450\r\n  libnvidia-gl-450 libnvidia-ifr1-450 nsight-compute-2019.5.0\r\n  nsight-systems-2019.5.2 nvidia-compute-utils-450 nvidia-dkms-450\r\n  nvidia-driver-450 nvidia-kernel-common-450 nvidia-kernel-source-450\r\n  nvidia-modprobe nvidia-settings nvidia-utils-450 openjdk-11-jre\r\n  openjdk-11-jre-headless xserver-xorg-video-nvidia-450\r\nSuggested packages:\r\n  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\r\n  | fonts-wqy-zenhei\r\nThe following packages will be REMOVED:\r\n  libnvidia-cfg1-440 libnvidia-compute-440 libnvidia-decode-440\r\n  libnvidia-encode-440 libnvidia-fbc1-440 libnvidia-fbc1-440:i386\r\n  libnvidia-gl-440 libnvidia-ifr1-440 nvidia-compute-utils-440 nvidia-dkms-440\r\n  nvidia-driver-430 nvidia-driver-440 nvidia-kernel-common-440\r\n  nvidia-kernel-source-440 nvidia-utils-440 xserver-xorg-video-nvidia-440\r\nThe following NEW packages will be installed:\r\n  cuda-10-1 cuda-command-line-tools-10-1 cuda-compiler-10-1 cuda-cudart-10-1\r\n  cuda-cudart-dev-10-1 cuda-cufft-10-1 cuda-cufft-dev-10-1 cuda-cuobjdump-10-1\r\n  cuda-cupti-10-1 cuda-curand-10-1 cuda-curand-dev-10-1 cuda-cusolver-10-1\r\n  cuda-cusolver-dev-10-1 cuda-cusparse-10-1 cuda-cusparse-dev-10-1\r\n  cuda-demo-suite-10-1 cuda-documentation-10-1 cuda-driver-dev-10-1\r\n  cuda-drivers cuda-drivers-450 cuda-gdb-10-1 cuda-gpu-library-advisor-10-1\r\n  cuda-libraries-10-1 cuda-libraries-dev-10-1 cuda-license-10-1\r\n  cuda-license-10-2 cuda-memcheck-10-1 cuda-misc-headers-10-1 cuda-npp-10-1\r\n  cuda-npp-dev-10-1 cuda-nsight-10-1 cuda-nsight-compute-10-1\r\n  cuda-nsight-systems-10-1 cuda-nvcc-10-1 cuda-nvdisasm-10-1 cuda-nvgraph-10-1\r\n  cuda-nvgraph-dev-10-1 cuda-nvjpeg-10-1 cuda-nvjpeg-dev-10-1\r\n  cuda-nvml-dev-10-1 cuda-nvprof-10-1 cuda-nvprune-10-1 cuda-nvrtc-10-1\r\n  cuda-nvrtc-dev-10-1 cuda-nvtx-10-1 cuda-nvvp-10-1 cuda-runtime-10-1\r\n  cuda-samples-10-1 cuda-sanitizer-api-10-1 cuda-toolkit-10-1 cuda-tools-10-1\r\n  cuda-visual-tools-10-1 default-jre default-jre-headless libcublas-dev\r\n  libcublas10 libcudnn7 libcudnn7-dev libnvidia-cfg1-450 libnvidia-common-450\r\n  libnvidia-compute-450 libnvidia-decode-450 libnvidia-encode-450\r\n  libnvidia-fbc1-450 libnvidia-gl-450 libnvidia-ifr1-450\r\n  nsight-compute-2019.5.0 nsight-systems-2019.5.2 nvidia-compute-utils-450\r\n  nvidia-dkms-450 nvidia-driver-450 nvidia-kernel-common-450\r\n  nvidia-kernel-source-450 nvidia-modprobe nvidia-settings nvidia-utils-450\r\n  openjdk-11-jre openjdk-11-jre-headless xserver-xorg-video-nvidia-450\r\n0 upgraded, 79 newly installed, 16 to remove and 239 not upgraded.\r\nNeed to get 0 B/2,205 MB of archives.\r\nAfter this operation, 4,855 MB of additional disk space will be used.\r\nDo you want to continue? [Y/n] \r\nExtracting templates from packages: 100%\r\n(Reading database ... 294935 files and directories currently installed.)\r\nRemoving nvidia-driver-430 (440.59-0ubuntu0.18.04.1) ...\r\nRemoving nvidia-driver-440 (440.82-0ubuntu0~0.18.04.2) ...\r\nRemoving xserver-xorg-video-nvidia-440 (440.82-0ubuntu0~0.18.04.2) ...\r\nRemoving libnvidia-cfg1-440:amd64 (440.82-0ubuntu0~0.18.04.2) ...\r\nRemoving libnvidia-encode-440:amd64 (440.82-0ubuntu0~0.18.04.2) ...\r\nRemoving libnvidia-decode-440:amd64 (440.82-0ubuntu0~0.18.04.2) ...\r\nRemoving nvidia-utils-440 (440.82-0ubuntu0~0.18.04.2) ...\r\nRemoving libnvidia-fbc1-440:i386 (440.82-0ubuntu0~0.18.04.2) ...\r\nRemoving libnvidia-fbc1-440:amd64 (440.82-0ubuntu0~0.18.04.2) ...\r\nRemoving libnvidia-ifr1-440:amd64 (440.82-0ubuntu0~0.18.04.2) ...\r\nRemoving libnvidia-gl-440:amd64 (440.82-0ubuntu0~0.18.04.2) ...\r\nRemoving nvidia-compute-utils-440 (440.82-0ubuntu0~0.18.04.2) ...\r\nRemoving nvidia-dkms-440 (440.82-0ubuntu0~0.18.04.2) ...\r\nRemoving all DKMS Modules\r\nDone.\r\nINFO:Disable nvidia\r\nDEBUG:Parsing /usr/share/ubuntu-drivers-common/quirks/dell_latitude\r\nDEBUG:Parsing /usr/share/ubuntu-drivers-common/quirks/put_your_quirks_here\r\nDEBUG:Parsing /usr/share/ubuntu-drivers-common/quirks/lenovo_thinkpad\r\nupdate-initramfs: deferring update (trigger activated)\r\nRemoving nvidia-kernel-common-440 (440.82-0ubuntu0~0.18.04.2) ...\r\nupdate-initramfs: deferring update (trigger activated)\r\nRemoving nvidia-kernel-source-440 (440.82-0ubuntu0~0.18.04.2) ...\r\nRemoving libnvidia-compute-440:amd64 (440.82-0ubuntu0~0.18.04.2) ...\r\nSelecting previously unselected package cuda-license-10-1.\r\n(Reading database ... 294368 files and directories currently installed.)\r\nPreparing to unpack .../00-cuda-license-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-license-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-misc-headers-10-1.\r\nPreparing to unpack .../01-cuda-misc-headers-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-misc-headers-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-nvcc-10-1.\r\nPreparing to unpack .../02-cuda-nvcc-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-nvcc-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-cuobjdump-10-1.\r\nPreparing to unpack .../03-cuda-cuobjdump-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-cuobjdump-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-nvprune-10-1.\r\nPreparing to unpack .../04-cuda-nvprune-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-nvprune-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-compiler-10-1.\r\nPreparing to unpack .../05-cuda-compiler-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-compiler-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-nvdisasm-10-1.\r\nPreparing to unpack .../06-cuda-nvdisasm-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-nvdisasm-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-gdb-10-1.\r\nPreparing to unpack .../07-cuda-gdb-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-gdb-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-nvprof-10-1.\r\nPreparing to unpack .../08-cuda-nvprof-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-nvprof-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-sanitizer-api-10-1.\r\nPreparing to unpack .../09-cuda-sanitizer-api-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-sanitizer-api-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-memcheck-10-1.\r\nPreparing to unpack .../10-cuda-memcheck-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-memcheck-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-cudart-10-1.\r\nPreparing to unpack .../11-cuda-cudart-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-cudart-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-driver-dev-10-1.\r\nPreparing to unpack .../12-cuda-driver-dev-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-driver-dev-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-cudart-dev-10-1.\r\nPreparing to unpack .../13-cuda-cudart-dev-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-cudart-dev-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-cupti-10-1.\r\nPreparing to unpack .../14-cuda-cupti-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-cupti-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-gpu-library-advisor-10-1.\r\nPreparing to unpack .../15-cuda-gpu-library-advisor-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-gpu-library-advisor-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-nvtx-10-1.\r\nPreparing to unpack .../16-cuda-nvtx-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-nvtx-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-command-line-tools-10-1.\r\nPreparing to unpack .../17-cuda-command-line-tools-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-command-line-tools-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package openjdk-11-jre-headless:amd64.\r\nPreparing to unpack .../18-openjdk-11-jre-headless_11.0.7+10-2ubuntu2~18.04_amd64.deb ...\r\nUnpacking openjdk-11-jre-headless:amd64 (11.0.7+10-2ubuntu2~18.04) ...\r\nSelecting previously unselected package default-jre-headless.\r\nPreparing to unpack .../19-default-jre-headless_2%3a1.11-68ubuntu1~18.04.1_amd64.deb ...\r\nUnpacking default-jre-headless (2:1.11-68ubuntu1~18.04.1) ...\r\nSelecting previously unselected package openjdk-11-jre:amd64.\r\nPreparing to unpack .../20-openjdk-11-jre_11.0.7+10-2ubuntu2~18.04_amd64.deb ...\r\nUnpacking openjdk-11-jre:amd64 (11.0.7+10-2ubuntu2~18.04) ...\r\nSelecting previously unselected package default-jre.\r\nPreparing to unpack .../21-default-jre_2%3a1.11-68ubuntu1~18.04.1_amd64.deb ...\r\nUnpacking default-jre (2:1.11-68ubuntu1~18.04.1) ...\r\nSelecting previously unselected package cuda-nsight-10-1.\r\nPreparing to unpack .../22-cuda-nsight-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-nsight-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-nvvp-10-1.\r\nPreparing to unpack .../23-cuda-nvvp-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-nvvp-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-nvrtc-10-1.\r\nPreparing to unpack .../24-cuda-nvrtc-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-nvrtc-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-nvrtc-dev-10-1.\r\nPreparing to unpack .../25-cuda-nvrtc-dev-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-nvrtc-dev-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-cusolver-10-1.\r\nPreparing to unpack .../26-cuda-cusolver-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-cusolver-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-cusolver-dev-10-1.\r\nPreparing to unpack .../27-cuda-cusolver-dev-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-cusolver-dev-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-license-10-2.\r\nPreparing to unpack .../28-cuda-license-10-2_10.2.89-1_amd64.deb ...\r\nUnpacking cuda-license-10-2 (10.2.89-1) ...\r\nSelecting previously unselected package libcublas10.\r\nPreparing to unpack .../29-libcublas10_10.2.2.89-1_amd64.deb ...\r\nUnpacking libcublas10 (10.2.2.89-1) ...\r\nSelecting previously unselected package libcublas-dev.\r\nPreparing to unpack .../30-libcublas-dev_10.2.2.89-1_amd64.deb ...\r\nUnpacking libcublas-dev (10.2.2.89-1) ...\r\nSelecting previously unselected package cuda-cufft-10-1.\r\nPreparing to unpack .../31-cuda-cufft-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-cufft-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-cufft-dev-10-1.\r\nPreparing to unpack .../32-cuda-cufft-dev-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-cufft-dev-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-curand-10-1.\r\nPreparing to unpack .../33-cuda-curand-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-curand-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-curand-dev-10-1.\r\nPreparing to unpack .../34-cuda-curand-dev-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-curand-dev-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-cusparse-10-1.\r\nPreparing to unpack .../35-cuda-cusparse-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-cusparse-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-cusparse-dev-10-1.\r\nPreparing to unpack .../36-cuda-cusparse-dev-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-cusparse-dev-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-npp-10-1.\r\nPreparing to unpack .../37-cuda-npp-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-npp-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-npp-dev-10-1.\r\nPreparing to unpack .../38-cuda-npp-dev-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-npp-dev-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-nvml-dev-10-1.\r\nPreparing to unpack .../39-cuda-nvml-dev-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-nvml-dev-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-nvjpeg-10-1.\r\nPreparing to unpack .../40-cuda-nvjpeg-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-nvjpeg-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-nvjpeg-dev-10-1.\r\nPreparing to unpack .../41-cuda-nvjpeg-dev-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-nvjpeg-dev-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package nsight-compute-2019.5.0.\r\nPreparing to unpack .../42-nsight-compute-2019.5.0_2019.5.0.14-1_amd64.deb ...\r\nUnpacking nsight-compute-2019.5.0 (2019.5.0.14-1) ...\r\nSelecting previously unselected package cuda-nsight-compute-10-1.\r\nPreparing to unpack .../43-cuda-nsight-compute-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-nsight-compute-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package nsight-systems-2019.5.2.\r\nPreparing to unpack .../44-nsight-systems-2019.5.2_2019.5.2.16-b54ef97_amd64.deb ...\r\nUnpacking nsight-systems-2019.5.2 (2019.5.2.16-b54ef97) ...\r\nSelecting previously unselected package cuda-nsight-systems-10-1.\r\nPreparing to unpack .../45-cuda-nsight-systems-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-nsight-systems-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-nvgraph-10-1.\r\nPreparing to unpack .../46-cuda-nvgraph-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-nvgraph-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-nvgraph-dev-10-1.\r\nPreparing to unpack .../47-cuda-nvgraph-dev-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-nvgraph-dev-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-visual-tools-10-1.\r\nPreparing to unpack .../48-cuda-visual-tools-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-visual-tools-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-tools-10-1.\r\nPreparing to unpack .../49-cuda-tools-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-tools-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-samples-10-1.\r\nPreparing to unpack .../50-cuda-samples-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-samples-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-documentation-10-1.\r\nPreparing to unpack .../51-cuda-documentation-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-documentation-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-libraries-dev-10-1.\r\nPreparing to unpack .../52-cuda-libraries-dev-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-libraries-dev-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-toolkit-10-1.\r\nPreparing to unpack .../53-cuda-toolkit-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-toolkit-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package libnvidia-common-450.\r\nPreparing to unpack .../54-libnvidia-common-450_450.36.06-0ubuntu1_all.deb ...\r\nChecking for existing driver runfile install\r\n/var/lib/dpkg/tmp.ci/preinst: 6: /var/lib/dpkg/tmp.ci/preinst: [[: not found\r\nUnpacking libnvidia-common-450 (450.36.06-0ubuntu1) ...\r\nPreparing to unpack .../55-libnvidia-compute-450_450.36.06-0ubuntu1_amd64.deb ...\r\nUnpacking libnvidia-compute-450:amd64 (450.36.06-0ubuntu1) ...\r\ndpkg: error processing archive /tmp/apt-dpkg-install-fjAi3S/55-libnvidia-compute-450_450.36.06-0ubuntu1_amd64.deb (--unpack):\r\n trying to overwrite '/usr/lib/x86_64-linux-gnu/libnvidia-allocator.so', which is also in package libnvidia-extra-440:amd64 440.82-0ubuntu0~0.18.04.2\r\nSelecting previously unselected package libnvidia-decode-450:amd64.\r\nPreparing to unpack .../56-libnvidia-decode-450_450.36.06-0ubuntu1_amd64.deb ...\r\nUnpacking libnvidia-decode-450:amd64 (450.36.06-0ubuntu1) ...\r\nSelecting previously unselected package libnvidia-encode-450:amd64.\r\nPreparing to unpack .../57-libnvidia-encode-450_450.36.06-0ubuntu1_amd64.deb ...\r\nUnpacking libnvidia-encode-450:amd64 (450.36.06-0ubuntu1) ...\r\nSelecting previously unselected package libnvidia-fbc1-450:amd64.\r\nPreparing to unpack .../58-libnvidia-fbc1-450_450.36.06-0ubuntu1_amd64.deb ...\r\nUnpacking libnvidia-fbc1-450:amd64 (450.36.06-0ubuntu1) ...\r\nSelecting previously unselected package libnvidia-gl-450:amd64.\r\nPreparing to unpack .../59-libnvidia-gl-450_450.36.06-0ubuntu1_amd64.deb ...\r\nUnpacking libnvidia-gl-450:amd64 (450.36.06-0ubuntu1) ...\r\nSelecting previously unselected package libnvidia-ifr1-450:amd64.\r\nPreparing to unpack .../60-libnvidia-ifr1-450_450.36.06-0ubuntu1_amd64.deb ...\r\nUnpacking libnvidia-ifr1-450:amd64 (450.36.06-0ubuntu1) ...\r\nSelecting previously unselected package nvidia-compute-utils-450.\r\nPreparing to unpack .../61-nvidia-compute-utils-450_450.36.06-0ubuntu1_amd64.deb ...\r\nUnpacking nvidia-compute-utils-450 (450.36.06-0ubuntu1) ...\r\nSelecting previously unselected package nvidia-kernel-source-450.\r\nPreparing to unpack .../62-nvidia-kernel-source-450_450.36.06-0ubuntu1_amd64.deb ...\r\nUnpacking nvidia-kernel-source-450 (450.36.06-0ubuntu1) ...\r\nSelecting previously unselected package nvidia-kernel-common-450.\r\nPreparing to unpack .../63-nvidia-kernel-common-450_450.36.06-0ubuntu1_amd64.deb ...\r\nUnpacking nvidia-kernel-common-450 (450.36.06-0ubuntu1) ...\r\nSelecting previously unselected package nvidia-dkms-450.\r\nPreparing to unpack .../64-nvidia-dkms-450_450.36.06-0ubuntu1_amd64.deb ...\r\nUnpacking nvidia-dkms-450 (450.36.06-0ubuntu1) ...\r\nSelecting previously unselected package nvidia-utils-450.\r\nPreparing to unpack .../65-nvidia-utils-450_450.36.06-0ubuntu1_amd64.deb ...\r\nUnpacking nvidia-utils-450 (450.36.06-0ubuntu1) ...\r\nSelecting previously unselected package libnvidia-cfg1-450:amd64.\r\nPreparing to unpack .../66-libnvidia-cfg1-450_450.36.06-0ubuntu1_amd64.deb ...\r\nUnpacking libnvidia-cfg1-450:amd64 (450.36.06-0ubuntu1) ...\r\nSelecting previously unselected package xserver-xorg-video-nvidia-450.\r\nPreparing to unpack .../67-xserver-xorg-video-nvidia-450_450.36.06-0ubuntu1_amd64.deb ...\r\nUnpacking xserver-xorg-video-nvidia-450 (450.36.06-0ubuntu1) ...\r\nSelecting previously unselected package nvidia-driver-450.\r\nPreparing to unpack .../68-nvidia-driver-450_450.36.06-0ubuntu1_amd64.deb ...\r\nUnpacking nvidia-driver-450 (450.36.06-0ubuntu1) ...\r\nSelecting previously unselected package nvidia-modprobe.\r\nPreparing to unpack .../69-nvidia-modprobe_450.36.06-0ubuntu1_amd64.deb ...\r\nUnpacking nvidia-modprobe (450.36.06-0ubuntu1) ...\r\nSelecting previously unselected package nvidia-settings.\r\nPreparing to unpack .../70-nvidia-settings_450.36.06-0ubuntu1_amd64.deb ...\r\nUnpacking nvidia-settings (450.36.06-0ubuntu1) ...\r\nSelecting previously unselected package cuda-drivers-450.\r\nPreparing to unpack .../71-cuda-drivers-450_450.36.06-1_amd64.deb ...\r\nUnpacking cuda-drivers-450 (450.36.06-1) ...\r\nSelecting previously unselected package cuda-drivers.\r\nPreparing to unpack .../72-cuda-drivers_450.36.06-1_amd64.deb ...\r\nUnpacking cuda-drivers (450.36.06-1) ...\r\nSelecting previously unselected package cuda-libraries-10-1.\r\nPreparing to unpack .../73-cuda-libraries-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-libraries-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-runtime-10-1.\r\nPreparing to unpack .../74-cuda-runtime-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-runtime-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-demo-suite-10-1.\r\nPreparing to unpack .../75-cuda-demo-suite-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-demo-suite-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-10-1.\r\nPreparing to unpack .../76-cuda-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package libcudnn7.\r\nPreparing to unpack .../77-libcudnn7_7.6.4.38-1+cuda10.1_amd64.deb ...\r\nUnpacking libcudnn7 (7.6.4.38-1+cuda10.1) ...\r\nSelecting previously unselected package libcudnn7-dev.\r\nPreparing to unpack .../78-libcudnn7-dev_7.6.4.38-1+cuda10.1_amd64.deb ...\r\nUnpacking libcudnn7-dev (7.6.4.38-1+cuda10.1) ...\r\nErrors were encountered while processing:\r\n /tmp/apt-dpkg-install-fjAi3S/55-libnvidia-compute-450_450.36.06-0ubuntu1_amd64.deb\r\nE: Sub-process /usr/bin/dpkg returned an error code (1)\r\n```"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "**System information**\r\n- Have I written custom code: NO\r\n- TensorFlow installed from: pip (tf-nightly)\r\n- TensorFlow version: 2.3.0-dev20200605\r\n\r\n**Describe the current behavior**\r\nTPU won't initialize in colab using the nightly build.\r\n\r\n**Describe the expected behavior**\r\nRun the https://www.tensorflow.org/guide/tpu notebook successfully, as one would if using TF 2.2.\r\n\r\n**Standalone code to reproduce the issue**\r\n1. Load https://www.tensorflow.org/guide/tpu in colab.\r\n2. Run `!pip install tf-nightly` in a new cell before running anything else.\r\n3. Run the TPU initialization section of the notebook.\r\n4. Observe the following error:\r\n\r\n```InvalidArgumentError: NodeDef expected inputs 'string' do not match 0 inputs specified; Op<name=_Send; signature=tensor:T -> ; attr=T:type; attr=tensor_name:string; attr=send_device:string; attr=send_device_incarnation:int; attr=recv_device:string; attr=client_terminated:bool,default=false; is_stateful=true>; NodeDef: {{node _Send}}\r\n```\r\n\r\n\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/tutorials/structured_data/time_series\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nIn the time-series forecasting tutorial, the normalization is done prior to obtaining time-series windows. \r\nConsider this:\r\n`uni_data = (uni_data-uni_train_mean)/uni_train_std`\r\nThis is done before:\r\n```\r\nx_train_uni, y_train_uni = univariate_data(uni_data, 0, TRAIN_SPLIT,\r\n                                           univariate_past_history,\r\n                                           univariate_future_target)\r\n```\r\nThis is causing the past_history samples using values of future targets as well during the normalization. This is a bias. In reality, we cannot use future values to normalize current values.\r\nThis, I think, is a bias and a bug.\r\n\r\n### Correct links\r\n\r\n\r\n\r\n### Parameters defined\r\n\r\n\r\n### Returns defined\r\n\r\n\r\n### Raises listed and defined\r\n\r\n\r\n### Usage example\r\n\r\nNormalization should be done after extraction of sequences and only using the LHS of the sequence. I still dont know if normalizing the RHS of the sequence is desired. but does not hurt as long as we denormalize\r\n\r\n### Request visuals, if applicable\r\n\r\n\r\n### Submit a pull request?\r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/compat/v1/setdiff1d\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nIn the \"Args\" section, there is an input `out_idx`, but it is not in the signature, and the function doesn't accept the argument.\r\n\r\nRunning code: \r\n\r\n~~~python\r\ntf.compat.v1.setdiff1d([1],[1],out_idx=tf.dtypes.int32, name=None)\r\n~~~\r\n\r\ngot exception:\r\n\r\n~~~python\r\nTypeError: setdiff1d() got an unexpected keyword argument 'out_idx'\r\n~~~\r\n\r\n### Parameters defined\r\n\r\nYes\r\n\r\n### Returns defined\r\n\r\nYes\r\n\r\n### Raises listed and defined\r\n\r\nNo\r\n\r\n\r\n## System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS Mojave 10.14\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 2.2.0-rc3\r\n- **Python version**: 3.8.2"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/nn/conv1d_transpose\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/nn/conv3d_transpose\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nUnclear type and dimension dependency of input `filters`. According to the document, `filters` should have the same type as `value` and the `in_channel` dimension must match that of `value`, but it is unclear what `value` is.\r\n\r\n### Parameters defined\r\n\r\nYes\r\n\r\n### Returns defined\r\n\r\nYes\r\n\r\n### Raises listed and defined\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/nn/conv1d_transpose: Yes\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/nn/conv3d_transpose:  No, the \"Raises\" list is not provided or defined\r\n\r\n\r\n## System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS Mojave 10.14\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 2.2.0-rc3\r\n- **Python version**: 3.8.2\r\n  "
  },
  {
    "labels": [null, "documentation"],
    "text": "I'm reading this tutorial page from the documentation: https://www.tensorflow.org/tutorials/text/text_generation\r\n\r\nThe GRU layer is stateful so it remembers its state between batches. But the batches are shuffled. Therefore I think the stateful parameter should be `False`. "
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/ragged/constant\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nFormat issue. In the \"Args\" section, format of description of `ragged_rank` is problematic. The default value should be `max(0, K-1-len(inner_shape))`\r\n\r\n### Parameters defined\r\n\r\nYes\r\n\r\n### Returns defined\r\n\r\nYes\r\n\r\n### Raises listed and defined\r\n\r\nYes\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/hessians\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nIn the \"Args\" section, there is an input `colocate_gradients_with_ops`, but it is not in the signature, and the function doesn't accept the argument.\r\n\r\nRunning code:\r\n\r\n~~~python\r\ntf.hessians(1,1,colocate_gradients_with_ops=None)\r\n~~~\r\n\r\ngot exception:\r\n\r\n~~~python\r\nTypeError: HessiansV2() got an unexpected keyword argument 'colocate_gradients_with_ops'\r\n~~~\r\n\r\n### Parameters defined\r\n\r\nYes\r\n\r\n### Returns defined\r\n\r\nYes\r\n\r\n### Raises listed and defined\r\n\r\nYes\r\n\r\n## System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS Mojave 10.14\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 2.2.0-rc3\r\n- **Python version**: 3.8.2\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/backend/moving_average_update\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nUnclear shape dependency of input `value`. According to the document, `value` should have the same shape as `variable`, but it is unclear what is `variable`.\r\n\r\n### Parameters defined\r\n\r\nYes\r\n\r\n### Returns defined\r\n\r\nYes\r\n\r\n### Raises listed and defined\r\n\r\nNo"
  },
  {
    "labels": [null, "documentation"],
    "text": "About the official document variable name introduced by Profiler is inconsistent！\r\n\r\nPlease see the URL：\r\n[https://tensorflow.google.cn/guide/profiler?hl=en](https://tensorflow.google.cn/guide/profiler?hl=en)\r\n\r\n![WechatIMG6](https://user-images.githubusercontent.com/61530230/83288790-8c986800-a216-11ea-94aa-0b6ddc2d4e51.png)\r\n\r\nYou can find problems with two variables：“tb_callback” and “tensorboard_callback” ！"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/math/maximum#returns\r\n\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe example of tf.math.maximum is not written correctly.\r\nIt's written in this manner,\r\nExample: \r\n``` x = tf.constant([0., 0., 0., 0.]) y = tf.constant([-2., 0., 2., 5.]) tf.math.maximum(x, y) ```\r\nInstead of this it should've written in this manner,\r\n``` \r\n    x = tf.constant([0., 0., 0., 0.])\r\n    y = tf.constant([-2., 0., 2., 5.])\r\n    tf.math.maximum(x, y)\r\n    -> tf.Tensor([0. 0. 2. 5.], shape=(4,), dtype=float32)\r\n```    \r\n\r\n\r\n\r\n\r\n\r\n### Submit a pull request?\r\nno"
  },
  {
    "labels": [null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue: https://www.tensorflow.org/lite/convert/python_api\r\n\r\n## Description of issue (what needs changing):\r\nUnder 'Converting a Keras model' it has the code `tf.gfile.GFile` and that code has moved to `tf.io.gfile.GFile`\r\n\r\n### Clear description\r\nThis change should be made so that the code runs.\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct? Yes\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly? Yes\r\n\r\n### Returns defined\r\n\r\nAre return values defined? Yes\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? No errors\r\n\r\n### Usage example\r\n\r\nIs there a usage example? No\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content? N/A\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://colab.research.google.com/github/tensorflow/examples/blob/master/community/en/flowers_tf_lite.ipynb\r\n\r\nhttps://github.com/tensorflow/examples/blob/master/lite/codelabs/flower_classification/android/finish/app/src/main/java/org/tensorflow/lite/examples/classification/tflite/Classifier.java#L292\r\n\r\n## Description of issue (what needs changing):\r\nIn the above codelabs tutorial, we see image has been rescaled to [0-1] by dividing by 255. Since pre-trained weights (imagenet) are trained by feed [-1 1] normalized image. Ideally tutorial should add that step to correctly leverage transfer learning. \r\n\r\n### Clear description\r\nSo what is happening is we create a tflite model trained with [0-1] based preprocessing. On android client we are doing [-1 1] based preprocessing before feeding to tflite model.\r\nCan someone please clarify?\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "\r\n## URL(s) with the issue: https://www.tensorflow.org/versions/r2.1/api_docs/python/tf/keras/optimizers/RMSprop\r\n\r\n## Description of issue (what needs changing): the sub-indexes in the formula are not displayed correctly.\r\n\r\n### Clear description\r\nAs an example, meansquared_{t} appears like mean_{s}quaredt and so on.\r\n"
  },
  {
    "labels": [null, null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/lite/guide/build_rpi#compile_natively_on_raspberry_pi\r\n\r\n## Description of issue (what needs changing):\r\nGuide on natively compiling says \"tested on Raspberry Pi Zero\", but following the instructions on a Raspberry Pi Zero leads to a build for armv7l, not armv6 as specified.\r\nAdding TARGET_ARCH=armv6 to the command would likely work, as has been done in the cross-compile section to separate newer models from the RPi 1 / Zero. However, since me following these cross-compiling instructions resulted in a armv7l target as well (hard-float VFP ABI linking errors on Zero), I directly followed the tips from #30181 to be on the safe side."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/Model#fit\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe description of the keras `Model.fit` function is either ambiguous, or incorrect, regarding the accepted datatypes for the parameter `validation_data`. Specifically, some data types *are* accepted, even when the documentation states that they are not. For example, the datatype `keras.utils.Sequence` *is* accepted as a possible datatype, and (as far as I can tell) behaves as one would expect. \r\n\r\nAs far as I can tell, this is primarily true when the user passes a generator/Sequence as `x`. In this case, the function `Model.fit` dispatches to the (deprecated) function `Model.fit_generator`, which *does* accept a generator or Sequence for the `validation_data` parameter.\r\n\r\nThis documentation should be corrected to unambiguously state one of the following: \r\n\r\n- *exactly* the list of datatypes that are accepted (e.g. numpy arrays, lists, pandas dataframes, etc). Note, this may require more work in order to fully test this set of datatypes. \r\n- *an approximation* of the list of datatypes that are accepted, with a cavaeat that some may be untested/only sometimes valid\r\n\r\nIf the types accepted are dependent on the type of `x`, then this should also be documented. \r\n\r\n### Submit a pull request?\r\n\r\nIf necessary, I am happy to open a PR, however I think that given this is clear user-facing code, and the primary interface for most tensorflow users it woudl be best to have this fix spearheaded by an internal developer."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Hi all,\r\nthe 'auto' mode in ReduceLROnPlateau  and ModelCheckpoint  are looking for specific string 'acc' in the name of the metrics to be monitor. this actually leads to unlickly scenarious of not working properly even while using metrics that are defined in tfa and hoping tf will be aware of the direction . this can be added in the doc to make the developers understand how to name their metrics or to set min max mode on their own. \r\nthanks\r\n\r\nhttps://github.com/tensorflow/addons/issues/1865\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "[https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet_v2/preprocess_input](url)\r\nThe documentation says in the 'Returns' paragraph that\r\n> The images are converted from RGB to BGR, then each color channel is zero-centered with respect to the ImageNet dataset, without scaling. \r\n\r\nHowever, according to [the function definition](https://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/python/keras/applications/resnet_v2.py#L125-L139) it's not true anymore  since the **mode parameter** can't be set and it is always equal to **'tf'**.\r\n\r\nTherefore, this docs part must be corrected to \r\n>will scale pixels between -1 and 1,  sample-wise\r\n\r\n\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/saved_model/README.md\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThat documentation uses deprecated code like 'tf.Session()'\r\n\r\n### Submit a pull request?\r\n\r\nNo, because I don't really know how it should be used now.\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/Model\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe docs is missing `get_weights`, `set_weights` method and `metrics` property.\r\n\r\n`get_weights` method and `metrics` property are defined in the src. But not in the generated docs.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/python/keras/engine/training.py#L190-L197\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/python/keras/engine/training.py#L361-L410\r\n\r\n`set_weights` method is mentioned in [keras docs](https://keras.io/api/models/model_saving_apis/#setweights-method).\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/agents/tutorials/0_intro_rl\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe equation after \"The optimal Q-function obeys the following Bellman optimality equation:\" is not rendering correctly. This is what I see on my screen:\r\n\r\n```\r\n$\\begin{equation} Q^(s, a) = \\mathbb{E}\\left[ r + \\gamma \\max_{a'} Q^(s', a')\\right] \\end{equation}$\r\n```\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "#38076  URL(s) with the issue:\r\nhttps://www.tensorflow.org/resources/tools#\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/resources/tools#\r\n\r\n## Description of issue (what needs changing):\r\nLink to what-if-tool is broken, as what-if moved to new repo.\r\n\r\n### Clear description\r\nCurrent broken link, when someone clicks on \"Get Started\" link at \r\nhttps://www.tensorflow.org/resources/tools\r\n\r\nBroken link ->\r\nhttps://github.com/tensorflow/tensorboard/blob/master/tensorboard/plugins/interactive_inference/What_If_Tool_Notebook_Usage.ipynb\r\n\r\nNew Correct link should be ->\r\nhttps://github.com/PAIR-code/what-if-tool/blob/master/What_If_Tool_Notebook_Usage.ipynb\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\nhttps://github.com/PAIR-code/what-if-tool/blob/master/What_If_Tool_Notebook_Usage.ipynb\r\n\r\nI wanted to submit a pull-request for this\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/guide/profiler#install_the_profiler_and_gpu_prerequisites\r\n\r\n## Description of issue (what needs changing):\r\nThe documentation says to do `ldconfig -p | grep libcupti` to check that CUPTI exists on the path, and to do `export LD_LIBRARY_PATH=/usr/local/cuda/extras/CUPTI/lib64:$LD_LIBRARY_PATH` to fix it if it is not on the path.  However, the documentation can be misleading in situations where an old install of CUDA 10.0 has been replaced with 10.1 (at least on my installation).\r\n\r\n\r\nMy output when checking the path is as below:\r\n```console\r\ntyler@lambda2:/usr/local/cuda/bin$ ldconfig -p | grep libcupti\r\n\tlibcupti.so.10.0 (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libcupti.so.10.0\r\n\tlibcupti.so (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libcupti.so\r\n```\r\n\r\nReading the documentation, this suggested to me that I did indeed have a version of libcupti on the path, and that everything should work. However, when I trained my model with the profiler on I saw the following error logs in the console.\r\n\r\n```\r\n2020-05-13 15:49:23.364143: I tensorflow/core/profiler/lib/profiler_session.cc:163] Profiler session started.\r\n2020-05-13 15:49:23.364212: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 1 GPUs\r\n2020-05-13 15:49:23.364588: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcupti.so.10.1'; dlerror: libcupti.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.1/lib64\r\n2020-05-13 15:49:23.364606: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1415] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\r\n```\r\n\r\nAfter double checking that I had CUDA 10.1 installed and not 10.2, I did the below\r\n```console\r\ntyler@lambda2:~/$ export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/extras/CUPTI/lib64\r\ntyler@lambda2:~/$ echo $LD_LIBRARY_PATH\r\n/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/extras/CUPTI/lib64\r\n```\r\n\r\nThis then allows the profiler to load CUPTI\r\n```\r\n2020-05-13 18:18:51.560268: I tensorflow/core/profiler/lib/profiler_session.cc:163] Profiler session started.\r\n2020-05-13 18:18:51.560338: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 1 GPUs\r\n2020-05-13 18:18:51.561266: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcupti.so.10.1\r\n```\r\n\r\nHowever, rerunning the command from the documentation for checking that CUPTI is on the path gives the same output as before\r\n\r\n```console\r\ntyler@lambda2:~/$ ldconfig -p | grep libcupti\r\n\tlibcupti.so.10.0 (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libcupti.so.10.0\r\n\tlibcupti.so (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libcupti.so\r\n```\r\n\r\n### Desired fixes\r\nAfter updating my path, I would expect that `ldconfig -p | grep libcupti` would update to show that `usr/local/cuda/extras/CUPTI/lib64` with version 10.1 is available. \r\n\r\nAdditionally, I believe the documentation should explicitly state that running `ldconfig -p | grep libcupti` should show `libcupti.so.10.1` or greater\r\n\r\n\r\n### Submit a pull request?\r\n\r\nNo, I'm not sure of what the best way to check for 10.1 or 10.2 would be\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/signal/rfft\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nThe table of `Args` in the documentation includes `Tcomplex`:\r\n\r\n```\r\nTcomplex | An optional tf.DType from: tf.complex64, tf.complex128. Defaults to tf.complex64.\r\n```\r\n\r\nBut the function does not accept this argument. Calling `tf.signal.rfft(..., Tcomplex=...)` results in the error:\r\n\r\n```\r\nTypeError: _rfft() got an unexpected keyword argument 'Tcomplex'\r\n```\r\n\r\nThis makes sense given the signature in the documentation:\r\n\r\n```\r\ntf.signal.rfft(\r\n    input_tensor, fft_length=None, name=None\r\n)\r\n```\r\n\r\nand https://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/python/ops/signal/fft_ops.py#L114-L140\r\n\r\n### Submit a pull request?\r\n\r\nNo. I could not find where this table was generated in the code."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv3DTranspose\r\n\r\n## Description of issue (what needs changing):\r\n\r\nOutput shape computation is shown as below on above documentation\r\n```\r\nnew_depth = ((depth - 1) * strides[0] + kernel_size[0] - 2 * padding[0] +\r\noutput_padding[0])\r\nnew_rows = ((rows - 1) * strides[1] + kernel_size[1] - 2 * padding[1] +\r\noutput_padding[1])\r\nnew_cols = ((cols - 1) * strides[2] + kernel_size[2] - 2 * padding[2] +\r\noutput_padding[2])\r\n```\r\nbut padding is either 'valid' or 'same'\r\nso, is padding computed based on traditional convolution computation (ref: https://www.tensorflow.org/api_docs/python/tf/nn/convolution) and then used here?\r\nThis is unclear from current documentation how `same`/`valid` mode is being used.\r\n\r\n\r\n### Clear description\r\n\r\nClarification about how these modes are reflected in computing actual padding and then used in specified formula.\r\n\r\n### Computation of output shape\r\n`deconv_output_length` from keras/utils/conv_utils.py is used for computing the output shape considering output_padding which should be reflected into documentation concisely\r\nref: https://github.com/tensorflow/tensorflow/blob/dd2ea875d92eeb83e81b1cb92e29e61d488e98b2/tensorflow/python/keras/utils/conv_utils.py#L168\r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/split\r\n\r\n## Description of issue (what needs changing):\r\n\r\n> If `num_or_size_splits` is an integer, then `value` is split along the dimension axis into `num_split` smaller tensors. This requires that `value.shape[axis]` is divisible by `num_split`.\r\n\r\nWhat is `num_split` here? I think this should be\r\n\r\n> If `num_or_size_splits` is an integer, then **we call it `num_split` and** `value` is split along the dimension axis into `num_split` smaller tensors. This requires that `value.shape[axis]` is divisible by `num_split`.\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/api_docs/python/tf/control_dependencies\r\n\r\n## Description of issue (what needs changing):\r\nDo we need to mention the debug use case in https://www.tensorflow.org/api_docs/python/tf/debugging/assert_equal#returns ?\r\n### Clear description\r\nWe declare in the note\r\n> Note: In TensorFlow 2 with eager and/or Autograph, you should not require this method, as code executes in the expected order. Only use tf.control_dependencies when working with v1-style code or in a graph context such as inside Dataset.map.\r\nBut there is any direct reference to the `assert_equal` use case\r\n\r\nFor example, why should someone use this method? How is it useful?\r\nTake a look at the issue [here](https://github.com/tensorflow/addons/issues/1794)"
  },
  {
    "labels": [null, "documentation"],
    "text": "[Here](https://github.com/tensorflow/tensorflow/blob/fedc6d951faa73936a1154d6507d54240614d416/tensorflow/python/eager/backprop.py#L532) a minor typo in the source code: **rturns** ==> **returns**\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\nhttps://codelabs.developers.google.com/codelabs/digit-classifier-tflite/index.html?index=..%2F..index#7\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nThere is an error in the code of step 4 of the codelabs.\r\nget a null safety error when implementing the code\r\n\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "Could you add the website link in the following url：\r\nhttps://github.com/tensorflow/tensorflow/tree/r1.13/tensorflow/contrib/quantize\r\n\r\n![image](https://user-images.githubusercontent.com/35229624/80811968-97e97b00-8bf9-11ea-9752-8b65e886e8d5.png)\r\nthe link marked in blue is 404 not found.\r\n\r\nThank you!\r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "The docstring says \" it is a negative quantity between -1 and 0, where 0 indicates orthogonality and values closer to -1 indicate greater similarity\". Although it is true that the function reverses the sign of the classic cosine similarity so that -1 will denote \"similarity\" instead of 1 in the original formula, the actual range is still -1 to 1 (not -1 to 0 as misleading by the docstring). \r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/e5bf8de410005de06a7ff5393fafdf832ef1d4ad/tensorflow/python/keras/losses.py#L1073"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/install/gpu\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe tf-nightly pip package does not support GPU. It should be: tf-nightly-gpu\r\n\r\nOn the Windows Setup section, the path:\r\n\r\nSET PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.1\\extras\\CUPTI\\libx64;%PATH%\r\n\r\nshould be:\r\n\r\nSET PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.1\\extras\\CUPTI\\lib64;%PATH% \r\n\r\nSince the CUDA toolkit generates this path with lib64 and not libx64.\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://github.com/tensorflow/docs/edit/master/site/en/tutorials/distribute/multi_worker_with_keras.ipynb\r\n\r\n## Description of issue (what needs changing):\r\nWhen rendered, the literal \\_\\_init\\_\\_ is replaced with init\r\n### Clear description\r\n\\_\\_init\\_\\_ is a \"built-in\" python function for classes.  In the ipynb source code it is correct.  However, when rendered at: https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras , it is incorrect.\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\nYes, please see the notebook in the docs.  The text is:\r\n```\r\nNote: TF_CONFIG is parsed and TensorFlow's GRPC servers are started at the time MultiWorkerMirroredStrategy.init() is called, so TF_CONFIG environment variable must be set before a tf.distribute.Strategy instance is created.\r\n```\r\nvs\r\n```\r\nNote: TF_CONFIG is parsed and TensorFlow's GRPC servers are started at the time MultiWorkerMirroredStrategy.__init__() is called, so TF_CONFIG environment variable must be set before a tf.distribute.Strategy instance is created.\r\n```\r\nNotice that .init() is shown when .\\_\\_init\\_\\_() should be shown.\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\nNo:  I didn't know how to escape the underscores, but I believe it is as in this report using a backslash before each underscore.\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL with the issue: https://www.tensorflow.org/lite/examples\r\n\r\n## Description of issue:\r\nThe digit classifier example card has the wrong description : \r\n\"Generate reply suggestions to input conversational chat messages.\"\r\n\r\n## Screenshot\r\n\r\n![image](https://user-images.githubusercontent.com/23613193/80188049-4441c500-862e-11ea-998d-b66c246de3d2.png)\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "ksizes should be sizes on:\r\nhttps://github.com/tensorflow/tensorflow/blob/e5bf8de410005de06a7ff5393fafdf832ef1d4ad/tensorflow/python/ops/array_ops.py#L4806\r\n\r\nalso on lines 4805 and 4835 the call needs updating to\r\n\r\n`tf.image.extract_patches`\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/e5bf8de410005de06a7ff5393fafdf832ef1d4ad/tensorflow/python/ops/array_ops.py#L4805\r\n\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/e5bf8de410005de06a7ff5393fafdf832ef1d4ad/tensorflow/python/ops/array_ops.py#L4835\r\n\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/tutorials/quickstart/beginner\r\n\r\n## Description of issue (what needs changing):\r\n\r\nTutorial makes use of model.evaluate(), and the documentation says that this is usually done on a \"Validation Set\". Everything else I read (glossary, docs for model.fit()... including validation set parameters) points to this relating to a \"Test Set\" since it occurs after the training phase, and the parameters passed are \"x_test\" and \"y_test\". The confusion is unhelpful to beginners. Change from \"Validation Set\" to \"Test Set\"?\r\n\r\n### Correct links\r\n\r\nn/a\r\n\r\n### Parameters defined\r\n\r\nn/a\r\n\r\n### Returns defined\r\n\r\nn/a\r\n\r\n### Raises listed and defined\r\n\r\nn/a\r\n\r\n### Usage example\r\n\r\nn/a\r\n\r\n\r\n### Request visuals, if applicable\r\nn/a\r\n\r\n### Submit a pull request?\r\n\r\nNo. I'm a beginner, so I don't want to do anything, lest I create more confusion.\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/experimental/CosineDecay\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/experimental/CosineDecayRestarts\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/experimental/LinearCosineDecay\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/experimental/NoisyLinearCosineDecay\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/ExponentialDecay\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/InverseTimeDecay\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/PiecewiseConstantDecay\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/PolynomialDecay\r\n\r\nMay be present on others, but I'm not going to scour the web site looking.\r\n\r\n## Description of issue (what needs changing):\r\nThe general documentation of these classes does not show up on the web site. This leads to confusion as many of them have argument documentation containing statements such as *\"See the decay computation above\"*, when there is no documented computation above.\r\n\r\nInstead you have to open the source code to see the documentation that is mentioned.\r\n\r\nHere's an example:\r\n![image](https://user-images.githubusercontent.com/1826947/79771096-4f2dea00-82fc-11ea-8373-ec3572b00f3b.png)\r\nAnd here's the missing documentation:\r\n![image](https://user-images.githubusercontent.com/1826947/79771213-77b5e400-82fc-11ea-9d0d-2dc9efc02232.png)\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "This is about [this tutorial](https://www.tensorflow.org/guide/data) on input pipelines, and in particular the following note under \"Reading input data\" > \"Consuming NumPy arrays\":\r\n\r\n> Note: The above code snippet will embed the features and labels arrays in your TensorFlow graph as tf.constant() operations. This works well for a small dataset, but wastes memory---because the contents of the array will be copied multiple times---and can run into the 2GB limit for the tf.GraphDef protocol buffer.\r\n\r\nCould we have a slightly more detailed justification for this note, namely as to why `tf.data.Dataset.from_tensor_slices()` is suboptimal in this case. In particular:\r\n\r\n1. In which way are the contents of the array copied multiple times?\r\n2. What is the alternative to that code if we don't want to run into the 2GB limit? What is the best practice in general?"
  },
  {
    "labels": [null, "documentation"],
    "text": "## Description of issue (what needs changing):\r\nTensorflow gives many errors, and most of them aren't very helpful.  Something like \"module tensorflow has no attribute reset_graph.\"  Can we change the error messages so they are more constructive?  In this situation, the issue was partially solved by downgrading to tensorflow 1.12.  It would be helpful if instead of the \"reset_graph\" error message, we could get a message more like: \"this version of tensorflow is incompatible with the current project.  Please downgrade to tensorflow 1.12 using: pip install tensorflow==1.12\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\nTo keep from tearing their own hair out.\r\n\r\n\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/dtypes/DType\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe dtypes, such as, `tf.qint8`, `tf.quint8`, `tf.qint16`, `tf.quint16`, `tf.qint32`, are a bit unclear. What is `Quantized` suppose to mean? Where should a reader go to learn more about it? Clicking on the hyperlink of any of the dtypes of the above leads to [tf](https://www.tensorflow.org/api_docs/python/tf) which is just text. It does not give info about variable itself ( what is `quantization`? How and why is it an `int` ? )\r\n\r\n### Clear description\r\n\r\nNo clear description about what `quantization` really means. \r\nGoogling for `quantized tensorflow` leads us to,\r\n1): [Post training quantization](https://www.tensorflow.org/lite/performance/post_training_quantization)\r\n2): [TensorFlow Lite 8-bit quantization specification](https://www.tensorflow.org/lite/performance/quantization_spec)\r\n3): [Converting Quantized Models](https://www.tensorflow.org/lite/convert/quantization)\r\n4): [tf.quantization.quantize](https://www.tensorflow.org/api_docs/python/tf/quantization/quantize)\r\n5): [Post-training dynamic range quantization](https://www.tensorflow.org/lite/performance/post_training_quant)\r\n\r\nNone of which give a quick definition into what `quantization` is and what it is in Tensorflow.\r\n\r\n### Correct links\r\n\r\nThe link is correct, it is this https://www.tensorflow.org/api_docs/python/tf/dtypes/DType#tf.qint32 .\r\n\r\n### Parameters defined\r\n\r\nNot related to code.\r\n\r\n### Returns defined\r\n\r\nNot based on code.\r\n\r\n### Raises listed and defined\r\n\r\nNot related to code.\r\n\r\n### Usage example\r\n\r\nNot related to code.\r\n\r\n### Request visuals, if applicable\r\n\r\nNot really.\r\n\r\n### Submit a pull request?\r\n\r\nI do not plan to. Don't really have the time. \r\n\r\nThis is similar to issue #15 , closed, at [here](https://github.com/tensorflow/tensorflow/issues/15) and #494, [here](https://github.com/tensorflow/tensorflow/issues/494).\r\n\r\nThank you! And have a nice day. \r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "The examples in the documentations of `tf.linalg.tensor_diag_part` and `tf.linalg.tensor_diag`\r\nare showing the non-tensor version of these functions, e.g.\r\n```\r\n# 'diagonal' is [1, 2, 3, 4]\r\ntf.diag(diagonal) ==> [[1, 0, 0, 0]\r\n                       [0, 2, 0, 0]\r\n                       [0, 0, 3, 0]\r\n                       [0, 0, 0, 4]]\r\n```\r\n\r\nSee \r\nhttps://www.tensorflow.org/api_docs/python/tf/linalg/tensor_diag\r\nhttps://www.tensorflow.org/api_docs/python/tf/linalg/tensor_diag_part"
  },
  {
    "labels": [null, "documentation"],
    "text": "In this doc https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Ftrl the math is messed up\r\n\r\nsee https://snipboard.io/my0uSb.jpg\r\n\r\nusing chrome browser"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue: \r\nhttps://www.tensorflow.org/api_docs/python/tf/saved_model/tag_constants\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/tfx/serving/serving_basic#train_and_export_tensorflow_model\r\n\r\n## Description of issue (what needs changing):\r\nIn the explanation corresponding to **`tags`** in [this link](https://www.tensorflow.org/tfx/serving/serving_basic#train_and_export_tensorflow_model), the Hyperlink corresponding to the Text, related [TensorFlow API documentation](https://www.tensorflow.org/api_docs/python/tf/saved_model/tag_constants) is broken.\r\n\r\n### Clear description\r\n\r\nThis link is useful for the community to understand the purpose of different Tags used while Saving a Model.\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly? : Yes\r\n\r\n### Returns defined\r\n\r\nAre return values defined? : N/A"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/guide/data\r\n\r\n## Description of issue (what needs changing):\r\nHow to store tf.dataset object to file?\r\nFor instance,\r\n```\r\ndataset1 = tf.data.Dataset.from_tensor_slices(\r\n    tf.random.uniform([4, 10], minval=1, maxval=10, dtype=tf.int32))\r\ndataset1\r\n```\r\nHow to store the dataset1 to file?\r\n\r\n### Clear description\r\n\r\nFor me, a saved copy of tokenized dataset saves lot of training time.\r\n```python\r\nfrom transformers import AlbertTokenizer\r\nimport tensorflow as tf\r\nimport DataReader\r\nimport Tokenizer\r\n\r\n\r\ndef encode(type, dataPath='./qgdata/nq-train-sample.json'):\r\n    entries = DataReader.read(dataPath)\r\n    encoding = []\r\n    for entry in entries:\r\n        if type == 'context':\r\n            context = Tokenizer.encode(\r\n                entry['passage'], entry['answer'], entry['question'], True)\r\n            encoding.append(context)\r\n        else:\r\n            question = Tokenizer.encode(\r\n                entry['passage'], entry['answer'], entry['question'], False)\r\n            encoding.append(question)\r\n    data = tf.data.Dataset.from_generator(\r\n        lambda: encoding, tf.int64, output_shapes=512)\r\n    return data\r\n\r\n\r\ndef make_dataset(dataPath='./qgdata/nq-train-sample.json', batch_size=1):\r\n    contextData = encode('context', dataPath)\r\n    questionData = encode('question', dataPath)\r\n    dataset = tf.data.Dataset.zip((contextData, questionData))\r\n    return dataset.batch(batch_size)\r\n```\r\nInstead of running this batching script before each training, it would be very efficient to store the tokenzied dataset object to file and avoid retokenizing.\r\n\r\n### Usage example\r\nMaybe like:\r\n```python\r\ndataset1 = tf.data.Dataset.from_tensor_slices(\r\n    tf.random.uniform([4, 10], minval=1, maxval=10, dtype=tf.int32))\r\ndataset1.save_dataset(path_to_store)\r\n```\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/lite/performance/gpu_advanced\r\n\r\n## Description of issue (what needs changing):\r\n\r\nAfter a couple of days digging through documentation and source code, I'm still very confused about the current state of GPU support in tensorflow/lite.\r\n\r\n1. https://www.tensorflow.org/lite/performance/gpu_advanced#android_cc : talks about C/C++, which gives the illusion that one might use the lite/c API. But as far as I can see, the `ModifyGraphWithDelegate` function is not present in lite/c (why? It would be very helpful), even though it has the concept of delegates;\r\n2. https://www.tensorflow.org/lite/performance/gpu_advanced#android_cc : suggests a build command that generates a 60MB shared library... I don't see any benefit in giving such suggestion, since other commands listed in other pages will generate properly optimized binaries;\r\n3. https://www.tensorflow.org/lite/performance/gpu_advanced#android_cc : building on (2.), I'm also under the impression that building the delegate as a separate shared lib would not be the best option for minimizing the overall size - in this case, a target for building the delegate + libtensorflowlite together would be highly appreciated, at least as a documentation snippet (not to mention prebuilt binaries, which are referred by the team as \"coming soon\" in several not-so-recent issue comments);\r\n3. https://www.tensorflow.org/lite/performance/gpu_advanced#inputoutput_buffers : suggests the use of `GpuDelegate` which, as far as I understand comes from `lite/delegates/gpu/gl_delegate.h` and as such is deprecated. A big notice in the source code warns to migrate to the new implementation before the end of 2019, so it probably shouldn't be in documentation;\r\n4. https://www.tensorflow.org/lite/performance/gpu_advanced#inputoutput_buffers : \r\nWhile a replacement exists (`lite/delegates/gpu/delegate.h`), it does not have any `bindGlBufferToTensor()` function, and it is not clear how to achieve the same thing with the new delegate. There are several unanswered questions on SO about this;\r\n5. https://www.tensorflow.org/lite/performance/gpu_advanced#inputoutput_buffers : the example uses a SSBO, however the delegate seems to support [textures as well?](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/gpu/gl_delegate.h#L53-L57) If this can be a different way to send initial input, it would be nice to have it documented;\r\n\r\nIt is hard for us to plan the adoption of TFLite without a clear view over what you have, or at least where you're heading. For example, I'm especially interested in using GL buffers as input (sounds like a game changer), but I have no clue about what's the state of this in TFLite. Same with using delegates in lite/c, the abstraction is there but `ModifyGraphWithDelegate` is not. So doc fixes apart, could we have a very brief description of where TFLite + GPU/delegates is headed and what's coming in the next couple of months, so that people can decide if it meets their needs and plan accordingly? \r\n\r\nI understand that some of these APIs are marked as experimental and I really appreciate your work. Thanks!\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Apparently it is possible to render edges between data points in the embeddings projector but I cannot find the documentation for this anywhere. It is also not clear what other things might be possible which are not obvious or documented.\r\nA column called `__next__` may have special meaning, judging from one of the examples, but it is not clear what exactly it can be used for, what the requirements on the input are or what other special meaning column names there may exist.\r\nOr am I missing some obvious documentation here?"
  },
  {
    "labels": ["documentation"],
    "text": "Hello :) \r\n\r\nI am totally new at programming, and wanted some advice. \r\nI want to create a program using the google maps api. \r\n\r\nIs Python the adequate programming language to use? \r\n\r\nThanks in advance for your answer :) "
  },
  {
    "labels": [null, "documentation"],
    "text": "https://www.tensorflow.org/tutorials/text/nmt_with_attention\r\n\r\nthe decoder is trained step by step, and it's not passing last step state to this step\r\n\r\n```\r\n# passing the concatenated vector to the GRU\r\noutput, state = self.gru(x)\r\n```\r\n\r\nis this a feature or a bug? I checked a lot of NMT with attention paper, unlike the document those decoder are connected.\r\n\r\nthanks in advance!"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://github.com/tensorflow/examples/tree/master/lite/examples/image_segmentation/ios\r\n## Description of issue (what needs changing):\r\n\r\nThe README must be provided with an explanation of how to change the settings of the project. At the moment I have problems adjusting the development team (\"**Signing**\").\r\nError message: No profile for team 'Rob De Putter (Personal Team)' matching 'Wildcard' found: Xcode couldn't find any provisioning profiles matching 'GPC87JXMXD/Wildcard'. Install the profile (by dragging and dropping it onto Xcode's dock item) or select a different one in the Signing & Capabilities tab of the target editor.\r\n\r\n<img width=\"1421\" alt=\"Schermafbeelding 2020-04-05 om 14 54 09\" src=\"https://user-images.githubusercontent.com/36565271/78500273-4f9b8200-774d-11ea-8b6a-4f214fa2fe81.png\">\r\n<img width=\"1154\" alt=\"Schermafbeelding 2020-04-05 om 14 54 37\" src=\"https://user-images.githubusercontent.com/36565271/78500283-6641d900-774d-11ea-9bca-6aec48736816.png\">\r\n<img width=\"1152\" alt=\"Schermafbeelding 2020-04-05 om 14 54 30\" src=\"https://user-images.githubusercontent.com/36565271/78500289-6cd05080-774d-11ea-984b-d6f3710d8f08.png\">\r\n\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\nNo examples of generating Arduino IDE specific files from source (.cc) files\r\n\r\n### Clear description\r\nThere is documentation and code (generate_microlite_projects() function,transform_arduino_source.py, etc.) suggesting that the Make build system allows for easily creating files and a directory from source files to be used in the Arduino IDE but there are no Arduino examples that show how this is or should be done. \r\n\r\nIt would be useful to show how the hello_world project example was built for the Arduino IDE from the repo's source using Make.\r\n\r\n### Usage example\r\nIs there a usage example?\r\nNot for Arduino."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Hi!\r\n\r\nPlease see:\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/losses/categorical_hinge  \r\nhttps://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/losses.py#L866-L882\r\n\r\nBoth mention:\r\n> y_true: The ground truth values. y_true values are expected to be -1 or 1. If binary (0 or 1) labels are provided they will be converted to -1 or 1.\r\n\r\nWhile the code is --as expected-- a transcription of keras' one:\r\n```\r\n# ...\r\ny_pred = ops.convert_to_tensor(y_pred)\r\ny_true = math_ops.cast(y_true, y_pred.dtype)\r\npos = math_ops.reduce_sum(y_true * y_pred, axis=-1)\r\nneg = math_ops.reduce_max((1. - y_true) * y_pred, axis=-1)\r\nreturn math_ops.maximum(0., neg - pos + 1.)\r\n```\r\n\r\nAnd this code is meant to work with one-hot-encoded tensors. See the original discussion here: https://github.com/keras-team/keras/issues/2830"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue: \r\nhttps://youtu.be/aNrqaOAt5P4?list=PLQY2H8rRoyvzuJw20FG82Lgm2SZjTdIXU&t=660\r\n\r\n## Description of issue (what needs changing): \r\nIn the [TF Dev Summit 2020](https://youtu.be/aNrqaOAt5P4?list=PLQY2H8rRoyvzuJw20FG82Lgm2SZjTdIXU&t=660\r\n), Paige Bailey has talked about **Keras Tuner** and has shown its implementation. I liked the functionality but I couldn't information/documentation about it in [tensorflow.org site](https://www.tensorflow.org/).\r\n\r\n### Clear description: \r\nThis being a New Functionality, the documentation about that functionality in the Website would help the Community.\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct? : N/A\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?: N/A\r\n\r\n### Returns defined\r\n\r\nAre return values defined? : N/A\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? : N/A\r\n\r\n### Usage example\r\n\r\nIs there a usage example? N/A"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/tutorials/keras/text_classification_with_hub#build_the_model\r\n\r\nPlease provide a link to the documentation entry, for example:\r\n\r\nhttps://www.tensorflow.org/tutorials/keras/text_classification_with_hub#build_the_model\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe last layer in the model is `model.add(tf.keras.layers.Dense(1))`. However, in the following description, it says `The last layer is densely connected with a single output node. Using the sigmoid activation function, ...`\r\n\r\nI check the api doc and find that the default activation is none for dense layer.\r\n\r\n- Without `activation='sigmoid'`, the predictions are not in the range of (0, 1) as shown below, which is not interpretable.\r\n\r\n```\r\npred = model.predict(test_data.batch(512))\r\nprint(pred)\r\n\r\n[[-0.29496038]\r\n [ 1.2088487 ]\r\n [ 0.11580676]\r\n ...\r\n [-1.610341  ]\r\n [-0.8496179 ]\r\n [ 1.3117154 ]]\r\n```\r\n\r\nSo shall the example code be `model.add(tf.keras.layers.Dense(1, activation='sigmoid'))`?"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "I've found a little mistake in the documentation. On the following website, the order of y_true and y_pred are reversed:\r\n\r\nhttps://www.tensorflow.org/tutorials/customization/custom_training\r\n\r\n```\r\ndef loss(predicted_y, target_y):\r\n  return tf.reduce_mean(tf.square(predicted_y - target_y))\r\n```\r\n\r\nIt's usually the other way around:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/losses/\r\n\r\n```\r\nkeras.losses.mean_squared_error(y_true, y_pred)\r\n```\r\nIt makes no difference for MSE since this loss is symmetric. It does make a difference for MMSE (Masked MSE) where random values of the target are mapped to zero.\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "It would be useful to show the lifecycle of an API in the docs. That is, show when say, `tf.data.Dataset.take` was added or when a certain is removed / renamed. It could be extended to arguments of each API as well. Or to put it in one line,\r\n``` \r\nExpose version control information of APIs directly on tf docs\r\n```\r\nIt would really help developers keep up with rapid development of TF even better."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue: The information related to Arguments corresponding to the Pre-Trained Models defined under  https://www.tensorflow.org/api_docs/python/tf/keras/applications is missing.\r\n\r\nSome examples links are shown below:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/applications/MobileNet\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/applications/InceptionV3\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/applications/ResNet50\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/applications/VGG16\r\n\r\n## Description of issue (what needs changing): The information corresponding to Arguments should be specified like that it is Specified in [Keras Website](https://keras.io/applications/#vgg16).\r\n\r\nFor example, why should someone use this method? How is it useful? : If someone want to know what Arguments should be passed while trying to use these Pre-Trained Models, information is lacking in TF.Org site and the Developers should go to Keras Website. The information is not available in the Source Code corresponding to those TF Pre-Trained Models.\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct? : Yes\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined? : Yes\r\n\r\n### Usage example\r\n\r\nIs there a usage example? : NO\r\n\r\n### Submit a pull request? : No\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/save_and_restore_models.ipynb\r\n\r\n## Description of issue (what needs changing): The Tutorials corresponding to 1.x Version in Github has the version 2.x used inside it, thus leaving no Tutorials corresponding to 1.x (at least for Save and Restore)\r\n\r\n### Clear description: Please find the screenshot in [this link](https://screenshot.googleplex.com/gT6SwTNeY3E).\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct? : Yes\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly? : N/A\r\n\r\n### Returns defined\r\n\r\nAre return values defined? : N/A\r\n\r\n### Usage example\r\n\r\nIs there a usage example? : No, usage example for Save and Restore is not present for Tensorflow 1.x version\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content? : N/A\r\n\r\n### Submit a pull request?: No\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://github.com/tensorflow/docs/blob/r2.0/site/en/api_docs/python/index.md\r\n\r\n## Description of issue (what needs changing):\r\nThe link for `tf.debugging.assert_same_float_dtype` is dead\r\n\r\n### Clear description\r\n\r\nThe previous link leads to: https://github.com/tensorflow/docs/blob/r2.0/site/en/api_docs/python/tf/debugging/assert_same_float_dtype \r\nThe new link must be:\r\nhttps://github.com/tensorflow/docs/blob/r2.0/site/en/api_docs/python/tf/debugging/assert_same_float_dtype.md\r\n(The .md file extension is missing in the link)\r\n\r\n\r\n### Submit a pull request?\r\n\r\nYes, will be updating the issue soon enough\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "I see the core here https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/distributed_runtime\r\n\r\nBut there is no instruction about how to run TF with distributed system (C++ language). \r\nPlease share with us some documents about distributed TF c++.\r\n\r\nThanks,"
  },
  {
    "labels": ["documentation"],
    "text": "in [tensorflow.org](https://www.tensorflow.org/community) website the below roadmap link is  not working\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/losses/cosine_similarity\r\n\r\n## Description of issue (what needs changing):\r\nDocumentation states that tf.keras.losses.cosine_similarity() \"is a negative quantity between -1 and 0, where 0 indicates orthogonality and values closer to -1 indicate greater similarity.\"\r\nBut it is actually not true. tf.keras.losses.cosine_similarity() can return positive values.\r\n\r\n### Usage example\r\n```\r\n>>> import tensorflow as tf\r\n>>> tf.keras.losses.cosine_similarity([[1., 1.]], [[-1., -1.]])\r\n<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.99999994], dtype=float32)>\r\n```\r\n"
  },
  {
    "labels": [null, null, null, null, "documentation"],
    "text": "Hi, Im newbie on tensorflow. \r\nHow to use embedding_rnn_seq2seq on tensorflow v2? On tensorflow v1, it is in contrib.legacy_seq2seq class."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nOn the third line of the second code box, origin probability is [.9, .05, .05], [.5, .89, .6], [.05, .01, .94], it should be [.9, .05, .05], [.05, .89, .06], [.05, .01, .94]. "
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue: https://www.tensorflow.org/api_docs/python/tf/Variable\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing): \r\n\r\n### Clear description\r\n\r\nTF 1.13.1\r\nI can't find anything detail about differences between VarHandlOp and VariableV2. \r\nAs far as I know it seems that VarHandleOp implement in Keras and VariableV2 in TF 1.X. \r\nHow can I convert VarHandleOp to VariableV2 in tf.keras?\r\nI'm using some model processing tool that can only run under VariableV2 ops.\r\n\r\n### Correct links\r\n\r\nhttps://git.codingcafe.org/Mirrors/tensorflow/tensorflow/commit/e4a5c5356063d7f7b324a5771fe296bb199b532c\r\nSomelink above is all I could find.\r\n\r\n### Parameters defined\r\n\r\n---\r\n\r\n### Returns defined\r\n\r\n---\r\n\r\n### Raises listed and defined\r\n\r\n---\r\n\r\n### Usage example\r\n\r\nIs this a usage example?\r\nhttps://www.tensorflow.org/api_docs/python/tf/raw_ops/VariableV2?hl=pl\r\nIs that a kind of example?\r\n\r\n### Request visuals, if applicable\r\n\r\n---\r\n\r\n### Submit a pull request?\r\n---\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/microcontrollers/get_started.md#validate-input-shape\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nAt following lines of the second code of [this section](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/microcontrollers/get_started.md#validate-input-shape), it is claimed that input is a 2D tensor.\r\n\r\n```c++\r\n// The property \"dims\" tells us the tensor's shape. It has one element for\r\n// each dimension. Our input is a 2D tensor containing 1 element, so \"dims\"\r\n// should have size 2.\r\nTF_LITE_MICRO_EXPECT_EQ(2, input->dims->size);\r\n```\r\n\r\nHowever, based on [the notebook where the model defined](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/hello_world/create_sine_model.ipynb), it should have 1D tensor for input.\r\n\r\n### Submit a pull request?\r\n\r\nNo."
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(S) with issue:\r\nhttps://github.com/tensorflow/federated/blob/master/docs/federated_core.md\r\nIn the above readme file [MapsReduce](https://research.google/pubs/pub62.pdf/)\r\n\r\n### Pull Request\r\nI've corrected the link and by successfully merging [#813](https://github.com/tensorflow/federated/pull/813) it'll resolve this issue.\r\nHey, @mihaimaruseac Kindly review it."
  },
  {
    "labels": [null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/guide/upgrade#recommended_upgrade_process\r\n\r\n\r\n## Description of issue (what needs changing):\r\nthere is two consecutive \"will\" in the point `Run the upgrade script`. \r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? \r\nYes. I'll be opening a PR soon."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/Model#fit\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/Model#predict\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nI can't find a clear statement whether or not the regularization layers (noise, dropout) are bypassed when the validation data is processed (to calculate the validation loss) when calling `Model.fit()` provided with validation data. I can see that in the source code of the Dropout Layer that it is branched based on the `training` argument of `call()`. https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/layers/core.py#L181\r\n\r\nBut it is completely unclear to me whether or not the validation pass is considered \"training\" or not. After all, I'm calling the \"fit\" function."
  },
  {
    "labels": ["documentation"],
    "text": "\r\n## URL(s) with the issue:\r\nhttps://github.com/tensorflow/federated/blob/master/docs/deployment.md\r\n```tf.backends``` link is missing .\r\n##Pull request\r\n[#812](https://github.com/tensorflow/federated/pull/812) by sucessfully merging this PR will closw this issue.\r\n\r\n\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "\r\n## URL(s) with the issue:\r\nIn this repo the ```tf.framework.Executor``` link is broken.\r\n### Pull Request\r\nSuccessfully merging of [#811](https://github.com/tensorflow/federated/pull/811) will close this issue.\r\nHey, @MarkDaoust , @lamberta, and @mihaimaruseac would you please review this pull request."
  },
  {
    "labels": ["documentation"],
    "text": "\r\n## URL(s) with the issue:\r\nhttps://github.com/tensorflow/docs/blob/master/site/en/community/forums.md\r\n\r\n## Description of the issue (what needs changing):\r\nIn forums.ms  [how to get help](https://github.com/tensorflow/docs/blob/master/community/#get_help) is broken and while clicking it's showing 404 error.\r\n\r\n### submit a pull request\r\nHey, @MarkDaoust and @lamberta would you please assign me this issue and please provide details to fix this issue I'll love to fix this issue."
  },
  {
    "labels": [null, "documentation"],
    "text": "The codelab in question is [Build a handwritten digit classifier app with TensorFlow Lite\r\n](https://codelabs.developers.google.com/codelabs/digit-classifier-tflite/index.html?index=..%2F..index#3).\r\n\r\nStep 4.6 introduces the following snippet of code:\r\n\r\n```kotlin\r\n// Read input shape from model file\r\nval inputShape = interpreter.getInputTensor(0).shape()\r\ninputImageWidth = inputShape[1]\r\ninputImageHeight = inputShape[2]\r\nmodelInputSize = FLOAT_TYPE_SIZE * inputImageWidth * inputImageHeight * PIXEL_SIZE\r\n\r\n// Finish interpreter initialization\r\nthis.interpreter = interpreter\r\n```\r\n\r\n`interpreter` is a class field that has not been initialized in any previous code snippets and the code fails to compile.\r\n\r\nLooking at the finalized code in the `finish` directory of the downloadable sample, 4.6 should've probably included this code snippet to initialize `interpreter`:\r\n\r\n```kotlin\r\n// Initialize TF Lite Interpreter with NNAPI enabled.\r\nval options = Interpreter.Options()\r\noptions.setUseNNAPI(true)\r\nval interpreter = Interpreter(model, options)\r\n```"
  },
  {
    "labels": [null, null, null, null, "documentation", null],
    "text": "Hi. I am new to transformer and I'm trying to understand this transformer tutorial (https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/transformer.ipynb).\r\n\r\nIn this tutorial, a transformer has encoders, decoders, and a final linear layer.\r\nBut in the paper, a transformer has a softmax layer after the final linear layer.\r\nI think that `predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)` line correctly returns the  expected output anyway, but I just want to know why the softmax layer is not implemented in this tutorial. If I add a softmax layer after the final linear layer and train the model, will the prediction result be different?\r\n\r\nAnd why this tutorial used two separate vocabs instead of a shared subwords vocabulary? (maybe to keep the example simple?) If I want to use a shared vocabulary, should I implement the `shared_embedding_and_softmax_weights` part in tensor2tensor?\r\n\r\nThanks."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Hello tf team. I was trying the embedding tutorial as mentioned on the tf docs webpage.\r\n[https://www.tensorflow.org/tutorials/text/word_embeddings](https://www.tensorflow.org/tutorials/text/word_embeddings)\r\n\r\nThe below two lines do give me error while I am following the same documentation as mentioned in the webpage.\r\n\r\ntrain_batches = train_data.shuffle(1000).padded_batch(10)\r\ntest_batches = test_data.shuffle(1000).padded_batch(10)\r\n\r\n![image](https://user-images.githubusercontent.com/47158509/77058288-3e3b4180-69fb-11ea-932a-df913d43c385.png)\r\n\r\nI have manually tried to fix the error by putting padded_shapes as [None] or [None, None] but both of them have thrown error.\r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/applications/ResNet50\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/applications/ResNet50V2\r\n\r\n## Description of issue (what needs changing):\r\n\r\nTF provides two type of ResNet models. The first is ResNet50 which is implemented by the following code:\r\n\r\nhttps://github.com/keras-team/keras-applications/blob/master/keras_applications/resnet_common.py#L423-L441\r\n\r\nwhere, `stack1` is **basic** version of residual function:\r\nhttps://github.com/keras-team/keras-applications/blob/master/keras_applications/resnet_common.py#L64-L127\r\n\r\nAnd the second is ResNet50V2 which is implemented by the following code:\r\n\r\nhttps://github.com/keras-team/keras-applications/blob/b34c10628a0ab436542e9160f98de72b49084bbe/keras_applications/resnet_common.py#L483-L501\r\n\r\nwhere, `stack2` is **bottleneck** version of residual function:\r\nhttps://github.com/keras-team/keras-applications/blob/master/keras_applications/resnet_common.py#L175-192\r\n\r\nThe original [paper](https://arxiv.org/pdf/1512.03385.pdf) lists different type of ResNet in Table 1.\r\n\r\nBy the original  definition, the `ResNet50` should be 34-layer ResNet in the Table 1.\r\n\r\nFrom the implementation by `pytorch`: \r\n\r\nhttps://github.com/pytorch/vision/blob/cc43e0a98368055d7a661651a2b9dbf28a19e533/torchvision/models/resnet.py#L244-L266\r\n\r\nThey claim the first one is ResNet34.\r\n\r\nSo I suggest that the `ResNet50` should change its name.\r\n\r\n\r\n\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "TF Version : 1.15.0\r\nOS : Windows 10 64-bit\r\nCompiler : MSVC 2017\r\n\r\n\r\nI'm attempting to load a TF SavedModel and run inference on it using the [C API](https://www.tensorflow.org/install/lang_c) for TF version 1.15.0.\r\n\r\n**Essential outlay**:\r\nInput Tensor(s) : 'encoded_image_string_tensor:0'\r\nOutput Tensor(s) [_not exhaustive_] : ['detection_boxes:0' , 'detection_scores:0', 'detection_classes:0']\r\n\r\nWhile there's some documentation in the API header that describes how TF_Tensors of type TF_STRING are encoded, I can't seem to find any concrete examples/illustrations which is probably why I keep running into an error when attempting to encode an image.\r\n\r\nI picked up some parts from [this](https://stackoverflow.com/questions/41138822/how-to-create-a-string-type-tensor-in-tensorflow-c-api) unchecked answer on StackOverflow to get started:\r\n```\r\n// char* image (contains a pointer to the image)\r\n// const unsigned int imageSize (contains the size of the image)\r\n\r\nstd::vector<int64_t> inputDims = { static_cast<int64_t>(TF_DataTypeSize(TF_UINT64)) + static_cast<int64_t>(imageSize) };\r\nsize_t encodedSize = TF_StringEncodedSize(imageSize);\r\nsize_t totalSize = TF_DataTypeSize(TF_UINT64) + encodedSize;\r\nchar* encodedInput = new char[totalSize];\r\nfor (size_t i = 0; i < TF_DataTypeSize(TF_UINT64); i++)\r\n  encodedInput[i] = 0;\r\n\r\nTF_StringEncode((const char*)image.data, imageSize, encodedInput + 8, encodedSize, status);\r\nif (TF_GetCode(status) == TF_OK) {\r\n  std::cerr << \"Failed to encode image\\n\"; // The code enters this block and TF_Message(status) returns nothing to the output stream\r\n  std::cerr << TF_Message(status) << std::endl;\r\n  return false;\r\n}\r\n\t\r\nTF_Tensor* input = TF_NewTensor(TF_STRING, inputDims.data(), inputDims.size(), encodedInput, totalSize, NULL, 0);\r\n\r\n```\r\nIs there any guide on how to encode images as TF_STRING type tensors?\r\n\r\nThanks!\r\n\r\n\r\n\r\n\r\nPlease use [Netron](https://lutzroeder.github.io/netron/) to view the model if necessary\r\n[saved_model.zip](https://github.com/tensorflow/tensorflow/files/4344883/saved_model.zip)\r\n\r\n  "
  },
  {
    "labels": [null, null, "documentation"],
    "text": "\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/tensor_scatter_nd_add\r\n\r\n## Description of issue (what needs changing):\r\nThese sentences: \r\n> `indices` is an integer tensor containing indices into a new tensor of shape `shape`. The last dimension of `indices` can be at most the rank of `shape`:\r\n\r\nSeem to be direct copy-paste from the docs of [`scatter_nd`](https://www.tensorflow.org/api_docs/python/tf/scatter_nd). However, there is no `shape` args in `scatter_nd_add`.\r\n\r\n### Clear description\r\n\r\nThe docs should instead refer to `tensor.shape`.\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct? There is no link (that's another issue though I guess), only to the tf v1\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly? Yes \r\n\r\n### Returns defined\r\n\r\nAre return values defined? Yes\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? No errors raised apparently\r\n\r\n### Usage example\r\n\r\nIs there a usage example? Yes\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content? No, but there are some in `scatter_nd`, I guess it's enough\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n\r\nNot right now\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\n* https://www.tensorflow.org/guide/migrate#1_replace_v1sessionrun_calls\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThere is no information provided to the end-user on how to convert simple `Session.run` calls into `tf.function` calls for TensorFlow 2. For people who are only interested in running saved models and not building their own architectures, the lack of information makes it difficult to fully migrate away from TensorFlow 1.x.\r\n\r\n### Clear description\r\n\r\nIf I am doing a SavedModel-based system with TensorFlow 1.x (I was provided the model, I did not make the model), there should be a direct explanation of how to convert `Session.run` calls into more modern `tf.function` calls. Here is an example of the code I'm trying to convert to TensorFlow 2, but I can't complete the conversion because of a lack of documentation for this use case:\r\n\r\n```python\r\nwith tf.Session(graph=tf.Graph()) as sess:\r\n    tf.saved_model.loader.load(sess, [\"serve\"], path_to_model)\r\n    cap = cv2.VideoCapture(camera_id)\r\n    ret, frame = cap.read()\r\n    ret, encoded = cv2.imencode(\".jpg\", frame)\r\n    inferred = sess.run([\"detection_scores:0\", \"detection_boxes:0\"], feed_dict={\r\n        \"encoded_image_string_tensor:0\": [encoded.tobytes(),]\r\n    })\r\n```\r\n\r\nEssentially, I'm looking for a piece of documentation with code equivalency for these sort of examples.\r\n\r\n### Correct links\r\n\r\n***Not applicable***\r\n\r\n### Parameters defined\r\n\r\n***Not applicable***\r\n\r\n### Returns defined\r\n\r\n***Not applicable***\r\n\r\n### Raises listed and defined\r\n\r\n***Not applicable***\r\n\r\n### Usage example\r\n\r\n***Not applicable***\r\n\r\n### Request visuals, if applicable\r\n\r\n***Not applicable***\r\n\r\n### Submit a pull request?\r\n\r\nI can't submit a pull request because of the lack of documentation on the issue at hand. I could, however, submit a pull request to resolve the problem once I know how to resolve the problem.\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nThe issue affects many pages, here is one example:\r\n- TF 2.2: https://www.tensorflow.org/versions/r2.2/api_docs/python/tf/keras/optimizers/schedules/ExponentialDecay\r\n- TF 2.1: https://www.tensorflow.org/versions/r2.1/api_docs/python/tf/keras/optimizers/schedules/ExponentialDecay\r\n- TF 2.0: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/optimizers/schedules/ExponentialDecay\r\n\r\n## Description of issue (what needs changing):\r\nThe generated docs for TF 2.1 and TF 2.2 is missing important information. Notably, the whole documentation of `__init__` method containing information like detailed learning rate computation\r\n```python\r\ndef decayed_learning_rate(step):\r\n  return initial_learning_rate * decay_rate ^ (step / decay_steps)\r\n```\r\nis missing in TF 2.1 and TF 2.2. However, the information is still present in the source, see \r\nhttps://github.com/tensorflow/tensorflow/blob/3c1e8c03419266bb6ba379d303d3e03a380617a8/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py#L64-L134\r\n\r\n## Further examples\r\nFor example Adam optimizer is also affected, see\r\n- TF 2.2: https://www.tensorflow.org/versions/r2.2/api_docs/python/tf/keras/optimizers/Adam\r\n- TF 2.0: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/optimizers/Adam\r\nThe TF 2.0 version contains a lot of math describing how Adam works, which is not present in TF 2.2 docs."
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:  \r\nhttps://github.com/tensorflow/docs/blob/r2.0/site/en/api_docs/python/index.md\r\n## Description of the issue (what needs changing):\r\nThere are lots of links are broken, some of them are:\r\nhttps://github.com/tensorflow/docs/blob/r2.0/site/en/api_docs/python/tf/dtypes/DType\r\nhttps://github.com/tensorflow/docs/blob/r2.0/site/en/api_docs/python/tf/data/experimental/get_structure\r\nhttps://github.com/tensorflow/docs/blob/r2.0/site/en/api_docs/python/tf/debugging/assert_same_float_dtype\r\nhttps://github.com/tensorflow/docs/blob/r2.0/site/en/api_docs/python/tf/estimator/ModeKeys\r\nhttps://github.com/tensorflow/docs/blob/r2.0/site/en/api_docs/python/tf/fill\r\n\r\n### Clear description\r\nThere are lots of the link is broken in r2.0/site/en/api_docs/python/index.md. when someone clicks on these links it's showing 404 ERROR.\r\n\r\n## Solution \r\nWhen I checked  https://www.tensorflow.org/versions/r2.0/api_docs/python . I found out every links\r\nare correct. For example\r\n* tf.DType link is broken in Github but working fine in TensorFlow website\r\nAs the numbers of broken links are big. I'll suggest adding a message like\r\n\" Our TensorFlow 2.0 RC docs is moved to https://www.tensorflow.org/versions/r2.0/api_docs/python. Kindly checkout there\"\r\nI have seen this type of message in some of the TensorFlow docs.\r\n## Pull Request\r\nHey, @dynamicwebpaige , @lamberta, @MarkDaoust  . Please assign me for doing this. I'll love to address this issue.\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/image/rgb_to_yuv?version=nightly\r\n\r\n## Description of issue (what needs changing):\r\n(1) The example image `x` has pixel values which are not in the range of [0,1]. So, it can't be fed to `rgb_to_yuv` directly without scaling it.\r\n(2) Users of the API need example which is close to practical scenario. In this case, nobody wants to see the values changed by the function but they want correct implementation and pre-processing example.\r\n\r\n### Submit a pull request? \r\nYes\r\n\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://github.com/tensorflow/models/tree/master/official/vision/detection\r\n\r\n## Description of issue (what needs changing):\r\n\r\nHi,\r\nIn the \"Train a vanilla ResNet-50 based RetinaNet.\" it is said to use the \"path to the pre-trained Resnet-50 checkpoint\". There is no link to any pre-trained model. \r\n![image](https://user-images.githubusercontent.com/54512903/76514447-2f331d00-6458-11ea-8d63-dd474964f22c.png)\r\n\r\nI tried to use the resnet-50 which is in https://github.com/tensorflow/models/tree/master/official/vision/image_classification because it was likely to be a correct implementation as an official one. \r\n![image](https://user-images.githubusercontent.com/54512903/76515131-5b02d280-6459-11ea-973f-aabff6078c2d.png)\r\nUnfortunately, when I use :\r\npython main.py --strategy_type=one_device --num_gpus=1 --model_dir=\"my_models\" --mode=train --config_file=\"my_retinanet.yaml\"\r\n\r\nWith this yaml : \r\ntype: 'retinanet'\r\ntrain: \r\n  checkpoint:\r\n    path: pretrained_model\\home\\hongkuny\\hongkuny_keras_resnet50_gpu_8_fp32_eager_graph_cfit\\checkpoints\r\n    prefix: resnet50\\\r\n  train_file_pattern: tfrecords\\train.record\r\neval:\r\n  eval_file_pattern: tfrecords\\test.record\r\n\r\nI got nothing load because the weight seems to be wrongly named in this file, so it is not matching.\r\n\r\n![image](https://user-images.githubusercontent.com/54512903/76515306-a4532200-6459-11ea-90d7-b144b6498151.png)\r\n \r\nI also tried some other models from the zoo assuming we might load weights from resnet based objects detection models but I got the same probleme. \r\n\r\nI think we might add a link to a correct checkpoint of a compatible pre-trained model in order to avoid roaming around incompatible models. \r\n\r\nregards, \r\n\r\nSwann"
  },
  {
    "labels": ["documentation"],
    "text": "\r\n\r\n## URL(s) with the issue:\r\nREADME.md  Resources's roadmap link is broken.\r\nhttps://www.tensorflow.org/community/roadmap\r\n\r\n## Description of issue (what needs changing):\r\nIt is occurred Page not found errer.\r\n\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/preprocessing\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe module documentation is very terse and only states that it contains \"preprocessing utils\". It does not state the specific purpose.\r\n\r\nIt would be helpful if it defined the intended use of the `tf.keras.preprocessing` module (_e.g._ to clean up or transform tf.data.Datasets before they are fed to the model).\r\n\r\nAlso, since the `tf.feature_column` module has similar functionality, it would be nice to describe when to use one or the other, or how they are intended to be used together."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/metrics/Precision\r\n\r\n## Description of issue (what needs changing):\r\nThis method does not compute the precision *on average* when top_k is set. This could lead to bad evaluations, especially when the sample_weight is set and used as counts.\r\n\r\n### Clear description\r\n\r\nTo see the issue, it's enough to run \r\n```\r\nm = tf.keras.metrics.Precision(top_k=2)\r\nm.update_state([0, 0, 1, 1], [1, 1, 1., 1.])\r\n\r\nprint('Final result: ', m.result().numpy()) # Returns 0 but should return 0.5\r\n```\r\nIt always computes the precision according to the given order and returns 0. However it should return 0.5 if it's on average.\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "Tensorflow2.0 is not supporting this `tf.contrib.training.bucket_by_sequence_length` and what can I use instead of this "
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\na link to the documentation entry\r\nhttps://tensorflow.google.cn/tutorials/estimator/boosted_trees_model_understanding\r\n\r\n## Description of issue (what needs changing):\r\nA bug I found in \"TensorFlow > Learn > TensorFlow Core > Tutorials > Gradient Boosted Trees: Model understanding\" as below:\r\n\r\nmatplotlib.mlab has been removed @ version 3.1.0 \"https://matplotlib.org/3.1.0/api/api_changes.html\"\r\nbut the tutorials still uses _griddata_ class for plotting, i can not get the result follow this.\r\n\r\nso would you mind adjust this for correct code? i am a beginner for tensorflow and python, so fix it by myself is difficult for me ,thanks \r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/datasets/overview\r\n\r\n## Description of issue (what needs changing):\r\n\r\n 😀I completed step 1 and  went to “https://www.tensorflow.org/datasets/overview” to get started with TFDS. I launched the code lab to continue with the overview. The code lab is a great option to easily run python and tensorflow! \r\n\r\n😑- I completed the first command to install tensorflow and tensorflow-datasets\r\n![image](https://user-images.githubusercontent.com/6283150/75946296-9433b500-5e51-11ea-921e-f44a6fc1573e.png)\r\n\r\nThe download ran but it was not clear which version of tensorflow was downloaded. The reason I was confused and wanted to know which version was installed is the disclaimer above states version >=1.15 is required.\r\n😑- In the second command, I received an error message after running the python script.\r\n![image](https://user-images.githubusercontent.com/6283150/75946322-a44b9480-5e51-11ea-8874-51a4863093ae.png)\r\n\r\nI was not clear if this was just a warning message, or an error due to my current tensorflow version. \r\n\r\n😀Step 2 was delightful!\r\n![image](https://user-images.githubusercontent.com/6283150/75946336-aca3cf80-5e51-11ea-949a-0ca03348d768.png)\r\n\r\nAdding in a disclaimer to include citations is great! 😑However, why is it after the download step? This seems out of place and disrupts the developer workflow. \r\n\r\nNext was step 3 to initiate eager execution.\r\n😑Without a baseline on what EE is, I felt required to read the eager execution page before I could move forward. It’s frustrating when a developer guide links out to other documentation, or I feel compelled to read the other pages, because it causes disruption in grasping one concept at a time. This frustration can be a “drop off” point for developers trying to onboard Tensorflow.\r\n\r\n![image](https://user-images.githubusercontent.com/6283150/75946528-35227000-5e52-11ea-9312-09405b8e3043.png)\r\n\r\nEnable_V2_Behavior is the command run after asking the user to enable eager execution. Why is that? (After reading the eager execution documentation this was clear, but it took time to dig for this info).\r\n\r\n😡Step 5 understanding what the tf “load” function does is frustrating.\r\n![image](https://user-images.githubusercontent.com/6283150/75946560-44092280-5e52-11ea-85be-ded98f6365c3.png)\r\n\r\n😡I’m strongly encouraged to read the official TensorFlow guide which is over 30 pages of material. I am 5 steps down this getting started guide, and then sent to another page that will reasonably take 4+ focused hours to additionally complete. This is very frustrating when I am trying to just get an overview of tensorflow datasets.\r\n\r\n😀Step 5 does a great job here showing an example directly in relation to the above paragraph on versioning! I’m delighted and can move on without needing to read the hyperlink. \r\n![image](https://user-images.githubusercontent.com/6283150/75946588-54b99880-5e52-11ea-8e80-6ec1f06b684e.png)\r\n\r\n😑Step 7 is confusing since it states we can achieve the same output using the DatasetBuilder, but when you run the test it only outputs the ds_train variable, as opposed to building the graph. \r\n![image](https://user-images.githubusercontent.com/6283150/75946599-5be0a680-5e52-11ea-9cfd-37520abadae3.png)\r\n\r\n### What should happen?\r\n\r\nI have organized answers to the above friction points in the following groupings:\r\n\r\n**Tensorflow Installation**\r\nTo identify which version of Tensorflow I installed I ran a grep command in the code lab to output the following:\r\n\r\n![image](https://user-images.githubusercontent.com/6283150/75946716-bd087a00-5e52-11ea-95d3-c13f68c33df9.png)\r\n\r\nHaving something like this ^ output during installation will help users know what is downloaded and executed in the install command. \r\n\r\n**Eager Execution**\r\n\r\nA simple way to clarify what eager execution is to write a one sentence definition in the guide. For example:\r\n\r\n“TensorFlow's eager execution is an imperative programming environment that evaluates operations immediately, without building graphs: operations return concrete values instead of constructing a computational graph to run later.”\r\n\r\nThis way I have a quick understanding and don’t feel compelled to read the linked page which is a very long document! :)\r\nI liken this to applications having a tooltip in consumer facing applications. Adding in quick non intrusive explanations to Respect the User keep your users engaged and on the same page. \r\n\r\nAdditionally, adding in the following message to define the command, “enable_v2_behavior”, would help clarify that Eager Execution is enabled by default tensorflow 2. \r\n\r\n![image](https://user-images.githubusercontent.com/6283150/75946725-c560b500-5e52-11ea-9229-96f8b71dc895.png)\r\n\r\n\r\n**Linking to the official guide for Tensorflow Datasets**\r\n![image](https://user-images.githubusercontent.com/6283150/75946747-d3163a80-5e52-11ea-820b-a43d13bbbe76.png)\r\n\r\nWe need to Respect the User, and provide simplicity when on boarding someone new to TFDS. They have invested time to make it down to the 5th step. If it is imperative the user get a baseline understanding of the Tensorflow API first, then we should put the disclaimer at the top of the overview to go read the guide first before continuing. \r\n\r\nIf it is not necessary, then we should summarize the API guide into 3-5 concise pillars of information that is required for the user to understand the rest of the overview. When the user completes the overview, we can encourage them to go deeper and read the rest of the guide. Similarly, an analogy is when loading a website you respect the user by building a light-weight modern site. Performant sites lazy load in images when they are needed to improve performance and minimize how much data your user needs to download, we should apply the same principles to information.  \r\n\r\n**DatasetBuilder**\r\nWhen introducing in the DatasetBuilder we should place this information right after Step 5 (calling .load), to show the two ways to load in datasets side by side. This way the user does not need to scroll back up the documentation and read before Step 6 (plotting the dataset). \r\n\r\n\r\n\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue / ## Description of issue (what needs changing):\r\n\r\nInside the Friction Log Document: https://docs.google.com/document/d/1HVG3t-mgGZKU4iMeguTWGejbnQ54qUTXwdCFkA5xHG0/edit\r\n\r\nThere is a broken link to the \"Bug / Performance\" template:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/.github/ISSUE_TEMPLATE/00-bug-performance-issue.md\r\n\r\n### Correct links\r\n\r\nI see there are two templates - \r\n**Performance:** https://github.com/tensorflow/tensorflow/issues/new?labels=type%3Aperformance&template=80-performance-issue.md\r\n\r\n**Bug**: https://github.com/tensorflow/tensorflow/issues/new?labels=type%3Abug&template=00-bug-issue.md\r\n\r\nThe friction log should update these links in the google doc, \r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/Module\r\n\r\n## Description of issue (what needs changing):\r\n\r\nI extract the example codes, run it and got Error. It seems caused by inconsistant kwargs name:\r\n\r\n```python\r\n class Dense(tf.Module):\r\n   def __init__(self, in_features, output_features, name=None):\r\n     super(Dense, self).__init__(name=name)\r\n     self.w = tf.Variable(\r\n         tf.random.normal([input_features, output_features]), name='w')\r\n     self.b = tf.Variable(tf.zeros([output_features]), name='b')\r\n\r\n   def __call__(self, x):\r\n     y = tf.matmul(x, self.w) + self.b\r\n     return tf.nn.relu(y)\r\n\r\n\r\nclass MLP(tf.Module):\r\n  def __init__(self, input_size, sizes, name=None):\r\n    super(MLP, self).__init__(name=name)\r\n    self.layers = []\r\n    with self.name_scope:\r\n      for size in sizes:\r\n        self.layers.append(Dense(input_size=input_size, output_size=size))\r\n        input_size = size\r\n\r\n  @tf.Module.with_name_scope\r\n  def __call__(self, x):\r\n    for layer in self.layers:\r\n      x = layer(x)\r\n    return x\r\n\r\nmlp = MLP(input_size=100, sizes=[30, 30])\r\n```\r\n\r\noutput:\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-137-269f8996957a> in <module>()\r\n----> 1 mlp = MLP(input_size=100, sizes=[30, 30])\r\n\r\n<ipython-input-135-066c337c5b7a> in __init__(self, input_size, sizes, name)\r\n     17    with self.name_scope:\r\n     18      for size in sizes:\r\n---> 19        self.layers.append(Dense(input_size=input_size, output_size=size))\r\n     20        input_size = size\r\n     21 \r\n\r\nTypeError: __init__() got an unexpected keyword argument 'input_size'\r\n```\r\n\r\n\r\n### Submit a pull request?\r\n\r\n I think just need to modify several lines to fix it:\r\n\r\n```python\r\n class Dense(tf.Module):\r\n   def __init__(self, input_size, output_size, name=None):\r\n     super(Dense, self).__init__(name=name)\r\n     self.w = tf.Variable(\r\n         tf.random.normal([input_size, output_size]), name='w')\r\n     self.b = tf.Variable(tf.zeros([output_size]), name='b')\r\n\r\n   def __call__(self, x):\r\n     y = tf.matmul(x, self.w) + self.b\r\n     return tf.nn.relu(y)\r\n\r\n\r\nclass MLP(tf.Module):\r\n  def __init__(self, input_size, sizes, name=None):\r\n    super(MLP, self).__init__(name=name)\r\n    self.layers = []\r\n    with self.name_scope:\r\n      for size in sizes:\r\n        self.layers.append(Dense(input_size=input_size, output_size=size))\r\n        input_size = size\r\n\r\n  @tf.Module.with_name_scope\r\n  def __call__(self, x):\r\n    for layer in self.layers:\r\n      x = layer(x)\r\n    return x\r\n```\r\n\r\nShould I submit a PR to fix this?\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "First of all, you have a great website to understand the Tensorflow library. I am a newbie. And want to understand the point is: I go through the examples. Except for basic image classification, there is no example : how to feed my own data wich has no label. And I want to get predictions of my own data. example :   https://stackoverflow.com/questions/60389558/how-to-feed-my-own-data-and-evaluate-at-tf-text-classification "
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/losses/get\r\n\r\n## Description of issue (what needs changing):\r\nCurrently there is no documentation at all.\r\nIts fairly straightforward to use by inputting a string denoting default class name:\r\nex:\r\n```\r\nidentifier = \"categorical_crossentropy\"\r\ntf.keras.losses.get(identifier)\r\n```\r\n\r\nHowever, I am having issues with dictionary objects:\r\nex:\r\n```\r\nidentifier = {\"class_name\":\"categorical_crossentropy\",\"config\":{\"from_logits\":True}}\r\ntf.keras.losses.get(identifier)\r\n```\r\nReturns:\r\n```\r\nTraceback (most recent call last):\r\n  File \".\\main.py\", line 85, in <module>\r\n    loss = tf.keras.losses.get(jsn)\r\n  File \"C:\\Users\\jopatterson\\Documents\\autoprime-ml\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\losses.py\", line 1186, in get\r\n    return deserialize(identifier)\r\n  File \"C:\\Users\\jopatterson\\Documents\\autoprime-ml\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\losses.py\", line 1175, in deserialize\r\n    printable_module_name='loss function')\r\n  File \"C:\\Users\\jopatterson\\Documents\\autoprime-ml\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\generic_utils.py\", line 315, in deserialize_keras_object\r\n    return cls(**cls_config)\r\nTypeError: categorical_crossentropy() missing 2 required positional arguments: 'y_true' and 'y_pred'\r\n```\r\nI believe it is failing because cls is the already initialized loss function, and it is passing cls_config as its input, rather than using them as parameters during initialization.\r\n\r\n### Clear description\r\n\r\nThis is a very useful method for abstract implementations of loss objects.\r\n\r\n### Correct links\r\n\r\nThis is where the issue is occuring, within the `deserialize_keras_object` function:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/utils/generic_utils.py#L382\r\n\r\n### Parameters defined\r\n\r\nThere currently is no documentation for this, as `identifier` can be a string, dictionary or callable.\r\n\r\n### Returns defined\r\n\r\nReturns are not defined, but its fairly obvious it returns a loss function.\r\n\r\n### Raises listed and defined\r\n\r\nNo.\r\n\r\n### Usage example\r\n\r\nNo.\r\n\r\n### Request visuals, if applicable\r\n\r\nNo.\r\n\r\n### Submit a pull request?\r\n\r\nI would do this if I had enough knowledge to do so. Unfortunately I only know how it works with `identifier` as a String."
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "The tutorial example for tf.keras.experimental.WideDeepModel instantiated the class with first input augment: dnn_model, and second augment: linear_model as shown in :\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/experimental/WideDeepModel#example_4\r\n\r\nHowever, the class should be instantiated by linear_model then dnn_model as shown in:\r\nhttps://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/premade/wide_deep.py#L72\r\n\r\nPlease update the tutorial example.\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/debugging/assert_shapes\r\n\r\n## Description of issue (what needs changing):\r\nThe documentation for the `shapes` argument states that is expects a dict, but in fact in many circumstances it is not possible to assemble such a dict because eager tensors are unhashable.\r\nSo while it is possible to submit a dict here in GraphMode, Eager expects a list of (key, value) pairs.\r\n\r\nIt should also state whether `tf.Variable`s can be used as keys.\r\n\r\n### Usage example\r\nThe usage example seems to confuse the two concepts, and provides a mixup of both in invalid python syntax:\r\n```\r\ntf.assert_shapes([\r\n  (x: ('N', 'Q')),\r\n  (y: ('N', 'D')),\r\n  (param: ('Q',)),\r\n  (scalar: ()),\r\n])\r\n```\r\n*This seems to be fixed already in master*\r\n\r\n\r\nFurther, `tf.assert_shapes` should probably be changed to `tf.debugging.assert_shapes`\r\n\r\n### Submit a pull request?\r\nYes"
  },
  {
    "labels": [null, "documentation"],
    "text": "![0](https://user-images.githubusercontent.com/61679488/75651231-4d9c5a00-5c9b-11ea-8054-bc2c8a22a1d1.PNG)\r\n\r\nhi\r\ni wanna use '**from utility import lazy_property**' code but i can't\r\n i think that code for TF1. can you let me know what is the Code that serves the same role in tf2?\r\n\r\nIf not, please let me know the appropriate code thanks"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback\r\nhttps://www.tensorflow.org/guide/keras/custom_callback\r\n\r\n## Description of issue (what needs changing):\r\nThe documentation for the keras `Callback` base class contains the following generic statement about the `logs` parameter passed to its methods:\r\n```\r\nThe logs dictionary that callback methods take as argument will contain keys for quantities relevant to the current batch or epoch.\r\n```\r\nand\r\n```\r\nThe logs dict contains the loss value, and all the metrics at the end of a batch or epoch. Example includes the loss and mean absolute error.\r\n```\r\non the Keras custom callbacks page.\r\n\r\nSince python passes objects by reference, the question becomes whether write-access to this logs parameter is allowed and supported. An example use case would be to provide a custom callback that populates the `logs` dictionary with some additional information that than would automatically be displayed in the progress bar and tensorboard, and recorded in history and CSV callbacks. \r\n\r\nTherefore, I think the documentation should clearly state whether \r\n1) Write-access to the `logs` dict is forbidden (in which case it might be worthwhile to pass a non-writeable dict-like type)\r\n2) Write-access to `logs` is allowed, and will not have any side-effects on any other Callback (i.e. each Callback gets an independent copy)\r\n3) The `logs` dict is writable, and changes to it are visible to any further Callback. This would also require to specify in which order the callbacks are processed.\r\n "
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Nadam\r\n\r\n## Description of issue (what needs changing):\r\nOptional name attribute is said to default as \"Adamax\" rather than \"Nadam\"\r\n\r\n### Clear description\r\n\r\nname: Optional name for the operations created when applying gradients. Defaults to \"Adamax\".\r\n\r\n### Correct links\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/optimizer_v2/nadam.py#L33-L238\r\n\r\nSource code correctly shows default as name=\"Nadam\". Therefore documentation issue.\r\n\r\n### Submit a pull request?\r\n\r\nNot at the moment"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/image/encode_png\r\n\r\n## Description of the issue (what needs changing):\r\n\r\nCurrently, all Image decoding and encoding functions are a part of the `tf.io` module but `encode_png` function is still a part of the `tf.image` module.\r\n\r\n## Changes required\r\n\r\nChange `tf.image.encode_png`  to `tf.io.encode_png`\r\n\r\n\r\n### Submit a pull request?\r\nI will be happy to help.\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "In tflite post integer quantization, `converter.representative_dataset` is necessary.\r\n\r\nHowever, the documentation never specifies the order of the fed inputs. Are they ordered by lexicographic order of the names, size of shapes or even random order? When multiple inputs are present, it is totally a guessing game.\r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/Attention\r\n\r\n## Description of issue (what needs changing):\r\nTypo was reintroduced in v2.1\r\nSee https://github.com/tensorflow/tensorflow/issues/34809 \r\n\r\nmust be \r\n\r\n```\r\nvalue_embeddings = token_embedding(value_input)\r\n```\r\n\r\n@rabitt"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/math/xlog1py\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThis documentation describes `tf.math.xlog1py`, shown as a part of \"stable\" version of TF 2.1 but I believe this API has not been released yet. `tf.math.xlog1py` is only available on nightly at this point, added in https://github.com/tensorflow/tensorflow/commit/19986377f2a3c560418f42f2323733564a7303eb (Jan 2020).\r\n\r\nFYI: I ran into this issue as I was using `tfp-nightly` which depends on `tf-nightly` (module 'tensorflow_core._api.v2.math' has no attribute 'xlog1py').\r\n\r\nThe documentation should have not published under \"TensorFlow Core v2.1.0\". Why was it the case? If it was due to a mistake, could we improve on the process so we can have a \"nightly\" doc and a \"stable\" doc?"
  },
  {
    "labels": [null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue: \r\nhttps://github.com/tensorflow/tensorflow/blob/master/README.md\r\n\r\n## Description of issue (what needs changing):\r\n\r\nSInce , PSF has officially stopped it's support for Python2, the documentation needs to be upgraded to Python3.\r\npip2 -> pip3 \r\n### Clear description\r\n\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\nYes, I'll\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/image/yuv_to_rgb\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe tf.image.yuv_to_rgb method specifies a YUV input of shape (H,W,3) and an RGB output of the same shape. It also notes:\r\n\r\n> The output is only well defined if the Y value in images are in [0,1], U and V value are in [-0.5,0.5].\r\n\r\nHowever YUV is natively encoded in HxWx1.5 Bytes, with values ranging from 0-255. Considering that multiple YUV-RGB conversion standards exist, it is unclear what pre-processing steps need to be done by a user who wants to pass YUV inputs to his network (https://en.wikipedia.org/wiki/YCbCr#JPEG_conversion).\r\n\r\n### Usage example\r\n\r\nMore documentation on the proper usage of this method would be highly helpful. Specifically:\r\n\r\n- An example showing how to pre-process a raw YUV image of size HxWx1.5B to the expected shape of (H,W,3) with normalized values Y: [0,1], UV: [-0.5,0.5].\r\n- An example of how one might append this method to an RGB-trained model to enable it to accept YUV inputs during inference. A likely scenario might be exporting a frozen model to an Android device that natively captures in YUV."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://keras.io/models/model/\r\nand \r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/Model#predict\r\n\r\n## Description of issue (what needs changing):\r\nDocumentation for model predict says \"batch_size: Integer or None. Number of samples per gradient update.\", but unless I'm missing something, there are no gradient updates while predicting.\r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/compat/v1/profiler/Profiler?hl=zh-TW\r\n\r\n## Description of issue (what needs changing):\r\nThe README link for this function is 404, so there is no support for usage. The sample code is not complete either.\r\n\r\n### Clear description\r\n![image](https://user-images.githubusercontent.com/33815430/75243362-b64f8680-5804-11ea-8bf6-2888306b1a38.png)\r\nFor example\r\n```python\r\nprofiler.profile_name_scope(options=(option_builder.ProfileOptionBuilder\r\n          .trainable_variables_parameter()))\r\n```\r\nNo declarence of option_builder. It's hard for me to reproduce the result by this sample code.\r\nCould tensorflow provide new support to this function??"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n[https://www.tensorflow.org/api_docs/python/tf/keras/applications?version=nightly](https://www.tensorflow.org/api_docs/python/tf/keras/applications?version=nightly)\r\n\r\n\r\n## Description of issue (what needs changing):\r\nThe doc corresponding to these two functions must be added in each application model doc.\r\n\r\nAre you planning to also submit a pull request to fix the issue? \r\nYes, Will mention these issue soon in those PRs.\r\n"
  },
  {
    "labels": [null, null, "documentation", null],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/api_docs/python/tf/GradientTape\r\n\r\n## Description of issue (what needs changing):\r\nI have model with two head and two loss. I want to optimize my model in the way that each loss propagate separately in it's head branch. \r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "**Describe the current behavior**\r\n\r\nI haven't be able to find documentation on if SSL is used during distributed training with `tf.distribute.Strategy` with gRPC.\r\n\r\n**Describe the expected behavior**\r\n\r\nI should be able to easily find this information in the documentation, and if it's supported, then I should easily be able to turn SSL on/off in distributed training for when I prefer security vs performance."
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "I'm implementing gradient checkpointing with my Tensorflow 2.1 project, following the doc here: https://www.tensorflow.org/api_docs/python/tf/recompute_grad\r\n\r\nWhen I try\r\n```code\r\nmodel = tf.recompute_grad(model)\r\n```\r\nit fails, and likewise with \r\n```code\r\nmodel.layer = tf.recompute_grad(model.layer)\r\n```\r\n\r\nI see that Keras acts differently because tf.recompute_grad() wraps the function with an inner() call, but what should I do to get it working?"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/tutorials/customization/custom_training_walkthrough#define_the_loss_and_gradient_function\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/Sequential\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/Model\r\n## Description of issue (what needs changing):\r\nIt is unclear whether the Sequential class makes use a 'training' flag fed into it during training/inference, as the tutorial above implies. \r\n\r\n### Clear description\r\nWhen building a custom model subclassing from tf.keras.Model, the standard signature for writing the `call` is as follows: `def call(self, inputs, training=None, mask=None):`\r\n\r\nIf my class includes submodels of the form Sequential, I am able to pass this flag forward but I'm unaware whether it's doing anything, as documentation from the class doesn't mention this flag.\r\nLooking at the customization tutorial above, however, the flag is passed into a Sequential model that does not include layers whose behavior change during training/inference. So I don't know if that flag is doing anything.\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/install\r\n\r\n## Description of issue (what needs changing):\r\nCould someone instruct me how to add a new OS on the support on the \"tested and supported\" list, I would like to make some efforts for Opensuse and SLE. \r\n\r\nThere might have some steps to make sure an OS is \"tested and supported\", right?\r\n\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "\r\n## URL(s) with the issue: \r\nhttps://www.tensorflow.org/tutorials/keras/save_and_load\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe first reference to \"optimizer configuration\" is unqualified.\r\nThe second reference to \"optimizers\" is kind of qualified with \"(from tf.train)\".\r\nDoes this mean, tf.keras.optimizer states are stored but not tf.optimizer or does this mean no optimizer states are stored?\r\n\r\nfull text as follows:\r\n\r\n```\r\nThis technique saves everything:\r\n\r\n- The weight values\r\n- The model's configuration(architecture)\r\n- The optimizer configuration\r\n\r\nKeras saves models by inspecting the architecture. Currently, it is not able to save TensorFlow optimizers (from tf.train). When using those you will need to re-compile the model after loading, and you will lose the state of the optimizer.\r\n```"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "For example, in SparseCategoricalAccuracy(), the words in this API does not help to give a clear picture to understand what it is doing. Why not give a formula. A formula, associated with an example, is clear enough for this API."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "This is sort of a follow up to #33756. The TF docs have undergone huge improvements over the last couple months. However, one thing I really like about the PyTorch docs which is still (mostly) missing in the TF docs are \"**See also**\"  references.\r\n\r\nA lot of functions have similar or related functionality. Examples include:\r\n\r\n1. `tf.split`, `tf.unstack`\r\n2. `tf.size`, `tf.shape`\r\n3. `tf.repeat`, `tf.concat`, `tf.tile`, `tf.stack`\r\n4. `tf.exp`, `tf.math.log`\r\n5. `tf.keras.layers.MaxPool2D`, `tf.nn.max_pool2d `\r\n6. `tf.ones`, `tf.ones_like` and `tf.zeros`, `tf.zeros_like`\r\n\r\njust to name a few.\r\n\r\nOften people happen to find one and start using it regularly but remain unaware of the others for quite a while. Even if I do know about all of them, I often find myself wanting to compare the signature of similar functions to find the one most suitable to the current use case. In those cases, it takes way too many clicks to get from one to the other(s).\r\n\r\nIn short, would be great if the docs referenced related content. That should help guide people to use the best tool for the job right from the start."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/Tensor\r\n\r\nThe page has the breadcrumbs `TensorFlow > API > TensorFlow Core v2.1.0 > Python`.\r\n\r\n## Description of issue (what needs changing):\r\n\r\nRunning the first example on the [Tensor](https://www.tensorflow.org/api_docs/python/tf/Tensor) page results in an error.\r\n\r\n### Clear description\r\n\r\nHere is the outcome of running the first example.\r\n``` py\r\n>>> # Build a dataflow graph.\r\n... c = tf.constant([[1.0, 2.0], [3.0, 4.0]])\r\n>>> d = tf.constant([[1.0, 1.0], [0.0, 1.0]])\r\n>>> e = tf.matmul(c, d)\r\n>>> # Construct a `Session` to execute the graph.\r\n... sess = tf.compat.v1.Session()\r\n>>> # Execute the graph and store the value that `e` represents in `result`.\r\n... result = sess.run(e)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 2, in <module>\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 960, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1108, in _run\r\n    raise RuntimeError('The Session graph is empty.  Add operations to the '\r\nRuntimeError: The Session graph is empty.  Add operations to the graph before calling run().\r\n```\r\n\r\nI understand from [here](https://kodlogs.com/34085/runtimeerror-the-session-graph-is-empty-add-operations-to-the-graph-before-calling-run) that a session is no longer required in tf v2.\r\n\r\nBut the Tensor documentation starts off with multiple session references which appears to now be obsolete or not required.\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer#call\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nThis is a key function that user will implement with they custom layer. Currently it is poorly documented, especially w.r.t the execution context of eager/graph. In TF 2.0, we are advocating eager execution by default. However, the call() body in keras is executed with graph context by default unless configured otherwise. It will raise error if user try to add print/debug related to items into the call body, eg print(eager_tensor.numpy()), etc.\r\n\r\nSome related question raised in  https://github.com/tensorflow/tensorflow/issues/27519.\r\n\r\n### Correct links\r\n\r\nYes\r\n\r\n### Parameters defined\r\n\r\nYes\r\n\r\n### Returns defined\r\n\r\nYes\r\n\r\n### Raises listed and defined\r\n\r\nYes\r\n\r\n### Usage example\r\n\r\nNo\r\n\r\n### Request visuals, if applicable\r\n\r\nNo\r\n\r\n### Submit a pull request?\r\nNo\r\n"
  },
  {
    "labels": [null, null, null, null, "documentation"],
    "text": "I am using TensorFlow version 1.15 for a project. I have converted a BioBert pre-trained model into a Keras layer following the code [here](https://towardsdatascience.com/fine-tuning-bert-with-keras-and-tf-module-ed24ea91cff2). However, when I run my code, I get the following error:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/jupyter-belona/.conda/envs/mimic-proj/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/home/jupyter-belona/.conda/envs/mimic-proj/lib/python3.7/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/jupyter-belona/Untitled_Folder/deep-learning-clinical-forecast/mimic3newmodels/decompensation/main.py\", line\r\n152, in <module>\r\n    verbose=args.verbose)\r\n  File \"/home/jupyter-belona/.conda/envs/mimic-proj/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/trainin\r\ng.py\", line 1296, in fit_generator\r\n    steps_name='steps_per_epoch')\r\n  File \"/home/jupyter-belona/.conda/envs/mimic-proj/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/trainin\r\ng_generator.py\", line 144, in model_iteration\r\n    shuffle=shuffle)\r\n  File \"/home/jupyter-belona/.conda/envs/mimic-proj/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/trainin\r\ng_generator.py\", line 477, in convert_to_generator_like\r\n    **num_samples = int(nest.flatten(data)[0].shape[0])**\r\nAttributeError: 'BatchGen' object has no attribute 'shape'\r\n```\r\nPlease, how do I fix this error? I really need your help."
  },
  {
    "labels": [null, "documentation", null],
    "text": "when I used the tensorflow-gpu=2.1.0 to run in keras-python3.6 env, it said:\r\n\r\nUsing TensorFlow backend.\r\n2020-02-13 21:47:27.592762: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll\r\nWARNING:tensorflow:From D:\\Anaconda3\\envs\\keras36\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nnon-resource variables are not supported in the long term\r\nTraceback (most recent call last):\r\n  File \"i:/Git_Lip/XWLip_lite/DC_kares_LipReading_P70_R18/code/network.py\", line 574, in <module>\r\n    models=Lip_net(**params)\r\n  File \"i:/Git_Lip/XWLip_lite/DC_kares_LipReading_P70_R18/code/network.py\", line 367, in Lip_net\r\n    input_data = Input(name='the_input', shape=(24,112,112,3), dtype='float32')\r\n  File \"D:\\Anaconda3\\envs\\keras36\\lib\\site-packages\\keras\\engine\\input_layer.py\", line 178, in Input\r\n    input_tensor=tensor)\r\n  File \"D:\\Anaconda3\\envs\\keras36\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"D:\\Anaconda3\\envs\\keras36\\lib\\site-packages\\keras\\engine\\input_layer.py\", line 87, in __init__\r\n    name=self.name)\r\n  File \"D:\\Anaconda3\\envs\\keras36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 517, in placeholder\r\n    x = tf.placeholder(dtype, shape=shape, name=name)\r\nAttributeError: module 'tensorflow' has no attribute 'placeholder'\r\n\r\nhow can I  sovle the problem?Thanks for replying."
  },
  {
    "labels": ["documentation", null],
    "text": "\r\nHere are the instructions and at the bottom is exp-11's script. I have no idea what to do. VERY new to programming.. thank you ahead of time!\r\n\r\nUsing the Exp-11.py script provide as a baseline your assignment is as follows:\r\n\r\n1) Allow the user to enter a path\r\n\r\n2) Using that path, process all the .jpg files contained in that folder  (note you will need to create a directory with jpg images)\r\n\r\n3) Extract, EXIF data from each of the images and create a pretty table output.  Note, you will go beyond the basics and extract whatever camera or photo data exists for each photo.\r\n\r\n4) Plot the geolocation of each image on a map. \r\n\r\n(Note, there are several ways to do this)  However, the easiest method would be to use MapMaker App, at https://mapmakerapp.com/\r\nyou can either manually enter the lat/long values your code generates or you can place your results in a CSV file and upload the data to the map.   \r\nNOTE, this is a manual step process\r\n\r\n5) Submit both your script and a screenshot of the results.\r\n\r\n\r\n\r\n\r\n\r\n'''\r\nEXIF Data Acquistion\r\nJanuary 2019\r\nVersion 1.1\r\n'''\r\nfrom __future__ import print_function\r\n\r\n'''\r\nCopyright (c) 2019 Chet Hosmer, Python Forensics\r\n\r\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software\r\nand associated documentation files (the \"Software\"), to deal in the Software without restriction, \r\nincluding without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, \r\nand/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, \r\nsubject to the following conditions:\r\n\r\nThe above copyright notice and this permission notice shall be included in all copies or substantial \r\nportions of the Software.\r\n\r\n'''\r\n# Usage Example:\r\n# python Exp-11.py \r\n#\r\n# Requirement: Python 2.x or 3.x\r\n#\r\n# Requirement: 3rd Party Library that is utilized is: PILLOW\r\n#                   pip install PILLOW  from the command line\r\n\r\n\r\n''' LIBRARY IMPORT SECTION '''\r\n\r\nimport os                       # Python Standard Library : Operating System Methods\r\nimport sys                      # Python Standard Library : System Methods\r\nfrom datetime import datetime   # Python Standard Libary datetime method from Standard Library\r\n\r\n# import the Python Image Library \r\n# along with TAGS and GPS related TAGS\r\n# Note you must install the PILLOW Module\r\n# pip install PILLOW\r\n\r\nfrom PIL import Image\r\nfrom PIL.ExifTags import TAGS, GPSTAGS\r\n\r\n\r\n# import the prettytable library\r\nfrom prettytable import PrettyTable\r\n\r\ndef ExtractGPSDictionary(fileName):\r\n    ''' Function to Extract GPS Dictionary '''\r\n    try:\r\n        pilImage = Image.open(fileName)\r\n        exifData = pilImage._getexif()\r\n\r\n    except Exception:\r\n        # If exception occurs from PIL processing\r\n        # Report the \r\n        return None, None\r\n\r\n    # Interate through the exifData\r\n    # Searching for GPS Tags\r\n\r\n    imageTimeStamp = \"NA\"\r\n    cameraModel = \"NA\"\r\n    cameraMake = \"NA\"\r\n    gpsData = False\r\n\r\n    gpsDictionary = {}\r\n\r\n    if exifData:\r\n\r\n        for tag, theValue in exifData.items():\r\n\r\n            # obtain the tag\r\n            tagValue = TAGS.get(tag, tag)\r\n\r\n            # Collect basic image data if available\r\n\r\n            if tagValue == 'DateTimeOriginal':\r\n                imageTimeStamp = exifData.get(tag).strip()\r\n\r\n            if tagValue == \"Make\":\r\n                cameraMake = exifData.get(tag).strip()\r\n\r\n            if tagValue == 'Model':\r\n                cameraModel = exifData.get(tag).strip()\r\n\r\n            # check the tag for GPS\r\n            if tagValue == \"GPSInfo\":\r\n\r\n                gpsData = True;\r\n\r\n                # Found it !\r\n                # Now create a Dictionary to hold the GPS Data\r\n\r\n                # Loop through the GPS Information\r\n                for curTag in theValue:\r\n                    gpsTag = GPSTAGS.get(curTag, curTag)\r\n                    gpsDictionary[gpsTag] = theValue[curTag]\r\n\r\n        basicExifData = [imageTimeStamp, cameraMake, cameraModel]    \r\n\r\n        return gpsDictionary, basicExifData\r\n\r\n    else:\r\n        return None, None\r\n\r\n# End ExtractGPSDictionary ============================\r\n\r\n\r\ndef ExtractLatLon(gps):\r\n    ''' Function to Extract Lattitude and Longitude Values '''\r\n\r\n    # to perform the calcuation we need at least\r\n    # lat, lon, latRef and lonRef\r\n    \r\n    try:\r\n        latitude     = gps[\"GPSLatitude\"]\r\n        latitudeRef  = gps[\"GPSLatitudeRef\"]\r\n        longitude    = gps[\"GPSLongitude\"]\r\n        longitudeRef = gps[\"GPSLongitudeRef\"]\r\n\r\n        lat = ConvertToDegrees(latitude)\r\n        lon = ConvertToDegrees(longitude)\r\n\r\n        # Check Latitude Reference\r\n        # If South of the Equator then lat value is negative\r\n\r\n        if latitudeRef == \"S\":\r\n            lat = 0 - lat\r\n\r\n        # Check Longitude Reference\r\n        # If West of the Prime Meridian in \r\n        # Greenwich then the Longitude value is negative\r\n\r\n        if longitudeRef == \"W\":\r\n            lon = 0- lon\r\n\r\n        gpsCoor = {\"Lat\": lat, \"LatRef\":latitudeRef, \"Lon\": lon, \"LonRef\": longitudeRef}\r\n\r\n        return gpsCoor\r\n\r\n    except:\r\n        return None\r\n\r\n# End Extract Lat Lon ==============================================\r\n\r\n\r\ndef ConvertToDegrees(gpsCoordinate):\r\n    ''' Function to CONVERT GPS COORIDINATES TO DEGRESS '''\r\n    d0 = gpsCoordinate[0][0]\r\n    d1 = gpsCoordinate[0][1]\r\n    try:\r\n        degrees = float(d0) / float(d1)\r\n    except:\r\n        degrees = 0.0\r\n\r\n    m0 = gpsCoordinate[1][0]\r\n    m1 = gpsCoordinate[1][1]\r\n    try:\r\n        minutes = float(m0) / float(m1)\r\n    except:\r\n        minutes=0.0\r\n\r\n    s0 = gpsCoordinate[2][0]\r\n    s1 = gpsCoordinate[2][1]\r\n    try:\r\n        seconds = float(s0) / float(s1)\r\n    except:\r\n        seconds = 0.0\r\n\r\n    floatCoordinate = float (degrees + (minutes / 60.0) + (seconds / 3600.0))\r\n\r\n    return floatCoordinate\r\n\r\n''' MAIN PROGRAM ENTRY SECTION '''\r\n\r\nif __name__ == \"__main__\":\r\n    '''\r\n    pyExif Main Entry Point\r\n    '''\r\n    print(\"\\nExtract EXIF Data from JPEG Files\")\r\n\r\n    print(\"Script Started\", str(datetime.now()))\r\n    print()\r\n\r\n    ''' PROCESS EACH JPEG FILE SECTION '''\r\n\r\n    latLonList = []\r\n    targetFile = \"test.jpg\"                 # file must be located in the same folder\r\n    if os.path.isfile(targetFile):\r\n        gpsDictionary, exifList = ExtractGPSDictionary(targetFile)\r\n            \r\n        if exifList:\r\n            TS = exifList[0]\r\n            MAKE = exifList[1]\r\n            MODEL = exifList[2]\r\n        else:\r\n            TS = 'NA'\r\n            MAKE = 'NA'\r\n            MODEL = 'NA'\r\n\r\n        print(\"Photo Details\")\r\n        print(\"-------------\")\r\n        print(\"TimeStamp:    \", TS)\r\n        print(\"Camera Make:  \", MAKE)\r\n        print(\"Camera Model: \", MODEL)\r\n        \r\n        if (gpsDictionary != None):\r\n\r\n            # Obtain the Lat Lon values from the gpsDictionary\r\n            # Converted to degrees\r\n            # The return value is a dictionary key value pairs\r\n\r\n            dCoor = ExtractLatLon(gpsDictionary)\r\n\r\n            print(\"\\nGeo-Location Data\")\r\n            print(\"-----------------\")\r\n\r\n            if dCoor:\r\n                lat = dCoor.get(\"Lat\")\r\n                latRef = dCoor.get(\"LatRef\")\r\n                lon = dCoor.get(\"Lon\")\r\n                lonRef = dCoor.get(\"LonRef\")\r\n                \r\n                if ( lat and lon and latRef and lonRef):\r\n                    print(\"Lattitude: \", '{:4.4f}'.format(lat))\r\n                    print(\"Longitude: \", '{:4.4f}'.format(lon))\r\n                else:\r\n                    print(\"WARNING No GPS EXIF Data\")\r\n            else:\r\n                print(\"WARNING No GPS EXIF Data\")                    \r\n        else:\r\n            print(\"WARNING\", \" not a valid file\", targetFile)\r\n\r\n    # Create Result Table Display using PrettyTable\r\n    ''' GENERATE RESULTS TABLE SECTION'''\r\n\r\n    ''' Result Table Heading'''\r\n    resultTable = PrettyTable(['File-Name', 'Lat','Lon', 'TimeStamp', 'Make', 'Model'])\r\n    ''' Your work starts here '''\r\n    \r\n    print()"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "It is a documentation issue, but embedded in the code. This seems most appropriate issue template.\r\n\r\n## URL(s) with the issue:\r\nhttps://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/layers/dense_attention.py#L187-L313\r\n\r\n## Description of issue (what needs changing):\r\nThere is an error in the provided example (L236 - 276):\r\n\r\nHere is a code example for using `Attention` in a CNN+Attention network:\r\n  ```python\r\n  value_input = tf.keras.Input(shape=(None,), dtype='int32')\r\n  value_embeddings = token_embedding(query_input)\r\n  ```\r\n\r\nThis last one should be ```value_embeddings = token_embedding(value_input)```\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\nhttps://github.com/tensorflow/tensorflow/blob/r0.8/tensorflow/examples/tutorials/mnist/mnist_with_summaries.py\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\nthe spelling of placeholder is incorrect in line 53\r\n\r\n### Clear description\r\nthe spelling in placehoolder and should be placeholder\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nMaybe.. If you accept the request \r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue \r\n\r\nhttps://www.tensorflow.org/install?hl=ko\r\n\r\n## Description of issue (what needs changing)\r\n\r\nOn installation document/windows build from source page, it tells that \"TensorFlow를 컴파일하는 데 사용되는 빌드 도구인 Bazel 0.23.0을 설치합니다. C++를 빌드하도록 Bazel을 설정합니다.\" which means install Bazel 0.23.0 to compile Tensorflow. However, most recent version of Tensorflow which is r2.1, doesn't support Bazel 0.23.0. Instead, it uses 0.27.0~0.29.0. I checked English document and it tells me the version of Bazel that is needed. So, I think the Korean page should be renewed.\r\n\r\n\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "I used `tf.saved_model.save` and `tf.saved_model.load` to save and load TF2 SavedModel. According to [this link][1], I created a signature and this signature is `serving_default`. Then I try to add a new function with the signature decorator in class `Adder`. But after I loaded the model according to [this][2], I find that the signatures disappear in the model, i.e., `print(adder1.signatures)` prints no signature names. I don't find any information about how to use multiple signatures while saving models. So I think this may be a bug. If it is not, can anyone tell me how can I use multiple signatures in one model? Thank you very much. \r\n\r\nTensorflow `2.1.0`, on Google Colab. The code looks like this: \r\n\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow_hub as hub\r\nimport numpy as np\r\nimport os\r\nimport pandas as pd\r\n\r\nclass Adder(tf.Module):\r\n\r\n  @tf.function(input_signature=[tf.TensorSpec(shape=None, dtype=tf.float32), tf.TensorSpec(shape=None, dtype=tf.float32)])# \r\n  def add(self, x, y):\r\n    return x + y ** 2 + 1\r\n  \r\n  @tf.function(input_signature=[tf.TensorSpec(shape=None, dtype=tf.float32)])\r\n  def square(self, x):\r\n    return x ** 2\r\n\r\nto_export = Adder()\r\ntf.saved_model.save(\r\n    to_export, \r\n    '/tmp/adder'            \r\n)\r\n\r\nadder1 = tf.saved_model.load(\"/tmp/adder\")\r\nprint(adder1.signatures)\r\nadder1_sig = adder1.signatures[\"serving_default\"]\r\nadder1_sig(x = tf.constant(1.), y = tf.constant(2.))\r\n```\r\n\r\n\r\n  [1]: https://www.tensorflow.org/api_docs/python/tf/saved_model/save#used-in-the-notebooks\r\n  [2]: https://www.tensorflow.org/api_docs/python/tf/saved_model/load"
  },
  {
    "labels": ["documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/tutorials/text/text_generation#the_prediction_loop\r\n\r\n## Description of issue (what needs changing):\r\nConsider the previously generated letters for subsequent generations. Right now only the lastly generated letter is considered to generate the immediate next letter. The result reads very far from natural as you can imagine.\r\n\r\n### Clear description\r\n\r\nThe `generate_text()` method is supposed to generate text, letter by letter, by taking into account a starting string and any letter that has been generated so far. Right now, it's generating the first letter by taking into account the starting string, then from then on, it only considers the last generated letter. \r\n\r\nSo in this:\r\n```\r\ndef generate_text(model, start_string):\r\n  # Evaluation step (generating text using the learned model)\r\n\r\n  # Number of characters to generate\r\n  num_generate = 1000\r\n\r\n  # Converting our start string to numbers (vectorizing)\r\n  input_eval = [char2idx[s] for s in start_string]\r\n  input_eval = tf.expand_dims(input_eval, 0)\r\n\r\n  # Empty string to store our results\r\n  text_generated = []\r\n\r\n  # Low temperatures results in more predictable text.\r\n  # Higher temperatures results in more surprising text.\r\n  # Experiment to find the best setting.\r\n  temperature = 1.0\r\n\r\n  # Here batch size == 1\r\n  model.reset_states()\r\n  for i in range(num_generate):\r\n      predictions = model(input_eval)\r\n      # remove the batch dimension\r\n      predictions = tf.squeeze(predictions, 0)\r\n\r\n      # using a categorical distribution to predict the character returned by the model\r\n      predictions = predictions / temperature\r\n      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\r\n\r\n      # We pass the predicted character as the next input to the model\r\n      # along with the previous hidden state\r\n      input_eval = tf.expand_dims([predicted_id], 0)\r\n\r\n      text_generated.append(idx2char[predicted_id])\r\n\r\n  return (start_string + ''.join(text_generated))\r\n```\r\n\r\nThe end of the for-loop needs to be updated to match the comment description, with something like this:\r\n```\r\n# We pass the predicted character as the next input to the model\r\n# along with the previous hidden state\r\ninput_eval = tf.concat([input_eval, tf.expand_dims([predicted_id], 0)], -1)\r\n```\r\nWhere we add the newly predicted ID to the end of what is currently `input_eval`\r\n\r\n### Submit a pull request?\r\n\r\nI plan on submitting a pull request with the quick fix.\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\n[Software requirements](https://www.tensorflow.org/install/gpu#software_requirements)\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe requirement may lack the dependency of [Microsoft Visual C++ Redistributable for Visual Studio](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads) runtime.\r\n\r\n### Clear description\r\n\r\nAfter installation, TF raises an error with `ImportError: DLL load failed: The specified module could not be found.`\r\n\r\nFixed after installing [Microsoft Visual C++ Redistributable for Visual Studio 2015, 2017 and 2019](https://aka.ms/vs/16/release/vc_redist.x64.exe) via [error page](https://www.tensorflow.org/install/errors) and issue https://github.com/tensorflow/tensorflow/issues/22794 & https://github.com/tensorflow/tensorflow/issues/22512\r\n\r\nWanna confirm whether Microsoft Visual C++ Redistributable for Visual Studio must be installed and its version. If true, please add this information to [software requirements](https://www.tensorflow.org/install/gpu#software_requirements).\r\n\r\n### Submit a pull request?\r\n\r\nIf confirmation, I can PR to [tensorflow/docs](https://github.com/tensorflow/docs/blob/master/site/en/install/gpu.md).\r\n\r\n---\r\nPS.. here comes system info to trace that issue.\r\nHardware:\r\n```\r\nProcessor: Intel(R) Core(TM) i7-7500U CPU @ 2.70GHz (4 CPUs), ~2.9GHz\r\nMemory: 16384MB RAM\r\nCard name: NVIDIA GeForce 940MX\r\nManufacturer: NVIDIA\r\nChip type: GeForce 940MX\r\n```\r\nSoftware:\r\n```\r\nOperating System: Windows 10 Pro 64-bit (10.0, Build 18363) (18362.19h1_release.190318-1202) \r\n(conda)TensorFlow: 2.1.0 (install via pypi)\r\n(conda)cudatoolkit: 10.1.243 (install via anaconda)\r\n(conda)cudnn: 7.6.5 (install via anaconda)\r\nNvidia Driver Version: 441.87\r\n```\r\nIt can be reproduced in `conda install` or `native install`.\r\n\r\nHope those info helps.\r\n\r\nThanks in advance! :-)"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://github.com/tensorflow/tensorflow/blob/cf7fcf164c9846502b21cebb7d3d5ccf6cb626e8/tensorflow/python/ops/signal/shape_ops.py#L55-L199\r\n\r\nDocumentation:\r\nhttps://www.tensorflow.org/api_docs/python/tf/signal/frame\r\n\r\n## Description of issue (what needs changing):\r\n\r\nIn the following example, the count of frames generated with pad_end=False is incorrect\r\n    \r\n    # A batch size 3 tensor of 9152 audio samples.\r\n    audio = tf.random.normal([3, 9152])\r\n\r\n    # Compute overlapping frames of length 512 with a step of 180 (frames overlap\r\n    # by 332 samples). By default, only 50 frames are generated since the last\r\n    # 152 samples do not form a full frame.\r\n    frames = tf.signal.frame(audio, 512, 180)\r\n    frames.shape.assert_is_compatible_with([3, 50, 512])\r\n\r\nIn fact, only 49 frames are generated with pad_true=False (the default).\r\n\r\n### Clear description\r\n\r\nSuppose we are given a tensor x with x.shape[-1] == N, a frame_length == K, and a frame_step == k.\r\n\r\nTo compute tf.signal.frame(x, frame_length, frame_step) (here default axis=-1 and pad_end=False), we could equivalently stack along axis -2 the following list of slices:\r\n\r\n    [x[..., 0:K],\r\n     x[..., k:K+k],\r\n     x[..., 2*k:K+2*k],\r\n     x[..., 3*k:K+3*k],\r\n     ...\r\n     x[..., j*k:K+j*k]]\r\n\r\nwhere j is the maximum integer such that K+j*k <= N.\r\n\r\nWe can compute that j = (N - K) // k, so the number of slices in this list is j+1 = 1 + (N - K) // k. \r\n\r\nIn the example here, N = 9152, K=512, k=180, so:\r\n\r\n    j+1 = 1 + (9152-512) // 180 = 1 + 8640 // 180 = 1+48 = 49\r\n\r\nThus in the example given, the return shape should be [3, 49, 512], not [3, 50, 512]. Attached is a screenshot showing that this is indeed the behavior of tf.signal.frame, so it is an error in the documentation not in the code.\r\n\r\n![tf signal frame](https://user-images.githubusercontent.com/47697814/74045729-497e6480-499b-11ea-9107-12305554ee18.png)\r\n\r\n### Submit a pull request?\r\n\r\nI am planning to submit a pull request."
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "\r\nThe documentation for pre-made estimators such as tensorflow.estimator.LinearRegressor says that each of the methods evaluate, predict and train take a parameter called \"hooks\", which is a list of tensorflow.train.SessionRunHooks. However, no such class exist in the v2.1 API; instead, the source code says that it expects instances of tensorflow.compat.v1.train.SessionRunHook.\r\n\r\nIn the example of LinearRegressor (other pre-made estimators share the same problem), this is the API doc, which I believe is generated directly from the source code (see the documentation of the parameters for the train, evaluate and predict methods):\r\nhttps://www.tensorflow.org/api_docs/python/tf/estimator/LinearRegressor#evaluate\r\nhttps://www.tensorflow.org/api_docs/python/tf/estimator/LinearRegressor#predict\r\nhttps://www.tensorflow.org/api_docs/python/tf/estimator/LinearRegressor#train\r\n\r\nThis is the source code that says it expects a class from the compat.v1 API:\r\nhttps://github.com/tensorflow/estimator/blob/a7ba3b45d07dd517a0e6ff38e90ae3aa240f424b/tensorflow_estimator/python/estimator/estimator.py#L1947\r\n\r\n\r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/guide/migrate#saved_models_compatibility\r\n\r\n## Description of issue (what needs changing):\r\nThe sentence below is unclear in what it means. I think there might be an extra word.\r\n\r\n\"TensorFlow 2.0 saved_models even load work in TensorFlow 1.x if all the ops are supported.\"\r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nNumerous links of the older TF APIs, listing only a few index pages as examples here:\r\n\r\n- Links under \"Classes\" and \"Functions\" within https://github.com/tensorflow/docs/blob/r1.11/site/en/api_docs/python/tf.md\r\n- Links under \"Classes\" and \"Functions\" within https://github.com/tensorflow/docs/blob/r1.11/site/en/api_docs/python/tfdbg.md\r\n- Links within https://github.com/tensorflow/docs/blob/r1.5/site/en/api_docs/python/index.md\r\n- \"JAVA\" link within https://github.com/tensorflow/docs/blob/r1.7/site/en/api_docs/index.md\r\n\r\n## Description of issue (what needs changing):\r\n\r\nA large amount of links on index pages (e.g. for functions and classes) are currently broken (404). This appears to affect only the older TF versions (multiple versions affected), whose index pages are Markdown files within Github repositories.\r\n\r\n### Clear description\r\n\r\nOutbound links from these indexing pages are currently broken. Some might be fixed by adding a .md after the current URL to point to the correct Markdown available in the repositories, but not all of them can be fixed through this way.\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n- Incorrect.\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue?\r\n- Currently no plan.\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\n[`tf.keras.optimizers.Optimizer`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Optimizer), specifically the section [Write a customized optimizer](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Optimizer#write_a_customized_optimizer_2).\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe instructions for creating a custom optimizer seem to be inconsistent with how `tf.keras.optimizers.Optimizer` subclasses are defined in TensorFlow and other projects.\r\n\r\n### Clear description\r\n\r\nThis originated as a [question on Stack Overflow](https://stackoverflow.com/q/58772846/1917160), which is reproduced below.\r\n\r\nSuppose I want to write a custom optimizer class that conforms to the `tf.keras` API (using TensorFlow version>=2.0). I am confused about the documented way to do this versus what's done in implementations.\r\n\r\nThe documentation for `tf.keras.optimizers.Optimizer` states,\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/7b1283ecf14e5f057b1a5c321a46db907ea713fc/tensorflow/python/keras/optimizer_v2/optimizer_v2.py#L217-L224\r\n\r\nHowever, the current `tf.keras.optimizers.Optimizer` implementation does not define a `resource_apply_dense` method, but it *does* define a private-looking [`_resource_apply_dense` method stub](https://github.com/tensorflow/tensorflow/blob/7b1283ecf14e5f057b1a5c321a46db907ea713fc/tensorflow/python/keras/optimizer_v2/optimizer_v2.py#L916-L928). Similarly, there are no `resource_apply_sparse` or `create_slots` methods, but there are a [`_resource_apply_sparse` method stub](https://github.com/tensorflow/tensorflow/blob/7b1283ecf14e5f057b1a5c321a46db907ea713fc/tensorflow/python/keras/optimizer_v2/optimizer_v2.py#L958-L977) and a [`_create_slots` method call](https://github.com/tensorflow/tensorflow/blob/7b1283ecf14e5f057b1a5c321a46db907ea713fc/tensorflow/python/keras/optimizer_v2/optimizer_v2.py#L434).\r\n\r\nIn official `tf.keras.optimizers.Optimizer` subclasses (using `tf.keras.optimizers.Adam` as an example), there are [`_resource_apply_dense`](https://github.com/tensorflow/tensorflow/blob/7b1283ecf14e5f057b1a5c321a46db907ea713fc/tensorflow/python/keras/optimizer_v2/adam.py#L192-L227), [`_resource_apply_sparse`](https://github.com/tensorflow/tensorflow/blob/7b1283ecf14e5f057b1a5c321a46db907ea713fc/tensorflow/python/keras/optimizer_v2/adam.py#L229-L267), and [`_create_slots`](https://github.com/tensorflow/tensorflow/blob/7b1283ecf14e5f057b1a5c321a46db907ea713fc/tensorflow/python/keras/optimizer_v2/adam.py#L150-L159) methods, and there are no such methods without the leading underscore.\r\n\r\nThere are similar leading-underscore methods in slightly-less-official `tf.keras.optimizers.Optimizer` subclasses (e.g., `tfa.optimizers.MovingAverage` from TensorFlow Addons: [`_resource_apply_dense`](https://github.com/tensorflow/addons/blob/999aebc0961ccddb8174cc5331cc23a7291a2255/tensorflow_addons/optimizers/average_wrapper.py#L73-L76), [`_resource_apply_sparse`](https://github.com/tensorflow/addons/blob/999aebc0961ccddb8174cc5331cc23a7291a2255/tensorflow_addons/optimizers/average_wrapper.py#L78-L82), [`_create_slots`](https://github.com/tensorflow/addons/blob/999aebc0961ccddb8174cc5331cc23a7291a2255/tensorflow_addons/optimizers/moving_average.py#L92-L95)).\r\n\r\nAnother confounding point for me is that some of the TensorFlow Addons optimizers *also* override the `apply_gradients` method (e.g., [`tfa.optimizers.MovingAverage`](https://github.com/tensorflow/addons/blob/999aebc0961ccddb8174cc5331cc23a7291a2255/tensorflow_addons/optimizers/average_wrapper.py#L55-L57)), whereas the `tf.keras.optimizers` optimizers do not.\r\n\r\nMoreover, I noticed that the `apply_gradients` method of `tf.keras.optimizers.Optimizer` method calls `_create_slots`, but the base `tf.keras.optimizers.Optimizer` class does not have a `_create_slots` method. So, it seems that a `_create_slots` method *must* be defined in an optimizer subclass if that subclass does not override `apply_gradients`.\r\n\r\n#### Questions\r\n\r\nWhat is the correct way to subclass a `tf.keras.optimizers.Optimizer`? Specifically,\r\n\r\n1. Does the `tf.keras.optimizers.Optimizer` documentation listed at the top simply mean to override the leading-underscore versions of the methods they mention (e.g., `_resource_apply_dense` instead of `resource_apply_dense`)? If so, are there any API guarantees about these private-looking methods not changing their behavior in future versions of TensorFlow? What are the signatures of these methods?\r\n2. When would one override `apply_gradients` in addition to the `_apply_resource_[dense|sparse]` methods?"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/tutorials/load_data/csv\r\n\r\nwhich is available on GitHub at\r\n\r\nhttps://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb\r\n\r\n## Description of issue:\r\n\r\nThis is about the output of the last cell in the section _Categorical data_, namely the output of `print(categorical_layer(example_batch).numpy()[0])`. If we remove the index `[0]`, we're supposed to get the one-hot encoding of the categorical features, i.e., a 5-by-20 matrix, where 5 is the batch size and 20 is the total dimensionality of all categorical features.\r\n\r\nIf, for the sake of reproducibility, we also set `shuffle=False` in the call to `tf.data.experimental.make_csv_dataset()` at the very top of the notebook, the matrix we then get is:\r\n\r\n```\r\n[[0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\r\n [0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.]\r\n [1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\r\n [0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\r\n [1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]]\r\n```\r\n\r\nThis does not match up with the input categorical features for that batch, namely\r\n\r\n```\r\nsex: [b'male' b'female' b'female' b'female' b'male']\r\nclass: [b'Third' b'First' b'Third' b'First' b'Third']\r\ndeck: [b'unknown' b'C' b'unknown' b'C' b'unknown']\r\nembark_town: [b'Southampton' b'Cherbourg' b'Southampton' b'Southampton' b'Queenstown']\r\nalone: [b'n' b'n' b'y' b'n' b'y']\r\n```\r\n\r\nFor example, `[b'male' b'female' b'female' b'female' b'male']` does not match up with the first two columns of the matrix."
  },
  {
    "labels": ["documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "```\r\ntf-version 2.1.0\r\nkeras-version 2.2.4-tf\r\n```\r\n\r\nIn Keras, according to [the documentation](https://keras.io/layers/core/), we expect:\r\n\r\n```python\r\nmodel.add(Reshape((-1, 2, 2)))\r\n# now: model.output_shape == (None, 3, 2, 2)\r\n```\r\n\r\nBut in tf.Keras [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Reshape):\r\n\r\n```python\r\nmodel.add(Reshape((-1, 2, 2)))\r\n# now: model.output_shape == (None, None, 2, 2)\r\n```\r\n\r\nThe second dimension is now `None` instead of the computed value.\r\n\r\nThis makes tf.Keras incompatible with Keras, and makes it harder to write code that is parameterized by of the output shape of an opaque model. Is there a way to get the true output shape?"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/install/source?hl=en\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nIt's said that tensorflow 2.1.0 is built by bazel 0.26.1, but when I use bazel 0.26.1 to build, I get the following error:\r\n```\r\nPlease upgrade your bazel installation to version 0.27.1 or higher to build TensorFlow!\r\n```\r\n\r\nSo, what is the correct bazel version?"
  },
  {
    "labels": [null, null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback\r\n\r\n## Description of issue (what needs changing):\r\n\r\nCurrently, the page https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback says `validation_data: Deprecated. Do not use.`, but if I attempt to access the attribute `validation_data` inside the callback I get the error `AttributeError: 'MyCustomCallbackClass' object has no attribute 'validation_data'.`. You should change the documentation to remove the attribute `validation_data`, which apparently was removed.\r\n\r\nSee also this issue https://github.com/tensorflow/tensorflow/issues/27318."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "**System information**\r\n- OS Platform and Distribution: Linux\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): [binary](https://pypi.org/project/tensorflow/1.15.2/#files)\r\n- TensorFlow version: 1.15.2\r\n- Python version: python2, python3.6\r\n- Installed using virtualenv? pip? conda?: pip\r\n\r\n\r\n**Describe the problem**\r\n\r\nAs [announced](https://groups.google.com/a/tensorflow.org/forum/#!topic/developers/iRCt5m4qUz0) Tensorflow 1.15 contained GPU support by default. Tensorflow 1.15.2 no longer has GPU support.\r\n"
  },
  {
    "labels": [null, null, null, null, "documentation"],
    "text": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution: Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): terminal\r\n- TensorFlow version: tensorflow                         2.1.0              \r\n                                   tensorflow-estimator               2.1.0\r\n- Python version: 3.6.7\r\n\r\n\r\n\r\n\r\n**Describe the problem**\r\nam done by following steps in this link https://www.tensorflow.org/tensorboard/get_started  but it gives an error message like that \r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\ntensorboard --logdir logs/fit\r\n\r\n\r\n**Any other info / logs**\r\n2020-01-29 15:42:56.124384: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\r\n2020-01-29 15:42:56.124520: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\r\n2020-01-29 15:42:56.124541: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\r\nTraceback (most recent call last):\r\n  File \"/home/kuppa/anaconda3/bin/tensorboard\", line 8, in <module>\r\n    sys.exit(run_main())\r\n  File \"/home/kuppa/anaconda3/lib/python3.6/site-packages/tensorboard/main.py\", line 59, in run_main\r\n    default.get_plugins() + default.get_dynamic_plugins(),\r\n  File \"/home/kuppa/anaconda3/lib/python3.6/site-packages/tensorboard/default.py\", line 115, in get_dynamic_plugins\r\n    for entry_point in pkg_resources.iter_entry_points('tensorboard_plugins')\r\n  File \"/home/kuppa/anaconda3/lib/python3.6/site-packages/tensorboard/default.py\", line 115, in <listcomp>\r\n    for entry_point in pkg_resources.iter_entry_points('tensorboard_plugins')\r\n  File \"/home/kuppa/anaconda3/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 2443, in load\r\n    self.require(*args, **kwargs)\r\n  File \"/home/kuppa/anaconda3/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 2466, in require\r\n    items = working_set.resolve(reqs, env, installer, extras=self.extras)\r\n  File \"/home/kuppa/anaconda3/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 792, in resolve\r\n    raise VersionConflict(dist, req).with_context(dependent_req)\r\npkg_resources.VersionConflict: (grpcio 1.16.1 (/home/kuppa/anaconda3/lib/python3.6/site-packages), Requirement.parse('grpcio>=1.24.3'))"
  },
  {
    "labels": [null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD#apply_gradients\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nThe formatting in the \"References\" section is wrong; there is a ``nesterov = True,`` that has nothing to do with the reference."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Not sure if this is a documentation issue or a functional bug. \r\n\r\n## Description of issue:\r\nThe layer names in 'tf.keras.applications' are not consistent with the layer names in 'keras.applications'.\r\n\r\n## Example:\r\n`keras.applications.resnet50.ResNet50(weights='imagenet').summary()` prints the following layers:\r\n\r\n> (...)\r\n> __________________________________________________________________________________________________\r\n> **conv1_pad** (ZeroPadding2D)       (None, 230, 230, 3)  0           input_3[0][0]                    \r\n> __________________________________________________________________________________________________\r\n> **conv1** (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \r\n> __________________________________________________________________________________________________\r\n> **bn_conv1** (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \r\n> __________________________________________________________________________________________________\r\n> **activation_50** (Activation)      (None, 112, 112, 64) 0           bn_conv1[0][0]                   \r\n> __________________________________________________________________________________________________\r\n> **pool1_pad** (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_50[0][0]              \r\n> __________________________________________________________________________________________________\r\n> (...)\r\n\r\n                           \r\n`tf.keras.applications.resnet50.ResNet50(weights='imagenet').summary()` prints the following layers:\r\n\r\n> (...)\r\n> __________________________________________________________________________________________________\r\n> **conv1_pad** (ZeroPadding2D)       (None, 230, 230, 3)  0           input_6[0][0]                    \r\n> __________________________________________________________________________________________________\r\n> **conv1_conv** (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \r\n> __________________________________________________________________________________________________\r\n> **conv1_bn** (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \r\n> __________________________________________________________________________________________________\r\n> **conv1_relu** (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \r\n> __________________________________________________________________________________________________\r\n> **pool1_pad** (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \r\n> __________________________________________________________________________________________________\r\n> (...)\r\n\r\nThis can lead to errors if code relying on layer names is migrated from `keras` to `tf.keras`. Even after looking for it for quite a bit, I have not found any documentation explaining the change of layer names. Also, I manually needed to map `keras `layer names to `tf.keras` layer names, which would be avoidable with some nice documentation.\r\n\r\n## URL(s) with the issue:\r\nProbably this should be mentioned in the migration docs or the applications docs.\r\nhttps://www.tensorflow.org/guide/migrate#a_note_on_slim_contriblayers\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/applications\r\n\r\n\r\n## Usage example\r\n\r\nThe following code snippet runs when applications is imported from `keras `but not with `tf.keras`, as the layer is not found.\r\n\r\n```\r\nloaded_model = applications.ResNet50(weights='imagenet')\r\n\r\npartial_model = Model(inputs=loaded_model.input, outputs=loaded_model.get_layer('res5c_branch2c').output)\r\n```\r\n\r\nSome easily findable documentation should be explaining why the layer is not found (renamed layer names) and where to find the mapping from `keras` layer names to `tf.keras` layer names (i.e., the mapping from `res5c_branch2c ` to `conv5_block3_3_conv`, which is the layer name used in tf.keras).\r\n\r\n## Used versions in these examples\r\ntensorflow 2.1.0\r\nKeras 2.3.1\r\n\r\n## Final Remark\r\nI'm not sure if renaming the layers was that useful... While the tf.keras layer names might be better readable, papers and tutorials often refer to the keras label names - and users now seem to have to find a mapping themself. \r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/lite/\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThis button \r\n![image](https://user-images.githubusercontent.com/2697890/73086114-09ba7600-3ee1-11ea-9b27-1f75816b4e94.png)\r\n\r\nlinks to 403 page\r\n![image](https://user-images.githubusercontent.com/2697890/73086137-1a6aec00-3ee1-11ea-9fa1-0ace2995a872.png)"
  },
  {
    "labels": ["documentation"],
    "text": "https://www.tensorflow.org/tutorials/images/classification\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nThere's a bug in code\r\n\r\n`history = model.fit_generator(\r\n    train_data_gen,\r\n    steps_per_epoch=total_train // batch_size,\r\n    epochs=epochs,\r\n    validation_data=val_data_gen,\r\n    validation_steps=total_val // batch_size\r\n)`\r\n\r\nwhere\r\n`    steps_per_epoch=total_train // batch_size,\r\n`\r\nwill not compile because the , is behind the comment. The correct code should be\r\n`history = model.fit_generator(\r\n    train_data_gen,\r\n    steps_per_epoch=total_train, // batch_size\r\n    epochs=epochs,\r\n    validation_data=val_data_gen,\r\n    validation_steps=total_val // batch_size\r\n)`"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/toco\r\n\r\nTflite converter is missing the usage documentation exmaple links :\r\n[link 1](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/convert/cmdline_reference.md)\r\n[link 2](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/convert/cmdline_examples.md)\r\n\r\nthe flags are needed to run such command : \r\n\r\n```\r\nbazel run --config=opt tensorflow/lite/toco:toco -- \\\r\n--input_file=$OUTPUT_DIR/tflite_graph.pb \\\r\n--output_file=$OUTPUT_DIR/detect.tflite \\\r\n--input_shapes=1,300,300,3 \\\r\n--input_arrays=normalized_input_image_tensor \\\r\n--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3'  \\\r\n--inference_type=FLOAT \\\r\n--allow_custom_ops\r\n```\r\n\r\nPlease update the links or some one points me at the file that contains these flags to investigate more other possibilities and methods.\r\n\r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n\r\n## URL(s) with the issue: https://groups.google.com/a/tensorflow.org/d/msg/discuss/sye03udicMI/sDr6MQvIDAAJ\r\n\r\n## Description of issue (what needs changing): No resources anywhere about tflite usage using Android NDK.\r\n\r\n### Clear description\r\nI have a .tflite model which involves lots of post processing. \r\nAfter following https://www.tensorflow.org/lite/guide/inference#load_and_run_a_model_in_c  I have written the code in cpp and tested on linux and adb shell.\r\n\r\nNow I want to use this code in the sample Android apk .(https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android)\r\n\r\nIs there any documentation/sample usage of tflite cpp in Android? \r\nI have only found this(https://github.com/zimenglyu/TFLiteExample) but not able to follow this :(\r\n\r\nAny help would be desperately appreciated.\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n\r\n\r\n\r\n## Description of issue (what needs changing):\r\nWe need a new documentation to interact with astronomy.\r\n### Clear description\r\n\r\nLike we think astronomical animation is good for research. We need a new documentaion how to interact with Phoebe or with other by Tensorflow .\r\n\r\n\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/tutorials/text/text_classification_rnn\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe sample for LSTM-based text classification doesn't run under Tensorflow 2.1 anymore.\r\n\r\nThe line:\r\n\r\n```\r\ntrain_dataset = train_dataset.padded_batch(BATCH_SIZE, train_dataset.output_shapes)\r\n```\r\n\r\nDoes fail with the error:\r\n\r\n```\r\nAttributeError: 'ShuffleDataset' object has no attribute 'output_shapes'\r\n```\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/function?version=stable \r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\nOriginal:\r\n> It also restricts the dhape and datatype of Tensors that can be used:\r\n\r\nSo, I think it should be updated as \r\n\r\nIt also restricts the **shape** and datatype of Tensors that can be used:\r\n\r\n### Clear description\r\n\r\nFind a typo.\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/applications\r\nhttps://github.com/tensorflow/models/tree/master/official\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThere are the pre-trained models for Keras found in `tf.keras.applications`. And there are those models found on GitHub in the Model Garden (under `/models`, as linked above). Now, from reading the docs (both for the applications as well as those in the Model Garden) I don't get the difference. Why do we have those two different model repos?"
  },
  {
    "labels": ["documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_lite/tflite_c05_exercise_rock_paper_scissors.ipynb\r\n---------------------------------------------------------------\r\n![Screenshot from 2020-01-16 18-37-30](https://user-images.githubusercontent.com/29497701/72527695-5d004900-388f-11ea-84f8-57ed0c12c915.png)\r\n----------------------------------------------------------------\r\n\r\n## Description of issue (what needs changing):\r\n\r\nI think this exercise doesn't make use of cats_vs_dogs dataset, right??\r\n\r\n### Clear description\r\n\r\nIn place of `cats_vs_dogs` dataset, `rock_paper_scissors` dataset should be mentioned.\r\n\r\n### Submit a pull request?\r\n\r\nYes, shortly"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "The current GPU Support instructions for CUDA 10 on Ubuntu 16.04 refers to a package version that does not exist in the [NVIDIA ML repo](https://developer.download.nvidia.cn/compute/machine-learning/repos/ubuntu1604/x86_64/): `libnvinfer5=6.0.1-1+cuda10.1`\r\n\r\n#### Ubuntu 16.04 (CUDA 10)\r\n\r\n<pre class=\"prettyprint lang-bsh\">\r\n...\r\n# Install TensorRT. Requires that libcudnn7 is installed above.\r\n<code class=\"devsite-terminal\">sudo apt-get install -y --no-install-recommends libnvinfer5=6.0.1-1+cuda10.1 \\\r\n    libnvinfer-dev=6.0.1-1+cuda10.1\r\n</code>\r\n</pre>\r\n\r\nThis results in an error when trying to install:\r\n```\r\nReading package lists... Done\r\nBuilding dependency tree       \r\nReading state information... Done\r\nE: Version ‘6.0.1-1+cuda10.1’ for ‘libnvinfer5’ was not found\r\n```\r\n\r\nChanging this to `libnvinfer6=6.0.1-1+cuda10.1` seems to work and run happily."
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "Are you going to update your TPU documentation https://cloud.google.com/tpu/docs/colabs with 2.1 release?"
  },
  {
    "labels": [null, "documentation"],
    "text": "**System information**\r\n- OS Platform and Distribution: macOS 10.15 and iPadOS 13.3\r\n- Mobile device: iPad 2018\r\n- TensorFlow installed from (source or binary): pod\r\n\r\n**Describe the problem**\r\n\r\nI did all the steps from the readme of https://github.com/tensorflow/examples/tree/master/lite/examples/posenet/ios \r\n\r\nbut got next error:\r\n\r\n> [!] CocoaPods could not find compatible versions for pod \"TensorFlowLiteSwift\":\r\n>  In snapshot (Podfile.lock):\r\n>    TensorFlowLiteSwift (= 0.0.1-nightly)\r\n\r\n> In Podfile:\r\n>    TensorFlowLiteSwift (= 0.0.1-nightly)\r\n\r\n> None of your spec sources contain a spec satisfying the dependencies: `TensorFlowLiteSwift (= 0.0.1-nightly), TensorFlowLiteSwift (= 0.0.1-nightly)`.\r\n\r\n>You have either:\r\n> * out-of-date source repos which you can update with `pod repo update` or with `pod install --repo-update`.\r\n> * mistyped the name or version.\r\n> * not added the source repo that hosts the Podspec to your Podfile.\r\n\r\n**The solution**\r\n\r\nTo make it work I just removed the Podfile.lock file and run again the command\r\n`pod install`\r\n\r\nMaybe the source repo should also be updated.\r\n\r\nThanks!\r\n\r\nP.S.: Initially it was posted there https://github.com/tensorflow/tensorflow/issues/35803 "
  },
  {
    "labels": [null, "documentation"],
    "text": "https://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_lite/tflite_c04_exercise_convert_model_to_tflite_solution.ipynb\r\n\r\nUnder \"Create a Dataset from Images and Labels\", we have this code\r\n\r\n`train_batches=train_examples.cache().shuffle(num_examples//4).batch(BATCH_SIZE).map(format_example).prefetch(1)`\r\n\r\nand similar for the validation and test examples...\r\n\r\nIs this a right practise?? \r\nShouldn't we first format the raw images and then batch them together rather than opposite way?"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_lite/tflite_c02_transfer_learning.ipynb\r\n\r\n## Description of issue (what needs changing):\r\n\r\n![Screenshot from 2020-01-13 12-53-58](https://user-images.githubusercontent.com/29497701/72238480-d7b53400-3603-11ea-847d-0eb7c0eb0716.png)\r\n\r\nIn description, it should be 'cats_vs_dogs'\r\n\r\n### Submit a pull request?\r\n\r\nYes"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue: \r\nhttps://www.tensorflow.org/api_docs/python/tf/linalg/diag_part?version=nightly\r\n\r\n## Description of issue (what needs changing):\r\nThe `diag_part` documentation contains old examples of non-existing APIs, it uses `tf.matrix_diag_part` in the examples which does not exist.\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/datasets/api_docs/python/tfds/load\r\n\r\n## Description of issue (what needs changing):\r\nAdd a warning that `tfds.load()` can not be used for the users own Datasets, i.e. that he creates himself. To a new user trying to to load a Dataset from a set of files it is not obvious that this method is only for pre-made, immutable Datasets.\r\n\r\nAlthough it does say\r\n> Loads the named dataset into a tf.data.Dataset.\r\n\r\ni initially interpreted it such that my own Dataset can be assigned a name. \r\n\r\nI was looking for a way to split a Dataset into train and validation subsets and stumbled upon this documentation. I was redirected from https://www.tensorflow.org/datasets/splits which comes up as one of the most prominent search results when searching for \"tensorflow Dataset splits\" .\r\n\r\n## Result\r\nA user who visits https://www.tensorflow.org/datasets/api_docs/python/tfds/load will not spend 1 h of trying to understand all the documentation but will immediately realize that this is only for immutable pre-made Datasets."
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l08c05_forecasting_with_machine_learning.ipynb\r\n\r\n## Description of issue (what needs changing):\r\n\r\nWindow size should be 30 instead of 20 in the description under \"Forecasting With Machine Learning\".\r\n\r\n### Clear description\r\n\r\n![Screenshot from 2020-01-10 12-05-13](https://user-images.githubusercontent.com/29497701/72131252-b1905980-33a1-11ea-8cf5-11d089d5316e.png)\r\n\r\n--------------------\r\nAs we can see under \"Linear Model\", `window_size=30` while in description it is mentioned as model forecasts, given previous 20 steps.\r\n\r\n### Submit a pull request?\r\n\r\nYes..."
  },
  {
    "labels": [null, null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nFor example,\r\nhttps://www.tensorflow.org/versions/r1.14/api_docs/python/tf/train\r\nhttps://www.tensorflow.org/versions/r1.14/api_docs/python/tf/estimator/Estimator\r\nhttps://www.tensorflow.org/versions/r1.14/api_docs/python/tf/keras/Model\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe links above currently redirect to GitHub. The 1.15 links work:\r\n\r\nhttps://www.tensorflow.org/versions/r1.15/api_docs/python/tf/train\r\nhttps://www.tensorflow.org/versions/r1.15/api_docs/python/tf/estimator/Estimator\r\nhttps://www.tensorflow.org/versions/r1.15/api_docs/python/tf/keras/Model\r\n\r\nI have projects using TensorFlow 1.14, so I would like to use the 1.14 docs for reference.\r\n\r\nWill the 1.14 docs be back up?\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/distribute/experimental/TPUStrategy?version=stable\r\n\r\n## Description of issue (what needs changing):\r\n\r\nOn the documentation page for tf.distribute.experimental.TPUStrategy, the Stable documentation is shown as the raw text of the documentation (looks like it's a combination of HTML and Markdown?).\r\n\r\nExample below:\r\n\r\n<img width=\"1664\" alt=\"Screen Shot 2020-01-09 at 1 22 11 PM\" src=\"https://user-images.githubusercontent.com/11432284/72094036-87786200-32e3-11ea-89ca-253b45a5ad7b.png\">\r\n\r\nClicking \"See Nightly\" it renders correctly, but clicking \"See Stable\" again it still shows the raw text again.\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l08c03_moving_average.ipynb\r\n\r\n## Description of issue (what needs changing):\r\n\r\nIt should be 'mean absolute error' instead of squared error while Naive Forecasting\r\n\r\n![Screenshot from 2020-01-09 12-10-09](https://user-images.githubusercontent.com/29497701/72044240-4bd89a80-32d9-11ea-937f-a189784b83b0.png)\r\n\r\n### Submit a pull request?\r\n\r\nYes, I'll be submitting one shortly"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/experimental/examples/lstm/TensorFlowLite_LSTM_Keras_Tutorial.ipynb\r\n\r\n## Description of issue (what needs changing):\r\nThe example script on how to make lstm layers ready for tf lite is outdated and not working anymore, because the requested tf-nightly package causes issues. \r\n\r\n\r\nI would like to get an updated tutorial or a better alternative. To use the TFLite converter with the experimental_flag set to True works with lstm layers, but does not allow post training quantization. As a general question I would like to know, if this would be possible with the the model that is build in the example script?\r\n\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://github.com/tensorflow/examples/blob/d631c0545dac90c6390da76ed8df7c4f6a2a25bc/courses/udacity_intro_to_tensorflow_for_deep_learning/l08c01_common_patterns.ipynb#L307\r\n\r\n`def white_noise(time, noise_level=1, seed=None):`\r\n\r\n## Description of issue (what needs changing):\r\n\r\nI think, we should add explanation of `seed` parameter here since it's quite an important one.\r\n\r\n### Clear description\r\n\r\nSome explanation about how `seed` affects generation of random numbers every time along with links for reference can be added.\r\n\r\n### Submit a pull request?\r\n\r\nYes"
  },
  {
    "labels": [null, null, null, null, "documentation"],
    "text": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n```\r\nimport tensorflow as tf\r\n\r\na = tf.Variable(2)\r\na.assign(5)\r\nassert a.numpy() == 5\r\n\r\n# ValueError: Shapes () and (2,) are incompatible\r\na.assign([1,2])  \r\n\r\n# TypeError: assign() got an unexpected keyword argument 'validate_shape'\r\na.assign([1,2], validate_shape=False)\r\n\r\n# ValueError: Shapes () and (2,) are incompatible\r\ntf.compat.v1.assign(a, [1,2], validate_shape=False)  \r\n\r\n```\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10, Linux\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 2.0.0, 2.1.0\r\n- Python version: 3.7\r\n\r\n**Describe the current behavior**\r\n\r\n`tf.assign` had a `validate_shape` parameter that `Variable.assign` seems to be missing.\r\n\r\nIn addition, the docs say:\r\n> If you want to change the shape of a variable later you have to use an `assign` Op with `validate_shape=False`.\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/Variable\r\n\r\nHow should one change the shape of a variable?\r\n\r\n**Code to reproduce the issue**\r\nSee above.\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization?version=stable\r\n\r\n## Description of issue (what needs changing):\r\n\r\nAfter the references list there is a stray malformed tag:\r\n\r\n{ {TRAINABLE_ATTRIBUTE_NOTE}}\r\n\r\nI suspect that this is supposed to resolve to the note that `moving_mean` and `moving_variance` are placed in `UPDATE_OPS` and need to be executed alongside the training op.  (This note is present in the `tf.layers` doc: https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/layers/batch_normalization)  But without knowing what this tag refers to I can't really say for sure.  (The tag is present in only three places in the Tensorflow codebase and shows up malformed on the website in each case.)\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\n* lower: https://www.tensorflow.org/api_docs/python/tf/strings/lower?version=stable\r\n* upper: https://www.tensorflow.org/api_docs/python/tf/strings/upper?version=stable\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nThe first line of the docstrings for these functions is the auto-generated \"TODO: add doc.\" instead of an actual summary.\r\n\r\n### Submit a pull request?\r\n\r\nYes, I'll be submitting one shortly."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/api_docs/python/tf/gradients?version=stable\r\n\r\n## Description of issue (what needs changing):\r\nIt's unclear how many list items are returned from `tf.gradients`.\r\n\r\nThe second paragraph states that \"It returns a list of Tensor of length `len(xs)` where each tensor is the `sum(dy/dx)` for y in `ys`.\" The \"Returns\" section says, \"A list of `sum(dy/dx)` for each x in `xs`.\"\r\n\r\nSo... which one is it? `sum(dy/dx)` for x in `xs` or `sum(dy/dx)` for y in `ys`? Besides the inconsistency, the summation notation in this documentation is ambiguous. When it says \"`sum(dy/dx)` for x in `xs`\" does that mean `dy/dx` is summed over the `ys` axis and there is one element produced for each `xs` or the other way around?\r\n\r\nA clarifying example would help and a statement along the lines of \"returns a list of <whatever> with as many elements as `xs`\" (or `ys` -- I don't know).\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://github.com/ManishAradwad/examples/blob/9f7d80aff8214b358e4aea0b83f2648748990c4b/courses/udacity_intro_to_tensorflow_for_deep_learning/l07c01_saving_and_loading_models.ipynb#L579\r\n\r\n`The differnece in output should be zero:`\r\n\r\n## Description of issue (what needs changing):\r\n\r\ndiffernece should be difference\r\n\r\n### Submit a pull request?\r\n\r\nYes\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/tfx/tutorials/transform/census#python_check_imports_and_globals\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe text says \"First we'll make sure that we're using Python 2, and then go ahead and install and import the stuff we need.\" but the code below indicates we need to use Python 3.\r\n\r\n### Clear description\r\n\r\nThe text states:\r\n\r\n> First we'll make sure that we're using Python 2, and then go ahead and install and import the stuff we need.\r\n\r\nThe code example says:\r\n\r\n```python\r\nimport sys\r\n\r\n# Confirm that we're using Python 3\r\nassert sys.version_info.major is 3, 'Oops, not running Python 3. Use Runtime > Change runtime type'\r\n```\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "The codelab still links to the experimental folder for the makefile, which is incorrect.\r\n\r\nVisual:\r\n![image](https://user-images.githubusercontent.com/997157/71787651-3bc27180-2fe0-11ea-8318-424dc887efc5.png)\r\n\r\nUpdate the codelab at this link https://codelabs.developers.google.com/codelabs/sparkfun-tensorflow/#3\r\n\r\nCode should read:\r\n```\r\nmake -f tensorflow/lite/micro/tools/make/Makefile \\                                    \r\nTARGET=sparkfun_edge micro_speech_bin\r\n```\r\n\r\n## URL(s) with the issue:\r\nhttps://codelabs.developers.google.com/codelabs/sparkfun-tensorflow/#3\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://codelabs.developers.google.com/codelabs/sparkfun-tensorflow/#3\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nThe \"Report a Mistake\" link at the bottom left does not work, and goes to a GitHub 404 instead.\r\n![image](https://user-images.githubusercontent.com/997157/71787589-711a8f80-2fdf-11ea-8c54-03f8fc68b8d0.png)\r\n\r\nCurrently it links to: https://github.com/tensorflow/tensorflow/issues/new/title=[sparkfun-tensorflow-codelab]:"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l05c03_exercise_flowers_with_data_augmentation.ipynb\r\n\r\n## Description of issue (what needs changing):\r\n\r\nIn the directory structure, it should be \"daisy\" instead of \"diasy\"\r\n\r\n![Screenshot from 2020-01-03 18-39-11](https://user-images.githubusercontent.com/29497701/71725075-a8aaff80-2e58-11ea-9ac8-076078500026.png)\r\n\r\n### Submit a pull request?\r\n\r\nYes\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/Model?version=stable\r\n\r\n## Description of issue (what needs changing):\r\nIn the `validation_data` part of `Model.fit()`, the third alternative reads\r\n> dataset For the first two cases, `batch_size` must be provided. For the last case, `validation_steps` must be provided.\r\n\r\nI feel a link break should be inserted after \"dataset\"."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## Description of issue (what needs changing):\r\n\r\nDo we still need the `steps_per_epochs` parameter while fitting the model to training set?\r\nIn the tensorflow tutorial(which is very similar to the MNIST tutorial of Intro to Deep Learning course ), there is no such parameter...\r\n\r\n## URL(s) with the issue:\r\n\r\nUdacity Course Notebook : https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l03c01_classifying_images_of_clothing.ipynb#scrollTo=S5Uhzt6vVIB2\r\n\r\n-----------------------------------------------------------------\r\n![Screenshot from 2020-01-01 23-27-10](https://user-images.githubusercontent.com/29497701/71644446-78dfe880-2cee-11ea-9da7-5c033d8a0592.png)\r\n-----------------------------------------------------------------\r\n\r\nTensorflow Tutorial : \r\nhttps://www.tensorflow.org/tutorials/keras/classification/\r\n\r\n-----------------------------------------------------------------\r\n![Screenshot from 2020-01-01 23-26-50](https://user-images.githubusercontent.com/29497701/71644452-93b25d00-2cee-11ea-97af-70d0ece074d9.png)\r\n-----------------------------------------------------------------\r\n\r\n### Parameters defined\r\n\r\n`steps_per_epoch` parameter in `model.fit` should be removed??\r\n\r\n### Submit a pull request?\r\n\r\nI'll submit a PR right away if this issue is relevant..."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/guide/keras/custom_layers_and_models#putting_it_all_together_an_end-to-end_example\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe code given in the guide does not run if the latent dimension is set 1, it runs fine for every latent dimension >1!\r\n\r\n### Clear description\r\n\r\nwhen the model is built and trained with code:\r\n```\r\nvae = VariationalAutoEncoder(784, 64, 1)\r\n\r\noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\r\n\r\nvae.compile(optimizer, loss=tf.keras.losses.MeanSquaredError())\r\nvae.fit(x_train, x_train, epochs=3, batch_size=64)\r\n```\r\nit throws the error:\r\n\r\n**ValueError: The last dimension of the inputs to Dense should be defined. Found None**\r\n\r\n### Correct links\r\n\r\nn/a\r\n\r\n### Parameters defined\r\n\r\nlatent_dim = 1\r\n(vae = VariationalAutoEncoder(784, 64, 1) )\r\n\r\n### Returns defined\r\n\r\nn/a\r\n\r\n### Raises listed and defined\r\n\r\n**ValueError: The last dimension of the inputs to Dense should be defined. Found None**\r\n\r\n### Usage example\r\n\r\ncode in the guide:\r\n\r\n```\r\nclass Sampling(layers.Layer):\r\n  \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\r\n\r\n  def call(self, inputs):\r\n    z_mean, z_log_var = inputs\r\n    batch = tf.shape(z_mean)[0]\r\n    dim = tf.shape(z_mean)[1]\r\n    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\r\n    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\r\n\r\n\r\nclass Encoder(layers.Layer):\r\n  \"\"\"Maps MNIST digits to a triplet (z_mean, z_log_var, z).\"\"\"\r\n\r\n  def __init__(self,\r\n               latent_dim=32,\r\n               intermediate_dim=64,\r\n               name='encoder',\r\n               **kwargs):\r\n    super(Encoder, self).__init__(name=name, **kwargs)\r\n    self.dense_proj = layers.Dense(intermediate_dim, activation='relu')\r\n    self.dense_mean = layers.Dense(latent_dim)\r\n    self.dense_log_var = layers.Dense(latent_dim)\r\n    self.sampling = Sampling()\r\n\r\n  def call(self, inputs):\r\n    x = self.dense_proj(inputs)\r\n    z_mean = self.dense_mean(x)\r\n    z_log_var = self.dense_log_var(x)\r\n    z = self.sampling((z_mean, z_log_var))\r\n    return z_mean, z_log_var, z\r\n\r\n\r\nclass Decoder(layers.Layer):\r\n  \"\"\"Converts z, the encoded digit vector, back into a readable digit.\"\"\"\r\n\r\n  def __init__(self,\r\n               original_dim,\r\n               intermediate_dim=64,\r\n               name='decoder',\r\n               **kwargs):\r\n    super(Decoder, self).__init__(name=name, **kwargs)\r\n    self.dense_proj = layers.Dense(intermediate_dim, activation='relu')\r\n    self.dense_output = layers.Dense(original_dim, activation='sigmoid')\r\n\r\n  def call(self, inputs):\r\n    x = self.dense_proj(inputs)\r\n    return self.dense_output(x)\r\n\r\n\r\nclass VariationalAutoEncoder(tf.keras.Model):\r\n  \"\"\"Combines the encoder and decoder into an end-to-end model for training.\"\"\"\r\n\r\n  def __init__(self,\r\n               original_dim,\r\n               intermediate_dim=64,\r\n               latent_dim=32,\r\n               name='autoencoder',\r\n               **kwargs):\r\n    super(VariationalAutoEncoder, self).__init__(name=name, **kwargs)\r\n    self.original_dim = original_dim\r\n    self.encoder = Encoder(latent_dim=latent_dim,\r\n                           intermediate_dim=intermediate_dim)\r\n    self.decoder = Decoder(original_dim, intermediate_dim=intermediate_dim)\r\n\r\n  def call(self, inputs):\r\n    z_mean, z_log_var, z = self.encoder(inputs)\r\n    reconstructed = self.decoder(z)\r\n    # Add KL divergence regularization loss.\r\n    kl_loss = - 0.5 * tf.reduce_mean(\r\n        z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1)\r\n    self.add_loss(kl_loss)\r\n    return reconstructed\r\n\r\n\r\n\r\nvae = VariationalAutoEncoder(784, 64, 1)\r\n\r\noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\r\n\r\nvae.compile(optimizer, loss=tf.keras.losses.MeanSquaredError())\r\nvae.fit(x_train, x_train, epochs=3, batch_size=64)\r\n```\r\n### Request visuals, if applicable\r\n\r\nn/a\r\n\r\n### Submit a pull request?\r\n\r\nn/a\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/tutorials/generative/dcgan\r\n\r\n## Description of issue (what needs changing):\r\n\r\nhttps://colab.research.google.com/gist/MokkeMeguru/614e16d83d16f1eb70b5f3b73c7d070b/batchnormalization_debug.ipynb\r\n\r\nIn you tutorial, BatchNormalization will be Actnormalization in Glow(https://arxiv.org/abs/1807.03039)\r\n\r\n### Clear description\r\n\r\nWe need Correct BathNormalization\r\n\r\n### Usage example\r\n\r\nWe should input the shape when   BatchNormalization is initialized"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "Can't find odeint or integrate...\r\ncan't import contrib from tf.compat.v1 \r\nwhere is odeint "
  },
  {
    "labels": [null, "documentation"],
    "text": "The link to the [EMNIST page](https://www.tensorflow.org/datasets/catalog/emnist) on Tensorflow's docs is broken.\r\n\r\nThe existing link is -\r\nhttps://www.nist.gov/node/1298471/emnist-dataset\r\n\r\nIt should be replaced by -\r\nhttp://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/gzip.zip"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/debugging/assert_shapes?version=stable\r\n\r\n## Description of issue (what needs changing):\r\n\r\nUpdate Documentation or implementation of `tf.debugging.assert_shapes`.     \r\n`Shapes` in its argument requires LIST OF TUPLE, not DICTIONARIES.\r\n\r\n### Clear description\r\n\r\nYour Documentation (Python 4's syntax?)\r\n```python\r\nx = tf.random.normal([128, 32, 32, 1])\r\ntf.debugging.assert_shapes(\r\n    [(x: (128, 32, 32, 1))]\r\n)\r\n# => \r\n#     [(x: (128, 32, 32, 1))]\r\n#       ^\r\n# SyntaxError: invalid syntax\r\n```\r\n\r\nWith dictionary (Python 3's syntax)\r\n```python\r\ntf.debugging.assert_shapes(\r\n    {x: (128, 32, 32, 1)}\r\n)\r\n# =>\r\n# ... ... Traceback (most recent call last):\r\n#   File \"<stdin>\", line 2, in <module>\r\n#  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 713, in __hash__\r\n#     raise TypeError(\"Tensor is unhashable if Tensor equality is enabled. \"\r\n# TypeError: Tensor is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key.\r\n```\r\nWith list of tuple (python 3's syntax)(NOT DICTIONARIES)\r\n```python\r\ntf.debugging.assert_shapes([\r\n    (x, (128, 32, 32, 1))\r\n]\r\n)\r\n# => nothing (correct)\r\n```\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r1.14/api_docs/python/tf/keras/applications\r\n\r\n## Description of issue (what needs changing):\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04 in Docker\r\n- TensorFlow installed from (source or binary): pip install\r\n- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38\r\n- Python version: 3.5\r\n- CUDA/cuDNN version: 10.0 / 7\r\n- GPU model and memory: GTX 1080Ti / 11175MiB\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nHi authors and developers,\r\n\r\nI noticed that tensorflow doesn't provide a clear document explain how to use pre-trained model.\r\n\r\nSo, I wrote a benchmark which showed the accuracy of pre-trained model with applying imageNet' validation set.\r\n\r\nThe following is the result:\r\n\r\n```\r\n[Testing][pixel vales are from (0,255)][model:ResNet50] - loss: 2.711 - accuracy: 0.457\r\n[Testing][pixel vales are from (0,255)][model:DenseNet121] - loss: 39.000 - accuracy: 0.006\r\n[Testing][pixel vales are from (0,255)][model:MobileNetV2] - loss: 9.979 - accuracy: 0.003\r\n\r\n[Testing][pixel vales are from (0,1)][model:ResNet50] - loss: 8.535 - accuracy: 0.001\r\n[Testing][pixel vales are from (0,1)][model:DenseNet121] - loss: 1.895 - acc: 0.599\r\n[Testing][pixel vales are from (0,1)][model:MobileNetV2] - loss: 2.283 - accuracy: 0.523\r\n\r\n[Testing][pixel vales are normalized from (-1,1)][model:ResNet50] - loss: 8.313 - acc: 0.001\r\n[Testing][pixel vales are normalized from (-1,1)][model:DenseNet121] - loss: 1.896 - acc: 0.599\r\n[Testing][pixel vales are normalized from (-1,1)][model:MobileNetV2] - loss: 2.287 - acc: 0.524\r\n\r\n```\r\n\r\nFirst, we can see the accuracy is not comparable with the original result(Top-1 accuracy is 70% up).\r\n\r\nI thought that this issue is I'm not sure which crop and pad method is applied in the original result.\r\n\r\nTherefore, I defined a custom function `CenterCrop` to fit the model's input size.\r\n\r\nBut, we can skip this issues there.\r\n\r\nWhat I want to mention is normalization issue.\r\n\r\nIf I don't apply any normalization(run_aug=1 in code), pixel's values are defined in **(0, 255)**.\r\n\r\nAll models' accuracy are near 0.001, except for resNet50 which achieves a meaningful accuracy.\r\n\r\nIf I do normalization(run_aug=2 in code), pixel's values are defined in **(0, 1)**.\r\n\r\nThis time, DenseNet121 and MobileNetV2 have a meaningful accuracy.\r\n\r\nIf I do standard normalization(run_aug=3 in code), pixel's values are defined in **(-1, 1)**.\r\n\r\nThe results are similar to previous case. But I'm sure why those two cases have same accuracy.\r\n\r\nThose behavior let me confused.\r\n\r\nBefore applying pre-trained model, I have to which normalization method should be applied.\r\n\r\nAfter reading the source code, I found that those applications are import from `keras_application` in `tensorflow`.\r\n\r\n[keras-applications](https://github.com/keras-team/keras-applications)\r\n\r\n[weight download](https://github.com/fchollet/deep-learning-models)\r\n\r\n---\r\n\r\nI didn't test other models, such as `ResNet50V2`, `InceptionV3` and `Xception` because their input size are `299` instead of `244` and this is a time consuming task.\r\n\r\nHowever, anyone can modify the test case and do the benchmark.\r\n\r\n---\r\n\r\nBecause of licence issue for ImageNet, I can't provide imagenet in public.\r\n\r\nBut the following is the minimal test case:\r\n\r\n```python\r\n# pip install tensorflow-gpu==1.14.0\r\n# pip pandas\r\n#%%\r\nimport time\r\nimport numpy as np\r\nimport pandas as pd\r\nimport tensorflow as tf\r\n\r\nfrom glob import glob\r\n\r\n#%%\r\n# input image dimensions\r\nimg_h = 224\r\nimg_w = 224\r\nchannels = 3\r\n\r\n# information for dataset\r\ndataset_path = \"dataset-imagenet/\"\r\nnum_classes = 1000\r\nnum_testing = 50000\r\n\r\n#%%\r\nclass DataGenerator:\r\n\r\n    def __init__(self, dataframe, batch_size, run_aug = True):\r\n\r\n        self.total_len  = len(dataframe.index)\r\n        self.batch_size = batch_size\r\n        self.run_aug = run_aug\r\n        self.dataframe  = dataframe\r\n        self.on_epoch_end()\r\n\r\n    def __build_pipeline(self, file_path, labelY):\r\n\r\n        # mapping function in tf\r\n        def preprocess_fn(file_path, labelY):\r\n\r\n            def fn_x(img_array):\r\n\r\n                img_array = img_array.numpy()\r\n\r\n                if self.run_aug == 1:\r\n                    # image's range is [0,255]\r\n                    image = img_array\r\n\r\n                if self.run_aug >= 2:\r\n                    # image's range is [0,1]\r\n                    image = img_array / 255.0\r\n\r\n                if self.run_aug == 3:\r\n                    # std normalization\r\n                    image[0,:,:] -= 0.485\r\n                    image[1,:,:] -= 0.456\r\n                    image[2,:,:] -= 0.406\r\n                    image[0,:,:] /= 0.229\r\n                    image[1,:,:] /= 0.224\r\n                    image[2,:,:] /= 0.225\r\n\r\n                return image\r\n\r\n            def fn_y(label):\r\n                return tf.keras.utils.to_categorical(label , num_classes)\r\n\r\n            # read image from files\r\n            image = tf.io.read_file(file_path)\r\n            image = tf.image.decode_image(image, channels=channels)\r\n            aug_size = 256\r\n            imageX = tf.compat.v1.image.resize_image_with_pad(image, aug_size, aug_size)\r\n            imageX = tf.image.resize_with_crop_or_pad(image, img_h, img_w)\r\n\r\n            # do normalizarion\r\n            [imageX] = tf.py_function(fn_x, [imageX], [tf.float32])\r\n            imageX.set_shape([img_h, img_w, channels])\r\n            imageX = tf.image.random_flip_left_right(imageX)\r\n\r\n            [labelY] = tf.py_function(fn_y, [labelY], [tf.float32])\r\n            labelY.set_shape([num_classes])\r\n\r\n            return imageX, labelY\r\n\r\n        dataset = tf.data.Dataset.from_tensor_slices( (file_path, labelY) )\r\n        dataset = dataset.shuffle(batch_size * 8)\r\n        dataset = dataset.repeat()\r\n        dataset = dataset.map(preprocess_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE)\r\n        dataset = dataset.batch(self.batch_size)\r\n        dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\r\n\r\n        self.dataset   = dataset\r\n\r\n    def  __len__(self):\r\n\r\n        return self.total_len // self.batch_size\r\n\r\n    def on_epoch_end(self):\r\n\r\n        cleanX = np.array(self.dataframe[\"File\"])\r\n        totalY = np.array(self.dataframe[\"One-hot\"])\r\n\r\n        # run permutation\r\n        rand_idx = np.random.permutation(self.total_len)\r\n        cleanX = cleanX[rand_idx]\r\n        totalY = totalY[rand_idx]\r\n\r\n        self.__build_pipeline(cleanX, totalY)\r\n\r\n#%%\r\ndef build_clf(model_name):\r\n\r\n    if model_name == \"ResNet50\":\r\n        clf_model = tf.keras.applications.ResNet50(include_top=True, pooling='max', weights='imagenet')\r\n\r\n    if model_name == \"DenseNet121\":\r\n        clf_model = tf.keras.applications.DenseNet121(include_top=True, pooling='max', weights='imagenet')\r\n\r\n    if model_name == \"MobileNetV2\":\r\n        clf_model = tf.keras.applications.MobileNetV2(include_top=True, pooling='max', weights='imagenet')\r\n\r\n    if model_name == \"InceptionV3\":\r\n        clf_model = tf.keras.applications.InceptionV3(include_top=True, weights='imagenet')\r\n\r\n\r\n    clf_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n\r\n    return clf_model\r\n\r\n#%%\r\ndef list_testing_data(classes, file_path, onehot_map):\r\n\r\n    try:\r\n        testing_data = pd.read_pickle('imagenet_test_list.pkl')\r\n        print('[Successful] Testing_data loaded from pickle ...')\r\n    except:\r\n        testing_image_info = []\r\n        for iter_class in classes:\r\n            files = glob(os.path.join(file_path, iter_class, '*.JPEG'))\r\n            for iter_img in files:\r\n                data_info = [iter_img, iter_class]\r\n                testing_image_info.append(data_info)\r\n\r\n        testing_data = pd.DataFrame(testing_image_info, columns=['File', 'Class'])\r\n        testing_data[\"One-hot\"] = testing_data[\"Class\"].replace(onehot_map, inplace=False)\r\n\r\n        testing_data.to_pickle('imagenet_test_list.pkl')\r\n\r\n    assert(testing_data.shape[0] == num_testing, \"[Fatal] Mismatched total length of testing data\")\r\n    return testing_data\r\n\r\n#%%\r\nif __name__ == '__main__':\r\n\r\n    # set GPU\r\n    import os\r\n    if os.environ.get(\"CUDA_VISIBLE_DEVICES\") is None:\r\n        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\r\n\r\n    # Hyperparameters\r\n    batch_size = 100\r\n    epochs = 5\r\n\r\n    # load one-hot labels\r\n    file_path = dataset_path + 'val'\r\n    classes = os.listdir(file_path)\r\n    list_class = sorted( list( set(classes) ) )\r\n    onehot_map = dict( zip( list_class, list(range(0, num_classes)) ))\r\n\r\n    # load list of validation data, those data should be considered as testing data\r\n    testing_data = list_testing_data(classes, file_path, onehot_map)\r\n\r\n    # build data generator\r\n    gen_type1 = DataGenerator(testing_data, batch_size, run_aug=1)\r\n    gen_type2 = DataGenerator(testing_data, batch_size, run_aug=2)\r\n    gen_type3 = DataGenerator(testing_data, batch_size, run_aug=3)\r\n    gen_list = [gen_type1, gen_type2, gen_type3]\r\n\r\n    # build model\r\n    model_list = [\"ResNet50\", \"DenseNet121\", \"MobileNetV2\"]\r\n    \r\n    # print result for type1\r\n    test_gen = gen_type1\r\n    for model_name in model_list:\r\n        model = build_clf(model_name)\r\n        meta_string = '[Testing][pixel vales are from (0,255)][model:{:s}] '.format(model_name)\r\n        prefix_string = ''\r\n        output = model.evaluate(test_gen.dataset, steps = test_gen.__len__())\r\n        for ii in range( len( model.metrics_names) ):\r\n            meta_string = meta_string + '- {:s}{:s}: {:.3f} '.format(prefix_string, model.metrics_names[ii], output[ii])\r\n\r\n        print(meta_string)\r\n\r\n    # print result for type2\r\n    test_gen = gen_type2\r\n    for model_name in model_list:\r\n        model = build_clf(model_name)\r\n        meta_string = '[Testing][pixel vales are from (0,1)][model:{:s}] '.format(model_name)\r\n        prefix_string = ''\r\n        output = model.evaluate(test_gen.dataset, steps = test_gen.__len__())\r\n        for ii in range( len( model.metrics_names) ):\r\n            meta_string = meta_string + '- {:s}{:s}: {:.3f} '.format(prefix_string, model.metrics_names[ii], output[ii])\r\n\r\n        print(meta_string)\r\n\r\n    # print result for type3\r\n    test_gen = gen_type3\r\n    for model_name in model_list:\r\n        model = build_clf(model_name)\r\n        meta_string = '[Testing][pixel vales are normalized from (-1,1)][model:{:s}] '.format(model_name)\r\n        prefix_string = ''\r\n        output = model.evaluate(test_gen.dataset, steps = test_gen.__len__())\r\n        for ii in range( len( model.metrics_names) ):\r\n            meta_string = meta_string + '- {:s}{:s}: {:.3f} '.format(prefix_string, model.metrics_names[ii], output[ii])\r\n\r\n        print(meta_string)\r\n```\r\n\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/losses/Reduction?version=stable\r\n\r\n## Description of issue (what needs changing):\r\n\r\nI intend to build up a custom loss function as follows:\r\n\r\n\r\n`\tfrom __future__ import absolute_import, division, print_function, unicode_literals\r\n\timport functools\r\n\r\n\timport numpy as np\r\n\timport tensorflow as tf\r\n\r\n\r\n\tclass GeneralDiceLoss(tf.keras.losses.Loss):\r\n\t\tdef __init__(self, reduction=tf.keras.losses.Reduction.AUTO, name='GeneralDiceLoss'):\r\n\t\t\tsuper().__init__(reduction=reduction, name=name)\r\n\t\t\tself.epsilon = 1e-16 \r\n\t\t\r\n\t\t\r\n\t\tdef get_config(self):\r\n\t\t\tconfig = super(GeneralDiceLoss, self).get_config()\r\n\t\t\treturn config\r\n\t\t\r\n\t\tdef call(self, yPred, yTrue):\r\n\t\t\t#yTrue =tf.dtypes.cast(yTrue, dtype=yPred.dtype)\r\n\t\t\t# Dot product yPred and yTrue and sum them up for each datum and class\r\n\t\t\tcrossProd=tf.multiply(yPred, yTrue)\r\n\t\t\tcrossProdSum=tf.math.reduce_sum(crossProd, axis=np.arange(2, yTrue.ndim))\r\n\t\t\t# Calculate weight for each datum and class \r\n\t\t\tweight = tf.math.reduce_sum(yTrue, axis=np.arange(2, yTrue.ndim))\r\n\t\t\tweight = tf.math.divide(1, tf.math.square(weight)+self.epsilon)\r\n\t\t\t# Weighted sum over classes\r\n\t\t\tnumerator = 2*tf.math.reduce_sum(tf.multiply(crossProdSum, weight), axis=1)\r\n\t\t\t# Saquared summation \r\n\t\t\tyySum = tf.math.reduce_sum(tf.math.square(yPred) + tf.math.square(yTrue), axis=np.arange(2, yTrue.ndim))\r\n\t\t\t# Weighted sum over classes\r\n\t\t\tdenominator = tf.math.reduce_sum(tf.multiply(weight, yySum), axis=1)\r\n\t\t\tloss = 1 - tf.math.divide(numerator, denominator+self.epsilon)\r\n\t\t\t#loss = tf.math.reduce_mean(1 - tf.math.divide(numerator, denominator+self.epsilon))\r\n\t\t\t\r\n\t\t\treturn loss\r\n`\r\n\r\nThen I create variables to have it test\r\n`\r\n\r\n\tGeneralDiceLoss()\r\n\tyPred = tf.random.uniform(shape=(16, 3, 4, 4, 4))\r\n\tyTrue = tf.round(tf.random.uniform(shape=(16, 3, 4, 4, 4)))\r\n\r\n\tloss=GeneralDiceLoss(yPred, yTrue)\r\n`\r\nBut I got an error\r\n`\r\n\r\n\t  File \"...\\keras-gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py\", line 96, in convert_to_eager_tensor\r\n\t\treturn ops.EagerTensor(value, ctx.device_name, dtype)\r\n\r\n\tTypeError: Cannot convert 'auto' to EagerTensor of dtype float\r\n`\r\n\r\nIn the doc above, \r\n1) there is NO clear indication or warning about conversion issue, not to mention there is NO dtype conversion in my code at all. \r\n2) there is NO clear example indicating which option, AUTO or SUM_OVER_BATCH_SIZE, should be adopted in one's minbatch size is greater than 1. In my case, assume my batch is 16 as exhibted in yPred and yTrue above, shall I use\r\n\r\n`\r\n\t\t\tloss = 1 - tf.math.divide(numerator, denominator+self.epsilon)\r\n`\r\nor \r\n`\r\n\t\t\tloss = tf.math.reduce_mean(1 - tf.math.divide(numerator, denominator+self.epsilon))\r\n`\r\nAnd for which option?\r\n\r\nBuilding up a custom layer/loss function is already a tough task for many practitioners, so could the doc provide more detailed explanations and examples so as to make users' life a little bit easier? Many thanks."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/tutorials/keras/classification/\r\n\r\n## Description of issue (what needs changing):\r\n\r\nUnder \"Train the model\" in \"Build the model\", the accuracy of the model on training data after 10 epochs is 0.91(91%) while it is mentioned as 0.88(88%).\r\n\r\n### Clear description\r\n\r\nSince, it is already mentioned in the tutorials that the model overfits the training data, thus the accuracy on training data should be more than that on testing data(88.3%).\r\n### Submit a pull request?\r\n\r\nIf this issue is alright, I'll be glad the submit a PR right away...\r\nThanks for the help!\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "It looks like `experimental_run_tf_function` was removed from `tf.keras.Model.compile` in this commit a few days ago: https://github.com/tensorflow/tensorflow/commit/c73c99ca3e0bacf2bca313f270bb3eae28869530#diff-de9b96ac2d81503324cbbbe21732031fR1159\r\n\r\nIn [Horovod](http://horovod.ai/), this flag / graph mode is necessary in order for `Optimizer.get_gradients()` to be called, which aggregates gradients across workers.  Since this flag has been removed, distributed training in Horovod with `tf.keras` is not working in our nightly builds.\r\n\r\nIs there a workaround to achieve the same behavior with the latest changes on master?\r\n\r\nNote that we cannot perform the allreduce aggregation in `apply_gradients` due to interactions with gradient clipping and loss scaling (see https://github.com/horovod/horovod/pull/1347).\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Line 194 is missing the square bracket:\r\n\r\n- **wrong**\r\n`Use distribution to create a linear combination of value with shape batch_size, Tq, dim]:`\r\n\r\n\r\n- **correct**\r\n`Use distribution to create a linear combination of value with shape [batch_size, Tq, dim]:`\r\n\r\nLink to the line code:\r\nhttps://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/layers/dense_attention.py#L194\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/constant_initializer\r\n\r\n## Description of issue (what needs changing):\r\nThe [example code](https://github.com/tensorflow/tensorflow/blob/1cf0898dd4331baf93fe77205550f2c2e6c90ee5/tensorflow/python/ops/init_ops_v2.py#L152) uses `>>>`, but on the website, this is incorrectly converted to `&gt;&gt;&gt;`\r\n\r\nTF docs link: https://www.tensorflow.org/api_docs/python/tf/constant_initializer\r\n\r\n### Submit a pull request?\r\n\r\nThis is more of a problem with how documentation is generated from comments in the python file. I don't mind taking a look if someone can point out where to get started. "
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/api_docs/python/tf/audio\r\n\r\n## Description of issue (what needs changing):\r\nCurrently, there are no usage examples for tf.audio APIs , which makes it difficult for new users to implement the same.\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n**Audio is an area not really explored in machine learning to extent image and text has. While TensorFlow does provide a good amount of documentation for the general Args and Returns of the various functions under tf.audio, since most new users will have very little experience with audio as compared to tf.image**\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n**Yes**\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n**Yes**\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n**Yes**\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n**No**\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n**No**\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n**Formatted code blocks are present, which are satisfactory.**\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n**Yes, I think I can provide a detailed usage example.**\r\n  "
  },
  {
    "labels": [null, null, "documentation"],
    "text": "We've had feedback from multiple developers that it's hard to figure out how to calculate the right  int8 values for quantized inputs, and understand what int8 values mean as outputs.\r\n\r\nFor example, when feeding an image to uint8 quantized inputs, the values can be left as in their source 0 to 255 range. For int8 inputs, the developer will typically need to subtract 128 from each value, but this knowledge (and how the offset value is calculated) is not documented. In the same way, users will need to map the -128 to 127 output values to the actual real number range of their outputs, but this process is unclear.\r\n\r\nTagging the @tensorflow/micro team."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes and no.\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.3 LTS\r\n- TensorFlow installed from (source or binary): I used `pip install tensorflow-gpu==2.0.0`\r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version: 3.7.5\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: 1080 TI and 11170 MiB\r\n\r\n**Describe the current behavior**\r\nFirst as discussed in this [issue](https://github.com/tensorflow/tensorflow/issues/18257). There is a bug in the first example of the documentation of `tf.while_loop`. \r\n\r\nThen, the parallel_iterations argument doesn't seem to parallelize the loop. There is no difference between the run time with `parallel_iterations = 1` or `parallel_iterations = 10`. \r\nI have a question opened on [Stackoverflow](https://stackoverflow.com/questions/59299060/tf-2-0-while-loop-and-parallel-iterations) .\r\n\r\n**Describe the expected behavior**\r\nIf the function in iteration n doesn't depend on previous iterations, then I expect that by setting `parallel_iterations = 10,` the loop should finish about 10 times faster than setting `parallel_iterations = 1`\r\n**Code to reproduce the issue**\r\nThe code is posted on the [Stackoverflow](https://stackoverflow.com/questions/59299060/tf-2-0-while-loop-and-parallel-iterations). \r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL with the issue: https://www.tensorflow.org/api_docs/python/tf/nn/ctc_loss\r\n\r\n## Description of issue:\r\nThere's no example provided for using this loss and I cannot make it work.\r\nFollowing the parameters definitions I created this toy example in tf2.0.0:\r\n\r\n```\r\nimport functools\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tensorflow.keras.models import Model\r\nfrom tensorflow.keras.layers import (Input, Conv2D, Lambda)\r\nfrom tensorflow.keras.optimizers import Adam\r\n\r\n# INPUTS\r\ninputs = Input(shape=[128, 64, 1], batch_size=32)    # [frames, num_labels, channels]\r\nlabels = Input(shape=[128], batch_size=32,  dtype=tf.int32)\r\nlabel_length = tf.constant(np.ones((32)), dtype=tf.int32)\r\nlogit_length = tf.constant(np.ones((32)),  dtype=tf.int32)\r\n# MODEL\r\nx = Conv2D(1, kernel_size=(5, 5),  padding='same')(inputs)\r\nlogits = Lambda(lambda z: tf.squeeze(z, [-1]))(x)\r\nmodel = Model(inputs, logits)\r\nmodel.compile(optimizer=Adam(lr=0.001), loss=tf.nn.ctc_loss(\r\n    labels=labels, logits=logits, label_length=label_length,\r\n    logit_length=logit_length, logits_time_major=False,\r\n    blank_index=-1\r\n))\r\n```\r\n\r\nwhich rises: \r\n\r\n```\r\n~/.virtualenvs/phd/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py in _apply_op_helper(self, op_type_name, name, **keywords)\r\n    469                 dtype=dtype if dtype else None,\r\n    470                 preferred_dtype=default_dtype,\r\n--> 471                 as_ref=input_arg.is_ref)\r\n    472             if input_arg.number_attr and len(\r\n    473                 set(v.dtype.base_dtype for v in values)) > 1:\r\n\r\n~/.virtualenvs/phd/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py in internal_convert_n_to_tensor(values, dtype, name, as_ref, preferred_dtype, ctx)\r\n   1363             as_ref=as_ref,\r\n   1364             preferred_dtype=preferred_dtype,\r\n-> 1365             ctx=ctx))\r\n   1366   return ret\r\n   1367\r\n\r\n~/.virtualenvs/phd/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx, accept_composite_tensors)\r\n   1262     graph = get_default_graph()\r\n   1263     if not graph.building_function:\r\n-> 1264       raise RuntimeError(\"Attempting to capture an EagerTensor without \"\r\n   1265                          \"building a function.\")\r\n   1266     return graph.capture(value, name=name)\r\n\r\nRuntimeError: Attempting to capture an EagerTensor without building a function.\r\n```\r\n\r\nThen, I tried to use it as a handle:\r\n\r\n```\r\nctc_loss = functools.partial(\r\n    tf.nn.ctc_loss,\r\n    labels,         # labels\r\n    logits,         # logits\r\n    label_length,   # label_length\r\n    logit_length,   # logit_length\r\n    False,          # logits_time_major\r\n    -1,             # blank_index\r\n)\r\nmodel.compile(optimizer=Adam(lr=0.001), loss=ctc_loss)\r\n```\r\n\r\nwhich rises:\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-147-2018e8450f34> in <module>\r\n----> 1 model.compile(optimizer=Adam(lr=0.001), loss=ctc_loss)\r\n\r\n~/.virtualenvs/phd/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)\r\n    455     self._self_setattr_tracking = False  # pylint: disable=protected-access\r\n    456     try:\r\n--> 457       result = method(self, *args, **kwargs)\r\n    458     finally:\r\n    459       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access\r\n\r\n~/.virtualenvs/phd/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py in compile(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\r\n    371\r\n    372       # Creates the model loss and weighted metrics sub-graphs.\r\n--> 373       self._compile_weights_loss_and_weighted_metrics()\r\n    374\r\n    375       # Functions for train, test and predict will\r\n\r\n~/.virtualenvs/phd/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)\r\n    455     self._self_setattr_tracking = False  # pylint: disable=protected-access\r\n    456     try:\r\n--> 457       result = method(self, *args, **kwargs)\r\n    458     finally:\r\n    459       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access\r\n\r\n~/.virtualenvs/phd/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py in _compile_weights_loss_and_weighted_metrics(self, sample_weights)\r\n   1651       #                   loss_weight_2 * output_2_loss_fn(...) +\r\n   1652       #                   layer losses.\r\n-> 1653       self.total_loss = self._prepare_total_loss(masks)\r\n   1654\r\n   1655   def _prepare_skip_target_masks(self):\r\n\r\n~/.virtualenvs/phd/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py in _prepare_total_loss(self, masks)\r\n   1732             # differentiate between use case where a custom optimizer\r\n   1733             # expects a vector loss value vs unreduced per-sample loss value.\r\n-> 1734             output_loss = loss_fn(y_true, y_pred, sample_weight=sample_weight)\r\n   1735             loss_reduction = losses_utils.ReductionV2.SUM_OVER_BATCH_SIZE\r\n   1736\r\n\r\nTypeError: ctc_loss_v2() got an unexpected keyword argument 'sample_weight'\r\n```\r\n\r\nThen, I tried to embed it:\r\n\r\n```\r\ndef my_ctc_loss(\r\n    labels, logits, label_length, logit_length, logits_time_major,\r\n    blank_index, sample_weight\r\n):\r\n    return tf.nn.ctc_loss(\r\n        labels=labels, logits=logits, label_length=label_length,\r\n        logit_length=logit_length, logits_time_major=logits_time_major,\r\n        blank_index=blank_index\r\n    )\r\n\r\n\r\nctc_loss_emb = functools.partial(\r\n    my_ctc_loss,\r\n    labels,         # labels\r\n    logits,         # logits\r\n    label_length,   # label_length\r\n    logit_length,   # logit_length\r\n    False,          # logits_time_major\r\n    -1,             # blank_index\r\n    None,           # sample_weight\r\n)\r\nmodel.compile(optimizer=Adam(lr=0.001), loss=ctc_loss_emb)\r\n```\r\nwhich rises: \r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-150-f20d10a91540> in <module>\r\n      9     None,           # sample_weight\r\n     10 )\r\n---> 11 model.compile(optimizer=Adam(lr=0.001), loss=ctc_loss_emb)\r\n\r\n~/.virtualenvs/phd/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)\r\n    455     self._self_setattr_tracking = False  # pylint: disable=protected-access\r\n    456     try:\r\n--> 457       result = method(self, *args, **kwargs)\r\n    458     finally:\r\n    459       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access\r\n\r\n~/.virtualenvs/phd/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py in compile(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\r\n    371\r\n    372       # Creates the model loss and weighted metrics sub-graphs.\r\n--> 373       self._compile_weights_loss_and_weighted_metrics()\r\n    374\r\n    375       # Functions for train, test and predict will\r\n\r\n~/.virtualenvs/phd/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)\r\n    455     self._self_setattr_tracking = False  # pylint: disable=protected-access\r\n    456     try:\r\n--> 457       result = method(self, *args, **kwargs)\r\n    458     finally:\r\n    459       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access\r\n\r\n~/.virtualenvs/phd/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py in _compile_weights_loss_and_weighted_metrics(self, sample_weights)\r\n   1651       #                   loss_weight_2 * output_2_loss_fn(...) +\r\n   1652       #                   layer losses.\r\n-> 1653       self.total_loss = self._prepare_total_loss(masks)\r\n   1654\r\n   1655   def _prepare_skip_target_masks(self):\r\n\r\n~/.virtualenvs/phd/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py in _prepare_total_loss(self, masks)\r\n   1732             # differentiate between use case where a custom optimizer\r\n   1733             # expects a vector loss value vs unreduced per-sample loss value.\r\n-> 1734             output_loss = loss_fn(y_true, y_pred, sample_weight=sample_weight)\r\n   1735             loss_reduction = losses_utils.ReductionV2.SUM_OVER_BATCH_SIZE\r\n   1736\r\n\r\nTypeError: my_ctc_loss() got multiple values for argument 'sample_weight'\r\n```\r\n\r\n### Usage example: Not provided\r\n\r\nSince it seems that ctc_loss has to be used differently from other losses, it will helpful to have an example that shows how to use it.\r\n\r\n### Raises listed and defined: Not defined\r\n\r\n\r\nThanks!"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nDoc Link:\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/callbacks/LearningRateScheduler\r\nCode Link:\r\nhttps://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/callbacks.py#L1311-L1358\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Parameters\r\n\r\nThe next API for `scheduler` parameter of `LearningRateScheduler` takes in 2 parameters, `epoch` and `lr` (learning rate) instead of just `epoch`, this is evident in the `on_epoch_begin` of the `LearningRateScheduler` method.\r\n\r\nThe documentation for this method is still outdated, the docs and the example code still shows the `scheduler` function takes in only `epoch` instead of both `epoch` and `lr`. I think the doc should be updated to reflect the new API.\r\n\r\nProposed change to the doc:\r\n\r\n1) update the description of `scheduler`: \r\n\r\n`\r\nschedule: a function that takes an epoch index as input (integer, indexed from 0) and current learning rate and returns a new learning rate as output (float).\r\n`\r\n(copied from the doc from keras.io)\r\n\r\n2) update the example usage to include a `scheduler` that utilize the current learning rate as well.\r\n\r\nI hope this is helpful! Happy to contribute if needed.\r\n\r\n### Submit a pull request? Yes, if this should be updated.\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "Greetings,\r\n\r\nWhile the document about [masking](https://www.tensorflow.org/guide/keras/masking_and_padding) is super good, I found it misses an important point: how the mask associated with the previous mask in compute_mask(input, previous_mask)\r\n\r\nSpecifically, let us assume we have two inputs A and B. I wrote a custom Add layers:\r\n\r\n```\r\nclass CustomAddingWithMasking(tf.keras.layers.Layer):\r\n    def __init__(self, masking_boolean, **kwargs):\r\n        super(CustomAddingWithMasking, self).__init__(**kwargs)\r\n\r\n    def call(self, inputs):\r\n        return inputs[0] + inputs[1]\r\n    \r\n    def compute_mask(self, inputs, mask=None):\r\n        return mask\r\n```\r\n\r\nHere, I want to compute the sum of two tensors. Let us also assume that A and B have their own masks, which could be different to each other. Because we technically have two \"previous masks\" (from A and B separately), I don't know how the mask parameter in compute_mask was received. Is it the OR (or AND?) operation between mask of A and mask of B?\r\n\r\nThose things are not clear as well as not documented well."
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback\r\n\r\n\r\n> on_epoch_end: logs include `acc` and `loss`, and\r\n>    optionally include `val_loss`\r\n>    (if validation is enabled in `fit`), and `val_acc`\r\n>    (if validation and accuracy monitoring are enabled).\r\n\r\nand\r\n\r\n> on_batch_end: logs include `loss`, and optionally `acc`\r\n\r\nThis is correct for the original Keras implementation. However, in tf2.keras callbacks get `accuracy` and `val_accuracy` instead of the short documented versions `acc`/`val_acc`. Either the implementation is wrong or the documentation.\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Hi, my name is Rachin Kalakheti and i am a participant of Google Code-in 2019. I felt overwhelmed to know Tensorflow is also one of the organization for this year. So, there was a task to create a notebook tutorial on Data Augmentation using tf.image. I see that currently there is no tutorial regarding the same topic. So, I would like to contribute to the community by adding my tutorial to the  Tensorflow repo. Therefore I am seeking guidance as to discuss this further.\r\nLink to my notebook tutorial: https://colab.research.google.com/drive/1skGIQhwifJY6HWO6ZnbFe4un-VuJ3VW5\r\n\r\nThank you!"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://github.com/tensorflow/tensorflow/blob/1cf0898dd4331baf93fe77205550f2c2e6c90ee5/tensorflow/python/keras/losses.py#L493\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe example will cause errors:\r\n\r\ncce = tf.keras.losses.SparseCategoricalCrossentropy()\r\nloss = cce(\r\n  [0, 1, 2],\r\n  [[.9, .05, .05], [.5, .89, .6], [.05, .01, .94]])\r\nprint('Loss: ', loss.numpy())  # Loss: 0.3239\r\n\r\nNeed to change to\r\n\r\ncce = tf.keras.losses.SparseCategoricalCrossentropy()\r\nloss = cce(\r\n  [0, 1, 2],\r\n  tf.constant([[.9, .05, .05], [.5, .89, .6], [.05, .01, .94]]))\r\nprint('Loss: ', loss.numpy())  # Loss: 0.3239\r\n\r\nIn addition [.5, .89, .6] should be [0.05, 0.89, 0.06] to be consistent with similar example (\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy?hl=en). Thus Loss should be updated to 0.0945\r\n\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): NO\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): mac os mojave 10.14.6\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below):  2.0.0\r\n- Python version: 2.7.10 \r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nI'm moving to TF 2.0 with its very nice dataset functionalities, but I got stuck when I want to save the model in the SavedModel format.\r\n\r\nI'm using the estimator class to do a linear regression, and after training this is how I'd set up the export in TF 1:\r\n```\r\ncolumns = [('hour', tf.int64),\r\n           ('domain', tf.string),\r\n           ('device_type', tf.string)]\r\nfeature_placeholders = {\r\n name: tf.placeholder(dtype, [1], name=name + \"_placeholder\")\r\n for name, dtype in columns\r\n}\r\n```\r\nI have three features with different datatypes, and I use the placeholder method to concatenate them into a dict that is then served using the tf.estimator.export.build_raw_serving_input_receiver_fn() method, and finally exported using the estimator.export_saved_model to my model directory:\r\n\r\n```\r\nexport_input_fn = tf.estimator.export.build_raw_serving_input_receiver_fn(\r\n    feature_placeholders)\r\nestimator.export_saved_model(model_dir, export_input_fn)\r\n```\r\nAll tutorials online uses this series of steps, but tf.placeholder() doesn't exist in TF 2.0, so how can I do this?\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): v1.12.1-16986-g6c32a22 2.1.0-dev20191029\r\n- Python version: 3.6.8\r\n\r\n**Describe the current behavior**\r\n`tf.keras.models.Sequential` doesn't support `run_eagarly` as mentioned in the [docs](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#run_eagerly).\r\n\r\n**Describe the expected behaviour**\r\nEither Sequential model accepts `run_eagarly` as a param and changes its behaviour, or we modify the docs. \r\n\r\n**Code to reproduce the issue**\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nmodel = tf.keras.models.Sequential(\r\n    layers=[tf.keras.layers.Dense(input_shape=(3, ), units=1)], \r\n    run_eagerly=True)\r\n```\r\n\r\n\r\n**Other info / logs**\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"tst.py\", line 5, in <module>\r\n    run_eagerly=True)\r\n  File \"/home/squadrick/.local/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\nTypeError: __init__() got an unexpected keyword argument 'run_eagerly'\r\n```"
  },
  {
    "labels": ["documentation"],
    "text": "Porting the original website from bootstrap3  to bootstrap4\r\n\r\nSection to change:\r\n- [ ] [_alumni.html](https://github.com/asetalias/asetalias.github.io/blob/master/templates/home-sections/_alumni.html)\r\n- [ ] [_events-participate.html](https://github.com/asetalias/asetalias.github.io/blob/master/templates/home-sections/_events-participate.html)\r\n- [ ] [_events.html](https://github.com/asetalias/asetalias.github.io/blob/master/templates/home-sections/_events.html)\r\n- [ ] [_home.html](https://github.com/asetalias/asetalias.github.io/blob/master/templates/home-sections/_home.html)\r\n- [ ] [_intro.html](https://github.com/asetalias/asetalias.github.io/blob/master/templates/home-sections/_intro.html)\r\n- [ ] [_open-source.html](https://github.com/asetalias/asetalias.github.io/blob/master/templates/home-sections/_open-source.html)\r\n- [ ] [_team.html](https://github.com/asetalias/asetalias.github.io/blob/master/templates/home-sections/_team.html)\r\n- [ ] [_webinars.html](https://github.com/asetalias/asetalias.github.io/blob/master/templates/home-sections/_webinars.html)\r\n\r\n\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/1cf0898dd4331baf93fe77205550f2c2e6c90ee5/tensorflow/python/keras/losses.py#L493\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nEntries [1,0] and [1,2] of a tensor linked to should be 10 times smaller in order for the second entry to sum up to 1.\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? \r\n\r\nNo, the change seems too small for an expensive TF CI to run. \r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution Ubuntu Linux 18.04 x64\r\n\r\n- TensorFlow installed from (source or binary): Installed from Anaconda\r\n\r\n- TensorFlow version (use command below):\r\n`python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\nunknown 2.0.0\r\nI am using TF 2.0.0.\r\n- Python version: python 3.7.4\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: Cuda release 10.1, V10.1.168; cudnn 7.6.0\r\n- GPU model and memory: Nvidia GTX 1080 11GB.\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nThis is both a code issue and a documentation problem--but mostly a code problem. \r\nI was looking at the tutorial(https://www.tensorflow.org/tutorials/structured_data/feature_columns#numeric_columns) and saw that the tutorial itself is generating warnings. So that suggests some problems in the code as well as the tutorial. \r\n\r\n**Describe the expected behavior**\r\n\r\nI would expect the tutorial to generate no warnings--and hence demonstrate proper code functionality. As it is, it is not clear whether the warnings are generated from a bug in the code, or from spurious warnings, etc. \r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n```\r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\n\r\nimport numpy as np\r\nimport pandas as pd\r\n\r\nimport tensorflow as tf\r\n\r\nfrom tensorflow import feature_column\r\nfrom tensorflow.keras import layers\r\nfrom sklearn.model_selection import train_test_split\r\n\r\nURL = 'https://storage.googleapis.com/applied-dl/heart.csv'\r\ndataframe = pd.read_csv(URL)\r\ntrain, test = train_test_split(dataframe, test_size=0.2)\r\ntrain, val = train_test_split(train, test_size=0.2)\r\nprint(len(train), 'train examples')\r\nprint(len(val), 'validation examples')\r\nprint(len(test), 'test examples')\r\n\r\ndef df_to_dataset(dataframe, shuffle=True, batch_size=32):\r\n  dataframe = dataframe.copy()\r\n  labels = dataframe.pop('target')\r\n  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\r\n  if shuffle:\r\n    ds = ds.shuffle(buffer_size=len(dataframe))\r\n  ds = ds.batch(batch_size)\r\n  return ds\r\n\r\nbatch_size = 5 # A small batch sized is used for demonstration purposes\r\ntrain_ds = df_to_dataset(train, batch_size=batch_size)\r\nval_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\r\ntest_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)\r\n\r\n# We will use this batch to demonstrate several types of feature columns\r\nexample_batch = next(iter(train_ds))[0]\r\n\r\n# A utility method to create a feature column\r\n# and to transform a batch of data\r\ndef demo(feature_column):\r\n  feature_layer = layers.DenseFeatures(feature_column)\r\n  print(feature_layer(example_batch).numpy())\r\n\r\nage = feature_column.numeric_column(\"age\")\r\ndemo(age) # <-- SHOULD TRIGGER OR DISPLAY THE WARNING\r\n```\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\nNo other materials provided."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/tensorboard/tensorboard_profiling_keras#other_ways_for_profiling\r\n\r\n## Description of the issue (what needs changing):\r\n\r\nThe guide presents the profiler API and service as other ways of profiling.\r\nBoth of these use modules inside the `tensorflow.python` package.\r\nHowever, this package does not seem to exist as exhibited by the error message:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-14-c7b3d51d1060> in <module>()\r\n----> 1 with tf.python.eager.profiler.Profiler('logdir_path'):\r\n      2   # do your training here\r\n      3   pass\r\n      4 \r\n      5 \r\n\r\nAttributeError: module 'tensorflow' has no attribute 'python'\r\n```\r\n\r\n### Submit a pull request?\r\n\r\nI would be pleased to submit a pull request, but do not know if there is any TF2.0 compatible way to use profile API or service."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/Attention\r\n\r\n## Description of issue (what needs changing):\r\nIn the code example, it currently reads:\r\n```python\r\n# Variable-length int sequences.\r\nquery_input = tf.keras.Input(shape=(None,), dtype='int32')\r\nvalue_input = tf.keras.Input(shape=(None,), dtype='int32')\r\n\r\n# Embedding lookup.\r\ntoken_embedding = tf.keras.layers.Embedding(max_tokens, dimension)\r\n# Query embeddings of shape [batch_size, Tq, dimension].\r\nquery_embeddings = token_embedding(query_input)\r\n# Value embeddings of shape [batch_size, Tv, dimension].\r\nvalue_embeddings = token_embedding(query_input)\r\n```\r\n\r\nThe last line should instead be:\r\n```\r\nvalue_embeddings = token_embedding(value_input)\r\n```"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue: N/A\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/install/source\r\n\r\n## Description of issue (what needs changing): Please add Tested build configurations for Tensorflow 1.15 and Tensorflow 1.15-gpu\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\nI cannot find the test build configurations for Tensorflow 1.15. It is useful for someone who is trying to build Tensorflow 1.15. \r\n\r\n\r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/StackedRNNCells\r\n\r\n## Description of issue (what needs changing):\r\n\r\nDocumentation example does not actually use `StackedRNNCells`. There is no example for the class being documented. Ideally there would be both an example of the class and an example showing how the same behaviour would be implemented without the class.\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "\r\n##  URL(s) with the issue:\r\nhttps://www.tensorflow.org/install/docker\r\n\r\n## Documentation page with the issue:\r\nhttps://www.tensorflow.org/install/docker\r\n\r\n## Description of issue (what needs changing):\r\nSince the latest docker builds are now tensorflow v2.x instead of v1.x the python example script on this page doesn't work out of the box. If the user copy and pastes the commands from this page they'll get a \"AttributeError: module 'tensorflow' has no attribute 'enable_eager_execution'\" error when trying to verify their docker container.\r\nThe python example script can be changing to this to fix it:\r\n\r\n```\r\nimport tensorflow.compat.v1 as tf\r\ntf.enable_eager_execution();\r\nprint(tf.reduce_sum(tf.random_normal([1000, 1000])))\r\n```\r\n\r\nA better alternative however would be to change it to a TF v2.0 native example.\r\n\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "Hi.\r\nI'm trying to find a way in the \"benchmark_params.json\":\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/benchmark/ios/README.md\r\n\r\nTo define multiple inputs to the network. Is it even possible?\r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Greetings,\r\n\r\nI expected embedding layer gives an error when a word id is beyond the fixed pre-determined vocab size. Nonetheless, it is not the case as tf.nn.embedding_lookup automatically return 0 for an out-of-vocab index. While this is nice, it is risky because there is no information or anything like that from the website https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding. I personally did not know that until digging to the code carefully.\r\n\r\nSo I think more information at the website should be updated.\r\n\r\nExample code to see how embedding_lookup returns output:\r\n\r\n>>> sess = tf.compat.v1.InteractiveSession()\r\n>>> params = tf.constant([10,20,30,40])\r\n>>> ids = tf.constant([0,1,2,3,4,5])\r\n>>> tf.nn.embedding_lookup(params,ids).eval()\r\narray([10, 20, 30, 40,  0,  0], dtype=int32)"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/constant_initializer#used_in_the_tutorials\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/api_docs/python/tf/constant_initializer#used_in_the_tutorials\r\n\r\n## Description of issue (what needs changing):\r\nPlease fix the example section of tf.constant_initialize\r\n### Clear description\r\nExamples section of the page is not properly compiled making it unreadable\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "This [line](https://github.com/tensorflow/tensorflow/blob/1cf0898dd4331baf93fe77205550f2c2e6c90ee5/tensorflow/python/keras/layers/dense_attention.py#L241) and this [one](https://github.com/tensorflow/tensorflow/blob/1cf0898dd4331baf93fe77205550f2c2e6c90ee5/tensorflow/python/keras/layers/dense_attention.py#L368) should be:\r\n```\r\nvalue_embeddings = token_embedding(value_input)\r\n```\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/activations/tanh\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe arguments section of the tanh activation documentation is not formatted correctly.\r\n\r\nI am uncertain as to why, but suspect it may be due to a lack of a newline after the example block ([code here](https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/activations.py#L201-L221))\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/io/TFRecordWriter\r\n\r\n## Description of issue:\r\n\r\nSo I've been using TFRecordWriter for a while now and I would be interested in the method it writes to files. If I create two TFRecord files with the exact same name what is the default wrtiing option? `append` or `(re)write`? It would be crucial to know this in my use case. Thanks in advance."
  },
  {
    "labels": ["documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/community/contribute/docs \r\n\r\n## Description of issue (what needs changing):\r\nDocumentation under \"Interactive notebooks\" needs to be modified to accommodate issues created after direct editing of Jupyter Notebook in Colab.\r\n  \r\n\r\n### Clear description. \r\n\r\nDirect editing (on colab or using VSCode) Jupyter Notebook and committing as mentioned [here](https://www.tensorflow.org/community/contribute/docs) adds additional unintended changes like prettifying and escapes unicode symbols. \r\n\r\nFor example, see here: https://github.com/tensorflow/docs/pull/1238 \r\n\r\nRelated code commit : https://github.com/copperwiring/docs/commit/98f35604617d1ecc93b3dc75ac6ec4ab108536eb \r\n\r\n### Correct links\r\n\r\nYes\r\n\r\n### Parameters defined\r\n\r\nN/A\r\n\r\n### Returns defined\r\n\r\nN/A\r\n\r\n### Raises listed and defined\r\n\r\nNone.\r\n\r\n### Usage example\r\n\r\nIt is useful and needed for any PR request for Jupyter Notebook\r\n\r\n### Request visuals, if applicable\r\n\r\nN/A\r\n\r\n### Submit a pull request?\r\n\r\nI am planning to submit a PR to improve the documentation.\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue: \r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/tutorials/keras/classification/ \r\n\r\n## Description of issue (what needs changing):\r\nOne of the first step-by-step tutorial which explains a neural network is on Basic Classification [here](https://www.tensorflow.org/tutorials/keras/classification/). However, it can benefit from additional explanations on few terms like overfitting, optimizer etc.  \r\n\r\n### Clear description\r\nWe add one line description for *overfitting*  to help user get a first hand idea of what *overfitting* does. Later, we add an extra line with a link to TensorFlow definition of overfit where user can find more information. The suggested changes  are expected to make it easier for users to get an intuitive understanding of the term.\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct? Yes\r\n\r\n### Submit a pull request? \r\n\r\nYes.\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n\r\nRewriting SECURITY.md with technical writing for better understanding."
  },
  {
    "labels": ["documentation"],
    "text": "Description of Tensorflow in README.md can be more descriptive."
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/nn/ctc_loss\r\n\r\n## Description of issue (what needs changing):\r\nThe logits and logits_time_major parameters are ill defined.\r\n### Current on docs\r\n* logits: tensor of shape [frames, batch_size, num_labels], if logits_time_major == False, shape is [batch_size, frames, num_labels].\r\n* logits_time_major: (optional) If True (default), logits is shaped [time, batch, logits]. If False, shape is [batch, time, logits]\r\n\r\n### Clear description\r\n* logits: tensor of shape [time, batch_size, num_labels], if logits_time_major == True. Shape is [batch_size, frames, num_labels] if logits_time_major == False.\r\n* logits_time_major: (optional) If True (default), logits is shaped [time, batch_size, num_labels]. If False, shape is [batch_size, time, num_labels]\r\n\r\n### Submit a pull request?\r\nI'm preparing a PR\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "In tensorflow website, it describes tf.losses.cosine_simialrity as follows:\r\nNote that it is a negative quantity between -1 and 0, where 0 indicates orthogonality and values closer to -1 indicate greater similarity. \r\nIn fact, the quantity is from 1. to -1., it just takes a negative from normal cosine_similarity.\r\nThe page is at\r\nhttps://tensorflow.google.cn/api_docs/python/tf/keras/losses/cosine_similarity"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nProblem 1:\r\nCould you provides the math model of the rnn?\r\n\r\nProblem 2:   this is not return information about  the method of \r\nget_initial_state(inputs=None, batch_size=None, dtype=None).\r\nand \r\nhow to define own get_initial_state ?\r\nwhat is the connect between   state_size  and get_initial_state\r\nProblem 3, \r\ncould  you write more clear about  arguments  of the methods:  call, build, get_initial_state,\r\nsuch as the   dimension of them.  each dimension is what .\r\n\r\nProblem 4:\r\nis the  cell  defined layer by user ?\r\n\r\nthanks! \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n \r\n\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nHi there, i want to use the StagingArea structure by using 'from tensorflow.contrib.staging import StagingArea' in old version. How could i use it in tf2, and i see the definition is here :tensorflow/python/ops/data_flow_ops.py\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md\r\n\r\n## Description of issue (what needs changing):\r\n\r\nNon functioning link in the documentation:\r\n\r\n```\r\n### Custom Training Data\r\nBy default the script will download the [Speech Commands\r\ndataset](https://download.tensorflow.org/data/speech_commands_v0.01.tgz)\r\n```\r\n\r\nhttps://download.tensorflow.org/data/speech_commands_v0.01.tgz leads to a non working page. "
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): binary pip \r\n- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0\r\n- Python version: 3.6.5\r\n- CUDA/cuDNN version: CUDA 10.1 cuDNN 7.6.2.24\r\n- GPU model and memory: Quadro P2000\r\n\r\n**Describe the current behavior**\r\n\r\nWhen creating a ragged tensor by using `tf.ragged.stack` on several regular tensors on the 0-th axis, the function crashes when the rank of the input tensors is 1.\r\n\r\n**Describe the expected behavior**\r\n\r\nAccording to the [documentation](https://www.tensorflow.org/api_docs/python/tf/ragged/stack): `Given a list of tensors or ragged tensors with the same rank R (R >= axis) [...]`. Here, R=1 and  axis=0, so the preconditions should be fulfilled.\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\ntf.ragged.stack([[1, 2, 3], [1, 2]], axis=0)\r\n```\r\n\r\n**Other info / logs**\r\nCalling the 2 lines above results in:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/veith/Projects/venvs/anontf2/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-14-488f6e6430bd>\", line 1, in <module>\r\n    tf.ragged.stack([[1, 2, 3], [1, 2]], axis=0)\r\n  File \"/home/veith/Projects/venvs/anontf2/lib/python3.6/site-packages/tensorflow_core/python/ops/ragged/ragged_concat_ops.py\", line 113, in stack\r\n    return _ragged_stack_concat_helper(values, axis, stack_values=True)\r\n  File \"/home/veith/Projects/venvs/anontf2/lib/python3.6/site-packages/tensorflow_core/python/ops/ragged/ragged_concat_ops.py\", line 167, in _ragged_stack_concat_helper\r\n    return array_ops.stack(rt_inputs, axis)\r\n  File \"/home/veith/Projects/venvs/anontf2/lib/python3.6/site-packages/tensorflow_core/python/util/dispatch.py\", line 180, in wrapper\r\n    return target(*args, **kwargs)\r\n  File \"/home/veith/Projects/venvs/anontf2/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py\", line 1154, in stack\r\n    return ops.convert_to_tensor(values, name=name)\r\n  File \"/home/veith/Projects/venvs/anontf2/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 1184, in convert_to_tensor\r\n    return convert_to_tensor_v2(value, dtype, preferred_dtype, name)\r\n  File \"/home/veith/Projects/venvs/anontf2/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 1242, in convert_to_tensor_v2\r\n    as_ref=False)\r\n  File \"/home/veith/Projects/venvs/anontf2/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 1296, in internal_convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/home/veith/Projects/venvs/anontf2/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py\", line 1278, in _autopacking_conversion_function\r\n    return _autopacking_helper(v, dtype, name or \"packed\")\r\n  File \"/home/veith/Projects/venvs/anontf2/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py\", line 1184, in _autopacking_helper\r\n    return gen_array_ops.pack(list_or_tuple, name=name)\r\n  File \"/home/veith/Projects/venvs/anontf2/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_array_ops.py\", line 6293, in pack\r\n    _six.raise_from(_core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Shapes of all inputs must match: values[0].shape = [3] != values[1].shape = [2] [Op:Pack] name: stack\r\n```\r\n\r\n**Workaround**\r\n\r\nExpanding the rank-1 tensors to rank-2 tensors followed by squeezing the redundant dimension seems to work:\r\n```python\r\nimport tensorflow as tf\r\nx = tf.ragged.stack([[[1, 2, 3]], [[1, 2]]], axis=0)\r\nprint(x.bounding_shape())  # <tf.Tensor: id=929, shape=(3,), dtype=int64, numpy=array([2, 1, 3])>\r\nx = tf.squeeze(x, axis=1) \r\nprint(x.bounding_shape())  # <tf.Tensor: id=1109, shape=(2,), dtype=int64, numpy=array([2, 3])>\r\n```\r\n\r\n**Estimated cause**\r\n\r\nI did not check the tensorflow source code for this, but the [general ragged documentation](https://www.tensorflow.org/guide/ragged_tensor#ragged_tensors_definitions) states:\r\n![image](https://user-images.githubusercontent.com/12949211/69247798-544f0780-0bab-11ea-8ff0-3f6626a8e2f8.png)\r\nI assume the issue is that there is no uniform dimension in the regular tensors before stacking them. Intuitively I would have assumed that I can use `tf.ragged.stack` to create this uniform dimension to form a ragged tensor from several non-ragged different-dimension tensors as above, similar to the regulat `tf.stack`, which creates a new dimension.\r\nI am not sure whether this is considered a bug or an error in the documentation of `tf.ragged.stack`, but it feels like a bug from a user perspective."
  },
  {
    "labels": [null, "documentation"],
    "text": "Hi!\r\n\r\nWe followed the [guide](https://www.tensorflow.org/lite/guide/ops_select#ios), which seems bit outdated as `tensorflow/contrib` has been removed. We couldn't get TFLite model with select ops working on iOS, while the same model is working well on Android. It seems that bazel could also be used for building the library together with using private CocoaPods. We tested this approach but were also unsuccessful. Could the documentation be improved with this regard for having clearer guidelines?\r\n\r\nIdeas and explanations of how to get it working are also welcome under this issue. Do you have an estimation when could we expect the CocoaPods (with-select-ops version) for iOS/Swift?\r\n\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/lite/guide/ops_select#ios\r\n\r\n## Description of issue (what needs changing):\r\nThe current guide could be improved, especially because `tensorflow/contrib` is removed in the latest version of TensorFlow. Therefore, `tensorflow/contrib/makefile/build_all_ios_with_tflite.sh` is no longer available for building TensorFlow Lite with select ops support.\r\n\r\n### Clear description\r\nCouldn't get a TFLite model with select ops working in iOS by following the [guide](https://www.tensorflow.org/lite/guide/ops_select#ios). The same model was successfully working on Android with nightly builds. Would be nice to have a guide for how to build it with bazel.\r\n\r\n### Correct links\r\nN/A\r\n\r\n### Parameters defined\r\nN/A\r\n\r\n### Returns defined\r\nN/A\r\n\r\n### Raises listed and defined\r\nN/A\r\n\r\n### Usage example\r\nWould be good if it would be explained in more detail what has to be done. Do we only have to compile and link libraries as explained in the documentation or do we need to modify the code also, e.g. add Flex delegate as an option for Interpreter?\r\n\r\n### Request visuals, if applicable\r\nNo need for visuals\r\n\r\n### Submit a pull request?\r\nN/A"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "https://github.com/tensorflow/tensorflow/blob/ba63d9082a2265da91ec4daefecfa4cd47fcf07f/tensorflow/examples/speech_commands/models.py#L337-L339\r\n\r\nBut the stride is actually **one** instead of **four**:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/ba63d9082a2265da91ec4daefecfa4cd47fcf07f/tensorflow/examples/speech_commands/models.py#L388-L389\r\n\r\nwhich results in a **huge** increase of the number of parameters of the subsequent FC layer."
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": " - python version: 3.6.7\r\n - tensorflow-gpu version: 2.0.0 \r\n - keras version: 2.3.1 \r\n - cuDNN version:10.0 \r\n - CUDA version:10.0\r\n\r\n\r\nmnist_mlp.py (https://github.com/keras-team/keras/blob/master/examples/mnist_mlp.py) works perfectly but code which is given below gives me this error:\r\n\r\n```\r\n    tensorflow.python.framework.errors_impl.UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n             [[node conv2d_7/convolution (defined at C:\\Users\\ACSECKIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1751) ]] [Op:__inference_keras_scratch_graph_4815]\r\n    \r\n    Function call stack:\r\n    keras_scratch_graph\r\n```\r\n\r\nProject code derived from https://machinelearningmastery.com/how-to-develop-a-pix2pix-gan-for-image-to-image-translation/\r\n\r\ncode:\r\n\r\n    ```\r\n    from numpy import load\r\n    from numpy import zeros\r\n    from numpy import ones\r\n    from numpy.random import randint\r\n    from keras.optimizers import Adam\r\n    from keras.initializers import RandomNormal\r\n    from keras.models import Model\r\n    from keras.models import Input\r\n    from keras.layers import Conv2D\r\n    from keras.layers import Conv2DTranspose\r\n    from keras.layers import LeakyReLU\r\n    from keras.layers import Activation\r\n    from keras.layers import Concatenate\r\n    from keras.layers import Dropout\r\n    from keras.layers import BatchNormalization\r\n    from keras.layers import LeakyReLU\r\n    from matplotlib import pyplot\r\n    \r\n    # define the discriminator model\r\n    def define_discriminator(image_shape):\r\n    \t# weight initialization\r\n    \tinit = RandomNormal(stddev=0.02)\r\n    \t# source image input\r\n    \tin_src_image = Input(shape=image_shape)\r\n    \t# target image input\r\n    \tin_target_image = Input(shape=image_shape)\r\n    \t# concatenate images channel-wise\r\n    \tmerged = Concatenate()([in_src_image, in_target_image])\r\n    \t# C64\r\n    \td = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\r\n    \td = LeakyReLU(alpha=0.2)(d)\r\n    \t# C128\r\n    \td = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\r\n    \td = BatchNormalization()(d)\r\n    \td = LeakyReLU(alpha=0.2)(d)\r\n    \t# C256\r\n    \td = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\r\n    \td = BatchNormalization()(d)\r\n    \td = LeakyReLU(alpha=0.2)(d)\r\n    \t# C512\r\n    \td = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\r\n    \td = BatchNormalization()(d)\r\n    \td = LeakyReLU(alpha=0.2)(d)\r\n    \t# second last output layer\r\n    \td = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\r\n    \td = BatchNormalization()(d)\r\n    \td = LeakyReLU(alpha=0.2)(d)\r\n    \t# patch output\r\n    \td = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\r\n    \tpatch_out = Activation('sigmoid')(d)\r\n    \t# define model\r\n    \tmodel = Model([in_src_image, in_target_image], patch_out)\r\n    \t# compile model\r\n    \topt = Adam(lr=0.0002, beta_1=0.5)\r\n    \tmodel.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\r\n    \treturn model\r\n    \r\n    # define an encoder block\r\n    def define_encoder_block(layer_in, n_filters, batchnorm=True):\r\n    \t# weight initialization\r\n    \tinit = RandomNormal(stddev=0.02)\r\n    \t# add downsampling layer\r\n    \tg = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\r\n    \t# conditionally add batch normalization\r\n    \tif batchnorm:\r\n    \t\tg = BatchNormalization()(g, training=True)\r\n    \t# leaky relu activation\r\n    \tg = LeakyReLU(alpha=0.2)(g)\r\n    \treturn g\r\n    \r\n    # define a decoder block\r\n    def decoder_block(layer_in, skip_in, n_filters, dropout=True):\r\n    \t# weight initialization\r\n    \tinit = RandomNormal(stddev=0.02)\r\n    \t# add upsampling layer\r\n    \tg = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\r\n    \t# add batch normalization\r\n    \tg = BatchNormalization()(g, training=True)\r\n    \t# conditionally add dropout\r\n    \tif dropout:\r\n    \t\tg = Dropout(0.5)(g, training=True)\r\n    \t# merge with skip connection\r\n    \tg = Concatenate()([g, skip_in])\r\n    \t# relu activation\r\n    \tg = Activation('relu')(g)\r\n    \treturn g\r\n    \r\n    # define the standalone generator model\r\n    def define_generator(image_shape=(256,256,3)):\r\n    \t# weight initialization\r\n    \tinit = RandomNormal(stddev=0.02)\r\n    \t# image input\r\n    \tin_image = Input(shape=image_shape)\r\n    \t# encoder model\r\n    \te1 = define_encoder_block(in_image, 64, batchnorm=False)\r\n    \te2 = define_encoder_block(e1, 128)\r\n    \te3 = define_encoder_block(e2, 256)\r\n    \te4 = define_encoder_block(e3, 512)\r\n    \te5 = define_encoder_block(e4, 512)\r\n    \te6 = define_encoder_block(e5, 512)\r\n    \te7 = define_encoder_block(e6, 512)\r\n    \t# bottleneck, no batch norm and relu\r\n    \tb = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e7)\r\n    \tb = Activation('relu')(b)\r\n    \t# decoder model\r\n    \td1 = decoder_block(b, e7, 512)\r\n    \td2 = decoder_block(d1, e6, 512)\r\n    \td3 = decoder_block(d2, e5, 512)\r\n    \td4 = decoder_block(d3, e4, 512, dropout=False)\r\n    \td5 = decoder_block(d4, e3, 256, dropout=False)\r\n    \td6 = decoder_block(d5, e2, 128, dropout=False)\r\n    \td7 = decoder_block(d6, e1, 64, dropout=False)\r\n    \t# output\r\n    \tg = Conv2DTranspose(3, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d7)\r\n    \tout_image = Activation('tanh')(g)\r\n    \t# define model\r\n    \tmodel = Model(in_image, out_image)\r\n    \treturn model\r\n    \r\n    # define the combined generator and discriminator model, for updating the generator\r\n    def define_gan(g_model, d_model, image_shape):\r\n    \t# make weights in the discriminator not trainable\r\n    \td_model.trainable = False\r\n    \t# define the source image\r\n    \tin_src = Input(shape=image_shape)\r\n    \t# connect the source image to the generator input\r\n    \tgen_out = g_model(in_src)\r\n    \t# connect the source input and generator output to the discriminator input\r\n    \tdis_out = d_model([in_src, gen_out])\r\n    \t# src image as input, generated image and classification output\r\n    \tmodel = Model(in_src, [dis_out, gen_out])\r\n    \t# compile model\r\n    \topt = Adam(lr=0.0002, beta_1=0.5)\r\n    \tmodel.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1,100])\r\n    \treturn model\r\n    \r\n    # load and prepare training images\r\n    def load_real_samples(filename):\r\n    \t# load compressed arrays\r\n    \tdata = load(filename)\r\n    \t# unpack arrays\r\n    \tX1, X2 = data['arr_0'], data['arr_1']\r\n    \t# scale from [0,255] to [-1,1]\r\n    \tX1 = (X1 - 127.5) / 127.5\r\n    \tX2 = (X2 - 127.5) / 127.5\r\n    \treturn [X1, X2]\r\n    \r\n    # select a batch of random samples, returns images and target\r\n    def generate_real_samples(dataset, n_samples, patch_shape):\r\n    \t# unpack dataset\r\n    \ttrainA, trainB = dataset\r\n    \t# choose random instances\r\n    \tix = randint(0, trainA.shape[0], n_samples)\r\n    \t# retrieve selected images\r\n    \tX1, X2 = trainA[ix], trainB[ix]\r\n    \t# generate 'real' class labels (1)\r\n    \ty = ones((n_samples, patch_shape, patch_shape, 1))\r\n    \treturn [X1, X2], y\r\n    \r\n    # generate a batch of images, returns images and targets\r\n    def generate_fake_samples(g_model, samples, patch_shape):\r\n    \t# generate fake instance\r\n    \tX = g_model.predict(samples)\r\n    \t# create 'fake' class labels (0)\r\n    \ty = zeros((len(X), patch_shape, patch_shape, 1))\r\n    \treturn X, y\r\n    \r\n    # generate samples and save as a plot and save the model\r\n    def summarize_performance(step, g_model, dataset, n_samples=3):\r\n    \t# select a sample of input images\r\n    \t[X_realA, X_realB], _ = generate_real_samples(dataset, n_samples, 1)\r\n    \t# generate a batch of fake samples\r\n    \tX_fakeB, _ = generate_fake_samples(g_model, X_realA, 1)\r\n    \t# scale all pixels from [-1,1] to [0,1]\r\n    \tX_realA = (X_realA + 1) / 2.0\r\n    \tX_realB = (X_realB + 1) / 2.0\r\n    \tX_fakeB = (X_fakeB + 1) / 2.0\r\n    \t# plot real source images\r\n    \tfor i in range(n_samples):\r\n    \t\tpyplot.subplot(3, n_samples, 1 + i)\r\n    \t\tpyplot.axis('off')\r\n    \t\tpyplot.imshow(X_realA[i])\r\n    \t# plot generated target image\r\n    \tfor i in range(n_samples):\r\n    \t\tpyplot.subplot(3, n_samples, 1 + n_samples + i)\r\n    \t\tpyplot.axis('off')\r\n    \t\tpyplot.imshow(X_fakeB[i])\r\n    \t# plot real target image\r\n    \tfor i in range(n_samples):\r\n    \t\tpyplot.subplot(3, n_samples, 1 + n_samples*2 + i)\r\n    \t\tpyplot.axis('off')\r\n    \t\tpyplot.imshow(X_realB[i])\r\n    \t# save plot to file\r\n    \tfilename1 = 'plot_%06d.png' % (step+1)\r\n    \tpyplot.savefig(filename1)\r\n    \tpyplot.close()\r\n    \t# save the generator model\r\n    \tfilename2 = 'model_%06d.h5' % (step+1)\r\n    \tg_model.save(filename2)\r\n    \tprint('>Saved: %s and %s' % (filename1, filename2))\r\n    \r\n    # train pix2pix models\r\n    def train(d_model, g_model, gan_model, dataset, n_epochs=50, n_batch=1):\r\n    \t# determine the output square shape of the discriminator\r\n    \tn_patch = d_model.output_shape[1]\r\n    \t# unpack dataset\r\n    \ttrainA, trainB = dataset\r\n    \t# calculate the number of batches per training epoch\r\n    \tbat_per_epo = int(len(trainA) / n_batch)\r\n    \t# calculate the number of training iterations\r\n    \tn_steps = bat_per_epo * n_epochs\r\n    \t# manually enumerate epochs\r\n    \tfor i in range(n_steps):\r\n    \t\t# select a batch of real samples\r\n    \t\t[X_realA, X_realB], y_real = generate_real_samples(dataset, n_batch, n_patch)\r\n    \t\t# generate a batch of fake samples\r\n    \t\tX_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\r\n    \t\t# update discriminator for real samples\r\n    \t\td_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)\r\n    \t\t# update discriminator for generated samples\r\n    \t\td_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\r\n    \t\t# update the generator\r\n    \t\tg_loss, _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])\r\n    \t\t# summarize performance\r\n    \t\tprint('>%d, d1[%.3f] d2[%.3f] g[%.3f]' % (i+1, d_loss1, d_loss2, g_loss))\r\n    \t\t# summarize model performance\r\n    \t\tif (i+1) % (bat_per_epo * 10) == 0:\r\n    \t\t\tsummarize_performance(i, g_model, dataset)\r\n    \r\n    \r\n    # load image data\r\n    dataset = load_real_samples('fabric_256.npz')\r\n    print('Loaded', dataset[0].shape, dataset[1].shape)\r\n    # define input shape based on the loaded dataset\r\n    image_shape = dataset[0].shape[1:]\r\n    # define the models\r\n    d_model = define_discriminator(image_shape)\r\n    g_model = define_generator(image_shape)\r\n    # define the composite model\r\n    gan_model = define_gan(g_model, d_model, image_shape)\r\n    # train model\r\n    train(d_model, g_model, gan_model, dataset)\r\n\r\n```\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "I'm really confused about what preprocessing to apply on image data when working with pre-trained models for transfer learning. Of course, this is very specific for each model, but I thought Keras brought some disambiguation by bringing the _**preprocess_input**_ function. By using it, users should normally not worry about how to transform an image before pushing it into the pre-trained model.\r\n\r\nI recently tried to use one of such model provided in Tensorflow 2.Keras. Even if this function exists, the related documentation is, let's say, minimal:\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/applications/mobilenet_v2/preprocess_input\r\n\r\nBut what is very disturbing is that this function is not used at all in the provided tutorials. For example, this one (https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub) pre-processes images by dividing raw pixels by 255.\r\n\r\n> image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\r\n\r\nIn this other tutorial (https://www.tensorflow.org/tutorials/images/transfer_learning), pre-processing is done like this: \r\n\r\n> image = (image/127.5) - 1\r\n\r\nHowever, both tutorial are supposed to use a **mobilenet_v2** model pre-trained on _ImageNet_\r\n\r\nThis makes **3 different ways to process an image**, without any helping documentation to shed some light on what appears to me like \"black magic\". Any help would be welcome, along with an appropriate documentation of course.\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/Model#fit\r\n\r\n## Description of issue (what needs changing):\r\nI think we need a description of how the loss is computed when (temporal) sample_weights are applied, i.e. how is the loss aggregated across samples/time-steps. As addressed in #25178, the behaviour has even changed over time in the external version of Keras from ignoring zero-values to counting them making the situation confusing. \r\n\r\nEven if I agree the current implementation is the right one, I think it is far from intuitive, especially when using zero-weighted zero-padding which decreases the loss value and the effective learning rate.\r\n\r\nI am not very familiar with the structure to be followed in the build-in TF.Keras documentation, but this could be also specified elsewhere than in the `fit` method doc which is already pretty dense.\r\n\r\nSorry if this is specified elsewhere in the doc but I can't find it so if it exists, it should maybe be referenced in the `fit` doc.\r\nThanks a lot,\r\nEmilien"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/install/pip\r\n\r\n## Description of issue (what needs changing):\r\nIt says tensorflow 1.15 is final version for 1xx versions yet pip install 1.15 returns this\r\n\r\n\"$ pip3 install tensorflow==1.15\r\nCollecting tensorflow==1.15\r\n  Could not find a version that satisfies the requirement tensorflow==1.15 (from versions: 0.12.1, 1.0.0, 1.0.1, 1.1.0rc0, 1.1.0rc1, 1.1.0rc2, 1.1.0, 1.2.0rc0, 1.2.0rc1, 1.2.0rc2, 1.2.0, 1.2.1, 1.3.0rc0, 1.3.0rc1, 1.3.0rc2, 1.3.0, 1.4.0rc0, 1.4.0rc1, 1.4.0, 1.4.1, 1.5.0rc0, 1.5.0rc1, 1.5.0, 1.5.1, 1.6.0rc0, 1.6.0rc1, 1.6.0, 1.7.0rc0, 1.7.0rc1, 1.7.0, 1.7.1, 1.8.0rc0, 1.8.0rc1, 1.8.0, 1.9.0rc0, 1.9.0rc1, 1.9.0rc2, 1.9.0, 1.10.0rc0, 1.10.0rc1, 1.10.0, 1.10.1, 1.11.0rc0, 1.11.0rc1, 1.11.0rc2, 1.11.0, 1.12.0rc0, 1.12.0rc1, 1.12.0rc2, 1.12.0, 1.12.2, 1.12.3, 1.13.0rc0, 1.13.0rc1, 1.13.0rc2, 1.13.1, 1.13.2, 1.14.0rc0, 1.14.0rc1, 1.14.0, 2.0.0a0, 2.0.0b0, 2.0.0b1)\r\nNo matching distribution found for tensorflow==1.15\r\n\"\r\n\r\n\r\nIt should be corrected I think.\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "Hello\r\nfrom the tflite conv.cc , I can see that now tflite supports Per-channel quantize , is there any guide or doc how to use per-channel quantize when convert tf model to tflite?"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "Should be value_input?\r\n\r\nThank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/Attention\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams\r\n\r\n## Description of issue (what needs changing):\r\nIn the documentation it's nowhere written how to tune learning rate hyper-parameter for different optimisation algorithms. Plus the code in file **python3.6/site-packages/tensorboard/plugins/hparams/summary_v2.py** says,\r\n`if dtype not in (int, float, bool, str):\r\n--> 482       raise ValueError(\"Unknown dtype: %r\" % (dtype,))` \r\n\r\nI am trying to create HParam list \r\n\r\n`hp_optimizer = hp.HParam('optimizer', hp.Discrete([optimizers.Adam(learning_rate=0.001),\r\n                                                   optimizers.Adam(learning_rate=0.0001),\r\n                                                   optimizers.Adamax(learning_rate=0.001),\r\n                                                   optimizers.Adamax(learning_rate=0.0001),\r\n                                                   optimizers.SGD(learning_rate=0.01),\r\n                                                   optimizers.SGD(learning_rate=0.001)]))`\r\n\r\n### Clear description\r\nHow should someone tune learning rate?"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense \r\n\r\n## Description of issue (what needs changing):\r\nThe tf.keras.layers.Dense can actually take input_shape as function input, but it is not shown in this document.\r\nIn addition, the example of this document has the function \"Dense\", but I tried on my Googlecolab and it is not defined in tensorflow2. "
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/install/lang_c\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe download instructions link to 1.14.0 libraries rather than 1.15.0; the 1.15.0 libraries appear to exist and 1.15.0 is a release according to https://github.com/tensorflow/tensorflow/releases\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "https://www.tensorflow.org/api_docs/python/tf/size\r\n\r\nExample: \"Returns the number of elements in the tensor. It equals the length of the flattened tensor.\""
  },
  {
    "labels": [null, null, "documentation"],
    "text": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version (use command below): 1.15\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source): No\r\n- GCC/Compiler version (if compiling from source): No\r\n- CUDA/cuDNN version: No\r\n- GPU model and memory: Run in CPU\r\n**Describe the current behavior**\r\ntf.keras.backend.sqrt(tf.constant(-1.0)) returns 0 as clip_by_value is being done in the source code (Which is highly misleading, as can be seen only in the source and not in the function document) whereas tf.sqrt(tf.constant(-1.0)) returns 'nan' which is the expected behavior of any sqrt function. This causes some bugs which are very difficult to track. \r\n\r\n**Describe the expected behavior**\r\nMake sqrt functions return only the expected behavior and remove the clip_by_value.\r\n\r\n**Code to reproduce the issue**\r\nimport tensorflow as tf\r\ntf.enable_eager_execution()\r\n\r\ntf.keras.backend.sqrt(tf.constant(-1.0)).numpy()\r\ntf.sqrt(tf.constant(-1.0)).numpy()\r\n\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n"
  },
  {
    "labels": [null, null, null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/Model#fit_generator\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/Model#predict_generator\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nI have had pain debugging here so it would be better if the documentation mentions the fallacy here.\r\n\r\nMy experience is: I used ctypes C++ to generate training data into a fixed numpy buffer and the generator merely invoked C++ method and return the same buffer in each iteration (with different content obviously). This is problematic as the internal implementation of `fit_generator` will iterate in advance. The correct usage is to make a copy of the buffer each time iterator is iterated\r\n\r\nThe document should probably mention explicitly that the method does not make deep copy of the return values of the generator on its generation, so e.g. **it is probably not a good idea to share a same numpy buffer across different batches - if one want to yield from same buffer due to certain reasons, one good practice is to make a `nparray.copy()` before `yield`**.\r\n\r\n"
  },
  {
    "labels": [null, null, null, null, "documentation"],
    "text": "Colab example: https://colab.research.google.com/drive/1iCyTZhKzco4CjxY17g37jKG9GS35-NGb\r\nRemember to use GPU instance\r\n\r\nWhen dtype is int32, tf.constant didn't place tensor on gpu but cpu.\r\n\r\n```python\r\nwith tf.device(\"/gpu:0\"):\r\n  a = tf.constant([0,1], dtype=tf.float32)\r\nprint(a.device)\r\n# '/job:localhost/replica:0/task:0/device:GPU:0'\r\n\r\nwith tf.device(\"/gpu:0\"):\r\n  b = tf.constant([0,1], dtype=tf.int32)\r\nprint(b.device)\r\n# '/job:localhost/replica:0/task:0/device:CPU:0'\r\n```\r\n\r\n\r\n\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/guide/migrate#custom_model_fn_with_tf_20_symbols\r\n\r\n## Description of issue (what needs changing):\r\n\r\nMy comments are about this piece of code:\r\n```\r\ndef my_model_fn(features, labels, mode):\r\n  model = make_model()\r\n\r\n  training = (mode == tf.estimator.ModeKeys.TRAIN)\r\n  loss_obj = tf.keras.losses.SparseCategoricalCrossentropy()\r\n  predictions = model(features, training=training)\r\n\r\n  # Get both the unconditional losses (the None part)\r\n  # and the input-conditional losses (the features part).\r\n  reg_losses = model.get_losses_for(None) + model.get_losses_for(features)\r\n  total_loss = loss_obj(labels, predictions) + tf.math.add_n(reg_losses)\r\n\r\n  # Upgrade to tf.keras.metrics.\r\n  accuracy_obj = tf.keras.metrics.Accuracy(name='acc_obj')\r\n  accuracy = accuracy_obj.update_state(\r\n      y_true=labels, y_pred=tf.math.argmax(predictions, axis=1))\r\n\r\n  train_op = None\r\n  if training:\r\n    # Upgrade to tf.keras.optimizers.\r\n    optimizer = tf.keras.optimizers.Adam()\r\n    # Manually assign tf.compat.v1.global_step variable to optimizer.iterations\r\n    # to make tf.compat.v1.train.global_step increased correctly.\r\n    # This assignment is a must for any `tf.train.SessionRunHook` specified in\r\n    # estimator, as SessionRunHooks rely on global step.\r\n    optimizer.iterations = tf.compat.v1.train.get_or_create_global_step()\r\n    # Get both the unconditional updates (the None part)\r\n    # and the input-conditional updates (the features part).\r\n    update_ops = model.get_updates_for(None) + model.get_updates_for(features)\r\n    # Compute the minimize_op.\r\n    minimize_op = optimizer.get_updates(\r\n        total_loss,\r\n        model.trainable_variables)[0]\r\n    train_op = tf.group(minimize_op, *update_ops)\r\n\r\n  return tf.estimator.EstimatorSpec(\r\n    mode=mode,\r\n    predictions=predictions,\r\n    loss=total_loss,\r\n    train_op=train_op,\r\n    eval_metric_ops={'Accuracy': accuracy_obj})\r\n\r\n# Create the Estimator & Train.\r\nestimator = tf.estimator.Estimator(model_fn=my_model_fn)\r\ntf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\r\n```\r\nMy first comment is: why write\r\n```\r\naccuracy = accuracy_obj.update_state(\r\n      y_true=labels, y_pred=tf.math.argmax(predictions, axis=1))\r\n```\r\ninstead of just `accuracy_obj.update_state(y_true=labels, y_pred=tf.math.argmax(predictions, axis=1))` ? First, `accuracy`is never used. Second, this may lead the reader to believe that the `tf.keras.metrics.Metric.update_state` outputs the accuracy value, just like the `tf.keras.metrics.Metric.result` method, whereas the output of `update_state` is `accuracy_obj.count`. See on the code below:\r\n```\r\nimport tensorflow as tf\r\n\r\naccuracy_obj = tf.keras.metrics.Accuracy(name='acc_obj')\r\naccuracy = accuracy_obj.update_state(\r\n      y_true=[0, 1], y_pred=tf.math.argmax([[0.3, 0.7], [0.3, 0.7]], axis=1))\r\n\r\ntf.print(accuracy)\r\n# 2\r\ntf.print(accuracy_obj.result())\r\n# 0.5\r\ntf.print(accuracy_obj.count)\r\n# 2\r\n```\r\n\r\nMy other comment is that we have the line `train_op = tf.group(minimize_op, *update_ops)` whereas in the [\"Custom model_fn with minimal changes\" section](https://www.tensorflow.org/guide/migrate#custom_model_fn_with_minimal_changes) the corresponding line is `train_op = tf.group(minimize_op, update_ops)` without the `*`. Why is that? Is this a mistake?"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/batch_to_space\r\n\r\n## Description of issue (what needs changing):\r\n1. Example needs to be added.\r\n2. `crops` part in `Args:` section is very difficult to understand. Needs to be better formatted (put into code). \r\n\r\n### Clear description:\r\nDocumentation is unclear, no example is shown. Also, there is one extremely long paragraph with code in between in the `crops` section under args.\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly? \r\n=> Not well formatted.\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n=> Yes\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? \r\n=> No\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n=> No\r\n\r\n### Submit a pull request?\r\n=> No\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## Docs URL\r\nhttps://www.tensorflow.org/api_docs/python/tf/estimator/DNNRegressor\r\n\r\n## Tensorflow Version (that I'm using);\r\n2.0.0\r\n\r\n## Issue\r\nI'm trying to create an \"estimator using an optimizer with a learning rate decay\". The documentation says to use `tf.AdamOptimizer`, `tf.exponential_decay`, and `tf.get_global_step`. Tensorflow has none of those attributes. I've tried playing around with suggestions from stack overflow (ie -- tf.train.AdamOptimizer), but I can't figure out where any of those attributes are actually located.\r\n\r\nexample code\r\n```\r\nmodel= tf.estimator.DNNRegressor(\r\n    feature_columns=feature_columns,\r\n    hidden_units = [100, 100, 100],\r\n    optimizer=lambda: tf.AdamOptimizer(\r\n        learning_rate=tf.exponential_decay(\r\n            learning_rate=0.1,\r\n            global_step=tf.get_global_step(),\r\n            decay_steps=10000,\r\n            decay_rate=0.96\r\n        )\r\n    )\r\n)\r\n```\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/debugging/assert_shapes\r\n\r\n## Description of issue (what needs changing):\r\nThe source code in the example is incorrect.\r\n\r\nIs:\r\ntf.assert_shapes([\r\n  (x: ('N', 'Q')),\r\n  (y: ('N', 'D')),\r\n  (param: ('Q',)),\r\n  (scalar: ()),\r\n])\r\n\r\nShould be:\r\ntf.assert_shapes([\r\n  (x, ('N', 'Q')),\r\n  (y, ('N', 'D')),\r\n  (param, ('Q',)),\r\n  (scalar, ()),\r\n]).\r\n\r\nNote that \":\" is not allowed in Python to form 2-tuples. "
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nExample: https://www.tensorflow.org/tutorials/keras/save_and_load\r\n\r\n## Description of issue (what needs changing):\r\n \r\nThe tutorial uses POSIX commands like:\r\n\r\n`!ls {checkpoint_dir}`\r\n\r\nUnfortunately I am on Windows so those commands does not work. Is there no way to condition the command on the OS?\r\n\r\n`!dir {checkpoint_dir}`\r\n\r\nThe alternative way would be to use Python straightaway:\r\n\r\n```\r\nonlyfiles = [f for f in os.listdir(mypath) if os.path.isfile(os.path.join(mypath, f))]\r\nprint(onlyfiles)\r\n```"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue\r\nhttps://www.tensorflow.org/api_docs/python/tf/compat\r\n\r\n## Description of issue (what needs changing):\r\nDocs say\r\n\r\n> Functions for Python 2 vs. 3 compatibility.\r\n\r\nBut on [StackOverflow they told me that](https://stackoverflow.com/questions/58631390/what-is-the-purpose-of-tf-compat)\r\n\r\n> The documentation for the module about Python should actually be changed. Originally, tf.compat only held functions for that purpose (and it was like that until 1.13, see all module documentation). However, it was later repurposed for TensorFlow version compatibility."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/install/source_windows\r\nhttps://www.tensorflow.org/install/source\r\n\r\n## Description of issue (what needs changing):\r\nThe sample sessions given in the docs are old (Bazel 0.15.1, TensorFlow 1.11, python 2.7)\r\nA new session-copy with the more recent TensorFlow 2.x with Bazel 0.26.1 would be more helpful.\r\nAlso, python 2.7 is reaching end-of-life in Jan 2020.\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? Yes. \r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n- https://www.tensorflow.org/install/source_windows\r\n- https://www.tensorflow.org/install/source\r\n\r\n## Browser used:\r\nTried on Microsoft Edge and Mozilla Firefox up-to-date versions.\r\n\r\n## Description of issue (what needs changing):\r\nThe 'Copy link to this section' feature is not working for the `View sample configuration session` sections for the Linux and Windows build-from-source instruction docs.\r\n### Clear description:\r\nThe issue-causing sections are located under these sections: \r\n- https://www.tensorflow.org/install/source#sample_session (Linux)\r\n- https://www.tensorflow.org/install/source_windows#configure_the_build (Windows)\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue?:  Yes, I can fix the markdown to correct the issue.\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "link which I want to edit: [https://www.tensorflow.org/community/contribute/docs](https://www.tensorflow.org/community/contribute/docs)\r\nThe description of Digit classifier is incorrect"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\n[https://www.tensorflow.org/api_docs/python/tf/keras/Model#save](https://www.tensorflow.org/api_docs/python/tf/keras/Model#save)\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe following sentence is outdated and recommends to use a deprecated method:\r\n\r\n> The 'tf' option is currently disabled (use [tf.keras.experimental.export_saved_model](https://www.tensorflow.org/api_docs/python/tf/keras/experimental/export_saved_model) instead)."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\nhttps://github.com/tensorflow/tensorflow/blob/1cf0898dd4331baf93fe77205550f2c2e6c90ee5/tensorflow/python/ops/linalg_ops.py#L426\r\n\r\n## Description of issue (what needs changing):\r\nI can't find ```tensorflow.linalg.norm``` on official v2.0 API document\r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "\r\n## URL(s) with the issue:\r\nhttps://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/classification.ipynb\r\n\r\n## Description of issue (what needs changing):\r\nTypo\r\n\r\n### Clear description\r\n```\r\nCreate the model\r\nThe model consists of three convolution blocks with a max pool layer in each of them. There's a fully connected layer with 512 units on top of it thatr is activated by a relu activation function. \r\n```\r\nIn Create the model section,\r\n```thatr``` should be ```that```\r\n\r\n```\r\nCreate the model\r\nThe model consists of three convolution blocks with a max pool layer in each of them. There's a fully connected layer with 512 units on top of it that is activated by a relu activation function. \r\n```\r\n### Submit a pull request?\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/tutorials/images/cnn\r\n## Description of issue (what needs changing):\r\nTwo mismatchs between output shape on model summary and tutorial:\r\n1\"To complete our model, you will feed the last output tensor from the convolutional base (of shape (3, 3, 64))\"\r\nshould be changed to\r\nTo complete our model, you will feed the last output tensor from the convolutional base (of shape (4, 4, 64))\r\n  \r\n2.\"As you can see, our (3, 3, 64) outputs were flattened into vectors of shape (576) before going through two Dense layers.\"\r\nThis should be changed to \r\n\"As you can see, our (4, 4, 64) outputs were flattened into vectors of shape (1024) before going through two Dense layers.\r\n\r\n\r\n\r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/guide\r\n\r\n## Description of issue (what needs changing):\r\n\r\nIn the TF1.* docs, a very helpful low-level API guide was provided which helped those of us interested in using TensorFlow for applications other than NN style models.  This appears to be entirely missing from the TF 2.0 documentation.  Is this omission on purpose, and if so how do we teach people how to use the low-level API?\r\n\r\nThanks,\r\n\r\nChris\r\n\r\n\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/losses/cosine_similarity\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/losses/CosineSimilarity\r\n\r\n## Description of issue (what needs changing):\r\nThe documentation for the cosine similarity does not state whether `y_true` and `y_pred`\r\nare expected to be normalized vectors. The provided equation `loss = -sum(y_true * y_pred)`\r\nsuggests the need to be, but looking at the source, they are normalized as part of the computation.\r\n```\r\ny_true = nn.l2_normalize(y_true, axis=axis)\r\ny_pred = nn.l2_normalize(y_pred, axis=axis)\r\nreturn -math_ops.reduce_sum(y_true * y_pred, axis=axis)\r\n```\r\nAs a special case, the doc does not state what happens in the case of either being zero.\r\n\r\n(Also, isn't the above implementation suboptimal in terms of speed, as each element is divided by \r\nthe norm, instead of simply dividing the result once?)\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Is graph_transforms  tool the newest tool to optimize and quantize for pb.\r\nwhen I find tf < 1.11,has quantize_graph.py."
  },
  {
    "labels": [null, null, null, null, "documentation"],
    "text": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): NA\r\n- TensorFlow version: 2.0\r\n- Python version: 3.6\r\n- Installed using virtualenv? pip? conda?: pip using wheel\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: \r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\nWe are not able to download the wheels given on page -> https://www.tensorflow.org/install/pip. We are getting the following error when we try to get the *.whl in a browser:\r\n\r\n<Error>\r\n<Code>NoSuchKey</Code>\r\n<Message>The specified key does not exist.</Message>\r\n<Details>\r\nNo such object: tensorflow/linux/gpu/tensorflow_gpu-2.0.0-cp36-cp36m-linux_x86_64.whl\r\n</Details>\r\n</Error>\r\n\r\nThe issue occurs with all the links. We tried wget command on linux and get 404 error.\r\n \r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nwget https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-2.0.0-cp36-cp36m-linux_x86_64.whl\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/SimpleRNN\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nThe document mentions nothing about call argument `inputs` when it takes \r\n`[[batch, timesteps, feature], [batch, state]]`. In case of `inputs` is a list, the elements of `inputs[1:]` work as initial_state in each batch.\r\n\r\nExample)\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import *\r\n\r\n\r\nclass foo(tf.keras.Model):\r\n    def __init__(self, rnn_units, dense_units, **kwargs):\r\n        super().__init__(**kwargs)\r\n        self.r1 = SimpleRNN(rnn_units)\r\n        self.r2 = SimpleRNN(rnn_units)\r\n        self.flat = tf.keras.layers.Flatten()\r\n        self.d1 = Dense(rnn_units)\r\n        self.d2 = Dense(dense_units)\r\n\r\n    def call(self, inputs, **kwargs):\r\n\r\n        x = self.r1(inputs)\r\n        state = self.d1(self.flat(x))\r\n        x = self.r2([inputs, state])\r\n        x = self.d2(x)\r\n\r\n        return x\r\n\r\n\r\ntrain_input = tf.random.normal(shape=(6, 5, 10))\r\ntrain_target = tf.random.normal(shape=(6, 8))\r\n\r\na = foo(10, 8)\r\na.compile(tf.keras.optimizers.SGD(0.01), loss=tf.keras.losses.MeanSquaredError())\r\na.fit(train_input, train_target)\r\n\r\n\r\nb = SimpleRNN(10)(train_input)\r\nstate = Dense(10)(tf.reshape(b, (tf.shape(b)[0], -1)))\r\nb = SimpleRNN(10)([train_input, state])\r\n```\r\n\r\nIt also should be noted that `initial_state` argument should be `None` when `inputs` has states.\r\nOther recurrent layers have same issue.\r\n\r\n### Submit a pull request?\r\nIf this issue was not intended or a bug,\r\nI'm planning to submit a pull request to fix the doc issue in a week. May i?"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "##  URL(s) with the issue: \r\nhttps://www.tensorflow.org/tutorials/distribute/custom_training\r\n\r\n## Description of issue (what needs changing):\r\nIn the tutorial, `with strategy.scope()` appears almost everywhere, which gives the impression that it is required that those locations. However, when checking [this example](https://github.com/tensorflow/examples/blob/master/tensorflow_examples/models/densenet/distributed_train.py), I found that the scope is not required at all! Only `strategy.experimental_run_v2` and `strategy.reduce` suffice. Therefore, I would propose to modify the tutorial code to keep only a minimum amount of `with strategy.scope()` when necessary (e.g. when defining the model).\r\n\r\n### Submit a pull request?\r\n\r\nYes, I can create a PR but only when you have approved that this is valid. Thanks.\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue: [https://www.tensorflow.org/tutorials/keras/save_and_load](https://www.tensorflow.org/tutorials/keras/save_and_load)\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/tutorials/keras/save_and_load\r\n\r\n## Description of issue (what needs changing):\r\n\r\nSince model re-training is quite vital in both applied and research-based environments, I think it would be great to include an example on the same in this tutorial. \r\n\r\n### Clear description\r\n\r\nThe tutorial shows how to save and load models using various options. It does mention that using the model checkpoints it is possible to train the model from the point it was left off. However, currently, there is no section in the tutorial that shows how to do that in the correct way. \r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\nThere are several instances where a model may have to be retrained:\r\n- There is new data and the model needs to re-trained on that\r\n- If we are on local machines and if there is a power failure or bottlenecks that cause the training process to stop, we can always load up the latest checkpoints and re-train the models from there. "
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "One really useful feature in the sklearn docs is that each and every item has a link back to its source on GitHub. For example, see [RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html):\r\n\r\n> class sklearn.ensemble.RandomForestRegressor(n_estimators=’warn’, criterion=’mse’, max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=’auto’, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False)&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;--> **[[source]](https://github.com/scikit-learn/scikit-learn/blob/1495f6924/sklearn/ensemble/forest.py#L1046)** <--\r\n\r\nWould be nice if the TF docs could do the same."
  },
  {
    "labels": [null, "documentation"],
    "text": "#32417  URL(s) with the issue:\r\n\r\nhttps://codelabs.developers.google.com/codelabs/tensorflow-for-poets/?utm_campaign=chrome_series_machinelearning_063016&utm_source=gdev&utm_medium=yt-desc#1\r\n\r\n## Description of issue (what needs changing):\r\nUpdate the link to redirect to the latest version of Tensorflow\r\n\r\n### Clear description\r\n\r\nAlways better to redirect to a page that helps out a user, rather than keep links to 404 pages.\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Raises listed and defined\r\n\r\nServer raises a 404 Page, which is an error.\r\n\r\n### Usage example\r\n\r\nIt isn't exactly a use case. Just a QoL change.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n<img width=\"1440\" alt=\"Screenshot 2019-10-26 at 4 36 23 PM\" src=\"https://user-images.githubusercontent.com/41414202/67618592-17435f80-f80f-11e9-9cb1-2b4d9a44ab34.png\">\r\n<img width=\"1440\" alt=\"Screenshot 2019-10-26 at 4 36 31 PM\" src=\"https://user-images.githubusercontent.com/41414202/67618594-1a3e5000-f80f-11e9-92f4-6716b871496f.png\">\r\n\r\n\r\n\r\n### Submit a pull request?\r\n Yes. I love contributing in small ways, since I'm still a rather newbie developer. Errors even small should be dealt with I presume?\r\n\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "I am trying to compile TensorflowLite for emscripten (I am aware of TensorflowJS) and pthreads are currently disabled. Is there a way to use it without pthreads?\r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry:\r\nhttps://www.tensorflow.org/tutorials/generative/deepdream\r\n\r\n## Description of the issue (what needs changing):\r\nIn this example, we are already performing this: `original_img = np.array(original_img)` in the beginning. Then, what is the point of repeating it here: `img = tf.constant(np.array(original_img))` and here: `shift_down, shift_right, img_rolled = random_roll(np.array(original_img), 512)`? "
  },
  {
    "labels": [null, "documentation"],
    "text": "https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html\r\n\r\nupdate generate_tf_record file according to running version in tensor flow."
  },
  {
    "labels": [null, "documentation"],
    "text": "This is issue is made in reference to Issue #33552 and the PR #33579:\r\nwhen I click on the person_detection.zip link after update this pops out:\r\n`\r\nThis XML file does not appear to have any style information associated with it. The document tree is shown below.\r\n<Error nighteye=\"disabled\">\r\n<Code>NoSuchKey</Code>\r\n<Message>The specified key does not exist.</Message>\r\n<Details>\r\nNo such object: tensorflow-nightly/github/tensorflow/tensorflow/lite/experimental/micro/tools/make/gen/arduino_x86_64/prj/person_detection/person_detection.zip\r\n</Details>\r\n</Error>\r\n` \r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/experimental/micro/examples/person_detection\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/experimental/micro/examples/person_detection#obtain-and-import-the-library\r\n\r\n## Description of issue (what needs changing):\r\nUnder the heading \"Obtain and Import the Library\", the link incorrectly refers to the micro_speech.zip package instead of a person_detection example. \r\n\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/tfx/serving/serving_advanced\r\n\r\n## Description of issue (what needs changing):\r\n\r\nWhen I attempt to execute  the \r\n```\r\ntools/run_in_docker.sh python tensorflow_serving/example/mnist_saved_model.py \\\r\n  --training_iteration=100 --model_version=1 /tmp/mnist\r\n```\r\nstep in the in the tutorial I get the this error:\r\n\r\n```\r\nserving % tools/run_in_docker.sh python tensorflow_serving/example/mnist_saved_model.py \\\r\n  --training_iteration=100 --model_version=1 /tmp/mnist\r\n== Pulling docker image: tensorflow/serving:nightly-devel\r\nnightly-devel: Pulling from tensorflow/serving\r\n22e816666fd6: Already exists \r\n079b6d2a1e53: Already exists \r\n11048ebae908: Already exists \r\nc58094023a2e: Already exists \r\ne9d1145448f7: Pull complete \r\n3b2b266356de: Pull complete \r\n9f9b2b982b72: Pull complete \r\nede8854b3a01: Pull complete \r\n7bb55a638df9: Pull complete \r\nbdd9b510b8a7: Pull complete \r\n90a5454f6928: Pull complete \r\n1941316fdbd3: Pull complete \r\nc9c9a434ee49: Pull complete \r\nDigest: sha256:3b52152115c73a6be79a86cda94c4c94569df9b490a3e40c2530d5a9a007afac\r\nStatus: Downloaded newer image for tensorflow/serving:nightly-devel\r\ndocker.io/tensorflow/serving:nightly-devel\r\n== Running cmd: sh -c 'cd /Users/***REMOVED***/GitHub/serving; python tensorflow_serving/example/mnist_saved_model.py --training_iteration=100 --model_version=1 /tmp/mnist'\r\nTraceback (most recent call last):\r\n  File \"tensorflow_serving/example/mnist_saved_model.py\", line 39, in <module>\r\n    tf.app.flags.DEFINE_integer('training_iteration', 1000,\r\nAttributeError: 'module' object has no attribute 'app'\r\n```\r\nI am running this on Mac OS Catalina w/ 8GB RAM allocated to the Docker Engine.\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Hi\r\n\r\nFollowing URL seems to be down:\r\n\r\nhttps://mirror.bazel.build/github.com/pybind/pybind11/archive/v2.3.0.tar.gz\r\n\r\nBazel uses that to download pybind11 and for some unknown reason fallback link (https://github.com/pybind/pybind11/archive/v2.3.0.tar.gz) is never being used as an alternative. (Is that a fallback btw?)\r\n\r\nBuild logs:\r\n\r\n```\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (192 packages loaded, 2655 targets configured)                              \r\nINFO: Call stack for the definition of repository 'pybind11' which is a tf_http_archive (rule definition at /root/tensorflow-1.15.0/third_party/repo.bzl:124:19):                                                                                                                             \r\n - /root/tensorflow-1.15.0/tensorflow/workspace.bzl:925:5                                                                                      \r\n - /root/tensorflow-1.15.0/WORKSPACE:19:1                                                                                                      \r\nERROR: An error occurred during the fetch of repository 'pybind11':                                                                            \r\n   java.io.IOException: Error downloading [https://mirror.bazel.build/github.com/pybind/pybind11/archive/v2.3.0.tar.gz, https://github.com/pybind/pybind11/archive/v2.3.0.tar.gz] to /root/.cache/bazel/_bazel_root/a0cf5ef42c8f00571631f8815d38246b/external/pybind11/v2.3.0.tar.gz: All mirrors are down: [GET returned 404 Not Found, connect timed out]       \r\n```                                                                           \r\n\r\nAny workaround? \r\n\r\n**System information**\r\n- OS Platform and Distribution: Ubuntu 19.10\r\n- TensorFlow version: 1.15.0\r\n- Python version: 3.7\r\n- Bazel version: 0.26.1"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux (Google Colab)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Google Colab\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0\r\n- Python version: 3.x\r\n- Bazel version (if compiling from source): -\r\n- GCC/Compiler version (if compiling from source): -\r\n- CUDA/cuDNN version: -\r\n- GPU model and memory: - \r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nUnable to import tf.broadcast_weights in TF 2.0. \r\n\r\n**Describe the expected behavior**\r\nShould be able to import tf.broadcast_weights in TF 2.0\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nMethod 1: Plain python + TF 2.0\r\n```\r\nimport tensorflow as tf     # version 2.0\r\ntf.broadcast_weights\r\n```\r\n_throws_ ** AttributeError: module 'tensorflow' has no attribute 'broadcast_weights'**\r\n\r\nMethod 2: Codelab\r\nI found this error in a recent TF 2.0 + Keras tutorial - https://colab.sandbox.google.com/drive/1UCJt8EYjlzCs1H1d1X0iDGYJsHKwu-NO\r\n\r\n- Search for \"broadcast_weights\" in this codelab. \r\n- Run all cells before this.\r\n- Modify code \"m.update_state([0, 1, 1, 1], [0, 1, 0, 0])\" to \"m.update_state([0, 1, 1, 1], [0, 1, 0, 0]), sample_weight=[0.1,0.2,0.3,0.4]\"\r\n- Run this cell\r\n- throws AttributeError: module 'tensorflow' has no attribute 'broadcast_weights'\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "Please update docs this example doesn't work\r\n\r\nhttps://www.tensorflow.org/lite/convert/python_api#converting_a_keras_model_\r\n\r\nConverting a Keras model \r\nThe following example shows how to convert a tf.keras model into a TensorFlow Lite FlatBuffer.\r\n\r\nimport tensorflow as tf\r\n\r\n# Create a simple Keras model.\r\nx = [-1, 0, 1, 2, 3, 4]\r\ny = [-3, -1, 1, 3, 5, 7]\r\n\r\nmodel = tf.keras.models.Sequential(\r\n    [tf.keras.layers.Dense(units=1, input_shape=[1])])\r\nmodel.compile(optimizer='sgd', loss='mean_squared_error')\r\nmodel.fit(x, y, epochs=50)\r\n\r\n# Convert the model.\r\n**converter = tf.lite.TFLiteConverter.from_keras_model(model)\r\ntflite_model = converter.convert()**\r\n\r\ntf.__version__\r\n'1.15.0-rc3'\r\n\r\noutput in colab \r\n\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-31-68e491526aaa> in <module>()\r\n     11 \r\n     12 # Convert the model.\r\n---> 13 converter = tf.lite.TFLiteConverter.get_input_arrays(model)\r\n     14 tflite_model = converter.convert()\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/lite.py in get_input_arrays(self)\r\n   1001       List of strings.\r\n   1002     \"\"\"\r\n-> 1003     if self._has_valid_tensors():\r\n   1004       return [_get_tensor_name(tensor) for tensor in self._input_tensors]\r\n   1005     else:\r\n\r\nAttributeError: 'Sequential' object has no attribute '_has_valid_tensors'\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue: https://www.tensorflow.org/guide/distributed_training\r\n## Description of issue (what needs changing): Out of date link to BERT tutorial\r\n### Clear description\r\nThe above URL contains an out of date link:\r\nBERT Tutorial: https://github.com/tensorflow/models/blob/master/official/bert/run_classifier.py \r\nThis is the correct link: https://github.com/tensorflow/models/blob/master/official/nlp/bert/run_classifier.py\r\n\r\nAre you planning to also submit a pull request to fix the issue?  Yes"
  },
  {
    "labels": ["documentation"],
    "text": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nIn the 1.15 changelog:\r\n\r\nhttps://github.com/tensorflow/tensorflow/releases/tag/v1.15.0\r\n> tf.keras.model.save_model and model.save now defaults to saving a TensorFlow SavedModel.\r\n\r\n\r\nIn the 1.15 docstring:\r\nhttps://www.tensorflow.org/versions/r1.15/api_docs/python/tf/keras/Model#save\r\n> filepath: String, path to SavedModel or H5 file to save the model. overwrite: Whether to silently \r\noverwrite any existing file at the target location, or provide the user with a manual prompt. include_optimizer: If True, save optimizer's state together. save_format: Either 'tf' or 'h5', indicating whether to save the model to Tensorflow SavedModel or HDF5. The default is currently 'h5', but will switch to 'tf' in TensorFlow 2.0. The 'tf' option is currently disabled (use tf.keras.experimental.export_saved_model instead).\r\n\r\n## Description of issue (what needs changing):\r\n\r\n- The changelogs states that tf.keras.Model are saved using tf format by default\r\n- The docstring states that the default save format in tf1.x is hdf5 and that tf is disabled\r\n- \"tf\" save format is NOT disabled but can be passed as parameters\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.15/tensorflow/python/keras/saving/save.py#L92\r\nWe can still save using tf format using tf.keras.Model.save(). HOWEVER you cannot load tf model\r\n\r\n## Usage example\r\n\r\nThis is not a critical issue but this can be confusing to users reading the changelog and reading the docstring, and seeing that tf behaviour is enabled by default.\r\n\r\nThis will lead users to:\r\n- Being confused between behaviours...\r\n- Thinking they need to update their codebases to switch to 1.15\r\n- Seeing that tf format doesn't work in tf1.15\r\n\r\nSaving works but not reloading, which confirms the fact that tf save format doesn't work\r\n\r\n```python\r\ni = tf.keras.layers.Input(shape=(10,))\r\nx = tf.keras.layers.Dense(2)(i)\r\no = tf.keras.layers.Activation(\"softmax\")(x)\r\nm = tf.keras.Model(inputs=i, outputs=o)\r\nm.save('test_model_tf', save_format=\"tf\")\r\nm2 = tf.keras.models.load_model(\"test_model_tf\")\r\nm2.summary()\r\n```\r\n\r\n```text\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-48-d0af62cb113d> in <module>\r\n----> 1 m2.summary()\r\n\r\n~/opt/miniconda3/envs/py36-tf1.15/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py in summary(self, line_length, positions, print_fn)\r\n   1459                               line_length=line_length,\r\n   1460                               positions=positions,\r\n-> 1461                               print_fn=print_fn)\r\n   1462 \r\n   1463   def _validate_graph_inputs_and_outputs(self):\r\n\r\n~/opt/miniconda3/envs/py36-tf1.15/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/layer_utils.py in print_summary(model, line_length, positions, print_fn)\r\n    224   for i in range(len(layers)):\r\n    225     if sequential_like:\r\n--> 226       print_layer_summary(layers[i])\r\n    227     else:\r\n    228       print_layer_summary_with_connections(layers[i])\r\n\r\n~/opt/miniconda3/envs/py36-tf1.15/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/layer_utils.py in print_layer_summary(layer)\r\n    182     name = layer.name\r\n    183     cls_name = layer.__class__.__name__\r\n--> 184     fields = [name + ' (' + cls_name + ')', output_shape, layer.count_params()]\r\n    185     print_row(fields, positions)\r\n    186 \r\n\r\n~/opt/miniconda3/envs/py36-tf1.15/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py in count_params(self)\r\n   1632                          ', but the layer isn\\'t built. '\r\n   1633                          'You can build it manually via: `' + self.name +\r\n-> 1634                          '.build(batch_input_shape)`.')\r\n   1635     return int(sum(np.prod(w.shape.as_list()) for w in self.weights))\r\n   1636 \r\n\r\nValueError: You tried to call `count_params` on input_1, but the layer isn't built. You can build it manually via: `input_1.build(batch_input_shape)`.\r\n\r\n```\r\nThis works,\r\n\r\n```python\r\ni = tf.keras.layers.Input(shape=(10,))\r\nx = tf.keras.layers.Dense(2)(i)\r\no = tf.keras.layers.Activation(\"softmax\")(x)\r\nm = tf.keras.Model(inputs=i, outputs=o)\r\nm.save('test_model_hdf5.hdf5`)\r\nm2 = tf.keras.models.load_model(\"test_model_hdf5.hdf5\")\r\nm2.summary()\r\n```\r\n```txt\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\ninput_4 (InputLayer)         [(None, 10)]              0         \r\n_________________________________________________________________\r\ndense_3 (Dense)              (None, 2)                 22        \r\n_________________________________________________________________\r\nactivation_3 (Activation)    (None, 2)                 0         \r\n=================================================================\r\nTotal params: 22\r\nTrainable params: 22\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\n```"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/guide/gpu\r\n\r\n## Description of issue (what needs changing):\r\n\r\nI was reading this documentation page https://www.tensorflow.org/guide/gpu, but it is **unclear** which TensorFlow version the documentation applies to. Especially now that a stable version of TF 2 has been released, it is important to clarify which TF version the documentation refers to. \r\n\r\nOn the top bar of the linked webpage, there is a menu called API, where you can select the API you are interested in. Right now, the sub-menu corresponding to the specific version of TF I am reading is not even highlighted, so I don't know if I am reading the documentation for TF 1 or 2. To confuse people even further, even though I think I am reading the documentation for TF 2, in another top bar, it is written `TF 1`. \r\n\r\nGiven that I am confused, another person can also be confused, so the documentation needs to be clarified. So, I suggest that every documentation page is associated (**in a very clear way**) with all applicable TF versions."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "I am using Huber loss implementation in tf.keras in tensorflow 1.14.0 as follows:\r\n\r\n```\r\nhuber_keras_loss = tf.keras.losses.Huber(\r\n        delta=delta,\r\n        reduction=tf.keras.losses.Reduction.SUM,\r\n        name='huber_loss'\r\n    )\r\n```\r\n\r\nI am getting the error AttributeError: module 'tensorflow.python.keras.api._v1.keras.losses' has no attribute 'Reduction'\r\n\r\nI have tried using tf.losses.Reduction, tf.compat.v2.losses.Reduction nothing seems to work.\r\n\r\nDid tensorflow remove Reduction from tf.keras.losses, it is strange if they did so because their documentation still shows: https://www.tensorflow.org/versions/r1.14/api_docs/python/tf/keras/losses/Huber#args"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "https://www.tensorflow.org/api_docs/python/tf/batch_to_space\r\n\r\nthe documentation describing the steps is merged together and not clear.\r\n\r\nIs the link to the source code correct?\r\nyes\r\n\r\n### Submit a pull request?\r\nyes submitted a fix here: https://github.com/tensorflow/tensorflow/pull/33351\r\n\r\n\r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## Description of issue (what needs changing):\r\n\r\nDocker Build from Source documentation seems to be out of date for docker 19.03.\r\nFor example there is no --runtime=nvidia flag available any more."
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/516c98da7b7d8526c153827c426c675a4ece9543/tensorflow/python/keras/optimizer_v2/optimizer_v2.py#L414\r\n\r\n## Description of issue (what needs changing):\r\n\r\n`grads_and_vars` is documented as list but is actually passed as `zip object`.\r\n\r\n### Clear description\r\n\r\nThis can be problematic when writing custom optimizers that iterate over the `grads_and_vars` multiple times, as in that case a `zip object` will not give the intended behaviour.\r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): `pip install tensorflow`\r\n- TensorFlow version: 2.0.0\r\n- Python version: 3.7\r\n- CUDA/cuDNN version: CUDA=10.0, cuDNN=7.6.4\r\n- GPU model and memory: GTX 1060 6GB\r\n\r\n\r\n**Describe the current behavior**\r\nThe prediction speed is slowed down a lot after `model.compile()` call.\r\n\r\n**Describe the expected behavior**\r\nSpeed should not be affected. Predict function is used by users assuming that it will work fast because we use it all the time in production. It should not cause surprise to users.\r\n\r\n**Code to reproduce the issue**\r\nhttps://nbviewer.jupyter.org/github/off99555/TensorFlowExperiments/blob/master/test-prediction-speed-after-compile.ipynb?flush_cache=true\r\n\r\n![image](https://user-images.githubusercontent.com/15215732/66762282-e3dc0900-eecf-11e9-8d93-82c8bcc5325b.png)\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "So I was following this codelab : https://codelabs.developers.google.com/codelabs/tensorflow-lab2-computervision/index.html?index=..%2F..index#4\r\n\r\nOn slide 5 the optimizer is set to be `tf.train.AdamOptimizer()`\r\nand it returns an error of\r\n `module 'tensorflow_core._api.v2.train' has no attribute 'AdamOptimizer'`\r\nI guess it should be \r\n`tf.optimizers.Adam()`\r\n?"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/GradientTape\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\nClass members and Return values in \"gradient\" function not consistent with actual values in code\r\n\r\n### Correct links\r\nYes\r\n### Parameters defined\r\nYes\r\n### Returns defined\r\nNeeds to be modified\r\ngradient () :\r\n1. Argument - unconnected_gradients: a value which can either hold 'none' or 'zero'\r\n\r\n  Should be NONE or ZERO\r\n\r\n2. Return values:  \r\n\r\nIn addition to the mentioned return values, If none of the provided elements in \"sources\" argument are being watched, the function will return None\r\n\r\n\r\n### Raises listed and defined\r\nYes\r\n\r\n### Usage example\r\nYes\r\n### Submit a pull request?\r\nYes"
  },
  {
    "labels": [null, null, null, null, null, "documentation", null],
    "text": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOSX 10.14.6\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d382ca 2.0.0\r\n- Python version: 3.7.4\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\n\r\nRandom seeds work in surprising ways in TF 2.0 when using `@tf.function`. In particular, the value of the global random seed is only taken into account when a function is traced, not when it is called. This is surprising and different from TF 1.x behavior.\r\n\r\n**Describe the expected behavior**\r\nI expect the value of the global random seed to be taken into account every time a pseudo-random number is generated.\r\n\r\n**Code to reproduce the issue**\r\n\r\n```python\r\n@tf.function\r\ndef rnd():\r\n    return tf.random.uniform(shape=[])\r\n\r\ntf.random.set_seed(42)\r\nprint(rnd()) # The rnd() function's seed is generated randomly now, based on\r\nprint(rnd()) # the current random seed (which is 42).\r\nprint()\r\n\r\ntf.random.set_seed(43) # resets the random sequence but ignores this seed!\r\nprint(rnd())\r\nprint(rnd())\r\nprint()\r\n\r\ntf.random.set_seed(42) # resets the random sequence but ignores this seed!\r\nprint(rnd())\r\nprint(rnd())\r\nprint()\r\n```\r\n\r\nThe output value is:\r\n\r\n```\r\ntf.Tensor(0.63789964, shape=(), dtype=float32)\r\ntf.Tensor(0.8774011, shape=(), dtype=float32)\r\n\r\ntf.Tensor(0.63789964, shape=(), dtype=float32)\r\ntf.Tensor(0.8774011, shape=(), dtype=float32)\r\n\r\ntf.Tensor(0.63789964, shape=(), dtype=float32)\r\ntf.Tensor(0.8774011, shape=(), dtype=float32)\r\n```\r\n\r\nNotice that we get the same sequence of random numbers every time, ignoring the value of the global random seed. The only value that matters is the first one (when the function gets traced).\r\n\r\nMore code and examples of surprising behavior in [this colab](https://colab.research.google.com/drive/1C3LZkt5hfO6T2Uo2xaYVG8hiNQL8c3xu).\r\n\r\n**Other info / logs**\r\n\r\nSpecifically, I would expect the output to look the same as when the function is not decorated with `@tf.function`:\r\n\r\n```\r\ntf.Tensor(0.6645621, shape=(), dtype=float32)\r\ntf.Tensor(0.68789124, shape=(), dtype=float32)\r\n\r\ntf.Tensor(0.2733041, shape=(), dtype=float32)\r\ntf.Tensor(0.5168259, shape=(), dtype=float32)\r\n\r\ntf.Tensor(0.6645621, shape=(), dtype=float32)\r\ntf.Tensor(0.68789124, shape=(), dtype=float32)\r\n```\r\n\r\nNote that the second sequence is different, as expected (in fact, the pseudo-random numbers should be identical whether the function is decorated or not, but that's a nice-to-have)."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\nHow to decode output float array into string using CTC beam search decoder in android. I'm not using tflite as of now. \r\n\r\n### Clear description\r\n\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\nFloat Array\r\nAre return values defined? \r\nYes\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Documentation for tf.feature_column like for example:\r\nhttps://www.tensorflow.org/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file\r\n\r\nuses input_layer, which is not available in v2\r\n```\r\ncolumns = [embedding_column(states, 3),...]\r\nfeatures = tf.io.parse_example(..., features=make_parse_example_spec(columns))\r\ndense_tensor = input_layer(features, columns)\r\n```\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "I am reading about tensorboard here: https://www.tensorflow.org/tensorboard/r1/summaries\r\n\r\nOn this page the link to *TensorBoard: Graph Visualization* is broken. This is the link: https://www.tensorflow.org/tensorboard/guide/graph_viz"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/nn/softmax\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nYes\r\n\r\n### Correct links\r\n\r\nyes\r\n\r\n### Parameters defined\r\n\r\nNo. \r\nPer the code, the first argument \"logits\" can be of any type that can be passed to \"convert_to_tensor()\", not just a tensor. Therefore the documentation can be modified to include \"Tensor objects, numpy arrays, Python lists, and Python scalars\".\r\n\r\n### Returns defined\r\nyes\r\n\r\n### Raises listed and defined\r\nyes\r\n\r\n### Submit a pull request?\r\nyes\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/raspberry_pi\r\n\r\n## Description of issue (what needs changing):\r\nNear the bottom of the instruction on speeding up inference it reads\r\n```python3 classify_picamera.py \\```\r\n\r\nBased on the files in that example folder should that instead read\r\n```python3 detect_picamera.py \\```\r\n\r\n### Clear description\r\nIf my assumption above is incorrect, then its unclear where the file ```classify_pycamera.py``` is coming from, and should maybe be explicitly mentioned.\r\n\r\n### Submit a pull request?\r\nI didnt plan to since its possibly a simple typo. But I can if you'd like."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nBetter performance with tf.data: https://www.tensorflow.org/guide/data_performance\r\n\r\n## Description of issue (what needs changing):\r\n\r\nCurrently, this guide seems to be the main documentation source for `tf.data` usage.\r\nHowever, the differents steps shown do not seems to be optimal. For example:\r\n* TFRecordDataset usage do not match the actual API (see #33048)\r\n* Usage of `interleave` with TFRecordDataset is redoundant (see [SO post](https://stackoverflow.com/questions/58014123/how-to-improve-data-input-pipeline-performance)).\r\n\r\n### Submit a pull request?\r\n\r\nNo PR intented for the moment as I think this requires some discussion if I missed something or whatever."
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nBetter performance with data: https://www.tensorflow.org/guide/data_performance#structure_of_an_input_pipeline\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe code example provided instantiate a `tf.data.TFRecordDataset` passing a globbing pattern: `\"/path/to/dataset/train-*.tfrecord\"` while it does not support it.\r\n\r\nThe example should be updated, relying on [`tf.data.Dataset.list_files`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset#list_files).\r\n\r\n```diff\r\n- dataset = tf.data.TFRecordDataset(\"/path/to/dataset/train-*.tfrecord\")\r\n+ dataset = tf.data.TFRecordDataset(tf.data.Dataset.list_files(\"/path/to/dataset/train-*.tfrecord\"))\r\n```\r\n\r\n### Submit a pull request?\r\n\r\nI will submit a pull request soon."
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n- https://www.tensorflow.org/tutorials/text/nmt_with_attention\r\n`Encoder`, `BahdanauAttention` and `Decoder` inherit `tf.keras.Model`.\r\n- https://www.tensorflow.org/guide/eager#variables_and_optimizers\r\nModel does not need to be a subclass of `tf.keras.Model` because we don't use `Model`'s utility methods.\r\n- https://www.tensorflow.org/tutorials/customization/custom_layers#models_composing_layers\r\n  > The main class used when creating a layer-like thing which contains other layers is tf.keras.Model. Implementing one is done by inheriting from tf.keras.Model.\r\n\r\n  This is not accurate since TF 1.13 (and standalone keras 2.3.0)\r\n\r\nThere are other tutorials which use `tf.keras.Model` when `tf.keras.layers.Layer` is sufficient.\r\n\r\n## Description of issue (what needs changing):\r\n\r\nWe should stop inheriting `tf.keras.Model` in tutorials when we don't use utility functions of `Model`.\r\n\r\n### Clear description\r\n\r\nSince tf1.13 and [standalone keras 2.3.0](https://github.com/keras-team/keras/releases/tag/2.3.0), *Layers set as attributes of a Layer are now tracked*.\r\nAlso, [Writing custom layers and models with Keras](https://www.tensorflow.org/guide/keras/custom_layers_and_models) says *A Model is just like a Layer, but with added training and serialization utilities.*\r\n\r\nWe don't need to inherit `Model` unless we use \"utility methods\" of `Model`. I think the idea like *\"Always extend Model because Model has more features\"* is not correct because utilities of Model work only with special subsets of Layer ([Layers whose call receive only one input](https://github.com/tensorflow/tensorflow/blob/c8ef33dd913463ced8cc347c03945a88b34da7f8/tensorflow/python/keras/engine/training.py#L1461)).\r\n\r\nThus, I think we should stop inheriting `tf.keras.Model` in tutorials when `tf.keras.layers.Layer` is enough.\r\n\r\nMy original question on stackoverflow as a context of this bug:\r\nhttps://stackoverflow.com/questions/58118334/when-should-we-inherits-keras-model-instead-of-keras-layers-layer-even-if-we-don\r\n### Submit a pull request?\r\n\r\nI'm sending a pull requests to fix them.\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "\r\n**System information**\r\n- Tensorflow basic tutorial code from https://www.tensorflow.org/tutorials/quickstart/beginner\r\n- Python version:3.7.4, standard yum repository, compiled by GCC 7.3.1 20180712 (Red Hat 7.3.1-6)] on linux\r\n- Amazon free-tier EC2 node running amazon linux 2. \r\n- pip installed version of tensorflow version 2.0.0\r\n\r\n\r\n**Describe the current behavior**\r\nDies due to memory constraints on Tensorflow 2.0.0 (but not in 1.14.0)\r\n\r\n**Describe the expected behavior**\r\nWith tensorflow 1.14.0, the tutorial works just fine, but with 2.0.0 it runs out of memory. This is a small machine that Amazon has on it's free tier (t2.micro). It comes with 1 GB of ram, and I'm not expecting it to run anything really large, but it's an ideal machine from a cost perspective to try out tensorflow basics, and it works just fine with tensorflow 1.14 and earlier.\r\n\r\n**Code to reproduce the issue**\r\nJust the tensorflow tutorial code directly from the tensorflow website.\r\n[ec2-user@ip-xxx-xxx-xxx-xxx ~]$ cat test_tf.py\r\n#!/usr/bin/env python3\r\nimport tensorflow as tf\r\nmnist = tf.keras.datasets.mnist\r\n\r\n(x_train, y_train),(x_test, y_test) = mnist.load_data()\r\nx_train, x_test = x_train / 255.0, x_test / 255.0\r\n\r\nmodel = tf.keras.models.Sequential([\r\n  tf.keras.layers.Flatten(input_shape=(28, 28)),\r\n  tf.keras.layers.Dense(512, activation=tf.nn.relu),\r\n  tf.keras.layers.Dropout(0.2),\r\n  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\r\n])\r\nmodel.compile(optimizer='adam',\r\n              loss='sparse_categorical_crossentropy',\r\n              metrics=['accuracy'])\r\n\r\nmodel.fit(x_train, y_train, epochs=5)\r\nmodel.evaluate(x_test, y_test)\r\n\r\n**Other info / logs**\r\nOutput from test_tf.py:\r\n[ec2-user@ip-xxx-xxx-xxx-xxx ~]$ ./test_tf.py\r\n2019-10-02 13:30:43.682116: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-10-02 13:30:43.775079: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400075000 Hz\r\n2019-10-02 13:30:43.778603: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3798a90 executing computations on platform Host. Devices:\r\n2019-10-02 13:30:43.778635: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\r\n2019-10-02 13:30:43.960286: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 376320000 exceeds 10% of system memory.\r\nSegmentation fault\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "I think we need more detailed description and example for streaming training data from disk on\r\nhttps://www.tensorflow.org/guide/data#basic_mechanics.\r\n\r\nIt is mentioned on other documents, but no how-tos. It would be helpful if we add how to implement streaming data from disk and improvements on TF2.0, if any.\r\n\r\n> When iterating over training data that fits in memory, feel free to use regular Python iteration. Otherwise, tf.data.Dataset is the best way to stream training data from disk. https://www.tensorflow.org/guide/effective_tf2\r\n\r\n> For large datasets (> 1 GB), this can waste memory and run into byte limits of graph serialization. If tensors contains one or more large NumPy arrays, consider the alternative described in this guide.\r\nhttps://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_tensor_slices\r\n** The link to \"this guide\" is broken.\r\n\r\n\r\n> The tf.data API supports a variety of file formats so that you can process large datasets that do not fit in memory. For example, the TFRecord file format is a simple record-oriented binary format that many TensorFlow applications use for training data. The tf.data.TFRecordDataset class enables you to stream over the contents of one or more TFRecord files as part of an input pipeline.\r\nhttps://www.tensorflow.org/guide/data#consuming_tfrecord_data\r\n\r\nAlso, it would be helpful if we make it clear...\r\n- If the tf.data.TFRecordDataset is the only class that supports streaming.\r\n- If the TFRecord is the only file format that supports streaming.\r\n- If the user needs to convert their dataset to TFRecord format.\r\n- If the trained model can be used with TFLite. \r\n- etc..."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://medium.com/tensorflow/upgrading-your-code-to-tensorflow-2-0-f72c3a4d83b5\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThis upgrade guide is linked from the TensorFlow 2.0 release notes. If the viewer has exceeded their quota on Medium, they are blocked by a paywall and cannot read the upgrade guide. Is this intentional?\r\n\r\n![image](https://user-images.githubusercontent.com/475017/65907458-68883c80-e392-11e9-82d0-edf8ad7efbe0.png)\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/versions/r1.15/api_docs/python/tf/strings/split\r\n\r\n## Description of issue (what needs changing):\r\nLast section is raw markdown instead of formatted HTML.\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/strings/reduce_join\r\n\r\n## Description of issue (what needs changing):\r\nAdd documentation for this method.\r\n\r\n### Clear description\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "Items in TensorFlow Core r1.14 is linked to r2.0.\r\nIn search results, all informations are correct except the link.\r\nAll links point to RC version, not r1.14.\r\n\r\nI checked tf.nn.dynamic_rnn and tf.nn.fused_batch_norm.\r\ndynamic_rnn is linked to [https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn) now.\r\nBut [https://www.tensorflow.org/versions/r1.14/api_docs/python/tf/nn/dynamic_rnn](https://www.tensorflow.org/versions/r1.14/api_docs/python/tf/nn/dynamic_rnn) is right."
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "when i use tensorflow.contrib.layers.convolution2d_transpose()\r\nusing tensorflow1.13-gpu, ubuntu\r\ni got this error:\r\nconvolution2d_transpose() got an unexpected keyword argument 'kernel_constraint'\r\n\r\nbut i check the document, there exits 'kernel_constraint' parameter in tensorflow.contrib.layers.convolution2d_transpose\r\nhow to fix it???\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "[This page](https://www.tensorflow.org/community/contribute/docs) links to https://www.tensorflow.org/customize, which doesn't exist.\r\n\r\n(\"We encourage the community to develop and maintain support for other languages with the approach recommended by the TensorFlow maintainers.\")\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/nn/batch_normalization\r\n\r\n## Description of issue (what needs changing):\r\nDocumentation\r\n\r\n### Clear description\r\nYes\r\n### Correct links\r\nYes\r\nIs the link to the source code correct?\r\nYes\r\n### Parameters defined\r\nYes\r\nAre all parameters defined and formatted correctly?\r\nNo.\r\n\r\n- tf.nn.moments(..., keep_dims=True) \r\n\r\nIn TF2 version of tf.nn.moments, keep_dims keyword should be \"keepdims\" instead\r\n\r\n- Does not implement the equation as given, but the equation 11 in Algorithm 2 of the paper.\r\n![image](https://user-images.githubusercontent.com/1215029/65819369-429b5480-e239-11e9-98e7-07bbf34f18d9.png)\r\n\r\n\r\n### Returns defined\r\nAre return values defined?\r\nYes\r\n### Raises listed and defined\r\nNo\r\n### Usage example\r\nIs there a usage example?\r\nNo\r\n### Request visuals, if applicable\r\nNo\r\nAre there currently visuals? If not, will it clarify the content?\r\nNo\r\n### Submit a pull request?\r\nYes\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/beta/tutorials/images/classification\r\n\r\n## Description of issue (what needs changing):\r\n```\r\nacc = history.history['accuracy']\r\nval_acc = history.history['val_accuracy']\r\n```\r\nshould be\r\n```\r\nacc = history.history['acc']\r\nval_acc = history.history['val_acc']\r\n```\r\n### Clear description\r\nWhen I copy and paste the code and run it directly, the model is trained for a few minutes/a while but I get KeyError: 'accuracy' and then when I change that, get KeyError: 'val_accuracy'\r\n\r\nSomeone would use this to perform image recognition with code they take directly from the Tensorflow docs on this page.\r\n\r\n### Correct links\r\nIt is not correct yet. I am thinking of making a PR to the docs repo\r\n\r\n### Parameters defined\r\nn/a\r\n\r\n### Returns defined\r\n\r\nn/a\r\n\r\n### Raises listed and defined\r\n\r\nn/a\r\n\r\n### Usage example\r\n\r\nto train images\r\n\r\n### Request visuals, if applicable\r\n\r\nThere's a few.\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n\r\nI am!\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/guide/autograph\r\n\r\n## Description of issue (what needs changing):\r\n\"Autograph capabilities and limitations.\" link points an out dated doc at:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/LIMITATIONS.md\r\n\r\n### Clear description\r\n\r\n- There was a similar bug in https://github.com/tensorflow/tensorflow/issues/22280 in 2018.\r\n- This issue was reported [in the closed bug](https://github.com/tensorflow/tensorflow/issues/22280#issuecomment-527699503)) but this comment did not get a reply. Thus, I'm filing a new bug.\r\n\r\n### Submit a pull request?\r\n\r\nActually, this issue was fixed on Aug 6th, 1.5+ month ago.\r\nhttps://github.com/tensorflow/docs/commit/c29c6fa8202fcd8da4ab8d8072c5f7dacf7c160a#diff-039832f2dbb662a37df6e0fa64ebe35e"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/install/pip\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe current pip package that exists on PyPi is `tensorflow-gpu==2.0.0rc2`. The documentation says `tensorflow-gpu==2.0.0-rc1`, which is 2 typos.\r\n\r\nThe command to install it is `pip install tensorflow-gpu==2.0.0rc2`.\r\n\r\nThe documents say `pip install tensorflow-gpu==2.0.0-rc1`, which is two typos.\r\n\r\nThis bug has existed for all release candidates.\r\n\r\n```python\r\nERROR: Could not find a version that satisfies the requirement tensorflow-gpu==dont_exist (from versions: 0.12.1, 1.0.0, 1.0.1, 1.1.0rc1, 1.1.0rc2, 1.1.0, 1.2.0rc0, 1.2.0rc1, 1.2.0rc2, 1.2.0, 1.2.1, 1.3.0rc0, 1.3.0rc1, 1.3.0rc2, 1.3.0, 1.4.0rc0, 1.4.0rc1, 1.4.0, 1.4.1, 1.5.0rc0, 1.5.0rc1, 1.5.0, 1.5.1, 1.6.0rc0, 1.6.0rc1, 1.6.0, 1.7.0rc0, 1.7.0rc1, 1.7.0, 1.7.1, 1.8.0rc0, 1.8.0rc1, 1.8.0, 1.9.0rc0, 1.9.0rc1, 1.9.0rc2, 1.9.0, 1.10.0rc0, 1.10.0rc1, 1.10.0, 1.10.1, 1.11.0rc0, 1.11.0rc1, 1.11.0rc2, 1.11.0, 1.12.0rc0, 1.12.0rc1, 1.12.0rc2, 1.12.0, 1.12.2, 1.12.3, 1.13.0rc0, 1.13.0rc1, 1.13.0rc2, 1.13.1, 1.13.2, 1.14.0rc0, 1.14.0rc1, 1.14.0, 1.15.0rc0, 1.15.0rc1, 2.0.0a0, 2.0.0b0, 2.0.0b1, 2.0.0rc0, 2.0.0rc1, 2.0.0rc2)\r\n```\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/beta/tutorials/generative/adversarial_fgsm\r\n## Description of issue (what needs changing):\r\n\r\nThe FGSM  implementaiton in the documentation seems to be incorrect.\r\n\r\n### Clear description\r\n\r\nIn the doc, `image_probs` which is equal to the value `model.predict(image)`,  is used to calculate the perturbation.\r\n```python\r\nperturbations = create_adversarial_pattern(image, image_probs)\r\n```\r\n\r\nThe `create_adversarial_pattern` function takes `input_image` and `input_label`. So the above code is the same as the blow code.\r\n```python\r\nperturbations = create_adversarial_pattern(input_image=image, input_label=model.predict(image))\r\n```\r\n\r\nHowever, `input_label` must be not the predicted _probability_ of the model, but the (one hot encoded) correct _label_ of input_image, I think. In fact, it is calculated that\r\n```python\r\nprediction = pretrained_model(input_image)\r\nloss = loss_object(input_label, prediction)\r\n```\r\nin the `create_adversarial_pattern` function.\r\n\r\nSorry if I have misunderstood.\r\n\r\nref. \"EXPLAINING AND HARNESSING ADVERSARIAL EXAMPLES,\" https://arxiv.org/pdf/1412.6572.pdf, p3.\r\n\r\n### ### Submit a pull request?\r\nIf my understanding is correct, I will submit a PR. But I do not have confidence that my understanding is correct yet.\r\n\r\n\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "Hi, I followed the instructions with (this)(https://www.tensorflow.org/install/lang_java?hl=zh-cn).\r\nAnd I add my implementations with bert pb model, but the GPUs are never used\r\n![image](https://user-images.githubusercontent.com/7105813/65370990-769ed480-dc91-11e9-80db-244ed652ff9d.png).\r\nI got Tesla K80, and cuda 9.0 \r\n![image](https://user-images.githubusercontent.com/7105813/65371023-bd8cca00-dc91-11e9-98e2-74f53302ed3e.png)\r\n![image](https://user-images.githubusercontent.com/7105813/65371031-e0b77980-dc91-11e9-8b45-3a2a8746b0bf.png)\r\n\r\nAny suggestions?\r\n\r\n\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue: https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/keras/Model#save\r\n\r\n## Description of issue (what needs changing):\r\n[1.15 branch]\r\nIt appears that the docstring of keras.model.save does not match the docs in 1.15.\r\n\r\nContent is different I think.\r\n\r\nThe bullet points for the input arguments for the save method are not formatted making it hard to read (although this may be poor formatting on the current source for the documentation as the docstring appears to be correctly formatted.).\r\n\r\nA side effect of this is that it also appears that the docs conflicts with the release notes that say the default format is as a `Tensorflow SavedModel ('tf')` however the docs say that the `tf` option is disabled implying that only `.h5` formats can be saved which is contradictory. An update of the docs from the seemingly correct docstring may fix this.\r\n\r\n### Correct links\r\n\r\nThe source code link appears to be correct despite the docstring not matching that of the website docs.\r\n\r\n### Parameters defined\r\n\r\nFormatting issue and also not updated.\r\n\r\n### Returns defined\r\n\r\nDepends on model format.\r\n\r\n### Raises listed and defined\r\n\r\nDepends on model format.\r\n\r\n### Submit a pull request?\r\n\r\nI don't quite understand why this has happened so no.\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "https://www.tensorflow.org/guide/eager#top_of_page\r\nsays\r\n\"For a collection of examples running in eager execution, see: tensorflow/contrib/eager/python/examples.\"\r\n\r\nThe link to `https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples` returns a 404 error."
  },
  {
    "labels": [null, "documentation"],
    "text": "Looking at ```Scenario 3``` in https://github.com/tensorflow/tensorflow/issues/new?labels=type%3Adocs&template=20-documentation-issue.md\r\n\r\nIt has a link to the class ```StreamExecutor``` but the link leads to the empty class with comments suggesting that it has been removed (?)\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "In\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs\r\nthe `Swift (Early Release)`  link points to `https://www.tensorflow.org/versions/r2.0/swift` which shows a 404 page.\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## Link\r\nhttps://www.tensorflow.org/api_docs/python/tf/signal/inverse_stft\r\n\r\n## Description of issue:\r\nI am missing what the output dimensions are.\r\n\r\n### Clear description\r\n\r\nI do not know what the output dimensions of inverse_stft are. And I do not know how they come to be.\r\n\r\n### Example Code\r\n\r\n```\r\naudioNp = np.random.random((1,120800)).astype(np.float32)\r\nframe_length = 2048\r\nframe_step = 2048//4\r\nstft = tf.contrib.signal.stft(\r\n    audioNp[0], \r\n    frame_length, \r\n    frame_step)\r\ninvstft = tf.contrib.signal.inverse_stft(\r\n    stft, \r\n    frame_length, \r\n    frame_step, \r\n    window_fn = tf.contrib.signal.inverse_stft_window_fn(frame_step))\r\nsess = tf.Session()\r\nstft, invstft = sess.run((stft, invstft))\r\nprint(invstft.shape)\r\n```\r\nThe output shape of invstft is then (120320,). And I don't know how it got there. In my opinion it should be again (120800).\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Such as:\r\n\r\n1. Global Flow Chart of Tensorflow\r\n2. Graph modify for Model Optimization(Insert an op in backend)\r\n3.  Basic Data Structure(Data management)\r\n4. Detail of Communication for Distribute Strategy"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "The tutorial given here: \r\n[https://www.tensorflow.org/beta/tutorials/generative/pix2pix](https://www.tensorflow.org/beta/tutorials/generative/pix2pix) no longer works on a clean install of the current tf2 rc. \r\n\r\nit breaks around the 16th block. \r\n\r\nI wasn't sure where to report this problem\r\n\r\n```\r\n\r\nWARNING:tensorflow:Entity <function load_image_train at 0x10e71cf80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\r\nWARNING: Entity <function load_image_train at 0x10e71cf80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\r\n\r\n---------------------------------------------------------------------------\r\nOperatorNotAllowedInGraphError            Traceback (most recent call last)\r\n<ipython-input-16-e1fc1fbf2b89> in <module>\r\n      2 train_dataset = train_dataset.shuffle(BUFFER_SIZE)\r\n      3 train_dataset = train_dataset.map(load_image_train,\r\n----> 4                                   num_parallel_calls=tf.data.experimental.AUTOTUNE)\r\n      5 train_dataset = train_dataset.batch(1)\r\n\r\n~/anaconda3/envs/playground/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py in map(self, map_func, num_parallel_calls)\r\n   1902       return DatasetV1Adapter(\r\n   1903           ParallelMapDataset(\r\n-> 1904               self, map_func, num_parallel_calls, preserve_cardinality=False))\r\n   1905 \r\n   1906   @deprecation.deprecated(None, \"Use `tf.data.Dataset.map()\")\r\n\r\n~/anaconda3/envs/playground/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py in __init__(self, input_dataset, map_func, num_parallel_calls, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\r\n   3452         self._transformation_name(),\r\n   3453         dataset=input_dataset,\r\n-> 3454         use_legacy_function=use_legacy_function)\r\n   3455     self._num_parallel_calls = ops.convert_to_tensor(\r\n   3456         num_parallel_calls, dtype=dtypes.int32, name=\"num_parallel_calls\")\r\n\r\n~/anaconda3/envs/playground/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py in __init__(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\r\n   2693       resource_tracker = tracking.ResourceTracker()\r\n   2694       with tracking.resource_tracker_scope(resource_tracker):\r\n-> 2695         self._function = wrapper_fn._get_concrete_function_internal()\r\n   2696         if add_to_graph:\r\n   2697           self._function.add_to_graph(ops.get_default_graph())\r\n\r\n~/anaconda3/envs/playground/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _get_concrete_function_internal(self, *args, **kwargs)\r\n   1852     \"\"\"Bypasses error checking when getting a graph function.\"\"\"\r\n   1853     graph_function = self._get_concrete_function_internal_garbage_collected(\r\n-> 1854         *args, **kwargs)\r\n   1855     # We're returning this concrete function to someone, and they may keep a\r\n   1856     # reference to the FuncGraph without keeping a reference to the\r\n\r\n~/anaconda3/envs/playground/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)\r\n   1846     if self.input_signature:\r\n   1847       args, kwargs = None, None\r\n-> 1848     graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n   1849     return graph_function\r\n   1850 \r\n\r\n~/anaconda3/envs/playground/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _maybe_define_function(self, args, kwargs)\r\n   2148         graph_function = self._function_cache.primary.get(cache_key, None)\r\n   2149         if graph_function is None:\r\n-> 2150           graph_function = self._create_graph_function(args, kwargs)\r\n   2151           self._function_cache.primary[cache_key] = graph_function\r\n   2152         return graph_function, args, kwargs\r\n\r\n~/anaconda3/envs/playground/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   2039             arg_names=arg_names,\r\n   2040             override_flat_arg_shapes=override_flat_arg_shapes,\r\n-> 2041             capture_by_value=self._capture_by_value),\r\n   2042         self._function_attributes,\r\n   2043         # Tell the ConcreteFunction to clean up its graph once it goes out of\r\n\r\n~/anaconda3/envs/playground/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    913                                           converted_func)\r\n    914 \r\n--> 915       func_outputs = python_func(*func_args, **func_kwargs)\r\n    916 \r\n    917       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\n~/anaconda3/envs/playground/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py in wrapper_fn(*args)\r\n   2687           attributes=defun_kwargs)\r\n   2688       def wrapper_fn(*args):  # pylint: disable=missing-docstring\r\n-> 2689         ret = _wrapper_helper(*args)\r\n   2690         ret = structure.to_tensor_list(self._output_structure, ret)\r\n   2691         return [ops.convert_to_tensor(t) for t in ret]\r\n\r\n~/anaconda3/envs/playground/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py in _wrapper_helper(*args)\r\n   2632         nested_args = (nested_args,)\r\n   2633 \r\n-> 2634       ret = autograph.tf_convert(func, ag_ctx)(*nested_args)\r\n   2635       # If `func` returns a list of tensors, `nest.flatten()` and\r\n   2636       # `ops.convert_to_tensor()` would conspire to attempt to stack\r\n\r\n~/anaconda3/envs/playground/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py in wrapper(*args, **kwargs)\r\n    235       except Exception as e:  # pylint:disable=broad-except\r\n    236         if hasattr(e, 'ag_error_metadata'):\r\n--> 237           raise e.ag_error_metadata.to_exception(e)\r\n    238         else:\r\n    239           raise\r\n\r\nOperatorNotAllowedInGraphError: in converted code:\r\n\r\n    <ipython-input-14-e5f2b44984ba>:3 load_image_train\r\n        input_image, real_image = random_jitter(input_image, real_image)\r\n    <ipython-input-12-b7170a9df479>:8 random_jitter\r\n        if tf.random.uniform(()) > 0.5:\r\n    /Users/nathan/anaconda3/envs/playground/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:765 __bool__\r\n        self._disallow_bool_casting()\r\n    /Users/nathan/anaconda3/envs/playground/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:528 _disallow_bool_casting\r\n        \"using a `tf.Tensor` as a Python `bool`\")\r\n    /Users/nathan/anaconda3/envs/playground/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:513 _disallow_when_autograph_disabled\r\n        \" Try decorating it directly with @tf.function.\".format(task))\r\n\r\n    OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed: AutoGraph is disabled in this function. Try decorating it directly with @tf.function.\r\n\r\n```"
  },
  {
    "labels": [null, null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/guide/eager#summaries_and_tensorboard\r\n\r\n## Description of issue (what needs changing):\r\n\r\nWe should not recommend the usage of `tf.contrib.summary` in eager mode.\r\n`tf.compat.v2.summary` (or `tf.summary` in TF2) should be used in this section.\r\n\r\nWith `tf.contrib.summary`, we need to use `always_record_summaries()` or `record_summaries_every_n_global_steps()` (#32587) to record events even in eager mode. This is very unnatural and confusing.\r\n\r\nWhen I read this section, I thought `record_summaries_every_n_global_steps()` is optional and spent a lot of time to notice why `tf.contrib.summary.scalar` operations in my code was no-op.\r\n\r\nIn eager mode, I think we should recommend code like:\r\n\r\n```\r\nfor i in range(num_steps):\r\n  loss = train_one_step()\r\n  step = i + 1\r\n  if step % 100 == 0:\r\n    tf_summary.scalar('loss', loss, step=step)\r\n```\r\n\r\nwith `tf.compat.v2.summary`.\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? \r\n\r\n**Yes**\r\n\r\nSee the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, null, null, null, "documentation"],
    "text": "Looks like the documentation for tf.estimator.EstimatorSpec got lost along the way from 1.13 to 1.14. Can we please add it back in?\r\n\r\n## URL(s) with the issue: https://www.tensorflow.org/versions/r1.14/api_docs/python/tf/estimator/EstimatorSpec\r\nhttps://www.tensorflow.org/versions/r1.15/api_docs/python/tf/estimator/EstimatorSpec\r\n\r\n## Description of issue (what needs changing): Reinstate documentation (see https://www.tensorflow.org/versions/r1.13/api_docs/python/tf/estimator/EstimatorSpec)\r\n\r\n### Submit a pull request? no"
  },
  { "labels": ["documentation"], "text": "" },
  {
    "labels": ["documentation"],
    "text": "\r\n## URL(s) with the issue:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md#contributor-license-agreements\r\n\r\n## Description of issue (what needs changing):\r\n\r\nI have no idea what any of this legal mumbo-jumbo actually entails.  \"Grant of Patent License\", \"Grant of Copyright License\".  Do I own my contributions?  Does Google own my contributions?  What does all of this mess mean?  If I create something and \"give it away\", I want to make it free as in gratis and as in libre widely, and not just to Google.  Is that happening here?  Does Google charge/restrict people (e.g. corporations) using tensorflow?  *Can* Google charge/restrict people using tensorflow and/or my contributions? \r\n\r\n### Submit a pull request?\r\nNo.\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/tutorials/estimators/linear\r\n\r\n## Description of issue (what needs changing):\r\n`https://github.com/tensorflow/models` has `wide_deep` in `official.r1.wide_deep` but the documentation says it's in `official.wide_deep`.\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "In the original paper of BERT it is said:\r\n\r\n> Note that the purpose of the masking strategies is to reduce the mismatch between pre-training and fine-tuning, as the [MASK] symbol never appears during the fine-tuning stage.\r\n\r\nLet's consider a sentence \"I am a Liverpool fan\" which with 40% masking will be transformed into \"I [MASK] a [MASK] fan\". When predicting the first [MASK], will it be predicted by a phrase \"I [MASK] a fan\", excluding the second [MASK] or \"I [MASK] a [MASK] fan\", by a full sentence?\r\n\r\nAnd what is the purpose of replacing 10% of masked tokens with themselves? Does it mean they will not be predicted? Or we will predict them, having themselves in the context (like predicting the first [MASK] by \"I am a [MASK] fan\"?\r\n\r\nWill be very grateful for any help!"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "Thank you for explaining about tf.scatter_nd using some wonderful visualizations. I have a doubt whether the cubes used for the higher dimensional explanation of tf.scatter_nd is right or not.\r\nPlease check the visualization of the Cube tagged as 'output' in [tf.scatter_nd](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/scatter_nd#) documentation, the second and fourth indices are shaded whereas the given indices according to the example is tf.constant([[0], [2]]) so the first and third indices (0 , 2) should be shaded instead of second and fourth. Please correct me if I'm wrong\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://colab.research.google.com/github/tensorflow/docs/blob/r2.0rc/site/en/tutorials/keras/basic_classification.ipynb#scrollTo=9ODch-OFCaW4&line=2&uniqifier=1\r\n## Description of issue (what needs changing):\r\n\r\nI was browsing the beginner tutorial for basic_classification. It was at the above link. In the section **Setup the Layers** it is throwing a warning when running:\r\n\r\n`WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nCall initializer instance with the dtype argument instead of passing it to the constructor`\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "The link <https://drive.google.com/open?id=1u46mTtAMZ7Y1aD-He1u3R8AE4ZyEpnOl>\r\non page `tensorflow/lite/experimental/micro/README.md` for `STM32F746G Discovery Board` links to keil project based files instead of `Make/GCC` based files."
  },
  {
    "labels": ["documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/install/gpu\r\n\r\n## Description of issue (what needs changing):\r\n\r\n1. change your language to chinese simplified from the upright corner.\r\n2. in the apt installation commands for Ubuntu 18.04 (CUDA 10), last step shown below is wrong:\r\n\r\n```\r\n  # Install TensorRT. Requires that libcudnn7 is installed above.\r\n    sudo apt-get update && \\\r\n            && sudo apt-get install -y --no-install-recommends libnvinfer-dev=5.1.5-1+cuda10.0\r\n```\r\n\r\n1.  there is a syntax error--> && \\ &&\r\n2.  libnvinfer5=5.1.5-1+cuda10.0  should be installed first before libnvinfer-dev=5.1.5-1+cuda10.0\r\n3.  just change the commands to the same as what is shown in english-language website.\r\n\r\n\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "The link for `tf.transpose` on page https://www.tensorflow.org/lite/guide/ops_compatibility#compatible_operations\r\nis broken."
  },
  {
    "labels": [null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "# URL(s) with the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/ones_like\r\n\r\n# Description of the issue (what needs changing):\r\nchange \"Creates a tensor with all elements set to zero.\" to \"Creates a tensor with all elements set to one.\""
  },
  {
    "labels": [null, "documentation"],
    "text": "I'm looking for documentation with all of the `TF_*` environment variables that can be set to make `./configure` unattended. All I can find are various github issues or random articles using them, but is there a definitive official list somewhere?"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "I have a hybrid tflite model, e.g. was converted with the option\r\n\r\n`converter.target_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]`\r\n\r\nSo it contains both tflite ops and normal ops. I test a lot, so this is quicker than implementing the missing parts myself. When trying to load the model with an interpreter, either with the Python or the C++ API, I get errors:\r\n\r\nPython\r\n```\r\nRuntimeError: Regular TensorFlow ops are not supported by this interpreter. Make sure you invoke the Flex delegate before inference.Node number 4 (Flex) failed to prepare.\r\n```\r\nC++\r\n```\r\nINFO: Initialized TensorFlow Lite runtime.\r\nERROR: Regular TensorFlow ops are not supported by this interpreter. Make sure you invoke the Flex delegate before inference.\r\nERROR: Node number 4 (FlexSoftplus) failed to prepare.\r\n```\r\n\r\nIt doesn't seem there are docs that cover how to treat this error and load such hybrid models correctly. If I have missed any docs by any chance, please share the link!"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://tensorflow.google.cn/versions/r2.0/api_docs/python/tf/feature_column/shared_embeddings\r\n\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe description in the document is a way to use the shared_embedding_columns module, but the title is the shared_embeddings module, and the shared_embedding_columns module has been removed in tensorflow2.0.\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "#31958  URL(s) with the issue:\r\nhttps://developers.google.cn/machine-learning/crash-course/reducing-loss/video-lecture\r\n\r\n## Description of issue (what needs changing):\r\nOn 1:50,it prompts me to do the gradient-descent practice，when i click the button,then redirect to the wrong page.\r\n\r\n### Correct links\r\n\r\nhttps://developers.google.cn/machine-learning/crash-course/reducing-loss/gradient-descent\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "All the link on the following page is forwarding to a 404 page.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/xla/g3doc/operation_semantics.md"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "I have been trying since 5 days to train a simple text classification model on TPUs. But because of lack of documentation it is very difficult. I just can not perform tokenization, encoding, padding without `tf.py_func`. Please add some examples for doing these steps for TPU devices so that dumb people like me can understand TF. Will be greatly thankful to everyone at Google.\r\nI am following this [tutorial](https://www.tensorflow.org/beta/tutorials/load_data/text#split_the_dataset_into_text_and_train_batches)."
  },
  {
    "labels": [null, "documentation"],
    "text": "Hi,\r\n\r\nOn https://www.tensorflow.org/lite/guide/python the sample Interpreter code is wrong \r\n\r\n![image](https://user-images.githubusercontent.com/2943831/63538358-9b562f80-c4cc-11e9-8cac-d81786a1acad.png)\r\n\r\n\"from tflite_runtime import Interpreter\"  should be changed to\r\n\r\n\"from tflite_runtime.interpreter import Interpreter\"\r\n\r\n\r\nThanks\r\n\r\nHakan\r\n\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "## URL with the issue:\r\nhttps://www.tensorflow.org/guide/keras\r\nhttps://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/keras.ipynb\r\nhttps://github.com/tensorflow/docs/blob/master/site/en/guide/keras.ipynb\r\n\r\n## Description of issue (what needs changing):\r\nThe last two links are directed to 404, which means they don't exist with valid colab files or gitlab files."
  },
  {
    "labels": [null, null, null, null, "documentation"],
    "text": "I am trying to write my code for using TPUs. However, I can not simply just tokenize the texts. I have tried many things to make it work but it just can not. There is NO documentation on Tensorflow on how to do it without enabling eager execution in TF1.14. \r\n````\r\ntokenizer = tfds.features.text.Tokenizer()\r\nvocabulary_set = set()\r\nfor text_tensor, _ in all_labeled_data:\r\n  some_tokens = tokenizer.tokenize(text_tensor)\r\n  vocabulary_set.update(some_tokens)\r\n````\r\nI am receiving following error\r\n`TypeError: Expected binary or unicode string, got <tf.Tensor 'IteratorGetNext_5:0' shape=() dtype=string>`\r\nI can not get the valiue of this iterator even by using `session.run`. THere is literally no help from Tensorflow on how to tokenize inputs for simple text classification without eager mode."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/xla/jit\r\n\r\n## Description of issue (what needs changing):\r\nGetting not found when opening\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "Hello,\r\nWhere one can find how to transform models to be suitable for working with tensorflow lite for gpu?\r\nWhat should i do to transfer images from 3 components to 4 components.\r\nI am trying to work with mtcnn. I have converted it successfully to tflite, works fine on the cpu,\r\n\r\nERROR: Next operations are not supported by GPU delegate:\r\nNEG: Operation is not supported.\r\nFirst 2 operations will run on the GPU, and the remaining 40 on the CPU.\r\nWARN: compileToBinary(256):\r\nC:\\fakepath(86,169-182): warning X3556: integer divides may be much slower, try using uints if possible.\r\nC:\\fakepath(86,246-259): warning X3556: integer modulus may be much slower, try using uints if possible.\r\n\r\nERROR: TfLiteGpuDelegate Invoke: ConvertToPHWC4: Input data size does not match expected size: 12288000 != 6912\r\nERROR: Node number 27 (TfLiteGpuDelegate) failed to invoke."
  },
  {
    "labels": [null, "documentation"],
    "text": "\r\nBroken URL : https://www.tensorflow.org/tfx/serving/serving_config#batching_configuration\r\n\r\nAll the link under batching configuration section return 404. \r\n\r\nExample links : \r\n\r\n1. https://www.tensorflow.org/tfx/batching/README#servers_with_multiple_models_model_versions_or_subtasks\r\n\r\n2. https://www.tensorflow.org/tfx/batching/README\r\n\r\n3. https://www.tensorflow.org/tfx/batching/README#batch_scheduling_parameters_and_tuning\r\n\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue: https://github.com/tensorflow/tensorflow/blob/r1.14/tensorflow/python/keras/layers/recurrent.py#L1615 https://github.com/tensorflow/tensorflow/blob/r1.14/tensorflow/python/keras/layers/recurrent.py#L1718\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/GRUCell\r\n\r\n## Description of issue (what needs changing):\r\nThe `states` argument to tf.keras.layers.GRUCell.call() is indexed with `h_tm1 = states[0]  # previous memory`, and the function returns `h` and `[h]`, which is the same value?\r\n\r\n### Clear description\r\nWhy does this occur? Its inconsistent with the pytorch torch.nn.GRUCell implementation (https://pytorch.org/docs/stable/nn.html#grucell). \r\n\r\nI noticed the `states` issue when I was converting a project from pytorch to tf.keras and the same code, with just the GRUCell swapped from pytorch to tf.keras, did not work. The error message was `tensorflow.python.framework.errors_impl.InvalidArgumentError: In[0] is not a matrix. Instead it has shape [200] [Op:MatMul] name: transition/gru_cell/MatMul/`, and the solution was to replace my `hidden` with `[hidden]` for the states parameter. \r\n\r\nFurthermore, when I got my return types, they were a tuple rather than the output. Upon further inspection, the tuple CONTAINED THE SAME VALUE TWICE.\r\n\r\nIs there any reason it does this? In the doc this is not explained AT ALL.\r\n\r\n### Correct links\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.14/tensorflow/python/keras/layers/recurrent.py#L1615\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.14/tensorflow/python/keras/layers/recurrent.py#L1718\r\n\r\n### Parameters defined\r\n`states` parameter is the confusing one in question.\r\n\r\n### Returns defined\r\n`return h, [h]` makes no sense\r\n\r\n### Raises listed and defined\r\nIrrelevant\r\n\r\n### Usage example\r\nself.rnn = tf.keras.layers.GRUCell(num_units)\r\nself.rnn(input, hidden)\r\n\r\nwhere input, hidden = shape(N, num_units) doesn't work. Needs to be changed to:\r\nself.rnn(input, [hidden]) to execute.\r\n\r\nFurthermore, on the LHS of self.rnn, rather than just an x = self.rnn(...), I need to do x, _ = self.rnn(...)\r\nWhy?\r\n\r\n### Submit a pull request?\r\nI would gladly change this if someone would confirm this is an issue."
  },
  {
    "labels": [null, null, null, null, "documentation"],
    "text": "Hi everyone,\r\nThanks for your work on maintaining and developing Tensorflow.\r\n\r\nI wish to raise a suggestion for the documentation of the `tf.data.Dataset` Python API.\r\nIn particular, I am referring to the documentation of the `shard` operation.\r\n\r\n## URL(s) with the issue:\r\n\r\nr1.14 docs: https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shard\r\n\r\nr2.0 docs: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset#shard\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nFrom my understanding of the source code, the `shard` operation is **deterministic**. \r\ni.e. if we apply `shard` on a Dataset A with some fixed values of `num_shards` and `index`, the operation will always return the same subset of Dataset A.\r\n\r\nPerhaps the documentation should mention that this operation is deterministic?\r\nThis will help readers understand that the sharding does not involve any randomness.\r\nCurrently, the docs do not mention this aspect of `shard`'s behaviour.\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct? Yes\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly? Yes\r\n\r\n### Returns defined\r\n\r\nAre return values defined? Yes\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? Yes\r\n\r\n### Usage example\r\n\r\nIs there a usage example? Yes\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? No, but this issue does not require visuals\r\n\r\n### Submit a pull request?\r\n\r\nI can submit a PR to update the docs - if this is indeed considered a useful fix.\r\n\r\nThanks for your time."
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/GraphKeys\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe GraphKeys doc is lacking explanation of ('__variable_store',) and ('__varscope',) keys relation to the others collections e to the variable creation in in a variable scope context.\r\nIn my modelling, since iam building a dnn from scratch, its cond sine-qua-non to estimate memory usage like given in this  for VGGNet \r\nhttp://cs231n.github.io/convolutional-networks/#case\r\n\r\nHowever to me its not clear which tensors summup the computation memory allocations (even if it initializes in the runtime, you should be able to pre-calculate the estimative from the graph builted, before running).\r\n\r\nSo iam able to realize the relations of scopes counting, variable creation and using, will be hard to do such kind of memory estimation function.\r\n\r\nToday iam using ._collections['variables'], i think it subsums the variables used in any session of training.\r\n\r\n### Clear description\r\n\r\nCollections are created in the modelling process with the intent of variable management for some functional reason. The developer must have a clear image of which is the intent of each collection and the inter-relation of them (this is somewhat done in GraphKeys, but the mentioned keys are lacking).\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n\r\n### More Info\r\n\r\nI have seem the RFC and know that the 2.0beta Variable became abs class and the management and implementation is more flexible, but now i dont have time to migrate the code, so i think this is stuff is good to keep-up updated (if it is possible and desirable by TFlow team), more people may be in the same condition ."
  },
  {
    "labels": ["documentation"],
    "text": "The tutorial say using tfdv.validate_tfexamples_in_tfrecord to check for errors on a per-example basis. But I can't import it, and also can't find source in code.\r\n\r\nPlease check this function .\r\n## URL(s) with the issue:https://www.tensorflow.org/tfx/data_validation/get_started\r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_tensor_slices\r\n\r\n## Description of issue (what needs changing):\r\n\r\nWhile following Google's ML crash course, I found it very difficult to understand the difference between `Dataset.from_tensors/from_tensor_slices` and when to use each. One thing that confused me was that `from_tensors` only creates a single tensor, despite the name including the plural form \"tensors\".\r\n\r\nBeginners get introduced to these APIs very early, but the current documentation consists of one terse sentence about behaviour (plus a multi-line warning about memory usage):\r\n\r\n```\r\nFTS:\r\nCreates a Dataset whose elements are slices of the given tensors.\r\n\r\nFT:\r\nCreates a Dataset with a single element, comprising the given tensors.\r\n```\r\n\r\nI think this would benefit from some elaboration and a clearer description of how the two are related. Given that users enocunter this API very early, the behaviour should ideally be obvious. A small example would help communicate this, e.g:\r\n\r\n```\r\nmy_data = { \"my_feature\" : [ [1, 2, 3], [4, 5, 6] ] }\r\ntf.data.Dataset.from_tensors(my_data) # Models a single, 2x3 tensor.\r\n```\r\n\r\n```\r\nmy_data = { \"my_feature\" : [ [1, 2, 3], [4, 5, 6] ] }\r\ntf.data.Dataset.from_tensor_slices(my_data) # Splits on rows. Models two, 1x3 tensors.\r\n```\r\n\r\n### Clear description\r\n\r\n### Correct links\r\n\r\nFine AFAIK\r\n\r\n### Parameters defined\r\n\r\nFine AFAIK\r\n\r\n### Returns defined\r\n\r\nFine AFAIK\r\n\r\n### Raises listed and defined\r\n\r\nFine AFAIK\r\n\r\n### Usage example\r\n\r\n**There is currently no usage example, and I think the documentation would greatly benefit from one.**\r\n\r\n### Request visuals, if applicable\r\n\r\nThere are currently no visuals. They might possibly help, but I think a usage example is probably sufficient. \r\n\r\n### Submit a pull request?\r\n\r\nI'm not sure if I'll submit a PR to improve this. I'd like to, but I'm still quite new to TF and wouldn't like to introduce any inaccuracies.\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/backend/relu\r\n\r\n## Description of the issue (what needs changing):\r\n\r\nThe documentation GitHub symbol link on the official `API_Docs` redirects to another symbol than the expected symbol.\r\n\r\n### Correct links\r\n\r\nNo\r\n\r\n### Parameters defined\r\n\r\nNo\r\n\r\n### Returns defined\r\n\r\nNo\r\n\r\n### Raises listed and defined\r\nNo\r\n\r\n### Usage example\r\n\r\nNo\r\n\r\n### Request visuals, if applicable\r\n\r\nYes\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nthe provided wrapper function has no docs\r\n\r\n## Description of issue (what needs changing):\r\n\r\nprovide a docs such\r\nexamples of usage:\r\nTransformGraph( graph.as_graph_def(), [], [], ['remove_nodes(op=loss/init)']) ...\r\n\r\n### Clear description\r\n\r\nI wanna to use this method has a way to do specifics editions and graph redefinitions while building the model, from inside python, withou having to go to command line.\r\n\r\n### Parameters defined\r\n\r\nI think how to use the parameters are exactly the problem, the README.md from the repository gives bazel example, but it dosnt work as it should in the wrapper\r\n### Usage example\r\n\r\nthis is my first try, i could not get the desirable result (strip init op from graph):\r\n\r\n```python\r\ngraph = tf.Graph()\r\nwith graph.as_default():\r\n\r\n  with tf.variable_scope('signal_in'):\r\n    signal_in = tf.placeholder(tf.float32, shape=(10,40,2,1))\r\n\r\n  with tf.variable_scope('dascope1'):\r\n    conv_linear = tf.keras.layers.Conv2D( 8, (8,2), padding='valid', name='conv_linear', use_bias=True, kernel_initializer=tf.initializers.lecun_normal(seed=137), bias_initializer=tf.initializers.lecun_normal(seed=137) )(signal_in)\r\n  \r\n  with tf.variable_scope('softmax'):\r\n    logits = tf.contrib.layers.fully_connected(conv_linear, 2, activation_fn=None, normalizer_fn=None, normalizer_params=None, weights_initializer=tf.initializers.lecun_normal(seed=731), weights_regularizer=None, biases_initializer=tf.initializers.lecun_normal(seed=777), biases_regularizer=None, reuse=None, variables_collections=None, outputs_collections=None, trainable=True, scope='logit')\r\n    softmax = tf.nn.softmax(logits,axis=0)            \r\n    \r\n  with tf.variable_scope('loss'):\r\n    l_vec = tf.placeholder(tf.float32, shape=(10,2))\r\n    loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False, label_smoothing=0)(l_vec, softmax)         \r\n    minimize_op = tf.train.AdamOptimizer(learning_rate=0.05).minimize(loss)\r\n    tf.global_variables_initializer()\r\n```\r\nthen:\r\n\r\n```python\r\ngraphdef = tf.tools.graph_transforms.TransformGraph( graph.as_graph_def(), [], [], ['remove_nodes(op=loss/init)'])\r\n\r\nwith tf.Graph().as_default() as g:  \r\n  tf.import_graph_def(graphdef,name = '')\r\n  for op in g.get_operations():\r\n    if op.name.split('/')[-1] == 'init':\r\n      print('True')\r\n``` \r\n\r\nreturns True\r\nSo how to use this wrapper ? note that init op dosnt have any input output but only dependency arrows as input.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nWaiting for instructions of the community about the use of this function.\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution: \r\n[Platform 1]\r\nNAME=\"Ubuntu\"\r\nVERSION=\"16.04.5 LTS (Xenial Xerus)\"\r\nID=ubuntu\r\nID_LIKE=debian\r\nPRETTY_NAME=\"Ubuntu 16.04.5 LTS\"\r\nVERSION_ID=\"16.04\"\r\n\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n\r\n[Platform 2]\r\nPRETTY_NAME=\"Mendel GNU/Linux 3 (Chef)\"\r\nNAME=\"Mendel GNU/Linux\"\r\nVERSION_ID=\"3\"\r\nVERSION=\"3 (chef)\"\r\nID=mendel\r\nID_LIKE=debian\r\n\r\n- TensorFlow installed from (source or binary): {Didn't install trying to use tflite_runtime} [TFLITE RUNTIME](https://www.tensorflow.org/lite/guide/python#run_an_inference_using_tflite_runtime)\r\n- TensorFlow version: N/A\r\n- Python version: Mendel 3.5.3 / Ubuntu 16.04 3.6.9\r\n- Installed using virtualenv? pip? conda?: virtualenv\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source):  Mendel (gcc (Debian 6.3.0-18+deb9u1) 6.3.0 20170516), Ubuntu 16.04 (gcc (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609)\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\nI tried to install the TFLITE Runtime using \r\n\r\nhttps://www.tensorflow.org/lite/guide/python#run_an_inference_using_tflite_runtime\r\n\r\nWhen I tried to import as follows.\r\n\r\n`from tflite_runtime import Interpreter`\r\n\r\nI get the following error in both devices (Ubuntu 16.04 and Mendel)\r\n\r\n`>>> from tflite_runtime import Interpreter\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n`\r\n\r\nBut when I just do \r\n\r\n`import tflite_runtime`\r\n\r\nDoesn't give me an error in either platform. \r\nI tried using IntelliSense and it shows me no Interpreter API. \r\n\r\nAm I doing something wrong? How to fix this issue? \r\n\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\n[tf.data.dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle)\r\n[model.fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit)\r\n\r\n## Description of issue (what needs changing):\r\nMy `tf.data.Dataset` does not have `repeat` set which means it should go forever. At the end of `steps_per_epoch`, does the `tf.data.Dataset` shuffle itself? Or does it pick up from where it left off? Or does it reset? \r\n\r\nI couldn't find a clear explanation online from the googling I did. My dataset is about 14 million examples, and the loss seems to be decreasing between epochs (with `steps_per_epoch` set). I'm just worried that it's fitting on the same X samples again and again\r\n\r\nIt's not entirely clear to me what is happening in the background with `fit`"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "tag:bug_template\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): binary through pip3\r\n- TensorFlow version (use command below): v2.0.0-beta0-16-g1d91213fe7 2.0.0-beta1\r\n- Python version: sys.version_info(major=3, minor=5, micro=6, releaselevel='final', serial=0)\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: 10.0.130_410.48 / 10.0-linux-x64-v7.4.2.24\r\n- GPU model and memory: GeForce GTX 1080 with 7598 MB memory\r\n\r\n**Describe the current behavior**\r\n\r\nIf a tf.Variable is passed as learning_rate to the Adam optimizer, and the variable is later changed that does not seem to affect the optimizer. Instead, the optimizer seems to \"cache\" the value of the variable at the time when the optimizer was constructed.\r\n\r\n**Describe the expected behavior**\r\n\r\nMy expectation was that if I pass a tf.Variable as the learning_rate argument to tf.keras.optimizers.Adam(), and later assign a new value to the variable, that would affect the optimization.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```\r\nimport tensorflow as tf\r\nprint(tf.version.GIT_VERSION, tf.version.VERSION)\r\n\r\nimport sys\r\nprint(sys.version_info)\r\n\r\ntf_a = tf.Variable(1.0)\r\nprint('Variable tf_a initialized to {}.'.format(tf_a.numpy()))\r\n\r\ntf_lr = tf.Variable(0.1, trainable=False)\r\n\r\ntf_opt = tf.keras.optimizers.Adam(learning_rate=tf_lr)\r\n\r\n@tf.function\r\ndef train_step():\r\n    with tf.GradientTape() as tf_tape:\r\n        tf_loss = tf_a**2\r\n        \r\n    tf_gradients = tf_tape.gradient(tf_loss, [tf_a])\r\n\r\n    tf_opt.apply_gradients(zip(tf_gradients, [tf_a]))\r\n\r\nprint('After one step with learning rate {}... '.format(tf_lr.numpy()), end='')\r\ntrain_step()\r\nprint('Variable tf_a is {}.'.format(tf_a.numpy()))\r\n\r\ntf_lr.assign(0.0)\r\n\r\nfor _ in range(10):\r\n    print('After another step, now with learning rate {}... '.format(tf_lr.numpy()), end='')\r\n    train_step()\r\n    print('Variable tf_a is {}.'.format(tf_a.numpy()))\r\n```\r\n\r\nThe code above produces the following output on my system:\r\n\r\n```\r\nv2.0.0-beta0-16-g1d91213fe7 2.0.0-beta1\r\nsys.version_info(major=3, minor=5, micro=6, releaselevel='final', serial=0)\r\nVariable tf_a initialized to 1.0.\r\nAfter one step with learning rate 0.10000000149011612... Variable tf_a is 0.8999971747398376.\r\nAfter another step, now with learning rate 0.0... Variable tf_a is 0.8004083633422852.\r\nAfter another step, now with learning rate 0.0... Variable tf_a is 0.7015821933746338.\r\nAfter another step, now with learning rate 0.0... Variable tf_a is 0.6039347052574158.\r\nAfter another step, now with learning rate 0.0... Variable tf_a is 0.5079591274261475.\r\nAfter another step, now with learning rate 0.0... Variable tf_a is 0.41423195600509644.\r\nAfter another step, now with learning rate 0.0... Variable tf_a is 0.3234161138534546.\r\nAfter another step, now with learning rate 0.0... Variable tf_a is 0.23625943064689636.\r\nAfter another step, now with learning rate 0.0... Variable tf_a is 0.1535806804895401.\r\nAfter another step, now with learning rate 0.0... Variable tf_a is 0.07624538242816925.\r\nAfter another step, now with learning rate 0.0... Variable tf_a is 0.005127914249897003.\r\n```\r\nAs you can see tf_a keeps changing at a fast pace. My expectation was that after setting the learning rate variable to 0.0 updates would no-longer change tf_a.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "tf.contrib.opt.AdamWOptimizer requires two arguments: weight_decay and learning_rate. Since learning_rate is usually decayed along with the training, should weight_decay also be decayed with the same schedule? Would you please provide an example? "
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "\r\n## Documentation contributor guide: \r\nhttps://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/tuple\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n### Correct links\r\nThe GitHub link to `tf.tuple` leads to `tf.tuple_v2`.\r\n### Usage example\r\nThere is no usage example.\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/train/list_variables\r\n\r\n## Description of the issue (what needs changing):\r\nRaises for exceptions to deal with any errors and a few drawings to be added to make it easier to understand.\r\n\r\n### Raises listed and defined\r\nNo, the errors are not listed and returned.\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\nNo, there are not any current visuals.\r\n\r\n### Submit a pull request?\r\n\r\nNo, I am not willing to submit a pull request.\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/backend/random_uniform\r\n\r\n## Description of issue (what needs changing):\r\nThe function has no usage example and there are no errors raised.\r\n\r\n### Raises listed and defined\r\nNo raises listed or defined.\r\n\r\n### Usage example\r\nNo usage example\r\n\r\n### Submit a pull request?\r\nNo.\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "##  URL(s) with the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/nn/log_softmax\r\n\r\n## Description of the issue (what needs changing):\r\n- No errors defined\r\n- No visuals\r\n\r\n### Are the errors defined?\r\n- There are no errors defined\r\n\r\n### Visuals, if applicable\r\n- There are no visuals available. I think that visuals are needed to clarify the content.\r\n\r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/io/encode_jpeg\r\n\r\n## Description of issue (what needs changing):\r\n- No link to github source code provided\r\n- No `Raises` provided in the description\r\n- No usage example\r\n\r\n### Correct links\r\n\r\nNo link provided\r\n\r\n### Raises listed and defined\r\n\r\nRaises are not defined/listed.\r\n\r\n### Usage example\r\n\r\nThere is no usage example\r\n\r\n### Request visuals, if applicable\r\n\r\nCurrently, no visuals, may not be required.\r\n\r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/beta/tutorials/text/transformer#set_hyperparameters\r\n\r\n## Description of issue (what needs changing):\r\nI've been working with the 'Transformer model for language understanding' notebook on my own dataset. I got it to work with the default hyperparameters. The tutorial explains that I can create a Transformer XL by adjusting the hyperparameters to those that are used in the paper. I changed them to the suggested values, and I am now getting a `ValueError` when I try to train.\r\n```\r\nValueError: Tensor's shape (8220, 128) is not compatible with supplied shape (8220, 512)\r\n```\r\nI think that this means that some object is not configured properly (not using the hyper parameter variables), but I can't figure out where it's happening. I tried restarting the runtime and running everything again, but it didn't help.\r\n\r\n## System information\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): I have made small adjustments to the provided code in the transformer notebook to accommodate my own data. I also changed the values of the hyper parameters of the model.\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  I am running the notebook in a Colab GPU runtime; Linux Ubuntu 18.04.2\r\n- TensorFlow installed from (source or binary): I'm not exactly sure, I install it using this command, provided with the notebook `pip install -q tensorflow-gpu==2.0.0-beta1`\r\n- TensorFlow version (use command below): `tensorflow-gpu==2.0.0-beta1`\r\n- Python version: 3.6.8\r\n- CUDA version: CUDA: 10.0.130\r\n- GPU model and memory: I'm not sure how to get this info, but it's a Colab GPU runtime.\r\n\r\n## Code snippets\r\nI changed the output encoder from a `SubwordTextEncoder` to a `TokenTextEncoder`:\r\n```\r\ntokenizer_out = tfds.features.text.TokenTextEncoder(\r\n    unique_concepts\r\n)\r\n```\r\nI changed the `tf_encode` function to use a single argument instead of two:\r\n```\r\ndef tf_encode(element):\r\n    return tf.py_function(encode, [element[0], element[1]], [tf.int64, tf.int64])\r\n```\r\nAnd I changed the hyperparameter values:\r\n```\r\nnum_layers = 6\r\nd_model = 512\r\ndff = 2048\r\nnum_heads = 8\r\n```"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/48af54a586790cc29150be3d8665d7e8a1770257/tensorflow/python/keras/layers/recurrent.py#L2461\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe current documentation reads:\r\n\r\n```\r\n  Call arguments:\r\n    inputs: A 3D tensor.\r\n    mask: Binary tensor of shape `(samples, timesteps)` indicating whether\r\n      a given timestep should be masked.\r\n    training: Python boolean indicating whether the layer should behave in\r\n      training mode or in inference mode. This argument is passed to the cell\r\n      when calling it. This is only relevant if `dropout` or\r\n      `recurrent_dropout` is used.\r\n    initial_state: List of initial state tensors to be passed to the first\r\n      call of the cell.\r\n```\r\n\r\nIt would be worth mentioning that\r\n\r\n- mask, training, and initial_state are optional\r\n- if initial_state is not provided, default zeros are imputed (by calling `cell.get_initial_state()` or `cell.zero_state()`), see tensorflow_core/python/ops/rnn.py lines 677 or 1382.\r\n\r\nDue to iheritance of RNN layers (incl. mixins) and missing documentation at some places (haven't found any comments on `get_initial_state`), it's quite hard to figure it out.\r\n\r\n### Submit a pull request?\r\n\r\nI'd like to keep it to someone who really knows the Keras internals; to me it's still a bit cryptic (i.e., where exactly `get_initial_state_fn` comes from, etc.)"
  },
  {
    "labels": [null, "documentation"],
    "text": "\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/tutorials/guide/keras\r\n\r\n## Description of issue (what needs changing):\r\n\r\ncan't open URL\r\n\r\n\r\n\r\n\r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/beta/guide/keras/training_and_evaluation#specifying_a_loss_metrics_and_an_optimizer\r\n\r\n## Description of issue (what needs changing):\r\n\r\nDocumentation is missing how to write custom loss functions and how to use the keras.losses.Loss class to write a loss function that takes more inputs than just y_true and y_pred despite the portion saying it will show how to write custom losses and metrics. Currently it shows how to write custom metrics and in layer loss only.\r\n\r\n### Clear description\r\n\r\nPeople can use this method to implement loss function not implemented in tensorflow or their own variations of loss functions. It also allows ports of loss functions without a keras.losses exposure such as tf.nn.weighted_cross_entropy_with_logits to be implemented in a model.compile use case without the need to write a custom training loop.\r\n\r\n### Correct links\r\n\r\nN/A\r\n\r\n### Parameters defined\r\n\r\nN/A\r\n\r\n### Returns defined\r\n\r\nN/A\r\n\r\n### Raises listed and defined\r\n\r\nN/A\r\n\r\n### Usage example\r\n\r\nThere is no documentation, but a good example would be porting a loss function from tensorflow.nn to be used in a class extending keras.losses.Loss and showing how to use a user written function without the keras.losses.Loss class.\r\n\r\n### Request visuals, if applicable\r\n\r\nNo visuals are there, but a portion of code similar to the custom metric code shown would be a good visual. \r\n\r\nA custom loss function I wrote in python follows:\r\n```\r\nclass WeightedBinaryCrossEntropy(keras.losses.Loss):\r\n    \"\"\"\r\n    pos_weight: Scalars the effec on loss by the positive class by whatever is passed into it.\r\n    weight: Scalars all the loss. Can be used to increase scalar of negative weight only by passing 1/weight to pos_weight. \r\n            To affect pos_weight even more after this multiply in the other scalar you had in mind for it\r\n    \"\"\"\r\n    def __init__(self, pos_weight, weight, from_logits=False, reduction=keras.losses.Reduction.AUTO, name='weighted_binary_crossentropy'):\r\n        super(WeightedBinaryCrossEntropy, self).__init__(reduction=reduction, name=name)\r\n        self.pos_weight = pos_weight\r\n        self.weight = weight\r\n        self.from_logits = from_logits\r\n\r\n    def call(self, y_true, y_pred):\r\n        if not self.from_logits:\r\n            with tf.name_scope('Weighted_Cross_Entropy'):\r\n                # Manually calculated the weighted cross entropy. Formula is qz * -log(sigmoid(x)) + (1 - z) * -log(1 - sigmoid(x)) where z are labels, x is logits, and q is the weight.\r\n                # Since the values passed are from sigmoid (assumably in this case) sigmoid(x) will be replaces with y_pred\r\n                x_1 = y_true * self.pos_weight * -tf.math.log(y_pred + 1e-6) # qz * -log(sigmoid(x)) 1e-6 is added as an epsilon to stop passing a zero into the log\r\n                x_2 = (1 - y_true) * -tf.math.log(1 - y_pred + 1e-6) # (1 - z) * -log(1 - sigmoid(x)). Epsilon is added to prevent passing a zero into the log\r\n                return tf.add(x_1, x_2) * self.weight # Must be negative as it is maximized when passed to optimizers\r\n        # Use built in function\r\n        return tf.nn.weighted_cross_entropy_with_logits(y_true, y_pred, self.pos_weight) * self.weight\r\n```\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "In TF 1.x it was possible to force CPU only by using:\r\n\r\n```\r\nconfig = tf.ConfigProto(device_count = {'GPU': 0})\r\n```\r\nHowever, `ConfigProto` doesn't exist in TF 2.0 and changing a OS environment variable seems very clunky.\r\n\r\nWhat's the TF 2.0 way of doing this?\r\n\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "Hi,\r\n  I create a `Session` with `tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)`. \r\nWhen I run the `Session`, I use the `top` command to observe the situations. But I found the program still use 1700% CPU. Why did this happen? What's the right way to control the number of cores/threads used by tensorflow?\r\nthx!\r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\nsite/en/r2/tutorials/generative/cvae.ipynb\r\n\r\n## Description of issue (what needs changing): implement @tf.function decorators in the computation to improve performance, and highlight one of the tf 2.0 features.\r\n\r\n### Clear description\r\nWhen implementing in colab the performance improves from 30s / epoch average to 3.6s /epoch which is a huge benefit, and well worth highlighting/recommending by adding only 4 lines of code.\r\n\r\n### Submit a pull request?\r\nI can do that, yes\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "### URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/install/source_windows#install_bazel\r\n\r\n## Description of issue (what needs changing):\r\nIt should be Bazel <0.23.0, not 0.24.1\r\n### Clear description\r\nFirst and last sentence contradict each other:\r\nInstall Bazel 0.24.1,\r\nEnsure you install Bazel 0.23.0 or lower.\r\n\r\n### Correct links\r\n\r\n### Parameters defined\r\n\r\n### Returns defined\r\n\r\n### Raises listed and defined\r\n\r\n### Usage example\r\n\r\n### Request visuals, if applicable\r\n\r\n### Submit a pull request?\r\nNo"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/tensordot\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThere are no `a_axes` and `b_axes` parameters, but the documentation describes the function as if there are.\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "Documentation contributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\nTensorFlow.v.2.0\r\nLink to doc : https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/math/sqrt\r\n\r\n## Doc issue description:\r\n\r\n**1.** The generated file in which this symbol is defined .i.e **python/ops/gen_math_ops.py** is just plain text rather than a link to the source file. It would be great if it's rightly linked to the source file to enable change proposals.\r\n\r\n**2.** There isn't a clear distinction between the choice of usage of either **tf.sqrt** or **tf.math.sqrt** and the implications (may be performance wise) of choosing one over the other.\r\n\r\n**3.** The usage example isn't a complete code sample but largely syntax-like. One of the parameters the function takes is represented by a placeholder symbol rather than a real valued tensor.\r\n\r\n**4.** There should also be a mention of the at-least the common errors that may arise as a result of incorrect usage of this function.\r\n"
  },
  {
    "labels": [null, null, null, null, "documentation"],
    "text": "From respective docs\r\nhttps://www.tensorflow.org/api_docs/python/tf/container\r\nhttps://www.tensorflow.org/api_docs/python/tf/VariableScope\r\n\r\nThe relation between these two context manager is not clear (although variable scope and name scope inter-relation are fine). \r\n\r\nBut from the source code ones can see that they are clearly two things that inter-relates but not the same thing. \r\n\r\nShould i use Container only in the eager mode ? why not use only variable scope or name scope instead? also, maybe other questions will come as people uses low-level API to specialize in tensorflow dev.\r\n\r\nSo i think its an Issue.\r\n\r\nThankyou \r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/io/decode_base64\r\n\r\n## Description of issue (what needs changing):\r\nSome base64 strings contains  \" \".\r\n### Clear description\r\nIt could be useful to add this information after this paragraph:\r\n\r\n> Input may or may not have padding at the end. See EncodeBase64 for padding. Web-safe means that input must use - and _ instead of + and  /.\r\n\r\n\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "<em>In Tensorflow 1.x, I can add regularization losses by using code like this:\r\n`regularization_loss = tf.add_n(tf.losses.get_regularization_losses(), 'regu')`\r\n`total_loss = loss + regularization_loss`\r\nBut in tensorflow 2.0.0beta1 api, the 'losses.get_regularization_losses()' was canceled.So how can I add that loss In this case?\r\n\r\n\r\n**System information**\r\n- TensorFlow version :2.0.0beta1\r\n\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/beta/tutorials/text/transformer#training_and_checkpointing\r\n\r\n## Description of issue (what needs changing):\r\nTeacher-forcing seems to not be implemented?\r\n\r\n### Clear description\r\nThe documentation here mentions that the training uses teacher-forcing, however, it doesn't seem like, with the code shown, that this is implemented. The variable `tar_real` is the true outputs, but it seems to only be used for loss and accuracy computations?\r\n\r\nPlease let me know if I'm making a mistake here! Thanks in advance."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/backend/batch_dot\r\n\r\n## Description of issue (what needs changing):\r\nI raised [an issue on the plaidML repo](https://github.com/plaidml/plaidml/issues/358), and after some back and forth we determined the documentation for BatchDot doesn't quite match the actual implementation in the tensorflow code.\r\n\r\n### Clear description\r\nA BatchDot with x.shape=(1,2,6,2) and y.shape=(1,2,2,3) and axes = (3, 1)has an output shape of (1,2,6,3)) whereas by the TF definition for output shape \"A tensor with shape equal to the concatenation of x's shape (less the dimension that was summed over) and y's shape (less the batch dimension and the dimension that was summed over). If the final rank is 1, we reshape it to (batch_size, 1).\" sounds like it should have an output shape of (1,2,6,2,3).\r\n\r\n### Submit a pull request?\r\nI am not planning to submit a PR at this time, but I may do it later"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Hi,\r\n\r\nPlease accept the following as feedback on my experience of Tensorflow 2.0 (beta):\r\n1. Read the [migration guide](https://www.tensorflow.org/beta/guide/migration_guide) and figured I would give it a go.\r\n2. Installed without issues on my Mac Conda environment.  This was to be the highlight of my successes.\r\n3. The [documentation site](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf) isn't searchable by version and given the frequency and amount of change here it would be nice to find a way to locate where various things have moved to.\r\n4.  By way of example, PhasedLSTMCell, I knew the contrib module is gone in 2.0 but its still in the GitHub 2.0 branch which is misleading.  Further misleading is the comments [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/__init__.py): \r\n> Created in contrib, eventual plans to move to core.\r\n\r\nNo indication of where one might currently find it.\r\n5. Figured it might be in in [Addons](https://github.com/tensorflow/addons) but no luck there.\r\n6. I wanted to use tf.keras for the first time.  Maybe its my Pip/Conda environment but no matter what I did I could not get it to import unless I did import tensorflow._python._keras.  Did I miss this in the docs because I swear I didn't read it anywhere.  \r\nAfter some more poking around I decided I had enough exposure to 2.0 and went back to 1.14 - it did give me some minutes of excitement.\r\n\r\nHowever, I would love 2.0 to be speedily and widely adopted.  The API looks a lot cleaner (from what I read of it, I didn't get to use any ultimately) and I think some improvements around how the documentation is accessible would help uptake.  I'm willing to contribute to help this along if I can.\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "TF 2 Datasets don't appear to have the output_shape property and there is no tf.data.get_output_shapes. \r\n\r\nWhat do we use instead?"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "For implementing CuDNN LSTM, according to [docs](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/LSTM) there are 6 requirements as follows- \r\n\r\n> activation == 'tanh'\r\nrecurrent_activation == 'sigmoid'\r\nrecurrent_dropout == 0\r\nunroll is False\r\nuse_bias is True\r\nInputs are not masked or strictly right padded.\r\n\r\nAccording to my understanding, the last one say to have input sequences not right padded. However, in text classification I want to pad sequences and I am using [the function](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset#padded_batch), now I do not know how to left pad using this function, as I could check it always right pad the input sequences, which means one can never use CuDNN LSTM for training on GPU(s) if they are padding the inputs. However, it can be done easily using `tf.keras..pad_sequences` function, defined [here](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences). "
  },
  {
    "labels": ["documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "Hello TF team,\r\n\r\nI've been combing the documentation for any reference to OpKernels, Graphs defs, the executor, rendezvous, ect... the important abstractions that seem to be near the core of tensorflow. So far I haven't been able to find any kind of high level overview of how they all come together. I'm working on a feature that involves adding a new device and I don't want to miss any important abstractions in my implementation.\r\n\r\nDoes anyone know where I could find documentation that is concerned with how the tensorflow framework / run time work?\r\nThanks,\r\nScott\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "## Description of issue (what needs changing):\r\n\r\nAccording to https://github.com/tensorflow/tensorflow/issues/1574 there was no (open source) way to generate HTML docs from the TensorFlow source code in March of 2016. Is that still the case? I haven't been able to find any way to generate HTML docs from the source.\r\n\r\nGenerating offline HTML docs is useful for having access to offline docs [without having to scrape www.tensorflow.org](https://github.com/ppwwyyxx/dash-docset-tensorflow)."
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "My Environment \r\nWorking sample Link : https://github.com/tensorflow/examples/tree/master/lite/examples/speech_commands/ml\r\nVirtual environment : Anaconda Navigator\r\nEditor : VS Code\r\nMode of execution : VS Code integrated Terminal with Conda envs\r\nOS : Mac OSX\r\n\r\nTensorflow Version : 1.13.1 (as required in the samples requirement)\r\n\r\nWhen i download the sample and run it as it is as per the ReadMe file, everything works perfectly fine. \r\nBut when i try to change the \"-output_representation\" parameter value to 'spec' or 'mfcc' it doesn't work. I get the error `ValueError: total size of new array must be unchanged` in the `model.py line no : 59 x = Reshape([800, 20])(x)`. After a quick traceback i found that the spectrogram fingerprint size is taken as 257x98 for every second. So i change that line to `x = Reshape([257, 98])(x)` and it successfully passed through this line. \r\nBut instead i get the following \r\n```\r\nTraceback (most recent call last):\r\n  File \"/Users/minimaci73/anaconda3/envs/Samples/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1659, in _create_c_op\r\n    c_op = c_api.TF_FinishOperation(op_desc)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Negative dimension size caused by subtracting 3 from 1 for 'conv1d_12/convolution/Conv2D' (op: 'Conv2D') with input shapes: [?,1,1,192], [1,3,192,256].\r\n```\r\nThis happens in the line no 99: `x = _reduce_conv(x, 256, 3)`.\r\n\r\nWhen i downloaded the ios example model and opened it in Netron i can clearly see that it uses audio spectrogram. \r\n\r\nWhat are all the changes that are to be done to train the model with 'spec', 'mfcc' and the 'mfcc_and_raw' ?"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "The [TPUEstimator constructor](https://github.com/JayMody/estimator/blob/e794e634ba52f9e8b04971e74fe24b91857f2228/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py#L2590) requires `train_batch_size` to be set if `use_tpu` is True. \r\n\r\nIn cases when I only want to use a TPU estimator to predict, that means I have to pass in an arbitrary value in for `train_batch_size`. Looking deeper into the code, I can't pinpoint why `train_batch_size` needs to be set when on a TPU, but I'm assuming it's required somewhere deeper in the code. \r\n\r\nIt was very confusing for me, especially since the documentation is conflicting [pull request #37](https://github.com/tensorflow/estimator/pull/37#issue-297115525). \r\n\r\nMaybe an option should be added that if `train_batch_size` is not set, but one of the other two (eval and predict) are, then provide a warning and pass an arbitrary value for `train_batch_size`. Otherwise maybe be more clear with the documentation that `train_batch_size` must always be set when on a TPU, even if you are only predicting or evaluating."
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/gather\r\n\r\n## Description of issue (what needs changing):\r\n\r\nIn TF 1.14, `tf.batch_gather` is marked as deprecated, and the keyword `batch_dims` has been added to `tf.gather` to handle the batch version. Though, the documentation of `tf.gather` has only been updated with the **type** of `batch_dims`, but not **how to use** it neither **what it does**.\r\n\r\nThe old [`tf.batch_gather`](https://www.tensorflow.org/versions/r1.13/api_docs/python/tf/batch_gather) function was documented in TF 1.13. Though, `tf.gather` is a bit more complex than the old `tf.batch_gather`, so maybe the [documentation of the underlying `_batch_gather`](https://github.com/tensorflow/tensorflow/blob/2aca283764bbbd54a5556319eb7cc0ed323c81f1/tensorflow/python/ops/array_ops.py#L3514) function could be used.\r\n\r\nThese two existing documentations could be used to complete the existing documentation of `tf.gather`.\r\n\r\n### Correct links\r\n\r\nYes.\r\n\r\n### Parameters defined\r\n\r\nYes\r\n\r\n### Returns defined\r\n\r\nYes\r\n\r\n### Raises listed and defined\r\n\r\nYes\r\n\r\n### Usage example\r\n\r\nNot for using `batch_dims`.\r\n\r\n### Submit a pull request?\r\n\r\nNo.\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "no way I am gonna fill this\r\nguys, update your doc please ;-)"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r1.13/api_docs/python/tf/keras/experimental/export\r\n\r\n## Description of issue (what needs changing):\r\n\r\nOk, so let's say for some arbitrary reason out of your control (*cough* sagemaker *cough*) you are pegged to TensorFlow <= 1.13.1. The cool new `tf.keras.experimental.export` feature looks a _lot_ easier than building all that stuff yourself, so you go to try and use it.\r\n\r\nUnfortunately, you get hit with the following error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"documented_example.py\", line 10, in <module>\r\n    saved_to_path = tf.keras.experimental.export(\r\nAttributeError: 'module' object has no attribute 'export'\r\n```\r\n\r\n### Correct links\r\n\r\nIt is not -- the part that is `Defined in tensorflow/python/keras/saving/saved_model.py.` links to `https://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/python/keras/saving/saved_model.py` which gets a 404!\r\n\r\n### Parameters defined\r\n\r\nProbably.\r\n\r\n### Returns defined\r\n\r\nVery possible\r\n\r\n### Raises listed and defined\r\n\r\nYep.\r\n\r\n### Usage example\r\n\r\nYes! In fact, it doesn't work.\r\n\r\nFor posterity here's that usage example copy-pasted into a Github gist: https://gist.github.com/zmjjmz/fcc73dad9f49d34f9c047c108fdd0e3f\r\n\r\n### Submit a pull request?\r\n\r\nNope."
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "**System information**\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS (Mojave) 10.14.4\r\n- TensorFlow installed from (source or binary): binary (pip)\r\n- TensorFlow version (use command below): 1.13.1\r\n- Python version: 3.6.7\r\n\r\n- CUDA/cuDNN version: No GPU\r\n- GPU model and memory: No GPU\r\n\r\n**Describe the current behavior**\r\nNone of the following imports work are working on the current version:\r\n```{python}\r\nfrom tensorflow.keras.applications import imagenet_utils\r\nfrom tensorflow.keras.applications.imagenet_utils import preprocess_input\r\n\r\nfrom tensorflow.keras.applications import preprocess_input\r\n```\r\n\r\n**Describe the expected behavior**\r\nThe aforementioned imports should work. I reviewed the source code for branch r1.13 examining file `tensorflow/python/keras/applications/__init__.py`\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/2aca283764bbbd54a5556319eb7cc0ed323c81f1/tensorflow/python/keras/applications/__init__.py#L74-L86\r\n\r\n`preprocess_input` appears to be missing. \r\n\r\n**Code to reproduce the issue**\r\nProvided above.\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/contrib/graph_editor\r\nhttps://www.tensorflow.org/api_guides/python/contrib.graph_editor\r\n\r\n## Description of issue (what needs changing):\r\nThe Graph Editor API Doc (first link above) links to the Graph Editor Guide (second link above) which is a 404 error.\r\n\r\n### Clear description\r\nThe broken link to the Graph Editor Guide needs to either be fixed or removed and replaced with some actual, comprehensive documentation on using the Graph Editor. At the moment, there is no documentation on Graph Editor usage available anywhere.\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "\r\n\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/install/source_windows\r\n\r\n\r\n## Description of issue (what needs changing):\r\n\r\nIt is purely a logical issue:\r\nInstall Bazel 0.24.1, the build tool used to compile TensorFlow. Set up Bazel to build C++.\r\n[...] Ensure you install Bazel 0.23.0 or lower.\r\n\r\n0.24.1 > 0.23.0 \r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/guide/extend/op#compile_the_op_using_your_system_compiler_tensorflow_binary_installation\r\n(Last Note of the paragraph).\r\n\r\n## Description of issue (what needs changing):\r\nThe documentation states that customs ops for the binary pip packages should be compiled with `-D_GLIBCXX_USE_CXX11_ABI=0`. For me this actually had to be removed (python 3.7, tensorflow-gpu==1.14.0  from pip), so I guess tf-1.14 is now built with `gcc > 4`?\r\nIf someone can confirm, I could open a PR :)\r\n\r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "# Description of issue\r\n\r\nThere a mention of a tensorflowlite model in the Google AI team [blog](https://ai.googleblog.com/2019/03/an-all-neural-on-device-speech.html)\r\n\r\n> made publicly available through the model optimization toolkit in the TensorFlow Lite library \r\n\r\nWhere can I find this model? Is this the right place: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/g3doc/models"
  },
  {
    "labels": ["documentation"],
    "text": "\r\n## Description of issue (what needs changing):\r\n\r\nGoogle who to a large extent runs this project has patented dropout.  See https://patents.google.com/patent/US9406017B2/en\r\n\r\nThis patent is not listed as a pledged patent in Google's list of patents that are thus *not* covered by the [Google Open Patent Non-Assertion Pledge](https://www.google.com/patents/opnpledge/patents/)\r\n\r\nSince this could cause serious issues for users, it needs to be documented.\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/image/image_gradients\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/image_ops_impl.py\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Usage example\r\n\r\nNo usage example provided\r\n\r\n### Submit a pull request?\r\n\r\nYes\r\nhttps://github.com/tensorflow/tensorflow/pull/30446"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.14/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py\r\n\r\n## Description of issue (what needs changing):\r\nUsage example of CosineDecay, CosineDecayRestarts, LinearCosineDecay, NoisyLinearCosineDecay takes a parameter \"global_step\" which does not correspond to the definition. \r\n\r\n### Clear description\r\n\r\nThe script defines the various learning rate decay classes used for network training.\r\n\r\n### Usage example\r\n\r\nThere is a usage example. However, it does not correspond to the definition. \r\n\r\n### Submit a pull request?\r\n\r\nI can if required\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/data/Dataset#list_files\r\n\r\n## Description of issue (what needs changing):\r\nIn the doc above, it says \r\n```\r\nNOTE: The default behavior of this method is to return filenames in \r\na non-deterministic random shuffled order. \r\nPass a seed or shuffle=False to get results in a deterministic order.\r\n```\r\n\r\nSo if pass `shuffle=False`, it will return a deterministic order.\r\n\r\nBut if check source code of the function, it calls following function to get matching files.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/data/ops/dataset_ops.py#L769\r\n\r\n```\r\n  @staticmethod\r\n  def list_files(file_pattern, shuffle=None, seed=None):\r\n      ...\r\n      matching_files = gen_io_ops.matching_files(file_pattern)\r\n```\r\n\r\nIf we check description of `gen_io_ops.matching_files`,  it says `Note also that the order of filenames returned can be non-deterministic.`\r\n\r\n```\r\n@tf_export('matching_files')\r\ndef matching_files(pattern, name=None):\r\n  r\"\"\"Returns the set of files matching one or more glob patterns.\r\n\r\n  Note that this routine only supports wildcard characters in the\r\n\r\n  basename portion of the pattern, not in the directory portion.\r\n\r\n  Note also that the order of filenames returned can be non-deterministic.\r\n\r\n  Args:\r\n    pattern: A `Tensor` of type `string`.\r\n      Shell wildcard pattern(s). Scalar or vector of type string.\r\n    name: A name for the operation (optional).\r\n\r\n  Returns:\r\n    A `Tensor` of type `string`.\r\n  \"\"\"\r\n```\r\n\r\nAnd also the document in https://www.tensorflow.org/api_docs/python/tf/io/matching_files.\r\n\r\n```\r\nDefined in generated file: python/ops/gen_io_ops.py.\r\n\r\nNote that this routine only supports wildcard characters in the basename portion of the pattern,\r\nnot in the directory portion. \r\nNote also that the order of filenames returned can be non-deterministic.\r\n```\r\n\r\nAnd also description in the function https://www.tensorflow.org/api_docs/python/tf/io/match_filenames_once \r\n\r\n```\r\nDefined in python/training/input.py.\r\n\r\nNOTE: The order of the files returned can be non-deterministic.\r\n```\r\n\r\nCheck source code of the fucntion\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.14/tensorflow/python/training/input.py#L63\r\n\r\nBoth `tf.io.matching_files` and  tf.io.match_filenames_once` call `gen_io_ops.matching_files`.\r\n\r\nI think it is quite confuse here."
  },
  {
    "labels": [null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue: https://www.tensorflow.org/tutorials/keras/basic_classification\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing): plt.xlabel(class_names[train_labels[i]])中train_labels返回的是numpy.float64 ，但是class_names需要Integer。\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/saved_model/Builder\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe documentation is unclear on several points and especially hard to understand for people who are new to tensorflow.\r\n\r\n### Clear description\r\n\r\nWhat is the difference of using saved_model.Builder to other ways of exporting models and graphs? For someone just wanting to use a pre-trained tensorflow model it is very hard to get an overview over all the different types of formats etc. \r\n\r\nFor example what is the difference to tf.io.write_graph? As far as I could find out I need to use the saved_model stuff, because it is able to add tags, which tf.io is not able to do and which is needed for serving. The docs are very unclear on the whole topic of how to use pre trained models in a custom application. (for example in https://github.com/tensorflow/models/blob/master/research/slim/export_inference_graph.py tf.io.write_graph is used)\r\n\r\nThere is also no data types given for the parameters so as someone new to TF I am absolutely unable to guess what should go there. The only description is foo_signatures and foo_assets, but there is no example showing how these parameters are properly used.\r\n\r\nI managed to use saved_model.simple_save, but it is deprecated and from the documentation of the saved_model.Builder, I have no idea how I could replicate the same functionality as with simple_save.\r\n\r\n### Usage example\r\n\r\nThere is example code, but there is no complete example on how to create a frozen graph or on how to export (and import again) a pre-trained model.\r\n\r\n### Submit a pull request?\r\n\r\nI am an absolute beginner to TF so I cannot correct the docs in a meaningful way. sorry\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04.4\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: binary from pip\r\n- **TensorFlow version (use command below)**: v1.14.0-rc1-22-gaf24dc91b5 1.14.0\r\n- **Python version**: 3.5.2\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: \r\n\r\n  1. launch jupyter notebook,\r\n  2. download tutorial from google colab (https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/estimators/boosted_trees.ipynb),\r\n  3. run the notebook.\r\n\r\n\r\n\r\n### Describe the problem\r\n\r\n\r\nHi, I'm currently learning TensorFlow from the tutorials of the TF site.\r\n\r\nBut, during exercise in the tutorial (https://www.tensorflow.org/tutorials/estimators/boosted_trees), I got a strange error.\r\n\r\nTensorFlow was constantly crashed with the code, although it was provided from official site. I tried both jupyter notebook and plain python code.\r\n\r\nSo I googled the problem a little bit, and found that there's a workaround (https://github.com/tensorflow/tensorflow/issues/6968), i.e.,\r\n\r\n```bash\r\nsudo apt install libtcmalloc-minimal4\r\nexport LD_PRELOAD=\"/usr/lib/libtcmalloc_minimal.so.4\"\r\n```\r\n\r\nAnd then the code worked flawlessly.\r\n\r\nHowever, this leaves another questions, and these are what I really wonder;\r\n\r\n1. does this problem happen to some boundary cases like mine? Perhaps I am missing some configurations. I'll be glad to let me know.\r\n\r\n2. if not, that is, `tcmalloc` is necessary for the TensorFlow, and considering that `tcmalloc` is not distributed with the every default linux (for example, ubuntu) installations, might be there a better way to evade this situation?\r\n\r\n\r\n\r\n### Source code / logs\r\n\r\n\r\nBefore applying the `tcmalloc` package, jupyter kernel died with this message,\r\n\r\n```\r\nKernel Restarting\r\n\r\nThe kernel appears to have died. It will restart automatically.\r\n```\r\n\r\nHere is some snippet of the log message.\r\n\r\n\r\n```\r\n*** Error in `/home/sungjin/.virtualenvs/boost/bin/python3': malloc(): memory corruption (fast): 0x00007fe0e804d6d0 ***\r\n======= Backtrace: =========\r\n/lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7fe1f56097e5]\r\n```\r\n\r\n\r\n\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/stack\r\n\r\n## Description of issue (what needs changing):\r\n\r\n```css\r\nbody[pending] {\r\n\toverflow: hidden;\r\n}\r\n```\r\n\r\nshould be removed.\r\n\r\n### Clear description\r\nJS is considered harmful, so the docs should be usable without JS.\r\n\r\nThe same problem is present in Android and Fuchsia docs.\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "Tensorflow 2.0.0-alpha0 AttributeError: module 'tensorflow' has no attribute 'matrix_band_part'"
  },
  {
    "labels": ["documentation"],
    "text": "_URL(s) with the issue:_\r\nhttps://www.tensorflow.org/beta/tutorials/load_data/images\r\n\r\n_Description of main issue:_\r\nPls take a look at JPG/JPEG links in the 'Load images with tf.data' tutorial in the 'Inspect the images' section. When you inspect the site elements they appear to be missing a letter 'g' as in `jpeg` or `jpg`\r\n```\r\nhttps://www.tensorflow.org/beta/tutorials/load_data/images_files/output_16_0.jpe\r\nhttps://www.tensorflow.org/beta/tutorials/load_data/images_files/output_16_2.jpe\r\nhttps://www.tensorflow.org/beta/tutorials/load_data/images_files/output_16_4.jpe\r\n```\r\n\r\n_Other minor suggestions:_\r\nRearrangement of words, fixing some grammar, addition/subtraction of commas/colons/spaces in English and Python for consistency - will submit a PR right away for your review @MarkDaoust @lamberta "
  },
  {
    "labels": [null, null, "documentation"],
    "text": "In the documentation for [BestExporter](https://www.tensorflow.org/api_docs/python/tf/estimator/BestExporter), the example mentioned does not specify how to write a _compare_fn_ .\r\nBy default, it takes the _loss_.\r\nHow to use it if we were to use custom metrics, that are evaluated in the _model_fn_ ."
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/overfit_and_underfit.ipynb#scrollTo=LqG3MXF5xSjR\r\n\r\n## Description of issue (what needs changing):\r\n\r\nNotebook crashes on the code block training the baseline model, reporting that all RAM has been consumed.\r\n\r\n### Clear description\r\n\r\nUsers should be able to complete the entire notebook without hitting resource limits\r\n\r\nMaybe the model is not defined correctly? This is the summary:\r\n\r\n```\r\nModel: \"sequential\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\ndense (Dense)                (None, 16)                160016    \r\n_________________________________________________________________\r\ndense_1 (Dense)              (None, 16)                272       \r\n_________________________________________________________________\r\ndense_2 (Dense)              (None, 1)                 17        \r\n=================================================================\r\nTotal params: 160,305\r\nTrainable params: 160,305\r\nNon-trainable params: 0\r\n```"
  },
  {
    "labels": ["documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue: https://www.tensorflow.org/versions/r1.12/api_docs/python/tf\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe link under API/r1.13 is pointing to r1.12.\r\n\r\nThe link should point to r1.13 https://www.tensorflow.org/versions/r1.13/api_docs/python/tf\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "## Description of issue (what needs changing):\r\n\r\nThe Tensorflow API for 1.13 leads to 1.12 page kindly fix the hyperlink .\r\n\r\n### Clear description\r\n\r\nThe change in the API list can cause confusion\r\n\r\n### Request visuals, if applicable\r\n![image](https://user-images.githubusercontent.com/11817160/60156197-98f79200-9809-11e9-846d-c7d2d1471a74.png)\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "Bug Description:\r\n\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/java/reference/org/tensorflow/package-summary\r\n\r\n## Description of issue (what needs changing): Documentation page was unreadable on Safari for Mac. Please see the screenshot. On Subsequent page load it somehow loaded just fine.\r\n\r\n### Clear description\r\n\r\nSee above\r\n<img width=\"1494\" alt=\"Screen Shot 2019-06-25 at 2 29 37 PM\" src=\"https://user-images.githubusercontent.com/395039/60135239-1eba0580-9756-11e9-9094-3430ab265841.png\">\r\n\r\n\r\n### Correct links\r\n\r\nN/A\r\n\r\n### Parameters defined\r\n\r\nN/A\r\n\r\n### Returns defined\r\n\r\nN/A\r\n\r\n### Raises listed and defined\r\n\r\nN/A\r\n\r\n### Usage example\r\n\r\nSee attached screenshot\r\n\r\n### Request visuals, if applicable\r\n\r\nYes, see attached screenshot\r\n\r\n### Submit a pull request?\r\n\r\nNo"
  },
  {
    "labels": [null, "documentation"],
    "text": "Description of issue: The image link for quickdraw_model.png is broken in document [recurrent_quickdraw.md](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/sequences/recurrent_quickdraw.md) \r\n\r\nThe current source url for the image points to non existent image location.\r\n\r\nUrl: [recurrent_quickdraw.md](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/sequences/recurrent_quickdraw.md)\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/image/extract_glimpse\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Raises listed and defined\r\n\r\nRaises are not listed and defined\r\n\r\n### Usage example\r\n\r\nNo usage example is given\r\n\r\n### Pull Request\r\n\r\nhttps://github.com/tensorflow/tensorflow/pull/30098"
  },
  {
    "labels": [null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/estimator/LinearClassifier\r\n\r\n## Description of issue (what needs changing):\r\n\r\n`FtrlOptimizer` is not accessible from `tf.train`:\r\n\r\n```python\r\n# Or estimator using the FTRL optimizer with regularization.\r\nestimator = LinearClassifier(\r\n    feature_columns=[categorical_column_a,\r\n                     categorical_feature_a_x_categorical_feature_b],\r\n    optimizer=tf.train.FtrlOptimizer(\r\n      learning_rate=0.1,\r\n      l1_regularization_strength=0.001\r\n    )\r\n    ### should be optimizer=tf.keras.optimizers.Ftrl(...)\r\n)\r\n\r\n> AttributeError: module 'tensorflow._api.v2.train' has no attribute 'FtrlOptimizer'\r\n```\r\n\r\n### Clear description\r\n\r\nN/A\r\n\r\n### Correct links\r\n\r\nN/A\r\n\r\n### Parameters defined\r\n\r\nN/A\r\n\r\n### Returns defined\r\n\r\nN/A\r\n\r\n### Raises listed and defined\r\n\r\nN/A\r\n\r\n### Usage example\r\n\r\nN/A\r\n\r\n### Request visuals, if applicable\r\n\r\nN/A\r\n\r\n### Submit a pull request?\r\n\r\nN/A\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "### Description:\r\nThere are two examples for \"tflite image classification on android\" on the Tensorflow repo which achieve the same thing. They both have almost identical code but slight differences(In UI and in code).\r\n\r\n**Example A:** https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification/android\r\n**Example B:** https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/java\r\n\r\nI would like to know which one is supposed to be used, and whether they can be merged so that this confusion is avoided?\r\n\r\n### Example of a difference:\r\n\r\n- In example A we do **not** create a NNAPI Delegate\r\n\r\nhttps://github.com/tensorflow/examples/blob/156a12782a06f085adeb6b352c2763648cece066/lite/examples/image_classification/android/app/src/main/java/org/tensorflow/lite/examples/classification/tflite/Classifier.java#L179\r\n\r\n- But in example B we do create an NNAPI Delegate\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/e8ad5b0552a03e5d065a8f302dd0c0e0ae6b3925/tensorflow/lite/java/demo/app/src/main/java/com/example/android/tflitecamerademo/ImageClassifier.java#L186"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/probability/api_docs/python/tfp/positive_semidefinite_kernels/ExponentiatedQuadratic\r\n\r\n## Description of issue (what needs changing):\r\n\r\nList default values for hyperparameters `amplitude` and `length_scale` that are used when a kernel is created with default values, as suggested [here](https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/GaussianProcess#examples):\r\n\r\n```\r\ntfd = tfp.distributions\r\npsd_kernels = tfp.positive_semidefinite_kernels\r\n\r\n# Define a kernel with default parameters.\r\nkernel = psd_kernels.ExponentiatedQuadratic()\r\n```\r\n\r\n### Parameters defined\r\n\r\nDefault values for `amplitude` and `length_scale` are not listed (apart from a keyword 'None')."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1333     try:\r\n-> 1334       return fn(*args)\r\n   1335     except errors.OpError as e:\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/client/session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)\r\n   1318       return self._call_tf_sessionrun(\r\n-> 1319           options, feed_dict, fetch_list, target_list, run_metadata)\r\n   1320 \r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/client/session.py in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata)\r\n   1406         self._session, options, feed_dict, fetch_list, target_list,\r\n-> 1407         run_metadata)\r\n   1408 \r\n\r\nInvalidArgumentError: tensor_name = linear//weight; shape in shape_and_slice spec [1,10] does not match the shape stored in checkpoint: [784,10]\r\n\t [[{{node save/RestoreV2}}]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saver.py in restore(self, sess, save_path)\r\n   1275         sess.run(self.saver_def.restore_op_name,\r\n-> 1276                  {self.saver_def.filename_tensor_name: save_path})\r\n   1277     except errors.NotFoundError as err:\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\r\n    928       result = self._run(None, fetches, feed_dict, options_ptr,\r\n--> 929                          run_metadata_ptr)\r\n    930       if run_metadata:\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n   1151       results = self._do_run(handle, final_targets, final_fetches,\r\n-> 1152                              feed_dict_tensor, options, run_metadata)\r\n   1153     else:\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\r\n   1327       return self._do_call(_run_fn, feeds, fetches, targets, options,\r\n-> 1328                            run_metadata)\r\n   1329     else:\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1347       message = error_interpolation.interpolate(message, self._graph)\r\n-> 1348       raise type(e)(node_def, op, message)\r\n   1349 \r\n\r\nInvalidArgumentError: tensor_name = linear//weight; shape in shape_and_slice spec [1,10] does not match the shape stored in checkpoint: [784,10]\r\n\t [[node save/RestoreV2 (defined at <ipython-input-56-0354ba381638>:2) ]]\r\n\r\nCaused by op 'save/RestoreV2', defined at:\r\n  File \"/opt/conda/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/opt/conda/lib/python3.7/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\r\n    app.launch_new_instance()\r\n  File \"/opt/conda/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\r\n    app.start()\r\n  File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\r\n    self.io_loop.start()\r\n  File \"/opt/conda/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\r\n    self.asyncio_loop.run_forever()\r\n  File \"/opt/conda/lib/python3.7/asyncio/base_events.py\", line 539, in run_forever\r\n    self._run_once()\r\n  File \"/opt/conda/lib/python3.7/asyncio/base_events.py\", line 1775, in _run_once\r\n    handle._run()\r\n  File \"/opt/conda/lib/python3.7/asyncio/events.py\", line 88, in _run\r\n    self._context.run(self._callback, *self._args)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\r\n    lambda f: self._run_callback(functools.partial(callback, future))\r\n  File \"/opt/conda/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\r\n    ret = callback()\r\n  File \"/opt/conda/lib/python3.7/site-packages/tornado/gen.py\", line 781, in inner\r\n    self.run()\r\n  File \"/opt/conda/lib/python3.7/site-packages/tornado/gen.py\", line 742, in run\r\n    yielded = self.gen.send(value)\r\n  File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\r\n    yield gen.maybe_future(dispatch(*args))\r\n  File \"/opt/conda/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\r\n    yielded = next(result)\r\n  File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\r\n    yield gen.maybe_future(handler(stream, idents, msg))\r\n  File \"/opt/conda/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\r\n    yielded = next(result)\r\n  File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\r\n    user_expressions, allow_stdin,\r\n  File \"/opt/conda/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\r\n    yielded = next(result)\r\n  File \"/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\r\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n  File \"/opt/conda/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\r\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\r\n    raw_cell, store_history, silent, shell_futures)\r\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\r\n    return runner(coro)\r\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\r\n    coro.send(None)\r\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\r\n    interactivity=interactivity, compiler=compiler, result=result)\r\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\r\n    if (yield from self.run_code(code, result)):\r\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-56-0354ba381638>\", line 2, in <module>\r\n    print (\"Predicted %d, Label: %d\" % (classifier.predict(test_data[0]), test_labels[0]))\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 574, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 574, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/linear.py\", line 539, in predict\r\n    as_iterable=as_iterable)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 574, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/linear.py\", line 574, in predict_classes\r\n    as_iterable=as_iterable)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 670, in predict\r\n    iterate_batches=iterate_batches)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 974, in _infer_model\r\n    config=self._session_config))\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py\", line 934, in __init__\r\n    stop_grace_period_secs=stop_grace_period_secs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py\", line 648, in __init__\r\n    self._sess = _RecoverableSession(self._coordinated_creator)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1122, in __init__\r\n    _WrappedSession.__init__(self, self._create_session())\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1127, in _create_session\r\n    return self._sess_creator.create_session()\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py\", line 805, in create_session\r\n    self.tf_sess = self._session_creator.create_session()\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py\", line 562, in create_session\r\n    self._scaffold.finalize()\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py\", line 217, in finalize\r\n    self._saver = training_saver._get_saver_or_default()  # pylint: disable=protected-access\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saver.py\", line 604, in _get_saver_or_default\r\n    saver = Saver(sharded=True, allow_empty=True)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saver.py\", line 832, in __init__\r\n    self.build()\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saver.py\", line 844, in build\r\n    self._build(self._filename, build_save=True, build_restore=True)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saver.py\", line 881, in _build\r\n    build_save=build_save, build_restore=build_restore)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saver.py\", line 507, in _build_internal\r\n    restore_sequentially, reshape)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saver.py\", line 385, in _AddShardedRestoreOps\r\n    name=\"restore_shard\"))\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saver.py\", line 332, in _AddRestoreOps\r\n    restore_sequentially)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saver.py\", line 580, in bulk_restore\r\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1572, in restore_v2\r\n    name=name)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\r\n    op_def=op_def)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): tensor_name = linear//weight; shape in shape_and_slice spec [1,10] does not match the shape stored in checkpoint: [784,10]\r\n\t [[node save/RestoreV2 (defined at <ipython-input-56-0354ba381638>:2) ]]\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-56-0354ba381638> in <module>\r\n      1 # here's one it gets right\r\n----> 2 print (\"Predicted %d, Label: %d\" % (classifier.predict(test_data[0]), test_labels[0]))\r\n      3 display(0)\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)\r\n    572                   func.__module__, arg_name, arg_value, 'in a future version'\r\n    573                   if date is None else ('after %s' % date), instructions)\r\n--> 574       return func(*args, **kwargs)\r\n    575 \r\n    576     doc = _add_deprecated_arg_value_notice_to_docstring(\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)\r\n    572                   func.__module__, arg_name, arg_value, 'in a future version'\r\n    573                   if date is None else ('after %s' % date), instructions)\r\n--> 574       return func(*args, **kwargs)\r\n    575 \r\n    576     doc = _add_deprecated_arg_value_notice_to_docstring(\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/linear.py in predict(self, x, input_fn, batch_size, outputs, as_iterable)\r\n    537           input_fn=input_fn,\r\n    538           batch_size=batch_size,\r\n--> 539           as_iterable=as_iterable)\r\n    540     return super(LinearClassifier, self).predict(\r\n    541         x=x,\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)\r\n    572                   func.__module__, arg_name, arg_value, 'in a future version'\r\n    573                   if date is None else ('after %s' % date), instructions)\r\n--> 574       return func(*args, **kwargs)\r\n    575 \r\n    576     doc = _add_deprecated_arg_value_notice_to_docstring(\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/linear.py in predict_classes(self, x, input_fn, batch_size, as_iterable)\r\n    572         batch_size=batch_size,\r\n    573         outputs=[key],\r\n--> 574         as_iterable=as_iterable)\r\n    575     if as_iterable:\r\n    576       return _as_iterable(preds, output=key)\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)\r\n    505                 'in a future version' if date is None else ('after %s' % date),\r\n    506                 instructions)\r\n--> 507       return func(*args, **kwargs)\r\n    508 \r\n    509     doc = _add_deprecated_arg_notice_to_docstring(\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py in predict(self, x, input_fn, batch_size, outputs, as_iterable, iterate_batches)\r\n    668         outputs=outputs,\r\n    669         as_iterable=as_iterable,\r\n--> 670         iterate_batches=iterate_batches)\r\n    671 \r\n    672   def get_variable_value(self, name):\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py in _infer_model(self, input_fn, feed_fn, outputs, as_iterable, iterate_batches)\r\n    972               checkpoint_filename_with_path=checkpoint_path,\r\n    973               scaffold=infer_ops.scaffold,\r\n--> 974               config=self._session_config))\r\n    975       if not as_iterable:\r\n    976         with mon_sess:\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py in __init__(self, session_creator, hooks, stop_grace_period_secs)\r\n    932     super(MonitoredSession, self).__init__(\r\n    933         session_creator, hooks, should_recover=True,\r\n--> 934         stop_grace_period_secs=stop_grace_period_secs)\r\n    935 \r\n    936 \r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py in __init__(self, session_creator, hooks, should_recover, stop_grace_period_secs)\r\n    646         stop_grace_period_secs=stop_grace_period_secs)\r\n    647     if should_recover:\r\n--> 648       self._sess = _RecoverableSession(self._coordinated_creator)\r\n    649     else:\r\n    650       self._sess = self._coordinated_creator.create_session()\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py in __init__(self, sess_creator)\r\n   1120     \"\"\"\r\n   1121     self._sess_creator = sess_creator\r\n-> 1122     _WrappedSession.__init__(self, self._create_session())\r\n   1123 \r\n   1124   def _create_session(self):\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py in _create_session(self)\r\n   1125     while True:\r\n   1126       try:\r\n-> 1127         return self._sess_creator.create_session()\r\n   1128       except _PREEMPTION_ERRORS as e:\r\n   1129         logging.info('An error was raised while a session was being created. '\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py in create_session(self)\r\n    803       \"\"\"Creates a coordinated session.\"\"\"\r\n    804       # Keep the tf_sess for unit testing.\r\n--> 805       self.tf_sess = self._session_creator.create_session()\r\n    806       # We don't want coordinator to suppress any exception.\r\n    807       self.coord = coordinator.Coordinator(clean_stop_exception_types=[])\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py in create_session(self)\r\n    569         init_op=self._scaffold.init_op,\r\n    570         init_feed_dict=self._scaffold.init_feed_dict,\r\n--> 571         init_fn=self._scaffold.init_fn)\r\n    572 \r\n    573 \r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/session_manager.py in prepare_session(self, master, init_op, saver, checkpoint_dir, checkpoint_filename_with_path, wait_for_checkpoint, max_wait_secs, config, init_feed_dict, init_fn)\r\n    279         wait_for_checkpoint=wait_for_checkpoint,\r\n    280         max_wait_secs=max_wait_secs,\r\n--> 281         config=config)\r\n    282     if not is_loaded_from_checkpoint:\r\n    283       if init_op is None and not init_fn and self._local_init_op is None:\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/session_manager.py in _restore_checkpoint(self, master, saver, checkpoint_dir, checkpoint_filename_with_path, wait_for_checkpoint, max_wait_secs, config)\r\n    193 \r\n    194     if checkpoint_filename_with_path:\r\n--> 195       saver.restore(sess, checkpoint_filename_with_path)\r\n    196       return sess, True\r\n    197 \r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saver.py in restore(self, sess, save_path)\r\n   1310       # We add a more reasonable error message here to help users (b/110263146)\r\n   1311       raise _wrap_restore_error_with_msg(\r\n-> 1312           err, \"a mismatch between the current graph and the graph\")\r\n   1313 \r\n   1314   @staticmethod\r\n\r\nInvalidArgumentError: Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\r\n\r\ntensor_name = linear//weight; shape in shape_and_slice spec [1,10] does not match the shape stored in checkpoint: [784,10]\r\n\t [[node save/RestoreV2 (defined at <ipython-input-56-0354ba381638>:2) ]]\r\n\r\nCaused by op 'save/RestoreV2', defined at:\r\n  File \"/opt/conda/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/opt/conda/lib/python3.7/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\r\n    app.launch_new_instance()\r\n  File \"/opt/conda/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\r\n    app.start()\r\n  File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\r\n    self.io_loop.start()\r\n  File \"/opt/conda/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\r\n    self.asyncio_loop.run_forever()\r\n  File \"/opt/conda/lib/python3.7/asyncio/base_events.py\", line 539, in run_forever\r\n    self._run_once()\r\n  File \"/opt/conda/lib/python3.7/asyncio/base_events.py\", line 1775, in _run_once\r\n    handle._run()\r\n  File \"/opt/conda/lib/python3.7/asyncio/events.py\", line 88, in _run\r\n    self._context.run(self._callback, *self._args)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\r\n    lambda f: self._run_callback(functools.partial(callback, future))\r\n  File \"/opt/conda/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\r\n    ret = callback()\r\n  File \"/opt/conda/lib/python3.7/site-packages/tornado/gen.py\", line 781, in inner\r\n    self.run()\r\n  File \"/opt/conda/lib/python3.7/site-packages/tornado/gen.py\", line 742, in run\r\n    yielded = self.gen.send(value)\r\n  File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\r\n    yield gen.maybe_future(dispatch(*args))\r\n  File \"/opt/conda/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\r\n    yielded = next(result)\r\n  File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\r\n    yield gen.maybe_future(handler(stream, idents, msg))\r\n  File \"/opt/conda/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\r\n    yielded = next(result)\r\n  File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\r\n    user_expressions, allow_stdin,\r\n  File \"/opt/conda/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\r\n    yielded = next(result)\r\n  File \"/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\r\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n  File \"/opt/conda/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\r\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\r\n    raw_cell, store_history, silent, shell_futures)\r\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\r\n    return runner(coro)\r\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\r\n    coro.send(None)\r\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\r\n    interactivity=interactivity, compiler=compiler, result=result)\r\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\r\n    if (yield from self.run_code(code, result)):\r\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-56-0354ba381638>\", line 2, in <module>\r\n    print (\"Predicted %d, Label: %d\" % (classifier.predict(test_data[0]), test_labels[0]))\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 574, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 574, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/linear.py\", line 539, in predict\r\n    as_iterable=as_iterable)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 574, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/linear.py\", line 574, in predict_classes\r\n    as_iterable=as_iterable)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 670, in predict\r\n    iterate_batches=iterate_batches)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 974, in _infer_model\r\n    config=self._session_config))\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py\", line 934, in __init__\r\n    stop_grace_period_secs=stop_grace_period_secs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py\", line 648, in __init__\r\n    self._sess = _RecoverableSession(self._coordinated_creator)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1122, in __init__\r\n    _WrappedSession.__init__(self, self._create_session())\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1127, in _create_session\r\n    return self._sess_creator.create_session()\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py\", line 805, in create_session\r\n    self.tf_sess = self._session_creator.create_session()\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py\", line 562, in create_session\r\n    self._scaffold.finalize()\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py\", line 217, in finalize\r\n    self._saver = training_saver._get_saver_or_default()  # pylint: disable=protected-access\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saver.py\", line 604, in _get_saver_or_default\r\n    saver = Saver(sharded=True, allow_empty=True)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saver.py\", line 832, in __init__\r\n    self.build()\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saver.py\", line 844, in build\r\n    self._build(self._filename, build_save=True, build_restore=True)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saver.py\", line 881, in _build\r\n    build_save=build_save, build_restore=build_restore)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saver.py\", line 507, in _build_internal\r\n    restore_sequentially, reshape)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saver.py\", line 385, in _AddShardedRestoreOps\r\n    name=\"restore_shard\"))\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saver.py\", line 332, in _AddRestoreOps\r\n    restore_sequentially)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saver.py\", line 580, in bulk_restore\r\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1572, in restore_v2\r\n    name=name)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\r\n    op_def=op_def)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\r\n\r\ntensor_name = linear//weight; shape in shape_and_slice spec [1,10] does not match the shape stored in checkpoint: [784,10]\r\n\t [[node save/RestoreV2 (defined at <ipython-input-56-0354ba381638>:2) ]]\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "**System information**\r\n- TensorFlow version: v2.0.0-beta0-16-g1d91213fe7 2.0.0-beta1\r\n\r\n**Describe the current behavior**\r\nError raised when attempting to call `tf.keras.preprocessing.text.tokenizer_from_json`:\r\n```\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n----> 1 tf.keras.preprocessing.text.tokenizer_from_json\r\n\r\nAttributeError: module 'tensorflow.python.keras.api._v2.keras.preprocessing.text' has no attribute 'tokenizer_from_json'\r\n```\r\n\r\n**Describe the expected behavior**\r\nI expect this method to be callable per the documentation of `tf.keras.preprocessing.text.Tokenizer.to_json` (below), which says we can use `keras.preprocessing.text.tokenizer_from_json(json_string)` to load a tokenizer.\r\n\r\nOtherwise, there's no obvious way to use the output of `Tokenizer.to_json` to restore a tokenizer.\r\n\r\n```\r\nSignature: tf.keras.preprocessing.text.Tokenizer.to_json(self, **kwargs)\r\nDocstring:\r\nReturns a JSON string containing the tokenizer configuration.\r\nTo load a tokenizer from a JSON string, use\r\n`keras.preprocessing.text.tokenizer_from_json(json_string)`.\r\n\r\n# Arguments\r\n    **kwargs: Additional keyword arguments\r\n        to be passed to `json.dumps()`.\r\n\r\n# Returns\r\n    A JSON string containing the tokenizer configuration.\r\n```\r\n**Code to reproduce the issue**\r\n```python3\r\njson_string = tf.keras.preprocessing.text.Tokenizer().to_json()\r\ntf.keras.preprocessing.text.tokenizer_from_json(json_string)\r\n```"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/install/pip\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nThere are no binary wheels for tensorflow 1.14 for mac (should be [here](https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.14.0-py3-none-any.whl)) and the documentation page still points to 1.13.\r\n\r\nIs 1.14 still considered unstable? Was the wheel generation and documentation update simply forgotten? Or is it normal that it takes a couple of days after the release?\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/contrib/data/map_and_batch\r\n\r\n## Description of issue (what needs changing):\r\n\r\nArgs document of this API:\r\n\r\n> num_parallel_calls: (Optional.) A tf.int32 scalar tf.Tensor, representing the number of elements to process in parallel. If not specified, batch_size * num_parallel_batches elements will be processed in **parallel**.\r\n\r\nthe last word should be `sequential` rather than `parallel` \r\n "
  },
  {
    "labels": [null, null, "documentation"],
    "text": "TensorFlow version: 2.0 (beta1)\r\n\r\n#### Doc links:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/LearningRateScheduler\r\nhttps://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/callbacks.py\r\n\r\n#### Description:\r\nThe definition should be expanded for clarity and better user experience. Instead of a one short sentence - \"Learning rate scheduler.\" - maybe try:\r\n```\r\nLearning rate scheduler which can be used to adjust the learning rate over time. Any function can be defined, such as a decay function that states which decay rate to use after a certain number of epochs or batches. Then this custom function can be passed as the `schedule` parameter in the `LearningRateSchuler` callback. \r\n```\r\nAlternatively, a description from the \"Distributed Training with Keras\" [tutorial](https://www.tensorflow.org/beta/tutorials/distribute/keras), linked in the API doc, can also be used:\r\n```\r\nLearning Rate Scheduler: Using this callback, you can schedule the learning rate to change after every epoch/batch.\r\n```\r\n#### Example:\r\nThe word \"Example\" is missing before the example.\r\n\r\n#### Raises/Returns:\r\nShould be added.\r\n\r\n\r\nFor improvement suggestions of other `tf.keras.callbacks` classes see #29958 "
  },
  {
    "labels": [null, null, "documentation"],
    "text": "https://www.tensorflow.org/install/gpu \r\n\r\nhow do you test your install to make sure everything went OK?"
  },
  {
    "labels": [null, "documentation"],
    "text": "TypeError: moments_v2() got an unexpected keyword argument 'keep_dims'"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "TensorFlow version: 2.0 (beta1)\r\n\r\n#### (Sub)classes of `tf.keras.callbacks`:\r\n`BaseLogger`, `History`, `Callback`, `CSVLogger`, `ModelCheckpoint`, `ProgbarLogger`, `RemoteMonitor`, `TensorBoard` and `TerminateOnNaN`:\r\n\r\n#### Summary:\r\nSince `tf.keras.callbacks` are important for monitoring models during training, the API docs require extra attention imo.\r\n\r\nExamples - to add - see below\r\nDescriptions - to be defined better - see below (especially the `Callback` custom class)\r\nReturns/raises - to add for better UX when needed\r\n\r\n#### Suggested improvements: \r\n\r\n- _Missing examples_: one example per (sub)class would be enough for good UX and a link to a tutorial presents an extra step for a user. E.g. a short example inside the docs similar to the ones in `EarlyStopping` ([link](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/EarlyStopping)), `ReduceLROnPlateau` ([link](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/ReduceLROnPlateau)) or `LambdaCallback` ([link](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/LambdaCallback))\r\n\r\nNote: `ModelCheckpoint` and `TensorBoard` have links to tutorials which have examples. `BaseLogger` and `History` are applied by default but that may not help understand them better.\r\n\r\nExample of a `Custom` callback from @fchollet Deep Learning with Python book:\r\n```python\r\nclass ActivationLogger(keras.callbacks.Callback):\r\n    def set_model(self, model):\r\n        self.model = model # Called by the parent model before training, to inform the callback of what model will be calling it\r\n        layer_outputs = [layer.output for layer in model.layers]\r\n        self.activations_model = keras.models.Model(model.input, layer_outputs) # Model instance that returns the activations of every layer\r\n\r\n    def on_epoch_end(self, epoch, logs=None):\r\n        if self.validation_data is None:\r\n                raise RuntimeError('Requires validation_data.')\r\n        validation_sample = self.validation_data[0][0:1] # Obtains the first input sample of the validation data\r\n        activations = self.activations_model.predict(validation_sample)\r\n        f = open('activations_at_epoch_' + str(epoch) + '.npz', 'w') # Saves arrays to disk\r\n        np.savez(f, activations)\r\n        f.close()\r\n```\r\n\r\nExample of a `TensorBoard` callback from @fchollet Deep Learning with Python book:\r\n```python\r\ncallbacks = [\r\n    keras.callbacks.TensorBoard(\r\n        log_dir='my_log_dir', # Location of log files\r\n        histogram_freq=1, # Records activation histogram every 1 epoch\r\n        embeddings_freq=1, # Records embedding data every 1 epoch\r\n    )\r\n]\r\n\r\nhistory = model.fit(x_train, y_train, \r\n                epochs=20, \r\n                batch_size=128, \r\n                validation_split=0.2, \r\n                callbacks=callbacks)\r\n\r\n# Browse to http://localhost:6006 and look at your model training\r\n...\r\n```\r\n\r\n- _Descriptions_: to be defined better if needed. Recommend to use the following Medium post  which has quite decent descriptions of each `callback`: https://medium.com/singlestone/keras-callbacks-monitor-and-improve-your-deep-learning-205a8a27e91c\r\n\r\nNote: Mention in the `EarlyStopping` and `ModelCheckpoint` descriptions that they are/should be both typically used together (see `callbacks_list` example from @fchollet with 2 callbacks passed into `model.fit` below) to stop training when improvement stops and save the current best model during training (`save_best_only=True`):\r\n\r\n```python\r\n# A list of 2 or more callbacks that can be passed into `model.fit`\r\ncallbacks_list = [\r\n        keras.callbacks.EarlyStopping(\r\n                monitor='acc',\r\n                patience=1,\r\n        ),\r\n        \r\n        keras.callbacks.ModelCheckpoint( # Saves the current weights after every epoch\r\n                filepath='my_model.h5',\r\n                monitor='val_loss',\r\n                save_best_only=True, # These two arguments mean you won’t overwrite the model file unless val_loss has improved\r\n        )\r\n]\r\n\r\nmodel.compile(optimizer='rmsprop',\r\n                loss='binary_crossentropy',\r\n                metrics=['acc'])\r\n\r\nmodel.fit(x, y,\r\n                epochs=10,\r\n                batch_size=32,\r\n                callbacks=callbacks_list,\r\n                validation_data=(x_val, y_val)\r\n                )\r\n```\r\n\r\n- _Returns/Raises_: to be defined/defined better if needed\r\n\r\n#### Doc links:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/BaseLogger\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/History\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/Callback\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/CSVLogger\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/ModelCheckpoint\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/ProgbarLogger\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/RemoteMonitor\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/TensorBoard\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/TerminateOnNaN"
  },
  {
    "labels": [null, "documentation", null],
    "text": "## Description of issue (what needs changing):\r\n\r\nIt is unclear how to translate the following code to tf 2:\r\n\r\n```python\r\n%matplotlib inline\r\nimport tensorflow as tf\r\nfrom matplotlib import pyplot as plt\r\nfrom tqdm.auto import tqdm, trange\r\nimport numpy as np\r\n\r\ntf.compat.v1.disable_eager_execution()\r\n\r\ny = np.array([[10., 1.], [6., 3.], [-1, 7]])\r\nx = np.array([[4., 15.], [1., 1.], [-7, 1]])\r\ntrajs = [[] for j in range(y.shape[0])]\r\n\r\ng = tf.compat.v1.Graph()\r\nwith g.as_default():\r\n\tsess = tf.compat.v1.Session(graph=g)\r\n\t\r\n\tyT = tf.compat.v1.placeholder(tf.float64)\r\n\txT = tf.compat.v1.Variable(x, trainable=True)\r\n\r\n\telementWiseLoss = tf.compat.v1.reduce_sum((yT - xT)**2, axis=1)\r\n\tloss = tf.compat.v1.reduce_sum(elementWiseLoss)\r\n\topt = tf.compat.v1.train.AdamOptimizer(0.1).minimize(loss)\r\n\tinit = tf.compat.v1.global_variables_initializer()\r\n\t\r\n\tsess.run(init)\r\n\tepochs = 300\r\n\tfor i in trange(epochs):\r\n\t\t_, lossR, x, elR = sess.run([opt, loss, xT, elementWiseLoss], feed_dict={yT: y})\r\n\t\tif not i % 10:\r\n\t\t\tfor j in range(y.shape[0]):\r\n\t\t\t\ttrajs[j].append([*x[j], elR[j]])\r\n\r\nprint(\"x\", x)\r\nprint(\"y\", y)\r\nprint(\"y - x\", y - x)\r\ntrajs = np.array(trajs)\r\nfor i, m in enumerate([\"o\", \"+\", \"*\"]):\r\n\tplt.scatter(trajs[i, :, 0], trajs[i, :, 1], marker=m, c=trajs[i, :, 2], cmap=\"rainbow\", label=str(i))\r\nplt.legend()\r\nplt.grid()\r\nplt.colorbar()\r\nplt.show()\r\n```\r\n\r\nThe solution:\r\n```python\r\n%matplotlib inline\r\nimport tensorflow as tf\r\nfrom matplotlib import pyplot as plt\r\nfrom tqdm.auto import tqdm, trange\r\nimport numpy as np\r\n\r\ny = np.array([[10., 1.], [6., 3.], [-1, 7]])\r\nx = np.array([[4., 15.], [1., 1.], [-7, 1]])\r\ntrajs = [[] for j in range(y.shape[0])]\r\n\r\n\r\nyT = tf.Variable(y)\r\nxT = tf.Variable(x)\r\n\r\n@tf.function\r\ndef elementWiseLoss():\r\n\treturn tf.reduce_sum((yT - xT)**2, axis=1)\r\n\r\n@tf.function\r\ndef loss():\r\n\treturn tf.reduce_sum(elementWiseLoss())\r\n\r\noptr = tf.optimizers.Adam(0.1)\r\n\r\nepochs = 300\r\nfor i in trange(epochs):\r\n\toptr.minimize(loss, [xT])\r\n\tlossR = loss().numpy()\r\n\tx = xT.numpy()\r\n\telR = elementWiseLoss().numpy()\r\n\tif not i % 10:\r\n\t\tfor j in range(yT.shape[0]):\r\n\t\t\ttrajs[j].append([*xT[j], elR[j]])\r\n\r\nprint(\"x\", x)\r\nprint(\"y\", y)\r\nprint(\"y - x\", y - x)\r\ntrajs = np.array(trajs)\r\nfor i, m in enumerate([\"o\", \"+\", \"*\"]):\r\n\tplt.scatter(trajs[i, :, 0], trajs[i, :, 1], marker=m, c=trajs[i, :, 2], cmap=\"rainbow\", label=str(i))\r\nplt.legend()\r\nplt.grid()\r\nplt.colorbar()\r\nplt.show()\r\n```\r\n\r\n### Clear description\r\n\r\nIt would be nice to have a tutorial page containing both v1-style solution and v2-style one.\r\n\r\n"
  },
  {
    "labels": [null, "documentation", null],
    "text": "I am developing a commercial application that uses the tensorflow C API. At all kinds of places, for example, https://github.com/tensorflow/tensorflow/blob/master/LICENSE, I found that tensorflow uses the Apache License 2.0. However, when I downloaded the C API from https://www.tensorflow.org/install/lang_c (https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-cpu-windows-x86_64-1.13.1.zip) it came with a huge LICENSE file that lists many 3rd party libraries.\r\n\r\nWhich license do I need to distribute with my application? Do I need to add the Apache License 2.0 for tensorflow or do I need to add the content of the LICENSE file that came with the C API?"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "##### Description:\r\n`tf.keras.callbacks` TF r2.0 and r1.14 docs state that it's defined in an `__init__.py` but the links are broken (404): \r\n\r\nThere is no link to `__init__.py` in TF 1.13 stable (1.14 too? since it's just been released)\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/callbacks\r\n\r\n- URL(s) with the issue (404):\r\nr2.0: https://github.com/tensorflow/tensorflow/tree/r2.0/tensorflow/python/keras/api/_v2/keras/callbacks/__init__.py\r\nr1.14: https://github.com/tensorflow/tensorflow/blob/r1.14/tensorflow/python/keras/api/_v1/keras/callbacks/__init__.py\r\n\r\n- Link to the documentation entry:\r\nr2.0: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks\r\nr1.14: https://www.tensorflow.org/versions/r1.14/api_docs/python/tf/keras/callbacks\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "https://www.tensorflow.org/versions/r1.14/api_docs/python/tf/train/experimental/enable_mixed_precision_graph_rewrite\r\n\r\nhttps://www.tensorflow.org/versions/r1.14/api_docs/python/tf/train/experimental/MixedPrecisionLossScaleOptimizer\r\n\r\nhttps://www.tensorflow.org/versions/r1.14/api_docs/python/tf/keras/mixed_precision/experimental/LossScaleOptimizer\r\n\r\nI have tried all of them. None of them worked for me in eager mode. Could you provide some examples?"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## System Information\r\n\r\nTensorFlow version: 2.0\r\n\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/sets/difference\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Raises listed and defined\r\n\r\nRaises not listed and defined.\r\nEvery method has a way that it can be mishandled, maybe when a wrong parameter or wrong order of parameters is/are passed in ( e.g, in this case, two sets `a` and `b` in which the last elements don't match) will raise an error.\r\n\r\n### Request visuals, if applicable\r\n\r\nNo visuals\r\n\r\n### Submit a pull request?\r\n\r\nNo\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## System Information\r\nTensorflow version 2.9\r\n\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/backend/count_params\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\nThe description is not clear, no details on how to use this symbol\r\n\r\n### Raises listed and defined\r\nNo errors have been defined \r\n\r\n### Request visuals, if applicable\r\nNo visuals? an example using arrays could be represented in visual form for clarification\r\n\r\n### Submit a pull request?\r\nNo\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/guide/using_tpu\r\n\r\n## Description of issue (what needs changing):\r\n\r\nNeeds to be completely redone\r\n\r\n### Clear description\r\n\r\nEverything is wrong and examples do not work\r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/beta/tutorials/load_data/tf_records#creating_a_tfexample_message\r\nhttps://www.tensorflow.org/tutorials/load_data/tf_records\r\n\r\n## Description of issue (what needs changing):\r\nthe TFRecord docs don't show how to serialize and parse tensors to a TFRecord. It's a minimal example with a bunch of strings, integers, and floats. How do you include tensor features in a tf.train.Example ?\r\n\r\nThe whole tf.train / tf.io / tf.data thing feels scattered and full of unnecessary boilerplate. Why are Examples Features, Feature in train, but then then we have to write a bunch of boilerplate tf.io functions like **_float_value _byte_value** to make the actual features? All I want to do is make a TFRecord with a bunch of tensors of different shapes in each entry. \r\n\r\n### Clear description\r\n\r\nAll of this stuff should be simplified and put into tf.data... Tf.io feels pointless since tf.data is meant to do the same thing. \r\n\r\nWhy can't the tensorflow guide to TFRecord tell us how to write tensor data to a TFRecord and read it with TFData? \r\n\r\nWhy do we need to write so much boilerplate to add features to tf.train.Example?\r\n\r\nWhy is Data IO spread out over four separate modules (train, io, dtypes, and data) ?"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/beta/tutorials/load_data/images#load_and_format_the_images\r\n\r\n## Description of issue (what needs changing):\r\nUnder \"Load and format the images\" section, the original code below fails to run since it uses a variable `img_path`, which should be `image_path` instead.\r\n\r\n```python\r\nimport matplotlib.pyplot as plt\r\n\r\nimage_path = all_image_paths[0]\r\nlabel = all_image_labels[0]\r\n\r\nplt.imshow(load_and_preprocess_image(img_path))\r\nplt.grid(False)\r\nplt.xlabel(caption_image(img_path))\r\nplt.title(label_names[label].title())\r\nprint()\r\n```\r\n\r\n### Clear description\r\nThis is a simple typo and needs to be fixed.\r\n\r\n### Correct links\r\nNot related.\r\n\r\n### Parameters defined\r\nNot related.\r\n\r\n### Returns defined\r\nNot related.\r\n\r\n### Raises listed and defined\r\nNot related.\r\n\r\n### Usage example\r\nNot related.\r\n\r\n### Request visuals, if applicable\r\nNot related.\r\n\r\n### Submit a pull request?\r\nNot this time.\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/GRU#properties\r\n\r\n### Clear description\r\n\r\nInitialising float variables using 0. rather than 0.0\r\n\r\ndropout=0.,\r\nrecurrent_dropout=0.,\r\n\r\n### Parameters defined\r\n   \r\n time_major Argument not documented.\r\n\r\n### Raises listed and defined\r\nNo\r\n\r\n### Usage example\r\nNo"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## System Information\r\nTensorflow version: 2.0\r\n\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/errors/DeadlineExceededError\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\nThe description could be better; needs more content for clarification\r\n\r\n### Usage example\r\nNo usage example defined  \r\n\r\n### Submit a pull request?\r\nNo\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## System Information\r\nTensorflow version: 2.0\r\n\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/dynamic_stitch\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Raises listed and defined\r\nNo errors have been defined\r\n\r\n### Submit a pull request?\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "1.\tThe parameters pool_function and input_spec in https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/layers/pooling.py#L59 where not defined the documentation https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/MaxPool1D and no return where defined."
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## System information\r\nTensorflow version: 2.0\r\n\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/dynamic_partition\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Raises listed and defined\r\nNo errors have been defined\r\n\r\n### Submit a pull request?\r\nYes\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/div_no_nan\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe web page corresponding to the link does not exist. Error 404\r\n\r\n### Correct links\r\n\r\nThe link is not correct. The page doesn't exist\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/debugging/check_numerics\r\n\r\nThis link gives a description of a symbol in a module which is supposed to be at https://github.com/tensorflow/tensorflow/tree/r2.0/tensorflow/python/ops\r\n\r\nBut the module doesn't seem to exist"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## System information\r\nTensorflow version: 2.0\r\n\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/experimental/unbatch\r\n\r\n## Description of issue (what needs changing):\r\nThe description needs more content, as no description has been provided for the available functions.\r\nNo recommendations have been given on when and when not to use this symbol\r\n\r\n### Parameters defined\r\nNo parameters have been defined\r\n\r\n### Raises listed and defined\r\nNo errors defined\r\n\r\n### Request visuals, if applicable\r\nNo visuals, the content will be clarified if visuals are provided\r\n\r\n### Others\r\nThis symbol is deprecated, am not sure if this review will  still be useful\r\n\r\n### Submit a pull request?\r\nNo\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## System  Information\r\nTensorflow version: 2.0\r\n\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/experimental/rejection_resample\r\n\r\n## Description of issue (what needs changing):\r\nNo recommendations of when and when not to use this symbol have been provided.\r\nThe description is not clear, it needs more content\r\n\r\n### Raises listed and defined\r\nNo raises listed\r\n\r\n### Usage example\r\nNo usage example has been provided\r\n\r\n### Request visuals, if applicable\r\nNo visuals, but they will be very useful if present\r\n\r\n### Submit a pull request? \r\nNo"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/debugging/assert_type\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe API symbol doesn't contain a complete, self-contained, coherent, appropriately formatted, and well-documented usage example code sample and the return values aren't defined\r\n\r\n### Usage example\r\n\r\nNo usage example\r\n\r\n### Returns defined\r\n\r\nThe return values aren't defined\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/experimental/prefetch_to_device\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe API symbol doesn't contain a complete, self-contained, coherent, appropriately formatted, and well-documented code sample.\r\n\r\n### Usage example\r\n\r\nNo usage example"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/errors/ResourceExhaustedError\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe API symbol doesn't contain a complete, self-contained, coherent, appropriately formatted, and well-documented code sample.\r\n\r\n### Usage example\r\n\r\nNo usage example"
  },
  {
    "labels": ["documentation"],
    "text": "## URL with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/errors/ResourceExhaustedError\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe API symbol doesn't contain a complete, self-contained, coherent, appropriately formatted, and well-documented code sample.\r\n\r\n### Usage example\r\n\r\nNo usage example?"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/io/decode_and_crop_jpeg\r\n\r\n## Description of issue :\r\nDocumentation of parameter type - crop_window\r\n\r\n### Clear description\r\nThe type of parameter is list of int and in the documentation it says:\r\n\r\n>     crop_window: A `Tensor` of type `int32`.\r\n\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "[UPDATE]:  This issue is about Maven artifact organization / dependency management and documentation.  \r\n\r\n**System information**\r\n- OS Platform and Distribution: Linux Ubuntu 18.04.2 LTS\r\n- TensorFlow installed from Maven, version 1.13.1\r\n- TensorFlow version: 1.13.1\r\n- Python version: 3.6.7\r\n- Installed using virtualenv\r\n- CUDA/cuDNN version:  NVIDIA-SMI 418.43       Driver Version: 418.43       CUDA Version: 10.1\r\n- GPU model and memory: 4xNvidia 1080Ti, \r\n\r\n**Describe the problem**\r\n\r\nI have created a TensorFlow model in Python and saved it to the disk using the standard method:\r\n\r\n    builder = tf.saved_model.builder.SavedModelBuilder(model_directory) \r\n    builder.add_meta_graph_and_variables(sess, [tf.saved_model.tag_constants.SERVING]) \r\n    builder.save(False)\r\n\r\nNext I am loading the model in Java:\r\n\r\n    SavedModelBundle savedModelBundle = SavedModelBundle.loader(modelDir)\r\n        .withTags(\"serve\")\r\n        .withConfigProto(\r\n            ConfigProto.newBuilder()\r\n                .setGpuOptions(\r\n                    GPUOptions.newBuilder()\r\n                        .setPerProcessGpuMemoryFraction(1.0).build())\r\n                .setLogDevicePlacement(true)\r\n                .build().toByteArray())\r\n        .load();\r\n    Session session = savedModelBundle.session();\r\n\r\nIn my pom.xml I have\r\n\r\n    <dependency>\r\n        <groupId>org.tensorflow</groupId>\r\n        <artifactId>tensorflow</artifactId>\r\n        <version>${tensorflow.version}</version>\r\n    </dependency>\r\n    <dependency>\r\n        <groupId>org.tensorflow</groupId>\r\n        <artifactId>proto</artifactId>\r\n        <version>${tensorflow.version}</version>\r\n    </dependency>\r\n    <dependency>\r\n        <groupId>org.tensorflow</groupId>\r\n        <artifactId>libtensorflow_jni_gpu</artifactId>\r\n        <version>${tensorflow.version}</version>\r\n    </dependency>\r\n\r\nHowever, this fails to use my GPU's on startup\r\n\r\n    2019-06-15 23:48:38.130731: I tensorflow/compiler/xla/service/service.cc:150] \r\n        XLA service 0x7fbfc4656e10 executing computations on platform Host. Devices:\r\n    2019-06-15 23:48:38.130768: I tensorflow/compiler/xla/service/service.cc:158]   \r\n        StreamExecutor device (0): <undefined>, <undefined>\r\n        Device mapping:\r\n            /job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\r\n    2019-06-15 23:48:38.131168: I tensorflow/core/common_runtime/direct_session.cc:317]    \r\n       Device mapping:\r\n        /job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\r\n\r\nPlease advise on how to use GPU with SaveModelBundle.  "
  },
  {
    "labels": [null, null, "documentation"],
    "text": "URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/estimator/SessionRunHook\r\nDescription of issue (what needs changing):\r\nClear description\r\n\r\nYes clear description\r\nCorrect links\r\n\r\nThe link to the source code correct.\r\nParameters defined\r\n\r\nAll parameters defined and formatted correctly.\r\nReturns defined\r\n\r\nReturn values are defined.\r\nRaises listed and defined\r\n\r\nNo raises listed and defined.\r\nUsage example\r\n\r\nNo usage examples provided\r\nRequest visuals, if applicable\r\n\r\nNo visuals included"
  },
  {
    "labels": ["documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/estimator/SessionRunHook\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nYes clear description\r\n\r\n### Correct links\r\n\r\nThe link to the source code correct.\r\n\r\n### Parameters defined\r\n\r\nAll parameters defined and formatted correctly.\r\n\r\n### Returns defined\r\nReturn values are defined.\r\n\r\n### Raises listed and defined\r\nNo raises listed and defined.\r\n\r\n### Usage example\r\n\r\nNo usage examples provided\r\n\r\n### Request visuals, if applicable\r\n\r\nNo visuals included\r\n\r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "only tf.keras.layers.Conv1D supports padding 'causal', and it is very important for time series research, however in\r\n\r\ntf.python.ops.conv1d\r\ninput: (batch_size, dim1size, dim2size, ... , channels_in)\r\nfilters: (filter_size, channels_in, channels_out)\r\n\r\nAlso this function behaves as expected, setting a op node according to the math and predicting an output Tensor of predictable shape.\r\n\r\ntf.keras.layers.Conv1D\r\ninput: (batch_size, steps, input_dim)\r\nfilter: size of 1D filter\r\noutput: (batch_size, new_steps, filters) \r\n\r\nThese are non usual names for the mathematical definition of convolution. Is \"steps\" the size of the time series ? new_steps the relation of the filter size with the input_dim ? are filters the channel output size ? \r\n\r\nSeems incompatible with the former that follows closely the mathematical definition and also expands for multi-channel like the 2D case. Also, is desirable to use causal padding with tf.python.ops.conv1d, without having to add extraneous functions by hand to the code.\r\n\r\nthank you, pls have your appreciation.\r\n\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\n[https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/Callback#on_train_batch_end](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/Callback#on_train_batch_end)\r\n\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Parameters defined\r\n\r\nThe parameter section of `on_train_batch_end` reads, in part,\r\n\r\n> `logs`: dict. Metric results for this batch\r\n\r\nSo the `logs` argument is expected to only contain metrics when this method is called. This is what I assumed when I coded my own custom training function.\r\n\r\nThis is different than the `logs` argument which is expected by `on_train_batch_begin` for example, which is:\r\n\r\n> `logs`: dict. Has keys `batch` and `size` representing the current batch number and the size of the batch.\r\n\r\nNow if we look at [the code](https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/callbacks.py) of `ModelCheckpoint`, we see that is has an `on_batch_end` method (which is called by `on_train_batch_end`) which calls the `size` key of `logs`. This is line 950:\r\n`self._samples_seen_since_last_saving += logs.get('size', 1)`\r\n\r\nSo the documentation of `on_train_batch_end` is not correct as to what is the dict expected by the method. And this has an impact when we want to create custom training functions that work well with Keras Callbacks."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/Print\r\n\r\n## Description of issue (what needs changing):\r\n\r\n[tf.Print](https://www.tensorflow.org/api_docs/python/tf/Print) was not rendered correctly in the website. I understand that it was deprecated in TF2.0, but it should be rendered correctly in the TF website.\r\n\r\n### Correct links\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/Print\r\n\r\n\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/train/polynomial_decay\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/api_docs/python/tf/train/polynomial_decay\r\n## Description of issue (what needs changing):\r\nA clarification of the example and why it actually works.\r\n\r\n### Clear description\r\nIn the example mentioned, if the global step is 0, it is unclear how the learning rate will actually change.\r\n\r\nThe formula can be rewritten as follows:\r\n\r\nd = (l - e) * (1 - g/s)^p + e\r\n\r\nIn the example, g = 0, which means the formula becomes (l - e) * 1 + e = l - e + e = l\r\n\r\nSo, I'm very unsure of why/how the learning rate in this example is actually going to decrease.\r\n\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "#### Issue description:\r\nIn the `tf.data` pipelines guide on TensorFlow.org called 'Importing Data', under 'Processing data with `Dataset.map()`' there is an [example](https://www.tensorflow.org/guide/datasets#parsing_tfexample_protocol_buffer_messages) showcasing how to parse `tf.example` protocol buffer messages':\r\n\r\n```python\r\ndef _parse_function(example_proto):\r\n  features = {\"image\": tf.FixedLenFeature((), tf.string, default_value=\"\"),\r\n              \"label\": tf.FixedLenFeature((), tf.int64, default_value=0)}\r\n  parsed_features = tf.parse_single_example(example_proto, features)\r\n  return parsed_features[\"image\"], parsed_features[\"label\"]\r\n...\r\n```\r\nThe config class for parsing fixed length input features used in the example - `tf.FixedLenFeature` - may not be easily identifiable in the API docs since its description is under the `tf.io` module under the alias `tf.io.FixedLenFeature`. \r\n\r\nUX: Figuring out what  `tf.FixedLenFeature` does required using the search bar on TensorFlow.org vs the TF Python [API site](https://www.tensorflow.org/api_docs/python/tf).\r\n\r\n(For your reference: [1.13 (core) doc](https://www.tensorflow.org/api_docs/python/tf/io/FixedLenFeature),  [r1.14 doc](https://www.tensorflow.org/versions/r1.14/api_docs/python/tf/io/FixedLenFeature), [r2.0 beta doc](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/io/FixedLenFeature))\r\n\r\n#### Feature request:\r\nChange the class in the guide to `tf.io.FixedLenFeature` or reference with a link to `tf.io...` for better UX."
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "# Existing URLs containing the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/constraints/MinMaxNorm\r\n## Description of the issue (what needs changing):\r\n- ### Correct links:\r\n     Yes\r\n\r\n- ###  Clear Description:\r\n  No, The description does not give recommendations of when and when not to use this symbol\r\n\r\n- ### Usage Example:\r\n   No usage example \r\n\r\n- ### Parameters Defined:\r\n   Parameters are Well defined\r\n\r\n  - ### Returns are not defined\r\n\r\n- ### Raises listed and Defined:\r\n  Errors are not defined.\r\n\r\n- ### Visuals if applicable:\r\n  No visuals are included."
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "TensorFlow version: 2.0\r\n## Existing URLs containing the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/metrics/BinaryAccuracy\r\n\r\n## Description of the issue (what needs changing):\r\n\r\n- #### Correct links: \r\n       Yes\r\n\r\n- #### Clear Description: \r\n   No, The description does not  give recommendations of when and when not to use this symbol\r\n\r\n- #### Usage Example: \r\n       Yes\r\n- #### Parameters Defined:\r\n\r\n  Parameters are poorly defined, and not formatted appropriately.\r\n- ####  Returns Defined: \r\n\r\n    Returns are not defined\r\n. \r\n- ####  Raises listed and Defined:\r\n\r\n   Errors are not defined.\r\n\r\n- #### Visuals if applicable: \r\n   No visuals are included.\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Referencing the deprecation hint of https://www.tensorflow.org/api_docs/python/tf/layers/dense\r\n\r\n## Description of issue (what needs changing):\r\n\r\nI wasn't able to find the referenced `tf.keras.layers.dense`, but only `tf.keras.layers.Dense`. Could this be a simple typo and the latter was ment to be pointed to?\r\n\r\n### Submit a pull request?\r\n\r\nIf this is a simple issue and not a functionality missing or a fault of me not finding the referenced method, then yes, I would PR it."
  },
  {
    "labels": [null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue: https://www.tensorflow.org/tutorials/load_data/tf_records#fetch_the_images\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing): There are two cat images but the second cat image should be replace by the bridge image as the image refers to a bridge.\r\n\r\n### Clear description\r\n\r\nThe second cat image should be changed to the bridge as the url points a bridge but the cat image has been published\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "URL(s) with the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/lite/OpHint/OpHintArgumentTracker\r\n\r\nDescription of issue (what needs changing):\r\nThe link to the TF 2.0 API Documentation is broken, it does not link to the documentation of the API. So, there is no documentation of TF 2.0 for this function."
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/lite/OpHint\r\n\r\n## Description of issue (what needs changing):\r\nThe link to the TF 2.0 API Documentation  is broken, it does not link to the documentation of the API. So, there is no documentation of TF 2.0 for this function.\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/experimental/Counter\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\nThe description is not clear, not provided as in the DOCS\r\n\r\n### Raises listed and defined\r\nErrors are not defined at all\r\n\r\n### Request visuals, if applicable\r\nNo visuals are included\r\n\r\n### Submit a pull request?\r\nYes\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/io/write_file\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\nThe description does not recommend at all in any way when and when not to use this symbol.\r\n\r\n### Correct links\r\n\r\nYes\r\n\r\n### Parameters defined\r\n\r\nYes\r\n\r\n### Returns defined\r\n\r\nYes\r\n\r\n### Raises listed and defined\r\nThe returned objects are not well defined and therefore not correct, complete and appropriately formatted\r\n\r\n### Usage example\r\n\r\nYes\r\n\r\n### Request visuals, if applicable\r\n\r\nNo single visual included in the symbol’s description. In some instances it will definitely clarify the content being presented.\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## Existing URLs containing the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/experimental\r\n\r\n## Description of the issue:\r\nCorrect Links: All links are correct and well defined\r\n\r\n## Clear Description\r\n\r\nThe description is not clear about when to use this symbol \r\n\r\n## Usage Example\r\nNo usage example is provided.\r\n\r\n## Parameters Defined\r\nParameters are poorly defined, and not formatted appropriately.\r\n\r\n## Returns Defined\r\nReturns are not defined.\r\n\r\n## Raises Listed and Defined\r\nErrors are not defined.\r\n\r\n## Visuals, if Applicable\r\nNo visuals are included."
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/io/FixedLenSequenceFeature\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\nThe description doesn’t give recommendation on when to use and not use the symbol\r\n\r\n### Parameters defined\r\nNo parameters defined.\r\n\r\n### Returns defined\r\nNo returns defined\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nNo errors defined \r\n\r\n### Usage example\r\nNo usage example \r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\nYes"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/io/read_file\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\nThe description does not give recommendations of when and when not to use this symbol.\r\n\r\n### Correct links\r\nThe link to the source code file (python/ops/gen_io_ops.py) is dormant.\r\n\r\n### Raises listed and defined\r\nErrors are not defined.\r\n\r\n### Usage example\r\nNo usage example provided.\r\n\r\n### Submit a pull request?\r\nYes"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## Existing Url with the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/io/FixedLenFeature\r\n\r\n## Description of issue (what needs changing):\r\nClear description with parameters, returns and usage example\r\n### Clear description\r\n\r\n### Correct links\r\nThe link to the python script where the function is define is activehttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/io/FixedLenFeature\r\n\r\n### Parameters defined\r\nNo parameters defined\r\n\r\n### Returns defined\r\nNo returns defined\r\n\r\n### Raises listed and defined\r\nThe raises is defined further in this link\r\nhttps://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/ops/parsing_ops.py\r\n\r\n###Are the errors defined? For example,\r\nErrors are not defined\r\n\r\n### Usage example\r\nUsage example provided in this link https://www.tensorflow.org/beta/tutorials/load_data/tf_records"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nI don't think it's documented so no link available.\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThere doesn't seem to be any documentation on how to change the default model for the `tf.keras.backend.get_session`. I need to do this to properly save my model (I think).\r\n\r\n### Clear description\r\n\r\nI have an RNN that I'm training in batches with TBTT using tf.keras. Since my model is stateful I have to be explicit about the batch size when I create the model. However, at predict time I want to be able to do predictions on arbitrary length sequences and to have a batch size of 1. So I create a new, nearly identical model,  and then copy the weights via `predict_model.set_weights(train_model.get_weights())`. This all works as expected.\r\n\r\nNow I want to save my prediction model so I can do inference from C++. If I follow the directions one finds on the internet (e.g. on [this page](https://medium.com/@pipidog/how-to-convert-your-keras-models-to-tensorflow-e471400b886a)) I need to do something like:\r\n\r\n```\r\nsession = tf.keras.backend.get_session()\r\ngraph = session.graph\r\nwith graph.as_default_graph():\r\n    # Do things to serialize the GraphDef to protobuf\r\n```\r\n\r\nBut if I do this the `session.graph` is the graph I used for training, not my prediction model. It seems `tf.keras` does some \"magic\" to switch sessions or default graph (not sure which) and I can't find any documentation about what it does or when. I believe I could make one \"dummy prediction\" with my `predict_model` to make it current but that seems super hacky.\r\n\r\nIs there any way to get the `Graph` that corresponds to a `tf.keras.Model`? If not, is there any way to make a `Model` be the current graph without doing something super hacky like making a prediction for data I don't care about?\r\n\r\nI tried tracing through the `model.predict` code to see where the session is used but didn't find it quickly and figured this should be documented so I decided to ask here.\r\n\r\n"
  },
  {
    "labels": [null, "documentation", null],
    "text": "I was using your distribute example: https://www.tensorflow.org/tutorials/distribute/training_loops\r\n\r\nI wanted to know how to properly extract some properties such as accuracy in this custom training loop example.\r\n\r\nI have tried a couple of things but the documentation regarding this is not too specific.\r\n\r\nSomething I was initially looking at was:\r\n  - passing in or returning a tf.Keras.metrics object, taking the logits and labels within the step_fn and getting predictions and then accuracy. But I am running into issues of tensor parsing. Should I be using tf.Summary.scalar in some way then?\r\n\r\nA concrete reply would help."
  },
  {
    "labels": [null, "documentation"],
    "text": "https://www.tensorflow.org/images/models/pose_estimation.gif\r\n\r\n\r\nthis Link is broken"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://github.com/tensorflow/docs/blob/master/site/en/r2/tutorials/generative/pix2pix.ipynb\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe code block below appears under the heading `Input Pipeline`.\r\nIt appears to be an almost, but not quite, semantic copy of the code block above it for the \r\n`train_dataset`, except that, in this code block for the `test_dataset` we are shuffling the\r\n`train_dataset` again.\r\n\r\n```\r\ntest_dataset = tf.data.Dataset.list_files(PATH+'test/*.jpg')\r\n# shuffling so that for every epoch a different image is generated\r\n# to predict and display the progress of our model.\r\ntrain_dataset = train_dataset.shuffle(BUFFER_SIZE)\r\ntest_dataset = test_dataset.map(load_image_test)\r\ntest_dataset = test_dataset.batch(1)\r\n```\r\n\r\nSo, I think that this code block should be:\r\n\r\n```\r\ntest_dataset = tf.data.Dataset.list_files(PATH+'test/*.jpg')\r\n# shuffling so that for every epoch a different image is generated\r\n# to predict and display the progress of our model.\r\ntest_dataset = test_dataset.shuffle(BUFFER_SIZE)\r\ntest_dataset = test_dataset.map(load_image_test)\r\ntest_dataset = test_dataset.batch(1)\r\n```\r\n\r\nAlso note that the code block for the `train_dataset` has:\r\n\r\n```\r\ntrain_dataset = train_dataset.map(load_image_train,\r\n                                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\r\n```\r\n\r\nBut the code block for the `test_dataset` only has:\r\n```\r\ntest_dataset = test_dataset.map(load_image_test)\r\n```\r\n\r\nThe `AUTOTUNE ` is noted here, but not explained, so I can't easily comment on what its use,\r\nor lack of, actually means:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/data/experimental#AUTOTUNE\r\n\r\n### Submit a pull request?\r\n\r\nI can if this is actually incorrect."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/beta/tutorials/load_data/csv#categorical_data\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe new `Load CSV with tf.data` tutorial is very nice. The tutorial shows users how to load a csv file into a tf.data Dataset. However, there are a couple of issues in the tutorial. First, the tutorial shows a very inconsistent and un-scalable way to encode categorical data using Regex expressions. A simpler way would be to use the already developed Feature Columns API, which is more consistent with the existing Tensorflow API. Second, the name of the tutorial is improper English. The tutorial is about loading tf.data with a CSV, not loading a CSV file with tf.data. So that should be fixed. \r\n\r\n### Clear description\r\n1. Overly complicated and unscalable explanation of how to encode categorical features.\r\n\r\nThe tutorial takes the user through loading a CSV file into a tf.data Dataset using the experimental `make_csv_dataset` function in TF-2.0.0-beta. That is all very well done. But the problem arises in the \"Data Preprocessing\" section. \r\n\r\nThe section on categorical data says that data must be converted from text to numerical encodings before passing the data to the model. However, the method described looks like this:\r\n\r\n```\r\nCATEGORIES = {\r\n    'sex': ['male', 'female'],\r\n    'class' : ['First', 'Second', 'Third'],\r\n    'deck' : ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'],\r\n    'embark_town' : ['Cherbourg', 'Southhampton', 'Queenstown'],\r\n    'alone' : ['y', 'n']\r\n}\r\n``` \r\nThen using this dictionary, the user is asked to:\r\n\r\n```\r\ndef process_categorical_data(data, categories):\r\n  \"\"\"Returns a one-hot encoded tensor representing categorical values.\"\"\"\r\n  \r\n  # Remove leading ' '.\r\n  data = tf.strings.regex_replace(data, '^ ', '')\r\n  # Remove trailing '.'.\r\n  data = tf.strings.regex_replace(data, r'\\.$', '')\r\n  \r\n  # ONE HOT ENCODE\r\n  # Reshape data from 1d (a list) to a 2d (a list of one-element lists)\r\n  data = tf.reshape(data, [-1, 1])\r\n  # For each element, create a new list of boolean values the length of categories,\r\n  # where the truth value is element == category label\r\n  data = tf.equal(categories, data)\r\n  # Cast booleans to floats.\r\n  data = tf.cast(data, tf.float32)\r\n  \r\n  # The entire encoding can fit on one line:\r\n  # data = tf.cast(tf.equal(categories, tf.reshape(data, [-1, 1])), tf.float32)\r\n  return data\r\n```\r\n\r\nNow this approach will work, but there are a couple of really big problems. First, Tensorflow has a Feature Column API already developed to handle this type of conversion. If the user simply did something like creating a feature column with vocabulary list, and then wrapping that column in an indicator column, this same code could be resolved in 2 lines instead of 14 lines. This change would also make the code easier to read, and provide more insight into how to use the Feature API.  \r\n```\r\ncol_sex = tf.feature_column.categorical_column_with_vocabulary_list(key=\"Sex\", vocabulary_list=[\"male\", \"female\"])\r\n\r\nfc_sex =  tf.feature_column.indicator_column(col_sex)\r\n```\r\n2. Correct the name of the tutorial\r\n\r\nThe name of the tutorial is \"Load CSV with tf.data.\" This name is actually improper English and a bit confusing. The current name makes it sound like you are loaded a tf.data dataset into a CSV, which is the opposite of the intent. The tutorial is about taking a CSV file and loading the data into a tf.data Dataset. So the proper name of the tutorial should be \"Load a CSV file into a tf.data Dataset,\" or \"Populate a tf.data Dataset with CSV file.\" This change might help reduce confusion about what the tutorial is trying to demonstrate. \r\n\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\nYes\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\nYes\r\n### Returns defined\r\n\r\nAre return values defined?\r\nYes\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\nErrors are not clearly defined. \r\n### Usage example\r\n\r\nIs there a usage example?\r\nThere is a usage example, but the usage example is very poorly designed. Hence I submitted the issue.\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\nVisuals are okay. \r\n### Submit a pull request?\r\nI am happy to submit a pull request. I guess let me see the response to this issue. If the development team agrees, then I can work on a pull request to update the documentation. \r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/guide/saved_model#save_and_restore_models\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description and Usage Example\r\n\r\nI've already created several models, trained over several days each, that we're ready to move from local testing to a serving environment.\r\n\r\nThe models were saved using the function\r\n\r\n```python\r\ndef save_graph_to_file(sess, graph, graph_file_name):\r\n    \"\"\"Saves an graph to file, creating a valid quantized one if necessary.\"\"\"\r\n    output_graph_def = graph_util.convert_variables_to_constants(sess, graph.as_graph_def(), [final_tensor_name])\r\n    with gfile.FastGFile(graph_file_name, 'wb') as f:\r\n        f.write(output_graph_def.SerializeToString())\r\n```\r\n\r\nvia the [image retraining sample script](https://github.com/tensorflow/tensorflow/blob/v1.6.0/tensorflow/examples/image_retraining/retrain.py#L853-L859).\r\n\r\nNow, I'm ready to move this to a serving environment (via Sagemaker, but that just implements `tensorflow.serving`).\r\n\r\nThe error is clear enough:\r\n\r\n```\r\n2019-06-04 22:38:53.794056: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:54] Reading meta graph with tags { serve }\r\n2019-06-04 22:38:53.798096: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:259] SavedModel load for tags { serve }; Status: fail. Took 83297 microseconds.\r\n2019-06-04 22:38:53.798132: E tensorflow_serving/util/retrier.cc:37] Loading servable: {name: model version: 1} failed: Not found: Could not find meta graph def matching supplied tags: { serve }. To inspect available tag-sets in the SavedModel, please use the SavedModel CLI: `saved_model_cli`\r\n```\r\n\r\nLoading up the graph by [adapting the loader from the retrain script](https://github.com/tensorflow/tensorflow/blob/v1.6.0/tensorflow/examples/image_retraining/retrain.py#L270-L293), I try to just append the serving tag to the graph\r\n\r\n```python\r\ndef load_graph(model_file):\r\n    \"\"\"\r\n    Code from v1.6.0 of Tensorflow's label_image.py example\r\n    \"\"\"\r\n    graph = tf.Graph()\r\n    graph_def = tf.GraphDef()\r\n    with open(model_file, \"rb\") as f:\r\n        graph_def.ParseFromString(f.read())\r\n    with graph.as_default():\r\n        tf.import_graph_def(graph_def)\r\n    return graph\r\n# Load the graph\r\ngraph = load_graph(modelPath)\r\nimport shutil\r\nif os.path.exists(exportDir):\r\n    shutil.rmtree(exportDir)\r\n# Add the serving metagraph tag\r\nbuilder = tf.saved_model.builder.SavedModelBuilder(exportDir)\r\nfrom tensorflow.saved_model import tag_constants\r\nwith tf.Session(graph= graph) as sess:\r\n    builder.add_meta_graph_and_variables(sess, [tag_constants.SERVING, tag_constants.GPU], strip_default_attrs= True)\r\nbuilder.save()\r\nprint(\"Built a SavedModel\")\r\n```\r\n\r\nwhich doesn't work (still has the same error). I'm not giving up on this, but given that the code was written out with a Tensorflow example, this seems like an obvious use case to cover.\r\n\r\n\r\n### Submit a pull request?\r\n\r\nIf I'm able to solve this in a timely way, I'll submit a PR for the docs; at the moment it's a few steps away from me being there, however.\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/io/decode_image\r\nhttps://github.com/tensorflow/tensorflow/edit/master/tensorflow/python/ops/image_ops_impl.py\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Usage example\r\n\r\nNo usage example given\r\n\r\n### Submit a pull request?\r\n\r\nYes\r\nhttps://github.com/tensorflow/tensorflow/pull/29512"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/image/crop_and_resize\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/image_ops_impl.py\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Raises listed and defined\r\n\r\nRaises are not defined\r\n\r\n### Usage example\r\n\r\nNo usage example is given\r\n\r\n### Submit a pull request?\r\n\r\nYes\r\nhttps://github.com/tensorflow/tensorflow/pull/29508"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/alpha/tutorials/generative/pix2pix\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe `generate_images` function:\r\n\r\n```python\r\ndef generate_images(model, test_input, tar):\r\n  # the training=True is intentional here since\r\n  # we want the batch statistics while running the model\r\n  # on the test dataset. If we use training=False, we will get\r\n  # the accumulated statistics learned from the training dataset\r\n  # (which we don't want)\r\n  prediction = model(test_input, training=True)\r\n  plt.figure(figsize=(15,15))\r\n\r\n  display_list = [test_input[0], tar[0], prediction[0]]\r\n  title = ['Input Image', 'Ground Truth', 'Predicted Image']\r\n\r\n  for i in range(3):\r\n    plt.subplot(1, 3, i+1)\r\n    plt.title(title[i])\r\n    # getting the pixel values between [0, 1] to plot it.\r\n    plt.imshow(display_list[i] * 0.5 + 0.5)\r\n    plt.axis('off')\r\n  plt.show()\r\n```\r\n\r\ngenerate images using the generator model with the flag training=True. The problem is that in this way the batch normalization statistics (moving mean and moving variance) are updated using the test set statistics. \r\n\r\nThis is wrong. The original pix2pix paper asserts that they evaluate the model using the flag training=True but they do this in order to normalize using the minibatch (with batch size = 1) statistics. This is done only in the test phase and statistics should not be saved into the model.\r\n\r\nI think that a better approach is to visualize the data generated during training (not re-calling the generator but using the data generated in order to calculate the loss). \r\n\r\nOnce the training is finished we can evaluate the model.\r\n\r\nThe problem is that in tf 2.0 is not possible to use the minibatch statistics in the batch normalization layer. Every time we call BatchNorm()(input, training=True) the moving mean and moving variance are updated. I think that this can be managed in a better way by adding a flag that tells the layer whether to use the minibatch statistics. \r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/accuracy/README.md\r\n\r\n## Description of issue (what needs changing):\r\n\r\nIn post_training_quantization page (https://tensorflow.google.cn/lite/performance/post_training_quantization), the link to _TensorFlow Lite model accuracy_ page is invalid, it changes to new address after check (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/accuracy/ilsvrc/README.md), Please fix it\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  { "labels": ["documentation"], "text": "TF 2.0 Alpha page 404" },
  {
    "labels": [null, null, null, "documentation"],
    "text": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No. this is a stock example, see collab notebook here to reproduce \r\nhttps://colab.research.google.com/drive/1O8dCWeYBVjFEax-ZK1XbJE_vfEzB2Ieq\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): '2.0.0-dev20190605'\r\n- Python version: \r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory: Collab\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nmodel.fit fails in the stock example with the following error:\r\nInvalidArgumentError: 2 root error(s) found.\r\n  (0) Invalid argument:  Expected D2 of index to be 2 got 3 at position 1\r\n\t [[node sequential/dense_features_6/age_bucketized_X_thal_indicator/SparseCross (defined at <ipython-input-20-bf1fb22dfeb0>:14) ]]\r\n  (1) Invalid argument:  Expected D2 of index to be 2 got 3 at position 1\r\n\t [[node sequential/dense_features_6/age_bucketized_X_thal_indicator/SparseCross (defined at <ipython-input-20-bf1fb22dfeb0>:14) ]]\r\n\t [[sequential/dense_features_6/age_bucketized_X_thal_indicator/SparseToDense/_56]]\r\n0 successful operations.\r\n0 derived errors ignored. [Op:__inference_keras_scratch_graph_2134]\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nhttps://colab.research.google.com/drive/1O8dCWeYBVjFEax-ZK1XbJE_vfEzB2Ieq\r\n\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/experimental/shuffle_and_repeat\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nNo.\r\nit has warning and it is kinda abstract on when to use the function\r\n\r\n\r\n### Raises listed and defined\r\nNo.\r\nyet while comparing  dataset.shuffle(buffer_size, reshuffle_each_iteration=True).repeat(count).the difference is in the actions performed on the datasets. \r\n\r\n\r\n### Usage example\r\nNo.\r\nthere is need of an example to clearly explain the difference between the two shuffles\r\n\r\n\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/backend/maximum\r\n\r\n## Description of the issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nThe description is not clear enough.\r\n\r\n### Correct links\r\n\r\nThe links are okay.\r\n\r\n### Parameters defined\r\n\r\nThe parameters are defined.\r\n\r\n### Returns defined\r\n\r\nThe return values are defined.\r\n\r\n### Raises listed and defined\r\n\r\nErrors are not defined or listed.\r\n\r\n### Usage example\r\n\r\nThere is no usage example.\r\n\r\n### Request visuals, if applicable\r\n\r\nThere are no visuals.\r\n\r\n### Submit a pull request?\r\n\r\nNo.\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/experimental/scan\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Raises listed and defined\r\nNo\r\nIt's  hard for a person to tell what is  raising the error \r\n\r\n\r\n### Usage example\r\n\r\nNo. usage example,it might be hard for someone to know under what context to use it \r\n\r\n### Request visuals, if applicable\r\nNo\r\n\r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/experimental/make_saveable_from_iterator\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Returns defined\r\n\r\nThe returns section is missing.\r\n\r\n### Raises listed and defined\r\n\r\nRaises are neither listed nor defined."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "\r\n## Existing Url with the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/io/decode_base64\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\nThe link to the python script where the function is define is inactive\r\nWrong: python/ops/gen_string_ops.py\r\nCorrect (The file is not mentioned in the repo)\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_columErrors are not defined\r\n\r\n### Usage example\r\n\r\nNo usage example provided\r\nUse case: (The documentation does not define how to use, when to use the symbol)\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "**Existing URLs containing the issue:**\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/io/decode_json_example\r\n\r\n### Description of issue (what needs changing):\r\n**Correct Links**\r\nThe link to the python script where the function is defined is inactive. \r\nWrong: python/ops/gen_parsing_ops.py.\r\nCorrect: (The file mentioned here is not in the repo)\r\n\r\n**Usage Example**\r\nNo usage example is provided.\r\nUse Cases: The documentation does not define when to use and when not to use the symbol.\r\n\r\n**Raises Listed and Defined**\r\nErrors are not defined."
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue: \r\nhttps://www.tensorflow.org/versions\r\n\r\n## Description of issue (what needs changing): \r\n\r\n### Clear Description \r\n\r\nWhen someone is in [this page](https://www.tensorflow.org/versions) , clicking on the bullet point `r1.13 (stable)` redirects to a `404 not found page`.\r\n\r\n### Correct links\r\n\r\nThe bullet point targets [here](https://www.tensorflow.org/versions/api_docs/python/tf) while it should target [here](https://www.tensorflow.org/api_docs/python/tf). \r\n\r\n\r\n### Submit a pull request?\r\n\r\nI tried to fix it but I cannot find where this link ref is stated. If someone could point me in the right direction I could fix it, otherwise someone else could do it.\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/image/convert_image_dtype\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/image_ops_impl.py\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Raises listed and defined\r\n\r\nRaises are not listed.\r\n\r\n### Usage example\r\n\r\nUsage example is not provided\r\n\r\n### Submit a pull request?\r\n\r\nYes\r\nhttps://github.com/tensorflow/tensorflow/pull/29387"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf\r\n\r\n## Description of issue (what needs changing):\r\n\r\nI cannot find a documentation how to do the native inference with a frozen or saved model in TF 2.0.\r\n\r\n### Clear description\r\n\r\nWe would like to do inferences/predictions with existing models we trained in Tensorflow 1. Therefore, we have normal frozen and saved models. However, we cannot find a documentation how we can load these models and execute them afterwards. \r\nWe managed to load the [Graph objects](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/Graph) but the Graph objects do not allow us to do predictions.\r\n\r\nIn the TFJS project the API is clear to us but in TF 2.0 we struggle a lot.  \r\n\r\n### Correct links\r\n### Parameters defined\r\n### Returns defined\r\n### Raises listed and defined\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\n```\r\nimport os\r\nimport tensorflow as tf\r\n\r\n# Load the Tensorflow model into memory.\r\ndetection_graph = tf.compat.v1.Graph()\r\nwith detection_graph.as_default():\r\n    od_graph_def = tf.compat.v1.GraphDef()\r\n    with tf.io.gfile.GFile(PATH_TO_FROZEN_MODEL, 'rb') as fid:\r\n        serialized_graph = fid.read()\r\n        od_graph_def.ParseFromString(serialized_graph)\r\n        tf.import_graph_def(od_graph_def, name='')\r\n```\r\n\r\n### Request visuals, if applicable\r\n### Submit a pull request?\r\n\r\nmany thanks,\r\nSebastian\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "# DOC Issue\r\n\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/tutorials/keras/basic_text_classification\r\n\r\n## Description of issue (what needs changing):\r\nBroken(Wrong) Link in basic text classification tutorial. Needs to be updated/removed/changed.\r\n\r\n### Clear description\r\nIn the basic text classification tutorial (imdb reviews) the reference link for pad_sequences points to https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences but you get redirected to \r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/preprocessing\r\nwhich is pretty unhelpful. \r\n+\r\non \r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/preprocessing\r\nthe reference link to the keras documentation returns a 404.\r\nSo there is not much information to be gained from following that link. \r\n\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/install/lang_c\r\n## Description of issue (what needs changing):\r\nThere is no mention on this page what options were used to build the library files.\r\nFor example the lib (\"Linux GPU support\") requires cuda 6.0 compute architecture (or above) which is not mentioned. While the pip package runs fine on 3.0 or above.\r\nOr which CPU instructions sets/extensions are supported and which are required (minimum).\r\nIt would be good if all of these were mentioned alongside the download link.\r\n\r\nI just run into this issue using a GPU with compute architecture 3.7, and TF says it ignores the device because it was not built to support that architecture. It also gives me an info message about the lib not built with SSE4.1 SSE4.2 AVX AVX2 FMA in mind.\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/tutorials/load_data/tf_records\r\n\r\n## Description of issue (what needs changing):\r\nin the context\r\n\r\n> The tf.train.Feature message type can accept one of the following three types (See the [.proto file](https://www.tensorflow.org/tutorials/load_data/(https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/feature.proto)%20for%20reference). Most other generic types can be coerced into one of these.\r\n\r\nNote: the link of `.proto file` is incorrect. \r\n\r\nIt should be \r\n\r\n> The tf.train.Feature message type can accept one of the following three types (See the [.proto file](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/feature.proto) for reference). Most other generic types can be coerced into one of these.\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/master/api_docs/python/tf/data\r\nhttps://www.tensorflow.org/versions/master/api_docs/python/tf/data/Dataset\r\nhttps://www.tensorflow.org/versions/master/api_docs/python/tf/data/TextLineDataset\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/data/ops/dataset_ops.py\r\n\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### The map() method call for each of these classes has an example which is not being rendered properly.\r\n\r\nThis is what is intended by the docstring\r\n\r\n```\r\n   # NOTE: The following examples use `{ ... }` to represent the\r\n    # contents of a dataset.\r\n    # Each element is a `tf.Tensor` object.\r\n    a = { 1, 2, 3, 4, 5 }\r\n    # `map_func` takes a single argument of type `tf.Tensor` with the same\r\n    # shape and dtype.\r\n    result = a.map(lambda x: ...)\r\n```\r\n\r\nThis is what gets rendered to the web.  It looks like the back tick references have an issue.\r\n\r\n```\r\n# NOTE: The following examples use `{ ... }` to represent the\r\n# contents of a dataset.\r\n# Each element is a <a href=\"../../tf/Tensor\"><code>tf.Tensor</code></a> object.\r\na = { 1, 2, 3, 4, 5 }\r\n# `map_func` takes a single argument of type <a href=\"../../tf/Tensor\"><code>tf.Tensor</code></a> with the same\r\n# shape and dtype.\r\nresult = a.map(lambda x: ...)\r\n```\r\n\r\n\r\n### Submit a pull request?\r\n\r\nNo, the docstring looks correct.  I don't know how to fix the error."
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/master/api_docs/python/tf/data/Dataset#list_files\r\nhttps://www.tensorflow.org/versions/master/api_docs/python/tf/data/experimental/CsvDataset#list_files\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/data/\r\n\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### list_files() routine for both classes use the same bit of code to describe how to use the method.  The descriptive text is written in docstring and it looks like this\r\nExample:\r\n      If we had the following files on our filesystem:\r\n        - /path/to/dir/a.txt\r\n        - /path/to/dir/b.py\r\n        - /path/to/dir/c.py\r\n      If we pass \"/path/to/dir/*.py\" as the directory, the dataset\r\n      would produce:\r\n        - /path/to/dir/b.py\r\n        - /path/to/dir/c.py\r\n\r\nHowever, when rendered it is all one line without the indentation or bullet points.  So it looks like this:\r\n\r\nIf we had the following files on our filesystem: - /path/to/dir/a.txt - /path/to/dir/b.py - /path/to/dir/c.py If we pass \"/path/to/dir/*.py\" as the directory, the dataset would produce: - /path/to/dir/b.py - /path/to/dir/c.py\r\n\r\n\r\n\r\n\r\nThis should be corrected.\r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/master/api_docs/python/tf/data/Dataset\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/data/ops/dataset_ops.py\r\n\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Need an overall example of how to use tf.data.Dataset\r\n\r\nIt is a struggle to relate the dataset with the keras model code.  The model.fit() doc describes how to use a tf.dataset as input but without experimentation its hard to discern the correct format of the dataset.\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?  Yes.\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly? Yes\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? Yes.\r\n\r\n### Usage example\r\n\r\nIs there a usage example?  No.  I added an example for the common use case of most users to use the dataset with a simple model.fit call for keras.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? No. yes, it would be helpful.\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue?  Yes.\r\n\r\n[[TF 2.0 API Docs] tf.data Add pointer to tutorials which work with r2.0 #29323](https://github.com/tensorflow/tensorflow/pull/29323)"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/master/api_docs/python/tf/image/central_crop\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/image_ops_impl.py\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Usage example\r\n\r\nNo usage example provided\r\n\r\n### Submit a pull request?\r\n\r\nYes"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/master/api_docs/python/tf/image/adjust_saturation\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/image_ops_impl.py\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Raises listed and defined\r\n\r\nRaises are not listed\r\n\r\n### Usage example\r\n\r\nNo usage example has been provided\r\n\r\n### Submit a pull request?\r\n\r\nYes\r\nhttps://github.com/tensorflow/tensorflow/pull/29333"
  },
  {
    "labels": ["documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/master/api_docs/python/tf/image/adjust_jpeg_quality\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/image_ops_impl.py\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Raises listed and defined\r\n\r\nRaises are not listed and defined.\r\n\r\n### Usage example\r\n\r\nNo usage example has been provided\r\n\r\n### Submit a pull request?\r\n\r\nYes\r\nhttps://github.com/tensorflow/tensorflow/pull/29331"
  },
  {
    "labels": ["documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/master/api_docs/python/tf/image/adjust_hue\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/image_ops_impl.py\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Raises listed and defined\r\n\r\nRaises are not listed and defined\r\n\r\n### Usage example\r\n\r\nNo usage example has been provided\r\n\r\n### Submit a pull request?\r\n\r\nYes\r\nhttps://github.com/tensorflow/tensorflow/pull/29328"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/master/api_docs/python/tf/image/adjust_gamma\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/image_ops_impl.py\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Usage example\r\n\r\nNo usage example provided\r\n\r\n### Submit a pull request?\r\n\r\nYes\r\nhttps://github.com/tensorflow/tensorflow/pull/29326"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/master/api_docs/python/tf/data\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/data/__init__.py\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Added reference to three tutorials on using tf.data\r\n\r\nSince there are a mix of r2.0 and r1.x tutorials on datasets, these three are relevant for 2.0\r\n\r\n### Correct links\r\n\r\nYes\r\n### Parameters defined\r\n\r\nYes/NA\r\n\r\n### Returns defined\r\n\r\nYes/NA\r\n\r\n### Raises listed and defined\r\n\r\nNo/Perhaps NA\r\n\r\n### Usage example\r\n\r\nNo, this is to add a pointer to usage.\r\n\r\n### Request visuals, if applicable\r\n\r\nNo. It would be good to have some simple visuals relative to the different classes.\r\n\r\n### Submit a pull request?\r\n\r\n[#29323](https://github.com/tensorflow/tensorflow/pull/29323)\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/master/api_docs/python/tf/image/adjust_contrast\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/image_ops_impl.py\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Raises listed and defined\r\n\r\nRaises are not listed and defined\r\n\r\n### Usage example\r\n\r\nNo usage example has been provided\r\n\r\n### Submit a pull request?\r\n\r\nYes\r\nhttps://github.com/tensorflow/tensorflow/pull/29322"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/master/api_docs/python/tf/image/adjust_brightness\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/image_ops_impl.py\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Raises listed and defined\r\n\r\nRaises are not listed and defined\r\n\r\n### Usage example\r\n\r\nNo usage example has been provided\r\n\r\n### Submit a pull request?\r\n\r\nYes\r\nhttps://github.com/tensorflow/tensorflow/pull/29320"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/master/api_docs/python/tf/identity_n\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Correct links\r\n\r\nThe path should be href, also the file it refers to does not exists\r\n\r\n### Raises listed and defined\r\n\r\nRaises are not listed and defined\r\n\r\n### Submit a pull request?\r\n\r\nNo"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/master/api_docs/python/tf/identity\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/array_ops.py\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Raises listed and defined\r\n\r\nRaises are not listed and defined\r\n\r\n### Usage example\r\n\r\nNo usage example provided\r\n\r\n### Submit a pull request?\r\n\r\nYes\r\nhttps://github.com/tensorflow/tensorflow/pull/29316"
  },
  {
    "labels": ["documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/RegisterGradient\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Raises listed and defined\r\n\r\n__init__ method can return __TypeError__ but not listed\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/estimator/VocabInfo\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nThis API Documentation does not state when or when not to use this symbol. The description lacks details specific to the desired use case. \r\n\r\n### Correct links\r\n\r\nThe link to the source code is correct.\r\n\r\n### Parameters defined\r\n\r\nAll of the parameters are defined and formatted correctly.\r\n\r\n### Returns defined\r\n\r\nReturn values are not defined.\r\n\r\n### Raises listed and defined\r\n\r\nErrors are not defined.\r\n\r\n### Usage example\r\n\r\nThe API Symbol also doesn't contain well-documented code sample(s). The current code samples provided are missing concise explanations. For example, why would you use the different backup initializers or invocations?\r\n\r\n### Request visuals, if applicable\r\n\r\nNo visuals specified.\r\n\r\n### Submit a pull request?\r\n\r\nYes, I've created a pull request.\r\nhttps://github.com/tensorflow/tensorflow/pull/29520\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/maximum\r\n\r\n## Description of issue (what needs changing):\r\n\r\nClarify description, and add usage examples.\r\n\r\n### Clear description\r\n\r\nDescription gives no insight into this methods function.\r\n\r\n### Usage example\r\n\r\nNo Usage example provided.\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/experimental/Reducer\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nBetter description could be provided\r\n\r\n### Parameters defined\r\n\r\nNo\r\n\r\n### Returns defined\r\n\r\nNo\r\n\r\n### Usage example\r\n\r\nNo example is provided\r\n\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "Link to Issue: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/estimator/DNNLinearCombinedEstimator\r\n\r\nSo I noticed that in the usage example for tf.estimator.BaselineEstimator, it references tf.contrib.estimator.multi_label_head(), and I heard that tf.contrib is being deprecated. There is not replacement yet available for multi_label_head, and I wanted to bring this to you attention."
  },
  {
    "labels": ["documentation"],
    "text": "Link to Issue: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/estimator/DNNEstimator\r\n\r\nSo I noticed that in the usage example for tf.estimator.DNNEstimator, it references tf.contrib.estimator.multi_label_head(), and I heard that tf.contrib is being deprecated. There is not replacement yet available for multi_label_head, and I wanted to bring this to you attention."
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/experimental/OptionalStructure\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nNo description provided to any of the defined methods\r\n\r\n### Usage example\r\n\r\nNo usage example is provided\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/io/decode_and_crop_jpeg\r\n\r\n## Description of issue (what needs changing):\r\nNo hyperlink for \r\n`Defined in generated file: python/ops/gen_image_ops.py`\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/experimental/Optional\r\n\r\n### Usage example\r\n\r\nNo usage example provided\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "Links to Issue: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/estimator/BaselineEstimator\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/estimator/DNNEstimator\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/estimator/DNNLinearCombinedEstimator\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/estimator/LinearEstimator\r\n\r\nSo I noticed that in the usage example for the modules listed above, they reference tf.contrib.estimator.multi_label_head(), and I heard that tf.contrib is being deprecated. There is not replacement yet available for multi_label_head, and I wanted to bring this to you attention. "
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/math/divide\r\n\r\n\r\n### Parameters defined\r\n\r\nParameter 'Name' is defined but no documentation provided regarding how to use it."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/nn/convolution\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Usage example\r\n\r\nNeeds usage example\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/control_dependencies\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nWhile current description is sufficiently clear, may want to link to the API doc referenced\r\n\r\n* currently: \"Wrapper for `Graph.control_dependencies()` using the default graph.\"\r\n* suggested: \"Wrapper for [`Graph.control_dependencies()`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/Graph#control_dependencies) using the default graph.\r\n\r\n### Submit a pull request?\r\n\r\nYes"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Options\r\n## Description of issue (what needs changing):\r\n\r\n### Usage example\r\n\r\nThere is no usage example."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/master/api_docs/python/tf/histogram_fixed_width_bins\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Raises listed and defined\r\n\r\nRaises are not defined and listed\r\n\r\n### Submit a pull request?\r\n\r\nNo"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/nn/dropout\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Usage example\r\n\r\nUsages are linked but none are detailed inline on the page\r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/master/api_docs/python/tf/histogram_fixed_width\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Raises listed and defined\r\n\r\nRaises are not defined and listed\r\n\r\n### Submit a pull request?\r\n\r\nNo"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/custom_gradient\r\n\r\n## Description of issue (what needs changing):\r\n### Raises listed and defined\r\n\r\nErrors are not defined."
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/VariableSynchronization\r\n\r\n\r\n### Usage example\r\n\r\nNo usage example is provided\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/metrics\r\n\r\n## Description of issue (what needs changing):\r\nthe link to the source code links to 404 page\r\n`Defined in python/keras/api/_v2/keras/metrics/__init__.py.`\r\n\r\n### Correct links\r\nhttps://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/metrics.py\r\n\r\n\r\n### Submit a pull request?\r\nno\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/master/api_docs/python/tf/hessians\r\n\r\n## Description of issue (what needs changing):\r\n\r\nNo usage example defined\r\n\r\n### Usage example\r\n\r\nUsage example is not provided. Although the method does not work with eager execution enabled and throws this error:\r\nRuntimeError: tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead.\r\n\r\n### Submit a pull request?\r\n\r\nNo"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue: \r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/autograph/experimental/Feature\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nThere is no description provided.\r\n\r\n### Parameters defined\r\n\r\nParameters are undefined.\r\n\r\n### Returns defined\r\n\r\nReturn values are not defined.\r\n\r\n### Raises listed and defined\r\n\r\nErrors are not defined? \r\n\r\n### Usage example\r\n\r\nThere is not a usage example.\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/nn/l2_loss\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nThe current description could be improved\r\n\r\n### Correct links\r\n\r\nIt refers to a generated python file that we cannot access\r\n\r\n### Raises listed and defined\r\n\r\nRaises are not defined\r\n\r\n### Usage example\r\n\r\nNo usage example\r\n\r\n### Request visuals, if applicable\r\n\r\nNo visual\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/master/api_docs/python/tf/guarantee_const\r\n\r\n## Description of issue (what needs changing):\r\n\r\nNo usage example is provided and the link does not exist. The raises are also not defined.\r\n\r\n### Correct links\r\n\r\nThe link does not exists and is also a simple text\r\n\r\n### Raises listed and defined\r\n\r\nRaises are not listed\r\n\r\n### Usage example\r\n\r\nNo usage example provided.\r\n\r\n### Submit a pull request?\r\n\r\nNo"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/clip_by_norm\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Raises listed and defined\r\n\r\nErrors are not defined.\r\n\r\n### Request visuals, if applicable\r\n\r\nNo visuals are included.\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/master/api_docs/python/tf/group\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/control_flow_ops.py\r\n\r\n## Description of issue (what needs changing):\r\n\r\nA clear description should be added and a proper usage example is to be added. \r\n\r\n### Clear description\r\n\r\nFor example:\r\nA group operations can run multiple operations at the same time, operations are not sequential and they will be executed when tf.group will be called.\r\n\r\n### Usage example\r\n\r\nThere is no usage example provided except for a link to where it's being used.\r\n\r\n### Submit a pull request?\r\nYes\r\nhttps://github.com/tensorflow/tensorflow/pull/29265"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/VariableAggregation\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nThe description is not opinionated about when to use this symbol, and unclear on what aggregation methods for combining gradients would be useful for.\r\n\r\n### Parameters defined\r\n\r\nParameters are poorly defined, and not formatted appropriately.\r\n\r\n### Returns defined\r\n\r\nReturns are not defined.\r\n\r\n### Raises listed and defined\r\n\r\nErrors are not defined.\r\n\r\n### Usage example\r\n\r\nNo usage example is provided.\r\n\r\n### Request visuals, if applicable\r\n\r\nNo visuals are included."
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/master/api_docs/python/tf/math/greater_equal\r\n\r\n## Description of issue (what needs changing):\r\n\r\nCorrect link is not provided in the sense that it is only a text and not an actual link to the file.\r\nNo usage example is given in the documentation.\r\nRaises are also not listed\r\n\r\n### Correct links\r\n\r\nCorrect link is not provided in the sense that it is only a text and not an actual link to the file.\r\n\r\n### Raises listed and defined\r\n\r\nRaises are also not listed\r\n\r\n### Usage example\r\n\r\nNo usage example is given in the documentation."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/master/api_docs/python/tf/math/greater\r\n\r\n## Description of issue (what needs changing):\r\n\r\nCorrect link is not provided in the sense that it is only a text and not an actual link to the file.\r\nNo usage example is given in the documentation.\r\nRaises are also not listed\r\n\r\n### Correct links\r\n\r\nCorrect link is not provided in the sense that it is only a text and not an actual link to the file.\r\n\r\n### Raises listed and defined\r\n\r\nRaises are not listed in the documentation\r\n\r\n### Usage example\r\n\r\nThere is no usage example provided"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\n#https://www.tensorflow.org/alpha/guide/data#applying_arbitrary_python_logic\r\nhttps://www.tensorflow.org/beta/guide/data#applying_arbitrary_python_logic\r\n## Description of issue (what needs changing):\r\n\r\nminor typo, just need to update `py_func` in example so it is `py_function`\r\n\r\n### Clear description\r\n\r\nIn last 4 lines of code block underneath \"applying arbitrary python logic\" section\r\n\r\n```Python\r\ndataset = dataset.map(\r\n    lambda filename, label: tuple(tf.py_func(\r\n        _read_py_function, [filename, label], [tf.uint8, label.dtype])))\r\ndataset = dataset.map(_resize_function)\r\n```\r\n\r\n### Correct links\r\n\r\nYes\r\n\r\n### Parameters defined\r\n\r\nYes\r\n\r\n### Returns defined\r\n\r\nYes\r\n\r\n### Raises listed and defined\r\nYes\r\n\r\n### Usage example\r\n\r\nYes\r\n\r\n### Request visuals, if applicable\r\n\r\nNo, not needed\r\n\r\n### Submit a pull request?\r\n\r\nNo\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/autograph/to_code\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nInitial description could be clearer, instead of referring to another function as similar (`to_graph`), restate primary use case: \r\n* From: “Similar to to_graph, but returns Python source code as a string.”\r\n* To: “`to_code` is a low-level API that returns the AutoGraph generated Python source code as a string. This is similar to `to_graph`, which returns the TensorFlow graph, instead of Python.”\r\n\r\n### Usage example\r\n\r\nNo usage example in docs, only references to guides/example, would suggest uplifting an example from a guide to the docs for completeness (ref https://www.tensorflow.org/alpha/guide/autograph)\r\n\r\n\r\n### Submit a pull request?\r\n\r\nYes"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/autograph/set_verbosity\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nDescription could be clearer:\r\n\r\n* Reference to Abseil's logging format could be referenced rather than only to Abseil, itself (user would have to hunt through docs to see the logging output format referenced)\r\n* There's a slight misspelling in the args for `alsologtostdout`\r\n    “ it is recommended to set this value to a larges number, like 10” should be “ it is recommended to set this value to a large number, like 10”\r\n\r\n### Submit a pull request?\r\n\r\nYes.\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/LSTM\r\n\r\n*Suggestion: Where applicable, the documentation for this should be consistent with the base class [tf.keras.layers.RNN](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/RNN) and other derived classes.*\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\n 1. Use of backticks can be made more consistent and in line with the [Documentation Style - Write about code](https://www.tensorflow.org/community/contribute/docs_style#write_about_code). For example, the value \"True\" and \"False\" in the description is not surronded by backticks, as recommended by the Documentation Style guide.\r\n\r\n### Correct links\r\n\r\n 1. Link to the source code at \"python/keras/layers/recurrent_v2.py\" is incorrect. It points to https://github.com/tensorflow/tensorflow/tree/r2.0/tensorflow/python/keras/layers/recurrent_v2.py, which is a 404 page. Correct link (for master) should be https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/recurrent_v2.py.\r\n\r\n### Parameters defined\r\n\r\n 1. (As with the Clear Heading section above) Use of backticks can be made more consistent and in line with the [Documentation Style - Write about code](https://www.tensorflow.org/community/contribute/docs_style#write_about_code). For example, the value \"True\" and \"False\" in the description is not surronded by backticks, as recommended by the Documentation Style guide.\r\n\r\n 1. `__init__(...)`:\r\n    - Parameter `time_major` is not defined.\r\n    - The default value is specified within the text of some of the parameter definitions *but not all*. For example, the definition for `unroll` is:\r\n       >Boolean (default False). If True, the network will be unrolled, else a symbolic loop will be used. Unrolling can speed-up a RNN, although it tends to be more memory-intensive. Unrolling is only suitable for short sequences.  \r\n\r\n       whereas the definition for `return_state` is:  \r\n\r\n       > Boolean. Whether to return the last state in addition to the output.\r\n\r\n1. `get_dropout_mask_for_cell(...)`:\r\n    - First word of the definition of the parameters should be capitalized\r\n\r\n1. `get_initial_state(...)`:\r\n    - Parameter `inputs` is not defined.\r\n\r\n1. `reset_states(...)`:\r\n    - Parameter `states` is not defined.\r\n\r\n### Returns defined\r\n\r\nReturn value is not defined for the following:\r\n - `get_initial_state(...)`\r\n - `reset_dropout_mask()`\r\n - `reset_recurrent_dropout_mask()`\r\n - `reset_state()`\r\n\r\nFor the last three items above, perhaps it is sufficiently clear that nothing will be returned.\r\n\r\n### Raises listed and defined\r\n\r\nNo errors are defined.\r\n\r\n### Usage example\r\n\r\nNo usage examples are provided. However, the description does have links to relevant guides and tutorials as follows:\r\n\r\n - Used in the guide:\r\n    - [The Keras Functional API in TensorFlow](https://www.tensorflow.org/alpha/guide/keras/functional)  \r\n\r\n - Used in the tutorials:\r\n    - [Load text with tf.data](https://www.tensorflow.org/alpha/tutorials/load_data/text)\r\n    - [Text classification with an RNN](https://www.tensorflow.org/alpha/tutorials/text/text_classification_rnn)\r\n    - [Text generation with an RNN](https://www.tensorflow.org/alpha/tutorials/text/text_generation)\r\n\r\n### Request visuals, if applicable\r\n\r\nThere are current *no* visuals. LSTM itself might be too broad a topic to be dealt with comprehensively using visuals in this documentation page.\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue?  \r\n**No.** *(I can fix the formatting and syntax issues, but populating the missing parameter definitions is currently beyond my level 😅)*\r\n\r\n\r\n### Related Issue\r\n\r\n#26197"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "Doc link: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/image/transpose\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Usage example\r\n\r\nNo usage example is provided.\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "\r\nDoc link: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/io/extract_jpeg_shape\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Correct links\r\n\r\nLink not provided. Path is written but href is not provided.\r\n\r\n### Raises listed and defined\r\n\r\nErrors are not defined.\r\n\r\n### Usage example\r\n\r\nNo usage example is provided.\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Doc link: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/image/rot90\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Usage example\r\n\r\nNo usage example is provided.\r\n\r\n### Request visuals, if applicable\r\n\r\nNo Visuals are included. A visual example of rotation can be added although not necessary.\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "**System information**\r\n\r\nTensorFlow version: 2.0\r\nDoc Link: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/math/maximum\r\n\r\n**Describe the documentation issue**\r\n\r\n**Links**\r\npython/ops/gen_math_ops.py\r\nThe implementation of the code is in c++.\r\nHowever, the documentation references a generated python file.\r\nwhich we can't open, or can't view a representative implementation.\r\n\r\nPerhaps, we can add a representative implementation for such function.\r\n\r\n**Usage Example**\r\nNo usage example is provided.\r\n\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r1.14/api_docs/python/tf/train/experimental/enable_mixed_precision_graph_rewrite\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\n* Should better explain the graph rewrite algorithm (black/white/grey listed ops) and where to see the list of ops.\r\n* Overall language can be clearer and more precise.\r\n* Minor issues with the formatting.\r\n\r\n### Correct links\r\n\r\nLinks present are all correct.\r\n\r\n### Parameters defined\r\n\r\nBriefly explain what the value `\"dynamic\"` (the default value) for `loss_scale` does, and link to the symbol for that.\r\n\r\n### Returns defined\r\n\r\nReturn values are defined properly.\r\n\r\n### Raises listed and defined\r\n\r\nExceptions are not listed nor explained.\r\n\r\n### Usage example\r\n\r\nNo usage example, I can provide a simple code snippet.\r\n\r\nAdditionally, I want to provide a Colab notebook to demonstrate increase in speed without negative impact on accuracy (on CIFAR10 for example).\r\n\r\n### Request visuals, if applicable\r\n\r\n* Overview of mixed precision process/flow\r\n\r\n### Submit a pull request?\r\n\r\nYes, I have submitted a PR. PR is here #29249 \r\n"
  },
  {
    "labels": ["documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/dtypes/complex\r\n\r\n## Description of issue (what needs changing):\r\n### Raises listed and defined\r\nNo\r\n\r\n### Submit a pull request?\r\n#29237\r\nI will"
  },
  {
    "labels": [null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/queue/FIFOQueue\r\n\r\n## Description of issue (what needs changing):\r\n\r\nSome methods not provides raising error lists\r\n\r\n### Raises listed and defined\r\n\r\n* dequeue\r\n* dequeue_many\r\n* dequeue_up_to\r\n* enqueue\r\n* enqueue_many\r\n\r\n### Submit a pull request?\r\nI will\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/dtypes/cast\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\nthe example: \r\n```python\r\nx = tf.constant([1.8, 2.2], dtype=tf.float32)\r\ntf.cast(x, tf.int32)  # [1, 2], dtype=tf.int32\r\n```\r\nis not correct.  \r\nIt need to change ```tf.cast``` to ```tf.dtypes.cast```.\r\n\r\nthis is correct example\r\n```python\r\nx = tf.constant([1.8, 2.2], dtype=tf.float32)\r\ntf.dtypes.cast(x, tf.int32)  # [1, 2], dtype=tf.int32\r\n```\r\n\r\n### Submit a pull request?\r\n\r\nhttps://github.com/tensorflow/tensorflow/pull/29214\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Conv2D\r\n\r\n## Description of issue (what needs changing):\r\n\r\n\r\n### Correct links\r\n\r\nhttps://www.tensorflow.org/alpha/tutorials/distribute/multi_worker is incorrect. \r\nIt has 404 error.\r\n\r\n### Parameters defined\r\n\r\n**kwargs is not defined.\r\n\r\n### Raises listed and defined\r\n\r\nErrors are not defined.\r\n\r\n### Usage example\r\n\r\nNo usage example is provided.\r\n\r\n### Request visuals, if applicable\r\n\r\nNo visuals are included.\r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "in [xla doc](https://www.tensorflow.org/xla/jit#tutorial) it suggest that \r\n\r\n> /tmp/foo will contain the HLO before and after optimizations for each HLO module that's run. You can read this as-is, or you can visualize it using tensorflow/compiler/xla/tools:interactive_graphviz.\r\n\r\nbut I cannot locate this binary."
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/GRU\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/GRUCell\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/LSTM\r\nAlso including (but probably not limited to) other recurrent Keras layers.\r\n## Description of issue (what needs changing):\r\nIt seems that API docs are generated using `tf-nightly` builds (`master` branch). However, links that define source code of API endpoints lead to `tensorflow==2.0.0-alpha0` build (`r2.0` branch), however using file structure of `master` branch. It causes some 404 errors (see example below).\r\n### Clear description\r\nThis problem affects (at least) documentation of all the recurrent tf.keras.layers. For example, on [tf.keras.GRU page](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/GRU) section \"Defined in\" leads to [https://github.com/tensorflow/tensorflow/tree/**r2.0**/tensorflow/python/keras/layers/recurrent_v2.py](https://github.com/tensorflow/tensorflow/tree/r2.0/tensorflow/python/keras/layers/recurrent_v2.py). \r\nThis file does not exist in `r2.0`, but it exists in `master`: [https://github.com/tensorflow/tensorflow/tree/**master**/tensorflow/python/keras/layers/recurrent_v2.py](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/python/keras/layers/recurrent_v2.py)\r\n### Correct links\r\n**Is the link to the source code correct?**\r\nNo - see the section above for details.\r\n### Submit a pull request?\r\nI'm pretty sure that docs generation script is ok, but there's some kind of misconfiguration problem."
  },
  {
    "labels": ["documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md\r\n\r\n## Description of issue (what needs changing):\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\nNo.\r\n```\r\n1.  Using tools and libraries installed directly on your system.\r\n\r\n    Refer to the\r\n    [CPU-only developer Dockerfile](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/docker/Dockerfile.devel)\r\n    and\r\n    [GPU developer Dockerfile](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/docker/Dockerfile.devel-gpu)\r\n    for the required packages. Alternatively, use the said\r\n```\r\nThe link of 'CPU-only developer Dockerfile' and 'GPU developer Dockerfile' are 404.\r\n\r\n### Submit a pull request?\r\nI'd like to fix it.\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Sorry if I'm something miss. It's my first attempt to make an issue.\r\n\r\ncommit b211c7a\r\n\r\nIn the :\r\ntensorflow/contrib/cmake/python_modules.txt:\r\n....\r\ntensorflow/contrib/tpu\r\ntensorflow/contrib/tpu/ops   <<< line 435\r\ntensorflow/contrib/tpu/profiler\r\ntensorflow/contrib/tpu/python\r\n...\r\n\r\nBut this module is not in the directory:\r\ntensorflow/contrib/tpu\r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nI implemented the custom metric shown in this page (CatgoricalTruePositives) https://www.tensorflow.org/alpha/guide/keras/training_and_evaluation\r\n\r\nI think it is full of bugs, it has some comments saying (#TODO: fix this). Any way, here what's particularly wrong about it. The accuracy of the NN approaches 99%, yet, this metric says:\r\n\r\nbinary_true_positives: 8459.0000\r\n\r\n(as shown on the website too). If number of samples in MNIST is 50,000, then at least 45k of them should be true positives.  It is unstable. I messed with it once and I got 49k true positive (which makes total sense). Then I reran it and it returned to 8k.\r\n\r\n**Describe the expected behavior**\r\nThe results are shown on the website. For a low loss of 0.03, the true positives should be close to 50k. However they're shown to be 8k only.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nSome operations, like `Assign`, use a `Ref` keyword for their input and/or output. (example: tensorflow/core/ops/state_ops.cc). This keyword is not documented anywhere.\r\n\r\nAdditionally, I haven't found any way to combine `Ref` with `list` (i.e. make an operation take a list of mutable tensors as input).\r\n"
  },
  {
    "labels": [null, null, null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/GradientTape?hl=en#gradient\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nActually there is no way to know what does the gradient method when target is not a tensor but a list of tensors, like `target=[loss_1, loss_2]`. Does it compute the sum of the gradients of `loss_1` and `loss_2` ? It seems like no, from some tests I did. What does it do then ?\r\n\r\nI tried to follow the source code, without success. GradientTape.gradient calls tensorflow.python.eager.imperative_grad.imperative_grad, which calls tensorflow.python.pywrap_tensorflow.TFE_Py_TapeGradient, which is a C++ function calling ComputeGradient. But I couldn't find the code of ComputeGradient. I just found it mentioned in tensorflow/c/eager/tape.h. But I don't find tape.cc.\r\n\r\n\r\n### Usage example\r\n\r\nThere is no usage example for this case."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 0.0.1-gpu-experimental\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n**Describe the current behavior**\r\n\r\nThe [mobilenet v1 1.0](https://storage.googleapis.com/download.tensorflow.org/models/tflite/gpu/mobilenet_v1_1.0_224.tflite) model in the [guide](https://www.tensorflow.org/lite/performance/gpu) contains a squeeze operation that isn't supported by GPU, but the [mobilenet v1 1.0](http://download.tensorflow.org/models/mobilenet_v1_2018_08_02/mobilenet_v1_1.0_224.tgz) at  [tensorflow/models](https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.md) does. AFAIK, squeeze isn't a supported operation, but both of them contain at least one. How come the operations are different even when the models are of the same version? Is the one in the guide deliberately modified? If so, would it be a better idea to have it noted in the guide? The page on tensor/models claims 569mil MACs, but the number of MACs this modified 1.0 has is unclear.\r\n\r\nWhat I've found is that the one provided in the guide contains 89 tensors but the one in tensorflow/models 88.\r\n\r\n**Describe the expected behavior**\r\n\r\nModels of the same version should be identical. Any modification should be explicitly documented."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "At the beginning of sub title [Train from tf.data datasets](https://www.tensorflow.org/alpha/guide/keras/overview#train_from_tfdata_datasets), there is a super link pointing to **Datasets API**.\r\n\r\nBut when you click it out, only 404 page is what you get.\r\n\r\nSince this API is very often been used, it would be better to correct this as soon as possible."
  },
  {
    "labels": ["documentation"],
    "text": "JavaScript on the website runs some sort of detection to see if there is network connectivity or tries to establish a connection in a surprising way.\r\n\r\nThis fails and I get a message \"There is no Internet connection :(\" which is clearly wrong. I am writing this issue with the same internet connection.\r\n\r\nThe JS console says:\r\n\r\n    Failed to load ‘https://www.google-analytics.com/analytics.js’. A ServiceWorker passed a promise to FetchEvent.respondWith() that rejected with ‘TypeError: NetworkError when attempting to fetch resource.’.\r\n\r\n    Failed to load ‘https://www.tensorflow.org/_d/profile/ogb’. A ServiceWorker passed a promise to FetchEvent.respondWith() that rejected with ‘TypeError: NetworkError when attempting to fetch resource.’.\r\n\r\n    Failed to load ‘https://www.tensorflow.org/_d/profile/user’. A ServiceWorker passed a promise to FetchEvent.respondWith() that rejected with ‘TypeError: NetworkError when attempting to fetch resource.’.\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "I dont like java and swift.\r\nI prefer c++.\r\nHowever, I seldom see any c++ api helps."
  },
  {
    "labels": [null, "documentation", null],
    "text": "We've translated this part of guidelines to Korean on our repository with github pages.\r\n\r\nThis is URL of Korean repository : https://github.com/BangSeongJin/translation_to_korean.git"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue: https://www.tensorflow.org/guide/distribute_strategy#using_tfdistributestrategy_with_custom_training_loops\r\n\r\n## Description of issue (what needs changing):\r\nIn the documentation the snippet:\r\n\r\n```python\r\ndef train_step():\r\n  def step_fn(inputs):\r\n    features, labels = inputs\r\n    logits = model(features)\r\n    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\r\n        logits=logits, labels=labels)  \r\n    loss = tf.reduce_sum(cross_entropy) * (1.0 / global_batch_size)\r\n    train_op = optimizer.minimize(loss)\r\n    with tf.control_dependencies([train_op]):\r\n      return tf.identity(loss)\r\n\r\n  per_replica_losses = mirrored_strategy.experimental_run(\r\n      step_fn, input_iterator)\r\n  mean_loss = mirrored_strategy.reduce(\r\n      tf.distribute.ReduceOp.MEAN, per_replica_losses)\r\n  return mean_loss\r\n```\r\ncalculates the loss using the distribution strategy. However the loss for each replica is reduced using `tf.distribute.ReduceOp.MEAN`. I think that the correct loss to return is the loss reduced using `tf.distribute.ReduceOp.SUM` since every loss is already reduced using the partial mean over the `global_batch_size` (` tf.reduce_sum(cross_entropy) * (1.0 / global_batch_size)`) . \r\n\r\nI think a better snippet would be:\r\n\r\n```python\r\ndef train_step():\r\n  def step_fn(inputs):\r\n    features, labels = inputs\r\n    logits = model(features)\r\n    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\r\n        logits=logits, labels=labels)  \r\n    loss = tf.reduce_sum(cross_entropy) * (1.0 / global_batch_size)\r\n    train_op = optimizer.minimize(loss)\r\n    with tf.control_dependencies([train_op]):\r\n      return tf.identity(loss)\r\n\r\n  per_replica_losses = mirrored_strategy.experimental_run(\r\n      step_fn, input_iterator)\r\n  loss = mirrored_strategy.reduce(\r\n      tf.distribute.ReduceOp.SUM, per_replica_losses)\r\n  return loss\r\n```\r\n\r\nAm I wrong?\r\n\r\n### Submit a pull request?\r\n\r\nMaybe I can submit a pull request to fix this.\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.py#L849\r\n\r\n## Description of issue (what needs changing):\r\n\r\nLink is broken. Why is it deprecated? What should I do about it?"
  },
  {
    "labels": ["documentation", null],
    "text": "\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/tutorials/keras/basic_regression\r\n#### Description of issue (what needs changing): https://www.tensorflow.org/tutorials/keras/basic_regression#build_the_model\r\n\r\n### Clear description\r\n\r\nThe `model = build_model()` function results in a `TypeError` and gives the following trace:\r\n```\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-19-671884cecb64> in <module>\r\n----> 1 model = build_model()\r\n\r\n<ipython-input-18-d3556ed39f80> in build_model()\r\n      3     layers.Dense(64, activation=tf.nn.relu, input_shape=[64]),\r\n      4     layers.Dense(64, activation=tf.nn.relu),\r\n----> 5     layers.Dense(1)\r\n      6   ])\r\n      7 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/keras/engine/sequential.py in __init__(self, layers, name)\r\n     91         if layers:\r\n     92             for layer in layers:\r\n---> 93                 self.add(layer)\r\n     94 \r\n     95     @property\r\n\r\n~/anaconda3/lib/python3.7/site-packages/keras/engine/sequential.py in add(self, layer)\r\n    130             raise TypeError('The added layer must be '\r\n    131                             'an instance of class Layer. '\r\n--> 132                             'Found: ' + str(layer))\r\n    133         self.built = False\r\n    134         if not self._layers:\r\n\r\nTypeError: The added layer must be an instance of class Layer. Found: <tensorflow.python.keras.layers.core.Dense object at 0x7efe86908f28>\r\n\r\n\r\n```\r\n\r\n\r\n\r\n\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly? <br>\r\nYes. This method does not use any parameters apart from `train_dataset` which has been replaced with a constant in my above example.\r\n\r\n\r\n\r\n### Raises listed and defined\r\n\r\nThis raises a TypeError.\r\n\r\n\r\n\r\n\r\n\r\n\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "Is there any limit in label map classes used in the training config file?"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe Example for \"from_generator\" fails.\r\n\r\n### Clear description\r\n\r\nThis example uses tf.enable_eager_execution() which gives the following error\r\nAttributeError: module 'tensorflow' has no attribute 'enable_eager_execution'\r\n\r\nIf you remove this line of code the example runs but identifies this code is deprecated in TF V2.\r\n\r\n### Correct links\r\n\r\nI do not see a link to the source.\r\n\r\n### Parameters defined\r\n\r\nThe parameters are defined but the example only uses three of the four parameters.  The last parameter is optional but not shown how to be used.\r\n\r\n### Returns defined\r\n\r\nThe return code is defined correctly as a dataset.\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nThere is a usage example.  This PR is regarding the example.\r\n\r\n### Request visuals, if applicable\r\n\r\nThere are not example.\r\n\r\n### Submit a pull request?\r\nyes\r\nhttps://github.com/tensorflow/tensorflow/pull/28842\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\nyes\r\nhttps://github.com/tensorflow/tensorflow/pull/28842\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nTensorFlow version: Tensorflow 2.0 alpha\r\nDoc Link: Using TFRecords and tf.Example https://www.tensorflow.org/alpha/tutorials/load_data/tf_records\r\nWindows 10 LTSC x64 Python3.6 Cuda 10.0 Cudnn 7.5\r\n\r\n## Description of issue (what needs changing):\r\n\r\nIf I run the example code, I will have an error in the cell:\r\ntf_serialize_example(f0,f1,f2,f3)\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\n`UnknownError           Traceback (most recent call last)\r\n<ipython-input-21-406ee79a7f52> in <module>\r\n----> 1 tf_serialize_example(f0,f1,f2,f3)\r\n\r\n<ipython-input-20-3f3d0d83f6b2> in tf_serialize_example(f0, f1, f2, f3)\r\n      3     serialize_example,\r\n      4     (f0,f1,f2,f3),  # pass these args to the above function.\r\n----> 5     tf.string)      # the return type is `tf.string`.\r\n      6   return tf.reshape(tf_string, ()) # The result is a scalar\r\n\r\nF:\\Anaconda3\\envs\\TF2\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py in eager_py_func(func, inp, Tout, name)\r\n    387     if `func` returns None.\r\n    388   \"\"\"\r\n--> 389   return _internal_py_func(func=func, inp=inp, Tout=Tout, eager=True, name=name)\r\n    390 \r\n    391 \r\n\r\nF:\\Anaconda3\\envs\\TF2\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py in _internal_py_func(func, inp, Tout, stateful, eager, is_grad_func, name)\r\n    276   if eager:\r\n    277     result = gen_script_ops.eager_py_func(\r\n--> 278         input=inp, token=token, Tout=Tout, name=name)\r\n    279   else:\r\n    280     if stateful:\r\n\r\nF:\\Anaconda3\\envs\\TF2\\lib\\site-packages\\tensorflow\\python\\ops\\gen_script_ops.py in eager_py_func(input, token, Tout, name)\r\n     64       else:\r\n     65         message = e.message\r\n---> 66       _six.raise_from(_core._status_to_exception(e.code, message), None)\r\n     67   # Add nodes to the TensorFlow graph.\r\n     68   token = _execute.make_str(token, \"token\")\r\n\r\nF:\\Anaconda3\\envs\\TF2\\lib\\site-packages\\six.py in raise_from(value, from_value)\r\n\r\nUnknownError: RuntimeError: Error copying tensor to device: CPU:0. Can't copy 35 bytes of a tensor into another with 32 bytes buffer.\r\nTraceback (most recent call last):\r\n\r\n  File \"F:\\Anaconda3\\envs\\TF2\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 205, in __call__\r\n    return func(device, token, args)\r\n\r\n  File \"F:\\Anaconda3\\envs\\TF2\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 107, in __call__\r\n    ret = self._func(*args)\r\n\r\n  File \"<ipython-input-5-a40a581f0687>\", line 10, in serialize_example\r\n    'feature2': _bytes_feature(feature2),\r\n\r\n  File \"<ipython-input-1-0ab605f55efd>\", line 8, in _bytes_feature\r\n    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\r\n\r\n  File \"F:\\Anaconda3\\envs\\TF2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 732, in numpy\r\n    return self._cpu_nograd()._numpy()  # pylint: disable=protected-access\r\n\r\n  File \"F:\\Anaconda3\\envs\\TF2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 899, in _cpu_nograd\r\n    return self._copy_nograd(context.context(), \"CPU:0\")\r\n\r\n  File \"F:\\Anaconda3\\envs\\TF2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 847, in _copy_nograd\r\n    new_tensor = self._copy_to_device(context=ctx._handle, device=device_name)\r\n\r\nRuntimeError: Error copying tensor to device: CPU:0. Can't copy 35 bytes of a tensor into another with 32 bytes buffer.\r\n\r\n [Op:EagerPyFunc]\r\n`\r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/tutorials/sequences/text_generation\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\n* Two questions regarding the `stateful` defined in the tutorial. \r\n* The input data was originally a long text. It got cut into sequences with length 100, shuffled, and packed into batches of size 64. However, according to the [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN) for the `statefulness`\r\n> You can set RNN layers to be 'stateful', which means that the states\r\ncomputed for the samples in one batch will be reused as initial states\r\nfor the samples in the next batch. This assumes a one-to-one mapping\r\nbetween samples in different successive batches.\r\n\r\nAfter pre-processing the data as discussed above, there is no such one-to-one mapping is not there, i.e. the samples in different batches are independent instead of related. This is confirmed by running the following code after the code for create training batches, which print out the successive samples with index `0` in the first two batches. \r\n```Python\r\nfor input_example, target_example in  dataset.take(2):\r\n  print ('Input data: ', repr(''.join(idx2char[input_example[0, :].numpy()])))\r\n```\r\noutputs\r\n```Python\r\nInput data:  'n that perished vessel the dowry of his\\nsister. But mark how heavily this befell to the\\npoor gentlew'\r\nInput data:  \"y enrich'd\\nWith politic grave counsel; then the king\\nHad virtuous uncles to protect his grace.\\n\\nFirs\"\r\n```\r\n---\r\n* In addition, if `stateful=True`, it is suggested to set `shuffle=False` in the `model.fit()`, which is also missing in the tutorial. \r\n> specify `shuffle=False` when calling fit().\r\n\r\n* The problems above are really confusing and any discussions are welcome. "
  },
  {
    "labels": [null, null, "documentation"],
    "text": "**Describe the current behavior**\r\n`losses.Reduction.SUM_BY_NONZERO_WEIGHTS` calculates the mean, not the sum. (The behavior is in sync with the [docs](https://www.tensorflow.org/api_docs/python/tf/losses/Reduction).)\r\n**Describe the expected behavior**\r\nI would expect `losses.Reduction.SUM_BY_NONZERO_WEIGHTS` to calculate the sum, not the mean.\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "I found that voice activity detection is implemented in the paper \"Small-Footprint Keyword Spotting Using Deep Neural Networks\". But I did not find anything related to voice activity detection in the paper \"Convolutional Neural Networks for Small-footprint Keyword Spotting\".\r\nMy question is that is voice activity detection implemented in this code or not?\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/alpha/tutorials/images/transfer_learning\r\n\r\n## Description of issue (what needs changing):\r\nclassification head should use sigmoid activation.\r\n### Clear description\r\nThe tutorial has this paragraph:\r\n\r\nYou don't need an activation function here because this prediction will be treated as a logit, or a raw prediciton value. Positive numbers predict class 1, negative numbers predict class 0.\r\n\r\nI think we need sigmoid activation. \r\nLater we use loss=\"binary_crossentropy\" in model.compile. binary_crossentropy by default has from_logits=False and expect a probability as is documented [here ](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/losses/BinaryCrossentropy) and [here](https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy)\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "When using the search bar in the [API docs](https://www.tensorflow.org/versions/r1.13/api_docs/python/tf) with a version in the URL, any search will include pages from different API versions, which means you often end up in the wrong module and have to click on the correct version _again_.\r\n\r\n## How to reproduce\r\n\r\n- Go to: https://www.tensorflow.org/versions/r1.13/api_docs/python/tf\r\n- Type in 'unsorted_segment_' and wait for the results to appear (see image)\r\n- Choose the top 'Pages' result\r\n- You're now in the 1.9 API rather than 1.13. \r\n\r\n<img width=\"394\" alt=\"Screenshot 2019-05-14 at 16 13 38\" src=\"https://user-images.githubusercontent.com/49023008/57705141-8d8a4600-7663-11e9-8640-5a3fdde51ae8.png\">"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/gan/python/losses/python/losses_impl.py#L468\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/gan/python/losses/python/losses_impl.py#L477\r\n\r\n## Description of issue (what needs changing):\r\n\r\nOne line 468:     `# -log((1 - label_smoothing) - sigmoid(D(x)))`\r\n\r\nShouldn't it be `-(1-label_smoothing) * log(sigmoid(D(x))` ?\r\nI'm uncertain about the label_smoothing part, but I think the argument of the `log` is wrong.\r\n\r\nOn line 477: `# -log(- sigmoid(D(G(x))))`\r\nShouldn't it be `-log(1-sigmoid(D(G(x))`?"
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.2 LTS\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: latest tf-nightly-2.0-preview\r\n- Python version: Python 3.6.7\r\n- Installed using virtualenv? pip? conda?: pip\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nOfficial colab link for tensorboard 2.0 demo is able to reproduce the bug:\r\n\r\nhttps://colab.research.google.com/github/tensorflow/tensorboard/blob/master/docs/r2/get_started.ipynb\r\n\r\n```\r\n$ pip install -q tf-nightly-2.0-preview\r\n\r\nERROR: thinc 6.12.1 has requirement wrapt<1.11.0,>=1.10.0, but you'll have wrapt 1.11.1 which is incompatible.\r\n```"
  },
  {
    "labels": [null, "documentation"],
    "text": "\r\n## Existing URL(s) with the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf\r\n\r\n## Description of issue (what needs changing):\r\n\r\nCopyable code block has extra characters `\",` at the end:\r\n\r\n```pip install tensorflow==2.0.0-alpha0\",```\r\n\r\n### Clear description\r\n\r\nCopyable code block should be changed to the following to make copying easier.\r\n\r\n```pip install tensorflow==2.0.0-alpha0```\r\n\r\n### Correct links\r\n\r\nThis is the overview for the TF 2.0 API, but I couldn't find the docstring in the referred source: https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/__init__.py\r\n\r\n### Submit a pull request?\r\n\r\nWould love to, but couldn't find in source where this was a docstring or being generated :(\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "In colab, use the following commands to reproduce:\r\n\r\n```\r\n!pip uninstall tensorflow -yq && pip install tf-nightly-gpu==1.14.1.dev20190510 -q\r\nimport tensorflow as tf\r\ntf.version.GIT_VERSION\r\n```\r\n\r\nWhich shows ``v1.12.1-1705-g978532afa9`` (last hex is not any git commit btw)\r\n\r\nShouldn't it be the git version used to build that package instead?\r\n\r\nGentle ping @gunan and @yifeif "
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/alpha/tutorials/text/transformer\r\n## Description of issue (what needs changing):\r\nformat and normalization layer.\r\n\r\n### Clear description\r\n1. when describe the multi-head attention, there is this text in one line:  \"Multi-head attention consists of four parts: * Linear layers and split into heads. * Scaled dot-product attention. * Concatenation of heads. * Final linear layer. \"\r\n  I guess the * mean bullet items. It is not formatted correctly.\r\n2. The EncoderLayer and DecoderLayer use LayerNormalization. There is no LayerNormalization in keras.layers. There is only BatchNormalization.\r\n3. Evaluate step creates mask. No mask is needed since a) there is no padding for a single sentence. b) there is no look_ahead since we are trying to predict next words. \r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "\r\n\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/tutorials/next_steps\r\n\r\n## Description of the issue (what needs changing):\r\nThis page is not opening\r\n\r\n### Clear description\r\n\r\nLink is getting 404\r\n\r\n\r\n\r\n### Request visuals, if applicable\r\n\r\n![404     Page Not Found     TensorFlow](https://user-images.githubusercontent.com/1620769/57435595-65fa3e80-725b-11e9-81da-8394e7147ca7.png)\r\n\r\n\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/guide/keras#multiple_gpus\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe last line of this guide produces a bug when ran on the associated colab notebook (maybe everywhere, I haven't checked).\r\n\r\n### Raises listed and defined\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1333     try:\r\n-> 1334       return fn(*args)\r\n   1335     except errors.OpError as e:\r\n\r\n19 frames\r\nInvalidArgumentError: No OpKernel was registered to support Op 'NcclAllReduce' used by {{node training/TFOptimizer/NcclAllReduce}}with these attrs: [reduction=\"sum\", shared_name=\"c0\", T=DT_FLOAT, num_devices=1]\r\nRegistered devices: [CPU, GPU, XLA_CPU, XLA_GPU]\r\nRegistered kernels:\r\n  <no registered kernels>\r\n\r\n\t [[{{node training/TFOptimizer/NcclAllReduce}}]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1346           pass\r\n   1347       message = error_interpolation.interpolate(message, self._graph)\r\n-> 1348       raise type(e)(node_def, op, message)\r\n   1349 \r\n   1350   def _extend_graph(self):\r\n\r\nInvalidArgumentError: No OpKernel was registered to support Op 'NcclAllReduce' used by node training/TFOptimizer/NcclAllReduce (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py:1254) with these attrs: [reduction=\"sum\", shared_name=\"c0\", T=DT_FLOAT, num_devices=1]\r\nRegistered devices: [CPU, GPU, XLA_CPU, XLA_GPU]\r\nRegistered kernels:\r\n  <no registered kernels>\r\n```\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nNo, I'm only beginning in TF/Keras :) "
  },
  {
    "labels": ["documentation"],
    "text": "## URL(s) with the issue:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/go/doc.go\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe link doesn't work. It strips the trailing `.md` off the URL when it is redirected through `tensorflow.org/code`\r\n\r\n\r\n### Correct links\r\n\r\nit is correct, I think the redirect is broken. for example, if you change \r\n`https://www.tensorflow.org/code/tensorflow/go/README.md` \r\nto\r\n`https://www.tensorflow.org/code/tensorflow/go/README.md.md` \r\n\r\nit works.\r\n\r\n### Parameters defined\r\n\r\nNA\r\n\r\n### Returns defined\r\n\r\nNA\r\n\r\n### Raises listed and defined\r\n\r\nNA\r\n### Usage example\r\n\r\nNA\r\n\r\n### Request visuals, if applicable\r\n\r\nNA\r\n\r\n### Submit a pull request?\r\n\r\ni don't think a PR is the solution here. if there is a better URL tho i'm happy to submit a PR.\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "[Current Dockerfile](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dockerfiles/dockerfiles/gpu.Dockerfile#L22) we have is based out of 16.04, its better if we can move to 18.04.\r\n\r\nThe corresponding version of TF Serving is already using 18.04 based ubuntu in their Dockerfile."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "## Existing URLs containing the issue:\r\nhttps://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#3\r\n\r\n## Description of issue (what needs changing):\r\nTypo\r\n\r\n### Clear Description\r\n```\r\nMobileNet is a a small efficient convolutional neural network.\r\n```\r\nshould be\r\n```\r\nMobileNet is a small efficient convolutional neural network.\r\n```\r\n\r\n### Submit PR?\r\nI couldn't find the source for this codelab to fix the error. Is this tutorial obsolete or has it been updated for TensorFlow 2.0?\r\n\r\nThe issue has also been reported [here](https://github.com/googlecodelabs/tensorflow-for-poets-2/issues/67)."
  },
  {
    "labels": [null, "documentation"],
    "text": "There is some problem in loading images \r\n\r\nfor n in range(3):\r\n  image_path = random.choice(all_image_paths)\r\n  display.display(display.Image(image_path))\r\n  print(caption_image(image_path))\r\n  print()\r\n\r\nError:\r\n---------------------------------------------------------------------------\r\nKeyError                                  Traceback (most recent call last)\r\n<ipython-input-9-dd286b0cbeda> in <module>\r\n      2   image_path = random.choice(all_image_paths)\r\n      3   display.display(display.Image(image_path))\r\n----> 4   print(caption_image(image_path))\r\n      5   print()\r\n\r\n<ipython-input-8-a5b6e935786e> in caption_image(image_path)\r\n      3 def caption_image(image_path):\r\n      4     image_rel = pathlib.Path(image_path).relative_to(data_root)\r\n----> 5     return \"Image (CC BY 2.0) \" + ' - '.join(attributions[str(image_rel)].split(' - ')[:-1])\r\n      6 \r\n\r\nKeyError: 'daisy\\\\3764116502_f394428ee0_n.jpg'\r\n\r\nPlease what is the problem?\r\n\r\n\r\n<em>Thanks so much for taking the time to file a documentation issue and even\r\nmore thanks if you intend to contribute to updating it! Please do introduce\r\nyourself on our mailing list with\r\n[Google Groups](https://groups.google.com/a/tensorflow.org/forum/#!forum/docs)\r\nor [email](mailto:docs@tensorflow.org) and let us know if you have any\r\nquestions. We also encourage you to review our\r\n[Documentation Contributor Guide](https://www.tensorflow.org/community/contribute/docs).\r\nAs a side note, per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:doc_template</em>\r\n\r\n## Existing URLs containing the issue:\r\n\r\nLink to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Correct Links\r\n\r\nIs the link pointing to the source code correct? To find the source code, use\r\n`git grep my_method` from the git command line in your locally checked out\r\nrepository.\r\n\r\n### Clear Description\r\n\r\nWhy should someone use this method? How is it useful?\r\n\r\n### Usage Example\r\n\r\nIs there a usage example?\r\n\r\n### Parameters Defined\r\n\r\nAre all arguments that can be passed in defined and formatted correctly?\r\n\r\n### Returns Defined\r\n\r\nAre return values defined?\r\n\r\n### Raises Listed and Defined\r\n\r\nAre errors defined?\r\n[Example](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises)\r\n\r\n### Request Visuals, if Applicable\r\n\r\nAre there currently visuals? If not, would they make the content clearer?\r\n\r\n### Submit PR?\r\n\r\nAre you planning to also submit a\r\n[Pull Request](https://help.github.com/en/articles/about-pull-requests) to fix\r\nthis issue? See the\r\n[Documentation Contributor Guide](https://www.tensorflow.org/community/contribute/docs)\r\nthe\r\n[Documentation Style Guide](https://www.tensorflow.org/community/contribute/docs_style).\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "## Existing URLs containing the issue:\r\n\r\nhttps://www.tensorflow.org/lite/guide/ops_compatibility\r\n\r\n## Description of issue (what needs changing):\r\n\r\nTensorFlow `r1.13`.\r\n\r\n`CONV_2D_TRANSPOSE` op is not present in TensorFlow Lite schema.\r\nAfter glimpsed `toco` source code,  `tf.nn.conv2d_transpose`(`Conv2DBackpropInput`) is converted to `TRANSPOSE_CONV`.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/lite/toco/import_tensorflow.cc#L1778 \r\n\r\nSo updating tflite documentation(replace `CONV_2D_TRANSPOSE` with `TRANSPOSE_CONV`  ) would be nice.\r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):mac\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip install\r\n- TensorFlow version (use command below):2.0 alpha\r\n- Python version:3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\ndataset in tf2.0 lack of key properties and methods which already in tf1.13, for example:\r\nproperties: output_shapes, output_types\r\nmethods: make_one_shot_iterator\r\n\r\n**Describe the expected behavior**\r\nthese key properties and methods should in dataset of tf2.0\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version:\r\n2.0\r\n- Doc Link:\r\nhttps://www.tensorflow.org/alpha/tutorials/text/nmt_with_attention\r\n\r\n**Describe the documentation issue**\r\n\r\n1. max_length function is not needed. The keras.preprocessing.sequence.pad_sequences already pad the sequence to max length. One can just get max length by input_seqs.shape[1]\r\n2. need to explain why we skip 0 for \"convert\" and \"loss_function\". I think it is because of padding\r\n3. Validation set is not used.  This could be an good example to explain how we evaluate the model.\r\n4.  GRU unit in encoder,  Dense in Attention weight calculation,  GRU unit in decoder all have the same units parameter. This is not necessary.  A note could be added to explain that same unit is used for convenience.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n\r\nYes\r\n\r\n"
  },
  {
    "labels": ["documentation", null],
    "text": "It is unclear whether this is a documentation or a programming issue. If misfiled, please say so and suggest whether a new issue should be raised, or what else can be done.\r\n\r\n**System information**\r\n- TensorFlow version:\r\n ('v1.13.1-0-g6612da8951', '1.13.1') (see #27538)\r\n('v1.12.0-9492-g2c319fb415', '2.0.0-alpha0') (see #27539) and\r\ntf-nightly-2.0-preview (see https://stackoverflow.com/questions/55682557/)\r\n\r\n- Doc Link:\r\nhttps://www.tensorflow.org/hub/tutorials/image_retraining and\r\nhttps://www.tensorflow.org/tutorials/images/hub_with_keras\r\n\r\n**Describe the documentation issue**\r\nBoth documents mention but do not describe conversion to mobile models. Yet, conversion using `tensorflowjs_converter` failed in every attempt. See https://stackoverflow.com/questions/55849309/retrain-image-detection-with-mobilenet, which mentions two attempts by me as well as questions by others with the same problem.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n\r\nAs soon as it is working, I would gladly fix and/or augment the docs.  I have not gotten **`tensorflowjs_converter`** to **work on a retrained MobileNet model**, despite the docs stating that it should work, [e.g.](https://www.tensorflow.org/tutorials/images/hub_with_keras#export_your_model):\r\n\r\n> This saved model can loaded for inference later, or converted to TFLite or TFjs."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: TensorFlow Core 1.13\r\n- Doc Link: https://www.tensorflow.org/api_docs/python/tf/test\r\n\r\n\r\n**Describe the documentation issue**\r\nThe link pointing to the testing guide is broken. \r\nbroken link -  [https://tensorflow.org/api_guides/python/test](https://tensorflow.org/api_guides/python/test)\r\n\r\n[A snapshot of the broken link, working as of 22nd Feb 2019](https://web.archive.org/web/20190222060703/https://tensorflow.org/api_guides/python/test)\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "### Existing URLs containing the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/image/extract_image_patches\r\n\r\n### Description of issue (what needs changing):\r\n\r\n- #### Clear Description\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Only a single sentence description is provided.\r\n\r\n- #### Usage Example\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;No usage example is provided.\r\n\r\n- #### Raises Listed and Defined\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Errors are not defined.\r\n\r\n- #### Visuals, if Applicable\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;No visuals are included.\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "JavaScript on the website runs some sort of detection to see if there is network connectivity or tries to establish a connection in a surprising way.\r\n\r\nThis fails and I get a message \"There is no Internet connection :(\" which is clearly wrong. I am writing this issue with the same internet connection."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- Linux edh-VirtualBox 4.18.0-17-generic #18~18.04.1-Ubuntu SMP Fri Mar 15 15:27:12 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux\r\n- TensorFlow installed from (source or binary): Git\r\n- TensorFlow version: 1.13.1\r\n- Python version:Python 2.7.15rc1\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): No\r\n- GCC/Compiler version (if compiling from source): gcc version 7.3.0 (Ubuntu 7.3.0-27ubuntu1~18.04)\r\n- CUDA/cuDNN version: No\r\n- GPU model and memory: No\r\n\r\n\r\n\r\n**Describe the problem**\r\nThe following command described in the **README** located in **tensorflow\\lite\\experimental\\micro\\examples\\micro_speech** loops for ever:\r\n_make -f tensorflow/lite/experimental/micro/tools/make/Makefile test_micro_speech_\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nI have followed the sequence described in the README:\r\n\r\n1. make -f tensorflow/lite/experimental/micro/tools/make/Makefile\r\n2. make -f tensorflow/lite/experimental/micro/tools/make/Makefile test_micro_speech\r\n\r\n\r\n**Any other info / logs**\r\n\r\nThe reason is a \"`while true`\" in the source **micro_speech**\r\n\r\nbut the makefile should run micro_speech_test instead, so i think that the issue is in the makefile but i don't understant this makefile.\r\n\r\n`.tensorflow/lite/experimental/micro/testing/test_linux_binary.sh tensorflow/lite/experimental/micro/tools/make/gen/linux_x86_64/bin/micro_speech '~~~ALL TESTS PASSED~~~'`\r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "I try this tutorial: [Hyperparameter Tuning with the HParams Dashboard](https://www.tensorflow.org/tensorboard/r2/hyperparameter_tuning_with_hparams) and it seems to not be up to date.\r\n\r\nMy setup:\r\n\r\n- Jupyterlab: '0.33.12'\r\n- ipython: '7.2.0'\r\n- python: '3.6.7'\r\n- tensorflow: '2.0.0-dev20190426'\r\n\r\nI have a problem with the line `tf.summary.scalar('accuracy', accuracy, step=1, description=\"The accuracy\")`\r\n\r\nI'm getting this error and I do not know how to handle it.\r\n\r\n```\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-27-1053baffc567> in <module>\r\n      8             print(hparams)\r\n      9             run_name = \"run-%d\" % session_num\r\n---> 10             run(\"logs/hparam_tuning/\" + run_name, hparams)\r\n     11             session_num += 1\r\n\r\n<ipython-input-26-1dc9836089ce> in run(run_dir, hparams)\r\n      7         summary_end = hparams_summary.session_end_pb(api_pb2.STATUS_SUCCESS)\r\n      8 \r\n----> 9         tf.summary.scalar('accuracy', accuracy, step=1, description=\"The accuracy\")\r\n     10         tf.summary.experimental.write_raw_pb(summary_start.SerializeToString(), step=1)\r\n     11         tf.summary.experimental.write_raw_pb(summary_end.SerializeToString(), step=1)\r\n\r\n~/hugoenv/lib/python3.6/site-packages/tensorboard/plugins/scalar/summary_v2.py in scalar(name, data, step, description)\r\n     53   summary_metadata = metadata.create_summary_metadata(\r\n     54       display_name=None, description=description)\r\n---> 55   with tf.summary.summary_scope(\r\n     56       name, 'scalar_summary', values=[data, step]) as (tag, _):\r\n     57     tf.debugging.assert_scalar(data)\r\n\r\nAttributeError: module 'tensorboard.summary._tf.summary' has no attribute 'summary_scope'\r\n```"
  },
  {
    "labels": [null, null, null, null, "documentation"],
    "text": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): \r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64 1809\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): unknown 2.0.0-dev20190428\r\n- Python version: 3.6.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: CUDA 10.0, cudnn-10.0-windows10-x64-v7.5.0.56\r\n- GPU model and memory: GeForce GTX 1070 8GB\r\n\r\n**Describe the current behavior**\r\nUsing tf.py_function which has tf.string type input generates warning like this:\r\n\r\n> W0429 14:24:18.965364 13252 backprop.py:820] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\r\n\r\nThis warning did not shown with v1.12.0-9492-g2c319fb415 2.0.0-alpha0, but 2.0.0-dev20190428 does.\r\n\r\n**Describe the expected behavior**\r\ndtype warning should not be shown.\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\n\r\n\r\ndef transform_tag_python(x):\r\n    return 1.0\r\n\r\n\r\ndataset = tf.data.Dataset.from_tensor_slices(['tag1'])\r\ndataset = dataset.map(lambda x: tf.py_function(\r\n    transform_tag_python, (x,), (tf.float32,)))\r\n\r\nfor sample in dataset:\r\n    print(sample)\r\n```"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "API Doc update for https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/audio/encode_wav\r\n\r\nCorrect links? No\r\nClear Description? No\r\nUsage Example?\r\nParameters Defined? Yes, not verified against current code\r\nReturns defined? Yes, not verified against current code\r\nRaises listed and defined? No\r\nVisuals, if applicable? No\r\n\r\nI will submit a PR, please assign this bug to me.\r\n\r\nPart of Issue #28237 & Issue #28236 "
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "API doc update for https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/audio/decode_wav\r\n\r\nCorrect links? No\r\nClear Description? No\r\nUsage Example?\r\nParameters Defined? Yes, not verified against current code\r\nReturns defined? Yes, not verified against current code\r\nRaises listed and defined? No\r\nVisuals, if applicable? No\r\n\r\nI will submit a PR, please assign this bug to me.\r\n\r\n\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "Docs update for https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/audio\r\n\r\nNeeds high level description & usage example\r\n\r\nI plan to submit a PR for this issue, please assign to me"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip install tensorflow-gpu==2.0.0-alpha0\r\n- TensorFlow version (use command below): 2.0.0-alpha0\r\n- Python version: 3.7.3\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: GeForce GTX 1080 Ti, 11175MiB\r\n\r\n**Describe the current behavior**\r\nIn TF-GPU 2.0 \r\n\r\n**Describe the expected behavior**\r\nEither have a `tf.keras.layers.CuDNNLSTM` or remove the warning.\r\n\r\n**Code to reproduce the issue**\r\nThis to raise the warning\r\n\r\n    import tensorflow as tf\r\n    import tensorflow.keras.layers as ll\r\n    input_ = ll.Input((100,50))\r\n    x = ll.LSTM(100)(input_)\r\n\r\nThis to try to use CuDNNLSTM \r\n\r\n    import tensorflow as tf\r\n    import tensorflow.keras.layers as ll\r\n    input_ = ll.Input((100,50))\r\n    x = tf.keras.layers.CuDNNLSTM(100)(input_)\r\n\r\n**Other info / logs**\r\n\r\nThe warning message:\r\n\r\n    W0428 17:18:46.256715 140569873639168 tf_logging.py:161] <tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7fd8c75a9940>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\r\n\r\nWhen trying to call CuDNNLSTM:\r\n\r\n    AttributeError: module 'tensorflow.keras.layers' has no attribute 'CuDNNLSTM'"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Is there any detailed documentation for C APIs besides  [version example](https://www.tensorflow.org/install/lang_c#build) and [c_api.h](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/c/c_api.h)? For example, creating a session and tensors, running queries, get tensor result, etc.\r\n\r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version:\r\n- Doc Link:\r\n\r\n\r\n**Describe the documentation issue**\r\nThis link is unreachable\r\n```\r\nTable 1: Top-1 accuracy of floating point and fully quantized CNNs on Imagenet Validation dataset.\r\nOur pre-trained models are available in the TensorFlow Lite model repository. The code used to generate these models is available.\r\n```\r\n\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "Hello there, something display error with **tensorflow.org** with a bunch of messy.\r\nJust like this.\r\n![image](https://user-images.githubusercontent.com/16497652/56794571-fdfe2e00-6840-11e9-8237-f03d8a8c4743.png)\r\n![image](https://user-images.githubusercontent.com/16497652/56794637-21c17400-6841-11e9-9a46-ea10b982ebf1.png)\r\n\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "**System information**\r\n- TensorFlow version: N/A\r\n- Doc Link: https://www.tensorflow.org/api_docs/python/tf/image\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\nOn the page\r\nhttps://www.tensorflow.org/api_docs/python/tf/image\r\n\r\nThe link within the text \"See the Images guide.\" is broken.\r\n(It is currently directing to https://www.tensorflow.org/api_guides/python/image, but 404'd)\r\n\r\n\r\n_edit: Removed contents from template unrelated to the issue._"
  },
  {
    "labels": [null, "documentation"],
    "text": "Since the tensorflow lite supports the GPU on mobile phone. But, it only supports float32 and float 16, the model size with float32 is too large. So, will the float16 be available for training and storage, and for converting to .tflite."
  },
  {
    "labels": [null, null, null, "documentation", null],
    "text": "**System information**\r\n- TensorFlow version (you are using): 2.0.0a0\r\n\r\n**Describe the feature and the current behavior/state.**\r\nAllow to compute a matrix multiplication between a `RaggedTensor` and a standard dense tensor, returning a `RaggedTensor`.  \r\nThe behavior would be similar to `tf.sparse.sparse_dense_matmul`. \r\n\r\nFor instance, given a `RaggedTensor` of shape `(batch, None, channels_in)`, and a dense tensor of shape `(channels_in, channels_out)`, the operation would return a `RaggedTensor` of shape `(batch, None, channels_out)`, where all entries along the ragged dimension have been multiplied by the dense tensor. \r\n\r\n**Will this change the current api? How?**\r\nIt could be implemented as a standalone operation like `tf.sparse.sparse_dense_matmul`, or it could be part of the existing API (for instance, `tf.math.sum` supports `RaggedTensors` as is). \r\n\r\n**Who will benefit with this feature?**\r\nAnybody working with irregular data, with applications ranging from computer vision (irregular images) to deep learning on graphs.  \r\nGiven the possibility to have `matmul` and `add` on `RaggedTensors`, one could implement dense, convolutional, and recurrent layers operating directly on irregular data. \r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n\r\nOS: Ubuntu 18.04.2\r\nTensorflow-gpu: 2.0.0alpha0\r\n\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW0423 15:59:53.297839 140450503571264 deprecation.py:323] From <path>/python3.6/site-packages/tensorflow/python/ops/confusion_matrix.py:194: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.cast` instead.\r\nW0423 15:59:53.298299 140450503571264 deprecation.py:323] From <path>/python3.6/site-packages/tensorflow/python/ops/confusion_matrix.py:195: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.cast` instead."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "**System information**\r\n- TensorFlow version: 1.13\r\n- Doc Link: https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/BahdanauAttention\r\n\r\nUnder the description for the __init__ function, in the Args, the memory_sequence_length should be in its own point and not part of memory.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?** Yes, I can submit a PR for this.\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "**Describe the documentation issue**\r\n\r\nThe [AUTHORS](https://github.com/tensorflow/tensorflow/blob/master/AUTHORS) file references a CONTRIBUTORS files, but no `CONTRIBUTORS` or `CONTRIBUTORS.md` file exists:\r\n\r\n```\r\n# This file is distinct from the CONTRIBUTORS files.\r\n# See the latter for an explanation.\r\n```\r\n\r\nIf CONTRIBUTORS is some where else, this should be made explicit in AUTHORS.\r\n\r\n**We welcome contributions by users. Can you submit a PR?**\r\n\r\nThis is a question for maintainers and a PR is not yet appropriate."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "**System information**\r\n- TensorFlow version: tensorflow-gpu 2.0.0-alpha0\r\n- Doc Link: https://www.tensorflow.org/alpha/guide/keras/training_and_evaluation#using_the_gradienttape_a_first_end-to-end_example\r\n\r\n**Describe the documentation issue**\r\nThat samples did not use tf.keras.backend.set_learning_phase() for manual training loop. So if the model has BatchNormalization() or other layers which depend on training state, it will be not trained correctly. There is no description about tf.keras.backend.set_learning_phase(), even in the page of BatchNormalization(). (https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/BatchNormalization)\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: TF r1.13 (and many other versions)\r\n- Doc Link: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn)\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\nIt describes the argument `sequence_length` as \"it's more for performance than correctness\", but this is wrong:\r\n\r\n- This argument enables this API to extract the last **VALID** state of RNN instead of a **PADDED** time step, **so it IS for correctness.**\r\n- This argument CANNOT reduce computation, because even with this argument, computation of new states of RNN cell still occurs. The only difference is that `tf.nn.dynamic_rnn` chooses to copy through old states instead of keeping the new states, and this leads to even larger computation. **So it is NOT for performance.**\r\n\r\nThe initial document is correct, see [this commit](https://github.com/tensorflow/tensorflow/commit/855d3b56014780a90143b3e0c0865334b188c2df).\r\n\r\n> it's more for correctness than performance\"\r\n\r\nI don't really understand why you replaced the correct document with a wrong one.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**"
  },
  {
    "labels": [null, "documentation"],
    "text": "**System information**\r\n- TensorFlow version: N/A\r\n- Doc Link: https://github.com/tensorflow/docs/blob/master/site/en/guide/premade_estimators.md\r\nhttps://github.com/tensorflow/docs/blob/master/site/en/guide/custom_estimators.md\r\n\r\n**Describe the documentation issue**\r\nAll of the diagrams / images are missing from both of the links above. \r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nNo.  I don't know what the diagrams were supposed to be."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "**System information**\r\n- TensorFlow version: 2.0-alpha.0\r\n- Doc Link:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/experimental/make_saveable_from_iterator\r\n\r\n**Describe the documentation issue**\r\nWith 2.0-alpha.0, tf.data.Dataset does not have any make_xx_iterator() methods, so I can't save/restore iterate state while training by using tf.data.experimental.make_saveable_from_iterator().\r\n\r\nHow to save/restore internal state of Dataset?\r\n\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "**System information**\r\n- OS Platform and Distribution Ubuntu 18.04 LTS\r\n- TensorFlow installed from source or binary): source\r\n- TensorFlow version (use command below): v2.0.0-alpha0-4-g2c2d508 2.0.0-alpha0\r\n- Python version: 3.5.7\r\n- Bazel version (if compiling from source): From docker image\r\n- GCC/Compiler version (if compiling from source): From docker image\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n\r\n**Describe the current behavior**\r\nThis documentation suggests there are 4 ways to load an optimizer:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/optimizers\r\n\r\nHowever:\r\n\r\n(tf_35) mark@science:~$ python tf_optimizers.py \r\nTraceback (most recent call last):\r\n  File \"tf_optimizers.py\", line 7, in <module>\r\n    opt4 = tf.optimizers.Adagrad\r\nAttributeError: module 'tensorflow' has no attribute 'optimizers'\r\n\r\n**Describe the expected behavior**\r\n\r\nopt = tf.optimizers.Adagrad doesn't work. The first 3 methods do.\r\n\r\n**MINIMAL code to reproduce the issue**\r\n\r\nimport tensorflow as tf\r\ntf.__version__\r\n\r\nopt1 = tf.compat.v2.keras.optimizers.Adagrad\r\nopt2 = tf.compat.v2.optimizers.Adagrad\r\nopt3 = tf.keras.optimizers.Adagrad\r\nopt4 = tf.optimizers.Adagrad\r\n\r\n\r\nI don't know if this is a documentation issue or a tensorflow bug.\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "\r\n**System information**\r\n- TensorFlow version: 2.0.0-alpha0\r\n- Doc Link: https://www.tensorflow.org/alpha\r\n\r\nGuides/examples that use feature columns follow a bad pattern for numeric features. In particular, the examples in the guides always create a list of scalar `numeric_column`s instead of one `numeric_column` with all numeric features. This results in really bad performance when training. See [this thread](https://groups.google.com/a/tensorflow.org/d/msg/discuss/Vt0JGKF_Bno/S5XXmdaoCQAJ).\r\nLocations in the docs (there may be others I missed): \r\n* https://www.tensorflow.org/alpha/tutorials/estimators/linear#base_feature_columns\r\n* https://www.tensorflow.org/guide/estimators#structure_of_a_pre-made_estimators_program\r\n* https://www.tensorflow.org/alpha/tutorials/keras/feature_columns#choose_which_columns_to_use\r\n* https://www.tensorflow.org/alpha/tutorials/estimators/boosted_trees#create_feature_columns_and_input_functions\r\n* https://www.tensorflow.org/alpha/tutorials/estimators/boosted_trees_model_understanding#create_feature_columns_input_fn_and_the_train_the_estimator\r\n\r\n\r\nThe '[Feature Columns guide](https://www.tensorflow.org/guide/feature_columns)' from TF 1 or anything analogous is not available in the [TF 2 docs](https://www.tensorflow.org/alpha). That guide does mention the shape parameter, but does not discuss performance at all, and also describes creating a separate `numeric_column` for each feature in the Iris dataset in [this section](https://www.tensorflow.org/guide/feature_columns#numeric_column)."
  },
  {
    "labels": [null, "documentation"],
    "text": "**System information**\r\nGoogle Colab\r\n- TensorFlow installed from (source or binary):\r\nInstalled from https://storage.googleapis.com/download.tensorflow.org/data/tensorflow_hub-0.4.0.dev0-py2.py3-none-any.whl\r\n- TensorFlow version (or github SHA if from source):\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: AVERAGE_POOL_2D, CONCATENATION, CONV_2D, FULLY_CONNECTED, MAX_POOL_2D, MEAN, RESHAPE, SOFTMAX. Here is a list of operators for which you will need custom implementations: IdentityN.\r\n\r\nAlso, please include a link to a GraphDef or the model if possible.\r\nGoogle Colab Notebook: https://colab.research.google.com/drive/1idF4ZZysBnfcGwfoj0DovQb8C4NVA42w\r\n\r\nI updated the Google Colab Tutorial and updated it to use InceptionV3(based on the link included in the notebook and modified the file size to be [299,299].\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "Not sure what the intention is as I see a lot of v1/v2 name changing.\r\n\r\ntf.summary.scalar is there but not tf.summary.tensor_summary\r\n\r\nIn [80]: tf.__version__\r\nOut[80]: '2.0.0-alpha0'"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "The TF documentation page \"Using TFRecords and tf.Example\" https://www.tensorflow.org/tutorials/load_data/tf_records lists these helper functions:\r\n\r\n```\r\n# The following functions can be used to convert a value to a type compatible\r\n# with tf.Example.\r\n\r\ndef _bytes_feature(value):\r\n  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\r\n  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\r\n\r\ndef _float_feature(value):\r\n  \"\"\"Returns a float_list from a float / double.\"\"\"\r\n  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\r\n\r\ndef _int64_feature(value):\r\n  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\r\n  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\r\n```\r\n\r\nSearching github code shows these have been cut and pasted 3453 times into other projects:\r\nhttps://github.com/search?q=_bytes_feature+_float_feature&type=Code\r\nand presumably many more times besides.\r\n\r\nCould TF include helper functions for these and other common tf.train.Features/Examples helpers?\r\n\r\n**System information**\r\n- TensorFlow version: 1.13.1\r\n- Are you willing to contribute it: Yes (at some point)\r\n\r\n**Describe the feature and the current behavior/state.**\r\nExamples and Features are recommended as the canonical way to store TF datasets.  However understanding the protobufs is non-trivial: they are multiple layers deep and have a verbose API.\r\n\r\n**Will this change the current api? How?**\r\nThis will make the API simpler and more pythonic for building usual Features and Examples.\r\n\r\n**Who will benefit with this feature?**\r\nAll users building datasets.\r\n\r\n**Any Other info.**\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "On macOS 10.14.4 I'm following the directions at this location:\r\n\r\nhttps://codelabs.developers.google.com/codelabs/sparkfun-tensorflow/#0\r\n\r\nEverything goes fine until step 4 when I try:\r\n\r\nmake -f tensorflow/lite/experimental/micro/tools/make/Makefile TARGET=sparkfun_edge micro_speech_bin\r\n\r\nand get the error:\r\n\r\nIn file included from tensorflow/lite/experimental/micro/kernels/fully_connected.cc:16:0:\r\n./tensorflow/lite/kernels/internal/reference/fully_connected.h:18:10: fatal error: fixedpoint/fixedpoint.h: No such file or directory\r\n #include \"fixedpoint/fixedpoint.h\"\r\n          ^~~~~~~~~~~~~~~~~~~~~~~~~\r\ncompilation terminated.\r\n\r\nAny ideas why fixedpoint/fixedpoint.h is not found?"
  },
  {
    "labels": ["documentation"],
    "text": "**System information**\r\n- TensorFlow version:2.0 \r\n- Doc Link:https://www.tensorflow.org/alpha/tutorials/generative/pix2pix\r\n**Input Pipeline Cell**\r\n\r\n\r\n**Documentation/Code Issue:**\r\nCell has the following code:\r\n\r\n1. test_dataset = tf.data.Dataset.list_files(PATH+'test/*.jpg')\r\n2. *#shuffling so that for every epoch a different image is generated*\r\n3. *#to predict and display the progress of our model.*\r\n4. train_dataset = train_dataset.shuffle(BUFFER_SIZE)\r\n5. test_dataset = test_dataset.map(load_image_test)\r\n6. test_dataset = test_dataset.batch(1)\r\n\r\n\r\nFrom line no 4, it seems we are not shuffling the test_dataset.  Should it have been \r\n\"test_dataset = test_dataset.shuffle(BUFFER_SIZE)\" ?\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "**System information**\r\n- TensorFlow version: `tensorflow-gpu==1.10.1`\r\n- Doc Link: https://www.tensorflow.org/tutorials/sequences/text_generation#the_prediction_loop\r\n\r\n**Describe the documentation issue**\r\nI followed the text generation tutorial, and trained my model until it achieved a cross entropy loss of ~0.5 after 30 epochs; however, the generated text was mostly garbage. Reading the code linked in the section above, I saw:\r\n\r\n```python\r\n      # We pass the predicted word as the next input to the model\r\n      # along with the previous hidden state\r\n      input_eval = tf.expand_dims([predicted_id], 0)\r\n```\r\n\r\nwhich doesn't make sense to me. The comment says we're passing along the hidden state (which maybe the model is doing for us?) but the only text that's passed along is the last predicted character. After modifying the text generation function to pass to the model last at most `seq_length` generated characters, the output text started to look like actual Shakespeare/English.\r\n\r\nMy question is: is the model supposed to implicitly propagate hidden state, (and I've done something wrong following the tutorial), or is the tutorial accidentally omitting the part where we pass along the last set of generated text?\r\n\r\n> __Note__: Since I'm running tensorflow 1.10, and the tutorial seems to require 1.13 I had to replace the loss function with `tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits)`. I don't think that change is related, but is it possible that tf 1.10 doesn't propagate the hidden state in the model?\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n\r\nI'm happy to contribute my code changes to the tutorial, but want to make sure I'm understanding what's going wrong first.\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: Any\r\n- Doc Link: https://github.com/tensorflow/docs/blob/master/site/en/r2/tutorials/sequences/image_captioning.ipynb\r\n\r\n\r\n**Describe the documentation issue**\r\nThe code in this [cell](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/r2/tutorials/sequences/image_captioning.ipynb#scrollTo=uEWM9xrYcg45) which sets `vocab_size = len(tokenizer.word_index) + 1` is wrong. `vocab_size` is set to `8235+1`, but actually needs to be set to `5000+1`, as `top_k = 5000`\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?** Yes\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "ssim, and ms_ssim take images as input and max_val which is defined as the dynamic range, implying that images can be eg in [-1,1] with maxval = 2. however they call convert_image_dtype() which assumes pixels are in [0,?]. so it is not clear whether ssim, ms_ssim can take images with negative pixel values."
  },
  {
    "labels": ["documentation"],
    "text": "### **On the page** \r\nhttps://www.tensorflow.org/api_docs/python/tf/image\r\n\r\n### **The link Under heading**\r\n `Module\r\n    tf.Image`\r\n\r\nhttps://www.tensorflow.org/code/stable/tensorflow/_api/v1/image/__init__.py\r\n**is broken.**\r\n\r\n\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "**System information**\r\n- TensorFlow version: 2.0 alpha\r\n- Doc Link:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/activations/selu\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/activations.py\r\n\r\n**- Links**\r\nShould format the referenced paper - get rid of \"-\" and add the authors/year of publishing:\r\n`\"Self-Normalizing Neural Networks\" (Klambauer et al, 2017)\"`\r\n\r\n**- Definition**\r\nThe current definition does not specify the fixed values for `alpha` and `scale` constants. It also assumes knowledge of the ELU activation function. We should also include a link (i.e. https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/activations/elu).\r\n\r\nProposed modified definition:\r\n\r\n```\r\nThe Scaled Exponential Linear Unit (SELU) activation function is:\r\n\r\n`scale` * `x` if `x > 0` and `scale * alpha * (exp(x)-1)` if `x < 0`\r\n\r\nwhere `alpha` and `scale` are pre-defined constants (`alpha = 1.6732632423543772848170429916717` and `scale = 1.0507009873554804934193349852946`.\r\nThe SELU activation function multiplies  `scale` > 1 with the `[elu](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/activations/elu)` (Exponential Linear Unit (ELU)) to ensure a slope larger than one for positive net inputs. \r\n```\r\n\r\nFollowed by what is already in the docs with the formatted `lecun_normal` initialization bit and a link to it: https://www.tensorflow.org/api_docs/python/tf/keras/initializers/lecun_normal:\r\n\r\n```\r\n...The values of alpha and scale are chosen so that the mean and variance of the inputs are preserved between two consecutive layers as long as the weights are initialized correctly (see `[lecun_normal` initialization](https://www.tensorflow.org/api_docs/python/tf/keras/initializers/lecun_normal)) and the number of inputs is \"large enough\" (see references for more information).\r\n```\r\n\r\n**- Examples**\r\nCan add a modified example fro the Intro to CNNs tutorials (use `selu` instead of `relu`)\r\n\r\n```\r\nmodel = models.Sequential()\r\nmodel.add(layers.Conv2D(32, (3, 3), activation='selu', input_shape=(28, 28, 1)))\r\nmodel.add(layers.MaxPooling2D((2, 2)))\r\nmodel.add(layers.Conv2D(64, (3, 3), activation='selu'))\r\nmodel.add(layers.MaxPooling2D((2, 2)))\r\nmodel.add(layers.Conv2D(64, (3, 3), activation='selu'))\r\n```\r\n\r\n**- Returns**\r\nCan modify to include the word `function`:\r\n```\r\nThe scaled exponential unit activation function`: `scale * elu(x, alpha)`.\r\n``` \r\nand format markdown for plain text.\r\n\r\n**- Raises**\r\nNot defined.\r\n\r\n**- Visuals**\r\nShould be added, similar to: https://cdn-images-1.medium.com/max/1600/1*WyQS-lnoemRA3_FpRL7r5w.png\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nYes"
  },
  {
    "labels": [null, "documentation"],
    "text": "**System information**\r\n- TensorFlow version: 2.0 alpha\r\n- Doc Link:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/activations/elu\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/activations.py\r\n\r\n**- Links**\r\nLinks exist. Should format the link to the original paper (delete \"-\"). Also, should add authors and year of publishing \r\n\r\nE.g. \r\n```\r\nReference: \"Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)\" (Clevert et al, 2015)\r\n```\r\n\r\n**- Definition**\r\nSince it just says: `Exponential linear unit` we can modify it to the following - similar to the [original paper](https://arxiv.org/abs/1511.07289) :\r\n```\r\nThe exponential linear unit (ELU) with `alpha` > 0 is:\r\n`x` if `x > 0` and `alpha * (exp(x)-1)` if `x < 0`\r\nThe ELU hyperparameter `alpha` (α) controls the value to which an ELU saturates for negative net inputs.\r\nELUs diminish the vanishing gradient effect.\r\n```\r\nFollowed by word-for-word stuff from the [original paper](https://arxiv.org/abs/1511.07289):\r\n```\r\nELUs have negative values which pushes the mean of the activations closer to zero. \r\nMean activations that are closer to zero enable faster learning as they bring the gradient closer to the natural gradient. \r\nELUs saturate to a negative value when the argument gets smaller. \r\nSaturation means a small derivative which decreases the variation and the information that is propagated to the next layer.\"\r\n```\r\n\r\n**- Examples**\r\nNo examples given. Can add a modified example from the Intro to CNNs tutorial (where `elu` replaces ReLU - `relu`) \r\n\r\nE.g.\r\n```\r\nmodel = models.Sequential()\r\nmodel.add(layers.Conv2D(32, (3, 3), activation='elu', input_shape=(28, 28, 1)))\r\nmodel.add(layers.MaxPooling2D((2, 2)))\r\nmodel.add(layers.Conv2D(64, (3, 3), activation='elu'))\r\nmodel.add(layers.MaxPooling2D((2, 2)))\r\nmodel.add(layers.Conv2D(64, (3, 3), activation='elu'))\r\n```\r\n\r\n**- Parameters**\r\nBoth params defined already but to aid the user it should state that `alpha` (α) should be set at 1.0  _by default_ and that:\r\n```\r\n`alpha` controls the value to which an ELU saturates for negative net inputs.\r\n```\r\n(source: [paper](https://arxiv.org/abs/1511.07289)) \r\n\r\n... instead of just \r\n```\r\n`alpha`: A scalar, slope of negative section\r\n```\r\n\r\n**- Returns**\r\nDefined but for clarity should say: \r\n```\r\nThe exponential linear unit (ELU) activation function: `x` if `x > 0` and `alpha * (exp(x) - 1)` if `x < 0`\r\n```\r\n instead of simply `The exponential linear activation:...[equation]`\r\n\r\n**- Raises**\r\nNot defined.\r\n\r\n**- Visuals**\r\nShould be added to help the user. Example - see p.5 of the original paper: https://arxiv.org/pdf/1511.07289.pdf.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nYes"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "**System information**\r\n- TensorFlow version: 1.13\r\n- Doc Link: https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/space-to-batch-n-d, https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/batch-to-space-n-d\r\n\r\n\r\n**Describe the documentation issue**\r\nExample 2 in https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/space-to-batch-n-d says\r\n\r\n> The output tensor has shape `[4, 1, 1, 3]` and value:\r\n\r\n>     [[[1, 2, 3]], [[4, 5, 6]], [[7, 8, 9]], [[10, 11, 12]]]\r\n\r\nHowever, that value's shape is `[4, 1, 3]`. It appears the shape is correct, but the value should be\r\n\r\n    [[[[1, 2, 3]]], [[[4, 5, 6]]], [[[7, 8, 9]]], [[[10, 11, 12]]]]\r\n\r\nThe same issue is present in https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/batch-to-space-n-d example 2.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nYes."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: v1.13\r\n- Doc Link:\r\n\r\n\r\n**Describe the documentation issue**\r\nHi, I am looking for documentation on the ReadVariableOp and VarHandleOp. Specifically as to what are the inputs that they take and what do they produce exactly. I dug around the source code for mentions of these ops and found some calls [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/resource_variable_ops.py#L196) and [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/resource_variable_ops.py#L864). While this hints at the signature of these ops, I would love to look at the implementation, which probably exists in [this](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/resource_variable_ops.py#L37) module, but I can not find it in this public repo's master branch. Could someone point me to this?\r\n\r\nAlternately, is there any documentation on these ops written [this](https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/fused-batch-norm) way?\r\n\r\nThanks!\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "\r\n- Doc Link: https://www.tensorflow.org/api_docs/python/tf/keras/layers/AveragePooling1D#arguments\r\n\r\n\r\n**Describe the documentation issue**\r\nSee the comment below\r\n\r\n```\r\npool_size: Integer, size of the **max** pooling windows.\r\n```\r\n\r\nIt should be **average** instead of **max** since this is average pooling.\r\n\r\nFurthermore, the format of the description for `input shape` and `output shape` is broken.\r\nIt is not rendered in a list format."
  },
  {
    "labels": [null, "documentation"],
    "text": "\r\n- Doc Link: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Add#class_add\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\nSee the code example (https://www.tensorflow.org/api_docs/python/tf/keras/layers/Add#class_add)\r\n\r\n```python\r\n    added = keras.layers.Add()([x1, x2])  # equivalent to added =\r\n    keras.layers.add([x1, x2])\r\n```\r\n\r\nIt should be\r\n\r\n```\r\n    added = keras.layers.Add()([x1, x2])  # equivalent to added = keras.layers.add([x1, x2])\r\n```"
  },
  {
    "labels": [null, "documentation"],
    "text": "\r\n- Doc Link: https://www.tensorflow.org/api_docs/python/tf/keras/models/Sequential#predict\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\nThe argument list is not rendered correctly.\r\n\r\nSee it below\r\n\r\n```\r\nArguments:\r\nx: Input samples. It could be: - A Numpy array (or array-like), or a list of arrays (in case the model has multiple inputs). - A TensorFlow tensor, or a list of tensors (in case the model has multiple inputs). - A tf.data dataset or a dataset iterator. - A generator or keras.utils.Sequence instance. * batch_size: Integer or None. Number of samples per gradient update. If unspecified, batch_size will default to 32. Do not specify the batch_size is your data is in the form of symbolic tensors, dataset, dataset iterators, generators, or keras.utils.Sequence instances (since they generate batches). * verbose: Verbosity mode, 0 or 1. * steps: Total number of steps (batches of samples) before declaring the prediction round finished. Ignored with the default value of None. * max_queue_size: Integer. Used for generator or keras.utils.Sequence input only. Maximum size for the generator queue. If unspecified, max_queue_size will default to 10. * workers: Integer. Used for generator or keras.utils.Sequence input only. Maximum number of processes to spin up when using process-based threading. If unspecified, workers will default to 1. If 0, will execute the generator on the main thread. * use_multiprocessing: Boolean. Used for generator or keras.utils.Sequence input only. If True, use process-based threading. If unspecified, use_multiprocessing will default to False. Note that because this implementation relies on multiprocessing, you should not pass non-picklable arguments to the generator as they can't be passed easily to children processes.\r\n```\r\n\r\nIt should be rendered in a list/item format."
  },
  {
    "labels": [null, "documentation"],
    "text": "\r\n- Doc Link: https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy#class_binarycrossentropy\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\nThe `__init__` function of `tf.keras.losses.BinaryCrossentropy` is not rendered correctly.\r\n\r\nSee the link here https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy#methods"
  },
  {
    "labels": ["documentation"],
    "text": "Hello, \r\nin tensorflow/stream_executor/platform/default/dso_loader.cc line 50\r\nLD_LIRARY_PATH is called instead of LD_LIBRARY_PATH\r\nBest"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "**System information**\r\n- Doc Link: https://www.tensorflow.org/guide/embedding\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\nThe guide says\r\n\r\n> To use images as metadata, you must produce a single sprite image, consisting of small thumbnails, one for each vector in the embedding. \r\n\r\nIt then goes on to explain what the sprite image should look like (but it doesn't make clear if it needs to be \"square\" where each row contains a number of thumbnails close to the square root of the total number of vectors). Is any standard image format OK? What does one do with the image file? It doesn't work to choose it in the dialog that says \"Step 2 (optional): Load a TSV file of metadata.\". If one creates a config.json file how should one refer to the sprite image URL?\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "I don't see any simple function optimisation example for tensorflow 2.0.\r\n\r\nSomething like log(x) ** 2 could be good."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "\r\n**System information**\r\n- TensorFlow version: 2.0\r\n- Doc Link:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model\r\n\r\n**Describe the documentation issue**\r\n\r\nIn the documentation keras/Model for \"predict\" function the list of argument is not display properly (fullblock instead of list) on both Chrome and Firefox\r\n\r\n<img width=\"910\" alt=\"Screenshot 2019-04-06 at 20 59 00\" src=\"https://user-images.githubusercontent.com/12021701/55674016-0cdf6980-58af-11e9-995f-fc569131a741.png\">\r\n\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: v2.0.0-alpha0\r\n- Doc Link: https://www.tensorflow.org/install/source_windows#install_bazel\r\n\r\n\r\n**Describe the documentation issue**\r\nI downloaded the latest (at the time of writing, 0.24.1) Bazel binary and when I tried to `./configure.py` I got this: \r\n```\r\nYou have bazel 0.24.1 installed.\r\nPlease downgrade your bazel installation to version 0.23.0 or lower to build TensorFlow! To downgrade: download the installer for the old version (from https://github.com/bazelbuild/bazel/releases) then run the installer.\r\n```\r\nI think it would be useful to state explicitly that 0.23.0 is the version required to build Tensorflow to save some time. I even just downloaded 0.23.2 because I didn't see that the message says 0.23.0 and sure enough, I got the same complaint about 0.23.2.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n\r\nYes. Will do a PR shortly.\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "As you might have seen Facebook released hyperbolic embeddings training; \r\nIs there any plan to support those in Tensorflow?\r\n\r\nhttps://github.com/facebookresearch/poincare-embeddings"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "I want to use tfjs-models in a commercial application. While source code in the [tfjs-models repository](https://github.com/tensorflow/tfjs-models) is licensed under Apache 2.0, I did not find any info about the license of the models hosted on storage.googleapis.com.\r\n\r\nFor example [body-pix](https://github.com/tensorflow/tfjs-models/tree/master/body-pix) is loading its model from [storage.googleapis.com/tfjs-models](https://storage.googleapis.com/tfjs-models)\r\ne.g.\r\n[posenet_mobilenet_025_partmap/model.json](https://storage.googleapis.com/tfjs-models/savedmodel/posenet_mobilenet_025_partmap/model.json)\r\n[posenet_mobilenet_025_partmap/tensorflowjs_model.p](https://storage.googleapis.com/tfjs-models/savedmodel/posenet_mobilenet_025_partmap/tensorflowjs_model.pb)\r\n[posenet_mobilenet_025_partmap/weights_manifest.json](https://storage.googleapis.com/tfjs-models/savedmodel/posenet_mobilenet_025_partmap/weights_manifest.json)\r\n\r\nAre the files on [storage.googleapis.com/tfjs-models](https://storage.googleapis.com/tfjs-models) licensed under Apache 2.0 as well?\r\n\r\nIf yes, it would be great to document it, and I'm willing to submit a PR.\r\n\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "**System information**\r\n- TensorFlow version: 2.0.0-aplha0\r\n- Doc Link: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/optimizers/Optimizer#apply_gradients\r\n\r\nI was implementing a DD Policy Gradient for reinforcement learning, and had a bug where my agent would minimize the reward, instead of maximizing it. It turned out optimizer.apply_gradients() follows negative of the gradients I give to it. This is a surprising behavior when using this function separately, outside of .minimize() context.\r\n\r\nDocumentation does not mention anywhere that negative gradient is followed by this method.\r\n\r\nhad to use a unit test to clarify the behavior:\r\n\r\n```\r\n    opt = tf.optimizers.Adam()\r\n    x = tf.Variable([1], dtype=tf.float32)\r\n    dx = tf.ones([1], dtype=tf.float32)\r\n\r\n    opt.apply_gradients( [(dx, x)] )\r\n    assert x.numpy()[0] > 1\r\n```\r\nThere is also no flag to invert this behavior and follow positive gradient. I have to pass negative gradient of the expected reward to follow it in positive direction.\r\n\r\n\r\n```\r\n    def train_actor(self, sars):\r\n\r\n        obs1, actions, rewards, obs2 = sars\r\n        with tf.GradientTape() as tape:\r\n            would_do_actions = self.actor(obs1)\r\n            score = tf.reduce_mean( self.critic( observations=obs1, actions=would_do_actions ) )\r\n            inverted = - score\r\n\r\n        # tf optimizer follows negative of the provided gradients.\r\n        # For this reason we provide negative gradient of the score -\r\n        # it will result in positive gradient being followed.\r\n        grads = tape.gradient( inverted, self.actor.trainable_weights )\r\n        self.optimizer.apply_gradients( zip(grads, self.actor.trainable_weights) )\r\n```"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 2.0\r\n- Doc Link: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/print\r\n\r\n\r\n**Describe the documentation issue**\r\nthe example doesn't work with TF 2.0\r\n```python\r\n    tf.enable_eager_execution()\r\n    @tf.contrib.eager.defun\r\n    def f():\r\n        tensor = tf.range(10)\r\n        tf.print(tensor, output_stream=sys.stderr)\r\n        return tensor\r\n    range_tensor = f()\r\n```\r\n```python\r\n    sess = tf.Session()\r\n    with sess.as_default():\r\n        tensor = tf.range(10)\r\n        print_op = tf.print(\"tensors:\", tensor, {2: tensor * 2},\r\n                            output_stream=sys.stdout)\r\n        with tf.control_dependencies([print_op]):\r\n          tripled_tensor = tensor * 3\r\n        sess.run(tripled_tensor)\r\n```\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "**System information**\r\n- TensorFlow version: 1.13.1\r\n- Doc Link: https://www.tensorflow.org/api_docs/python/tf/contrib/saved_model/save_keras_model?hl=en\r\n\r\n\r\n**Describe the documentation issue**\r\nI followed [this tutorial](https://www.tensorflow.org/tutorials/keras/save_and_restore_models) and this [API reference page](https://www.tensorflow.org/api_docs/python/tf/contrib/saved_model/save_keras_model?hl=en) to save a trained Keras model as a SavedModel, which in my use case is required to upload it to GCP ML Engine.\r\nBut I encounter a non documented `AssertionError` specifying I should use eager mode.\r\nThis seems related to [this commit](https://github.com/tensorflow/tensorflow/commit/6603c69fa71d6ebdee717863079ca34308c9ddb1).\r\nDid I understand something wrong or should this compatibility requirements also be documented for `save_keras_model` (at least with `serving_only` set to `True`) ?"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "**System information**\r\n- TensorFlow version: 2.0 alpha\r\n- Doc Link:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Sequential\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/sequential.py\r\n\r\n**Describe the documentation issue**\r\n\r\n**- Description:**\r\n\r\nThe order of _Properties_ and _Methods_ is alphabetical, probably by TF doc design. With a large doc for an arguably popular module such as `tf.keras.Sequential` navigating around it may be confusing to the user. Perhaps we should start with the most important ones e.g. `compile` and `fit` under Methods. Since `tf.keras.Sequential`, like many other modules/classes, expands on `keras.Sequential` it would still be logical to list certain Properties, Methods etc in the beginning (at the top of the page) in order of importance for better UX. See: https://keras.io/models/sequential/ as a good example where these are not in alphabetical order.\r\n\r\nAlso, in the beginning after a short intro (\"inherits from `Model`... a linear stack of layers\"), a link to \"Build a Simple Model\" (with `tf.keras.Sequential`) in TensorFlow would be cool for those who are new to `(tf.)Keras`/TF - https://www.tensorflow.org/alpha/guide/keras/overview#sequential_model. Also, the official Keras.io docs include a URL in https://keras.io/models/sequential/ to \"Getting started with the Keras Sequential model\": https://keras.io/getting-started/sequential-model-guide.\r\n\r\n**- Examples:**\r\n\r\nThere already is an example right in the beginning. Maybe adding adding a separate link to or copying an example from this Sequential notebook would be cool too - https://github.com/tensorflow/docs/blob/master/site/en/r2/tutorials/quickstart/beginner.ipynb (source: https://www.tensorflow.org/alpha/guide/keras/overview#sequential_model)\r\n\r\n**- Parameters**\r\n\r\nInconsistent. Some reformatting may be needed e.g. input_shape -> `input_shape`. \r\nAlso, both _Arguments_ and _Args_ are used throughout the doc.\r\n\r\n**- Returns, Raises:**\r\n\r\nSometimes exist, sometimes not - creates a UX issue because of inconsistency.\r\n\r\n**- Visuals:**\r\n\r\nA simple one similar to https://www.tensorflow.org/alpha/guide/keras/functional would be appreciated.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nFor sure."
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "**System information**\r\n- TensorFlow version: 2.0 alpha\r\n- Doc Link: \r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/training.py\r\n\r\n**Describe the documentation issue**\r\n\r\n**- Links:**\r\n\r\nA link to **_Keras Functional API in TensorFlow_** would be appreciated for those who are new to `(tf.)Keras` and TensorFlow 1.x and 2.0 - https://www.tensorflow.org/alpha/guide/keras/functional. E.g. See this Keras Model class API doc: https://keras.io/models/model/#model-class-api.\r\n\r\n**- Description:**\r\n\r\nTaking into account this is a 'heavy' module it may not be easy to write good docs for `tf.keras.Model`. Since `tf.keras` is a crucial API to TF 2.0, so let's make the docs a delight to read. The current documentation for `tf.keras.Model` is a bit incomprehensible for a novice or experienced user.\r\n\r\nIn terms of user experience for someone who is new or not new to TF, maybe the description should be improved and follow the keras.io docs more closely. For instance, arguments under `compile` were apparently copy-pasted from `keras.Model` docs (https://keras.io/models/model/). However, you have to scroll all the way down to see them here: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#compile (_update: maybe because Methods etc are listed in alphabetical order which is not intuitive_).\r\n\r\nThe description at keras.io is neater and more organized imo. It starts with a short description and jumps to args from `compile`. I'd suggest we follow the same structure.\r\n\r\nAlso, as in https://keras.io/models/model/, we should include a link to the guide to **_Keras Functional API in TensorFlow_** - https://www.tensorflow.org/alpha/guide/keras/functional - which is quite well written.\r\n\r\n**- Examples:**\r\n\r\nNot enough examples - they are mentioned here and there. See UX issues above under Description. Recommend to rewrite it to follow the original `keras.Model` module - https://keras.io/models/model/#model-class-api - along with examples. \r\n\r\n**- Parameters, Returns, Raises:**\r\n\r\nUX issues - see Description above.\r\n\r\n**- Visuals:**\r\n\r\nRecommend to add visuals from https://www.tensorflow.org/alpha/guide/keras/functional\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nYes, let's make `tf.keras` docs awesome."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Pro\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: not applicable\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: tensorflow-gpu 2.0.0a0\r\n- Python version: 3.6.7\r\n- Installed using virtualenv? pip? conda?: virtualenv + pip\r\n- Bazel version (if compiling from source): -\r\n- GCC/Compiler version (if compiling from source): - \r\n- CUDA/cuDNN version: 10.0/7.5.0.56\r\n- GPU model and memory: NVIDIA GTX 1080 Max-Q\r\n\r\n\r\n\r\n**Describe the problem**\r\nI've just followed the installation guides for tensorflow 2.0 (see above) from:\r\n- https://www.tensorflow.org/install/pip\r\n- https://www.tensorflow.org/install/gpu#software_requirements\r\nThe final step is to \"Verify the install\" (see the pip link above) which gives me the following output:\r\n```\r\n$ python -c \"import tensorflow as tf; tf.enable_eager_execution(); print(tf.reduce_sum(tf.random_normal([1000, 1000])))\"\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nAttributeError: module 'tensorflow' has no attribute 'enable_eager_execution'\r\n```\r\n\r\nWhich I did not expect/hope to see.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n- Follow the guides mentioned above.\r\n- Create all the environment variables. \r\n-- Path within venv then contains: \r\n```\r\nD:\\dev\\project\\project-venv\\\r\nD:\\dev\\tools\\cuda\\cudnn-10.0-windows10-x64-v7.5.0.56\\cuda\\bin;\r\nC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\bin;\r\nC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\extras\\CUPTI\\libx64;\r\nC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\include;\r\nC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\libnvvp;\r\nC:\\ProgramData\\DockerDesktop\\version-bin;\r\nC:\\Program Files\\Docker\\Docker\\Resources\\bin;\r\nD:\\dev\\tools\\oraclexe\\oraclexe\\app\\oracle\\product\\11.2.0\\server\\bin;\r\nC:\\Program Files\\Python36\\Scripts\\;\r\nC:\\Program Files\\Python36\\;\r\nC:\\Program Files\\Microsoft MPI\\Bin\\;\r\nC:\\Program Files (x86)\\Common Files\\Oracle\\Java\\javapath;\r\nC:\\ProgramData\\Oracle\\Java\\javapath;\r\nC:\\WINDOWS\\system32;\r\nC:\\WINDOWS;\r\nC:\\WINDOWS\\System32\\Wbem;\r\nC:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\;\r\nC:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;\r\nC:\\Program Files\\dotnet\\;\r\nC:\\Program Files\\Microsoft SQL Server\\130\\Tools\\Binn\\;\r\nD:\\dev\\tools\\putty\\;\r\nC:\\Program Files\\TortoiseSVN\\bin;\r\nC:\\Program Files\\NVIDIA Corporation\\NVIDIA NvDLISR;\r\nC:\\Program Files\\nodejs\\;\r\nC:\\WINDOWS\\system32;\r\nC:\\WINDOWS;\r\nC:\\WINDOWS\\System32\\Wbem;\r\nC:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\;\r\nC:\\WINDOWS\\System32\\OpenSSH\\;\r\nC:\\dev\\tools\\python\\python3.6.7\\Scripts\\;\r\nC:\\dev\\tools\\python\\python3.6.7\\;\r\nC:\\Program Files\\Python36\\Scripts\\;\r\nC:\\Program Files\\Python36\\;\r\nC:\\Users\\tve21314\\AppData\\Local\\Microsoft\\WindowsApps;\r\nD:\\dev\\tools\\maven\\apache-maven-3.5.3\\bin;\r\nC:\\Program Files\\Java\\jdk1.8.0_201\\bin;\r\nC:\\Program Files\\Java\\jre1.8.0_201\\bin;\r\nC:\\Program Files\\Git\\bin;\r\nC:\\Users\\tve21314\\AppData\\Local\\Programs\\Microsoft VS Code\\bin;\r\nC:\\Users\\tve21314\\AppData\\Roaming\\npm;\r\n```\r\n- Finally run from within the venv:\r\n```python -c \"import tensorflow as tf; tf.enable_eager_execution(); print(tf.reduce_sum(tf.random_normal([1000, 1000])))\"```\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n- The traceback again:\r\n```\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nAttributeError: module 'tensorflow' has no attribute 'enable_eager_execution'\r\n```\r\n\r\n- If I use ```python -c \"import tensorflow as tf;print(tf.reduce_sum(tf.random_normal([1000, 1000])))\"``` the error becomes:\r\n```\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nAttributeError: module 'tensorflow' has no attribute 'random_normal'\r\n```"
  },
  { "labels": [null, "documentation"], "text": "" },
  {
    "labels": [null, "documentation"],
    "text": "I'm having trouble reading/interpreting a tensor from a file using read_file() operation in Python. The tensor was saved using Save() ops in tensorflow CC API. I can read the underlying byte encoded tensor, but find no methods to convert that back to float(original content of the tensor). I have tried decode_raw() in python but it complaints about of not being of proper multiple of 4. \r\nThe above tensor comprises of a 3 channel nd array with float contents. Would appreciate any help in deciphering the content\r\nMore precisely would really appreciate on some details on how Save() ops in tensorflow CC API works?"
  },
  {
    "labels": ["documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\nSystem information\r\n\r\n    chrome\r\n    Internet speed 120+ Mbps\r\n    TensorFlow version: all\r\n    Doc Link: all pages\r\n\r\nIt takes a really long time to load the docs. Navigating to another page can take 10+ seconds to load a new page."
  },
  {
    "labels": [null, "documentation"],
    "text": "**System information**\r\n- TensorFlow version:\r\n- Doc Link:\r\n\r\n\r\n**Syntax error in TensorFlow nodejs example**\r\n[See sample code for Node.js usage](https://www.tensorflow.org/js/tutorials/setup)\r\nExtra semicolon is causing the syntax error.\r\n\r\n`onEpochEnd: (epoch, log) => console.log(`Epoch ${epoch}: loss = ${log.loss}`);`\r\nIn the above line, semi-colon in the end should be removed.\r\n****\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "**System information**\r\n- TensorFlow version: 2.0\r\n- Doc Link: https://www.tensorflow.org/guide/extend/formats\r\n\r\n**Describe the documentation issue**\r\n\r\nThe C++ code to extend Dataset (especially since DatasetV2) is outdated.\r\n\r\nHere is a working version of files needed in the documentation : https://github.com/vrince/tensorflow_addons/tree/master/tensorflow_addons/dataset\r\n\r\nNOTE: the only part I am not really sure about is this one : https://github.com/vrince/tensorflow_addons/blob/master/tensorflow_addons/dataset/cc/my_dataset.cpp#L76 ... basically let it as it was but I don't see the point.\r\n\r\nThere is also and external test running from python and bazel files.\r\n\r\nNot sure where or if I even can do a pull request to change the doc."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: API r1.13\r\n- Doc Link: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing\r\n\r\n\r\n**Describe the documentation issue**\r\nA _404 - Page not found_ error is displayed when clicking on the link in the paragraph below:\r\n\r\n> Additional documentation can be found [on the keras site](https://keras.io/preprocessing/), \r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 1.13\r\n- Doc Link: https://www.tensorflow.org/tutorials/images/hub_with_keras\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\nThe above example provides no example of loading the model after it's saved. I'm used to using the \"old style\" of freezing, optimizing (`optimize_for_inference_lib.optimize_for_inference`), and saving models with:\r\n`tf.train.write_graph(output_graph_def, output_dir, 'model.pb', as_text=False)`\r\n\r\nWhich gives me a graph: `model.pb`. I run predictions on this graph locally on my mobile applications with full Tensorflow (in Unity, so not using TF-Lite).\r\n\r\nIn my local prediction script, I load the graph like this:\r\n```python\r\ndef load_graph(model_file):\r\n  graph = tf.Graph()\r\n  graph_def = tf.GraphDef()\r\n\r\n  with open(model_file, \"rb\") as f:\r\n    graph_def.ParseFromString(f.read())\r\n  with graph.as_default():\r\n    tf.import_graph_def(graph_def)\r\n  return graph\r\n```\r\nThen grab the graph input and output ops and run a prediction session. This works pretty well.\r\n\r\nHowever, this new example uses `tf.contrib.saved_model.save_keras_model` to export the model, which I would love to use because it exports all kinds of useful information (which I'd like to use in conjunction with TF Serving for certain applications), and it looks to be making it into TF 2.0 core.\r\n\r\nWith `save_keras_model`, I end up with:\r\n`assets  labels.csv  saved_model.pb  variables`\r\n\r\nWhen trying to use my old graph loading script with this newly generated model with `save_keras_model`, I get an error like this:\r\n```bash\r\n...\r\n    graph_def.ParseFromString(f.read())\r\ngoogle.protobuf.message.DecodeError: Error parsing message\r\n```\r\nThis had me puzzled, as I expected this `.pb` graph generated with the new API to work the same as the one I generated with `tf.train.write_graph`. Browsing through their contents, they look the same, but the newer API's model is smaller in file size. Which makes me wonder if it's missing something.\r\n\r\nI found an alternative method to load it as a graph anyways, but I ran into issues down the road with running it's ops, so I'm not sure I'm approaching this correctly by loading it as a graph, or if there's a \"new, Keras way\" of loading a model and running predictions. Maybe I'm too far in the weeds with trying to load this model as a graph and run it's ops, I'd expect there's a higher level API to do this.\r\n\r\n\r\nSo I have a few questions:\r\n- Is the exported `saved_model.pb` frozen?\r\n- Is it optimized? If not, I can convert the model I have to a graph, then back to a model for something like `save_keras_model`?\r\n\r\n**Ultimately**, can an example be added to this tutorial that demonstrates how to load a saved model?\r\n\r\n\r\nI wrote our initial codebase using TF 1.7 a little while back and I haven't changed much since then, but the API is changing a lot and I want to take full advantage of the advancements. Also I understand if this issue should be moved, I assumed this was appropriate since there was no documentation demonstrating loading a saved model with the new API.\r\n\r\nThank you! \r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nYes\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Doc Link: https://www.tensorflow.org/xla/operation_semantics\r\nThe documentation for [XlaBuilder::Slice](https://www.tensorflow.org/xla/operation_semantics#slice) does not mention the stride parameter. "
  },
  {
    "labels": [null, "documentation"],
    "text": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nmac os 10.14\r\n- TensorFlow installed from (source or binary):\r\n`pip install tensorflow==2.0.0-alpha0`\r\n- TensorFlow version:\r\n2.0.0-alpha0\r\n- Python version:\r\n 3.7.2\r\n- Installed using virtualenv? pip? conda?:\r\nconda: tf was installed in a conda env, the jupyter notebook is launched in the base environment. There is a jupyter kernel for the tensorflow env.\r\n\r\n**Describe the problem**\r\nAfter loading the tensorboard extension with `%load_ext tensorboard.notebook`,  the `%tensorboard` magic fails with:\r\n```\r\n---------------------------------------------------------------------------\r\nFileNotFoundError                         Traceback (most recent call last)\r\n<ipython-input-4-d46782f9619b> in <module>\r\n----> 1 get_ipython().run_line_magic('tensorboard', '--logdir logs')\r\n\r\n[...]\r\n\r\nFileNotFoundError: [Errno 2] No such file or directory: 'tensorboard': 'tensorboard'\r\n```\r\n\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n```\r\nimport tensorflow\r\n%load_ext tensorboard.notebook\r\n%tensorboard --logdir logs\r\n```\r\n\r\n**Any other info / logs**\r\nThe issue is that the `tensorboard` binary is installed in the environment's bin dir which is added to the path when the env is activated. However, when selecting the kernel in the notebook, the path is not modified. So, while the tensorboard extension loads, the magic `%tensorboard` fails because it cannot find the `tensorboard` executable.\r\n\r\nA workaround is to manually add the environment's bin dir to the path from inside the notebook:\r\n\r\n```\r\nimport os\r\nPATH = os.getenv('PATH')\r\n%env PATH=/Users/anto/miniconda3/envs/tf2_env/bin:$PATH\r\n````\r\n\r\nWith this the `%tensorboard` magic starts working."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "\r\n**System information**\r\n- Doc Link: https://www.tensorflow.org/api_docs/python/tf/logging\r\n\r\n\r\n**Describe the documentation issue**\r\n> Defined in **tensorflow/_api/v1/logging/ _ _ init _ _.py**.\r\n\r\nThe link for _ _ init _ _.py is broken: https://www.tensorflow.org/code/stable/tensorflow/_api/v1/logging/__init__.py\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/logging"
  },
  {
    "labels": [null, "documentation"],
    "text": "Hello tf developers team. \r\n\r\nI'm coming to this page: https://www.tensorflow.org/api_docs/python/tf/bitwise, and I see no indication whether this is implemented on GPU or CPU only. Will tf help me for my project or not? I find this information page extremely unhelpful for my purpose. As the overview should state clearly when to use the library and when not (I need only bitwise operations). \r\n\r\nI left a feedback on your page giving two stars - but I can't write a string for you. How would you know what to fix if everyone are just saying the document is bad, and can't explain why and what they're missing? \r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "\r\n**System information**\r\n- TensorFlow version: latest\r\n- Doc Link: https://www.tensorflow.org/js/tutorials/setup\r\n\r\nhttps://www.tensorflow.org/js/tutorials/setup\r\n**Describe the documentation issue**\r\n\r\n ```javascript\r\nconst tf = require('@tensorflow/tfjs');\r\n\r\n// Optional Load the binding:\r\n// Use '@tensorflow/tfjs-node-gpu' if running with GPU.\r\nrequire('@tensorflow/tfjs-node');\r\n\r\n// Train a simple model:\r\nconst model = tf.sequential();\r\nmodel.add(tf.layers.dense({units: 100, activation: 'relu', inputShape: [10]}));\r\nmodel.add(tf.layers.dense({units: 1, activation: 'linear'}));\r\nmodel.compile({optimizer: 'sgd', loss: 'meanSquaredError'});\r\n\r\nconst xs = tf.randomNormal([100, 10]);\r\nconst ys = tf.randomNormal([100, 1]);\r\n\r\nmodel.fit(xs, ys, {\r\n  epochs: 100,\r\n  callbacks: {\r\n    onEpochEnd: (epoch, log) => console.log(`Epoch ${epoch}: loss = ${log.loss}`);   <--- wrong semicolumn\r\n  }\r\n});\r\n  ```\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "on page https://www.tensorflow.org/install/pip\r\n\r\nchange \"tensorflow==2.0.0-alpha0\" to \"tensorflow==2.0.0-a0\"    (two instances)\r\nchange \"tensorflow-gpu==2.0.0-alpha0\" to \"tensorflow-gpu==2.0.0-a0\"\r\nchange \"tensorflow==2.0.0-alpha0-gpu\" to \"tensorflow-gpu==2.0.0-a0\"\r\n\r\non page https://www.tensorflow.org/install/gpu\r\n\r\nchange \"tensorflow==2.0.0-alpha0\" to \"tensorflow==2.0.0-a0\" \r\n\r\ni had to make these changes on my ubuntu-18-04 system to get it to install."
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 1.13\r\n- Doc Link: https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn\r\n\r\n\r\n**Describe the documentation issue**\r\nOn the warning about this function being deprecated, it is suggested to use instead use keras.layers.RNN. However, the function is called tf.keras.layers.RNN (https://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN) \r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: Tensorflow 2.0 alpha\r\n- Doc Link: \r\n[Load images with tf.data](https://www.tensorflow.org/alpha/tutorials/load_data/images)\r\n[Using TFRecords and tf.Example](https://www.tensorflow.org/alpha/tutorials/load_data/tf_records)\r\n\r\n**Describe the documentation issue**\r\n[Load images with tf.data](https://www.tensorflow.org/alpha/tutorials/load_data/images) and [Using TFRecords and tf.Example](https://www.tensorflow.org/alpha/tutorials/load_data/tf_records) have wrong links to Colab and github.\r\n\r\nThey should link to \r\nhttps://github.com/tensorflow/docs/blob/master/site/en/r2/tutorials/load_data/images.ipynb\r\nhttps://github.com/tensorflow/docs/blob/master/site/en/r2/tutorials/load_data/tf_records.ipynb\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: Tensorflow 2.0 alpha\r\n- Doc Link: [Using TFRecords and tf.Example](https://www.tensorflow.org/alpha/tutorials/load_data/tf_records)\r\n\r\n\r\n**Describe the documentation issue**\r\nI don't know why this tutorial only works for tensorflow CPU version.\r\nIf I run on GPU I will have an error in the cell:\r\n`tf_serialize_example(f0,f1,f2,f3)`\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nUnknownError                              Traceback (most recent call last)\r\n<ipython-input-14-406ee79a7f52> in <module>\r\n----> 1 tf_serialize_example(f0,f1,f2,f3)\r\n\r\n<ipython-input-13-3eb13f28c327> in tf_serialize_example(f0, f1, f2, f3)\r\n      3     serialize_example,\r\n      4     (f0,f1,f2,f3),  # pass these args to the above function.\r\n----> 5     tf.string)      # the return type is `tf.string`.\r\n      6   return tf.reshape(tf_string, ()) # The result is a scalar\r\n\r\nD:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py in eager_py_func(func, inp, Tout, name)\r\n    387     if `func` returns None.\r\n    388   \"\"\"\r\n--> 389   return _internal_py_func(func=func, inp=inp, Tout=Tout, eager=True, name=name)\r\n    390 \r\n    391 \r\n\r\nD:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py in _internal_py_func(func, inp, Tout, stateful, eager, is_grad_func, name)\r\n    276   if eager:\r\n    277     result = gen_script_ops.eager_py_func(\r\n--> 278         input=inp, token=token, Tout=Tout, name=name)\r\n    279   else:\r\n    280     if stateful:\r\n\r\nD:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\ops\\gen_script_ops.py in eager_py_func(input, token, Tout, name)\r\n     64       else:\r\n     65         message = e.message\r\n---> 66       _six.raise_from(_core._status_to_exception(e.code, message), None)\r\n     67   # Add nodes to the TensorFlow graph.\r\n     68   token = _execute.make_str(token, \"token\")\r\n\r\n~\\AppData\\Roaming\\Python\\Python36\\site-packages\\six.py in raise_from(value, from_value)\r\n\r\nUnknownError: RuntimeError: Error copying tensor to device: CPU:0. Can't copy 37 bytes of a tensor into another with 32 bytes buffer.\r\nTraceback (most recent call last):\r\n\r\n  File \"D:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 205, in __call__\r\n    return func(device, token, args)\r\n\r\n  File \"D:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 107, in __call__\r\n    ret = self._func(*args)\r\n\r\n  File \"<ipython-input-7-60a59d21d73e>\", line 10, in serialize_example\r\n    'feature2': _bytes_feature(feature2),\r\n\r\n  File \"<ipython-input-3-8047e5ac1b09>\", line 7, in _bytes_feature\r\n    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\r\n\r\n  File \"D:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 732, in numpy\r\n    return self._cpu_nograd()._numpy()  # pylint: disable=protected-access\r\n\r\n  File \"D:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 899, in _cpu_nograd\r\n    return self._copy_nograd(context.context(), \"CPU:0\")\r\n\r\n  File \"D:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 847, in _copy_nograd\r\n    new_tensor = self._copy_to_device(context=ctx._handle, device=device_name)\r\n\r\nRuntimeError: Error copying tensor to device: CPU:0. Can't copy 37 bytes of a tensor into another with 32 bytes buffer.\r\n\r\n [Op:EagerPyFunc]\r\n```\r\n\r\nDoes it have a specific thing only for CPU? \r\n\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: Tensorflow 2.0 alpha\r\n- Doc Link: Tutorial [Load images with tf.data](https://www.tensorflow.org/alpha/tutorials/load_data/images)\r\n\r\n**Describe the documentation issue**\r\nTutorial [Load images with tf.data](https://www.tensorflow.org/alpha/tutorials/load_data/images) will have an error if it runs on windows because of the backslash of the path in this cell.\r\n```\r\nimport IPython.display as display\r\n\r\ndef caption_image(image_path):\r\n    image_rel = pathlib.Path(image_path).relative_to(data_root)\r\n    return \"Image (CC BY 2.0) \" + ' - '.join(attributions[str(image_rel)].split(' - ')[:-1])\r\n```\r\n\r\nSo I fixed it by replacing the backslash with the slash.\r\nimport IPython.display as display\r\n\r\n```\r\ndef caption_image(image_path):\r\n    image_rel = pathlib.Path(image_path).relative_to(data_root)\r\n    image_rel = str(image_rel)\r\n    image_rel=image_rel.replace('\\\\','/')\r\n    str_return = \"Image (CC BY 2.0) \" + ' - '.join(attributions[str(image_rel)].split(' - ')[:-1]) \r\n    return str_return\r\n\r\n```\r\n\r\n\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "<\r\n\r\n**System information**\r\n- TensorFlow version: 2.0\r\n- Doc Link: https://www.tensorflow.org/guide/datasets\r\n\r\nIssue\r\n - The tf.dataset guide mentions using one shot iterator.  \r\n - The doc does not have a section to view by API release.  \r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "**System information**\r\n- TensorFlow version: 2.0\r\n- Doc Link: \r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/bitcast\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/bitwise/bitwise_and\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/bitwise/bitwise_or\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/bitwise/bitwise_xor\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/bitwise/bitwise_invert\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/bitwise/right_shift\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/bitwise/left_shift\r\n\r\n**Describe the documentation issue**\r\n* Correct links? No\r\n* Clear Description?  Yes\r\n* Usage Example? No\r\n* Parameters Defined? Yes\r\n* Returns defined? Yes\r\n* Raises listed and defined? No\r\n* Visuals, if applicable? No\r\n\r\nsame as #26492, #26532 documentation for tf.bitcast and tf.bitwise.* is created from a generated file, python/ops/gen_array_ops.py, and made incorrect link to source code.\r\nThe documentation can be modified by editing the appropriate .pbtxt files within the tensorflow/tensorflow/core/api_def/base_api directory of the source repository.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nyes"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: script built around docs\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: n/a\r\n- **TensorFlow installed from (source or binary)**: conda gpu version\r\n- **TensorFlow version (use command below)**: 1.10\r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**: n/a\r\n- **GCC/Compiler version (if compiling from source)**: n/a\r\n- **CUDA/cuDNN version**: 10\r\n- **GPU model and memory**: Quadro 16GiB\r\n- **Exact command to reproduce**: `ex.run()` (see comments below)\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nThis request comes with an associated [colab](https://colab.research.google.com/drive/1oJDfvIWnf7sY5uFcJ7XhTSEdA1n_3Jxv#scrollTo=8pqa0A7BUrG-)\r\n\r\nFurther, this documentation request stems from @walidk 's response on issue #26928 where \r\nit is suggested to shard the input matrix based on [wals_test.py](https://github.com/tensorflow/tensorflow/blob/f07558116ac7c90858cf0572a1bca1e50e208a37/tensorflow/contrib/factorization/python/ops/wals_test.py#L141)\r\n\r\nWhile the code is relevant, it is not necessarily clear how to apply it to the [colab](https://colab.research.google.com/drive/1oJDfvIWnf7sY5uFcJ7XhTSEdA1n_3Jxv#scrollTo=8pqa0A7BUrG-)\r\n\r\nWhy?\r\n\r\n\r\n1. there is `WALSModel` (used in the [colab](https://colab.research.google.com/drive/1oJDfvIWnf7sY5uFcJ7XhTSEdA1n_3Jxv#scrollTo=8pqa0A7BUrG-) ) and `WALSMatrixFactorization` (used in the linked test code). They seem the same, but what is the difference? Is that code compatible with `WALSModel`?\r\n\r\n2. both `WALSModel` and `WALSMatrixFactorization` have `num_row_shards=1` / `num_col_shards=1` as arguments. It is unclear if these would automatically shard the input matrix.\r\n\r\n3. as test code, it is not necessarily commented for pedagogical purposes\r\n\r\n4. as test code, it is not exactly a MWE demonstrating just what is needed to handle shard an input matrix and train accordingly. Should both rows and cols be sharded at the same time? \r\n\r\n5. part of the test code may work against the goal of sharding (or it is also likely I do not full understand it):\r\n\r\ne.g.\r\n\r\n```python\r\n....\r\n def _fn():\r\n      ...\r\n      sp_mat = self.np_array_to_sparse(np_matrix)\r\n      sp_mat_t = sparse_ops.sparse_transpose(sp_mat) #<--- if goal is to shard input matrix because it is too large, why make 2?\r\n      ...\r\n...\r\n```\r\n\r\nI understand that this request it is a bit of an \"advanced\"  documentation and that those contributing to TF are very busy - especially with v2. However I feel like this is a valid request as:\r\n\r\n1. the current documentation for `WALSModel` and `WALSMatrixFactorization` is already more than MWE including session supervisors (although leaning more towards pseudo code in some places which may make it more confusing than need be)\r\n\r\n2. the current documentation for the built in arguments `num_row_shards` / `col` state \"number of shards to use\", which gives no indication that the linked test code is even needed or where it should be introduced\r\n\r\n3. the current documentation hints at sharding (e.g. `transposed_matrix_slices_from_queue_for_worker_shard`) but assumes the user knows how to set that up.\r\n\r\n\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: v1.13.1\r\n- Doc Link: https://github.com/tensorflow/tensorflow/blob/v1.13.1/tensorflow/tools/graph_transforms/README.md#flatten_atrous_conv\r\n\r\n\r\n**Describe the documentation issue**\r\nThe `flatten_atrous_conv` section lists `Prerequisites: fold_constants`, whereas in the main paragraph, it says `You will need to make sure you run fold_constants after this transform.`\r\nSo should `fold_constants` be before or after `flatten_atrous_conv`?\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nI assume it's before `flatten_atrous_conv`, so I submitted a PR.\r\nhttps://github.com/tensorflow/tensorflow/pull/27145"
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 2.0.0-alpha.0\r\n- Doc Link: https://www.tensorflow.org/alpha/guide/keras/estimators\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\nIt's confusing since abundant guide stuff were uploaded, since no guide for custom estimator, just an example of using boostedClassifier\r\n\r\nIs tf.keras.Model replacing tf.estimator?\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 1.13\r\n- Doc Link: [tf.keras.losses.CategoricalCrossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy#class_categoricalcrossentropy)\r\n\r\n\r\n**Describe the documentation issue**\r\nIn the example code \r\n\r\n```\r\nloss = cce(\r\n    [[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]],\r\n    [[.9, .05, .05], [.5, .89, .6], [.05, .01, .94]])\r\n```\r\n\r\nI think the second array in the second line should be `[.05, .89, .06]` instead of `[.5, .89, .6]`, as they're supposed to be summed to one.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Anaconda on Windows 10\r\n- TensorFlow installed from (source or binary): install by pip in anaconda environment\r\n- TensorFlow version (use command below): tensorflow-gpu 2.0 alpha\r\n- Python version: 3.6.8\r\n- CUDA/cuDNN version: Cuda toolkit 10.0; cuDNN 7.5\r\n- GPU model and memory: GTX 980 Ti 6Gb\r\n\r\n\r\n**Describe the current behavior**\r\nI run the [transfer_learning.ipynb](https://github.com/tensorflow/docs/blob/master/site/en/r2/tutorials/images/transfer_learning.ipynb) tutorial on/r2 for Tensroflow 2.0 on Jupyter Notebook in Anaconda Windows 10 and I get the error on step:\r\n```\r\nSPLIT_WEIGHTS = (8, 1, 1)\r\nsplits = tfds.Split.TRAIN.subsplit(weighted=SPLIT_WEIGHTS)\r\n\r\n(raw_train, raw_validation, raw_test), metadata = tfds.load(\r\n    'cats_vs_dogs', split=list(splits),\r\n    with_info=True, as_supervised=True)\r\n```\r\n\r\n**Error**: \r\n```\r\n`Downloading / extracting dataset cats_vs_dogs (786.68 MiB) to C:\\Users\\Khoa\\tensorflow_datasets\\cats_vs_dogs\\2.0.0...\r\n\r\nDl Completed...: 0 url [00:00, ? url/s]\r\n\r\nDl Size...: 0 MiB [00:00, ? MiB/s]\r\n\r\n\r\n\r\n0 examples [00:00, ? examples/s]\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-7-2bc776459ab0> in <module>\r\n      4 (raw_train, raw_validation, raw_test), metadata = tfds.load(\r\n      5     'cats_vs_dogs', split=list(splits),\r\n----> 6     with_info=True, as_supervised=True)\r\n\r\nD:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow_datasets\\core\\api_utils.py in disallow_positional_args_dec(fn, instance, args, kwargs)\r\n     50     _check_no_positional(fn, args, ismethod, allowed=allowed)\r\n     51     _check_required(fn, kwargs)\r\n---> 52     return fn(*args, **kwargs)\r\n     53 \r\n     54   return disallow_positional_args_dec(wrapped)  # pylint: disable=no-value-for-parameter\r\n\r\nD:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow_datasets\\core\\registered.py in load(name, split, data_dir, batch_size, download, as_supervised, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs)\r\n    251   if download:\r\n    252     download_and_prepare_kwargs = download_and_prepare_kwargs or {}\r\n--> 253     dbuilder.download_and_prepare(**download_and_prepare_kwargs)\r\n    254 \r\n    255   if as_dataset_kwargs is None:\r\n\r\nD:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow_datasets\\core\\api_utils.py in disallow_positional_args_dec(fn, instance, args, kwargs)\r\n     50     _check_no_positional(fn, args, ismethod, allowed=allowed)\r\n     51     _check_required(fn, kwargs)\r\n---> 52     return fn(*args, **kwargs)\r\n     53 \r\n     54   return disallow_positional_args_dec(wrapped)  # pylint: disable=no-value-for-parameter\r\n\r\nD:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py in download_and_prepare(self, download_dir, download_config)\r\n    217         self._download_and_prepare(\r\n    218             dl_manager=dl_manager,\r\n--> 219             max_examples_per_split=download_config.max_examples_per_split)\r\n    220 \r\n    221         # NOTE: If modifying the lines below to put additional information in\r\n\r\nD:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py in _download_and_prepare(self, dl_manager, max_examples_per_split)\r\n    666       self._file_format_adapter.write_from_generator(\r\n    667           make_generator_fn(**split_generator.gen_kwargs),\r\n--> 668           output_files,\r\n    669       )\r\n    670 \r\n\r\nD:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow_datasets\\core\\file_format_adapter.py in write_from_generator(self, generator_fn, output_files)\r\n    105     wrapped = (\r\n    106         _dict_to_tf_example(d).SerializeToString() for d in generator_fn())\r\n--> 107     _write_tfrecords_from_generator(wrapped, output_files, shuffle=True)\r\n    108 \r\n    109   def dataset_from_filename(self, filename):\r\n\r\nD:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow_datasets\\core\\file_format_adapter.py in _write_tfrecords_from_generator(generator, output_files, shuffle)\r\n    270     with _close_on_exit(writers) as writers:\r\n    271       logging.info(\"Writing TFRecords\")\r\n--> 272       _round_robin_write(writers, generator)\r\n    273     # Shuffle each shard\r\n    274     if shuffle:\r\n\r\nD:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow_datasets\\core\\file_format_adapter.py in _round_robin_write(writers, generator)\r\n    283 def _round_robin_write(writers, generator):\r\n    284   \"\"\"Write records from generator round-robin across writers.\"\"\"\r\n--> 285   for i, example in enumerate(tqdm.tqdm(generator, unit=\" examples\")):\r\n    286     writers[i % len(writers)].write(example)\r\n    287 \r\n\r\nD:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tqdm\\_tqdm.py in __iter__(self)\r\n   1020                 \"\"\"), fp_write=getattr(self.fp, 'write', sys.stderr.write))\r\n   1021 \r\n-> 1022             for obj in iterable:\r\n   1023                 yield obj\r\n   1024                 # Update and possibly print the progressbar.\r\n\r\nD:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow_datasets\\core\\file_format_adapter.py in <genexpr>(.0)\r\n    104   def write_from_generator(self, generator_fn, output_files):\r\n    105     wrapped = (\r\n--> 106         _dict_to_tf_example(d).SerializeToString() for d in generator_fn())\r\n    107     _write_tfrecords_from_generator(wrapped, output_files, shuffle=True)\r\n    108 \r\n\r\nD:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py in generator_fn()\r\n    636 \r\n    637       def generator_fn():\r\n--> 638         for i, ex in enumerate(self._generate_examples(**kwargs)):\r\n    639           # Use the DatasetInfo FeaturesDict to encode the example. This allows\r\n    640           # the user's function to simply yield raw examples from the source\r\n\r\nD:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow_datasets\\image\\cats_vs_dogs.py in _generate_examples(self, archive)\r\n    104     if num_skipped != _NUM_CORRUPT_IMAGES:\r\n    105       raise ValueError(\"Expected % corrupt images, but found %d\" % (\r\n--> 106           _NUM_CORRUPT_IMAGES, num_skipped))\r\n    107     logging.warning(\"%d images were corrupted and were skipped\", num_skipped)\r\n\r\nValueError: Expected ۊorrupt images, but found 0`\r\n```\r\n\r\n\r\n**Describe the expected behavior**\r\nThe code run perfectly on my Jupyter Notebook - Anaconda server Ubuntu 16.04 and also on Colab.\r\nMy Jupyter notebook is 5.7.4 on both windows and ubuntu.\r\n\r\n"
  },
  {
    "labels": ["documentation", null],
    "text": "Run the following code:\r\n\r\n```\r\nimport os, logging\r\n\r\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\r\nlogging.getLogger(\"tensorflow\").setLevel(logging.CRITICAL)\r\nlogging.getLogger(\"tensorflow_hub\").setLevel(logging.CRITICAL)\r\n\r\nimport tensorflow as tf\r\nimport tensorflow_hub as hub\r\n\r\nprint(tf.contrib.util.constant_value(tf.ones([1])))\r\n```\r\nThen you will get the following warnings:\r\n```\r\n\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW0322 16:52:19.971889 139848381953792 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\r\n\r\nWARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\r\nFor more information, please see:\r\n  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\r\n  * https://github.com/tensorflow/addons\r\nIf you depend on functionality not listed there, please file an issue.\r\n\r\n```\r\n\r\nHow can I remove these disgusting messages?"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- OS Platform and Distribution : cenos7 \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no\r\n- TensorFlow installed from (source or binary): source code \r\n- TensorFlow version: 1.93\r\n- Python version: 3.6\r\n- Installed using virtualenv? pip? conda?: un installed virtualenv\r\n- Bazel version (if compiling from source): 0.22.0\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: no\r\n- GPU model and memory: no\r\n\r\n\r\n**Describe the documentation issue**\r\nIn centos, I downloaded the tensorflow project. I open '/root/tensorflow/tensorflow/core/framework/allocator.h' file,  Tips can not find thoese included files, such as 'tensorflow/core/framework/numeric_types.h' file not found.but those files are already exists. thanks \r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "**System information**\r\n- TensorFlow version: All\r\n- Doc Link: All the Python API documentation, for example: https://www.tensorflow.org/api_docs/python/tf/nn/conv2d_transpose\r\n\r\n**Describe the documentation issue**\r\nThe Python API documentation often points to the Python code (on github) where the operation is defined. For the example, for `tf.nn.conv2d_transpose()`, it links to [this code](https://www.tensorflow.org/code/stable/tensorflow/python/ops/nn_ops.py).\r\n\r\nUnfortunately, most operations are fairly thin wrappers around C++ operations, and since the link from Python to C++ is automatically generated (in this example, it's `gen_nn_ops.conv2d_backprop_input()`), it is not trivial to find the corresponding C++ code (the mapping is in Bazel code, really hard to find). Many people have been bothered by this problem, as you can see by searching for gen_nn_ops on StackOverflow, for example this question: https://stackoverflow.com/questions/41147734/looking-for-source-code-of-from-gen-nn-ops-in-tensorflow\r\n\r\nIt would be great if the documentation could point to both the Python function and the C++ operation. In this case, it would be https://www.tensorflow.org/versions/r2.0/api_docs/cc/class/tensorflow/ops/conv2-d-backprop-input and the source code is in [tensorflow/core/kernels/conv_grad_input_ops.cc](https://github.com/tensorflow/tensorflow/blob/94be8f012aa59730570bf71e6ba7cd2aa432a589/tensorflow/core/kernels/conv_grad_input_ops.cc#L265).\r\n\r\nTo find it, I had to search locally on my computer to find the `gen_nn_ops.py` file, and I found that `gen_nn_ops.conv2d_backprop_input()` just called the `Conv2DBackpropInput` operation. But then I had to go back to github to search for its C++ source code (since the TensorFlow binary does not include it), and it was tricky to find, since the C++ operation is also dynamically registered, so the actual name of the function is `Conv2DCustomBackpropInputOp`. Searching for `\"REGISTER_KERNEL_BUILDER  Conv2DBackpropInput\"` helps.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nI'm not sure where I could contribute this fix."
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version:2.0.0-alpha\r\n- Doc Link: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/dtypes/DType\r\n\r\n\r\n**Describe the documentation issue**\r\nThe documentation of TF 2.0 still mentions ```_ref``` types even though it is no longer a thing.\r\nRelated issue #26941.\r\n\r\n\r\n \r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nYes"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "**MobileNetV2** is a significant improvement over [MobileNetV1](https://research.googleblog.com/2017/06/mobilenets-open-source-models-for.html) and pushes the state of the art for mobile visual recognition including classification, object detection and semantic segmentation. It builds upon the ideas from MobileNetV1, using depthwise separable convolution as efficient building blocks. However, V2 introduces two new features to the architecture: \r\n\r\n1. Linear bottlenecks between the layers, and \r\n2. Shortcut connections between the bottlenecks1.\r\n\r\nThe research team's academic paper describes MobileNetV2 in detail: https://arxiv.org/abs/1801.04381.\r\n\r\nAn example of MobileNetV2 implemented with Slim can be found [here](https://colab.research.google.com/github/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet_example.ipynb).\r\n\r\nThe purpose of this issue is to migrate models into the TF 2.0 Keras API. Each migrated model must be eager and distribution compatible, with tests, and all associated engineering artifacts."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "[**BERT**, or Bidirectional Encoder Representations from Transformers](https://github.com/google-research/bert), is a new method of pre-training language representations which obtains state-of-the-art results on a wide array of Natural Language Processing (NLP) tasks.\r\n\r\nThe research team's academic paper describes BERT in detail and provides full results on a number of tasks: https://arxiv.org/abs/1810.04805.\r\n\r\nAn example of using BERT can be found [here](https://colab.sandbox.google.com/github/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb).\r\n\r\nThe purpose of this issue is to migrate models into the TF 2.0 Keras API. Each migrated model must be eager and distribution compatible, with tests, and all associated engineering artifacts."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "[**BERT**, or Bidirectional Encoder Representations from Transformers](https://github.com/google-research/bert), is a new method of pre-training language representations which obtains state-of-the-art results on a wide array of Natural Language Processing (NLP) tasks.\r\n\r\nThe research team's academic paper describes BERT in detail and provides full results on a number of tasks: https://arxiv.org/abs/1810.04805.\r\n\r\nAn example of using BERT can be found [here](https://colab.sandbox.google.com/github/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb).\r\n\r\nThe purpose of this issue is to migrate models into the TF 2.0 Keras API. Each migrated model must be eager and distribution compatible, with tests, and all associated engineering artifacts."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "**System information**\r\n- TensorFlow version: 2.0 alpha\r\n- Doc links: \r\n`tf.math` module-related, including:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/math/log\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/math/less\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/math/less_equal\r\n... and **many more** - a lot of endpoints mentioned below affected\r\n\r\n**Describe the documentation issue**\r\n\r\nSimilar to [26530](https://github.com/tensorflow/tensorflow/issues/26530), [25802](https://github.com/tensorflow/tensorflow/issues/25802), [25846](https://github.com/tensorflow/tensorflow/issues/25846)\r\n\r\n(May be similar to [26532](https://github.com/tensorflow/tensorflow/issues/26532) but has to do with `gen_math_ops.py` not `[math_ops.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/math_ops.py)`.)\r\n\r\n- **Incorrect links:**\r\nMissing links to ?non-existent `...python/ops/gen_math_ops.py`\r\n\r\nSince [1.10](https://github.com/tensorflow/tensorflow/blob/67a4cbbc7cacdbc33b2adb44f1b08b5a0dbc3186/RELEASE.md):\r\n```\r\nNew symbols have been added to the following modules: tf.debugging, tf.dtypes, tf.image, tf.io, tf.linalg, tf.manip, **tf.math**, tf.quantization, tf.strings\r\n```\r\n\r\n`...python/ops/gen_math_ops.py` has been referenced a bunch of times e.g. [here](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/math/log\r\n) but does not appear to exist or cannot be easily found. There are similar issues with examples, raises, etc for some if not all of the [following](https://github.com/tensorflow/tensorflow/blob/67a4cbbc7cacdbc33b2adb44f1b08b5a0dbc3186/RELEASE.md): \r\n```\r\nNew endpoints in tf.math module namespace: tf.math.acos, tf.math.acosh, tf.math.add, tf.math.asin, tf.math.asinh, tf.math.atan, tf.math.atan2, tf.math.atanh, tf.math.betainc, tf.math.ceil, tf.math.cos, tf.math.cosh, tf.math.digamma, tf.math.equal, tf.math.erfc, tf.math.exp, tf.math.expm1, tf.math.floor, tf.math.greater, tf.math.greater_equal, tf.math.igamma, tf.math.igammac, tf.math.invert_permutation, tf.math.less, tf.math.less_equal, tf.math.lgamma, tf.math.log, tf.math.log1p, tf.math.logical_and, tf.math.logical_not, tf.math.logical_or, tf.math.maximum, tf.math.minimum, tf.math.not_equal, tf.math.polygamma, tf.math.reciprocal, tf.math.rint, tf.math.rsqrt, tf.math.segment_max, tf.math.segment_mean, tf.math.segment_min, tf.math.segment_prod, tf.math.segment_sum, tf.math.sin, tf.math.sinh, tf.math.softplus, tf.math.softsign, tf.math.squared_difference, tf.math.tan, tf.math.unsorted_segment_max, tf.math.unsorted_segment_min, tf.math.unsorted_segment_prod, tf.math.unsorted_segment_sum, tf.math.zeta\r\n```\r\n\r\n- **Usage examples**\r\nNeeds examples for each of tf.math calculations e.g.\r\n`tf.math.log(42.)` returns\r\n```\r\n<tf.Tensor: id=5, shape=(), dtype=float32, numpy=3.7376697>\r\n```\r\n\r\n- **Raises**\r\nNot listed/defined. Obfuscated error from unexpected args (e.g. strings)\r\n\r\nE.g. `tf.math.log('hello log')` gives this long error message for a simple natural log calculation. As @dynamicwebpaige said [here](https://github.com/tensorflow/tensorflow/issues/25802) all tf.math.* operations and the operations they influence ... would experience these same obfuscated XLA errors.\r\n```\r\n---------------------------------------------------------------------------\r\nInternalError                             Traceback (most recent call last)\r\n<ipython-input-7-208ff95958ff> in <module>()\r\n----> 1 tf.math.log('hello log')\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py in log(x, name)\r\n   5327       try:\r\n   5328         return log_eager_fallback(\r\n-> 5329             x, name=name, ctx=_ctx)\r\n   5330       except _core._SymbolicException:\r\n   5331         pass  # Add nodes to the TensorFlow graph.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py in log_eager_fallback(x, name, ctx)\r\n   5376   _attrs = (\"T\", _attr_T)\r\n   5377   _result = _execute.execute(b\"Log\", 1, inputs=_inputs_flat, attrs=_attrs,\r\n-> 5378                              ctx=_ctx, name=name)\r\n   5379   _execute.record_gradient(\r\n   5380       \"Log\", _inputs_flat, _attrs, _result, name)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     64     else:\r\n     65       message = e.message\r\n---> 66     six.raise_from(core._status_to_exception(e.code, message), None)\r\n     67   except TypeError as e:\r\n     68     if any(ops._is_keras_symbolic_tensor(x) for x in inputs):\r\n\r\n/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)\r\n\r\nInternalError: Could not find valid device for node.\r\nNode: {{node Log}}\r\nAll kernels registered for op Log :\r\n  device='XLA_CPU'; T in [DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_BFLOAT16, DT_COMPLEX128, DT_HALF]\r\n  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_BFLOAT16, DT_COMPLEX128, DT_HALF]\r\n  device='CPU'; T in [DT_COMPLEX128]\r\n  device='CPU'; T in [DT_COMPLEX64]\r\n  device='CPU'; T in [DT_BFLOAT16]\r\n  device='CPU'; T in [DT_DOUBLE]\r\n  device='CPU'; T in [DT_HALF]\r\n  device='CPU'; T in [DT_FLOAT]\r\n [Op:Log]\r\n```\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nOk\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version:\r\n- Doc Link: https://www.tensorflow.org/guide/premade_estimators\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\nAll images were broken in guide pages.\r\nFor example:\r\nhttps://www.tensorflow.org/images/tensorflow_programming_environment.png\r\nin \r\nhttps://www.tensorflow.org/guide/premade_estimators\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "**System information**\r\n- TensorFlow version: 2.0 alpha\r\n- Doc Link: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/transpose\r\n\r\n**Describe the documentation issue**\r\n\r\n_Params:_ Minor thing - `tf.conj(tf.transpose(input))` should be formatted appropriately imho\r\n\r\n_Visuals:_ One would be useful\r\n\r\n_Raises:_ No raises listed/defined but would be useful for some folks\r\ne.g. Running this `tf.transpose([1, 2, 3], 262)` gives a long error because `perm` must be a vector\r\n```\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-19-357e79a92891> in <module>()\r\n----> 1 tf.transpose([1, 2, 3], 262)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py in transpose_v2(a, perm, conjugate, name)\r\n   1605     A transposed `Tensor`.\r\n   1606   \"\"\"\r\n-> 1607   return transpose(a=a, perm=perm, name=name, conjugate=conjugate)\r\n   1608 \r\n   1609 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py in transpose(a, perm, name, conjugate)\r\n   1693           ret.set_shape(input_shape[::-1])\r\n   1694     else:\r\n-> 1695       ret = transpose_fn(a, perm, name=name)\r\n   1696     return ret\r\n   1697 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py in transpose(x, perm, name)\r\n  10743       try:\r\n  10744         return transpose_eager_fallback(\r\n> 10745             x, perm, name=name, ctx=_ctx)\r\n  10746       except _core._SymbolicException:\r\n  10747         pass  # Add nodes to the TensorFlow graph.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py in transpose_eager_fallback(x, perm, name, ctx)\r\n  10780   _attrs = (\"T\", _attr_T, \"Tperm\", _attr_Tperm)\r\n  10781   _result = _execute.execute(b\"Transpose\", 1, inputs=_inputs_flat,\r\n> 10782                              attrs=_attrs, ctx=_ctx, name=name)\r\n  10783   _execute.record_gradient(\r\n  10784       \"Transpose\", _inputs_flat, _attrs, _result, name)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     64     else:\r\n     65       message = e.message\r\n---> 66     six.raise_from(core._status_to_exception(e.code, message), None)\r\n     67   except TypeError as e:\r\n     68     if any(ops._is_keras_symbolic_tensor(x) for x in inputs):\r\n\r\n/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)\r\n\r\nInvalidArgumentError: perm must be a vector, not [] [Op:Transpose] name: transpose/\r\n```\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the doc style guide) to fix the doc Issue?**\r\nWill try\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 2 alpha\r\n- Doc Link: N/A\r\n\r\n\r\n**Describe the documentation issue**\r\nHello, I'm in the process of porting some of our existing TF 1.x based code to be ready for TF 2.0. This means we are trying to be focused around tf.keras, so I was hoping for an example of the best way to do transfer learning in tf.keras. Specifically, we have the following (I assume common) use case.\r\n\r\n1. Train a model (say it's classification) with on dataset a, with 100 classes in the outputs.\r\n2. Finetune the model on dataset b, using the same architecture, also with 100 classes.\r\n3. Finetune the model on dataset c, which is the same except it has 50 classes, and thus the final layer has a different shape. So, we want to load all of the weights except the final layer,  and then train.\r\n\r\nIn TF 1.x, we used tf.estimator. For task 3, we would label the final layer with the name \"final_layer\", and then when warm-starting the models for finetuning, we would use the WarmstartSettings object to exclude weights that have final_layer in them. What is the equivalent for tf.keras in TF 2.x? Probably the cleanest way we could have the old functionality is if tf.keras.Model.load_weights had a regex field in the same form as WarmStartSettings, which only loaded a subset of variables.\r\n\r\nThanks!\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nI'm happy to write the docs if someone could give a high-level summary of how this is done. All the ways I've come up with are pretty jank, and I assume there is a better way to do this given how elegant it was in TF 1.X.\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version:\r\n- Doc Link: https://www.tensorflow.org/install/pip\r\n\r\n\r\n**Describe the documentation issue**\r\nIn the \"Install TensorFlow with pip\", section \"3. Install the TensorFlow pip package\", the sentence \"**tensorflow==2.0.0-alpha0-gpu** —Preview TF 2.0 Alpha build with GPU support (unstable, Ubuntu and Windows)\" is wrong.\r\nIt's should \"**tensorflow-gpu==2.0.0-alpha0**\" instead of \"**tensorflow==2.0.0-alpha0-gpu**\"\r\n\r\nBecause I can't install with \"pip install --upgrade tensorflow==2.0.0-alpha0-gpu\"\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): Experimental Micro-controller version\r\n- Are you willing to contribute it (Yes/No): Not now.\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\n**Will this change the current api? How?**\r\n\r\n**Who will benefit with this feature?**\r\n\r\n**Any Other info.**\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 1.7.1\r\n- Doc Link: - \r\n\r\n\r\n**Describe the documentation issue**\r\n\r\nUpdate the README.md file of Tensorflow Lite Android Example.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n\r\nYes."
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "https://www.tensorflow.org/alpha/tutorials/images/transfer_learning\r\nThis is the tutorial for transfer learning for tensorflow 2.0\r\nbut if you click on run on colab or view source on github buttons,\r\nthen the contents are not the same \r\n(colab link : https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb\r\ngithub link :\r\nhttps://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb\r\n)\r\n\r\nwhich one is the latest one and which one I should follow?\r\n\r\nThank you in advance!"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "\r\n**System information**\r\n- TensorFlow version: 2.0.0-alpha0\r\n- Doc Link: \r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/estimator/LinearEstimator\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/estimator/LinearClassifier\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/estimator/LinearRegressor\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\nThe examples in these documents use tf.train.FtrlOptimizer which is not available in TF2.0.\r\n```python\r\n# Or estimator using the FTRL optimizer with regularization.\r\nestimator = LinearRegressor(\r\n    feature_columns=[categorical_column_a,\r\n                     categorical_feature_a_x_categorical_feature_b],\r\n    optimizer=tf.train.FtrlOptimizer(\r\n      learning_rate=0.1,\r\n      l1_regularization_strength=0.001\r\n    ))\r\n```\r\n\r\nI tried to use tf.optimizers.Ftrl instead, but it gives the following error:\r\n\r\n```python\r\n# Or estimator using the FTRL optimizer with regularization.\r\nestimator = LinearRegressor(\r\n    feature_columns=[categorical_column_a,\r\n                     categorical_feature_a_x_categorical_feature_b],\r\n    optimizer=tf.optimizers.Ftrl(\r\n      learning_rate=0.1,\r\n      l1_regularization_strength=0.001\r\n    ))\r\n\r\nValueError: The given object is not an Optimizer instance. Given: <tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object\r\nat 0x1293a32b0>\r\n```\r\n\r\nI think the documentation should be updated, but I am not sure the correct way of defining optimizer. Could please someone take a look at this?\r\n\r\nThanks,"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "**System information**\r\n- TensorFlow version: 2.0 alpha\r\n- Doc Link: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/Tensor\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\nThe documentation of `tf.Tensor` in the 2.0 section is still about the `tf.Tensor` as a symbolic tensor that contains the result of a  `tf.Operation` and it states that the only way to get its value is to use a `tf.Session` to run the node.\r\n\r\nThis is no more the truth in tf2:\r\n\r\n- `tf.Session` is no more available\r\n- `tf.Tensor` holds the value of the computation and we can extract it using `.numpy()`.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n\r\nYes, I can submit a PR if needed - in the PR I can remove any reference to `tf.Session` and replace the introduction, explaining what is a `tf.Tensor` in Tensorflow 2.0."
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "**System information**\r\n\r\n> tensorflow-estimator-2.0-preview==1.14.0.dev2019031500\r\n> tensorflow-probability==0.5.0\r\n\r\n- Doc Link : https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/Graph\r\n\r\n**Describe the documentation issue**\r\nI believe for TF2 these docs can be more explicit that tf.Graph should not be used directly, and instead provide guidance similar to what Alex does in his talk\r\nhttps://www.youtube.com/watch?v=Up9CvRLIIIw\r\n\r\nThe wording that `A default Graph is always registered` is confusing in TF2 verbiage. and I believe the warning that the graph will not be executed eagerly should also be made more prominent, potentially by moving it up.\r\n\r\nThe confusion compounds because after using this method the user is left with a `tf.Tensor` but we're advised not to use `tf.Session` so it's not entirely clear what should be done next to evaluate the graph.\r\n\r\nSome of my confusion is visible in this thread (Big thanks to @brianwa84 for the help)\r\nhttps://github.com/pymc-devs/pymc4/pull/93#issuecomment-473490764 for reference\r\n\r\nThanks in advance!\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nIf I can get some help on how to word things correctly then yes\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "Many deprecated functions currently contain a notice such as\r\n```\r\nWarning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version. Instructions for updating: Use tf.data.experimental.ignore_errors().\r\n```\r\nIt would be really nice if the suggested replacement would actually link to the corresponding documentation."
  },
  {
    "labels": [null, "documentation"],
    "text": "**System information**\r\n- Have I written custom code: Yes\r\n- OS Platform and Distribution: Ubuntu 16.04\r\n- TensorFlow installed from: binary\r\n- TensorFlow version: `2.0.0.dev20190311`\r\n- Python version: 3.6.6\r\n- CUDA/cuDNN version: 10.0\r\n\r\n**Describe the current behavior**\r\n\r\nWhen using `tf.numpy_function`, a warning is logged about `tf.py_func` being deprecated.\r\n\r\n**Describe the expected behavior**\r\n\r\nAs a V2 symbol, `tf.numpy_function` should not produce a deprecation warning.\r\n\r\n**Code to reproduce the issue**\r\n\r\n```python\r\nimport tensorflow as tf\r\ntf.numpy_function(lambda x: x, [tf.zeros([5])], [tf.float32])\r\n```\r\n\r\n```text\r\nW0315 11:05:55.860109 139695358637824 deprecation.py:323] From /home/klein/dev/OpenNMT-tf/envv2/lib/python3.6/site-packages/tensorflow/python/ops/script_ops.py:476: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\ntf.py_func is deprecated in TF V2. Instead, there are two\r\n    options available in V2.\r\n    - tf.py_function takes a python function which manipulates tf eager\r\n    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\r\n    an ndarray (just call tensor.numpy()) but having access to eager tensors\r\n    means `tf.py_function`s can use accelerators such as GPUs as well as\r\n    being differentiable using a gradient tape.\r\n    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\r\n    (it is not differentiable, and manipulates numpy arrays). It drops the\r\n    stateful argument making all functions stateful.\r\n```"
  },
  {
    "labels": ["documentation", null],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 2.0.0-alpha0\r\n- Doc Link: \r\nhttps://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l02c01_celsius_to_fahrenheit.ipynb\r\nand \r\nhttps://classroom.udacity.com/courses/ud187/lessons/e0c70c77-5584-4f83-a47b-a67a6172ae75/concepts/fe91023e-9699-418a-8f4e-58c6acad1169\r\n\r\n\r\n**Describe the documentation issue**\r\nIf you try to execute this code in a python REPL, it fails at\r\n\r\n    tf.logging.set_verbosity(tf.logging.ERROR)\r\n\r\nwith \r\n\r\n    AttributeError: 'module' object has no attribute 'logging'\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n\r\nDepends on how you want it. As of https://www.tensorflow.org/versions/r2.0/api_docs/python/tf, it seems the logging API does not exist. Of the methods in https://stackoverflow.com/questions/35911252/disable-tensorflow-debugging-information, only \r\n\r\n    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \r\n\r\nworked.\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "\r\n**System information**\r\n- TensorFlow version: 2.0.0-alpha\r\n- Doc Link: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/image/resize_image_with_pad\r\n\r\n\r\n**Describe the documentation issue**\r\nThis is not available in 2.0.0 it is renamed as tf.image.resize_with_pad\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "Doc Link: https://www.tensorflow.org/js/tutorials/transfer/image-classification\r\n\r\nThe above link is broken.\r\n\r\n\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 1.13\r\n- Doc Link: https://www.tensorflow.org/api_guides/python/test\r\n\r\n\r\n**Describe the documentation issue**\r\n[Testing guide](https://www.tensorflow.org/api_guides/python/test) not exist which linked from [tf.test page](https://www.tensorflow.org/api_docs/python/tf/test).\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nI don't know if the page originally exists. 🤔 "
  },
  {
    "labels": [null, "documentation"],
    "text": "I run the [pix2pix_eager.ipynb](https://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/contrib/eager/python/examples/pix2pix/pix2pix_eager.ipynb) on colab. \r\n\r\nAt the step [training](https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/pix2pix/pix2pix_eager.ipynb#scrollTo=a1zZmKmvOH85):\r\n`train(train_dataset, EPOCHS)`\r\n\r\nThe error log: \r\n```\r\n---------------------------------------------------------------------------\r\nNotImplementedError                       Traceback (most recent call last)\r\n<ipython-input-22-d152560ca122> in <module>()\r\n----> 1 train(train_dataset, EPOCHS)\r\n\r\n<ipython-input-18-24e63cd58368> in train(dataset, epochs)\r\n      6 \r\n      7       with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\r\n----> 8         gen_output = generator(input_image, training=True)\r\n      9 \r\n     10         disc_real_output = discriminator(input_image, target, training=True)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    590       else:\r\n    591         # Eager execution on data tensors.\r\n--> 592         outputs = self.call(inputs, *args, **kwargs)\r\n    593         self._handle_activity_regularization(inputs, outputs)\r\n    594         return outputs\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)\r\n    862   def __call__(self, *args, **kwargs):\r\n    863     \"\"\"Calls a graph function specialized to the inputs.\"\"\"\r\n--> 864     graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\r\n    865     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n    866 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)\r\n   1174                 self._input_signature,\r\n   1175                 autograph=self._autograph,\r\n-> 1176                 arg_names=arg_names),\r\n   1177             self._function_attributes)\r\n   1178         if self._input_signature:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, add_control_dependencies, arg_names, op_return_value)\r\n    446         tf_decorator.rewrap(python_func, original_func, converted_func)\r\n    447 \r\n--> 448       func_outputs = python_func(*func_args, **func_kwargs)\r\n    449 \r\n    450       # invariant: `func_outputs` contains only Tensors, IndexedSlices,\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in bound_method_wrapper(*args, **kwargs)\r\n   1654     # If __wrapped__ was replaced, then it is always an unbound function\r\n   1655     # that takes self as first argument.\r\n-> 1656     return wrapped_fn(weak_instance(), *args, **kwargs)\r\n   1657 \r\n   1658   # pylint: disable=protected-access\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)\r\n    439                   strip_decorators=(def_function.function,),\r\n    440                   optional_features=(),\r\n--> 441               ), *args, **kwargs)\r\n    442 \r\n    443         # Wrapping around a decorator allows checks like tf_inspect.getargspec\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py in converted_call(f, owner, options, *args, **kwargs)\r\n    287       experimental_partial_types=partial_types)\r\n    288 \r\n--> 289   result = converted_f(*effective_args, **kwargs)\r\n    290 \r\n    291   # The converted function's closure is simply inserted into the function's\r\n\r\n/tmp/tmply9ws8vn.py in tf__call(self, x, training)\r\n      1 from __future__ import print_function\r\n      2 def tf__call(self, x, training):\r\n----> 3   x1 = ag__.converted_call('down1', self, ag__.converter.ConversionOptions(recursive=True, verbose=0, strip_decorators=(function, defun, ag__.convert, ag__.do_not_convert, ag__.converted_call), force_conversion=False, optional_features=(), internal_convert_user_code=True), x, training=training)\r\n      4   x2 = ag__.converted_call('down2', self, ag__.converter.ConversionOptions(recursive=True, verbose=0, strip_decorators=(function_1, defun_1, ag__.convert, ag__.do_not_convert, ag__.converted_call), force_conversion=False, optional_features=(), internal_convert_user_code=True), x1, training=training)\r\n      5   x3 = ag__.converted_call('down3', self, ag__.converter.ConversionOptions(recursive=True, verbose=0, strip_decorators=(function_2, defun_2, ag__.convert, ag__.do_not_convert, ag__.converted_call), force_conversion=False, optional_features=(), internal_convert_user_code=True), x2, training=training)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py in converted_call(f, owner, options, *args, **kwargs)\r\n    285       experimental_strip_decorators=options.strip_decorators,\r\n    286       experimental_verbose=options.verbose,\r\n--> 287       experimental_partial_types=partial_types)\r\n    288 \r\n    289   result = converted_f(*effective_args, **kwargs)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py in to_graph(entity, recursive, arg_values, arg_types, experimental_optional_features, experimental_strip_decorators, experimental_verbose, experimental_partial_types)\r\n    407       uncompiled_modules=config.DEFAULT_UNCOMPILED_MODULES)\r\n    408   _, name, namespace = conversion.entity_to_graph(entity, program_ctx,\r\n--> 409                                                   arg_values, arg_types)\r\n    410 \r\n    411   nodes = []\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/conversion.py in entity_to_graph(o, program_ctx, arg_values, arg_types)\r\n    137     node, name, ns = function_to_graph(o, program_ctx, arg_values, arg_types)\r\n    138   elif tf_inspect.ismethod(o):\r\n--> 139     node, name, ns = function_to_graph(o, program_ctx, arg_values, arg_types)\r\n    140   # TODO(mdan,yashkatariya): Remove when object conversion is implemented.\r\n    141   elif hasattr(o, '__class__'):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/conversion.py in function_to_graph(f, program_ctx, arg_values, arg_types, owner_type)\r\n    335       owner_type=owner_type)\r\n    336   context = converter.EntityContext(namer, entity_info, program_ctx)\r\n--> 337   node = node_to_graph(node, context)\r\n    338 \r\n    339   if isinstance(node, gast.Lambda):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/conversion.py in node_to_graph(node, context)\r\n    373   # TODO(mdan): Insert list_comprehensions somewhere.\r\n    374 \r\n--> 375   node = converter.standard_analysis(node, context, is_initial=True)\r\n    376   # Past this point, line numbers are no longer accurate so we ignore the\r\n    377   # source.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/core/converter.py in standard_analysis(node, context, is_initial)\r\n    469   # TODO(mdan): Consider not running all analyses every time.\r\n    470   # TODO(mdan): Don't return a node because it's modified by reference.\r\n--> 471   graphs = cfg.build(node)\r\n    472   node = qual_names.resolve(node)\r\n    473   node = activity.resolve(node, context.info, None)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/pyct/cfg.py in build(node)\r\n    819 def build(node):\r\n    820   visitor = AstToCfg()\r\n--> 821   visitor.visit(node)\r\n    822   return visitor.cfgs\r\n\r\n/usr/lib/python3.6/ast.py in visit(self, node)\r\n    251         method = 'visit_' + node.__class__.__name__\r\n    252         visitor = getattr(self, method, self.generic_visit)\r\n--> 253         return visitor(node)\r\n    254 \r\n    255     def generic_visit(self, node):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/pyct/cfg.py in visit_FunctionDef(self, node)\r\n    672     self._process_basic_statement(node.args)\r\n    673     for stmt in node.body:\r\n--> 674       self.visit(stmt)\r\n    675 \r\n    676     self.builder.exit_section(node)\r\n\r\n/usr/lib/python3.6/ast.py in visit(self, node)\r\n    251         method = 'visit_' + node.__class__.__name__\r\n    252         visitor = getattr(self, method, self.generic_visit)\r\n--> 253         return visitor(node)\r\n    254 \r\n    255     def generic_visit(self, node):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/pyct/cfg.py in visit_With(self, node)\r\n    814       self._process_basic_statement(item)\r\n    815     for stmt in node.body:\r\n--> 816       self.visit(stmt)\r\n    817 \r\n    818 \r\n\r\n/usr/lib/python3.6/ast.py in visit(self, node)\r\n    251         method = 'visit_' + node.__class__.__name__\r\n    252         visitor = getattr(self, method, self.generic_visit)\r\n--> 253         return visitor(node)\r\n    254 \r\n    255     def generic_visit(self, node):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/pyct/cfg.py in visit_If(self, node)\r\n    727     self.builder.new_cond_branch(node)\r\n    728     for stmt in node.body:\r\n--> 729       self.visit(stmt)\r\n    730 \r\n    731     self.builder.new_cond_branch(node)\r\n\r\n/usr/lib/python3.6/ast.py in visit(self, node)\r\n    251         method = 'visit_' + node.__class__.__name__\r\n    252         visitor = getattr(self, method, self.generic_visit)\r\n--> 253         return visitor(node)\r\n    254 \r\n    255     def generic_visit(self, node):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/pyct/cfg.py in visit_With(self, node)\r\n    814       self._process_basic_statement(item)\r\n    815     for stmt in node.body:\r\n--> 816       self.visit(stmt)\r\n    817 \r\n    818 \r\n\r\n/usr/lib/python3.6/ast.py in visit(self, node)\r\n    251         method = 'visit_' + node.__class__.__name__\r\n    252         visitor = getattr(self, method, self.generic_visit)\r\n--> 253         return visitor(node)\r\n    254 \r\n    255     def generic_visit(self, node):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/pyct/cfg.py in visit_If(self, node)\r\n    731     self.builder.new_cond_branch(node)\r\n    732     for stmt in node.orelse:\r\n--> 733       self.visit(stmt)\r\n    734 \r\n    735     self.builder.exit_cond_section(node)\r\n\r\n/usr/lib/python3.6/ast.py in visit(self, node)\r\n    251         method = 'visit_' + node.__class__.__name__\r\n    252         visitor = getattr(self, method, self.generic_visit)\r\n--> 253         return visitor(node)\r\n    254 \r\n    255     def generic_visit(self, node):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/pyct/cfg.py in visit_Try(self, node)\r\n    800     if node.handlers:\r\n    801       # TODO(mdan): Should we still support bare try/except? Might be confusing.\r\n--> 802       raise NotImplementedError('exceptions are not yet supported')\r\n    803 \r\n    804     self._exit_lexical_scope(node)\r\n\r\nNotImplementedError: exceptions are not yet supported\r\n```\r\n\r\n\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 1.12.0\r\n- Doc Link: https://www.tensorflow.org/guide/graphs\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\nOn the documentation an example was given using tf.zeroes().\r\n\r\nHowever, the module 'tensorflow' has no attribute 'zeroes'. \r\n\r\n```\r\nwith tf.device(\"/job:ps/task:0\"):\r\n  weights_1 = tf.Variable(tf.truncated_normal([784, 100]))\r\n  biases_1 = tf.Variable(tf.zeroes([100]))\r\n\r\nwith tf.device(\"/job:ps/task:1\"):\r\n  weights_2 = tf.Variable(tf.truncated_normal([100, 10]))\r\n  biases_2 = tf.Variable(tf.zeroes([10]))\r\n\r\nwith tf.device(\"/job:worker\"):\r\n  layer_1 = tf.matmul(train_batch, weights_1) + biases_1\r\n  layer_2 = tf.matmul(train_batch, weights_2) + biases_2\r\n```\r\nThe documentation should use tf.zeros() instead\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nyes"
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 1.13.1\r\n- Doc Link: https://www.tensorflow.org/api_docs/python/tf/contrib/predictor/from_saved_model https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/saved_model/load https://www.tensorflow.org/alpha/guide/keras/saving_and_serializing\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\nOn using `tf.contrib.predictor.from_saved_model` to get predictions from a saved_model, the warning message says that there _will_ be a new function to load saved models in TensorFlow 2.0, and nothing else.\r\n\r\nSpecifically, consider the following snippet of code (from https://colab.research.google.com/github/suyash/transformer/blob/master/imdb_sentiment_demo.ipynb)\r\n\r\n```py\r\np = predictor.from_saved_model(\r\n    export_dir, \r\n    input_names={\"input_text\": \"input_text:0\"}, \r\n    output_names={\r\n        \"prediction\": \"dense/Softmax:0\",\r\n        \"attention_0\": \"attention/attention_weights:0\",\r\n        \"attention_1\": \"attention_1/attention_weights:0\",\r\n    },\r\n)\r\noutputs = p({\"input_text\": inputs})\r\nprint(outputs[\"prediction\"])\r\nprint(outputs[\"attention_0\"])\r\nprint(outputs[\"attention_1\"])\r\n```\r\n\r\nThis prints the following warning message\r\n\r\n```\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/predictor/saved_model_predictor.py:153: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nThis function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\r\n```\r\n\r\nI have trying to figure out extracting multiple outputs from the same saved model. The current guide for saved models at alpha (https://www.tensorflow.org/alpha/guide/keras/saving_and_serializing) does not provide information on loading, while the equivalent for stable (https://www.tensorflow.org/guide/saved_model) does.\r\n\r\nI am trying to use the new `tf.saved_model.load` function. I have prepared a demo for my use-case at https://colab.research.google.com/gist/suyash/2c7e5b77ea4d94d5c3b8c3e178d06878. Specifically, I create a model with dense layers, convert it to an estimator, trained it while defining an `Exporter` for evaluation checkpoints.\r\n\r\nNow, when I load using the new function, I am able to obtain values for the `dense_2` tensor, however in an equivalent scenario, how do I get the values of the `dense_1` tensor in the current approach. As I show in my predictor example, the output of the predictor will have 3 keys, \"prediction\", \"attention_0\" and \"attention_1\". How do I get the output of the \"dense_1\" tensor in my 2.0 example?\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n"
  },
  {
    "labels": [null, null, null, null, "documentation"],
    "text": "**System information**\r\n- Uses a basic CNN MNIST Keras example\r\n- CentOS7\r\n- TensorFlow installed from: Anaconda\r\n- TensorFlow version: Both 1.12-gpu and 2.0.0-alpha0-cpu\r\n- Python version: 3.6\r\n\r\n**Describe the current behavior**\r\n* When using a \"built in\" loss function, the \"accuracy\" metric is **automatically** resolved to the \"correct one\".\r\n* When using a custom loss function that \"touches\" `y_pred` and `y_true` in any way (even trivially as seen below), \"accuracy\" is no longer automatically resolved.\r\n\r\n**Preamble:**\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow.keras.backend as K\r\nfrom tensorflow.keras import datasets, layers, models\r\n\r\n(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\r\n\r\ntrain_images = train_images.reshape((60000, 28, 28, 1))\r\ntest_images = test_images.reshape((10000, 28, 28, 1))\r\n\r\n# Normalize pixel values to be between 0 and 1\r\ntrain_images, test_images = train_images / 255.0, test_images / 255.0\r\n```\r\n\r\n**\"Working\" Example:**\r\n```\r\ndef customLoss1():\r\n    return tf.keras.losses.sparse_categorical_crossentropy\r\nmodel = models.Sequential()\r\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\r\nmodel.add(layers.MaxPooling2D((2, 2)))\r\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\r\nmodel.add(layers.MaxPooling2D((2, 2)))\r\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\r\nmodel.add(layers.Flatten())\r\nmodel.add(layers.Dense(64, activation='relu'))\r\nmodel.add(layers.Dense(10, activation='softmax'))\r\n\r\nmodel.compile(loss=customLoss1(), optimizer='adam', metrics=['accuracy',])\r\nmodel.fit(train_images, train_labels, epochs=1)\r\n```\r\n\r\n**\"Broken\" Example:**\r\n```\r\ndef customLoss2(y_true, y_pred):\r\n    return K.sparse_categorical_crossentropy(y_true, y_pred)\r\n\r\nmodel = models.Sequential()\r\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\r\nmodel.add(layers.MaxPooling2D((2, 2)))\r\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\r\nmodel.add(layers.MaxPooling2D((2, 2)))\r\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\r\nmodel.add(layers.Flatten())\r\nmodel.add(layers.Dense(64, activation='relu'))\r\nmodel.add(layers.Dense(10, activation='softmax'))\r\n\r\nmodel.compile(loss=customLoss2(), optimizer='adam', metrics=['accuracy',])\r\nmodel.fit(train_images, train_labels, epochs=1)\r\n```\r\n\r\n**Describe the expected behavior**\r\nI am not sure if this is intended, a bug, or a reasonable failure. \r\n\r\n**Broken Example Now Works:**\r\nIn order to get the \"Broken\" exmaple to \"work\" correctly, you have to specify the correct accuracy metric directly:\r\n\r\n```\r\nmodel = models.Sequential()\r\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\r\nmodel.add(layers.MaxPooling2D((2, 2)))\r\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\r\nmodel.add(layers.MaxPooling2D((2, 2)))\r\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\r\nmodel.add(layers.Flatten())\r\nmodel.add(layers.Dense(64, activation='relu'))\r\nmodel.add(layers.Dense(10, activation='softmax'))\r\n\r\nmodel.compile(loss=customLossWorks(), optimizer='adam', metrics=['sparse_categorical_accuracy'])\r\nmodel.fit(train_images, train_labels, epochs=1)\r\n```\r\n\r\n**Other info / logs**\r\n* This was originally posted under #26490 but @timudk helped clarify my problem so I reposted as a separate issue."
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "Was going through the Jupyter notebook on TFP that was associated with the TF Dev Summit:\r\n\r\nhttps://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/Probabilistic_Layers_Regression.ipynb\r\nRun\r\n\r\nRunning the line \r\n\r\n`import tensorflow.compat.v2 as tf`\r\n\r\nReturns the error:\r\n\r\n> ModuleNotFoundError: No module named 'tensorflow.compat.v2'\r\n\r\nRunning tf.VERSION shows it's 1.13. \r\n\r\nI'm assuming this is related to not having TF 2.0 installed, and only having T 1.13 installed.\r\nIs a separate, 2nd installation of TF (2.0) needed to import tensorflow.compat.v2 or can both be installed into the same virtual environment?\r\n\r\nJust want to make sure installing both alongside each other won't break either or both.\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n> b'unknown' 1.13.1\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version:  2.0\r\n- Doc Link: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/zeros_like\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\n- **Raises listed and defined**\r\n  No raises listed\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version:  2.0\r\n- Doc Link: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/zeros_initializer\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\n- **Raises listed and defined**\r\n  No raises listed\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version:  2.0\r\n- Doc Link: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/zeros\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\n- **Visuals, if Applicable**\r\n  No visuals are included.\r\n\r\n- **Raises listed and defined**\r\n  No raises listed\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version:  2.0\r\n- Doc Link: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/unique\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\n- **Visuals, if Applicable**\r\n  No visuals are included.\r\n\r\n- **Raises listed and defined**\r\n  No raises listed\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version:  2.0\r\n- Doc Link: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/unstack\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\n- **Visuals, if Applicable**\r\n  No visuals are included.\r\n\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version:  2.0\r\n- Doc Link: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/argsort\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\n- **Usage example**\r\n  No usage example is provided.\r\n\r\n- **Visuals, if Applicable**\r\n  No visuals are included.\r\n\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version:  2.0\r\n- Doc Link: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/math/argmin\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\n- **Usage example**\r\n  No usage example is provided.\r\n\r\n- **Visuals, if Applicable**\r\n  No visuals are included.\r\n\r\n- **Raises listed and defined**\r\n  No raises listed\r\n\r\nMuch like #26530, documentation for tf.math.argmin is created from a generated file ``python/ops/gen_math_ops.py``; a link to the file that generates ``python/ops/gen_math_ops.py`` would be handy for users.\r\n\r\nRelated files to be updated: ``tensorflow/core/api_def/base_api/api_def_ArgMin.pbtxt``, ``/tensorflow/core/ops/math_ops.cc``\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "\r\n**System information**\r\n- TensorFlow version:\r\n- Doc Link: https://tensorflow.google.cn/tutorials/keras/basic_classification#preprocess_the_data\r\n\r\n**Describe the documentation issue**\r\nplt.show()  missing\r\n\r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version:  2.0\r\n- Doc Link: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/math/argmax\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\n- **Usage example**\r\n  No usage example is provided.\r\n\r\n- **Visuals, if Applicable**\r\n  No visuals are included.\r\n\r\n- **Raises listed and defined**\r\n  No raises listed\r\n\r\nMuch like #25802, documentation for tf.math.argmax is created from a generated file ``python/ops/gen_math_ops.py``; a link to the file that generates ``python/ops/gen_math_ops.py`` would be handy for users.\r\n\r\nRelated files to be updated: ``tensorflow/core/api_def/base_api/api_def_ArgMax.pbtxt``, ``/tensorflow/core/ops/math_ops.cc``\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "**System information**\r\n- TensorFlow version: TF 2.0 Alpha\r\n- Doc Link: https://www.tensorflow.org/alpha/guide/distribute_strategy#examples_and_tutorials\r\n\r\n**Describe the documentation issue**\r\n\r\nThe second link (the `Tutorial` text shown below) in `Examples and Tutorials` section is missing:\r\n\r\n```text\r\n2. Tutorial to train Fashion MNIST with TPUStrategy (currently uses disable_eager_execution)\r\n```\r\n\r\n![image](https://user-images.githubusercontent.com/3454980/54072195-bdf7e180-42ba-11e9-9c09-3de5687cc016.png)\r\n\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "**System information**\r\n- TensorFlow version: 2.0 preview\r\n- Doc Link: [`tf.lookup.StaticHashTable`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/lookup/StaticHashTable#class_statichashtable)\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\nThe example usage describes using `StaticHashTable.init.run()`, which is not possible since there is no `init` attribute (and it's missing from the documentation). [This comment](https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/ops/lookup_ops.py#L321) in `lookup_ops.py` indicates that it's definitely not the correct way to initialize the table in TF 2.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n\r\nI don't think so, because I really have no idea what the correct way to initialize the table is :)\r\n\r\nI've tried a few things [as shown here](https://gist.github.com/zmjjmz/81138b0d62764fabe00085cd7091dd14#file-tokenize_layer_tf2-py-L50) but to no avail, usually ending in a `FailedPreconditionError` :(\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "**System information**\r\n- TensorFlow version: 2.0\r\n- Doc Links:\r\n   tf.math.atan: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/math/atan\r\n   tf.math.asin: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/math/asin\r\n\r\n**Describe the documentation issue**\r\nDocumentation for `tf.math.asin` and `tf.math.atan` is created from a generated file, `python/ops/gen_math_ops.py`. The documentation can be modified by editing the appropriate `.pbtxt` files within the `tensorflow/tensorflow/core/api_def/base_api` directory of the source repository.\r\n\r\nBoth of these math operations could use a clear description, usage examples, and a list specifying the errors raised by these operations.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nDefinitely :smile: "
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Notebook - Intro to CNNs (TF 2.0 Alpha tutorial - images): https://github.com/tensorflow/docs/blob/master/site/en/r2/tutorials/images/intro_to_cnns.ipynb\r\nIn the last cell there is a broken link (404): https://github.com/tensorflow/docs/blob/master/site/en/r2/tutorials/_index_/advanced.ipynb (\"_As you can see, our simple CNN has achieved a test accuracy of over 99%. Not bad for a few lines of code! For another style of writing a CNN (using the Keras Subclassing API and a GradientTape) head [here](https://github.com/tensorflow/docs/blob/master/site/en/r2/tutorials/_index_/advanced.ipynb)._\")"
  },
  {
    "labels": ["documentation"],
    "text": "\r\n\r\n**System information**\r\n- TensorFlow version: master\r\n- Doc Link: https://www.tensorflow.org/tutorials/sequences/recurrent#language_modeling\r\n\r\n**Describe the documentation issue**\r\n\r\n\r\nThe link <https://catalog.ldc.upenn.edu/ldc99t42> for \" Penn Tree Bank\" is no long accessible.\r\n\r\nThe correct URL might be https://catalog.ldc.upenn.edu/LDC99T42 , that is, upper cases for \"LDC99T42\"\r\n\r\n\r\n"
  },
  {
    "labels": [null, "documentation", null],
    "text": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):source\r\n- TensorFlow version (use command below):r1.13\r\n- Python version:3.6\r\n- Bazel version (if compiling from source):0.23\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:9.0/7.0\r\n- GPU model and memory:1080ti/11gb\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\ntensorflow/tensorflow/examples/label_image/main.cc\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\ni think the reason is \"TF_RETURN_IF_ERROR(env->NewRandomAccessFile(filename, &file));\"\r\nhttps://github.com/tensorflow/tensorflow/blob/5fad2f50d610fdb765f4f99c7e0531b7a3ddbe94/tensorflow/examples/label_image/main.cc#L100"
  },
  {
    "labels": [null, "documentation", null],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version:\r\n- Doc Link:\r\n\r\nsite/en/tutorials/load_data/images.ipynb\r\n\r\n*Describe the documentation issue**\r\nThe model fails to converge most of times. I changed the steps per epoch to run through all the data but it fails to converge. A lot of times just stuck in high loss low accuracy. \r\n\r\nI noted last layer output logits. It this expected?\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Previous, TF control flow primitives are Switch, Merge, Enter, NextIteration, and Exit, we can see them in a simple while_loop graph. Currently, in your r1.13 and r2.0 [docs](https://www.tensorflow.org/versions/r2.0/api_docs/cc/group/control-flow-ops), seems the control flow ops changed a lot, how could I see this ops in a graphdef? are they still in while_loop and cond?"
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version:\r\n- Doc Link: https://www.tensorflow.org\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\nNone of http://tensorflow.org  is working on Safari (latest macOS) for me; seems related to Service Worker. Works fine on Safari Technology Preview and on @googlechrome.\r\nMight have visited the page during the last 48h (pre-launch).\r\n\r\n![skjermbilde 2019-03-06 kl 23 11 45](https://user-images.githubusercontent.com/939844/53964361-81c45580-40ef-11e9-9812-d42291dfb970.png)\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nYes, if applicable."
  },
  {
    "labels": ["documentation"],
    "text": "**System information**\r\n- TensorFlow version: master\r\n- Doc Link: https://www.tensorflow.org/guide/saved_model\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\nThe link <https://www.tensorflow.org/tfx/guide/serving/serving_basic> for \"TensorFlow serving\" is no long available in the doc [Build and load a SavedModel](https://www.tensorflow.org/guide/saved_model#build_and_load_a_savedmodel)\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "In the \"sparse_softmax_cross_entropy_with_logits\" function inside tensorflow/python/ops/nn_ops.py, logits that are in fp16 are automatically upcasted to fp32. At the end of the function, the result is cast back down to fp16. \r\n\r\nThis functionality ought to be exposed in documentation and/or a warning. For users doing mixed precision training, the expected behavior would be that the entire loss (softmax + cross entropy) is done in fp16. \r\n\r\nRelevant lines:\r\n```\r\nlogits = ops.convert_to_tensor(logits)\r\nprecise_logits = math_ops.cast(logits, dtypes.float32) if (dtypes.as_dtype(\r\n\tlogits.dtype) == dtypes.float16) else logits\r\n...\r\ncost, _ = gen_nn_ops.sparse_softmax_cross_entropy_with_logits(\r\n\tprecise_logits, labels, name=name)\r\n```\r\n\r\nThanks so much.\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 1.12\r\n- Doc Link: https://www.tensorflow.org/install/source#tested_build_configurations\r\n\r\n\r\n**Describe the documentation issue**\r\nThe tested build configurations table does not supply adequate information for the user since it does not provide minor versions for the cuDNN and CUDA tested in the build.  Please add this information.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 2.0\r\n- Doc Link: https://www.tensorflow.org/install\r\n\r\n\r\n**Describe the documentation issue**\r\n[Link](https://drive.google.com/file/d/10G-wS5A_QQ1ma7YRLdCpUVmist-J3t-N/view?usp=sharing)\r\nAs seen in the .gif file in the link uploaded, the code container for \"Download a Package\" section isn't working correctly. On decreasing window size, the code container initially gets cut into half without a scroll feature and then gets completely deleted from the webpage.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nYes"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "- TensorFlow version: 1.13.1\r\n- Doc Link: https://www.tensorflow.org/install/gpu\r\n\r\nThe existing documentation on how to setup TensorFlow with docker&GPU is great. Unfortunately it doesn't work with Kubernetes. This [Kubernetes Engine GPUs](https://cloud.google.com/kubernetes-engine/docs/how-to/gpus) guide suggest using \"nvidia/cuda:10.0-runtime-ubuntu18.04\" docker image. TensorFlow docs suggest \"tensorflow/tensorflow:latest-gpu\". \r\n\r\nIdeally, we could use them both as base images, but that's of course impossible. \r\n\r\nThis of course depends also on which VM image you're using for the k8s nodes.\r\n\r\nIt would be great if the docs provide some some guidance on this setup. \r\n\r\nIt would be really awesome if a docker image compatible with one of k8s VM images was available containing both the necessary NVidia support for a k8s node and complete tensorflow-gpu package environment."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 2.0\r\n- Doc Link: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/activations/softmax\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\n* The softmax activation function is not described in detail, and there is no recommendation about when to use it.\r\n\r\n* There is no usage example.\r\n\r\n* The description of the returned value could be more useful.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n\r\nYes."
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 1.12\r\n- Doc Link: \r\nhttps://www.tensorflow.org/versions/r1.12/api_docs/python/tf/contrib/opt/AdamWOptimizer\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/opt/python/training/weight_decay_optimizers.py\r\n\r\n\r\n**Describe the documentation issue**\r\nIn `MomentumWOptimizer`, `AdamWOptimizer` and `DecoupledWeightDecayExtension` the documentation refers to `extend_with_weight_decay`:\r\n\r\n```python\r\n  extend_with_weight_decay(tf.train.MomentumOptimizer,\r\n                           weight_decay=weight_decay)\r\n  ```\r\nAFAIK there is no \"`extend_with_weight_decay`\", only \"`extend_with_decoupled_weight_decay`\", which seems to serve a similar purpose:\r\n\r\n```python\r\nMyAdamW = extend_with_decoupled_weight_decay(tf.train.AdamOptimizer)\r\n  # Create a MyAdamW object\r\n  optimizer = MyAdamW(weight_decay=0.001, learning_rate=0.001)\r\n```\r\nIs my understanding correct?\r\nI could submit a PR if necessary\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "**Type of breakage**: Breakage with changing code.\r\n\r\nAPIs that are affected: \r\n\r\n1. [`tf.train.GradientDescentOptimizer`](https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer)\r\n2. [`tf.train.MomentumOptimizer`](https://www.tensorflow.org/api_docs/python/tf/train/MomentumOptimizer)\r\n3. [`tf.train.RMSPropOptimizer`](https://www.tensorflow.org/api_docs/python/tf/train/RMSPropOptimizer)\r\n4. [`tf.train.AdamOptimizer`](https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer)\r\n5. [`tf.train.AdadeltaOptimizer`](https://www.tensorflow.org/api_docs/python/tf/train/AdadeltaOptimizer)\r\n6. [`tf.train.AdagradOptimizer`](https://www.tensorflow.org/api_docs/python/tf/train/AdagradOptimizer)\r\n7. [`tf.train.FtrlOptimizer`](https://www.tensorflow.org/api_docs/python/tf/train/FtrlOptimizer)\r\n\r\n**Side Note**: there are two extra `tf.contrib`-owned optimizers that will also have breaking changes: \r\n\r\n1. [`tf.contrib.opt.NadamOptimizer`](https://www.tensorflow.org/api_docs/python/tf/contrib/opt/NadamOptimizer)\r\n2. [`tf.contrib.opt.AdaMaxOptimizer`](https://www.tensorflow.org/api_docs/python/tf/contrib/opt/AdaMaxOptimizer)\r\n\r\n**Description of change**: The current endpoint `tf.train.xxxOptimizer()` is being deprecated in favor of `tf.keras.optimizers.xxx()`. Specifically:\r\n\r\n1. `tf.train.GradientDescentOptimizer(lr=???)` -> `tf.keras.optimizers.SGD(learning_rate=???)`\r\n2. `tf.train.MomentumOptimizer(lr=???, momentum=???)` -> `tf.keras.optimizers.SGD(learning_rate=???, momentum=???)`\r\n3. `tf.train.RMSPropOptimizer(lr=???)` -> `tf.keras.optimizers.RMSprop(learning_rate=???)`\r\n4. `tf.train.AdamOptimizer(lr=???, beta1=???, beta2=???)` -> `tf.keras.optimizers.Adam(learning_rate=???, beta_1=???, beta_2=???)`\r\n5. `tf.train.AdadeltaOptimizer(lr=???)` -> `tf.keras.optimizers.Adadelta(learning_rate=???)`\r\n6. `tf.train.AdagradOptimizer(lr=???)` -> `tf.keras.optimizers.Adagrad(learning_rate=???)`\r\n7. `tf.train.FtrlOptimizer(lr=???)` -> `tf.keras.Ftrl(learning_rate=???)`\r\n\r\nTensorFlow users of `tf.train.xxxOptimizer()` will be updated to `tf.keras.optimizers.xxx()`, and checkpoints from the old `tf.train.xxxOptimizer()` calls will no longer work.\r\n\r\n**Variable name change map**:  The `tf.keras.optimizers.xxx` weights are in different format than existing `tf.train.xxxOptimizer`. There isn't direct mapping for that.\r\n\r\n**Target time window**: Undecided since the update requires non-trivial user side change."
  },
  {
    "labels": [null, "documentation"],
    "text": "\r\n**System information**\r\n- Linux Ubuntu 18.04.2 LTS:\r\n- TensorFlow installed from Docker image: 1.13.1-gpu-py3-jupyter\r\n- TensorFlow version: Should be 1.13.1\r\n- Python version: From Docker, appears to be 3.5.2\r\n- Installed using pip: NA - don't get that far\r\n- Bazel version (if compiling from source): Missing in docker image?\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: cuda-10 from Docker image\r\n- GPU model and memory:\r\n\r\nprocessor       : 11\r\nvendor_id       : GenuineIntel\r\ncpu family      : 6\r\nmodel           : 44\r\nmodel name      : Intel(R) Core(TM) i7 CPU       X 980  @ 3.33GHz\r\nstepping        : 2\r\nmicrocode       : 0x13\r\ncpu MHz         : 1630.792\r\ncache size      : 12288 KB\r\nphysical id     : 0\r\nsiblings        : 12\r\ncore id         : 10\r\ncpu cores       : 6\r\napicid          : 21\r\ninitial apicid  : 21\r\nfpu             : yes\r\nfpu_exception   : yes\r\ncpuid level     : 11\r\nwp              : yes\r\nflags           : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx est tm2 ssse3 cx16 xtpr pdcm pcid sse4_1 sse4_2 popcnt aes lahf_lm epb pti tpr_shadow vnmi flexpriority ept vpid dtherm ida arat\r\nbugs            : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf\r\nbogomips        : 6675.50\r\nclflush size    : 64\r\ncache_alignment : 64\r\naddress sizes   : 36 bits physical, 48 bits virtual\r\npower management:\r\n\r\nTHE PROBLEM: The Docker image tensorflow/tensorflow:1.13.1-gpu-py3-jupyter doesn't build as per the instructions here:\r\n\r\nhttps://www.tensorflow.org/install/source#gpu_support_2\r\n\r\nUsing the tensorflow/tensorflow:1.13.1-gpu-py3-jupyter Docker image the build fails at the first step. (./configure) There's nothing in the /tensorflow directory.\r\n\r\nUsing the tensorflow/tensorflow:nightly-devel-gpu-py3 Docker image everything works fine and after being built tensorflow can be imported in python within the Docker container. In this image there is source code in /tensorflow.\r\n\r\nALSO, in this Docker container /usr/local/lib has only python3.5. In the nightly-devel-gpu-py image there is a bazel directory\r\n\r\n\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "Sorry if this is not exactly a documentation bug, but it is, for us, a big change in 1.13.1 that is not addressed in the release notes.\r\n\r\nI realize that tf.python was never part of the public API, but it used to be available, and after upgrading from 1.12, it isn't any longer.  The reason we need it is that it is heavily used internally by tensorflow code, and occasionally we need to \"vendor\" some of this code.  It would be really inconvenient to do this by maintaining our own fork of tensorflow; instead we just copied a python file from the tensorflow source into our repo and made the changes we needed.  Is there some way to keep doing this in 1.13.1 with minimal changes (i.e., not finding all the uses of tf.python and changing them to their public api equivalents)?  (Also, btw, why do the python parts of the Tensorflow source use tf.python so much in the first place?  Couldn't they just use the public api?)"
  },
  {
    "labels": [null, null, "documentation", null],
    "text": "**System information**\r\n- TensorFlow version: 1.13\r\n- Doc Link: https://www.tensorflow.org/api_docs/python/tf/nn/batch_normalization\r\n\r\n\r\n**Describe the documentation issue**\r\ntf.nn.batch_normalization can actually be used to implement layer_normalization or group_normalization as well. (https://github.com/tensorflow/addons/pull/14)  Therefore the name of the function is quite confusing since the \"batch normalization\" is more or less a special case of this function (when you feed the right mean and variance tensor). \r\n\r\nI think something like \"normalization()\" could work as well and would be less confusing.\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):n/a\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:n/a\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version (use command below):b'v1.13.0-rc2-0-gc865ec5621' 1.13.0-rc2\r\n- Python version:3.7\r\n- Bazel version (if compiling from source):n/a\r\n- GCC/Compiler version (if compiling from source):n/a\r\n- CUDA/cuDNN version:n/a\r\n- GPU model and memory:n/a\r\n\r\nThis is a follow up on https://github.com/tensorflow/tensorflow/issues/6720#issuecomment-468830039 about `tf.image.crop_and_resize`. (cc @martinwicke )\r\n\r\nSuppose I have an image that looks like this:\r\n```\r\n[[ 0.  1.  2.  3.  4.]\r\n [ 5.  6.  7.  8.  9.]\r\n [10. 11. 12. 13. 14.]\r\n [15. 16. 17. 18. 19.]\r\n [20. 21. 22. 23. 24.]]\r\n```\r\nI wanted to crop the 2x2 patch that contains `[[6, 7], [11, 12]]`, and upsample it to 4x4. I expect to get the following outputs:\r\n```\r\n[[ 4.5  5.   5.5  6. ]\r\n [ 7.   7.5  8.   8.5]\r\n [ 9.5 10.  10.5 11. ]\r\n [12.  12.5 13.  13.5]]\r\n```\r\nI think this is a reasonable expectation. The above output, is also what I got if I do \"resize_and_crop\" instead of `tf.image.crop_and_resize`, __after the fix__ https://github.com/tensorflow/tensorflow/commit/371c96df55a7b23eb8d8496fb477b473fd137fcc yesterday that addressed the alignment issues in resize op.\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport tensorflow.contrib.eager as tfe\r\ntfe.enable_eager_execution()\r\nfrom tensorflow.python.ops.image_ops_impl import resize_images_v2\r\narr = np.arange(25).astype('float32').reshape(5, 5)\r\ninput4D = tf.reshape(arr, [1, 5, 5, 1])\r\nresize = resize_images_v2(input4D, [10, 10], method='bilinear')[0,:,:,0]   # resize\r\nprint(resize[2:6,2:6])  # crop\r\n# print expected output\r\n```\r\n\r\nOK, what is the correct \"boxes\" I should provide for `crop_and_resize`, in order to get the above output?\r\nHere is what the document says:\r\n\r\n> boxes: A Tensor of type float32. A 2-D tensor of shape [num_boxes, 4]. The i-th row of the tensor specifies the coordinates of a box in the box_ind[i] image and is specified in normalized coordinates [y1, x1, y2, x2]. A normalized coordinate value of y is mapped to the image coordinate at y * (image_height - 1), so as the [0, 1] interval of normalized image height is mapped to [0, image_height - 1] in image height coordinates. We do allow y1 > y2, in which case the sampled crop is an up-down flipped version of the original image. The width dimension is treated similarly. Normalized coordinates outside the [0, 1] range are allowed, in which case we use extrapolation_value to extrapolate the input image values.\r\n\r\nIt turns out, that the correct \"boxes\" I should use, is: `[3/16, 3/16, 9/16, 9/16]`. If you cannot tell why it is 3/16 and 9/16 from the above documentation, you and I are on the same page:\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport tensorflow.contrib.eager as tfe\r\ntfe.enable_eager_execution()\r\n\r\n# want to crop 2x2 out of a 5x5 image, and resize to 4x4\r\nimage = np.arange(25).astype('float32').reshape(5, 5)\r\ntarget = 4\r\nprint(tf.image.crop_and_resize(\r\n    image[None, :, :, None],\r\n    np.asarray([[3/16,3/16,9/16,9/16]]), [0], [target, target])[0][:, :, 0])\r\n# print expected output\r\n```\r\n\r\nThis function has weird alignment issues like those fixed in #6720 . It's less of a problem than #6720 because at least we can provide some box coordinates to make it work as expected, and you can say it's just how this function is defined. \r\nThere is actually [a formula](https://github.com/tensorpack/tensorpack/blob/1cdd2e9efb6ffe3066a010e677ef9e76547faaa3/examples/FasterRCNN/modeling/model_box.py#L104-L135) that I use in my code to compute the coordinates in order to use this function. \r\n\r\nBut I do hope this function can have a better-defined behavior and fit reasonable expectation. In my experiments this ill-posed behavior actually hurt my models (which I believe also hurt other models like TF's object detection)."
  },
  {
    "labels": [null, null, null, null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 1.13.1\r\n- Doc Link: https://www.tensorflow.org/api_docs/python/tf/custom_gradient\r\n\r\nI've been having some difficulty using `custom_gradient` recently. Before implementing the op I actually have in mind, I'm trying to make a [simple polynomial op](https://gist.github.com/tsbertalan/b6c02bf6e39116d8446faa0159a011af) with `custom_gradient` in an effort to get my head around the requirements.. The documentation is not at all clear on how summing over batch and output indices should be done, and (until recently) wasn't clear on whether we should return the full *Jacobian* of the operation, or just the vector-Jacobian-product (\"VJP\") function. (I did notice some explanation of the latter issue made it in in the 1.12 -> 1.13 update, which was helpful).\r\n\r\nI think this problem applies both the derivative WRT the op's input, and WRT to the parameters (called `grad_xs` and `grad_vars` in the documentation). However, when I incorporated the VJP tidbit in my sample code, I got correct results for the former, but not the latter, I believe because the implicit sum over batch was already present in the supplied `grad_ys`, and because the VJP also collapses out the index across `grad_ys`.\r\n\r\nSo, the lack of clarity about sums (accidentally) only hit me when trying to write the `grad_vars` part. In my [gist linked above](https://gist.github.com/tsbertalan/b6c02bf6e39116d8446faa0159a011af), I had to use a `reduce_sum` when computing $dy/dp$, which, for a polynomial, is the corresponding powers of $x$. (Since $dy/dx$ doesn't depend on $x$, this issue didn't appear when writing the `grad_xs` part.)\r\n\r\nIn addition to simply saying what you mean in this documentation (the sum of the gradient over examples is not \"the gradient\"--only the per-example gradient truly deserves that name! But I suppose that particular fight is a lost cause.), it would be good if there were at least some examples that exercised the `grad_vars` part and the `variables=None` keyword argument."
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 2.0\r\n- Doc Link: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/activations/relu\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\n* The description is minimal, not written with complete sentences, and lacks recommendations of when and when not to use the symbol.\r\n\r\n* There is no usage example.\r\n\r\n* The parameters are described only briefly and with inconsistent capitalization.\r\n\r\n* The returned object description could be more useful.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n\r\nYes."
  },
  {
    "labels": ["documentation"],
    "text": "**System information**\r\n- TensorFlow version: N/A\r\n- Doc Link: https://www.tensorflow.org/\r\n\r\nMy locale is set to uk_UA. When I visit https://www.tensorflow.org/, the app_loader.js tries to load https://www.gstatic.com/devrel-devsite/v138ceba75b8052825cb18f1c6025ea06485e9d36137e0fd82d2d54619f803209/tensorflow/js/devsite_app__uk.js (notice the added '__uk' suffix). The file does not exist. Since devsite_app.js provides the main functionality, none of the links, buttons, and selectors that use JavaScript are operational. This includes the top nav bar, the side nav bar, and the search. It also makes it very hard to navigate to APIs and to browse the API pages. It is not possible to change the language, because the language drop-down is also using JavaScript.\r\n\r\nThe problem persists across different browsers (Firefox, Safari, Chrome, Vivaldi) and I assume it also affects other locales for which a localised devsite_app.js is not available (for instance, Belarusian be, Croatian hr, etc.)\r\n\r\nIdeally, the app_loader should check whether the localised version exists. If not, it should load the unlocalised version instead.\r\n\r\nI'm sorry if this is not the right place for the bug. However, it is directly related to the documentation and I could not find any other places to submit.\r\n"
  },
  {
    "labels": [null, null, null, null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n**System information**\r\n- TensorFlow version: 2.0\r\n- Doc Link: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras\r\n\r\n**Describe the documentation issue**\r\n\r\n**Links** \r\n\"Defined in python/keras/api/_v2/keras/__init__.py\" is pointing to a broken link:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/api/_v2/keras/__init__.py\r\n\r\n**Description**\r\nCurrently it has \"Detailed documentation and user guides are available at keras.io.\"\r\nIt would be better to point users to https://www.tensorflow.org/guide/keras, otherwise the experience feels broken.\r\n\r\nIt would be great to list some key differences between tf.keras vs Keras as an independent project (keras.io). Or at least point out there is no 1:1 mapping and what each one has and the other one doesn't have. This has been discussed in blog posts and forums but the official documentation should at least have a high level overview with a few sentences.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nYes\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "Hello,\r\n\r\nIt seems like CRF (tensorflow.contrib.crf) is moving to tensorflow/probability in TensorFlow 2.0. \r\n(https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md)\r\n\r\nbut, I couldn't find them on https://github.com/tensorflow/probability.\r\n \r\nWhere can I find CRF related features in TensorFlow 2.0?\r\n\r\n\r\n "
  },
  {
    "labels": [null, "documentation"],
    "text": "**Describe the feature and the current behavior/state.**\r\nA documentation explaining determinism and sources of non determinism in TF applications. It should cover things from having multiple readers, seeds in the specific ops, seed in numpy, PYTHONHASHSEED, non-deterministic ops in CUDA (and why TF does not support passing deterministic flag even though it would be slower), `TF_CUDNN_USE_AUTOTUNE`, and probably some others I do not know about.\r\n\r\n**Who will benefit with this feature?**\r\nI take part in many Kaggle competitions and very often people there have problems with non-determinism in NN. \r\n"
  },
  {
    "labels": ["documentation"],
    "text": "I'm updating to Tensorflow 1.13 from 1.12.\r\n\r\ntf.layers.batch_normalization is being deprecated.\r\n\r\nThe note states:\r\n\r\n```\r\nbatch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse keras.layers.batch_normalization instead.\r\n```\r\nFirst, there is no 'keras.layers.batch_normalization'. This is a 'keras.layers. BatchNormalization', but that is a different function and a direct replacement for 'tf.layers. BatchNormalization'.\r\n\r\nTherefore, either make a 'keras.layers. BatchNormalization' function or remove the deprecation warning for 'tf.layers.batch_normalization.\r\n\r\nHere's the link to the batch_normalization fuction.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.12/tensorflow/python/layers/normalization.py\r\n\r\nThanks,"
  },
  {
    "labels": [null, "documentation"],
    "text": "I'm updating to Tensorflow 1.13 from 1.12.\r\n\r\ntf.layers.conv2d is being deprecated.  \r\n\r\nThe note states:\r\n```\r\nconv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse keras.layers.conv2d instead.\r\n``` \r\n\r\nFirst, there is no 'keras.layers.conv2d'.  This is a 'keras.layers.Conv2D', but that is a different function and a direct replacement for 'tf.layers.Conv2D'.  \r\n\r\nTherefore, either make a 'keras.layers.conv2d' function or remove the deprecation warning for 'tf.layers.conv2d'.  \r\n\r\nHere's the link to the conv2d fuction.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.12/tensorflow/python/layers/convolutional.py\r\n\r\nThanks,\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "In the tensorflow 1.13 document of tf.layers.dense, there is a warning:\r\nWarning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version. Instructions for updating: Use keras.layers.dense instead.\r\n\r\nI am very confused, because this function is very easy to use, and I used it very frequently. Why do you deprecate it? \r\n\r\nBy the way, I did not find the alternative “keras.layers.dense”, there is only \"keras.layers.Dense\" "
  },
  {
    "labels": [null, "documentation"],
    "text": "**System information**\r\n- TensorFlow version: TF r1.12.0 if possible\r\n- Doc Link: N/A\r\n\r\n\r\n**Describe the documentation issue**\r\nI can't find any official tutorial on how to cross-compile Tensorflow on the main platforms other than the less-than-descriptive official tutorial to cross-compile for the Pi. I'm not sure if this is more of a Doc issue than a Feature request but I was looking for any help compiling for Ubuntu 16.04 from a Windows 10 machine. Since there are quite a bunch of error-prone steps to cross-compiling, as there are many options to configure and files to write in a specific way, I would really benefit from some guidance, even if minimal. There are a few tutorials on Medium, but those dont't target the same platforms and/or are old.\r\n\r\nIs this something that could be added to Tensorflow's website ?\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nNo, unless I manage to do it myself."
  },
  {
    "labels": ["documentation"],
    "text": "**System information**\r\n- TensorFlow version: from \r\n- Doc Link:\r\n\r\n\r\n**Describe the documentation issue**\r\nWhen I'm browsing the documentation, I often need to switch from TF 1.x to TF 2.0 or vice versa. Unfortunately, the context is lost when I do that.\r\nFor example, visit the `tf.constant` documentation for TF 2.0:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/constant\r\nThen from the drop down menu at the top (labeled \"API r2.0\"), select any TF 1.x version. Notice that you do not land on the `tf.constant` page.\r\nThe same is true in the reverse direction.\r\n\r\nThis also makes it hard to find TF 2.0 documentation by searching: I generally land on a TF 1.x page, when I switch to TF 2.0 the context is lost.\r\n\r\nOf course, many functions have been removed or moved, but this should not be a problem, since most of them are still available in `tf.compat.v1`.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nWhy not, but I would need someone to point me to the code that handles this."
  },
  {
    "labels": ["documentation"],
    "text": "**System information**\r\n- TensorFlow version: not important\r\n- Doc Link: https://www.tensorflow.org/tutorials/keras/basic_classification\r\n\r\n**Describe the documentation issue**\r\nWhen I was reading the Russian translation of this documentation page, I found a few places with not a natural way of using the Russian language(I'm a native Russian speaker), also I noticed a few small typo mistakes. I carefully read the whole page and compared with the original article on English and made some updates. The PR with these changes will be sent in the next couple of minutes after opening this issue. PR with updates: https://github.com/tensorflow/docs/pull/345"
  },
  {
    "labels": [null, "documentation"],
    "text": "**Windows 10\r\nTF Version: b'v1.11.0-rc2-4-gc19e29306c' 1.11.0\r\nAnaconda Python 3.6.5\r\nGPU: GeForce GTX 1070 Max-Q Design\r\nTensorflow 2.0 (gpu) preview installed via pip.**\r\n\r\nI'm building a [reinforcement learning framework](https://github.com/danaugrs/huskarl) on top of TensorFlow 2.0 using the `tf.keras` API and I've come across the following issue.\r\n\r\nThe 2.0 API docs for [`tf.keras.losses`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/losses) shows many objects that are not actually available in the preview package. For example the loss classes such as Huber. Hinge, etc... are not accessible.\r\n\r\n1. Why are those classes not included in the preview package?\r\n2. Why are there both classes and functions for many of the same loss types? That seems like unnecessary duplication.\r\n2a. Why is there a `Huber` class but no `huber` function?\r\n3. I'd love to contribute PRs and help fix these issues. Would that be desired?\r\n\r\nEdit: This has also been noticed here: https://github.com/tensorflow/tensorflow/issues/26007"
  },
  {
    "labels": [null, null, null, null, "documentation"],
    "text": "**Existing URLs containing the issue:**\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/applications/MobileNetV2\r\n\r\n**Description of issue (what needs changing):**\r\n- __Correct Links__:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/python/keras/applications/__init__.py is incorrect\r\nThe correct link should be:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/applications/__init__.py\r\n\r\n* __Clear Description__:\r\nThe description does not describe what this symbol does or when it should be \r\n\r\n* __Usage Example__:\r\nNo usage example is provided.\r\n\r\n* __Parameters Defined__:\r\nParameters are not defined.\r\n\r\n* __Returns Defined__:\r\nReturns are not defined.\r\n\r\n* __Raises Listed and Defined__:\r\nErrors are not listed or defined.\r\n\r\n* __Visuals, if Applicable__:\r\nNo visuals are included.\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "### Existing URLs containing the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/losses/poisson\r\n\r\n### Description of issue (what needs changing):\r\n* **Correct Links**\r\n  All links are correct.\r\n* **Clear Description**\r\n  Lacks a description.\r\n* **Usage Example**\r\n  No usage example is provided.\r\n* **Parameters Defined**\r\n  Parameters are not defined.\r\n* **Returns Defined**\r\n  Returns are not defined.\r\n* **Raises Listed and Defined**\r\n  Errors are not defined.\r\n* **Visuals, if Applicable**\r\n  No visuals are included, but may not be applicable anyway.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nI'd like to help, yes.😁\r\n"
  },
  {
    "labels": [null, null, null, null, "documentation"],
    "text": "### Existing URLs containing the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/image/non_max_suppression#aliases\r\n\r\n### Description of issue (what needs changing):\r\n\r\n* **Correct Links**\r\n  https://github.com/tensorflow/tensorflow/blob/master/python/ops/image_ops_impl.py is incorrect. The correct link should be https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/image_ops_impl.py.\r\n\r\n* **Clear Description**\r\n  The description is not opinionated about when to use this symbol and unclear how arguments effect the functionality.\r\n\r\n* **Usage Example**\r\n  Usage example is mixed into the description, not formatted and not self-contained\r\n\r\n* **Parameters Defined**\r\n  Parameters are defined correctly with expected formats.\r\n\r\n* **Returns Defined**\r\n  Returns are defined correctly with expected formats.\r\n\r\n* **Raises Listed and Defined**\r\n  Errors are not defined.\r\n\r\n* **Visuals, if Applicable**\r\n  No visuals are included."
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 1.12\r\n- Doc Link: https://youtu.be/FAMfy7izB6A?t=930\r\n\r\n\r\n**Describe the documentation issue**\r\nAndrew Selle showed off a cool demo, and said, \"I'm not an electrical engineer or mechanical engineer, so you can do this too.\" It's been 10.5 months. Maybe he forgot to release the code so that we can do that too? He also mentioned in the comment section that it would be released as a demo.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nI don't have access to the code in question\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n**System information**\r\n- TensorFlow version (you are using): Tensorflow Android 1.12.0\r\n- Are you willing to contribute it (Yes/No): No\r\n\r\n**Describe the feature and the current behavior/state.**\r\nI'm currently using a custom frozen model in .pb format for real-time face detection with Tensorflow Android. Everything is working fine except that the model is quite heavy and my app stops working from time to time. Logcat shows that the ActivityManager force closes my app, which I think is because it is using too many resources despite running in a different thread. Tensorflow Lite seems to be a good solution with continuous support and better performance. I want to migrate my existing solution to TFLite but I can't find any clear documentation on how to do so. The TensorFlowInferenceInterface methods and parameters are very different from Interpreter in TFLite. \r\n\r\nI followed the TFLiteObjectDetectionAPIModel samples for both Tensorflow Android and TFLite but I can't follow on the differences as someone who is not familiar with Tensorflow. Please provide documentation on how to migrate especially when you are deprecating Tensorflow Android already.\r\n\r\n**Will this change the current api? How?**\r\nI think no if there is proper documentation.\r\n\r\n**Who will benefit with this feature?**\r\nDevelopers currently using Tensorflow Android with performance issues\r\n\r\n**Any Other info.**\r\nNone"
  },
  {
    "labels": [null, null, null, null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 2.0\r\n- Doc Link: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/math/add\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\nMuch like #25802, documentation for `tf.math.add` is created from a generated file `python/ops/gen_math_ops.py`; a link to the file that generates `python/ops/gen_math_ops.py` would be handy for users.\r\n\r\n`tf.math.add` could use a usage example, and a list of Errors raised. \r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nYes"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "**System information**\r\n- TensorFlow version: 2.0\r\n- Doc Link: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/lite/TFLiteConverter\r\n\r\n**Describe the documentation issue**\r\n\r\n- **Links** (Fixed)\r\n\r\nIncorrect - https://github.com/tensorflow/tensorflow/blob/master/lite/python/lite.py\r\nCorrect - https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/python/lite.py\r\n\r\n- **Description** (In PR #26067) \r\n\r\nThis is used to convert from a TensorFlow \"GraphDef or SavedModel\" into either a TFLite FlatBuffer or graph visualization.\r\n\r\nShould be \"…GraphDef, Saved Model or tf.keras model…\"\r\n\r\n- **Usage example** (In PR #26067) \r\n\r\nThis line of code should be repeated for each of the methods\r\nopen(\"converted_model.tflite\", \"wb\").write(tflite_model)\r\n\r\n- **Parameters Defined** (Fixed)\r\n\r\nMissing 2 parameters\r\n- optimizations\r\n- representative_dataset\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?** \r\n\r\nYes"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "**System information**\r\n- TensorFlow version: 2.0\r\n- Doc Link: https://www.tensorflow.org/versions/r1.13/api_docs/python/tf/keras/activations/serialize\r\n* **Correct Links** https://github.com/tensorflow/tensorflow/blob/master/python/keras/activations.py is incorrect. The correct link should be https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/activations.py.\r\n* **Clear Description**\r\n  The description is not opinionated about when to use this symbol, or what happens when arguments are passed to the symbol.\r\n* **Usage Example**\r\n  No usage example is provided.\r\n* **Parameters Defined**\r\n  Parameters are poorly defined, and not formatted appropriately.\r\n* **Returns Defined**\r\n  Returns are not defined.\r\n* **Raises Listed and Defined**\r\n  Errors are not defined."
  },
  {
    "labels": [null, null, null, null, "documentation"],
    "text": "**System information**\r\n- TensorFlow version: 2.0\r\n- Doc Link: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/activations/tanh\r\n* **Correct Links** https://github.com/tensorflow/tensorflow/blob/master/python/keras/activations.py is incorrect. The correct link should be https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/activations.py.\r\n* **Clear Description**\r\n  No description of what the symbol does or what happens when arguments are passed to the symbol.\r\n* **Usage Example**\r\n  No usage example is provided.\r\n* **Parameters Defined**\r\n  Parameters are not defined.\r\n* **Returns Defined**\r\n  Returns are not defined.\r\n* **Raises Listed and Defined**\r\n  Errors are not defined."
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "\r\n**System information**\r\n- TensorFlow version: 2.0\r\n- Doc Link: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/compat/path_to_str\r\n\r\n### Existing URLs containing the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/compat/path_to_str\r\n\r\n### Description of issue (what needs changing):\r\n* **Correct Links**\r\n  https://github.com/tensorflow/tensorflow/blob/master/python/util/compat.py is incorrect. The correct link should be https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/util/compat.py.\r\n* **Clear Description**\r\n  There could be a description of use cases where using this symbol would be appropriate. \r\n* **Raises Listed and Defined**\r\n  Errors are not defined.\r\n* **Visuals, if Applicable**\r\nI do not think visuals are necessary for the symbol.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n"
  },
  {
    "labels": [null, null, null, null, "documentation"],
    "text": "**System information**\r\n- TensorFlow version: 2.0\r\n- Doc Link: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/math/add_n\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\n* **Links**\r\nhttps://github.com/tensorflow/tensorflow/blob/master/python/ops/math_ops.py\r\nshould be\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/math_ops.py\r\n\r\n* **Clear Description**\r\nThe description is not clear enough.  In the description, it should probably link to [tf.math.accumulate_n](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/math/accumulate_n) and explain when to use `tf.math.add_n`.\r\n\r\n* **Usage example**\r\nNo usage example is provided.\r\n\r\n* **Visuals, if Applicable**\r\n  No visuals are included.\r\n\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nYes.\r\n"
  },
  {
    "labels": [null, null, null, null, "documentation"],
    "text": "**System information**\r\n- TensorFlow version: 2.0\r\n- Doc Link: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/math/acos\r\n\r\n**Describe the documentation issue**\r\n\r\nDocumentation for `tf.math.acos` is created from a generated file, `python/ops/gen_math_ops.py`. It would be excellent to have a link to the files that are used to generate `gen_math_ops.py` - so a user could make modifications quickly, without having to search through `tensorflow/tensorflow`.\r\n\r\n`tf.math.acos` could use a clear description, usage examples, and example visuals. A great template to model this on could be [`numpy.arccos`](https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.arccos.html).\r\n\r\nUsers also experience obfuscated errors from unexpected arguments (ex: strings, Booleans, and even just `int`s). Some examples are shared below. The file used to generate this error is located [here](https://github.com/tensorflow/tensorflow/blob/e1d20b3b4f25047679cf34107f8d87329cc9070f/tensorflow/core/common_runtime/eager/execute.cc#L201). All `tf.math.*` operations and the operations they influence (e.g., `tf.linspace`) would experience these same obfuscated XLA errors.\r\n\r\n```\r\nInvalidArgumentError: Invalid cast from floating point type to S32 in ConstantR0WithType.\r\n\t [[{{node Acos}}]] [Op:Acos]\r\n```\r\n\r\n```\r\nInternalError: Could not find valid device for node.\r\nNode: {{node Acos}}\r\nAll kernels registered for op Acos :\r\n  device='XLA_CPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64, DT_INT64, DT_COMPLEX128, DT_HALF]\r\n  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64, DT_INT64, DT_COMPLEX128, DT_HALF]\r\n  device='CPU'; T in [DT_DOUBLE]\r\n  device='CPU'; T in [DT_FLOAT]\r\n [Op:Acos]\r\n```\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nI shall certainly try! :) \r\n"
  },
  {
    "labels": [null, null, null, null, "documentation"],
    "text": "### Existing URLs containing the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/AggregationMethod\r\n\r\n### Description of issue (what needs changing):\r\n\r\n* **Correct Links**\r\nhttps://github.com/tensorflow/tensorflow/blob/master/python/ops/gradients_util.py is incorrect. The correct link should be https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/gradients_util.py.\r\n\r\n* **Clear Description**\r\nThe description is not opinionated about when to use this symbol, and unclear on what aggregation methods for combining gradients would be useful for. \r\n\r\n* **Usage Example**\r\nNo usage example is provided.\r\n\r\n* **Parameters Defined**\r\nParameters are poorly defined, and not formatted appropriately.\r\n\r\n* **Returns Defined**\r\nReturns are not defined.\r\n\r\n* **Raises Listed and Defined**\r\nErrors are not defined.\r\n\r\n* **Visuals, if Applicable**\r\nNo visuals are included."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 1.12\r\n- Doc Link: https://www.tensorflow.org/api_docs/python/tf/norm\r\n\r\n\r\n**Describe the documentation issue**\r\nThere are no mathematical definitions of the norms. This may result in ambiguity and confusion (e.g. are they Schatten p-norms?).\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?** Not anytime soon, and in any case I would face said ambiguity and confusion."
  },
  {
    "labels": ["documentation"],
    "text": "in the website \"https://tensorflow.google.cn\",the experience of auto-scroll is so bad for  focusing on the content. I wish it could be improved. Thanks."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version: 1.13.0rc1\r\n- Python version: 3.7.1\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: 10 / 7.4.2\r\n- GPU model and memory: MX150 2GB\r\n\r\n**Describe the problem**\r\nTensorflow 1.13.0rc1 said the numpy requires >=1.13.3 (I had np 1.15.4) in setup.py but it only works with >=1.16.0. Either the setup.py is wrong or there is something wrong while building the wheel??\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n```py\r\nimport tensorflow\r\n```\r\n\r\n**Any other info / logs**\r\n```py\r\nPyBfloat16_Type.tp_base != nullptr\r\n```"
  },
  {
    "labels": [null, "documentation"],
    "text": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Linux Ubuntu 17.04**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **-**\r\n- TensorFlow installed from (source or binary): **Binary/Docker**\r\n- TensorFlow version: **???**\r\n- Python version: **2.7**, **3.5**\r\n- Installed using virtualenv? pip? conda?: **Docker**\r\n- Bazel version (if compiling from source): **-**\r\n- GCC/Compiler version (if compiling from source): **-**\r\n- CUDA/cuDNN version: **-**\r\n- GPU model and memory: **-**\r\n\r\nThe problem is that Docker [images](https://hub.docker.com/r/tensorflow/tensorflow/tags) with tags `1.13.0rc0` and `1.13.0rc0-py3` contains wrong version of `tensorflow`.\r\n\r\nJust to show:\r\n```\r\n$ docker run -it tensorflow/tensorflow:1.13.0rc0 bash\r\n\r\n________                               _______________                \r\n___  __/__________________________________  ____/__  /________      __\r\n__  /  _  _ \\_  __ \\_  ___/  __ \\_  ___/_  /_   __  /_  __ \\_ | /| / /\r\n_  /   /  __/  / / /(__  )/ /_/ /  /   _  __/   _  / / /_/ /_ |/ |/ / \r\n/_/    \\___//_/ /_//____/ \\____//_/    /_/      /_/  \\____/____/|__/\r\n\r\nroot@d1f1dd416bdd:/# pip show tensorflow\r\nDEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7.\r\nName: tensorflow\r\nVersion: 1.12.0\r\n```"
  },
  {
    "labels": [null, "documentation", null],
    "text": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.0 preview\r\n- Are you willing to contribute it (Yes/No): No\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nCould you please include small examples with the functions embedded in real code with the documentation?\r\n\r\n**Will this change the current api? How?**\r\nMake the usage more elucidate.\r\n\r\n**Who will benefit with this feature?**\r\nAll the new and intermediate users.\r\n\r\n**Any Other info.**\r\nFor example, you can see this documentation API doc: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/audio/decode_wav\r\n\r\nThis is the function call, but there isn't any boilerplate code to show the sequence of its usage.  This is just one example.  All the function call should be similar."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NO\r\n- TensorFlow installed from (source or binary): Anaconda\r\n- TensorFlow version (use command below): 1.12.0\r\n- Python version: 3.5.0\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\nreference: https://www.tensorflow.org/api_docs/python/tf/keras/initializers/glorot_normal\r\n\r\nAccording to reference, it draws samples from a truncated normal distribution centered on 0 with stddev = sqrt(2 / (fan_in + fan_out)) where fan_in is the number of input units in the weight tensor and fan_out is the number of output units in the weight tensor.\r\n\r\nI generated them with fan_in = 100, fan_out = 100 and ploted their histogram. I printed out the smallest and largest from the sampe and I got -0.22728574 0.22735965. These should be 2!\r\n\r\n**Describe the expected behavior**\r\n\r\nI generated them with fan_in = 100, fan_out = 100 and ploted their histogram. I printed out the smallest and largest from the sampe and I got -0.22728574 0.22735965. These should be 2!\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nimport tensorflow as tf\r\n\r\nfan_in = 100\r\nfan_out = 100\r\n\r\ntf.random.set_random_seed(337)\r\n\r\nW = tf.get_variable(\"W\", \\\r\n                    shape=(fan_in, fan_out), \\\r\n                    initializer=tf.keras.initializers.glorot_normal)\r\n\r\nsigma = np.sqrt(2 / (fan_in + fan_out))\r\n\r\nwith tf.Session() as sess:\r\n    tf.global_variables_initializer().run()\r\n    \r\n    W_now = sess.run(W)\r\n    \r\n    plt.hist(W_now.reshape((-1,)), bins=100)\r\n    plt.show()\r\n    \r\n    print(2*sigma)\r\n    print(np.min(W_now.reshape((-1,))), np.max(W_now.reshape((-1,))))\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 1.12.0\r\n- Doc Link: https://www.tensorflow.org/guide/performance/overview\r\n\r\n\r\n**Describe the documentation issue**\r\nA minor nit, i the performance overview page change /Alexne**x**/Alexne**t**/\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nyes\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 1.12\r\n- Doc Link: https://www.tensorflow.org/api_docs/python/tf/layers/Dense\r\n\r\n\r\n**Describe the documentation issue**\r\n`reuse` is no longer a valid argument, and should be replaced with `_reuse` instead. Passing reuse to Dense will cause the following error:\r\n\r\n```python\r\nTypeError: ('Keyword argument not understood:', 'reuse')\r\n```\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "When training model that need specific update such as batch norm mean and variance, it is not clear \r\nfrom the current version of documentations how we can handle this. \r\n\r\nThis docs https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model suggests that we have to call `model.updates`\r\n\r\nWhile here https://github.com/tensorflow/docs/blob/master/site/en/r2/tutorials/generative/dcgan.ipynb there's nothing about `model.updates`\r\n\r\n**System information**\r\n- TensorFlow version: 2.0-preview\r\n"
  },
  {
    "labels": [null, "documentation", null],
    "text": "**[TensorFlow Extended (TFX)](https://www.tensorflow.org/tfx/)** is an end-to-end, TensorFlow-based, general-purpose machine learning platform implemented at Google. We've already open sourced some TFX libraries with the rest of the system to come. For an overview of TFX, read our [KDD’2017 paper](https://dl.acm.org/citation.cfm?id=3098021) and watch the [Dev Summit talk](https://www.youtube.com/watch?v=vdG7uKQ2eKk).\r\n\r\nTFX includes:\r\n- **[TensorFlow Data Validation](https://www.tensorflow.org/tfx/data_validation)**: a library for exploring and validating machine learning data.\r\n- **[TensorFlow Transform](https://www.tensorflow.org/tfx/transform)**: full-pass analyses over data to create transformation graphs that are consistently applied during training and serving.\r\n- **[TensorFlow Model Analysis](https://www.tensorflow.org/tfx/model_analysis)**: libraries and visualization components to compute full-pass and sliced model metrics over large datasets, and analyze them in a notebook.\r\n- **[TensorFlow Serving](https://www.tensorflow.org/serving)**: a flexible, high-performance serving system for machine learning models, designed for production environments.\r\n\r\nThe purpose of this issue is to track the creation of an end-to-end TFX example using TensorFlow 2.0: a Keras model working with Transform, TFMA, data validation, and Serving."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Documentation and tutorials are a critical piece of every open-source project, and a developer's first impression of the product. The purpose of this issue will be to track the creation, migration, and translations for TensorFlow 2.0 docs.\r\n\r\nFor more information, check out the example notebooks we have available [here](https://github.com/tensorflow/docs/tree/master/site/en/r2), as well as the [TF 2.0 upgrade guide](https://github.com/tensorflow/docs/blob/master/site/en/r2/guide/upgrade.md) and the [Effective 2.0 Style Guide](https://github.com/tensorflow/docs/blob/master/site/en/r2/guide/effective_tf2.md).\r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "**[TensorFlow Datasets (TFDS)](https://www.tensorflow.org/datasets/api_docs/python/tfds)** is a collection of datasets ready-to-use with TensorFlow. Each dataset is defined as a `tfds.core.DatasetBuilder`, which encapsulates the logic to download the dataset and construct an input pipeline, as well as contains the dataset documentation (version, splits, number of examples, etc.).\r\n\r\nThe purpose of this issue is to migrate all tutorials to use TensorFlow Datasets, and to be compliant with the TF 2.0 API. Each migrated tutorial must be eager and distribution compatible, with tests, and all associated engineering artifacts."
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "**System information**\r\n- TensorFlow version: 1.12.0\r\n- Doc Link: https://www.tensorflow.org/api_docs/python/tf/data/Dataset#zip\r\n\r\n\r\n**Describe the documentation issue**\r\nI have tested the code provided in the documentation. Here the code : \r\n\r\n```\r\nfrom tensorflow.data import Dataset # i have added my own\r\n\r\n\r\n# NOTE: The following examples use `{ ... }` to represent the\r\n# contents of a dataset.\r\na = { 1, 2, 3 }\r\nb = { 4, 5, 6 }\r\nc = { (7, 8), (9, 10), (11, 12) }\r\nd = { 13, 14 }\r\n\r\n# The nested structure of the `datasets` argument determines the\r\n# structure of elements in the resulting dataset.\r\nDataset.zip((a, b)) == { (1, 4), (2, 5), (3, 6) }\r\nDataset.zip((b, a)) == { (4, 1), (5, 2), (6, 3) }\r\n\r\n# The `datasets` argument may contain an arbitrary number of\r\n# datasets.\r\nDataset.zip((a, b, c)) == { (1, 4, (7, 8)),\r\n                            (2, 5, (9, 10)),\r\n                            (3, 6, (11, 12)) }\r\n\r\n# The number of elements in the resulting dataset is the same as\r\n# the size of the smallest dataset in `datasets`.\r\nDataset.zip((a, d)) == { (1, 13), (2, 14) }\r\n```\r\n\r\nHere the error provided by the system:\r\n```\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 13, in <module>\r\n    Dataset.zip((a, b)) == { (1, 4), (2, 5), (3, 6) }\r\n  File \"/home/idolon/.virtualenvs/research/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 612, in zip\r\n    return ZipDataset(datasets)\r\n  File \"/home/idolon/.virtualenvs/research/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 2037, in __init__\r\n    raise TypeError(message)\r\nTypeError: The argument to `Dataset.zip()` must be a nested structure of `Dataset` objects.\r\n```\r\n\r\nI don't really understand what is Dataset and how it works, there's no explicit examples of its functionalities. What can we do with it ? How to build a dataset, how it's used, and how to show data. We have only examples on official datasets but what about making our own datasets ? Maybe i've not found the correct documentation page because of my bad english mastering. \r\n\r\nSo, is it an error of the documentation or just me that have not followed correctly the doc ?\r\nBest regards. \r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 1.12, 1.13, 2.0\r\n- Doc Link: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/TFRecordDataset#map\r\n\r\n\r\n**Describe the documentation issue**\r\nThe [documentation's symbol resolver](https://github.com/tensorflow/docs/blob/58e99a76ebd4b533fed5591147441ee3f6db3dae/tools/tensorflow_docs/api_generator/parser.py#L119) will automatically replace all appearances of \\`tf.symbol\\` with markdown links to the symbol's definition, which is generally great, however when these symbols appear \r\nwithin code blocks (e.g. in [usage examples](https://github.com/tensorflow/tensorflow/blob/09696450acc1a69dcac4717de87ee4f30544865a/tensorflow/python/data/ops/dataset_ops.py#L912)) the inserted link cannot be rendered correctly, and is interpreted as a plain string like `<a href=\"../../tf/Tensor\"><code>tf.Tensor</code></a>`. Thus, it would be best if symbols within code blocks are not replaced by links, or by links that do render correctly (AFAIK links cannot be placed within code blocks). \r\n\r\nNote: I have only observed this behavior in comments within code blocks.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nYes, I could submit a PR. However I'm unsure as to the best strategy to efficiently determine if the symbol lies within a code block. I imagine that one could split the strings by re matching ` ``` ` and then deciding whether or not to `re.sub` the current section of the docstring, but this much string manipulation might be somewhat costly. "
  },
  {
    "labels": [null, "documentation"],
    "text": "\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 1.12\r\n- Doc Link: https://github.com/tensorflow/docs/blob/b4d8d7096099c2b0a7df6a0564bf6eca8c96c4a0/site/en/tutorials/structured_data/feature_cols_keras.ipynb\r\n\r\n**Describe the documentation issue**\r\nwhen comment `tf.enable_eager_execution()`, the demo code fails. \r\n\r\n`ValueError: logits and labels must have the same shape ((32, 1) vs (32,))`\r\n\r\n\r\n\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "https://www.tensorflow.org/tutorials/keras/basic_regression#split_features_from_labels\r\n\r\n```\r\ndef plot_history(history):\r\n  plt.figure()\r\n  plt.xlabel('Epoch')\r\n  plt.ylabel('Mean Abs Error [MPG]')\r\n  plt.plot(hist['epoch'], hist['mean_absolute_error'],\r\n           label='Train Error')\r\n```\r\n\r\nThis function references `hist` instead of `history` so it doesn't parse."
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 1.12.0\r\n- Doc Link: https://www.tensorflow.org/tutorials/keras/basic_regression\r\n\r\n**Describe the documentation issue**\r\nThe function plot_history(history) is using pandas DataFrame \"hist\" from outside of the function scope, making it draw the same figure even when the EarlyStopping callbacks are used the second time. This error is corrected in the notebook (https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/basic_regression.ipynb), but for some reason, it is not reflected on the website.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nI will look into it later."
  },
  {
    "labels": ["documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version:\r\n- Doc Link:\r\nhttps://github.com/tensorflow/tensorflow/commit/3ae375aa92fbb6155f82393735d0b98d8fb9c1b2?diff=split#diff-4ffc4dce469256b24264cb6c7db54363\r\n\r\n**Describe the documentation issue**\r\nThe link to the TF-GAN tutorial is in tensorflow/contrib/gan/README.md L:59\r\npoints to http://https://github.com/tensorflow/models/tree/master/research/gan/tutorial.ipynb but it should point to https://github.com/tensorflow/models/tree/master/research/gan/tutorial.ipynb\r\nThe wrong link takes one to some sales page.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "**System information**\r\n- TensorFlow version: 1.12\r\n- Doc Link: https://www.tensorflow.org/api_docs/python/tf/contrib/layers/xavier_initializer\r\n\r\n**Describe the documentation issue**\r\n\r\nAccording to the documentation the Xavier initializer allows use of both the uniform distribution and the normal distribution.  However, when passing `uniform=False` to `xavier_initializer`, the code in `variance_scaling_initializer` actually uses a truncated normal distribution instead, [code link](https://github.com/tensorflow/tensorflow/blob/a6d8ffae097d0132989ae4688d224121ec6d8f35/tensorflow/contrib/layers/python/layers/initializers.py#L146).\r\n\r\nThe fix would consist of adjusting the documentation to provide details about the truncated Normal sampling."
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 1.12.0\r\n- Doc Link:\r\n\r\n\r\n**Describe the documentation issue**\r\nIt would be great if code examples or a tutorial can be written up to help with manually inserting fake quant nodes into an existing TensorFlow graph. The current rewriter provided in contrib/quantize doesn't seem to be able to handle complex graphs well.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 1.12\r\n- Doc Links:\r\n  - https://www.tensorflow.org/guide/using_tpu\r\n  - https://cloud.google.com/ml-engine/docs/tensorflow/using-tpus\r\n  - https://www.tensorflow.org/api_docs/python/tf/contrib/tpu/TPUEstimatorSpec\r\n\r\n\r\n**Describe the documentation issue**\r\n> The tf.train.SessionRunHook are unsupported, so these fields are omitted\r\n\r\nThe first link from above claims that no hooks are supported whatsover.\r\n> TPUEstimator handles many of the details of running on TPU devices, such as replicating inputs and models for each core, and returning to host periodically to run hooks.\r\n\r\nThe second link from above claims that they are indeed supported.\r\nThe documentation of the `TPUEstimatorSpec` itself does not mention anything about that.\r\n\r\nWhich of the two is now the case? Which hooks are supported (`training_hooks`, `evaluation_hooks`, `prediction_hooks`)?\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nYes absolutely! If you clarify the current level of support, I gladly update the documentation!"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: '1.12.0'\r\n- Doc Link: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/eager/custom_training_walkthrough.ipynb\r\n\r\n**Describe the documentation issue**\r\nBy running on google CoLab this notebook ( https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/eager/custom_training_walkthrough.ipynb#scrollTo=iDuG94H-C122 ), I have received the following error\r\n\r\n![image](https://user-images.githubusercontent.com/19335547/51309762-17445100-1a80-11e9-8199-195b3d460e2f.png)\r\n\r\nIf one converts the tensors to numpy, it works normally.\r\n\r\n```\r\nplt.scatter(features['petal_length'].numpy(),\r\n            features['sepal_length'].numpy(),\r\n            c=labels.numpy(),\r\n            cmap='viridis')\r\n\r\nplt.xlabel(\"Petal length\")\r\nplt.ylabel(\"Sepal length\");\r\n```\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "**System information**\r\n- TensorFlow version: 1.12\r\n- Doc Link: https://github.com/tensorflow/docs/blob/master/site/en/r2/guide/upgrade.md\r\n\r\n\r\n**Describe the documentation issue**\r\nThe document says that `Note: tf_upgrade_v2 is installed automatically by pip install for TensorFlow 1.12 and later.` but looking at the setup.py files this console command is not installed by 1.12, but will be installed in 1.13\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nNo\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "**System information**\r\n- TensorFlow version: 1.13.0-dev20190114\r\n- Doc Link: https://www.tensorflow.org/lite/\r\n**Describe the documentation issue**\r\nTFLite's home page links to this Object Detection tutorial: https://medium.com/tensorflow/training-and-serving-a-realtime-mobile-object-detector-in-30-minutes-with-cloud-tpus-b78971cf1193 \r\nThe tutorial is not compatible with the latest TensorFlow (1.13). It has multiple references to the TOCO convertor which used to be in tensorflow/contrib/lite/toco:toco but has been recently removed. I believe, it has been replaced by TFLiteConverter which has a different interface, so the tutorial needs to be updated. Plus, it would make a lot of sense to provide an iOS specific object detection tutorial. You already have both Android and iOS image classifier tutorials, so it would be sweet to give object detection the same coverage.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n\r\nThis tutorial must be fixed by somebody who knows how to get TFLiteConverter to work. I gave it a shot but was unable to convert the post-processing operation. I already filed issue 24910 with all the details on this."
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: v2.0\r\n- Doc Link: https://github.com/ehennis/Blog/tree/master/TensorFlow\r\n\r\n\r\n**Describe the documentation issue**\r\nI was looking through the eager execution documentation and one of the links is missing the extension 'ipynb'. If you click on the \"eager execution guide\" the link is broken.\r\n\r\nMarkdown Page: https://github.com/ehennis/Blog/tree/master/TensorFlow.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "**System information**\r\n- TensorFlow version: v1.8\r\n- Doc Link: [tf.contrib.rnn.LSTMCell](https://www.tensorflow.org/versions/r1.8/api_docs/python/tf/contrib/rnn/LSTMCell), [tf.contrib.rnn.LSTMBlockCell](https://www.tensorflow.org/versions/r1.8/api_docs/python/tf/contrib/rnn/LSTMBlockCell), [tf.contrib.rnn.LSTMBlockFusedCell](https://www.tensorflow.org/versions/r1.8/api_docs/python/tf/contrib/rnn/LSTMBlockFusedCell), [tf.nn.rnn_cell.LSTMCell](https://www.tensorflow.org/api_docs/python/tf/nn/rnn_cell/LSTMCell), [tf.keras.layers.LSTM](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM), [tf.contrib.cudnn_rnn.CudnnLSTM](https://www.tensorflow.org/api_docs/python/tf/contrib/cudnn_rnn/CudnnLSTM), [tf.contrib.cudnn_rnn.CudnnLSTMSaveable](https://www.tensorflow.org/api_docs/python/tf/contrib/cudnn_rnn/CudnnLSTMSaveable)\r\n\r\nIgnoring any fancy versions like Grid LSTM cells and LSTM cells somehow combined with convolutions there are **6!** different LSTM implementations in tensorflow (see documentation links above). Some are better documented than others, some claim to be faster than others (there seems to be the order  tf.contrib.rnn.LSTMCell < tf.contrib.rnn.LSTMBlockCell < tf.contrib.rnn.LSTMBlockFusedCell but then why keep the slower implementations instead of just replacing the slower ones with faster implementations?), all have slightly different APIs.\r\n\r\nWhat I am missing is a guide that tells me:\r\n* What is the fastest implementation on what hardware (I might be willing to deal with poor documentation if the result is at least fast, but having to deal with poor documentation just to find out that the performance is bad sucks).\r\n* What is the stable implementation which I can expect to be maintained for a longer time period.\r\n* What implementations are just included for historic reasons or to maintain backwards compatibility (and therefor should be avoided when starting a new project).\r\n* Maybe there are good reasons (that I am not aware of) to keep multiple implementations in parallel because they all have different tradeoffs. In this case I would like to know more what the differences are between the implementations. This can just be a table with pros and cons.\r\n\r\nThe state of affairs is probably similar for GRU cells and simple RNN cells. The situation with the LSTM cells is just exemplary ..."
  },
  {
    "labels": [null, "documentation"],
    "text": "installation with gpu is very difficult. could you please publish a one-command script that does the whole process? see a list of the steps here (i wrote them):\r\n\r\nhttps://github.com/rnreich/ubuntu-tensorflow-gpu-all-versions"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "I believe https://github.com/tensorflow/tensorflow/issues/23673 was closed incorrectly.\r\n\r\nThe problem is newer versions of bazel are not reading the bazel.rc that provides:\r\n```\r\ntools/bazel.rc:build --define=grpc_no_ares=true\r\n```\r\n\r\nThe solution can not be to install ares as this option is supposed to disable the need for it.\r\n\r\nPlease fix the build process to support newer versions of bazel (in my case, using 0.19.0)"
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 1.12\r\n- Doc Link:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/linalg/eigvalsh\r\n\r\n**Describe the documentation issue**\r\n\r\nNote: If your program backpropagates through this function, you should replace it with a call to tf.linalg.eigvalsh (possibly ignoring the second output) to avoid computing the eigen decomposition twice. This is because the eigenvectors are used to compute the gradient w.r.t. the eigenvalues. See _SelfAdjointEigV2Grad in linalg_grad.py.\r\n\r\nThis warning is quite ambiguous since\r\n1) ling.eigvalsh returns only one output, while linalg.eigh returns two outputs\r\n2) it circularly references itself\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n\r\nYes if it devs agree that there's an issue.\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 1.8.0\r\n- Python version: 2.7\r\n- Bazel version (if compiling from source): compiled from source \r\n- GCC/Compiler version (if compiling from source): c++ (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\n- CUDA/cuDNN version: 9.1\r\n- GPU model and memory:  Tesla K80 \r\n\r\n\r\n**Describe the current behavior**\r\nAdding batch normalization to a bidirectional RNN prevent me from updating the moving_mean and moving_variances during training and inference correctly.\r\nThe problem is that both the ```tf.control_dependencies``` and the ``while_loop```  of the dynamic_rnn are executed at the same time. The gradient will find nodes that have input from different frames and will throw errors. \r\n\r\nMy error message is  : \r\n```\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: node train/update (defined at ...)  has inputs from different frames. \r\nThe input node bidirectional_rnn/fw/fw/while/fw/bnlstm_cell/bnlstm_cell/state/batch_normalization/AssignMovingAvg (defined at ... )  is in frame 'train/Listener/features/layer1/BLSTM/bidirectional_rnn/fw/fw/while/while_context'. The input node train/apply_gradients/Assign (defined at ... )  is in frame ''.\r\n```\r\n\r\n**Describe the expected behavior**\r\nThe expected behaviour is being able to add the control_dependencies when we have the while_loop context. \r\nAdding clearer documentation about how to handle the moving_mean and moving_variance in case you have a distributed training.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n```python\r\ndef _update(self, loss, learning_rate, cluster):\r\n    '''\r\n    create the op to update the model\r\n\r\n    args:\r\n        loss: the loss to minimize\r\n        learning_rate: the learning rate\r\n        cluster: the tf cluster\r\n\r\n    returns: the update op\r\n    '''\r\n\r\n    #create the optimizer\r\n    optimizer = tf.train.AdamOptimizer(learning_rate)\r\n\r\n    #create an optimizer that aggregates gradients\r\n    if int(self.conf['numbatches_to_aggregate']) > 0:\r\n        if 'local' in cluster.as_dict():\r\n            num_workers = 1\r\n        else:\r\n            num_workers = len(cluster.as_dict()['worker'])\r\n\r\n        optimizer = tf.train.SyncReplicasOptimizer(\r\n            opt=optimizer,\r\n            replicas_to_aggregate=int(\r\n                self.conf['numbatches_to_aggregate']),\r\n            total_num_replicas=num_workers)\r\n\r\n\r\n    tf.summary.scalar('training_loss', loss,\r\n                      collections=['training_summaries'])\r\n\r\n    #get the list of trainable variables\r\n    trainable = tf.trainable_variables()\r\n\r\n    #get the list of variables to be removed from the trainable\r\n    #variables\r\n    untrainable = tf.get_collection('untrainable')\r\n\r\n    #remove the variables\r\n    trainable = [var for var in trainable\r\n                 if var not in untrainable]\r\n\r\n    #compute the gradients\r\n    grads_and_vars = optimizer.compute_gradients(\r\n        loss=loss,\r\n        var_list=trainable)\r\n\r\n    with tf.variable_scope('clip'):\r\n        #clip the gradients\r\n        grads_and_vars = [(tf.clip_by_value(grad, -1., 1.), var)\r\n                          for grad, var in grads_and_vars]\r\n\r\n\r\n    #opperation to apply the gradients\r\n    apply_gradients_op = optimizer.apply_gradients(\r\n        grads_and_vars=grads_and_vars,\r\n        name='apply_gradients')\r\n\r\n    #all remaining operations with the UPDATE_OPS GraphKeys\r\n    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\n    print(\"update_ops {}\".format(update_ops))\r\n    print(\"################\")\r\n    #create an operation to update the gradients, the batch_loss\r\n    #and do all other update ops\r\n    update_op = tf.group(\r\n        *([apply_gradients_op] + update_ops),\r\n        name='update')\r\n\r\n    return update_op\r\n\r\n```\r\n**Other info / logs**\r\n\r\nrelated issues : \r\n1) https://github.com/tflearn/tflearn/issues/540#issue-197855026\r\n2) https://github.com/tensorflow/tensorflow/issues/6087#issue-193534788\r\n\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "**System information**\r\n- TensorFlow version: TFlite \r\n- Doc Link:https://www.tensorflow.org/lite/performance/model_optimization\r\n\r\nin the model optimization documentation page:\r\nhttps://www.tensorflow.org/lite/performance/model_optimization\r\nTable 1 gives a latency of 145ms for post-training quantization and 80.2 for quantization-aware training. \r\n\r\nit is unclear to me why there should be a difference in latency as both methods results in models that use 8-bit operation. The documentation implies that the benefit of using quantization aware training is to increase model accuracy when using int8, but from the table it seems that latency is also improved. why is that?\r\n\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nYes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nMac OS X 10.13.6\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nN/A\r\n- TensorFlow installed from (source or binary):\r\nbinary\r\n- TensorFlow version (use command below):\r\nVERSION=\"1.13.0-dev20181226\" (this is the TF 2.0-preview)\r\nGIT_VERSION=\"b'v1.12.0-5133-gc343196842'\"\r\n- Python version:\r\n3.6.6\r\n- Bazel version (if compiling from source):\r\nN/A\r\n- GCC/Compiler version (if compiling from source):\r\nN/A\r\n- CUDA/cuDNN version:\r\nN/A\r\n- GPU model and memory:\r\nN/A\r\n\r\n**Describe the current behavior**\r\n`tf.function` returns a `PolymorphicFunction`.  When called, this function creates a concrete function to call for the specific types and shapes of the arguments, by calling `PolymorphicFunction.get_concrete_function()`, and subsequently, it reuses the same concrete function when it encounters the same types and shapes again.\r\n\r\nUnfortunately, when passed python scalars or arrays of scalars, it seems to create a new function for each different value, instead of each different type (see code example below). Similarly, it creates a new function for [1.0, 2.0], and [3.0, 4.0].\r\n\r\nI understand that there may be a good technical reason for this, but even if there is, I fear that users will pass Python scalar values or arrays (instead of tensors or NumPy arrays) to @tf.functions and they won't understand why their system blows up (slowed down by all the traces and new concrete functions piling up in RAM all the time).\r\n\r\n**Describe the expected behavior**\r\nI expect `PolymorphicFunction.get_concrete_function()` to return the same concrete function whether I pass it 1, or 2, or tf.constant(3) or tf.constant(4) as an argument.  I expect a different concrete function to be returned when I pass it [1.0], but this second concrete function should be the same as for the arguments [2.0], or tf.constant([3.0]), or tf.constant([4.0]) or np.array([5.0]), or or np.array([6.0])\r\n\r\n**Code to reproduce the issue**\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n@tf.function\r\ndef square(x):\r\n    print(\"Calling\")\r\n    tf.get_logger().warning(\"Tracing\")\r\n    return tf.square(x)\r\n\r\nprint(\"Square of int32 scalars\")\r\nfor i in range(3):\r\n    square(tf.constant(i))\r\nprint(\"OKAY\")\r\n    \r\nprint()\r\nprint(\"Square of float32 scalars\")\r\nfor i in range(3):\r\n    square(tf.constant(i, dtype=tf.float32))\r\nprint(\"OKAY\")\r\n\r\nprint()\r\nprint(\"Square of float32 arrays of shape [2]\")\r\nfor i in range(3):\r\n    square(tf.constant([i, i], dtype=tf.float32))\r\nprint(\"OKAY\")\r\n\r\nprint()\r\nprint(\"Square of float32 NumPy arrays of shape [2]\")\r\nfor i in range(3):\r\n    square(tf.constant(np.array([i, i]), dtype=tf.float32))\r\nprint(\"OKAY\")\r\n\r\nprint()\r\nprint(\"Square of python integers 1, 2, 3\")\r\nfor i in range(3):\r\n    square(i)\r\nprint(\"ERROR! Why is there one trace per call?\")\r\n\r\nprint()\r\nprint(\"Square of python integers 1, 2, 3 (AGAIN)\")\r\nfor i in range(3):\r\n    square(i)\r\nprint(\"ERROR! No traces anymore, which means that one Function was cached for each specific integer 1, 2, 3.\")\r\n\r\nprint()\r\nprint(\"Square of python integers arrays of shape [2]\")\r\nfor i in range(3):\r\n    square([i, i])\r\nprint(\"ERROR! Why is there one trace per call?\")\r\n```\r\n\r\n**Other info / logs**\r\nHere is the output of this program:\r\n\r\n```\r\nSquare of int32 scalars\r\nWARNING:tensorflow:Tracing\r\nCalling\r\nCalling\r\nCalling\r\nOKAY\r\n\r\nSquare of float32 scalars\r\nWARNING:tensorflow:Tracing\r\nCalling\r\nCalling\r\nCalling\r\nOKAY\r\n\r\nSquare of float32 arrays of shape [2]\r\nWARNING:tensorflow:Tracing\r\nCalling\r\nCalling\r\nCalling\r\nOKAY\r\n\r\nSquare of float32 NumPy arrays of shape [2]\r\nCalling\r\nCalling\r\nCalling\r\nOKAY\r\n\r\nSquare of python integers 1, 2, 3\r\nWARNING:tensorflow:Tracing\r\nCalling\r\nWARNING:tensorflow:Tracing\r\nCalling\r\nWARNING:tensorflow:Tracing\r\nCalling\r\nERROR! Why is there one trace per call?\r\n\r\nSquare of python integers 1, 2, 3 (AGAIN)\r\nCalling\r\nCalling\r\nCalling\r\nERROR! No traces anymore, which means that one Function was cached for each specific integer 1, 2, 3.\r\n\r\nSquare of python integers arrays of shape [2]\r\nWARNING:tensorflow:Tracing\r\nCalling\r\nWARNING:tensorflow:Tracing\r\nCalling\r\nWARNING:tensorflow:Tracing\r\nCalling\r\nERROR! Why is there one trace per call?\r\n```\r\n\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "**System information**\r\n- TensorFlow version: r1.12\r\n- Doc Link: https://www.tensorflow.org/api_docs/python/tf/keras/backend/batch_normalization\r\n\r\n**Describe the documentation issue**\r\nThe documentation describes the op as computing \r\n\r\n~~~\r\noutput = (x - mean) / (sqrt(var) + epsilon) * gamma + beta\r\n~~~\r\n\r\nthe op actually computes\r\n\r\n~~~\r\noutput = (x - mean) / (sqrt(var + epsilon)) * gamma + beta\r\n~~~\r\n\r\nwith `epsilon` inside the sqrt\r\n\r\nPractically, it doesn't really matter where the epsilon is added in actual use.  (I only noticed because I was comparing the output of each layer when translating something from caffe to tensorflow)\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n\r\nMaybe eventually, would take me awhile to get around to it"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nNo\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nMac OS X 10.13.6\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nN/A\r\n- TensorFlow installed from (source or binary):\r\nbinary\r\n- TensorFlow version (use command below):\r\nVERSION=\"1.13.0-dev20181226\" (this is the TF 2.0-preview)\r\nGIT_VERSION=\"b'v1.12.0-5133-gc343196842'\"\r\n- Python version:\r\n3.6.6\r\n- Bazel version (if compiling from source):\r\nN/A\r\n- GCC/Compiler version (if compiling from source):\r\nN/A\r\n- CUDA/cuDNN version:\r\nN/A\r\n- GPU model and memory:\r\nN/A\r\n\r\n**Describe the current behavior**\r\n`tf.log()` is missing.  It is only available in `tf.math.log()`.\r\n\r\n**Describe the expected behavior**\r\nThe log function is fundamental and used all the time, it should be available in `tf.log()` (and also in `tf.math.log()`. Especially considering that `tf.exp()` is available. Note that many code examples still show `tf.log()` (try searching for `'tf.log('` in the code base, you will find 12 matches across 8 files).\r\n\r\n**Code to reproduce the issue**\r\n\r\n```python\r\nimport tensorflow as tf\r\ntf.log(42.)\r\n```\r\n\r\n**Other info / logs**\r\nI also checked the changes listed in the API names RFC, and I noticed a few discrepancies (I can file a separate issue if necessary):\r\n\r\n```\r\nNot deleted: tf.Event\r\nNot deleted: tf.losses\r\nNot deleted: tf.space_to_batch\r\n\r\nNot moved: tf.floormod => tf.math.floormod\r\nNot moved: tf.realdiv => tf.math.realdiv\r\nNot moved: tf.SummaryMetadata => tf.summary.SummaryMetadata\r\nNot moved: tf.truncatediv => tf.math.truncatediv\r\nNot moved: tf.truncatemod => math.truncatemod\r\n\r\nNot added: tf.batch_to_space_nd\r\nNot added: tf.debugging.is_finite\r\nNot added: tf.debugging.is_inf\r\nNot added: tf.debugging.is_non_decreasing\r\nNot added: tf.debugging.is_strictly_increasing\r\nNot added: tf.debugging.Print\r\nNot added: tf.debugging.verify_tensor_all_finite\r\nNot added: tf.dtypes.bitcast\r\nNot added: tf.initializers.glorot_normal\r\nNot added: tf.initializers.orthogonal_initializer\r\nNot added: tf.initializers.tables_initializer\r\nNot added: tf.initializers.uniform_unit_scaling\r\nNot added: tf.initializers.variance_scaling\r\nNot added: tf.io.PaddingFIFOQueue\r\nNot added: tf.io.PriorityQueue\r\nNot added: tf.io.QueueBase\r\nNot added: tf.io.RandomShuffleQueue\r\nNot added: tf.io.tf_record_iterator\r\nNot added: tf.linalg.matrix_band_part\r\nNot added: tf.linalg.matrix_inverse\r\nNot added: tf.linalg.matrix_solve_ls\r\nNot added: tf.linalg.self_adjoint_eig\r\nNot added: tf.linalg.self_adjoint_eigvals\r\nNot added: tf.math.mod\r\nNot added: tf.math.reduce_join\r\nNot added: tf.quantization.quantize_v2\r\nNot added: tf.random.get_seed\r\nNot added: tf.random.multinomial\r\nNot added: tf.random.random_gamma\r\nNot added: tf.random.random_poisson\r\nNot added: tf.random.set_random_seed\r\nNot added: tf.saved_model.build_tensor_info\r\nNot added: tf.saved_model.get_tensor_from_tensor_info\r\nNot added: tf.saved_model.LEGACY_INIT_OP_KEY\r\nNot added: tf.saved_model.load\r\nNot added: tf.saved_model.main_op\r\nNot added: tf.saved_model.MAIN_OP_KEY\r\nNot added: tf.saved_model.main_op_with_restore\r\nNot added: tf.saved_model.maybe_saved_model_directory\r\nNot added: tf.saved_model.SavedModelBuilder\r\nNot added: tf.saved_model.TRAINING\r\nNot added: tf.sparse.matmul\r\nNot added: tf.sparse.merge\r\nNot added: tf.sparse.placeholder\r\nNot added: tf.sparse.reduce_max_sparse\r\nNot added: tf.sparse.reduce_sum_sparse\r\nNot added: tf.sparse.SparseTensorValue\r\nNot added: tf.summary.HistogramProto\r\nNot added: tf.train.confusion_matrix\r\n```\r\n\r\nAnd `tf.spectral` is called `tf.signal`."
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n**System information**\r\n- TensorFlow version: GPU 1.14.0\r\n- Doc Link: https://www.tensorflow.org/install/source_windows\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\nThe documentation for installing Bazel on Windows is separated into two different pages with no indication that the second page is required after following the first.  This can lead to install issues and build errors that make absolutely no sense, but do after figuring out that you're missing 5 dependencies, mentioned only on the second page under \"Building C++ Projects\"\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n\r\nI have written a massive walkthrough for installing tensorflow <a href=\"http://aaronjencks.net/blog/8/#Bazel\">here</a>, but in reality, just a mention of the second page as an indication that there's more to set up than just the \"Install Bazel\" <a href=\"https://docs.bazel.build/versions/master/install-windows.html\">link</a> on the site, that the user must also install the dependencies for building C++ projects with Bazel, found <a href=\"https://docs.bazel.build/versions/master/windows.html\">here</a>, would solve the issue."
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version:v1.9\r\n- Doc Link:\r\nhttps://tensorflow.google.cn/api_docs/python/tf/image/resize_bilinear\r\n\r\n**Describe the documentation issue**\r\ni want to see the 'tf.image.resize_bilinear' source code.\r\nbut i can not find 'tensorflow/python/ops/gen_image_ops.py'.\r\n\r\n"
  },
  {
    "labels": ["documentation", null],
    "text": "**Describe the current behavior**\r\nIn the Predict fuel efficiency: regression lesson (TensorFlow->Learn->Tutorials->Learn and use ML->Regression), the normalize method is called to normalize the entire dataset, including the one-hot columns.\r\n\r\n**Describe the expected behavior**\r\nThe one-hot columns in the dataset should not be normalized.\r\n\r\n**Code to reproduce the issue**\r\ndataset['USA'] = (origin == 1)*1.0\r\ndataset['Europe'] = (origin == 2)*1.0\r\ndataset['Japan'] = (origin == 3)*1.0\r\ntrain_dataset = dataset.sample(frac=0.8,random_state=0)\r\ntrain_stats = train_dataset.describe()\r\ntrain_stats.pop(\"MPG\")\r\ntrain_stats = train_stats.transpose()\r\n\r\ndef norm(x):\r\n  return (x - train_stats['mean']) / train_stats['std']\r\nnormed_train_data = norm(train_dataset)\r\n\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "**System information**\r\n- TensorFlow version: Docker version\r\n- Doc Link: https://www.tensorflow.org/install/docker\r\n\r\n\r\n**Describe the documentation issue**\r\nIn the install with Docker documentation, there are examples of how to pull images by adding multiple parameters together, there is am implicit reference to latest-gpu-jupyter. On [docker-hub](https://hub.docker.com/r/tensorflow/tensorflow/tags/), it appears that tag is no longer valid or is no longer being built. This can cause a confusing error relating to a missing manifest when trying to pull that image.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nOf course, I just need to know if this is a permanent deprecation of latest-gpu-py3-jupyter and latest-gpu-jupyter, or if it's just a mistake, the nightly builds do contain those tags (nightly-gpu-py3-jupyter) for example\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: master\r\n- Doc Link: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/experimental/micro\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\nIn \"Getting Started\" chapter, the command for cloning tensorflos is: \r\n\r\nDownload the TensorFlow source with git clone https://github.com/tensorflow\r\n\r\nIt should be : \r\n\r\ngit clone https://github.com/tensorflow/tensorflow.git\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n\r\nYes"
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: r1.12\r\n- Doc Link: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer\r\n\r\n\r\n**Describe the documentation issue**\r\nBelow the 'Arguments' list, it looks like there are supposed to be lists of read-only properties and mutable properties, but they render as paragraphs rather than lists.\r\n\r\nSeems like the issue is that the parser splits the docstring into sections based on a magic list of keywords, `detail_keywords = '|'.join(['Args', 'Arguments', 'Fields', 'Returns', 'Yields', 'Raises', 'Attributes'])`, and that list does not include the strings 'Read-only properties', or 'Mutable properties'. So it treats everything below \"Arguments\" as part of the list of arguments, and trips over itself.\r\n\r\n(There's also some question as to whether these lists should be there at all, or whether this information should be in the [Properties](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer#properties) section)\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nNot with my current understanding of the docs system. I was able to find a script for generating a markdown index of the docs locally (`tensorflow/tools/docs/generate2.py`), but when I ran it, I got [a markdown file that didn't seem to have the issue I see on the site](https://gist.github.com/colinmorris/0a180ea671e12ccdb65fe6cc9f0319fa). Maybe it's because I used `generate2.py` but the docs on the site are generated by `generate.py`? Maybe the lists are fine in GitHub-flavoured markdown but not whatever engine is used when converting the docs from md to html for the site? (I'll file a separate issue about this meta-documentation issue)"
  },
  {
    "labels": [null, "documentation"],
    "text": "This bug was closed while the problem still exists: https://github.com/tensorflow/tensorflow/issues/21362"
  },
  {
    "labels": ["documentation"],
    "text": "Link:\r\nhttps://www.tensorflow.org/guide/extend/architecture\r\n\r\nIn the above link, an introduction link is provided. Its broken.\r\nhttps://www.tensorflow.org/guide/guide/low_level_intro\r\n\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "- Doc Link: https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator\r\n\r\nIn the section for `export_savedmodel`, it mentioned `export_to_savedmodel` which seems should be `export_savedmodel`. Maybe worth a fix."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nYes, please see this [Colab](https://colab.research.google.com/drive/1GKAqEo7qSr6kMAgxPrOrudA5eLndQ6Ub)\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): n/a\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): n/a\r\n- TensorFlow version (use command below): 1.10+\r\n- Python version: 3.5\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: whatever is on Colab\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\n\r\nOne can not train a distributed-`Estimator` and export the model, then load it on a non-distributive device because if we look at the TensorFlow docs for BestExporter\r\n\r\n```\r\n__init__(\r\n    name='best_exporter',\r\n    serving_input_receiver_fn=None,\r\n    event_file_pattern='eval/*.tfevents.*',\r\n    compare_fn=_loss_smaller,\r\n    assets_extra=None,\r\n    as_text=False,\r\n    exports_to_keep=5\r\n)\r\n```\r\nit is apparent that `clear_devices` is not an option.\r\n\r\n**Describe the expected behavior**\r\n\r\nLet me easily export and import `Estimators`\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n see this [Colab](https://colab.research.google.com/drive/1GKAqEo7qSr6kMAgxPrOrudA5eLndQ6Ub)\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "Can someone provide me documentation or examples of using Tensorflow lite + Android NDK C++.\r\n\r\nThe only project example is in Java, but I need to use Tensorflow lite with the Android NDK in C++.\r\n\r\nI'm also using a Windows 10 computer and have the latest version of Bazel installed.\r\n\r\nAny steps, documentation, and example projects for Tensorflow lite + Android NDK C++ would be very beneficial to me and the community..\r\n\r\nThank you for any support"
  },
  {
    "labels": ["documentation"],
    "text": "**System information**\r\n- TensorFlow version: 1.12\r\n- Doc Link: https://www.tensorflow.org/api_docs/python/tf/saved_model/simple_save \r\n\r\nSimple_save seems to be a newer and more standardized saving approach. Since it can also use assets to store vocabularies, I wonder if it is possible to have a working example in document based on keras sentiment analysis system's data? So there is place to look up how to really integrate the entire model (including vocabulary, word embedding, etc) in a single simple_save."
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 1.6.0\r\n- Doc Link: https://www.tensorflow.org/api_docs/python/tf/contrib/periodic_resample/periodic_resample\r\n\r\n\r\n**Describe the documentation issue**\r\nThere is no example on how to use the operation at all. Specifically, most graphs that this operation is useful for (DCGANs) use 4D tensors (batch size, height, width, channels), with the batch size being unknown already (``None``) and the operation should decrease a single dimension specified as ``None``. Since we usually don't want to decrease the batch size with this operation, I have no idea how to actually use it in this case.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nIf I understand how to actually use this function, yes.\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "**System information**\r\n- TensorFlow version: ALL\r\n- Doc Link: \r\nCustom op: https://www.tensorflow.org/guide/extend/op\r\nBuild graph in c++: https://www.tensorflow.org/guide/extend/cc\r\n\r\n\r\n**Describe the documentation issue**\r\nPlease provide documentation about how to build graph using custom OP.\r\nRelated StackOverflow question: https://stackoverflow.com/questions/53384454/how-to-use-custom-op-to-build-tensorflow-graph-in-c\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version:\r\n- Doc Link: https://www.tensorflow.org/guide/performance/overview#comparing_compiler_optimizations\r\n\r\n\r\n**Describe the documentation issue**\r\nThe following section has been removed from official documentation: \r\nhttps://www.tensorflow.org/guide/performance/overview#comparing_compiler_optimizations\r\nI was able to find the benchmark after long search here:\r\nhttps://github.com/tensorflow/tensorflow/issues/13050#issuecomment-330699371\r\nI was wondering if the section was removed deliberately or by accident?\r\n\r\nRegards, Anton\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 1.12\r\n- Doc Link: https://www.tensorflow.org/guide/extend/model_files\r\n\r\n\r\n**Describe the documentation issue**\r\nLinked file in https://www.tensorflow.org/guide/extend/model_files#text_or_binary was already removed from tensorboard repo by https://github.com/tensorflow/tensorboard/pull/1512.\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nCan not."
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- Doc Link:\r\n   i.  https://www.tensorflow.org/guide/extend/model_files\r\n   ii. https://github.com/tensorflow/docs/blob/master/site/en/guide/extend/model_files.md\r\n\r\n\r\n**Describe the documentation issue**\r\nAs in the previously closed #5978 and #12042, the link for `graph_run_run2.pbtxt` is currently broken."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 1.10+\r\n- Doc Link: https://www.tensorflow.org/api_docs/python/tf/estimator/export/ServingInputReceiver\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\nIt is unclear:\r\n\r\n1. what a `serving_input_receiver_fn` is\r\n2. why one is needed\r\n3. how one should be written (e.g. what arguments are required in the function definition)\r\n4. what should be returned \r\n5. what the difference is between the `features` argument of `tf.estimator.export.ServingInputReceiver` and the `receiver_tensors` argument is and why they are needed.\r\n\r\n\r\nSee this [S.O. post](https://stackoverflow.com/questions/52874647/tensorflow-v1-10-why-is-an-input-serving-receiver-function-needed-when-checkpoi) for an example of why it is unclear\r\n\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 1.12.0\r\n- Doc Link: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/graph_transforms\r\n\r\n\r\n**Describe the documentation issue**\r\nAs newbie to Tensorflow it quite confusing seeing that you need to `bazel build` something, all I had to do before this point is `pip install`. To be more specific, what is bazel? Why do I need it to use GTT? Why is GTT not available from pip installation? Why when I'm going to _Build from source page_ it encourages me that you providing pre-built packages, where is GTT then?\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version:\r\n- Doc Link:\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 1.11 +\r\n- Doc Link: https://www.tensorflow.org/install/gpu\r\n\r\n\r\n**Describe the documentation issue**\r\nThe documentation states that you will need to install the cuda9.0 package. This does not exist in the repo - http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/. It should be the cuda-9-0 package instead.\r\n\r\nIf you don't install the package, tensorflow works, but the GPUs are not engaged. This can be verified using the `gpustat -cp` command provided by the python pip gpustat library.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "**System information**\r\n\r\n- TensorFlow version: 1.12\r\n- Doc Link:\r\n  1. https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/distribute\r\n  2. https://www.tensorflow.org/api_docs/python/tf/contrib/distribute/MirroredStrategy\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\n[Document i](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/distribute) says that `tf.contrib.distribute.MirroredStrategy` is for only the case of \"single worker and multi GPUs\".\r\nBut [document ii](https://www.tensorflow.org/api_docs/python/tf/contrib/distribute/MirroredStrategy) says that `MirroredStrategy` can work in multi-worker (multi-node) cluster.\r\n\r\nWhich is right?\r\n\r\nIf [document i](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/distribute) is out of date, we have to update it.\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: unrelated, I'm using github ui viewing the code\r\n- Doc Link: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/client/client_lib.py#L18\r\n\r\n\r\n**Describe the documentation issue**\r\nThis link https://tensorflow.org/api_guides/python/client gives 404\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: Version 2.0\r\n- Doc Link: The following docs all have links that return a 404 error:\r\n\r\n  - [tensorflow/contrib/util/\\_\\_init\\_\\_.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/util/__init__.py)\r\n    - [https://www.tensorflow.org/api_guides/python/contrib.util](https://www.tensorflow.org/api_guides/python/contrib.util)\r\n  - [tensorflow/python/lib/io/python_io.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/lib/io/python_io.py)\r\n    - [https://www.tensorflow.org/api_guides/python/python_io](https://www.tensorflow.org/api_guides/python/python_io)\r\n  - [tensorflow/python/client/client_lib.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/client/client_lib.py)\r\n    - [https://www.tensorflow.org/api_guides/python/client](https://www.tensorflow.org/api_guides/python/client)\r\n  - [tensorflow/contrib/crf/\\_\\_init\\_\\_.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/crf/\\_\\_init\\_\\_.py)\r\n    - [https://www.tensorflow.org/api_guides/python/contrib.crf](https://www.tensorflow.org/api_guides/python/contrib.crf)\r\n  - [tensorflow/python/debug/\\_\\_init\\_\\_.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/debug/__init__.py)\r\n    - [https://tensorflow.org/api_guides/python/tfdbg](https://tensorflow.org/api_guides/python/tfdbg)\r\n  - [tensorflow/contrib/rnn/\\_\\_init\\_\\_.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/__init__.py)\r\n    - [https://tensorflow.org/api_guides/python/contrib.rnn](https://tensorflow.org/api_guides/python/contrib.rnn)\r\n  - [tensorflow/core/api_def/base_api/api_def_SegmentMax.pbtxt](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/api_def/base_api/api_def_SegmentMax.pbtxt)\r\n  - [tensorflow/core/api_def/base_api/api_def_SegmentMean.pbtxt](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/api_def/base_api/api_def_SegmentMean.pbtxt)\r\n  - [tensorflow/core/api_def/base_api/api_def_SegmentMin.pbtxt](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/api_def/base_api/api_def_SegmentMin.pbtxt)\r\n  - [tensorflow/core/api_def/base_api/api_def_SegmentProd.pbtxt](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/api_def/base_api/api_def_SegmentProd.pbtxt)\r\n  - [tensorflow/core/api_def/base_api/api_def_SegmentSum.pbtxt](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/api_def/base_api/api_def_SegmentSum.pbtxt)\r\n  - [tensorflow/core/api_def/base_api/api_def_UnsortedSegmentMax.pbtxt](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/api_def/base_api/api_def_UnsortedSegmentMax.pbtxt)\r\n  - [tensorflow/core/api_def/base_api/api_def_UnsortedSegmentSum.pbtxt](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/api_def/base_api/api_def_UnsortedSegmentSum.pbtxt)\r\n  - [tensorflow/core/api_def/base_api/api_def_SparseSegmentSqrtN.pbtxt](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/api_def/base_api/api_def_SparseSegmentSqrtN.pbtxt)\r\n  - [tensorflow/core/api_def/base_api/api_def_SparseSegmentMean.pbtxt](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/api_def/base_api/api_def_SparseSegmentMean.pbtxt)\r\n  - [tensorflow/core/api_def/base_api/api_def_SparseSegmentMeanWithNumSegments.pbtxt](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/api_def/base_api/api_def_SparseSegmentMeanWithNumSegments.pbtxt)\r\n  - [tensorflow/core/api_def/base_api/api_def_SparseSegmentSqrtNWithNumSegments.pbtxt](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/api_def/base_api/api_def_SparseSegmentSqrtNWithNumSegments.pbtxt)\r\n  - [tensorflow/core/api_def/base_api/api_def_SparseSegmentSum.pbtxt](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/api_def/base_api/api_def_SparseSegmentSum.pbtxt)\r\n  - [tensorflow/core/api_def/base_api/api_def_SparseSegmentSumWithNumSegments.pbtxt](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/api_def/base_api/api_def_SparseSegmentSumWithNumSegments.pbtxt)\r\n  - [tensorflow/core/api_def/base_api/api_def_UnsortedSegmentMin.pbtxt](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/api_def/base_api/api_def_UnsortedSegmentMin.pbtxt)\r\n  - [tensorflow/core/api_def/base_api/api_def_UnsortedSegmentProd.pbtxt](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/api_def/base_api/api_def_UnsortedSegmentProd.pbtxt)\r\n    - [https://tensorflow.org/api_guides/python/math_ops#Segmentation](https://tensorflow.org/api_guides/python/math_ops#Segmentation)\r\n  - [tensorflow/contrib/framework/\\_\\_init\\_\\_.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/framework/__init__.py)\r\n    - [https://tensorflow.org/api_guides/python/contrib.framework](https://tensorflow.org/api_guides/python/contrib.framework)\r\n  - [tensorflow/contrib/layers/\\_\\_init\\_\\_.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/__init__.py)\r\n    - [https://tensorflow.org/api_guides/python/contrib.layers](https://tensorflow.org/api_guides/python/contrib.layers)\r\n  - [tensorflow/python/training/training.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/training.py)\r\n    - [https://www.tensorflow.org/api_guides/python/train](https://www.tensorflow.org/api_guides/python/train)\r\n  - [tensorflow/python/summary/summary.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/summary/summary.py)\r\n    - [https://tensorflow.org/api_guides/python/summary](https://tensorflow.org/api_guides/python/summary)\r\n  - [tensorflow/python/ops/session_ops.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/session_ops.py)\r\n    - [https://tensorflow.org/api_guides/python/session_ops](https://tensorflow.org/api_guides/python/session_ops)\r\n  - [tensorflow/python/ops/string_ops.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/string_ops.py)\r\n    - [https://tensorflow.org/api_guides/python/string_ops](https://tensorflow.org/api_guides/python/string_ops)\r\n  - [tensorflow/python/ops/state_ops.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/state_ops.py)\r\n    - [https://tensorflow.org/api_guides/python/state_ops](https://tensorflow.org/api_guides/python/state_ops)\r\n  - [tensorflow/python/ops/math_ops.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/math_ops.py)\r\n    - [https://tensorflow.org/api_guides/python/math_ops#segmentation](https://tensorflow.org/api_guides/python/math_ops#segmentation)\r\n  - [tensorflow/python/ops/functional_ops.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/functional_ops.py)\r\n    - [https://tensorflow.org/api_guides/python/functional_ops](https://tensorflow.org/api_guides/python/functional_ops)\r\n  - [tensorflow/python/ops/check_ops.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/check_ops.py)\r\n    - [https://tensorflow.org/api_guides/python/check_ops](https://tensorflow.org/api_guides/python/check_ops)\r\n  - [tensorflow/python/ops/array_ops.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/array_ops.py)\r\n    - [https://tensorflow.org/api_guides/python/array_ops](https://tensorflow.org/api_guides/python/array_ops)\r\n  - [tensorflow/python/ops/control_flow_ops.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/control_flow_ops.py)\r\n    - [https://tensorflow.org/api_guides/python/control_flow_ops](https://tensorflow.org/api_guides/python/control_flow_ops)\r\n  - [tensorflow/python/ops/sparse_ops.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/sparse_ops.py)\r\n    - [https://tensorflow.org/api_guides/python/sparse_ops](https://tensorflow.org/api_guides/python/sparse_ops)\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?** No\r\n"
  },
  {
    "labels": [null, null, null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 1.9\r\n- Doc Link: https://www.tensorflow.org/tutorials/estimators/cnn\r\n\r\n\r\n**Describe the documentation issue**\r\nIn this CNN tutorial example, there is no exporting savedmodel example. For users that need to save the trained model for future usage, it will be better to add exporting savedmodel part in the tutorial.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "**System information** Windows 10\r\n- TensorFlow version: tf-nightly-gpu (Oct. 25. 2018)\r\n- Doc Link:\r\nhttps://www.tensorflow.org/install/pip\r\n\r\n\r\n**Describe the documentation issue**\r\nThe suggested post-install test:\r\n\r\n`python -c \"import tensorflow as tf; print(tf.__version__)\"\r\n`\r\npasses even when there are unresolved GPU CUDA/cuDNN driver issues.\r\n\r\nThe test previously suggested exercises the CUDA/cuDNN GPU drivers and seems to be better one to suggest:\r\n\r\n`python -c \"import tensorflow as tf; hello = tf.constant('Hello, TF'); sess = tf.Session(); print(sess.run(hello))\"\r\n`\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nyes\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow 1.9.0\r\n- Python 3.6.6\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nThe tf.nn.embedding_lookup_sparse need two tf.SparseTensor (sp_ids and sp_weights) but I can't figure out why. Specifically, it seems to me that the columns of the indices of sp_ids and sp_weights are useless (see the example in the doc). This could be changed to use only one SparseTensor with:\r\n- rows of indices pointing to the index of the element of the batch.\r\n- columns of indices pointing to the index of the target element of the embedding (params).\r\n- values corresponding to the weights. \r\n\r\nSmall example of two operations doing the same things:\r\ntf.sparse_tensor_dense_matmul(sparse_tensor, embeddings)\r\ntf.nn.embedding_lookup_sparse(embeddings, sparse_ids, sparse_weights, \"sum\")\r\nHere sparse_ids and sparse_weights have the same indices, the values of sparse_ids are the columns of indices of sparse_tensor and the values of weights are the values of  sparse_tensor. The three sparse tensors share the same rows of indices. \r\n\r\nps: It might not work in higher dimensional embedding lookups, I just wanted to point out the fact that embedding_lookup and embedding_lookup_sparse, despite their close names, have actually a very different usability. \r\n\r\n\r\n**Will this change the current api? How?**\r\nI can't really say.  tf.nn.embedding_lookup_sparse(params, sp_ids, sp_weights...) could become tf.nn.embedding_lookup_sparse(params, sparse_ids...) to be more consistent with tf.nn.embedding_lookup.\r\n\r\n\r\n**Who will benefit with this feature?**\r\nI don't really know. \r\n\r\n\r\n**Any Other info.**\r\n\r\nHave I written custom code: no\r\nOS Platform and Distribution: linux, but not relevant\r\nTensorFlow installed from: pip\r\nTensorFlow version: 1.9.0\r\nBazel version: ?\r\nCUDA/cuDNN version: no CUDA\r\nGPU model and memory: no GPU\r\nExact command to reproduce: See above\r\nMobile device: not relevant\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 1.11.0\r\n- Doc Link: NA\r\n\r\n\r\n**Describe the documentation issue**\r\nWith the introduction of `tf.data` and deprecation of `QueueRunner`, TFRecords seem to play a major role if you want to effeciently use accelerators while training on large datasets. Unfortunately, the current `tf.data` [documentation](https://www.tensorflow.org/guide/datasets) starts off assuming we already have `TFRecords` on disk without even linking how we could convert images, say `tiny imagenet` or even arbitrary images to the `TFRecord`s format. \r\n\r\nTo be precise, there is no documentation for `TFRecord` , `TFExample` or even the readers and writers. Moreover, the examples do not cover how these things would work in eager execution mode. It would be great if these could be fixed as it would improve adoption of TFRecords and help more people use the tf.data pipelines.\r\n\r\nPS, I am aware of code examples in the repo such as [1](https://github.com/tensorflow/models/blob/1af55e018eebce03fb61bba9959a04672536107d/research/deeplab/datasets/build_voc2012_data.py) and [2](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/how_tos/reading_data/convert_to_records.py) but would prefer to have better documentation and maybe a guide for this. \r\n\r\nThanks\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?** no\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n**System information**\r\n- TensorFlow version: 1.6.0\r\n- Doc Link: https://www.tensorflow.org/api_docs/python/tf/train/FtrlOptimizer\r\n\r\n**Describe the documentation issue**\r\nThis is probably a silly, small issue, but the docs for the FTRL optimizer do not describe what `learning_rate_power` and how it interacts with `learning_rate`.  I tried to figure it out based on the source, but couldn't actually find [where learning_rate_power is used in the code.](https://github.com/tensorflow/tensorflow/blob/1c7bc899dbb86cec70a2c11207a9ce8acf30c13b/tensorflow/python/training/ftrl.py#L41)\r\n\r\nThe `l2_shrinkage_regularization_strength` has a very detailed explanation and an equation.  Something similar for `learning_rate_power` would be nice."
  },
  {
    "labels": [null, "documentation"],
    "text": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Fedora 28\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.11.0\r\n- **Python version**: 3.5.0\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nThe page https://cloud.google.com/ml-engine/docs/tensorflow/distributed-training-details#tensorflow-config notes that \"The tf.estimator.train method doesn't work with distributed training on Cloud ML Engine. Please use train_and_evaluate instead.\". This is not documented on the Estimator page (https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator) or anywhere else I've seen. I believe it would be helpful to document it more prominently, as I can't be the only one who didn't read the \"Using TF_CONFIG for Distributed Training Details\" page and wasted time debugging why a model wouldn't work when distributed.\r\n\r\nIf possible, it would be even more helpful to make tf.estimator.train raise an exception when run in a distributed ML Engine context, or log a warning. It's unreasonable to expect the user to figure this out themselves as from an API perspective there's no reason to expect `train_and_evaluate` would work where `train` fails (one might reasonably assume `train_and_evaluate` calls `train`)."
  },
  {
    "labels": ["documentation"],
    "text": "Does the page [Eager Execution basics](https://www.tensorflow.org/tutorials/eager/eager_basics) have the right title? It hardly touches on eager execution, might be better named Tensor Basics."
  },
  {
    "labels": [null, "documentation"],
    "text": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04 \r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**1.11:\r\n- **Python version**:3.6\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI think I have found that the contrib.opt.AdamWOptimizer and associated decoupled weight decay optimizers do not function correctly when using learning rate decay without explicitly applying the decay to the weight_decay parameter. \r\n\r\nIn the original paper, as seen in algorithm 2, the schedule multiplier is factored out and applied to the whole expression, the current interface means you have to do `AdamWOptimizer(weight_decay=wd*decay, learning_rate=lr*decay)` to achieve parity with the paper, this is not in its self an issue, but I think the documentation should reflect this difference. Alternatively the API could give a schedule multiplier parameter and then fixed lr and wd parameters used. \r\n\r\nHappy to submit a PR if someone can advise whether a documentation or interface update is the desired approach.\r\n\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: docker\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: n/a\r\n- **TensorFlow installed from (source or binary)**: docker\r\n- **TensorFlow version (use command below)**: latest-gpu-py3\r\n- **Python version**: python3\r\n- **Bazel version (if compiling from source)**: n/a\r\n- **GCC/Compiler version (if compiling from source)**: n/a\r\n- **CUDA/cuDNN version**: \r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**: toco\r\n\r\n### Describe the problem\r\nAttempting to convert TF graph to TF-lite using the latest stable GPU Python3 docker image. Commands (shown below) differ from those shown in documentation [here](https://www.tensorflow.org/lite/devguide). Additionally, toco conversion of graph throws errors about unsupported operations Fill, Unpack, and MeanSquaredDifference. \r\n\r\nDownloading the latest bazel in the docker container and rebuilding toco from source gives a clearly different version.\r\n\r\n### Source code / logs\r\n\r\n```\r\nusage: toco [-h] --output_file OUTPUT_FILE\r\n            (--graph_def_file GRAPH_DEF_FILE | --saved_model_dir SAVED_MODEL_DIR | --keras_model_file KERAS_MODEL_FILE)\r\n            [--output_format {TFLITE,GRAPHVIZ_DOT}] [--inference_type {FLOAT,QUANTIZED_UINT8}]\r\n            [--inference_input_type {FLOAT,QUANTIZED_UINT8}] [--input_arrays INPUT_ARRAYS] [--input_shapes INPUT_SHAPES]\r\n            [--output_arrays OUTPUT_ARRAYS] [--saved_model_tag_set SAVED_MODEL_TAG_SET]\r\n            [--saved_model_signature_key SAVED_MODEL_SIGNATURE_KEY] [--std_dev_values STD_DEV_VALUES]\r\n            [--mean_values MEAN_VALUES] [--default_ranges_min DEFAULT_RANGES_MIN]\r\n            [--default_ranges_max DEFAULT_RANGES_MAX] [--quantize_weights QUANTIZE_WEIGHTS] [--drop_control_dependency]\r\n            [--reorder_across_fake_quant] [--change_concat_input_ranges] [--allow_custom_ops]\r\n            [--dump_graphviz_dir DUMP_GRAPHVIZ_DIR] [--dump_graphviz_video]\r\n```"
  },
  {
    "labels": [null, "documentation"],
    "text": "\r\n\r\n### System information\r\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): window10 and jupyter\r\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: iPhone X\r\nTensorFlow installed from (source or binary): source\r\nTensorFlow version (use command below): 1.11\r\nPython version: 3.6\r\nBazel version (if compiling from source):\r\nGCC/Compiler version (if compiling from source):\r\nCUDA/cuDNN version: 9.1 / 7.1\r\nGPU model and memory:\r\nExact command to reproduce:\r\n\r\n\r\n### Describe the problem\r\nI used the tensorflow github example form [here](https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/generative_examples/image_captioning_with_attention.ipynb#scrollTo=Cffg2i257iMS) change the CNN model \r\n`img = tf.keras.applications.inception_v3.preprocess_input(img)\r\n--->img = tf.keras.applications.inception_resnet_v2.preprocess_input(img)`\r\n\r\n`image_model = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet')\r\n---->image_model =tf.keras.applications.InceptionResNetV2(include_top=False, weights='imagenet')`\r\n\r\nthe output\r\n```\r\nEpoch 1 Batch 0 Loss nan\r\nEpoch 1 Batch 100 Loss nan\r\nEpoch 1 Batch 200 Loss nan\r\nEpoch 1 Batch 300 Loss nan\r\nEpoch 1 Loss nan\r\n```\r\ni have tried to change the learning rate and loss function,even others CNN model (vgg19,vgg16) but it was same \r\n\r\n### Source code / logs\r\nthe Source code is tensorflow example [from here](https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/generative_examples/image_captioning_with_attention.ipynb#scrollTo=Cffg2i257iMS)\r\nyou just need to change the CNN model and wait a few minute  run it."
  },
  {
    "labels": ["documentation"],
    "text": "Tensorflow [Add a new op tutorial](https://www.tensorflow.org/extend/adding_an_op) never mention the building instructions for GPU ops. \r\n\r\nI find one [here](https://gist.github.com/Sergio0694/fc94fb14388ee4b7b92be6e33704e5b9), but it met the similar issue with [Building custom op instructions out of date ](https://github.com/tensorflow/tensorflow/issues/13607).\r\n`\r\ntensorflow.python.framework.errors_impl.NotFoundError: ./libcuda_op.so: undefined symbol: _ZTIN10tensorflow8OpKernelE`\r\n\r\n\r\nTensorflow really needs to give some suggestions on how to build GPU ops."
  },
  {
    "labels": ["documentation"],
    "text": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS 10.13.6\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: no\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: v1.10.0-rc1-19-g656e7a2b34 1.10.0\r\n- **Python version**: 3.6.5\r\n- **Bazel version (if compiling from source)**: no\r\n- **GCC/Compiler version (if compiling from source)**: no\r\n- **CUDA/cuDNN version**: no\r\n- **GPU model and memory**: no\r\n- **Exact command to reproduce**: `python bug.py`\r\n\r\n### Describe the problem\r\n\r\nIf we feed a `SparseTensorValue` to `tf.data.Dataset.from_tensor_slices` such that its indices are not lexicographically sorted by row then col, then we will get a `InvalidArgumentError`.\r\n\r\nMaybe it could be said in the docs, or the error should provide a clearer message. It was hard to guess that `indices[2] = [1,0] is out of order` meant the indices were not provided in lexicographic order.\r\n\r\nI finally saw that it was explained in the [`SparseTensor` docs](https://www.tensorflow.org/api_docs/python/tf/SparseTensor), but I feel it should be said in the [`SparseTensorValue` docs](https://www.tensorflow.org/api_docs/python/tf/SparseTensorValue) as well.\r\n\r\n### Source code / logs\r\n\r\n```python\r\nfrom scipy.sparse import csr_matrix\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n\r\nM = np.array([[0, 1, 1], [1, 0, 0], [1, 0, 2], [0, 1, 1]])\r\n\r\n# First observation: these two slicing operations provide different orderings\r\nS = csr_matrix(M)[1:3].tocoo()\r\nprint('1:3', S.row, S.col)\r\nS = csr_matrix(M)[[1, 2]].tocoo()\r\nprint('1,2', S.row, S.col)\r\n\r\nentries = np.column_stack((S.row, S.col, S.data))\r\nordering = np.arange(len(S.data))\r\n\r\n# Uncomment the following line to fix the error\r\n# ordering = np.lexsort((S.col, S.row))  # Sort by row then col\r\n\r\nX_train = tf.SparseTensorValue(indices=entries[ordering, :2],\r\n                               values=entries[ordering, 2],\r\n                               dense_shape=S.shape)\r\n\r\ndataset = tf.data.Dataset.from_tensor_slices(X_train)\r\niterator = dataset.make_initializable_iterator()\r\nX_sample = iterator.get_next()\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(iterator.initializer)\r\n    print(sess.run(X_sample))\r\n```\r\n\r\n    Traceback (most recent call last):\r\n      File \"/Users/jilljenn/code/vae/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1278, in _do_call\r\n        return fn(*args)\r\n      File \"/Users/jilljenn/code/vae/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1263, in _run_fn\r\n        options, feed_dict, fetch_list, target_list, run_metadata)\r\n      File \"/Users/jilljenn/code/vae/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1350, in _call_tf_sessionrun\r\n        run_metadata)\r\n    tensorflow.python.framework.errors_impl.InvalidArgumentError: indices[2] = [1,0] is out of order\r\n         [[Node: SerializeManySparse = SerializeManySparse[T=DT_INT64, out_type=DT_VARIANT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](tensors/SparseTensor/indices, tensors/SparseTensor/values, tensors/SparseTensor/dense_shape)]]\r\n\r\n    During handling of the above exception, another exception occurred:\r\n\r\n    Traceback (most recent call last):\r\n      File \"bug.py\", line 27, in <module>\r\n        sess.run(iterator.initializer)\r\n      File \"/Users/jilljenn/code/vae/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 877, in run\r\n        run_metadata_ptr)\r\n      File \"/Users/jilljenn/code/vae/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1100, in _run\r\n        feed_dict_tensor, options, run_metadata)\r\n      File \"/Users/jilljenn/code/vae/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1272, in _do_run\r\n        run_metadata)\r\n      File \"/Users/jilljenn/code/vae/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1291, in _do_call\r\n        raise type(e)(node_def, op, message)\r\n    tensorflow.python.framework.errors_impl.InvalidArgumentError: indices[2] = [1,0] is out of order\r\n         [[Node: SerializeManySparse = SerializeManySparse[T=DT_INT64, out_type=DT_VARIANT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](tensors/SparseTensor/indices, tensors/SparseTensor/values, tensors/SparseTensor/dense_shape)]]\r\n\r\n    Caused by op 'SerializeManySparse', defined at:\r\n      File \"bug.py\", line 22, in <module>\r\n        dataset = tf.data.Dataset.from_tensor_slices(X_train)\r\n      File \"/Users/jilljenn/code/vae/venv/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 254, in from_tensor_slices\r\n        return TensorSliceDataset(tensors)\r\n      File \"/Users/jilljenn/code/vae/venv/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1173, in __init__\r\n        self._tensors = sparse.serialize_many_sparse_tensors(tensors)\r\n      File \"/Users/jilljenn/code/vae/venv/lib/python3.6/site-packages/tensorflow/python/data/util/sparse.py\", line 132, in serialize_many_sparse_tensors\r\n        for tensor in nest.flatten(tensors)\r\n      File \"/Users/jilljenn/code/vae/venv/lib/python3.6/site-packages/tensorflow/python/data/util/sparse.py\", line 132, in <listcomp>\r\n        for tensor in nest.flatten(tensors)\r\n      File \"/Users/jilljenn/code/vae/venv/lib/python3.6/site-packages/tensorflow/python/ops/sparse_ops.py\", line 1469, in serialize_many_sparse\r\n        out_type=out_type)\r\n      File \"/Users/jilljenn/code/vae/venv/lib/python3.6/site-packages/tensorflow/python/ops/gen_sparse_ops.py\", line 502, in serialize_many_sparse\r\n        out_type=out_type, name=name)\r\n      File \"/Users/jilljenn/code/vae/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n        op_def=op_def)\r\n      File \"/Users/jilljenn/code/vae/venv/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\r\n        return func(*args, **kwargs)\r\n      File \"/Users/jilljenn/code/vae/venv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\r\n        op_def=op_def)\r\n      File \"/Users/jilljenn/code/vae/venv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\r\n        self._traceback = tf_stack.extract_stack()\r\n\r\n    InvalidArgumentError (see above for traceback): indices[2] = [1,0] is out of order\r\n         [[Node: SerializeManySparse = SerializeManySparse[T=DT_INT64, out_type=DT_VARIANT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](tensors/SparseTensor/indices, tensors/SparseTensor/values, tensors/SparseTensor/dense_shape)]]"
  },
  {
    "labels": ["documentation"],
    "text": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:na\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:na\r\n- **TensorFlow installed from (source or binary)**:na\r\n- **TensorFlow version (use command below)**:na\r\n- **Python version**:na\r\n- **Bazel version (if compiling from source)**:na\r\n- **GCC/Compiler version (if compiling from source)**:na\r\n- **CUDA/cuDNN version**:na\r\n- **GPU model and memory**:na\r\n- **Exact command to reproduce**:na\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nIn the documentation \"Creating Custom Estimators\" (https://www.tensorflow.org/guide/custom_estimators), under \"Write an Input function\", it is claimed that the function is the same as in \"pre-made Estimator implementation\" (https://www.tensorflow.org/guide/premade_estimators) and in iris_data.py (https://github.com/tensorflow/models/blob/master/samples/core/get_started/iris_data.py). But in both these sources the function is returning the created dataset, while in \"Creating Custom Estimators\" the function returns dataset.make_one_shot_iterator().get_next() instead.\r\n\r\nI haven't been able to understand if both approaches are equivalent, or if both are correct but yield different results, or if one of them is wrong. But in any of these situations, I think the documentation should state why it is using the get next operations instead of the original dataset, since it refers to sources where dataset is used instead.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n\"Creating Custom Estimators\": https://www.tensorflow.org/guide/custom_estimators\r\nClaim: \"_Our custom Estimator implementation uses the same input function as our pre-made Estimator implementation, from iris_data.py. Namely:_\"\r\nFunction:\r\n```\r\ndef train_input_fn(features, labels, batch_size):\r\n    \"\"\"An input function for training\"\"\"\r\n    # Convert the inputs to a Dataset.\r\n    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\r\n\r\n    # Shuffle, repeat, and batch the examples.\r\n    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\r\n\r\n    # Return the read end of the pipeline.\r\n    return dataset.make_one_shot_iterator().get_next()\r\n```\r\n\"Premade Estimators\": https://www.tensorflow.org/guide/premade_estimators\r\nFunction:\r\n```\r\ndef train_input_fn(features, labels, batch_size):\r\n    \"\"\"An input function for training\"\"\"\r\n    # Convert the inputs to a Dataset.\r\n    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\r\n\r\n    # Shuffle, repeat, and batch the examples.\r\n    return dataset.shuffle(1000).repeat().batch(batch_size)\r\n```\r\niris_data.py: https://github.com/tensorflow/models/blob/master/samples/core/get_started/iris_data.py\r\nFunction:\r\n```\r\ndef train_input_fn(features, labels, batch_size):\r\n    \"\"\"An input function for training\"\"\"\r\n    # Convert the inputs to a Dataset.\r\n    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\r\n    # Shuffle, repeat, and batch the examples.\r\n    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\r\n    # Return the dataset.\r\n    return dataset\r\n```"
  },
  {
    "labels": ["documentation"],
    "text": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nnot relevant\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux 4.9.0-8-amd64 #1 SMP Debian 4.9.110-3+deb9u4 (2018-08-21) x86_64 GNU/Linux\r\nVERSION_ID=\"9\"\r\nVERSION=\"9 (stretch)\"\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n1.10.1 (from pip binary)\r\n- **TensorFlow version (use command below)**:\r\ntf.VERSION = 1.10.1\r\ntf.GIT_VERSION = v1.10.1-0-g4dcfddc5d1\r\ntf.COMPILER_VERSION = v1.10.1-0-g4dcfddc5d1\r\n- **Python version**:\r\nPython 3.5.3\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2017 NVIDIA Corporation\r\nBuilt on Fri_Nov__3_21:07:56_CDT_2017\r\nCuda compilation tools, release 9.1, V9.1.85\r\n\r\n- **GPU model and memory**:\r\nTesla P100-PCIE-16GB\r\n\r\n- **Exact command to reproduce**:\r\n\r\n\r\n### Describe the problem\r\nIt appears that the kernel of `tf.reduce_sum` is not registerd for GPU's if the type of the tensor to be summed is `int64` (only registered for `tf.int32`)\r\nMoreover the kernel of `tf.tile` is not registered for the case where the tensor to be tiled is of type `tf.int32` (only registered for `tf.int64`)\r\n\r\nWhy is there this inconsistency?\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "There were additional topics discussed that could not be turned into coherent notes after the fact.\r\n\r\n## Action items\r\n   * TensorFlow team to create a block diagram and then go deeper.  Goal is to help people who want to contribute plugins or extensions. [#22356](https://github.com/tensorflow/tensorflow/issues/22356)\r\n   * Make the NVIDIA Library to TF Version matrix more visible and consider better error messages. [#22357](https://github.com/tensorflow/tensorflow/issues/22357)\r\n   * Document tips and methods to use for large batch scaling with TensorFlow.  Possibly mention where this is proven and unproven to work.  This would include adding optimizers or wrapper to simplify usage.  Researchers are large labs want to scale but do not have the knowledge to do it quickly. [#22358](https://github.com/tensorflow/tensorflow/issues/22358)\r\n\r\n## General Questions and discussion results\r\n\r\n   * Should TensorFlow default builds move forward more aggressively with newer versions of CUDA/cuDNN?\r\n      * Internally Google moves slowly to new versions of CUDA as the verification process is long and often includes multiple patches with NVIDIA until all edge cases are covered.  The bar is extremely high for obvious reasons.\r\n      * Group thought was it doesn’t matter. Situation would be improved with better error messages indicating what version is needed and making the matrix showing what NVIDIA libs are needed for each TensorFlow version.\r\n   * Provide more models with good performance and accuracy in github.com/tensorflow/models.  Too many different versions and unsure which one to use.  Example:  There are 3+ ResNet models.\r\n      * Contact tfboyd@ or comment in this thread if there is a specific model of interest and why.  MLPerf may improve this situation.\r\n   * Auto regressive models with long dependency chains are hard to optimize by doing fusion by hand.\r\n      * Consider trying XLA and providing feedback. An objective of XLA is to reduce the need for custom fusion.\r\n   * [Ask] Distributing the input pipeline across servers.  Some work has been done and rumored to have occured in production but not trivial to setup.  Consider an RFP and/or reach out to the tf.data team.\r\n   * TensorCores are only used if you are using tf.16.  You can do Pseudo FP16 with an envar that should be in TF 1.11 from NVIDIA as an experimental feature.  You still need to do loss scaling.\r\n\r\n## Debugging and performance investigations\r\n   * Hard to get timelines and profiler results.\r\n      * New guide is on the way, not positive this will make it as easy as desired.\r\n   * [Ask] Provide an interface to autotuning parameters such as intra and inter thread pools.\r\n      * In hindsight, more information is needed to make this actionable.  Please add info to the comments.  \r\n\r\n## Distributed compute (multi-gpu and multi-node)\r\n   * All reduce API for multi-node and support MPI.\r\n      * MPI would be useful for supercomputers where you need to use their MPI library to get good communication.\r\n      * NCCL currently used by MirroredStrategy but only for multi-GPU.  TensorFlow’s own `ops` are used for multi-node all-reduce.\r\n\r\n   * Document on how the distribution strategies is setup with the goal of showing how others can add their own solution and collective ops.  The API is the best place right now to figure this out.\r\n   * [AI] TensorFlow team to create a block diagram and then go deeper.  Goal is to help people who want to contribute plugins or extensions.\r\n   * Having a hard time with MPI.  People are using a newer versions of MPI\r\n   * How do we plan to support fault tolerance? Will it allow dynamic addition and removal of machines to the collective. E.g. preemption but keep training with a smaller pool. Also increasing machines & batch size as training progresses. Need to adjust the learning rate, so maybe get a callback, especially when you are going to lose or have just lost a machine. Response to call back is starting with revised set of machines an new learning rate.\r\n   *[AI] Document strategies for large batch training.  LARS looking to automatic learning rate, warmup rate and stuff.  \r\n\r\n## Model parallelism and Data parallelism\r\n   * Model parallelism is currently manual.  Work to automate it is on going and it can be phrased as an RL problem.  \r\n   * Data parallelism supported via MirroredStrategy discussed today\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: n/a\r\n- **TensorFlow installed from (source or binary)**: binary (Docker tensorflow/tensorflow)\r\n- **TensorFlow version (use command below)**: 1.10.1 (from core/public/version.h)\r\n- **Python version**:2.7.12\r\n- **Bazel version (if compiling from source)**: n/a\r\n- **GCC/Compiler version (if compiling from source)**: n/a\r\n- **CUDA/cuDNN version**: n/a\r\n- **GPU model and memory**: n/a\r\n- **Exact command to reproduce**: \r\n\\# docker run -it tensorflow/tensorflow bash\r\nroot@xxxxxxx:/notebooks# python2.7 -c \"import tensorflow as tf\"\r\nIllegal instruction\r\n\r\n### Describe the problem\r\nThis is a request to update documentation to include minimal system requirements, especially the description for Docker images that include prebuilt binaries.\r\n\r\nFor example, the main Docker image on DockerHub (tensorflow/tensorflow, 19M downloads) [currently does not operate on CPU's without AVX support](https://github.com/tensorflow/tensorflow/issues/17411).  This includes CPUs sold as recently as 4 years ago.\r\n\r\nThis requirement should be stated in the Docker image description displayed in DockerHub.  Perhaps also include a link to an alternative docker image that users with non-AVX CPUs may utilize to build from source.\r\n\r\n### Source code / logs\r\nn/a\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  MacOS 10.13.5 (Non-Relevant)\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:  Non-Relevant\r\n- **TensorFlow installed from (source or binary)**: Unsure\r\n- **TensorFlow version (use command below)**: org.tensorflow:tensorflow-android:1.9.0 Non-Relevant\r\n- **Python version**:  N/A\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**:N/A\r\n\r\n### Describe the problem\r\n\r\nIn Android Yolo Sample Code\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/src/org/tensorflow/demo/TensorFlowYoloDetector.java#L171\r\n\r\n```java\r\n        new float[gridWidth * gridHeight * (NUM_CLASSES + 5) * NUM_BOXES_PER_BLOCK];\r\n        ............\r\n        for (int y = 0; y < gridHeight; ++y) {\r\n           for (int x = 0; x < gridWidth; ++x) {\r\n               for (int b = 0; b < NUM_BOXES_PER_BLOCK; ++b) {\r\n                   ..........\r\n                    for (int c = 0; c < NUM_CLASSES; ++c) {\r\n                        classes[c] = output[offset + 5 + c];\r\n```\r\nalong with the following output decoding process, is not compatible with the original paper\r\nthese code assumes the output formats was \r\n\r\n **grid * grid * (class + 5) * box** \r\n\r\nbut in the original paper and other resource , this should be   \r\n\r\n**grid * grid * (class + box * 5)**\r\n\r\nas per in the paper [https://arxiv.org/pdf/1506.02640.pdf]( S * S * (B * 5 + C) )\r\nthis is totally different in format and size since every offset of the grid messed up\r\nthe paper indicates that the network only predicts one set of class probabilities per cell, regardless of the number of boxes B\r\n\r\n### Source code / logs\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/src/org/tensorflow/demo/TensorFlowYoloDetector.java#L171\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/src/org/tensorflow/demo/TensorFlowYoloDetector.java#L187-L213\r\n\r\nhttps://arxiv.org/pdf/1506.02640.pdf\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: n/a\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: n/a\r\n- **TensorFlow installed from (source or binary)**: n/a\r\n- **TensorFlow version (use command below)**: 1.10\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: n/a\r\n- **GCC/Compiler version (if compiling from source)**: n/a\r\n- **CUDA/cuDNN version**: n/a\r\n- **GPU model and memory**: n/a\r\n- **Exact command to reproduce**: n/a\r\n\r\n### Describe the problem\r\nDocumentation problem. In the method documentation for 'tf.data.Dataset.padded_batch', the argument of `padded_shapes` is described to be \r\n\r\n> A nested structure of `tf.TensorShape` or `tf.int64` vector tensor-like objects...\r\n\r\nPython contains a myriad of different nesting structures. I would like the doc to at least refer to some complete definition of what this nested structure can be. Can it contain lists, tuples, dicts, sets? Maybe even more complex objects? Can it be an arbitrary non-cyclic graph? Please make clear any limitations on this structure.\r\n\r\n### Source code / logs\r\n[https://github.com/tensorflow/tensorflow/blob/r1.10/tensorflow/python/data/ops/dataset_ops.py](https://github.com/tensorflow/tensorflow/blob/r1.10/tensorflow/python/data/ops/dataset_ops.py)\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "### System information\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): window10 and jupyter\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: iPhone X\r\n- TensorFlow installed from (source or binary): source \r\n- **TensorFlow version (use command below)**: 1.9\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 9.1 / 7.1\r\n- **GPU model and memory**: \r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\n\r\ni used tensorflow1.9 function `tf.keras.applications.InceptionResNetV2` and follow the tensorflow document from [here](https://tensorflow.google.cn/versions/r1.9/api_docs/python/tf/keras/applications/InceptionResNetV2?authuser=2&hl=vi) ,but can't used on the tensorflow  [example code,](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/generative_examples/image_captioning_with_attention.ipynb)\r\nit will be print error`int() argument must be a string, a bytes-like object or a number, not'TensorShape'`but others Library (vgg16,19 & inception_v3..and so on) can work!\r\n \r\n### Source code / \r\ninput  image-----\r\n`def load_image(image_path):`\r\n    `img = tf.read_file(image_path)`\r\n   ` img = tf.image.decode_jpeg(img, channels=3)`\r\n   ` img = tf.image.resize_images(img, (299, 299))`\r\n    `img = tf.keras.applications.inception_resnet_v2.preprocess_input(img)`\r\n   ` return img, image_path`\r\n\r\ncreate mode -----\r\n`image_model =tf.keras.applications.inception_resnet_v2.InceptionResNetV2(include_top=False, \r\n                                                                                                                        weights='imagenet')`\r\n\r\n\r\nthe error -------\r\n`TypeError                                 Traceback (most recent call last)\r\n<ipython-input-8-fe73201476b6> in <module>()\r\n      1 startTime=time.time()\r\n----> 2 image_model =tf.keras.applications.inception_resnet_v2.InceptionResNetV2(include_top=False, weights='imagenet')\r\n      3 \r\n      4 #image_model = inception_v4.create_model(weights='imagenet', include_top=True)\r\n      5 new_input = image_model.input\r\n\r\nD:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\inception_resnet_v2.py in InceptionResNetV2(include_top, weights, input_tensor, input_shape, pooling, classes)\r\n    304   for block_idx in range(1, 11):\r\n    305     x = inception_resnet_block(\r\n--> 306         x, scale=0.17, block_type='block35', block_idx=block_idx)\r\n    307 \r\n    308   # Mixed 6a (Reduction-A block): 17 x 17 x 1088\r\n\r\nD:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\inception_resnet_v2.py in inception_resnet_block(x, scale, block_type, block_idx, activation)\r\n    187       output_shape=K.int_shape(x)[1:],\r\n    188       arguments={'scale': scale},\r\n--> 189       name=block_name)([x, up])\r\n    190   if activation is not None:\r\n    191     x = Activation(activation, name=block_name + '_ac')(x)\r\n\r\nD:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    712           input_shapes = nest.map_structure(lambda x: x.get_shape(), inputs)\r\n    713 \r\n--> 714         output_shapes = self.compute_output_shape(input_shapes)\r\n    715         output_shapes = nest.flatten(output_shapes)\r\n    716         outputs = [\r\n\r\nD:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py in compute_output_shape(self, input_shape)\r\n    675 \r\n    676   def compute_output_shape(self, input_shape):\r\n--> 677     input_shape = tuple(tensor_shape.TensorShape(input_shape).as_list())\r\n    678 \r\n    679     if self._output_shape is None:\r\n\r\nD:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py in __init__(self, dims)\r\n    539       else:\r\n    540         # Got a list of dimensions\r\n--> 541         self._dims = [as_dimension(d) for d in dims_iter]\r\n    542     self._ndims = None\r\n    543 \r\n\r\nD:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py in <listcomp>(.0)\r\n    539       else:\r\n    540         # Got a list of dimensions\r\n--> 541         self._dims = [as_dimension(d) for d in dims_iter]\r\n    542     self._ndims = None\r\n    543 \r\n\r\nD:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py in as_dimension(value)\r\n    480     return value\r\n    481   else:\r\n--> 482     return Dimension(value)\r\n    483 \r\n    484 \r\n\r\nD:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py in __init__(self, value)\r\n     35       raise TypeError(\"Cannot convert %s to Dimension\" % value)\r\n     36     else:\r\n---> 37       self._value = int(value)\r\n     38       if (not isinstance(value, compat.bytes_or_text_types) and\r\n     39           self._value != value):\r\n\r\nTypeError: int() argument must be a string, a bytes-like object or a number, not 'TensorShape'`"
  },
  {
    "labels": [null, "documentation"],
    "text": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n"
  },
  {
    "labels": [null, "documentation", null],
    "text": "Please provide an example, documentation for tensorflow audio recognition on iOS as you provide on Android [(example).](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/src/org/tensorflow/demo/SpeechActivity.java)"
  },
  {
    "labels": [null, "documentation"],
    "text": "hi all,\r\n\r\nit would be really great to have a tutorial on how to use the many awesome wrappers like dropoutwrapper, attentionwrapper, etc. "
  },
  {
    "labels": [null, "documentation"],
    "text": "There are many flags/options for tensorflow build, some of them are performance related.\r\nUser may want to build a whl from source (with some modifications) , using **exactly the same** build configuration that prebuilt binary used\r\n\r\nWith previous Jenkins CI server, we can still figure out the build configuration from log of a release-xxxx build job.\r\nBut now with the new internal build system, it is not quite clear what build configuration is used for prebuilt binary anymore.\r\ne.g. \r\ncuda compute capability: default value in configure.py (3.5,7.0) seems not complete.\r\ncpu simd option: one may have to search release note to figure out whether it is still AVX.\r\n\r\nIt will be great to document the build setting somewhere, or introduce some script to produce prebuilt binary for a release.\r\nThanks.\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "1. It must be a bug, a feature request, or **a significant problem with documentation** (for small docs fixes please send a PR instead).\r\n------------------------\r\n\r\n### System information (N/A)\r\n\r\n### Describe the problem\r\n#1749 was closed with the note that \"We revamped our docs. Feel free to open a new issue if this is still missing from our new docs.\" \r\n\r\nDespite being the \"recommended format\" for input data, I still can't find any official documentation on creating TFRecords, and what the best practices are surrounding this task.\r\n\r\nIt seems strange that blogs and the source code are the only sources of information on this. I think it would be a good idea to have an official guide showing how to go from a directory of images to some TFRecords. Maybe using [this script from tensorflow/models](https://github.com/tensorflow/models/blob/master/research/inception/inception/data/build_imagenet_data.py) as an example.\r\n\r\n### Source code / logs (N/A)"
  },
  {
    "labels": [null, "documentation"],
    "text": "------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: 1.9\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: tf.contrib.data.AUTOTUNE\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\nAccording to release notes for 1.8, there is a new parameter called tf.contrib.data.AUTOTUNE. It's functionality is described in release notes as follows:\r\n 'Add tf.contrib.data.AUTOTUNE, which allows the tf.data runtime to automatically tune the prefetch buffer sizes based on your system and environment.'\r\nBut I couldn't find any other documentation associated with it in [tf.dataset ](https://www.tensorflow.org/api_docs/python/tf/data)\r\n\r\nI used it in my pipeline as shown below and it didn't give any errors. But I have no idea how it works and which circumstances I should use it. Please provide some documentation on how to use this feature.\r\n\r\n### Source code / logs\r\n```\r\n#Make dataset for training\r\ndataset_train = tf.data.Dataset.from_tensor_slices((file_ids_training,file_names_training))\r\ndataset_train = dataset_train.flat_map(lambda file_id,file_name: tf.data.Dataset.from_tensor_slices(\r\n    tuple (tf.py_func(_get_data_for_dataset, [file_id,file_name], [tf.float32,tf.float32]))))\r\n\r\ndataset_train= dataset_train.shuffle(buffer_size=train_buffer_size)\r\ndataset_train= dataset_train.repeat()\r\ndataset_train= dataset_train.batch(train_batch_size) #Make dataset, shuffle, and create batches\r\ndataset_train = dataset_train.prefetch(tf.contrib.data.AUTOTUNE)\r\n\r\ndataset_train_iterator = dataset_train.make_one_shot_iterator()\r\nget_train_batch = dataset_train_iterator.get_next()\r\n```"
  },
  {
    "labels": ["documentation"],
    "text": "In the tutorial \"_Getting Started with TensorFlow_\" there is a code segment for image classification, using the MNIST dataset. The segment includes a Keras Sequential model, which is missing the `input_shape` argument in the first layer. \r\n\r\nIn particular, I propose changing: \r\n- `tf.keras.layers.Flatten()` to `tf.keras.layers.Flatten(input_shape = (28, 28))`.\r\n\r\n\"_Getting Started with TensorFlow_\" link: https://www.tensorflow.org/tutorials/"
  },
  {
    "labels": [null, "documentation"],
    "text": "The example in the `tf.train.natural_exp_decay` documentation uses an nonexistent function called `exponential_time_decay`. Also, it is missing the `decay_steps` parameter in both the example and the showed equation\r\n\r\nEquation:\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/python/training/learning_rate_decay.py#L316\r\nExample\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/python/training/learning_rate_decay.py#L326"
  },
  {
    "labels": ["documentation"],
    "text": "--------------------\r\n\r\n### Describe the problem\r\nThe link https://ci.tensorflow.org/view/Nightly/job/nightly-android/ (prebuilt android libraries) is broken but is still used in various files in documentation :\r\n- https://www.tensorflow.org/mobile/android_build#android_inference_library\r\n- https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/android/README.md\r\n\r\nI use it for my app, but obviously I can't download the new versions. \r\n\r\nIs there a new link from which we could retrieve built binaries for Android ? \r\nWhy has the nightly-android stopped running and will it restart eventually ?\r\nCan someone fix the documentation files ?\r\n\r\nThanks. \r\n\r\n### UPDATE\r\nHave I written custom code N/A\r\nOS Platform and Distribution N/A\r\nTensorFlow installed from N/A\r\nTensorFlow version N/A\r\nBazel version N/A\r\nCUDA/cuDNN version N/A\r\nGPU model and memory N/A\r\nExact command to reproduce N/A\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "### System information\r\n\r\nNo relevant for this issue.\r\n\r\n### Describe the problem\r\n\r\nThe current documentation for [`tf.tables_initializer`](https://www.tensorflow.org/api_docs/python/tf/tables_initializer) states\r\n\r\n> Returns an Op that initializes all tables of the default graph.\r\n\r\nAs a beginner, it is not clear to me why we would need tables in TF. So, I think the documentation should add a few examples of use-cases where tables are created (initialized) and used. In other words, the documentation should briefly answer the questions \r\n\r\n1. Why do we need tables in TF? \r\n2. What does it even mean to initialize a table? \r\n   1. In which cases would tables need (or not) to be initialized? \r\n3. What kind of tables are these? Hash-tables?\r\n4. In general, what are examples of use-cases where tables are used?\r\n\r\nIn the documentation, there's also \"See the guide: Variables > Sparse Variable Updates\", but [Variables > Sparse Variable Updates](https://www.tensorflow.org/api_guides/python/state_ops#Sparse_Variable_Updates), if I understood correctly, doesn't answer the questions above.\r\n\r\nGiven that I don't think I am very qualified to answer the questions above, I decided to open this issue, instead of submitting a PR.\r\n\r\n### Source code / logs\r\n \r\nNo relevant for this issue."
  },
  {
    "labels": ["documentation"],
    "text": "The documentation at [`tensorflow/examples/ios/README.md #reducing-the-binary-size`](https://github.com/tensorflow/tensorflow/blob/c941c087a9dfd5b27eff00ead928c9ee208e9a35/tensorflow/examples/ios/README.md#reducing-the-binary-size) features the following (two-year-old) snippet:\r\n\r\n> After that, you can manually look at modifying the list of kernels included in `tensorflow/contrib/makefile/tf_op_files.txt` to reduce the number of implementations to the ones you're actually using in your own model. We're hoping to automate this step in the future, but for now manually removing them is the best approach.\r\n\r\nToday, selective registration uses `tensorflow/core/framework/ops_to_register.h` and commit\r\nc4ef927b5eaf144dbf1e0419c0d1d3fd968177bd introduced the `OPTIMIZE_FOR_GRAPH` option in `tensorflow/contrib/makefile/build_all_ios.sh` which automates its creation.\r\n\r\nI think the documentation (and possibly tooling) for iOS selective registration need to be updated."
  },
  {
    "labels": [null, "documentation"],
    "text": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: y \r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux  4.14.8-gentoo-r1\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.8.0\r\n- **Python version**: 3.5.5\r\n- **Bazel version (if compiling from source)**: n\r\n- **GCC/Compiler version (if compiling from source)**: n\r\n- **CUDA/cuDNN version**: 7.1.4\r\n- **GPU model and memory**:  GeForce GTX 1080 Ti / 11171MiB\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nCurrently I am working on making predictions of two models (outputs of model1 as inputs of model2) with large amount of inputs. I tried to use tf.data.Dataset.from_generator, while it seems there are some problems about context stack.\r\n\r\n### Source code / logs\r\nHere is my example\r\n``` python\r\nimport tensorflow as tf\r\n\r\ndef model_fn(features, labels, mode):\r\n    x = features[\"inputs\"]\r\n    W = tf.get_variable(\r\n        name=\"weight\",\r\n        shape=[1],\r\n        dtype=tf.float32,\r\n        initializer=tf.initializers.constant(value=0.0),\r\n        trainable=(mode == tf.estimator.ModeKeys.TRAIN),\r\n    )\r\n    b = tf.get_variable(\r\n        name=\"bias\",\r\n        shape=[1],\r\n        dtype=tf.float32,\r\n        initializer=tf.initializers.constant(value=0.0),\r\n        trainable=(mode == tf.estimator.ModeKeys.TRAIN),\r\n    )\r\n    hypothesis = W * x + b\r\n    if mode == tf.estimator.ModeKeys.TRAIN:\r\n        y = labels[\"labels\"]\r\n        cost = tf.square(hypothesis - y)\r\n        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\r\n        train_op = optimizer.minimize(\r\n            loss=cost, global_step=tf.train.get_global_step())\r\n    else:\r\n        train_op = None\r\n        cost = None\r\n    return tf.estimator.EstimatorSpec(\r\n        mode=mode, predictions=hypothesis, loss=cost, train_op=train_op)\r\n\r\n\r\ndef get_input_fn(inputs, num_epochs=1):\r\n    def gen():\r\n        for item in inputs:\r\n            if isinstance(item, tuple) or isinstance(item, list):\r\n                yield item\r\n            else:\r\n                yield item, 0\r\n\r\n    def input_fn():\r\n        dataset = tf.data.Dataset.from_generator(\r\n            gen, (tf.float32, tf.float32),\r\n            (tf.TensorShape([]), tf.TensorShape([])))\r\n        dataset = dataset.repeat(num_epochs)\r\n        dataset = dataset.batch(1)\r\n        iterator = dataset.make_one_shot_iterator()\r\n        inputs, labels = iterator.get_next()\r\n        return {\"inputs\": inputs}, {\"labels\": labels}\r\n\r\n    return input_fn\r\n\r\n\r\nmodel1 = tf.estimator.Estimator(model_fn=model_fn, model_dir=\"model1\")\r\nmodel2 = tf.estimator.Estimator(model_fn=model_fn, model_dir=\"model2\")\r\n# model1.train(input_fn=get_input_fn([(1, 1), (2, 2), (3, 3)], num_epochs=100))\r\n# model2.train(input_fn=get_input_fn([(1, 2), (2, 4), (3, 6)], num_epochs=100))\r\n\r\n# ok\r\nfor item in model1.predict(input_fn=get_input_fn([1, 2, 3, 4])):\r\n    print(item)\r\n# ok\r\nfor item in model2.predict(input_fn=get_input_fn([1, 2, 3, 4])):\r\n    print(item)\r\n\r\nmodel1_output = model1.predict(input_fn=get_input_fn([1, 2, 3, 4]))\r\nmodel2_input_fn = get_input_fn(model1_output)\r\n# IndexError: pop from empty list\r\n# tensorflow/python/framework/ops.py\", line 5267, in get_controller\r\n#    context.context().context_switches.pop()\r\nfor item in model2.predict(model2_input_fn):\r\n    print(item)\r\n```\r\n\r\nError log\r\n```\r\nTraceback (most recent call last):\r\n\r\n  File \"/home/miacro/.local/lib64/python3.5/site-packages/tensorflow/python/ops/script_ops.py\", line 157, in __call__\r\n    ret = func(*args)\r\n\r\n  File \"/home/miacro/.local/lib64/python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 382, in generator_py_func\r\n    values = next(generator_state.get_iterator(iterator_id))\r\n\r\n  File \"test.py\", line 36, in gen\r\n    for item in inputs:\r\n\r\n  File \"/home/miacro/.local/lib64/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 519, in predict\r\n    for key, value in six.iteritems(preds_evaluated)\r\n\r\n  File \"/usr/lib64/python3.5/contextlib.py\", line 66, in __exit__\r\n    next(self.gen)\r\n\r\n  File \"/home/miacro/.local/lib64/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 5267, in get_controller\r\n    context.context().context_switches.pop()\r\n\r\n  File \"/home/miacro/.local/lib64/python3.5/site-packages/tensorflow/python/eager/context.py\", line 136, in pop\r\n    self.stack.pop()\r\n\r\nIndexError: pop from empty list\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/miacro/.local/lib64/python3.5/site-packages/tensorflow/python/client/session.py\", line 1322, in _do_call\r\n    return fn(*args)\r\n  File \"/home/miacro/.local/lib64/python3.5/site-packages/tensorflow/python/client/session.py\", line 1307, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"/home/miacro/.local/lib64/python3.5/site-packages/tensorflow/python/client/session.py\", line 1409, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.UnknownError: IndexError: pop from empty list\r\nTraceback (most recent call last):\r\n\r\n  File \"/home/miacro/.local/lib64/python3.5/site-packages/tensorflow/python/ops/script_ops.py\", line 157, in __call__\r\n    ret = func(*args)\r\n\r\n  File \"/home/miacro/.local/lib64/python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 382, in generator_py_func\r\n    values = next(generator_state.get_iterator(iterator_id))\r\n\r\n  File \"test.py\", line 36, in gen\r\n    for item in inputs:\r\n\r\n  File \"/home/miacro/.local/lib64/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 519, in predict\r\n    for key, value in six.iteritems(preds_evaluated)\r\n\r\n  File \"/usr/lib64/python3.5/contextlib.py\", line 66, in __exit__\r\n    next(self.gen)\r\n\r\n  File \"/home/miacro/.local/lib64/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 5267, in get_controller\r\n    context.context().context_switches.pop()\r\n\r\n  File \"/home/miacro/.local/lib64/python3.5/site-packages/tensorflow/python/eager/context.py\", line 136, in pop\r\n    self.stack.pop()\r\n\r\nIndexError: pop from empty list\r\n\r\n\r\n         [[Node: PyFunc = PyFunc[Tin=[DT_INT64], Tout=[DT_FLOAT, DT_FLOAT], token=\"pyfunc_7\"](arg0)]]\r\n         [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?], [?]], output_types=[DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator)]]\r\n         [[Node: IteratorGetNext/_19 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_6_IteratorGetNext\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 72, in <module>\r\n    for item in model2.predict(model2_input_fn):\r\n  File \"/home/miacro/.local/lib64/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 509, in predict\r\n    preds_evaluated = mon_sess.run(predictions)\r\n  File \"/home/miacro/.local/lib64/python3.5/site-packages/tensorflow/python/training/monitored_session.py\", line 567, in run\r\n    run_metadata=run_metadata)\r\n  File \"/home/miacro/.local/lib64/python3.5/site-packages/tensorflow/python/training/monitored_session.py\", line 1043, in run\r\n    run_metadata=run_metadata)\r\n  File \"/home/miacro/.local/lib64/python3.5/site-packages/tensorflow/python/training/monitored_session.py\", line 1134, in run\r\n    raise six.reraise(*original_exc_info)\r\n  File \"/usr/lib64/python3.5/site-packages/six.py\", line 693, in reraise\r\n    raise value\r\n  File \"/home/miacro/.local/lib64/python3.5/site-packages/tensorflow/python/training/monitored_session.py\", line 1119, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/home/miacro/.local/lib64/python3.5/site-packages/tensorflow/python/training/monitored_session.py\", line 1191, in run\r\n    run_metadata=run_metadata)\r\n  File \"/home/miacro/.local/lib64/python3.5/site-packages/tensorflow/python/training/monitored_session.py\", line 971, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/home/miacro/.local/lib64/python3.5/site-packages/tensorflow/python/client/session.py\", line 900, in run\r\n    run_metadata_ptr)\r\n  File \"/home/miacro/.local/lib64/python3.5/site-packages/tensorflow/python/client/session.py\", line 1135, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/home/miacro/.local/lib64/python3.5/site-packages/tensorflow/python/client/session.py\", line 1316, in _do_run\r\n    run_metadata)\r\n  File \"/home/miacro/.local/lib64/python3.5/site-packages/tensorflow/python/client/session.py\", line 1335, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.UnknownError: IndexError: pop from empty list\r\nTraceback (most recent call last):\r\n\r\n  File \"/home/miacro/.local/lib64/python3.5/site-packages/tensorflow/python/ops/script_ops.py\", line 157, in __call__\r\n    ret = func(*args)\r\n\r\n  File \"/home/miacro/.local/lib64/python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 382, in generator_py_func\r\n    values = next(generator_state.get_iterator(iterator_id))\r\n\r\n  File \"test.py\", line 36, in gen\r\n    for item in inputs:\r\n\r\n  File \"/home/miacro/.local/lib64/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 519, in predict\r\n    for key, value in six.iteritems(preds_evaluated)\r\n\r\n  File \"/usr/lib64/python3.5/contextlib.py\", line 66, in __exit__\r\n    next(self.gen)\r\n\r\n  File \"/home/miacro/.local/lib64/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 5267, in get_controller\r\n    context.context().context_switches.pop()\r\n\r\n  File \"/home/miacro/.local/lib64/python3.5/site-packages/tensorflow/python/eager/context.py\", line 136, in pop\r\n    self.stack.pop()\r\n\r\nIndexError: pop from empty list\r\n\r\n\r\n         [[Node: PyFunc = PyFunc[Tin=[DT_INT64], Tout=[DT_FLOAT, DT_FLOAT], token=\"pyfunc_7\"](arg0)]]\r\n         [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?], [?]], output_types=[DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator)]]\r\n         [[Node: IteratorGetNext/_19 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_6_IteratorGetNext\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n\r\n```"
  },
  {
    "labels": ["documentation", null],
    "text": "The https://www.tensorflow.org/ site would be greatly improved by a sticky flag (stored in a cookie in the browser) for the version you're using.  This would be used (as a default) for the landing page and search results.  People could choose to set it, or use have some such value as 'stable' for the latest stable release.\r\n\r\nI waste a lot of time repeatedly navigating from 1.8 to the right version for the environment I'm working in.  When reading the docs, I prefer to read them for the right version of the API ..."
  },
  {
    "labels": ["documentation"],
    "text": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: n/a\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: n/a\r\n- **TensorFlow installed from (source or binary)**: n/a\r\n- **TensorFlow version (use command below)**: n/a\r\n- **Python version**:  n/a\r\n- **Bazel version (if compiling from source)**: n/a\r\n- **GCC/Compiler version (if compiling from source)**: n/a\r\n- **CUDA/cuDNN version**: n/a\r\n- **GPU model and memory**: n/a\r\n- **Exact command to reproduce**: n/a\r\n\r\nDocumentation Suggestion: In `https://www.tensorflow.org/performance/datasets_performance` I think it would be worth:\r\n\r\n- Adding some mention of `tf.contrib.data.prefetch_to_device()`. This method isn't presented in this document, nor in the basic programming guide at `https://www.tensorflow.org/programmers_guide/datasets`. It's hard to know about this potentially useful method if it's not mentioned. I only learned of it when watching a Youtube video by Derek Murray from the TF Dev Summit 2018.\r\n\r\n- In `https://www.tensorflow.org/performance/datasets_performance`, in addition to mentioning `.prefetch_to_device()` I think it would be useful to some to clarify how it's different from `.prefetch()`, perhaps with a useful diagram like the one presented to clarify `.prefetch()`. I've seen several questions online about this point. I think it's clear when one carefully reads the documentation, but some extra clarity wouldn't hurt.\r\n\r\n- Also, more examples of how to use these tools would be nice...for example, some before (using `feed_dict` for all data into a model) vs after (using `tf.data.Dataset` and associated tools) would be helpful.\r\n\r\nThank you.\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "After trying to figure out how to use tensorflow profiler to test my model I am giving up. Current `README.md`  does not only lack details but is actually quite confusing. "
  },
  {
    "labels": [null, "documentation"],
    "text": "### Describe the problem\r\nYou are declaring GPLv3 attribution at https://github.com/tensorflow/tensorflow/blob/v1.8.0/third_party/eigen3/LICENSE#L1011 for a directory that you have removed. The license attributed is also improperly identified as GPLv3 but instead should be GPLv2 as per Eigen's own repo, https://github.com/eigenteam/eigen-git-mirror/blob/master/bench/btl/COPYING.\r\nThe later isn't of much concern since you already removed the directory, but the former shows that you need to update your attribution to correctly reflect what is in the package. Thanks!"
  },
  {
    "labels": ["documentation"],
    "text": "Thanks for this tutorial, found it super-useful and helped me understand a lot. It would be great to see a version that uses Tensorflow.js / for Node, and how this works differently."
  },
  {
    "labels": ["documentation"],
    "text": "The error occurs when I click develop button in \"www.tensorflow.org/programmers_guide/variables\" or in everywhere. My default lang is set to English(but it does not matter and has influence only on the bottom menu). But when I'm trying to change the language to Chinese I get the following error message:\r\n\r\n- XSRF Token missing or incorrect\r\n\r\n![image](https://user-images.githubusercontent.com/19337606/41533342-02b6581e-732d-11e8-95a9-afbe28a40dbe.png)\r\n\r\n![image](https://user-images.githubusercontent.com/19337606/41533370-1cda29dc-732d-11e8-9912-2eb9583feb71.png)\r\n\r\nWindows 10\r\nVersion 67.0.3396.87 (Official Build) (64-bit)\r\n\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "Hello,\r\n\r\nMy question is considering the inference in C++ API using batches. I'm trying to run SSD net based on Mobilenet. It works on a single image, but when I try to use multiple images inference, I can't understand how to get the multiple outputs. It seems like my program runs properly as a run time increased for a batch inference though.\r\nHere is my sample code: I'm loading a batch of 32 images with OpenCV, transform them into a input tensor and run the Session. I need to understand what should I change in order to get 32 outputs. \r\nThank you.\r\n\r\n```\r\nint main(int argc, char* argv[]) {\r\n\t//string image(argv[1]);\r\n\tint batchSize = 32;\r\n\tstring pathFilenameImg1 = \"Patch6.jpg\";\r\n\tstring pathFilenameImg2 = \"Patch1.jpg\";\r\n\tstring pathFilenameImg3 = \"Patch2.jpg\";\r\n\tstring pathFilenameImg4 = \"Patch3.jpg\";\r\n\tstring pathFilenameImg5 = \"Patch0.jpg\";\r\n\tstring pathFilenameImg6 = \"Patch1.jpg\";\r\n\tstring pathFilenameImg7 = \"Patch2.jpg\";\r\n\tstring pathFilenameImg8 = \"Patch3.jpg\";\r\n\tstring graph = \"ssd_mobilenet.pb\";\r\n\tstring labels = \"security_labels.txt\";\r\n\tint32 input_width = 512;\r\n\tint32 input_height = 512;\r\n\tint32 input_depth = 3;\r\n\tstring input_layer = \"image_tensor\";\r\n\tvector<string> output_layer = { \"detection_boxes:0\", \"detection_scores:0\", \"detection_classes:0\", \"num_detections:0\"};\r\n\r\n\tbool self_test = false;\r\n\tstring root_dir = \"\";\r\n\r\n\t// First we load and initialize the model.\r\n\tstd::unique_ptr<tensorflow::Session> session;\r\n\tstring graph_path = tensorflow::io::JoinPath(root_dir, graph);\r\n\tLOG(ERROR) << \"graph_path:\" << graph_path;\r\n\tStatus load_graph_status = LoadGraph(graph_path, &session);\r\n\tif (!load_graph_status.ok()) {\r\n\t\tLOG(ERROR) << \"LoadGraph ERROR!!!!\" << load_graph_status;\r\n\t\treturn -1;\r\n\t}\r\n\r\n\r\n\t// Read and prepare images using OpenCV:\r\n\tstd::vector<string> imgPathArray= { pathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1, pathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1, \r\n\t\t\t\t\t\t\t\t\t\tpathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1, pathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1,\r\n\t\t\t\t\t\t\t\t\t\tpathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1, pathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1,\r\n\t\tpathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1, pathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1\r\n\t};\r\n\tstd::vector<cv::Mat> imgArray;\r\n\tfor (int i = 0; i < batchSize; i++)\r\n\t\timgArray.push_back(cv::imread(imgPathArray.at(i)));\r\n\r\n\r\n\t// creating a Tensor for storing the data\r\n\tTensor input_tensor(tensorflow::DT_UINT8, tensorflow::TensorShape({ batchSize, input_height, input_width, input_depth}));\r\n\tauto input_tensor_mapped = input_tensor.tensor<uchar, 4>();\r\n\r\n\tfor (int bz = 0; bz < batchSize; ++bz) {\r\n\t\tuchar *source_data;\r\n\t\tsource_data = imgArray.at(bz).data;\r\n\t\tfor (int y = 0; y < input_height; ++y) {\r\n\t\t\tuchar* source_row = source_data + (y * input_width * input_depth);\r\n\t\t\tfor (int x = 0; x < input_width; ++x) {\r\n\t\t\t\tuchar* source_pixel = source_row + (x * input_depth);\r\n\t\t\t\tuchar* source_B = source_pixel + 0;\r\n\t\t\t\tuchar* source_G = source_pixel + 1;\r\n\t\t\t\tuchar* source_R = source_pixel + 2;\r\n\t\t\t\tinput_tensor_mapped(bz, y, x, 0) = *source_R;\r\n\t\t\t\tinput_tensor_mapped(bz, y, x, 1) = *source_G;\r\n\t\t\t\tinput_tensor_mapped(bz, y, x, 2) = *source_B;\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\r\n\r\n\t/*// Get the image from disk as a float array of numbers, resized and normalized\r\n\t// to the specifications the main graph expects.\r\n\tstd::vector<Tensor> resized_tensors;\r\n\tstring image_path = tensorflow::io::JoinPath(root_dir, image);\r\n\tStatus read_tensor_status = ReadTensorFromImageFile(image_path, input_height, input_width, input_mean, input_std, &resized_tensors);\r\n\tif (!read_tensor_status.ok()) {\r\n\t\tLOG(ERROR) << read_tensor_status;\r\n\t\treturn -1;\r\n\t}\r\n\tconst Tensor& resized_tensor = resized_tensors[0];\r\n\r\n\tLOG(ERROR) << \"image shape:\" << resized_tensor.shape().DebugString() << \",len:\" << resized_tensors.size() << \",tensor type:\" << resized_tensor.dtype();*/\r\n\r\n\r\n\t// Actually run the image through the model.\r\n\tstd::vector<Tensor> outputs;\r\n\r\n\tstd::chrono::steady_clock::time_point begin = std::chrono::steady_clock::now();\r\n\tStatus run_status = session->Run({ { input_layer, input_tensor} }, output_layer, {}, &outputs);\r\n\tstd::chrono::steady_clock::time_point end = std::chrono::steady_clock::now();\tstd::cout << \"Time difference (sec) = \" << (std::chrono::duration_cast<std::chrono::microseconds>(end - begin).count()) / 1000000.0 << std::endl;\r\n\r\n\tif (!run_status.ok()) {\r\n\t\tLOG(ERROR) << \"Running model failed: \" << run_status;\r\n\t\treturn -1;\r\n\t}\r\n\r\n\t//int image_width = resized_tensor.dims();\r\n\t//int image_height = 0;\r\n\t//int image_height = resized_tensor.shape()[1];\r\n\r\n\t//LOG(ERROR) << \"output size:\" << outputs.size() << \",image_width:\" << image_width << \",image_height:\" << image_height << endl;\r\n\r\n\tauto boxes = outputs[0].flat_outer_dims<float, 3>();\r\n\ttensorflow::TTypes<float>::Flat scores = outputs[1].flat<float>();\r\n\ttensorflow::TTypes<float>::Flat classes = outputs[2].flat<float>();\r\n\ttensorflow::TTypes<float>::Flat num_detections = outputs[3].flat<float>();\r\n\r\n\r\n\t//LOG(ERROR) << \"num_detections:\" << num_detections(0) << \",\" << outputs[0].shape().DebugString();\r\n\tint BarcodeCnt = 0;\r\n\tint GyoshCnt = 0;\r\n\tfor (size_t i = 0; i < num_detections(0) && i < 20; ++i)\r\n\t{\r\n\t\tif (scores(i) > 0.9)\r\n\t\t{\r\n\t\t\tLOG(ERROR) <<\"score:\" << scores(i) << \",class:\" << classes(i) << \",box:\" << \",\" << boxes(0, i, 0) << \",\" << boxes(0, i, 1) << \",\" << boxes(0, i, 2) << \",\" << boxes(0, i, 3);\r\n\t\t\tif(classes(i) == 1)\r\n\t\t\t\tBarcodeCnt++;\r\n\t\t\telse\r\n\t\t\t\tGyoshCnt ++;\r\n\t\t}\r\n\t}\r\n\tLOG(ERROR) << \"Total number of Security Barcodes is :\" << BarcodeCnt;\r\n\tLOG(ERROR) << \"Total number of Security Gyoshes is :\" << GyoshCnt;\r\n\r\n\t\r\n\r\n\r\n\treturn 0;\r\n}\r\n```"
  },
  {
    "labels": [null, "documentation"],
    "text": "I haven't filled out the provided form because this is a feature request for the documentation.\r\n\r\nThe documentation for [`tf.train.MomentumOptimizer`](https://www.tensorflow.org/api_docs/python/tf/train/MomentumOptimizer) offers a `use_nesterov` parameter on which the documentation says the following:\r\n\r\n> `use_nesterov`: If True use Nesterov Momentum. See [Sutskever et al.,\r\n> 2013](http://proceedings.mlr.press/v28/sutskever13.pdf). This\r\n> implementation always computes gradients at the value of the\r\n> variable(s) passed to the optimizer. Using Nesterov Momentum makes the\r\n> variable(s) track the values called `theta_t + mu*v_t` in the paper.\r\n\r\nThe problem is that the linked paper outlines the normal NAG algorithm, which requires computation of a gradient at a different value to those provided (namely at the next step). This is not clarified in the documentation and led me to some confusion. I ended up [asking this question on StackOverflow](https://stackoverflow.com/questions/50774683/how-is-nesterovs-accelerated-gradient-descent-implemented-in-tensorflow) and cobbled together [an answer myself](https://stackoverflow.com/a/50774886/1613983), however I think the answer by `user1735003` is so complete that without too much wrangling it could greatly enhance the documentation:\r\n\r\n[Answer by `user1735003`](https://stackoverflow.com/a/50778921/1613983)\r\n\r\nSome clarification to the fact that tensorflow actually implements a modified version of the algorithm which is only correct under certain conditions would have been very helpful and would have saved me some time."
  },
  {
    "labels": [null, "documentation"],
    "text": "------------------------\r\n------------------------\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: 1.8\r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: Visual Studio 2015\r\n- **CUDA/cuDNN version**: Yes\r\n- **GPU model and memory**:  NVIDIA Quadro P5000 16GB\r\n- **Exact command to reproduce**: N/A\r\n------------------------\r\n------------------------\r\n\r\n### Description of the problem: Save Training Results using Tensorflow C++ VS2015\r\nI have successfully compiled tensorflow to be able to use the C++ with VS2015, and I have successfully run some examples.\r\n\r\nI want to save my training results and restore them to be able to continue training or simply to use the network to perform e.g. classification.\r\n\r\nI was unable until now to perform that, and the C++ interface didn't have many examples or tutorials available.\r\n\r\nCan someone provide me some instructions to perform that?\r\n\r\n------------------------\r\n------------------------"
  },
  {
    "labels": ["documentation"],
    "text": "Small, possible error found in https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#4:\r\n\"The first figure shows accuracy (x-axis) as a function of training progress (y-axis):\"\r\n\r\nShould be corrected to:\r\n\"The first figure shows accuracy (y-axis) as a function of training progress (x-axis):\"\r\n\r\nOr you can change the \"accuracy_1\" graph below it."
  },
  {
    "labels": [null, "documentation"],
    "text": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: r1.8\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**: 0.11.0\r\n- **GCC/Compiler version (if compiling from source)**: 4.9\r\n- **CUDA/cuDNN version**: No\r\n- **GPU model and memory**: No\r\n- **Exact command to reproduce**: ` bazel build tensorflow/tools/graph_transforms:transform_graph`\r\n\r\n### Describe the problem\r\nI followed the proposed commands for optimizing the model. However, \"remove_node(op=Identity, op=CheckNumerics)\" and \"fold_old_batch_norms\" cannot be used together.\r\n\r\n### Source code / logs\r\n```\r\nbazel-bin/tensorflow/tools/graph_transforms/transform_graph \\\r\n--in_graph=resnet-18_train.pb \\\r\n--out_graph=opt_resnet-18_train.pb \\\r\n--inputs='input_x' \\\r\n--outputs='output/BiasAdd' \\\r\n--transforms='\r\nstrip_unused_nodes(type=float, shape=\"1,224,224,3\")\r\nremove_nodes(op=Identity, op=CheckNumerics)\r\nfold_old_batch_norms\r\nfold_batch_norms'\r\n```\r\nError:\r\n> 2018-05-24 20:53:06.184534: I tensorflow/tools/graph_transforms/transform_graph.cc:264] Applying strip_unused_nodes\r\n2018-05-24 20:53:06.259019: I tensorflow/tools/graph_transforms/transform_graph.cc:264] Applying remove_nodes\r\n2018-05-24 20:53:06.486037: I tensorflow/tools/graph_transforms/transform_graph.cc:264] Applying fold_old_batch_norms\r\n2018-05-24 20:53:06.513047: E tensorflow/tools/graph_transforms/transform_graph.cc:210] Beta input to batch norm has bad shape: [64]\r\n\r\nHowever, if \"remove_node(op=Identity, op=CheckNumerics)\" is removed\r\n```\r\nbazel-bin/tensorflow/tools/graph_transforms/transform_graph \\\r\n--in_graph=resnet-18_train.pb \\\r\n--out_graph=opt_resnet-18_train.pb \\\r\n--inputs='input_x' \\\r\n--outputs='output/BiasAdd' \\\r\n--transforms='\r\nstrip_unused_nodes(type=float, shape=\"1,224,224,3\")\r\nfold_old_batch_norms\r\nfold_batch_norms'\r\n```\r\nIt then works...\r\n\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "Dropout layer is (usually) only used while training. Keras automatically enable dropout layers while training and disable them while predicting.\r\n\r\nThus, tf.keras.layers.Dropout has no 'is_training' argument (but it exists in tf.layers.dropout). That can mislead Keras and tf users when trying to mix Keras with TF layers. Indeed, predicting new data with dropout layers doesn't produce any error but reduces the accuracy ! Maybe a warning note in 'tf.keras.layers.Dropout' documentation can be useful. \r\n\r\nWith tf.layers\r\n```\r\ndropout = tf.layers.dropout(inputs=dense, rate=0.2, training=is_training, name=\"dropout-1\")\r\n```\r\n\r\nWith tf.Keras.layers\r\n```\r\ndense = ...\r\nif(is_training):\r\n      dropout = tf.keras.layers.Dropout(0.2, noise_shape=None, seed=None)(dense)\r\n  else :\r\n      dropout = dense\r\n```"
  },
  {
    "labels": [null, "documentation"],
    "text": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: osx 10.11.6\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.8\r\n- **Python version**: NA\r\n- **Bazel version (if compiling from source)**: NA\r\n- **GCC/Compiler version (if compiling from source)**: NA\r\n- **CUDA/cuDNN version**: NA\r\n- **GPU model and memory**: NA\r\n- **Exact command to reproduce**: https://github.com/ravwojdyla/minimal-repo-tf-crashing\r\n\r\n### Describe the problem\r\nWe have an issue open in scio (https://github.com/spotify/scio/issues/1137) which depends on java TF artifacts, please read full description in the link above. A TLDR: in cross test TF crushes with:\r\n\r\n```\r\nCannot register 2 metrics with the same name: /tensorflow/cc/saved_model/load_attempt_count\r\n```\r\n\r\nThis problem started to manifest itself from version 1.4.0 (previous versions were not affected), and continues to be a problem. The minimal reproduction repo is here: https://github.com/ravwojdyla/minimal-repo-tf-crashing and to reproduce you run `sbt +test`.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS 10.13\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: v1.8.0-0-g93bc2e2072 1.8.0\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\n\r\n`tf.gfile.Open` in `\"w\"` mode delays the creation of the file until the first write. This is different from the buitin [`open`](https://docs.python.org/3/library/functions.html#open), which creates a file right away. I am not sure if this is a bug, or the intended behaviour, but I think should be clarified in the documention of `tf.gfile.Open`.\r\n\r\n### Source code / logs\r\n\r\n```python\r\n>>> import tensorflow as tf\r\n>>> tf.gfile.Open(\"hdfs://root/tmp/user/test\", \"wb\").close()\r\n>>> tf.gfile.Exists(\"hdfs://root/tmp/user/test\")\r\n# ...\r\nFalse\r\n>>> tf.gfile.Open(\"/tmp/test\", \"wb\").close()\r\n>>> tf.gfile.Exists(\"/tmp/test\")\r\nFalse\r\n```"
  },
  {
    "labels": [null, "documentation"],
    "text": "In the [official documentation][1] of tf.nn.raw_rnn we have emit structure as the third output of loop_fn when the loop_fn is run for the first time\r\n\r\nlater on the emit_structure is used to copy tf.zeros_like(emit_structure) to the minibatch entries that are finished by `emit = tf.where(finished, tf.zeros_like(emit_structure), emit)`\r\n\r\nmy lack of understanding is: emit structure is `None` so `tf.where(finished, tf.zeros_like(emit_structure), emit)` is going to throw a ValueError as `tf.zeros_like(None)` does so. Can somebody please fill in what i am missing here?\r\n\r\nbasically even the example implementation of dynamic_rnn using raw_rnn is simple wrong\r\nto quote exact parts:\r\nin dynamic_rnn implementation shown\r\n```\r\ndef loop_fn(time, cell_output, cell_state, loop_state):\r\n  emit_output = cell_output  # == None for time == 0\r\n```\r\nand in raw_rnn we have:\r\n```\r\ntime = tf.constant(0, dtype=tf.int32)\r\n(finished, next_input, initial_state, emit_structure, loop_state) = loop_fn(\r\n    time=time, cell_output=None, cell_state=None, loop_state=None)\r\n.\r\n.\r\n.\r\n# Emit zeros and copy forward state for minibatch entries that are finished.\r\n  state = tf.where(finished, state, next_state)\r\n  emit = tf.where(finished, tf.zeros_like(emit_structure), emit)\r\n```\r\n\r\nThis will fail at the first time step itself. But i have gone through code, this is not how it is implemented. In case of None for emit_structure  cell_output is used.\r\n\r\nraw_rnn is really powerful and once i have understood it there is no going back to dynamic_rnn or any other rnn unfolding mechanism. But the documentation is making is really tough to understand this amazing api. An improvement is in order\r\n\r\nHave I written custom code N/A\r\nOS Platform and Distribution windows 10\r\nTensorFlow installed from https://www.tensorflow.org/install/install_windows\r\nTensorFlow version 1.7\r\nBazel version NA\r\nCUDA/cuDNN version NA\r\nGPU model and memory NA\r\nExact command to reproduce tf.zeros_like(None)\r\n\r\n\r\n  [1]: https://www.tensorflow.org/api_docs/python/tf/nn/raw_rnn"
  },
  {
    "labels": [null, "documentation"],
    "text": "From the [TensorFlow Deploy page](https://www.tensorflow.org/deploy/), the links for TensorFlow serving all give 404 page not found errors. \r\n\r\nFor example, try the [Installation page](https://www.tensorflow.org/setup)\r\n\r\nFor example, try the [Serving a TensorFlow Model](https://www.tensorflow.org/serving_basic)"
  },
  {
    "labels": [null, "documentation"],
    "text": "https://github.com/tensorflow/tensorflow/blob/a44996a84b24c43cca40c685a009fd59275755ab/tensorflow/contrib/slim/python/slim/learning.py#L573\r\n\r\nI believe there was a typo in the description in the penultimate word (\"and\"), which is probably worth replacing with \"are\".\r\nExample:  \r\nlog_every_n_steps: The frequency, in terms of global steps, that the loss and global step **are** logged."
  },
  {
    "labels": ["documentation"],
    "text": "While I was perusing the documentation for install_linux, I got to the section *Determine which TensorFlow to install*, and then I continued on.\r\n\r\nI was at *Determine how to install TensorFlow* and I settled on *Virtualenv*. So I went to that section, and I followed the steps. But when I got to the sub-section (2) stating\r\n\r\n> where `targetDirectory` specifies the top of the Virtualenv tree. Our instructions assume that `targetDirectory` is `~/tensorflow`, but you may choose any directory.\r\n\r\nI was caught off guard a bit. I didn't know if I had missed something, so I spent a bit of time back-tracking the documentation to see if that was the case. I finally decided to `mkdir ~/tensorflow` and give it a go.\r\n\r\nIt would be nice if there was a (sub-)section stating this. I don't want to write it, so I'm making it as an issue instead. I did do this amazing thing though: #18766"
  },
  {
    "labels": [null, "documentation"],
    "text": "------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Custom code\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: 1.7\r\n- **Python version**:  3.6\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**:\r\n`estimator_vae = tf.keras.estimator.model_to_estimator(keras_model=vae)`\r\n\r\n### Describe the problem\r\n `tf.keras.estimator.model_to_estimator()` API is failing when Keras model contains `Lambda ` layer.\r\nThe error I am getting is `SystemError: unknown opcode`\r\nThe problem seems to be only there when I am using custom functions inside the Keras mode.\r\n\r\n### Source code / logs\r\nI implemented a VAE in Keras and was trying to convert it into an TF estimator model. The model works and trains using Keras. The Keras model has functions for gaussian sampling and VAE training loss. The code and  error trace back is given below.\r\n\r\n```\r\n#Encoder network, mapping inputs to our latent distribution parameters:\r\nx = Input(batch_shape=(batch_size, original_dim),name='encoder_input')\r\nencoded = Dense(intermediate_dim, activation='relu',name='encoder_dense_1')(x)\r\nz_mean = Dense(latent_dim,name='z_mean')(encoded)\r\nz_log_var = Dense(latent_dim,name='z_log_var')(encoded)\r\n\r\n# Sampling from Gaussian\r\ndef sampling(args):\r\n    \r\n    z_mean, z_log_var = args\r\n\r\n    epsilon = tf.random_normal(shape=(batch_size, latent_dim),\r\n                               mean=0., stddev=epsilon_std) \r\n    \r\n    return z_mean + tf.exp(z_log_var/2) * epsilon\r\nz = Lambda(sampling,name='z')([z_mean, z_log_var]) \r\n\r\n#Compute VAE loss\r\ndef vae_loss(x, x_decoded):\r\n    x_mse_loss = original_dim*tf.keras.losses.mean_squared_error(tf.layers.flatten(x), tf.layers.flatten(x_decoded))\r\n    beta = 4.0\r\n    kl_loss = - 0.5*beta* tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1)\r\n    return tf.reduce_mean(x_mse_loss + kl_loss)\r\n\r\n# Map these sampled latent points back to reconstructed inputs:\r\n#Decoder network layers\r\ndecoder_dense_1 = Dense(intermediate_dim, activation='relu',name='decoder_dense_1')\r\ndecoder_output = Dense(48, activation='relu',name='decoder_output')\r\ndecoded = decoder_dense_1(z)\r\nx_decoded = decoder_output(decoded)\r\n\r\n# end-to-end autoencoder\r\nvae = Model(x, x_decoded)\r\nvae.compile(optimizer='adam',loss=vae_loss) \r\nvae.summary()\r\n#Converting to tf estimator\r\nestimator_vae = tf.keras.estimator.model_to_estimator(keras_model=vae)\r\n```\r\nOutput:\r\n\r\n```\r\n__________________________________________________________________________________________________\r\nLayer (type)                    Output Shape         Param #     Connected to                     \r\n==================================================================================================\r\nencoder_input (InputLayer)      (50, 48)             0                                            \r\n__________________________________________________________________________________________________\r\nencoder_dense_1 (Dense)         (50, 24)             1176        encoder_input[0][0]              \r\n__________________________________________________________________________________________________\r\nz_mean (Dense)                  (50, 10)             250         encoder_dense_1[0][0]            \r\n__________________________________________________________________________________________________\r\nz_log_var (Dense)               (50, 10)             250         encoder_dense_1[0][0]            \r\n__________________________________________________________________________________________________\r\nz (Lambda)                      (50, 10)             0           z_mean[0][0]                     \r\n                                                                 z_log_var[0][0]                  \r\n__________________________________________________________________________________________________\r\ndecoder_dense_1 (Dense)         (50, 24)             264         z[0][0]                          \r\n__________________________________________________________________________________________________\r\ndecoder_output (Dense)          (50, 48)             1200        decoder_dense_1[0][0]            \r\n==================================================================================================\r\nTotal params: 3,140\r\nTrainable params: 3,140\r\nNon-trainable params: 0\r\n__________________________________________________________________________________________________\r\nINFO:tensorflow:Using the Keras model provided.\r\nINFO:tensorflow:Using default config.\r\nWARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\SPLATH~1\\AppData\\Local\\Temp\\tmps7nagdhz\r\nINFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\SPLATH~1\\\\AppData\\\\Local\\\\Temp\\\\tmps7nagdhz', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000238136D9DA0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\r\n---------------------------------------------------------------------------\r\nSystemError                               Traceback (most recent call last)\r\n<ipython-input-10-77cc01c33881> in <module>()\r\n     13 vae.summary()\r\n     14 #Converting to tf estimator\r\n---> 15 estimator_vae = tf.keras.estimator.model_to_estimator(keras_model=vae)\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\estimator.py in model_to_estimator(keras_model, keras_model_path, custom_objects, model_dir, config)\r\n    481                            estimator,\r\n    482                            custom_objects,\r\n--> 483                            keras_weights)\r\n    484   elif keras_model.built:\r\n    485     logging.warning('You are creating an Estimator from a Keras model '\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\estimator.py in _save_first_checkpoint(keras_model, estimator, custom_objects, keras_weights)\r\n    396       training_util.create_global_step()\r\n    397       model = _clone_and_build_model(model_fn_lib.ModeKeys.TRAIN, keras_model,\r\n--> 398                                      custom_objects)\r\n    399       if isinstance(model, models.Sequential):\r\n    400         model = model.model\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\estimator.py in _clone_and_build_model(mode, keras_model, custom_objects, features, labels)\r\n    270         model = models.clone_model(keras_model, input_tensors=input_tensors)\r\n    271     else:\r\n--> 272       model = models.clone_model(keras_model, input_tensors=input_tensors)\r\n    273   else:\r\n    274     model = keras_model\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\models.py in clone_model(model, input_tensors)\r\n    261     return _clone_sequential_model(model, input_tensors=input_tensors)\r\n    262   else:\r\n--> 263     return _clone_functional_model(model, input_tensors=input_tensors)\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\models.py in _clone_functional_model(model, input_tensors)\r\n    166               kwargs['mask'] = computed_masks\r\n    167           output_tensors = generic_utils.to_list(layer(computed_tensors,\r\n--> 168                                                        **kwargs))\r\n    169           output_masks = generic_utils.to_list(\r\n    170               layer.compute_mask(computed_tensors, computed_masks))\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\base_layer.py in __call__(self, inputs, **kwargs)\r\n    237     \"\"\"\r\n    238     # Actually call the layer (optionally building it).\r\n--> 239     output = super(Layer, self).__call__(inputs, **kwargs)\r\n    240     if context.executing_eagerly():\r\n    241       return output\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py in __call__(self, inputs, *args, **kwargs)\r\n    712 \r\n    713         if not in_deferred_mode:\r\n--> 714           outputs = self.call(inputs, *args, **kwargs)\r\n    715           if outputs is None:\r\n    716             raise ValueError('A layer\\'s `call` method should return a Tensor '\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\layers\\core.py in call(self, inputs, mask)\r\n    640     if has_arg(self.function, 'mask'):\r\n    641       arguments['mask'] = mask\r\n--> 642     return self.function(inputs, **arguments)\r\n    643 \r\n    644   def compute_mask(self, inputs, mask=None):\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\layers\\core.py in sampling(args)\r\n     16 def sampling(args):\r\n     17     #import tensorflow as tf\r\n---> 18     z_mean, z_log_var = args\r\n     19 \r\n     20     epsilon = tf.random_normal(shape=(batch_size, latent_dim),\r\n\r\nSystemError: unknown opcode\r\n```\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nyes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary\r\n- **TensorFlow version (use command below)**:\r\n1.7\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n9.0\r\n- **GPU model and memory**:\r\nV100 16GB\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nIt is not clear in documents that, in Matmul, FP16xFP16 is accumulated to FP16 or FP32. \r\nThis choice affects not only training accuracy, but also TensorCore computing performance on Volta GPU.\r\n\r\n"
  },
  {
    "labels": [null, "documentation", null],
    "text": "Hello Tensorflow team, \r\n\r\nFirst of all let me thank you for your amazing job. Tensorflow is one of the greatest Deep Learning frameworks out there.\r\n\r\nI am opening this issue because I am experiencing  something weird after following the MNIST tutorial with the new Estimator high level interface. \r\nThe training and evaluation worked fine, but visualizing the model graph on Tensorboard there is something weird: the input shape that the model requires is 100 x 784.\r\nI thought I would see ?x784 there, because even if I did use 100 as a batch size in training, in the model function it is explicitly specified that the amount of samples in the input is variable:\r\n ```python\r\ninput_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1], name=\"input_layer\")\r\n```\r\n\r\nHere is a screenshot from Tensorboard: as you can see in the right box, expected input size is 100x784.\r\n\r\n![image](https://user-images.githubusercontent.com/6909990/38542816-285b9dc4-3ca3-11e8-99ac-dafb8b3822f3.png)\r\n\r\nAt first I thought this was a Tensorboard issue, but after some testing I don't think so anymore.\r\n\r\nFirst of all I tried to test my model changing the amount of input samples using the Estimator interface:\r\n- I tried to use the estimator.train and estimator.evaluate methods on the same model with different batch sizes (e.g. 50).\r\n- I tried to use the estimator.predict method passing a single sample at a time.  \r\n\r\nIn these cases, everything worked fine.\r\n\r\nAfter that, I have frozen my model using the \"freeze_graph\" script in the TensorFlow tools, and I have tried to load the frozen model into a GraphDef and to run it in a session.\r\nThis is the code I have used:\r\n```python\r\nimport tensorflow as tf\r\nimport cv2\r\nimport numpy as np\r\n\r\nwith tf.gfile.GFile(\"/path/to/my/frozen/model.pb\", \"rb\") as f:\r\n    graph_def = tf.GraphDef()\r\n    graph_def.ParseFromString(f.read())\r\n\r\nwith tf.Graph().as_default() as graph:\r\n    tf.import_graph_def(graph_def, name=\"prefix\")\r\n\r\n    for op in graph.get_operations():\r\n        print(op.name)\r\n\r\n    # so far it worked: i was able to print the operation of the MNIST model\r\n\r\n    x = graph.get_tensor_by_name('prefix/input_layer:0')\r\n    y = graph.get_tensor_by_name('prefix/softmax_tensor:0')\r\n\r\n    with tf.Session(graph=graph) as sess:\r\n        img = cv2.imread(\"/path/to/a/mnist/like/image.png\", cv2.IMREAD_GRAYSCALE)\r\n        img = np.asarray(1-img/255, dtype=np.float32)\r\n        img = np.reshape(img, (28, 28, 1))\r\n\r\n        y_out = sess.run(y, feed_dict={x: [img]})\r\n        print(y_out)\r\n```\r\n\r\nI got this error: **ValueError: Cannot feed value of shape (1, 28, 28, 1) for Tensor 'prefix/input_layer:0', which has shape '(100, 28, 28, 1)'**\r\n\r\nSo, I feel that I get problems if I try to use this model without passing through the Estimator interface.   \r\nThis worries me a lot, because in production I do need to freeze, optimize and convert my models to run them on TensorFlow Lite. So I won't be using the Estimator interface to perform prediction (but I still would like to employ it during training and evaluation).\r\n\r\n### Environment\r\n**Have I written custom code**: Yes, but only for testing purposes. My model was trained with this [MNIST tutorial code](https://github.com/tensorflow/tensorflow/blob/r1.7/tensorflow/examples/tutorials/layers/cnn_mnist.py) \r\n**OS Platform and Distribution**: MacOS High Sierra 10.13.3\r\n**TensorFlow installed from**: pip\r\n**TensorFlow version**: 1.7\r\n**Bazel version**: N/A\r\n**CUDA/cuDNN version**: N/A\r\n**GPU model and memory**: N/A\r\n**Exact command to reproduce**: N/A\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nNo\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: N/A\r\n- **TensorFlow installed from (source or binary)**: N/A\r\n- **TensorFlow version (use command below)**: 1.7\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\n Native TensorRT support in TensorFlow was announced by both [Google ](https://developers.googleblog.com/2018/03/tensorrt-integration-with-tensorflow.html) and Nvidia blog posts last week. But `tf.contrib.tensorrt` is missing from the Python API list. Currently, the only documentation is on readme file in the  [tensorflow/contrib/tensorrt](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/tensorrt) repository. But it doesn't given details about using the API.  Please include documentation for this important feature."
  },
  {
    "labels": ["documentation"],
    "text": "1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: ('v1.6.0-0-gd2e24b6039', '1.6.0')\r\n- **Python version**: Python 2.7.12 (default, Dec  4 2017, 14:50:18) [GCC 5.4.0 20160609] on linux2\r\n- **CUDA/cuDNN version**: Not using GPU\r\n- **GPU model and memory**: Not using GPU\r\n- **Exact command to reproduce**:\r\nFollow the \"wide_deep\" tutorial\r\nTry to freeze the generated model by running: \r\npython freeze_graph.py \r\n  --input_graph=/tmp/census_model/graph.pbtxt \r\n  --input_checkpoint=/tmp/census_model/model.ckpt-190 \r\n  --output_graph=/tmp/census_model/frozen_graph.pb\r\n  --output_node_names=softmax\r\n\r\nAn error is generated:\r\nTypeError: names_to_saveables must be a dict mapping string names to Tensors/Variables. Not a variable: Tensor(\"dnn/hiddenlayer_0/bias:0\", shape=(100,), dtype=float32)\r\n\r\n### Describe the problem\r\nI would think that the freeze_graph script should finish successfully, hence I believe the problem is that an error message is generated.\r\n\r\n### Source code / logs\r\nTraceback (most recent call last):\r\n  File \"freeze_graph.py\", line 380, in <module>\r\n    app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/media/LinuxApps/home/karsten/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 126, in run\r\n    _sys.exit(main(argv))\r\n  File \"freeze_graph.py\", line 274, in main\r\n    FLAGS.saved_model_tags, checkpoint_version)\r\n  File \"freeze_graph.py\", line 256, in freeze_graph\r\n    checkpoint_version=checkpoint_version)\r\n  File \"freeze_graph.py\", line 130, in freeze_graph_with_def_protos\r\n    var_list=var_list, write_version=checkpoint_version)\r\n  File \"/media/LinuxApps/home/karsten/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1293, in __init__\r\n    self.build()\r\n  File \"/media/LinuxApps/home/karsten/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1302, in build\r\n    self._build(self._filename, build_save=True, build_restore=True)\r\n  File \"/media/LinuxApps/home/karsten/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1339, in _build\r\n    build_save=build_save, build_restore=build_restore)\r\n  File \"/media/LinuxApps/home/karsten/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 774, in _build_internal\r\n    saveables = self._ValidateAndSliceInputs(names_to_saveables)\r\n  File \"/media/LinuxApps/home/karsten/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 677, in _ValidateAndSliceInputs\r\n    variable)\r\nTypeError: names_to_saveables must be a dict mapping string names to Tensors/Variables. Not a variable: Tensor(\"dnn/hiddenlayer_0/bias:0\", shape=(100,), dtype=float32)\r\n"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "Hi,\r\n\r\nAs per documentation in the below link:\r\n\r\n[https://www.tensorflow.org/versions/r1.5/install/install_linux#InstallingVirtualenv](url)\r\n\r\nRequirement for tensorflow 1.5 is Cuda 8. I installed tensorflow using the following tf binary url https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.5.0rc1-cp27-none-linux_x86_64.whl\r\n\r\nHowever, still it is asking for cuda 9. Is there any .whl, which supports cuda 8 ( tensorflow 1.5)."
  },
  {
    "labels": [null, "documentation"],
    "text": "System information\r\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux ubuntu 16.04\r\nTensorFlow installed from (source or binary): binary\r\nTensorFlow version (use command below): 1.4.1 gpu\r\nPython version: 3.5.4\r\nBazel version (if compiling from source):\r\nGCC/Compiler version (if compiling from source):\r\nCUDA/cuDNN version: Cuda 8.0/Cudnn 6.0\r\nGPU model and memory: Titan xp\r\nExact command to reproduce: no method for outer product\r\n\r\nDescribe the problem\r\nMany links in the documentation say 'see the guide' and point to `Building Graphs > ...` \r\nhttps://www.tensorflow.org/api_guides/python/framework#Core_graph_data_structures\r\nbut no prose guide is present. It would be useful to have some examples of using such methods as `tf.reset_default_graph` , etc.\r\n \r\n\r\nFor example, the `tf.Graph` page links to 'Building Graphs': https://www.tensorflow.org/api_docs/python/tf/Graph"
  },
  {
    "labels": [null, "documentation"],
    "text": "Hi all,\r\n\r\nLooks like parameter `num_sampled` in  `tf.nn.nce_loss` function defines the number of negative examples per a positive example but not per a batch as described in tensorflow documentation (https://www.tensorflow.org/api_docs/python/tf/nn/nce_loss) \r\n\r\n(see the next code)\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n# `_compute_sampled_logits` is invoked in nce_loss to generate negative sample and calculate logits\r\nfrom tensorflow.python.ops.nn_impl import _compute_sampled_logits\r\n\r\nembedding_size = 10\r\nwords_number = 300\r\nbatch_size = 3\r\nnum_sampled = 3\r\n\r\ngraph = tf.Graph()\r\nwith graph.as_default():\r\n    # Input data.\r\n    train_inputs = tf.placeholder(tf.int32, shape=[batch_size])\r\n    train_labels = tf.placeholder(tf.int64, shape=[batch_size, 1])\r\n\r\n    with tf.device('/cpu:0'):\r\n        embeddings = tf.Variable(\r\n                tf.random_uniform([words_number, embedding_size], -4., 4.))\r\n        embed = tf.nn.embedding_lookup(embeddings, train_inputs)\r\n        nce_weights = tf.Variable(\r\n                tf.random_uniform([words_number, embedding_size], -4., 4.))\r\n        nce_biases = tf.Variable(tf.zeros([words_number]))\r\n        \r\n    logits, labels = _compute_sampled_logits(\r\n                       weights=nce_weights,\r\n                       biases=nce_biases,\r\n                       inputs=embed,\r\n                       labels=train_labels,\r\n                       num_true=1,\r\n                       num_sampled=num_sampled,\r\n                       num_classes=words_number,\r\n                       remove_accidental_hits = False)\r\n    init = tf.global_variables_initializer()\r\n\r\n\r\nsession = tf.InteractiveSession(graph=graph)\r\ninit.run(session=session)\r\n\r\nbatch_inputs = np.array([0,1,2], dtype=np.int32)\r\nbatch_labels = np.array([[3],[4],[5]], dtype=np.int32)\r\n\r\nfeed_dict = {train_inputs : batch_inputs, train_labels : batch_labels}\r\nlogits_val, labels_val = session.run([logits, labels], feed_dict=feed_dict)\r\n\r\nprint (\"logits_val = {}\".format(logits_val))\r\nprint (\"labels_val = {}\".format(labels_val))\r\n\r\n```\r\n\r\nAs a result, `_compute_sampled_logits` function generated `num_sampled` examples per **1 positive example**:\r\n```\r\nlogits_val = [[ -8.18727493   2.02518415  14.18676853   0.51900673]\r\n [ -8.97232056   5.60003376   4.52866602   3.68161726]\r\n [ -0.36226368  -5.84330416  -3.39891291   5.58423615]]\r\nlabels_val = [[ 1.  0.  0.  0.]\r\n [ 1.  0.  0.  0.]\r\n [ 1.  0.  0.  0.]]\r\n```"
  },
  {
    "labels": ["documentation"],
    "text": "![image](https://user-images.githubusercontent.com/35289454/37821263-29a87d1c-2ea9-11e8-90b5-7f3bb5f42d49.png)\r\nIn the [FAQ section](https://www.tensorflow.org/programmers_guide/debugger#frequently_asked_questions), there seem to be some markdown formatting problems."
  },
  {
    "labels": ["documentation"],
    "text": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Google Colab (also tried on a Windows 10 machine with TF 1.6)\r\n- **TensorFlow installed from (source or binary)**: defaults from Colab\r\n- **TensorFlow version (use command below)**: 1.6.0\r\n- **Python version**: 3.6.3 (default, Oct  3 2017, 21:45:48)\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: see attached file\r\n\r\n### Describe the problem\r\nI'm new to tf.contrib.distributions. I've just copied the example for MaskedAutoregressiveFlow from [https://www.tensorflow.org/api_docs/python/tf/contrib/distributions/bijectors/MaskedAutoregressiveFlow](https://www.tensorflow.org/api_docs/python/tf/contrib/distributions/bijectors/MaskedAutoregressiveFlow). Running the example fails with a ValueError at `maf.sample()`. See the attached file and error log below.  Running `tf.global_variables_initializer()` in the session doesn't solve it either. It looks like `masked_autoregressive_default_template` expects a tensor with `ndim>1` but `MaskedAutoregressiveFlow.forward()` passes a tensor with `ndim=1`. \r\n\r\n[masked_autoregressive_issue.txt](https://github.com/tensorflow/tensorflow/files/1837741/masked_autoregressive_issue.txt)\r\n\r\n\r\n### Source code / logs\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-3-646c58f4e818> in <module>()\r\n     12 sess.run(tf.global_variables_initializer())\r\n     13 \r\n---> 14 x = maf.sample()  # Expensive; uses `tf.while_loop`, no Bijector caching.\r\n     15 maf.log_prob(x)   # Almost free; uses Bijector caching.\r\n     16 maf.log_prob(0.)  # Cheap; no `tf.while_loop` despite no Bijector caching.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/distributions/distribution.py in sample(self, sample_shape, seed, name)\r\n    687       samples: a `Tensor` with prepended dimensions `sample_shape`.\r\n    688     \"\"\"\r\n--> 689     return self._call_sample_n(sample_shape, seed, name)\r\n    690 \r\n    691   def _log_prob(self, value):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/distributions/transformed_distribution.py in _call_sample_n(self, sample_shape, seed, name, **kwargs)\r\n    411       # work, it is imperative that this is the last modification to the\r\n    412       # returned result.\r\n--> 413       y = self.bijector.forward(x, **kwargs)\r\n    414       y = self._set_sample_static_shape(y, sample_shape)\r\n    415 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/distributions/bijector_impl.py in forward(self, x, name)\r\n    618       NotImplementedError: if `_forward` is not implemented.\r\n    619     \"\"\"\r\n--> 620     return self._call_forward(x, name)\r\n    621 \r\n    622   def _inverse(self, y):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/distributions/bijector_impl.py in _call_forward(self, x, name, **kwargs)\r\n    599       if mapping.y is not None:\r\n    600         return mapping.y\r\n--> 601       mapping = mapping.merge(y=self._forward(x, **kwargs))\r\n    602       self._cache(mapping)\r\n    603       return mapping.y\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/distributions/python/ops/bijectors/masked_autoregressive.py in _forward(self, x)\r\n    245     y0 = array_ops.zeros_like(x, name=\"y0\")\r\n    246     # call the template once to ensure creation\r\n--> 247     _ = self._shift_and_log_scale_fn(y0)\r\n    248     def _loop_body(index, y0):\r\n    249       \"\"\"While-loop body for autoregression calculation.\"\"\"\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/template.py in __call__(self, *args, **kwargs)\r\n    358           custom_getter=self._custom_getter) as vs:\r\n    359         self._variable_scope = vs\r\n--> 360         result = self._call_func(args, kwargs)\r\n    361         return result\r\n    362 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/template.py in _call_func(self, args, kwargs)\r\n    300       trainable_at_start = len(\r\n    301           ops.get_collection(ops.GraphKeys.TRAINABLE_VARIABLES))\r\n--> 302       result = self._func(*args, **kwargs)\r\n    303 \r\n    304       if self._variables_created:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/distributions/python/ops/bijectors/masked_autoregressive.py in _fn(x)\r\n    478             activation=activation,\r\n    479             *args,\r\n--> 480             **kwargs)\r\n    481       x = masked_dense(\r\n    482           inputs=x,\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/distributions/python/ops/bijectors/masked_autoregressive.py in masked_dense(inputs, units, num_blocks, exclusive, kernel_initializer, reuse, name, *args, **kwargs)\r\n    386         *args,\r\n    387         **kwargs)\r\n--> 388     return layer.apply(inputs)\r\n    389 \r\n    390 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py in apply(self, inputs, *args, **kwargs)\r\n    807       Output tensor(s).\r\n    808     \"\"\"\r\n--> 809     return self.__call__(inputs, *args, **kwargs)\r\n    810 \r\n    811   def _add_inbound_node(self,\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py in __call__(self, inputs, *args, **kwargs)\r\n    671 \r\n    672           # Check input assumptions set before layer building, e.g. input rank.\r\n--> 673           self._assert_input_compatibility(inputs)\r\n    674           if input_list and self._dtype is None:\r\n    675             try:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py in _assert_input_compatibility(self, inputs)\r\n   1195                            ', found ndim=' + str(ndim) +\r\n   1196                            '. Full shape received: ' +\r\n-> 1197                            str(x.get_shape().as_list()))\r\n   1198       # Check dtype.\r\n   1199       if spec.dtype is not None:\r\n\r\nValueError: Input 0 of layer dense_1 is incompatible with the layer: : expected min_ndim=2, found ndim=1. Full shape received: [5]\r\n\r\noriginally defined at:\r\n  File \"<ipython-input-3-646c58f4e818>\", line 10, in <module>\r\n    hidden_layers=[512,512])),\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/distributions/python/ops/bijectors/masked_autoregressive.py\", line 499, in masked_autoregressive_default_template\r\n    \"masked_autoregressive_default_template\", _fn)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/template.py\", line 152, in make_template\r\n    **kwargs)\r\n```\r\nedit: fixed link to TF doc"
  },
  {
    "labels": [null, null, "documentation"],
    "text": "(This issue is with terminology used in documentation and code. System information not applicable.)\r\n\r\nThe documentation and code in tf.contrib.seq2seq.BeamSearchDecoder and friends seems to use \"beam\" to mean \"search state\", whereas beam conventionally means \"a collection of search states\". This non-standard usage makes for confusing documentation!\r\n\r\nExamples in documentation at https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/BeamSearchDecoder:\r\n\r\n\"The BeamSearchDecoder shuffles its beams\" \r\n\"beam_width: Python integer, the number of beams\" \r\n\r\nOr in code:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/838a8f54f92452a15e3bb62a23ad5cd67e86933f/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py#L144\r\n\r\nThe conventional search algorithm terminology as I understand it, and attested by wikipedia (https://en.wikipedia.org/wiki/Beam_search) and recent academic usage (http://www.ijcai.org/Proceedings/05/Papers/0596.pdf), is that beam search is called beam search because it keeps a beam of search states in memory. The beam refers to the collection of search states, not the individual search states (I presume by the analogy that a beam of light illuminates certain objects but not others that fall outside the beam)."
  },
  {
    "labels": ["documentation", null],
    "text": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nWindows 10 Pro 64-bit (10.0, Build 16299)\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary\r\n- **TensorFlow version (use command below)**:\r\nb'unknown' 1.5.0\r\n- **Python version**: \r\n3.6.4\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI get 'UnimplementedError (see above for traceback): Broadcast between <Tensor> and <Tensor> is not supported yet' when trying to broadcast between different kinds of tensors.\r\n\r\nWhat I take from this is that the broadcasting system in tensorflow has limits on how many dimensions that can be broadcasted. After having tried multiple tensor permutations, I have further concluded that  the constraints on broadcasting for tensors is a bit unintuitive. For example:\r\n\r\nThis works:\r\n[1,2,1,1,2,2,2,2]*\r\n[2,2,2,2,1,2,2,2]\r\n\r\nThis doesn't work:\r\n[1,2,1,1,2,2,2,2]*\r\n[2,2,2,2,1,2,2,1]\r\n\r\nThis works:\r\n[2,2,2,2,1]*\r\n[1,2,1,2,2]\r\n\r\nThis doesn't work:\r\n[2,2,2,2,1,2]*\r\n[1,2,1,2,2,2]\r\n\r\nWhat I take from this is that broadcasting works for any permutation when the tensor rank is less than 6. When it is above 6, broadcasting only works when there is a maximum of 2 regions of consecutive 1's (both tensors' 1's taken into consideration). For example:\r\n\r\nThis has two regions of consecutive 1's:\r\n[1,2,1,1,2,2,2,2]*\r\n[2,2,2,2,1,2,2,2]\r\n\r\nThis has three regions of consecutive 1's:\r\n[1,2,1,1,2,2,2,2]*\r\n[2,2,2,2,2,1,2,2]\r\n\r\nAlthough, this rule seems to be wrong when calculating the product below. This doesn't work:\r\n[1,2,1,1,2,1,2,2]*\r\n[2,2,2,2,1,2,2,2]\r\n\r\nMaybe there is also a constraint on each individual tensor that it cannot contain more than two regions of consecutive 1's. An example of this:\r\n\r\nThis works:\r\n[1,2,1,1,2,2,2,2]*\r\n[2,1,2,2,1,2,2,2]\r\n\r\nNevertheless, I hope that I have demonstrated that the underlying constraints for broadcasting are confusing and unintuitive, so could you please show me the current constraints on broadcasting or confirm that above constraints are the only ones? \r\n\r\nConfigurations aside, is it possible to fix the broadcasting system such that it can support any broadcasting configuration? If not, is there at least a way to increase the number of regions of consecutive 1's in the constraints for broadcastability between two tensors? I.e. is there a way to increase the maximum of 2 regions of consecutive 1's to a maximum of e.g. 4 regions?\r\n\r\nI understand that a workaround is to tile the tensors, but I assume that this increases memory usage (by quite a lot when the tensors' ranks are high); something that is very limited in my current program.\r\n\r\n### Source code / logs\r\nAn example of case 1 and 2 above:\r\n\r\n```\r\nimport tensorflow as tf\r\nt1 = tf.random_normal([1,2,1,1,2,2,2,2])\r\nt2 = tf.random_normal([2,2,2,2,1,2,2,2])\r\nt3 = d*e\r\n\r\nt4 = tf.random_normal([1,2,1,1,2,2,2,2])\r\nt5 = tf.random_normal([2,2,2,2,1,2,2,1])\r\nt6 = d*e\r\n\r\nsess = tf.InteractiveSession()\r\nsess.run(t3)\r\nsess.run(t6)\r\n```\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "Hi,\r\nI just found tf.matrix_solve_ls and read its documentation at https://www.tensorflow.org/api_docs/python/tf/matrix_solve_ls :\r\n![grafik](https://user-images.githubusercontent.com/1200058/37315800-cbf13e16-265b-11e8-9ead-727fd6d95c7d.png)\r\nSeems like there are some markdown errors...\r\n\r\nHave I written custom code: No\r\nOS Platform and Distribution: N/A\r\nTensorFlow installed from: N/A\r\nTensorFlow version: N/A\r\nBazel version: N/A\r\nCUDA/cuDNN version: N/A\r\nGPU model and memory: N/A\r\nExact command to reproduce: N/A"
  },
  {
    "labels": ["documentation"],
    "text": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nThere is an small error in the [installation guild](https://www.tensorflow.org/install/install_mac#determine_which_tensorflow_to_install)\r\nwhich is 7th step under the **Installing with Virtualenv** section.\r\n\r\nThe site give an example command of installing TensorFlow in the active Virtualenv for macOS, python which is actually for py3 with pip3 command. \r\n```\r\n $ pip3 install --upgrade \\\r\n https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.6.0-py3-none-any.whl\r\n```\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "Are there any estimated plans for Java api development in terms of functionality ? The only absolute choice for Java language nowadays is Deeplearning4j, any plans to occupy a niche for Java language? \r\nBy the term \"full-fledged\" I mean: constructing a graph from scratch (including most common math function/operations, respectively), train CNN, test CNN, recognize the result, all of this using Java language only.\r\n[#14094](https://github.com/tensorflow/tensorflow/pull/14094) and [#16120](https://github.com/tensorflow/tensorflow/pull/16120) is still in work and latter frozen for a few days. Just want to know your vision of future. \r\n\r\nP.s. need to choose right framework for starting a project at the end of June."
  },
  {
    "labels": ["documentation"],
    "text": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.5\r\n- **Python version**: 3.5.2\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: 9.0\r\n- **GPU model and memory**: NVIDIA Titan X\r\n- **Exact command to reproduce**: Go to https://www.tensorflow.org/versions/r1.5/api_docs/python\r\n\r\n### Describe the problem\r\nThe Python and C++ API Documentation links at https://www.tensorflow.org/versions/r1.5/api_docs/ silently redirect you to documentation for version 1.6. The links are (I assume) correct, but the URLs https://www.tensorflow.org/versions/r1.5/api_docs/python and https://www.tensorflow.org/versions/r1.5/api_docs/cc redirect to https://www.tensorflow.org/api_docs/python/ and https://www.tensorflow.org/api_docs/cc/ respectively.\r\n\r\nI spent a while trying to diagnose a problem based on the documentation for 1.6, without realizing I was looking at 1.6 rather than 1.5. Turns out the problem was caused by an API change between 1.5 and 1.6. \r\n\r\n### Source code / logs\r\nN/A"
  },
  {
    "labels": [null, "documentation"],
    "text": "On tensorflow.org there is a logo with a broken link to https://qualcomm.com/ (ERR_TIMED_OUT)\r\nLooks like it should be https://www.qualcomm.com/\r\n\r\nSorry, if creating an issue was wrong, but I did not find any contact possibilities.\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "On https://www.tensorflow.org/versions, there's a link to \r\nhttps://www.tensorflow.org/versions/r1.6/\r\nThis link is 404"
  },
  {
    "labels": [null, "documentation"],
    "text": "### System information\r\n\r\nJava examples at https://www.tensorflow.org/ for tensorflow 1.6.0.\r\n\r\n### Describe the problem\r\n\r\n`org.tensorflow.Session.Runner.run()` returns list of closables, Javadoc clearly states that the caller is responsible to free all of them. None of the Java examples I found at https://www.tensorflow.org/ highlights that, I realized it by happy accident during in-depth reading implementation in Session.java quite long time after I wrote my code that uses TensorFlow.\r\n\r\n```\r\n    /**\r\n     * Execute the graph fragments necessary to compute all requested fetches.\r\n     *\r\n     * <p><b>WARNING:</b> The caller assumes ownership of all returned {@link Tensor}s, i.e., the\r\n     * caller must call {@link Tensor#close()} on all elements of the returned list to free up\r\n     * resources.\r\n     *\r\n     * ...\r\n     */\r\n    public List<Tensor<?>> run() {\r\n      return runHelper(false).outputs;\r\n    }\r\n```\r\n\r\nI'm not sure if the examples them-self contain any resource leak or not, they free only the first element of the list, but there may be more of them (in general). I would expect an explicit loop properly freeing all the returned resources there.\r\n\r\nSuch examples for beginners should be as explicit as possible, 100% clear and understandable for anyone. A lot of people (like me) base core of their code on them which may easily introduce significant resource leak bugs to their applications.\r\n\r\n- https://www.tensorflow.org/install/install_java, HelloTF example\r\n- https://www.tensorflow.org/install/install_java, referenced advanced example LabelImage\r\n- https://github.com/tensorflow/tensorflow/blob/r1.6/tensorflow/java/src/main/java/org/tensorflow/examples/LabelImage.java\r\n\r\n### Source code / logs\r\n\r\nNone.\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "The documentation for tf.train.Saver (https://www.tensorflow.org/api_docs/python/tf/train/Saver) is not explaining how to actually use the saver. The crucial missing part:\r\n* `saver = tf.train.Saver()` needs to be executed right before finalizing the graph"
  },
  {
    "labels": ["documentation"],
    "text": "I think that one of the main features of TensorFlow is its portability. I want to exploit it in a huge code written in C, where a small but computational heavy part can be computed using GPU through TF. So I started to study the problem about saving a graph, loading it to another code (possibly in another programming language) and passing it data to perform some computations.\r\n\r\nI'm finding very difficult to understand the documentation. I try to point the main problems:\r\n1- there is no C API documentation despite it is the only \"other language\" which satisfies the stability promises, there is only a link to the `c_api.h` file in the repo that I find very difficult to understand;\r\n2- it is very unclear how one can save a graph which can be restored and loaded in another code written in C (or maybe C++), and I don't find where is explained how one can run the graph in the other code passing data to it. Indeed, people had to write many tutorials, or ask many questions on StackOverflow which are unfortunately very outdated (e.g. [here](https://medium.com/jim-fleming/loading-a-tensorflow-graph-with-the-c-api-4caaff88463f) and [here](https://stackoverflow.com/questions/38947658/tensorflow-saving-into-loading-a-graph-from-a-file));\r\n3- as far as I can see there are many ways to do save/restoring but it is unclear when you should use one of these way or another. E.g. `saver.save` -> `saver.restore`; `tf.train.write_graph` -> `tf.import_graph_def` or C analogue `TF_GraphImportGraphDef`; `tf.saved_model.builder.SavedModelBuilder` -> `saved_model.loader.load` or C analogue `LoadSavedModel`.\r\n\r\nThe more I explore the documentation about this topic, the more questions arises, but I hope to have explained enough the issues I'm facing studying it. Shortly, I could say simply that we need a schematic and coherent page which can summarize the procedures about saving, loading, running graph at least from-to any languages which satisfy the stability promises, maybe with links to the specific standard methods and explanation about which of these ones could be used in a certain situation and why.\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "After searching for and eventually posting a question on StackOverflow (https://stackoverflow.com/questions/49007742/tensorflow-examples-and-tutorials-missing-from-the-pip-package) I was recommended to report this as a bug:\r\n\r\nWhen installing Tensorflow (e.g. tensorflow-1.5.0-cp36-cp36m-manylinux1_x86_64.whl from https://pypi.python.org/pypi/tensorflow/1.5.0) from pip, there is only the tutorials/mnist example in tensorflow/examples. It would be nice to have the examples available without having to get them separately from GitHub. Is there a reason why the rest of the examples are not included? Can they be included in future releases?"
  },
  {
    "labels": [null, "documentation"],
    "text": "There is no official documentation on how to use tf metrics in tf.keras. \r\nTwo stackoverflow reference but I don't know if it is a API stable solution: \r\nhttps://stackoverflow.com/questions/45947351/how-to-use-tensorflow-metrics-in-keras\r\nhttps://stackoverflow.com/questions/43158719/how-can-i-use-tensorflow-metric-function-within-keras-models"
  },
  {
    "labels": [null, "documentation"],
    "text": "The windows installation pages specifically asks to use cuDNN 6 - [link](https://www.tensorflow.org/install/install_windows). Then, when running tensorflow it looks specifically for cuDNN7.\r\n\r\n    % (build_info.cudnn_dll_name, build_info.cudnn_version_number))\r\nImportError: Could not find 'cudnn64_7.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Note that installing cuDNN is a separate step from installing CUDA, and this DLL is often found in a different directory from the CUDA DLLs. You may install the necessary DLL by downloading cuDNN 7 from this URL: https://developer.nvidia.com/cudnn\r\n\r\nWould be great if the page modified this to specifically ask for cuDNN 7.\r\n\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "This is a feature request.\r\n\r\nPlease add some example to the docs describing how to use report_tensor_allocations_upon_oom and other options of RunOptions\r\n\r\nAll I could find is this file:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/profiler/model_analyzer_test.py\r\n\r\nBut it is not obvious. For example, it contains:\r\n\r\n    from tensorflow.core.protobuf import config_pb2\r\n\r\nand then\r\n\r\n    with session.Session() as sess:\r\n        sess.run(c, options=config_pb2.RunOptions(\r\n            report_tensor_allocations_upon_oom=True))\r\n\r\nAnd more questions arise like: \"What is config_pb2?\" etc.\r\n\r\nThanks."
  },
  {
    "labels": [null, "documentation"],
    "text": "### System information\r\nN/A\r\n### Describe the problem\r\nRecently I've written some code using Dataset API and I would like to request a problem with documentation (IMO).  Instead of hardcoding comments [here](https://github.com/tensorflow/tensorflow/blob/3ee1721b46d0e61097d0ee72f01e3de9739f0b6f/tensorflow/python/data/ops/iterator_ops.py#L31), please, move @mrry's annotation about `Iterator.get_next()` and `GET_NEXT_CALL_WARNING_THRESHOLD` into `get_next()` method documentation. \r\n\r\nI don't know why I didn't get that beautiful warning on my console output but I think I'm not the first person with funny thread-bomb running and consuming system resources. :) You know about that also (see comment).\r\nSo... It would be great if you could move all critical annotation into main documentation. I'm thinking now about all ML newcomers rather than me (Yeah, I actually found solution by myself :)) \r\nThat's all. \r\n### Source code / logs\r\nN/A"
  },
  {
    "labels": ["documentation"],
    "text": "**Inaccuracies in the documentation**.\r\n\r\nIn the installation documentation Tensorflow in Windows says that the system must be running a version of CUDA 9.0 (correctly) and cuDNN 6.0 (not correct) because on the Nvidia website we can download and install only:\r\n- **cuDNN** v7.0.5 , for **CUDA** 8.0/9.0/9.1 ;\r\n- **cuDNN** v7.0.4 , for **CUDA** 8.0/9.0 ;\r\n- **cuDNN** v6.0 , for **CUDA** 8.0 .\r\n\r\nIn https://developers.googleblog.com/2018/01/announcing-tensorflow-15.html said that \r\n\r\n> If you are using GPU Acceleration on **Windows** or Linux, TensorFlow 1.5 now has CUDA 9 and **cuDNN 7** support built-in. \r\n\r\nIn issue #16477 (https://github.com/tensorflow/tensorflow/issues/16477)  as @gunan  said \r\n> Windows also requires cuDNN 7, looks like we missed that.\r\n\r\nIn proof of his words let me give you output logs:\r\n\r\n(tensorflow15) C:\\Windows\\system32>python\r\nPython 3.5.4 |Anaconda, Inc.| (default, Nov  8 2017, 14:34:30) [MSC v.1900 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n      import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\User\\AppData\\Local\\conda\\conda\\envs\\tensorflow15\\lib\\site-packages\\tensorflow\\python\\platform\\self_check.py\", line 87, in preload_check\r\n    ctypes.WinDLL(build_info.cudnn_dll_name)\r\n  File \"C:\\Users\\User\\AppData\\Local\\conda\\conda\\envs\\tensorflow15\\lib\\ctypes\\__init__.py\", line 351, in __init__\r\n    self._handle = _dlopen(self._name, mode)\r\nOSError: [WinError 126] Не найден указанный модуль (The specified module was not found)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\User\\AppData\\Local\\conda\\conda\\envs\\tensorflow15\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\Users\\User\\AppData\\Local\\conda\\conda\\envs\\tensorflow15\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\User\\AppData\\Local\\conda\\conda\\envs\\tensorflow15\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 30, in <module>\r\n    self_check.preload_check()\r\n  File \"C:\\Users\\User\\AppData\\Local\\conda\\conda\\envs\\tensorflow15\\lib\\site-packages\\tensorflow\\python\\platform\\self_check.py\", line 97, in preload_check\r\n    % (build_info.cudnn_dll_name, build_info.cudnn_version_number))\r\nImportError: Could not find **'cudnn64_7.dll'**. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Note that installing cuDNN is a separate step from installing CUDA, and this DLL is often found in a different directory from the CUDA DLLs. You may install the necessary DLL by downloading **cuDNN 7** from this URL: https://developer.nvidia.com/cudnn\r\n\r\n\r\nIn conclusion.\r\n\r\nNeed to replace:\r\n\r\n> **cuDNN  v6.0**. For details, see NVIDIA's documentation. Note that cuDNN is typically installed in a different location from the other CUDA DLLs. Ensure that you add the directory where you installed the cuDNN DLL to your %PATH% environment variable.\r\n\r\nto\r\n\r\n> **cuDNN v7.0**. For details, see NVIDIA's documentation. Note that cuDNN is typically installed in a different location from the other CUDA DLLs. Ensure that you add the directory where you installed the cuDNN DLL to your %PATH% environment variable.\r\n\r\non the web page https://www.tensorflow.org/install/install_windows\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "The dequeue_many operation returns a **list** of Tensors, while the documentation states that it should be a **tuple** (which is more sensible).\r\n\r\n> Returns:\r\n> The tuple of concatenated tensors that was dequeued.\r\n(https://www.tensorflow.org/api_docs/python/tf/QueueBase)\r\n\r\nVersion: 1.5.0 from PIP, Python3, on OS/X"
  },
  {
    "labels": [null, "documentation"],
    "text": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No, I used the stock version.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **TensorFlow installed from (source or binary)**: pip binary for windows with GPU support\r\n- **TensorFlow version (use command below)**: 1.5.0\r\n- **Python version**: Python 3.6.1 from Anaconda\r\n- **CUDA/cuDNN version**: 9.0/7.0.5\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**: import tensorflow as tf\r\n\r\n### Describe the problem\r\nInstalled CUDA/CUDNN 8.0/6, 9.0/7, 9.1/7\r\nUsed pip to install tensorflow_gpu 1.5.0\r\n\r\nThe installation process finished normally.\r\n\r\nHowever, when import the module by \"import tensorflow as tf\", error messages raises and it says ImportError: Could not find 'cudart64_90.dll'.\r\n\r\nI double checked the CUDA_PATH and PATH environmental variables to make sure that CUDA/CUDNN 9.0/7 are being used. Later I removed the 8.0/6 and 9.1/7, and the problem still exists.\r\n\r\n### Source code / logs\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 30, in <module>\r\n    self_check.preload_check()\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\platform\\self_check.py\", line 82, in preload_check\r\n    % (build_info.cudart_dll_name, build_info.cuda_version_number))\r\nImportError: Could not find 'cudart64_90.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Download and install CUDA 9.0 from this URL: https://developer.nvidia.com/cuda-toolkit\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:binary\r\n- **TensorFlow version (use command below)**:('v1.4.0-rc1-11-g130a514', '1.4.0')\r\n- **Python version**: 2.7.14\r\n\r\n\r\n### Describe the problem\r\nFrom the documentation of `tf.self_adjoint_eig` I cannot see what the order of eigenvalues is. I tried with several examples and found they were sorted in ascending order. Does this always hold?\r\n\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "Go tot the page \r\nhttps://www.tensorflow.org/versions/r0.12/tutorials/syntaxnet/\r\n\r\nand click the \"tutorial\" link. It gets a 404 error.\r\n\r\nThe target of the link is\r\nhttps://github.com/tensorflow/models/tree/master/syntaxnet#installation\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Arch Linux\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.5.0-rc1\r\n- **Python version**: NA (Using Go bindings)\r\n- **Bazel version (if compiling from source)**: 0.9.0\r\n- **GCC/Compiler version (if compiling from source)**: 7.2.1\r\n- **CUDA/cuDNN version**: 9.1 / 7.0\r\n- **GPU model and memory**: GTX 1060 6GB\r\n- **Exact command to reproduce**: See below\r\n\r\n\r\n### Describe the problem\r\nAccording to the docs, AssignAddVariableOp \"Outputs the incremented value, which can be used to totally order the increments to this variable.\". Without this feature, I get non deterministic behavior when reading the value of the variable at the same time as I update it. However, at least in the Go bindings, it returns an operation which has no outputs. I can work around this problem by using two calls to `sess.Run()`, but this is inelegant.\r\n\r\n### Source code / logs\r\n```\r\npackage main\r\n\r\nimport (\r\n\t\"fmt\"\r\n\r\n\ttf \"github.com/tensorflow/tensorflow/tensorflow/go\"\r\n\t\"github.com/tensorflow/tensorflow/tensorflow/go/op\"\r\n)\r\n\r\nfunc main() {\r\n\ts := op.NewScope()\r\n\tvalue1 := op.Const(s.SubScope(\"zero\"), float32(0))\r\n\tvalue2 := op.Const(s, float32(3.1415))\r\n\thandle := op.VarHandleOp(s, tf.Float, tf.ScalarShape())\r\n\tinit := op.AssignVariableOp(s, handle, value1)\r\n\tupdate := op.AssignAddVariableOp(s, handle, value2)\r\n\tfmt.Println(\"NumOutputs:\", update.NumOutputs())\r\n\tgraph, err := s.Finalize()\r\n\tif err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\tsess, err := tf.NewSession(graph, nil)\r\n\tif err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\t_, err = sess.Run(nil, nil, []*tf.Operation{init})\r\n\tif err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\t_, err = sess.Run(nil, []tf.Output{update.Output(0)}, nil)\r\n\tif err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n}\r\n```\r\n```\r\n$ go run assign_demo.go \r\nNumOutputs: 0\r\npanic: Tried to fetch data for 'AssignAddVariableOp:0', which produces no output.  To run to a node but not fetch any data, pass 'AssignAddVariableOp:0' as an argument to the 'target_node_names' argument of the Session::Run API.\r\n\r\ngoroutine 1 [running]:\r\nmain.main()\r\n\t/home/isaac/go/src/github.com/is8ac/gotf/assign_demo.go:32 +0x448\r\nexit status 2\r\n```"
  },
  {
    "labels": [null, "documentation"],
    "text": "The RELEASE.md states that \"Prebuilt binaries are now built against CUDA 9 and cuDNN 7.\"\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/15604 says that CUDA 9.1 is not supported.\r\n\r\nCould we change the RELEASE.md so that it says \"Prebuilt binaries are now built against CUDA 9.0 and cuDNN 7.\" until later versions are supported?\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "### System information\r\n- Windows 10 x64\r\n- Installed from binary\r\n- TensorFlow 1.3.0\r\n- Python 3.6.3\r\n- CuDNN 6.4.6, CUDA 8.0\r\n- NVIDIA GeForce 940M\r\n\r\n### Bug Description\r\n\r\nIssue [15403](https://github.com/tensorflow/tensorflow/issues/15403) was closed since it was labelled as \"not a bug or feature request\". I believe it is indeed a bug. \r\n\r\nThe fundamental problem is that gradients do not seem to be working inside of `tf.while_loop`s. Here is a demonstration of code run inside and outside of a while loop. The code outside of the loop produces a result, whereas the gradient inside of the loop returns None: \r\n```\r\nimport tensorflow as tf\r\n\r\ni = tf.constant(0)\r\nx = tf.constant(3.0)\r\nprint(\"External gradient:\", tf.gradients(x, x)[0])     # Prints Tensor(\"gradients/Fill:0\", shape=(), dtype=float32)\r\n\r\ndef loop_body(i, x, y):\r\n    print(\"internal gradient:\", tf.gradients(x, y)[0]) # Prints None\r\n    return i + 1, x, y\r\n\r\ntf.while_loop( lambda i,x,y: tf.less(i, 5), loop_body, [i, x, x]);\r\n```"
  },
  {
    "labels": ["documentation"],
    "text": "I believe that the documentation for tf.while_loop is lacking usage clarity, and actually provides contradictory statements. \r\n\r\nSpecifically, it seems that many people are using the tf.while_loop as a \"for loop\" ([see stackoverflow](https://stackoverflow.com/questions/35330117/how-can-i-run-a-loop-with-a-tensor-as-its-range-in-tensorflow)). However, the [tf.while_loop](https://www.tensorflow.org/versions/r0.12/api_docs/python/control_flow_ops/control_flow_operations#while_loop) docs state:\r\n\r\n> For correct programs, while_loop should return the same result for any parallel_iterations > 0.\r\n\r\nA loop counter inside of the \"while loop\" body, seems to violate this constraint despite the fact that this is given as an example usage in the docs:\r\n\r\n> python i = tf.constant(0) c = lambda i: tf.less(i, 10) b = lambda i: tf.add(i, 1) r = tf.while_loop(c, b, [i])\r\n\r\nSo it seems that there are two bad outcomes here:\r\n\r\n1. If this is indeed the canonical way of creating a \"for loop\", then the example explicitly creates a dependency between iterations, meaning that the \"while loop\" iterations cannot be run in parallel. \r\n\r\n1. The example is incorrect? \r\n\r\nIt seems like the while_loop docs should have an example which better illustrates how to use it as a \"for loop\", if such usage is indeed intended, or a warning on the implications of the provided example.  \r\n"
  },
  {
    "labels": ["documentation"],
    "text": "### Documentation Issue\r\nIt seems `losses.softmax_cross_entropy()` works just fine with any tensor rank/shape (as long as the last dimension is classes) and not just shapes of `[batch_size, num_classes]` as the documentation indicates. (The documentation also indicates weights should be rank 0 or 1; also not true)\r\n\r\nIf this is the expected behavior, fixing the documentation would help people avoid doing unnecessary reshapes."
  },
  {
    "labels": [null, "documentation"],
    "text": "It would be cool if the documentation of TF operations would contain graphical examples.\r\n\r\nE.g. the \"tf.dynamic_partition\" operation contains such a visualization:\r\n![image](https://user-images.githubusercontent.com/1200058/35163918-880ec02e-fd48-11e7-944f-7d3aac7cadc5.png)\r\n\r\nThis would be especially helpful to understand the different slicing/joining operations."
  },
  {
    "labels": ["documentation"],
    "text": "### System information\r\nN/A\r\n\r\n### Describe the problem\r\nThe method/class templates in documentation should include a full, functioning path to the method instead of just truncating to the method's name.\r\n\r\nI.e. this is what we have at present (bad): \r\n<img width=\"399\" alt=\"screen shot 2018-01-16 at 2 23 08 pm\" src=\"https://user-images.githubusercontent.com/9597721/35007940-0511d55c-fac9-11e7-9d0c-4be2db021533.png\">\r\n\r\nThis is a more practical and copy/paste-friendly version:\r\n<img width=\"426\" alt=\"screen shot 2018-01-16 at 2 22 49 pm\" src=\"https://user-images.githubusercontent.com/9597721/35007976-2970cdc2-fac9-11e7-80b8-0ec1e2334734.png\">\r\n\r\nI'm constantly just grabbing method templates, pasting to my text editor and then coming back to docs to copy/paste the package path which is now the header of the page; which is an awful workflow.\r\n\r\n### Source code / logs\r\nN/A"
  },
  {
    "labels": [null, "documentation"],
    "text": "### Describe the problem\r\n\r\nThe documentation for tf.contrib.rnn.GridLSTMCell cites the paper \"Grid Long Short-Term Memory\", by Kalchbrenner et al.\r\nThe paper describes an architecture, called the 2D Grid LSTM, to replace a stack of LSTM cells. In a 2D Grid LSTM, 2 state components are passed from one layer to the next vertically.\r\n\r\nIn Tensorflow RNN parlance, one would expect both the state and the output of the cell to be an LSTMStateTuple, which would allow seamless integration with a MultiRNNCell.\r\nIn the current implementation, instead it appears that the vertical unrolling is done internally to the GridLSTMCell.\r\nI say it appears, because I can't quite make sense of the arguments and their documentation: specifically, there is a required \"num_frequency_block\" argument whose meaning is quite obscure.\r\nLooking at the implementation also did not help me understand what value is actually expected in that parameter, and the related parameters.\r\nNote that the above mentioned paper does not talk about frequencies anywhere.\r\n\r\nWould it be possible to expand on the documentation for the cell, as well as provide a code example on how to replicate the 2D Grid LSTM from the paper?\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "### System information\r\n\r\nNot necessary.\r\n\r\n### Describe the problem\r\n\r\nThe documentation for `placeholder` does not explain the case when its shape is `()`, `[]` or `[None]`.\r\n\r\n### Possible solution\r\n\r\nAdd the explanations in [this SO  answer](https://stackoverflow.com/a/46941087/3924118) to the documentation of `placeholder`, including the example !!\r\n\r\n  "
  },
  {
    "labels": [null, "documentation"],
    "text": "### System information\r\n\r\nNot necessary in this case.\r\n\r\n### Describe the problem\r\n\r\nNo documentation for the `ConfigProto` class in the TF website. Specifically, in neither of the following pages\r\n\r\n- https://www.tensorflow.org/api_docs/python/tf/ConfigProto\r\n- https://www.tensorflow.org/versions/r1.5/api_docs/python/tf/ConfigProto\r\n- https://www.tensorflow.org/versions/master/api_docs/python/tf/ConfigProto\r\n  \r\n### Possible solutions\r\n\r\nThe following article https://www.tensorflow.org/tutorials/using_gpu contains info about `ConfigProto`. Either the docs for `ConfigProto` can be written based on that info or, at least, a link to that article should be added to the `ConfigProto` docs."
  },
  {
    "labels": [null, "documentation"],
    "text": "OS Platform and Distribution : CentOS\r\nTensorFlow installed from : Sources\r\nTensorFlow version : 1.4\r\nBazel version : N/A\r\nCUDA/cuDNN version 8.0 (CUDA) and 6.0 (CuDNN)\r\nGPU model and memory : N/A\r\nExact command to reproduce : N/A\r\n\r\nThe `.meta` file from TensorFlow contains device information. Although I can use `clear_devices=False` to prevent device information getting logged, I beg to ask the relevance of the `.meta` file with respect to portability.\r\n\r\n 1. If I have the code for the generation of the TensorFlow graph, then I do not need the `.meta` file as per [this answer][1]. \r\n\r\n 2. What is the applicability of transferring only the `.meta` file to someone ? \r\n\r\n 3. Assuming that I train the graph with 4 GPUs, and then provide `.meta` file to someone with 8 or possibly only 1 GPU. For someone with 8 GPUs, would this not prevent him/her from actually running the graph for training/inference over 8 GPUs ? In the case of someone with only 1 GPU, what would happen to entities with device numbers 1-3 ?\r\n\r\n 4. And finally, what are the implications of point 3, when `clear_devices=True` ? \r\n\r\n  [1]: https://stackoverflow.com/a/36203288/8530591\r\n  "
  },
  {
    "labels": ["documentation"],
    "text": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Win10\r\n- **TensorFlow installed from (source or binary)**:source\r\n- **TensorFlow version (use command below)**:1.4\r\n- **Python version**: 3.52\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:8.0,6.46\r\n- **GPU model and memory**:2GB\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nI used the tf.data.Dataset.from_sparse_tensor_slices to built a dataset. But the website has no enought information.\r\nHere's my code\r\n`    point_cloud_feature_dataset = tf.data.Dataset.from_sparse_tensor_slices(sparse_feature)\r\n    point_cloud_feature_dataset = point_cloud_feature_dataset.shuffle(buffer_size = 100000)\r\n    point_cloud_feature_dataset = point_cloud_feature_dataset.batch(batch_size = BATCH_SIZE)\r\n    point_cloud_feature_dataset = point_cloud_feature_dataset.repeat()\r\n    iterator_feature = point_cloud_feature_dataset.make_one_shot_iterator()`\r\n\r\nwhen I called the iterator_feature.get_nest(). It return 3 Tensors of shape [none,none,1]. Instead of a SparseTensor.  The input Sparse Tensor of dataset has a shape of [1000000,300000]. Each row is a example. I hope talents can replenish the Doc. Thanks!!  \r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "The `Dataset` API is now the recommended input pipeline, however I am missing some guidance on how to include summaries of my images.\r\n\r\n```python\r\ndef get_data():\r\n  dataset = FixedLengthRecordDataset(...)\r\n  dataset = dataset.map(parse_dataset, ...)\r\n  if is_training:\r\n    dataset = dataset.map(preprocess_for_train, ...)\r\n  # Do shuffling, batching...\r\n  return dataset\r\n\r\ndef preprocess_for_train(image, label):\r\n  # Do preprocessing...\r\n  image = tf.image.random_flip_left_right(image)\r\n  # Add summary\r\n  tf.summary.image('preprocessed_image', tf.expand_dims(image, 0))\r\n  return image, label\r\n```\r\n\r\nThis is what I would do intuitively, but since `map()` uses a different thread and therefore a different `tf.Graph` instance (?), the summaries are lost.\r\n\r\nWhat is the recommended way of adding image summaries when using the `Dataset` API? I would like to request a comment / example on that in the official docs. "
  },
  {
    "labels": ["documentation"],
    "text": "There are some examples with custom ops that use SetIsStateful() method during registration, e.g. https://www.tensorflow.org/extend/new_data_formats\r\n\r\nBut there is no documentation about that method."
  },
  {
    "labels": [null, "documentation"],
    "text": "This gave me a lot of grief recently as the AWS Region for S3 is controlled by an undocumented constant `S3_REGION` which defaults to `us-east-1` unless defined on the system-level. Extra frustrating as it departs from the common naming practice: `AWS_REGION`:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/79422ab39b5fe0e1491abb8deabc7ecb5fd9f3a2/tensorflow/core/platform/s3/s3_file_system.cc#L52\r\n\r\nIf somebody could suggest where to document this, I'd be happy to contribute. "
  },
  {
    "labels": ["documentation"],
    "text": "https://www.tensorflow.org/programmers_guide/embedding#projections\r\nn the visual for data exploration there are 2 options for distance. One of them should be \"Euclidean\" as against \"Euclidian\""
  },
  {
    "labels": [null, "documentation"],
    "text": "TensorFlow Lite provides a list of currently supported ops [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/tf_ops_compatibility.md) and I wonder if XLA could also have such a list. It's rough to develop and train a model with the full TensorFlow Python API only to get stuck during AOT compilation because of missing ops kernels in the tf2xla bridge."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/README.md"
  },
  {
    "labels": [null, "documentation"],
    "text": "Can someone please explain the flags that can be enabled when compiling TensorFlow from source? I don't seem to understand the functionality of most of them and they are not documented.\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "from https://www.tensorflow.org/mobile/prepare_models\r\nin the section: How do you get a model you can use on mobile?\r\nthe right path is ：\r\n```\r\nbazel build tensorflow/python/tools:freeze_graph\r\n```\r\nnot \r\n```\r\nbazel build tensorflow/tools:freeze_graph\r\n```"
  },
  {
    "labels": ["documentation"],
    "text": "Hi all,\r\n\r\nI use tf-slim [(this network)][1] for my classification problem. I want to do online data augmentation like [Keras ImageDataGenerator][2] for my images. I know [these functions][3] in Tensorflow, but I need a tutorial or an example in Tensorflow or tf-slim that does this online data augmentation. Would you please, help me to find a way to do this?\r\n\r\n\r\n  [1]: https://github.com/pudae/tensorflow-densenet\r\n  [2]: https://keras.io/preprocessing/image/\r\n  [3]: https://www.tensorflow.org/api_guides/python/image"
  },
  {
    "labels": ["documentation"],
    "text": "https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#3\r\n\r\nThere's a link for `Inception V3 model` pointing to https://github.com/tensorflow/models/tree/master/slim#pre-trained-models which 404's.\r\n\r\nI assume it can point to https://arxiv.org/abs/1512.00567 instead.\r\n\r\n<img width=\"375\" alt=\"screen shot 2017-11-11 at 06 37 47\" src=\"https://user-images.githubusercontent.com/287584/32687045-e22af624-c6aa-11e7-9773-a189f761a5ba.png\">\r\n\r\nI would've sent a PR fixing the link, but the codelab text doesn't seem to be available on anywhere Github. 😞 "
  },
  {
    "labels": ["documentation"],
    "text": "After installing Python 3.5.0 using the Windows 64 bit installer (which includes pip in the install):\r\n\r\npip3 install --upgrade tensorflow\r\nCollecting tensorflow\r\n  Could not find a version that satisfies the requirement tensorflow (from versions: )\r\nNo matching distribution found for tensorflow\r\nYou are using pip version 7.1.2, however version 9.0.1 is available.\r\nYou should consider upgrading via the 'python -m pip install --upgrade pip' command.\r\n\r\nI tried on a different machine that worked, and found the only difference to be the pip version.  Updating to pip 9.0.1 solved the issue.\r\n\r\nIt's not explicitly stated anywhere that you need a newer version of pip.  When an old version of something is required to run something, people tend to ignore the messages indicating there is a newer version of it because that's exactly what they are expecting: \"yeah I know there's a newer version, I meant to do this\".\r\n\r\nIf this cannot be resolved for older version of pip (specifically, versions included with the required Python versions), could you please state this in the documentation."
  },
  {
    "labels": ["documentation"],
    "text": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 17.10\r\n- **TensorFlow installed from (source or binary)**: Binary (pip install tensorflow)\r\n- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0\r\n- **Python version**: 3.6.3\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: (see the \"Source code\" section)\r\n\r\n### Describe the problem\r\nI was following the instructions for updating `moving_mean` and `moving_variance` by using the code snippet provided in [batch_normalization documentation](https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization) and it resulted in an \"tensorflow.python.framework.errors_impl.InvalidArgumentError: Retval[0] does not have value\" exception.\r\n\r\n### Source code / logs\r\n\r\nFull instructions to reproduce: \r\n\r\n    git clone -b control-dependencies-exc https://github.com/naktinis/language-id.git ctrl-dep-exc\r\n    cd ctrl-dep-exc/\r\n    python3 -m venv venv\r\n    . venv/bin/activate\r\n    pip install tensorflow==1.4.0 Pillow\r\n    python3 main.py --image-dir test_data/ --label-file test_data/labels.csv --model rnn\r\n\r\nThe specific code change that was enough to produce the exception (seems to match the snippet in the official [documentation](https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization)):\r\nhttps://github.com/naktinis/language-id/commit/50740f\r\n\r\nFull exception:\r\n```\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 173, in <module>\r\n    tf.app.run(main=run_experiment)\r\n  File \"/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"main.py\", line 165, in run_experiment\r\n    hparams=params,\r\n  File \"/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/learn_runner.py\", line 218, in run\r\n    return _execute_schedule(experiment, schedule)\r\n  File \"/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/learn_runner.py\", line 46, in _execute_schedule\r\n    return task()\r\n  File \"/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/experiment.py\", line 625, in train_and_evaluate\r\n    self.train(delay_secs=0)\r\n  File \"/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/experiment.py\", line 367, in train\r\n    hooks=self._train_monitors + extra_hooks)\r\n  File \"/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/experiment.py\", line 807, in _call_train\r\n    hooks=hooks)\r\n  File \"/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 302, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 783, in _train_model\r\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\r\n  File \"/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 521, in run\r\n    run_metadata=run_metadata)\r\n  File \"/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 892, in run\r\n    run_metadata=run_metadata)\r\n  File \"/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 967, in run\r\n    raise six.reraise(*original_exc_info)\r\n  File \"/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/six.py\", line 693, in reraise\r\n    raise value\r\n  File \"/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 952, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 1024, in run\r\n    run_metadata=run_metadata)\r\n  File \"/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 827, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 889, in run\r\n    run_metadata_ptr)\r\n  File \"/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1120, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _do_run\r\n    options, run_metadata)\r\n  File \"/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1336, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Retval[0] does not have value\r\n\r\n```"
  },
  {
    "labels": [null, "documentation"],
    "text": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 14.04\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.4.0\r\n- **Python version**: 3.6.3\r\n- **Bazel version (if compiling from source)**: **4.5**\r\n- **GCC/Compiler version (if compiling from source)**: 4.8\r\n- **CUDA/cuDNN version**: 8/6\r\n- **GPU model and memory**: nvidia\r\n- **Exact command to reproduce**: bazel build --config=opt --config=cuda --verbose_failures //tensorflow/tools/pip_package:build_pip_package\r\n\r\n\r\n### Describe the problem\r\nDocumentation is incorrect: https://www.tensorflow.org/install/install_sources\r\n\r\n\"Tested source configurations\" lists bazel 0.4.5 for tensorflow 1.4.0. Tensorflow 1.4.0 rejects this version of bazel with an error message:\r\n\r\nCurrent Bazel version is 0.4.5, expected at least 0.5.4\r\n\r\n### Source code / logs\r\n```\r\n$ bazel build --config=opt --config=cuda --verbose_failures //tensorflow/tools/pip_package:build_pip_package\r\n ---> Running in 547db5b015bf\r\nWARNING: Config values are not defined in any .rc file: opt\r\nERROR: /tmp/tensorflow/WORKSPACE:41:1: Traceback (most recent call last):\r\nFile \"/tmp/tensorflow/WORKSPACE\", line 41\r\n\t\ttf_workspace()\r\n\tFile \"/tmp/tensorflow/tensorflow/workspace.bzl\", line 146, in tf_workspace\r\n\t\tcheck_version(\"0.5.4\")\r\n\tFile \"/tmp/tensorflow/tensorflow/workspace.bzl\", line 56, in check_version\r\n\t\tfail(\"\r\nCurrent Bazel version is {}, e...))\r\n\r\nCurrent Bazel version is 0.4.5, expected at least 0.5.4\r\n```\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: OS X 10.12.6\r\n- **TensorFlow installed from (source or binary)**: source, latest 1.4 branch\r\n- **TensorFlow version (use command below)**: v1.4.0-rc1-12-gd752244fba 1.4.0\r\n- **Python version**: 3.6.3\r\n- **Bazel version (if compiling from source)**: 0.7.0\r\n- **GCC/Compiler version (if compiling from source)**: Apple LLVM version 9.0.0 (clang-900.0.38)\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**:\r\n\r\nsee below\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\n\r\nThe 1.4 version of the documentation mentions tf.layers.Network in its examples of using the new function based layers (here is a link to the specific doc, https://www.tensorflow.org/api_docs/python/tf/layers/Input), so all you have to do is copy/paste the example code and run it.\r\n\r\n### Source code / logs\r\nthe most basic code to verify is\r\n\r\n```\r\nimport tensorflow as tf\r\nprint(tf.layers.Network)\r\n```\r\n\r\non my system this results in \r\n\r\n```\r\nAttributeError: module 'tensorflow.python.layers.layers' has no attribute 'Network'\r\n```"
  },
  {
    "labels": ["documentation"],
    "text": "Could we have a proper documentation (either in the pod files with a custom header) or in the readme?\r\nIt would help greatly to have the list of available methods and what they do (unless method name is self-explanatory).\r\nHaving to dig into ~20 objective-c files to get a grasp of what is possible in swift is not equivalent to a proper documentation"
  },
  {
    "labels": [null, "documentation"],
    "text": "### System information\r\nnot applicable (regards documentation)\r\n\r\n### Describe the problem\r\nThe docstring of matrix_triangular_solve is not clear, see https://www.tensorflow.org/api_docs/python/tf/matrix_triangular_solve. There are formatting issues, but moreover, it is not immediately clear what the effect of `adjoint=True` is. It would be helpful to describe the effect using linear algebra notation.\r\n\r\n### Source code / logs\r\nnot applicable (regards documentation)"
  },
  {
    "labels": [null, null, "documentation", null],
    "text": "The implementation done in the paper:\r\nhttp://aclweb.org/anthology/P/P16/P16-1100.pdf\r\n\r\nis a hybrid seq2seq model with advancements where the encoder is fed with inputs based on following two cases:\r\n\r\n1.Normal vector representation of a word (Embedding vector) - when the word input is present in the vocabulary\r\n\r\n2.Output of another LSTM network - when the word is **out of vocabulary** and a separate character based LSTM is used to **generate an embedding on the fly**\r\n\r\nConsider the following example sentence:\r\n\"The brown fox jumped over the lazy dog\"\r\n\r\nAssume these are the words present in the vocabulary: _The, brown, jumped, over, dog_ - These words are fed to the seq2seq encoder as such\r\n\r\nout of vocabulary(OOV) words are: _fox, lazy_ - These words are passed to a character LSTM and the output of the same is passed to the seq2seq model along with the above words\r\n\r\nThese both word level and character level encoder needs to be trained end to end simultaneously. \r\n\r\nSince the implementation is a bit different from the normal seq2seq can a tutorial or example of such case be added to the examples section?"
  },
  {
    "labels": ["documentation"],
    "text": "Could the dear developers confirm that tfdbg works with tensorflow GPU version or not?\r\nAt least on my platform it doesn't work.\r\nOS: Red Hat Enterprise Linux Workstation release 7.3 (Maipo)\r\nPython: Python 2.7.5\r\ntensorflow (1.4.0rc0) (compiled from source with CUDA enabled, CUDA 8.0.61, cuDNN8-7.0.1)\r\nnVidia Quadro P5000\r\n\r\nthe code for reproducing the problem is as follows:\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nfrom tensorflow.python import debug as tf_debug\r\n\r\nt = tf.constant(np.ones((10, 16)), tf.float32)\r\n\r\ndef weight_variable(shape):\r\n    initial = tf.truncated_normal(shape, stddev = 0.1)\r\n    return tf.Variable(initial)\r\n\r\ndef bias_variable(shape):\r\n    initial = tf.constant(0., shape = shape)\r\n    return tf.Variable(initial)\r\n\r\nlin1_output_size = 32\r\nlin2_output_size = 1\r\n\r\nwith tf.name_scope(\"lin1\"):\r\n    weight_shape = t.get_shape().as_list()[1:] + [lin1_output_size]\r\n    lin1_output = tf.matmul(t, weight_variable(weight_shape)) + bias_variable([lin1_output_size])\r\n\r\nwith tf.name_scope(\"lin2\"):\r\n    weight_shape = [lin1_output_size, lin2_output_size]\r\n    lin2_output = tf.matmul(lin1_output, weight_variable(weight_shape)) + bias_variable([lin2_output_size])\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n\r\n    sess = tf_debug.LocalCLIDebugWrapperSession(sess)\r\n\r\n    print(sess.run(lin2_output))\r\n\r\n``` \r\n\r\nThe phenomenon is after invoking stepper and steps for several steps, it is reporting segmentation fault and exit.\r\n\r\nI just wonder is it due to GPU issue?"
  },
  {
    "labels": ["documentation"],
    "text": "    def model_fn(features, labels, mode, params):\r\n      \"\"\"Model function for Estimator.\"\"\"\r\n    \r\n      # Connect the first hidden layer to input layer\r\n      # (features[\"x\"]) with relu activation\r\n      first_hidden_layer = tf.layers.dense(features[\"x\"], 10, activation=tf.nn.relu)\r\n    \r\n      # Connect the second hidden layer to first hidden layer with relu\r\n      second_hidden_layer = tf.layers.dense(\r\n          first_hidden_layer, 10, activation=tf.nn.relu)\r\n    \r\n      # Connect the output layer to second hidden layer (no activation fn)\r\n      output_layer = tf.layers.dense(second_hidden_layer, 1)\r\n    \r\n      # Reshape output layer to 1-dim Tensor to return predictions\r\n      predictions = tf.reshape(output_layer, [-1])\r\n    \r\n      # Provide an estimator spec for `ModeKeys.PREDICT`.\r\n      if mode == tf.estimator.ModeKeys.PREDICT:\r\n        return tf.estimator.EstimatorSpec(\r\n            mode=mode,\r\n            predictions={\"ages\": predictions})\r\n    \r\n      # Calculate loss using mean squared error\r\n      loss = tf.losses.mean_squared_error(labels, predictions)\r\n    \r\n      # Calculate root mean squared error as additional eval metric\r\n      eval_metric_ops = {\r\n          \"rmse\": tf.metrics.root_mean_squared_error(\r\n              tf.cast(labels, tf.float64), predictions)\r\n      }\r\n    \r\n      optimizer = tf.train.GradientDescentOptimizer(\r\n          learning_rate=params[\"learning_rate\"])\r\n      train_op = optimizer.minimize(\r\n          loss=loss, global_step=tf.train.get_global_step())\r\n    \r\n      # Provide an estimator spec for `ModeKeys.EVAL` and `ModeKeys.TRAIN` modes.\r\n      return tf.estimator.EstimatorSpec(\r\n          mode=mode,\r\n          loss=loss,\r\n          train_op=train_op,\r\n          eval_metric_ops=eval_metric_ops)\r\n\r\nAbove is an example of the model_fn used by Tensorflow's [Estimator][1].\r\n\r\nAs mentioned in the tutorial, this model_fn could be called in different context (train, predict, evaluate). However, I'm a bit confused, because each time the model_fn is called, **instead of reusing existing graph, it seems to create a new graph.(or create new node in the graph)**\r\n\r\nFor example, firstly I called model_fn under TRAIN mode, then I called model_fn with PREDICT mode. How can I make sure the PREDICT one is reusing the weight of the trained values?\r\n\r\n  [1]: https://www.tensorflow.org/extend/estimators"
  },
  {
    "labels": [null, "documentation"],
    "text": "[tf.reduce_mean](https://www.tensorflow.org/api_docs/python/tf/reduce_mean) emphasized that this function is compatible with numpy:\r\n\r\n> Equivalent to np.mean\r\n\r\nBut it doesn't in the output type. Consider the following code for example:\r\n\r\n```\r\nimport tensorflow as tf\r\nx = tf.Variable([1, 0, 1, 0])\r\ninit = tf.global_variables_initializer()\r\nsess = tf.Session()\r\nsess.run(init)\r\nprint(sess.run(tf.reduce_mean(x)))\r\n\r\n```\r\n\r\nThe output is zero. It seems that tf.reduce_mean infer the output type from the input tensor because casting the input tensor to float values, solve the problem. This attribute is not compatible to np.mean:\r\n\r\n```\r\nimport numpy as np\r\nprint(np.mean([1,0,0,1]))\r\n```\r\n\r\n\r\n### System information\r\n- **OS Platform and Distribution**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: 1.3\r\n- **Python version**: 3.6\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "https://github.com/tensorflow/tensorflow/blob/107cc777af7880c140d089e44ad898a6ba929286/tensorflow/python/ops/nn_ops.py#L1661\r\n\r\nIt should be `If logits are scalars (need to have rank >= 1) or if the rank\r\n      of the labels is not equal to the rank of the logits minus one.`"
  },
  {
    "labels": [null, "documentation"],
    "text": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS X 10.11.6\r\n- **TensorFlow installed from (source or binary)**: conda-forge\r\n- **TensorFlow version (use command below)**: 1.3\r\n- **Python version**:  3.6\r\n- **Bazel version (if compiling from source)**: NA\r\n- **CUDA/cuDNN version**: NA\r\n- **GPU model and memory**: NA\r\n- **Exact command to reproduce**: Copy and paste code sample and run on a Jupter Notebook. The code sample on GitHub works (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/get_started/estimator.md). The code sample on Tensorflow documentation doesn't (https://www.tensorflow.org/get_started/estimator). My guess is that the web documentation requires \"syncing\" with Github version? \r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nThis is regarding (possibly out-dated) web documentation not \"synced\" with the correct GitHub version.\r\n\r\n- The code sample on Tensorflow documentation doesn't run on Python 3.6 / TensorFlow v1.3 (https://www.tensorflow.org/get_started/estimator). \r\n- The code sample on GitHub works (probably more up to date)\r\n (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/get_started/estimator.md). \r\n\r\n### Source code / logs\r\nIf you copy and paste the code sample from web documentation and run on a Jupter notebook, you get:\r\n\r\n```\r\nAttributeError: module 'urllib' has no attribute 'urlopen'\r\n```\r\n\r\n(this has been addressed in GitHub repo sample code. Just not the web doc).\r\n\r\nAlso, the line that reads (for both training and test):\r\n\r\n```.py\r\nwith open(IRIS_TRAINING, \"w\") as f:\r\n```\r\n\r\nshould be corrected to:\r\n\r\n```.[py\r\nwith open(IRIS_TRAINING, \"wb\") as f:\r\n```\r\n\r\n(again, this has been addressed in GitHub repo sample code. Just not the web doc).\r\n\r\nSo possible just need a refresh of the code sample on the web doc?\r\n\r\ni.e. replace the [current web doc](https://www.tensorflow.org/get_started/estimator) with the [GitHub doc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/get_started/estimator.md)?\r\n\r\nThanks!"
  },
  {
    "labels": ["documentation"],
    "text": "This is the tutorial for the Estimator-class:\r\n\r\nhttps://www.tensorflow.org/extend/estimators\r\n\r\nYou have the following code:\r\n\r\n    my_nn = tf.estimator.DNNClassifier(feature_columns=[age, height, weight],\r\n                                       hidden_units=[10, 10, 10],\r\n                                       activation_fn=tf.nn.relu,\r\n                                       dropout=0.2,\r\n                                       n_classes=3,\r\n                                       optimizer=\"Adam\")\r\n\r\nand the following:\r\n\r\n    input_layer = tf.feature_column.input_layer(\r\n        features=features, feature_columns=[age, height, weight])\r\n\r\nIf I understand correctly, the feature-columns use the __variables__ `age`, `height` and `weight`. However, these __variables__ are not defined anywhere in the source-code for the tutorial.\r\n\r\nThe complete source-code is available in `abalone.py` as well:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/examples/tutorials/estimators/abalone.py\r\n\r\nBut here you no longer have the `input_layer` that uses the feature-columns. Instead you have the following which pulls out `\"x\"` from the `features`-dict:\r\n\r\n    # Connect the first hidden layer to input layer\r\n    # (features[\"x\"]) with relu activation\r\n    first_hidden_layer = tf.layers.dense(features[\"x\"], 10, activation=tf.nn.relu)\r\n\r\nSo I'm a bit confused how this is supposed to work?\r\n\r\nIn general, why don't you make the tutorials as Jupyter Notebooks instead? It would be immensely more helpful than your current tutorial style which is very confusing.\r\n\r\nAnd please remember, that for each hour you spend polishing the code, you will likely save several hours of head-aches for each person trying to understand your code. Multiplied by the many thousands of TensorFlow users, this is a tremendous amount of work-hours that is freed up for the community!\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "Hi,\r\n\r\nSomeone take a look at the document page of [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn). I think there are some formatting bugs in the second half of the web page. "
  },
  {
    "labels": ["documentation"],
    "text": "I could not find the documentation for tensorflow::ops::Const starting from the C++ API documentation. I figured out it is declared in ops/const_op.h, but there is no link from the main C++ docs:\r\nhttps://www.tensorflow.org/api_docs/cc/\r\n\r\nA search returns this, but it looks orphaned:\r\nhttps://www.tensorflow.org/api_docs/cc/group/const-op\r\n\r\nSo I guess there is something wrong in the docs."
  },
  {
    "labels": ["documentation"],
    "text": "The latest documentation on tensorflow.org expains that for embedding_lookup* functions ids are obtained typically from FeatureValueTold. The last term is not found anywhere else on the site. Probably some remnant from ancient functions.\r\n\r\nIt should probably be replaced with index_table_from* or something similar.\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "In tf.svd documentation, it was said that the tensorflow implementation of svd is simply np.linalg.svd\r\n\r\nin fact it was not the same, in tensorflow, the index for V matrix is transposed..different from np.linalg.svd default setting. Funny thing is, this type of problem is a famous bug in matlab code people usually write, which is row selection and transpose is not equal to transpose then column selection.\r\n\r\ncode demonstration:\r\n\r\n\r\n```\r\nimport tensorflow as tf\r\ntf.__version__\r\n\r\n## benchmark using numpy svd\r\nimport numpy as np\r\n\r\nx = np.array([1.0,2.0,3.0,4.0,5.0,6,7,8,9])\r\nx = x.reshape(3,3)\r\n\r\nu_,s_,v_=np.linalg.svd(x,compute_uv=True)\r\n# print s_\r\nprint u_\r\nprint v_\r\n\r\nr = 2\r\ndiagS = np.diag(s_)\r\nprint diagS\r\ndiagS = diagS[:r,:r]\r\nx_rank1 = np.matmul(u_[:,:r], np.matmul(diagS, v_[:r,:]))\r\n\r\nprint 'original = \\n',x\r\nprint 'rank1 approximation\\n',x_rank1\r\n```\r\nResult is\r\n```\r\n[[-0.21483724  0.88723069  0.40824829]\r\n [-0.52058739  0.24964395 -0.81649658]\r\n [-0.82633754 -0.38794278  0.40824829]]\r\n[[-0.47967118 -0.57236779 -0.66506441]\r\n [-0.77669099 -0.07568647  0.62531805]\r\n [-0.40824829  0.81649658 -0.40824829]]\r\n[[  1.68481034e+01   0.00000000e+00   0.00000000e+00]\r\n [  0.00000000e+00   1.06836951e+00   0.00000000e+00]\r\n [  0.00000000e+00   0.00000000e+00   4.41842475e-16]]\r\noriginal = \r\n[[ 1.  2.  3.]\r\n [ 4.  5.  6.]\r\n [ 7.  8.  9.]]\r\nrank1 approximation\r\n[[ 1.  2.  3.]\r\n [ 4.  5.  6.]\r\n [ 7.  8.  9.]]\r\n```\r\n\r\nBut in tensorflow svd\r\n```\r\nX = tf.constant([1.0,2.0,3.0,4.0,5.0,6,7,8,9],shape=[3,3])\r\n\r\nsess = tf.InteractiveSession()\r\n    \r\nprint sess.run(X)\r\n\r\ns,u,v = tf.svd(X)\r\n\r\nprint sess.run(u)\r\nprint sess.run(v)\r\n\r\ndiagS_tf = tf.diag(s)\r\n# print sess.run(diagS_tf)\r\n\r\ntmp_correct =  tf.matmul(diagS_tf[:r,:r], tf.transpose(v[:,:r]))\r\ntmp_wrong = tf.matmul(diagS_tf[:r,:r], v[:r,:])\r\n\r\nprint 'following differs'\r\nprint sess.run(tf.transpose(v[:,:r]))\r\nprint sess.run(v[:r,:])\r\n\r\n# print sess.run(tmp)\r\n\r\nx_rank1_tf_correct= tf.matmul(u[:,:r], tmp_correct)\r\nx_rank1_tf_wrong= tf.matmul(u[:,:r], tmp_wrong)\r\n\r\nprint 'printing rank1 approximation from tensorflow'\r\nprint sess.run(x_rank1_tf_correct)\r\nprint sess.run(x_rank1_tf_wrong)\r\n```\r\n\r\nthe output is \r\n```\r\n[[ 1.  2.  3.]\r\n [ 4.  5.  6.]\r\n [ 7.  8.  9.]]\r\n[[ 0.21483716  0.88723052 -0.40824857]\r\n [ 0.52058721  0.24964423  0.81649649]\r\n [ 0.82633758 -0.38794291 -0.4082481 ]]\r\n[[ 0.47967106 -0.77669096  0.40824836]\r\n [ 0.57236761 -0.07568647 -0.81649655]\r\n [ 0.66506428  0.62531805  0.40824822]]\r\nfollowing differs\r\n[[ 0.47967106  0.57236761  0.66506428]\r\n [-0.77669096 -0.07568647  0.62531805]]\r\n[[ 0.47967106 -0.77669096  0.40824836]\r\n [ 0.57236761 -0.07568647 -0.81649655]]\r\nprinting rank1 approximation from tensorflow\r\n[[ 0.99999887  1.99999869  2.99999857]\r\n [ 3.9999969   4.99999666  5.99999666]\r\n [ 6.99999809  7.99999809  8.99999809]]\r\n[[  2.27875805  -2.88305187   0.7037462 ]\r\n [  4.35980749  -6.83247042   3.36293888]\r\n [  6.44085884 -10.78189278   6.0221343 ]]\r\n\r\n```\r\n\r\n\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "TensorFlow version: 1.3.0\r\n\r\nAccording to the document, I should be able to put a tensor to a StagingArea<sup>[[1]](https://www.tensorflow.org/api_docs/python/tf/contrib/staging/StagingArea#put)</sup>. But the following code does not work:\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib import staging\r\n\r\nstaging.StagingArea(dtypes=[tf.int32]).put(tf.constant(1))\r\n```\r\n\r\nThe output says:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/███████/dataset.py\", line 4, in <module>\r\n    staging.StagingArea(dtypes=[tf.int32]).put(tf.constant(1))\r\n  File \"/███████/site-packages/tensorflow/python/ops/data_flow_ops.py\", line 1671, in put\r\n    vals, _ = self._check_put_dtypes(values, indices)\r\n  File \"/███████/site-packages/tensorflow/python/ops/data_flow_ops.py\", line 1480, in _check_put_dtypes\r\n    raise ValueError(\"Indices must be supplied when inserting a list \"\r\nValueError: Indices must be supplied when inserting a list of tensors\r\n```"
  },
  {
    "labels": [null, "documentation"],
    "text": "== cat /etc/issue ===============================================\r\nLinux EricDesktop 4.4.0-96-generic #119-Ubuntu SMP Tue Sep 12 14:59:54 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"16.04.2 LTS (Xenial Xerus)\"\r\nVERSION_ID=\"16.04\"\r\nVERSION_CODENAME=xenial\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux EricDesktop 4.4.0-96-generic #119-Ubuntu SMP Tue Sep 12 14:59:54 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy (1.13.1)\r\nprotobuf (3.4.0)\r\ntensorflow (1.3.0)\r\ntensorflow-tensorboard (0.1.6)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.3.0\r\ntf.GIT_VERSION = v1.3.0-rc1-2409-g5ee3804\r\ntf.COMPILER_VERSION = v1.3.0-rc1-2409-g5ee3804\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH /usr/local/cuda-8.0/lib64\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nSun Sep 24 14:08:03 2017       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 375.82                 Driver Version: 375.82                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 670     Off  | 0000:03:00.0     N/A |                  N/A |\r\n| 33%   50C    P0    N/A /  N/A |    254MiB /  4031MiB |     N/A      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  GeForce GTX 670     Off  | 0000:04:00.0     N/A |                  N/A |\r\n| 32%   48C    P0    N/A /  N/A |    253MiB /  4036MiB |     N/A      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n|    0                  Not Supported                                         |\r\n|    1                  Not Supported                                         |\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs  ===================================================\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61\r\n\r\n### Describe the problem\r\n\r\n    I have been trying to get a custom op working for many hours, and have finally collected enough information to know that it isn't entirely my fault, and I can help you improve the custom op documentation to save others such effort.  \r\nWalkthrough to see what the problem is:\r\n1) Following the instructions on the documentation page (https://www.tensorflow.org/extend/adding_an_op) I copy the zero_out.cc code\r\n2) Compile with Bazel\r\n3) Test with python.  Everything works, this example behaves exactly as it should.\r\n4) But I want a GPU kernel, so now I try the \"example\" example.\r\nCopy the example.h, example.cc and example.cu.cc files on the documentation page.  Didn't make any changes.\r\n5) Now I hit some problems.  The documentation isn't very clear on how to compile this more complicated op with bazel.  I managed to figure it out, but I would strongly recommend notifying users about the \"gpu_srcs\" argument that can be used inside the BUILD file, since this took me quite a while to discover.\r\n\r\nWorking BUILD file:\r\nload(\"//tensorflow:tensorflow.bzl\", \"tf_custom_op_library\")\r\n\r\ntf_custom_op_library(\r\n    name = \"example.so\",\r\n    srcs = [\"example.cc\", \"example.h\"],\r\n    gpu_srcs = [\"example.cu.cc\", \"example.h\"],\r\n)\r\nWorking Bazel command to invoke the BUILD file:\r\nbazel build --config opt --config=cuda --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" //tensorflow/core/user_ops:example.so\r\n\r\n6) Now it compiles.  But the op does not load properly in python; the module created by tf.load_op_library does not contain the actual op, as you can see by my tests under the source code section.\r\n7) After a long time, I discover the extremely obvious problem: the example code in the documentation does not have any REGISTER_OP macro call.  This is clearly an omission in the documentation.\r\n8) I try copying the REGISTER_OP macro call from the zero_out example, and it doesn't really work since the \"example\" example is more complicated, but python now at least recognizes the op.  I am sure if I were to spend the time to figure out how to correctly call the REGISTER_OP macro in example.cc, the example would work correctly for me.\r\n\r\n    I could make some other recommendations about changing the \"Adding a New Op\" documentation page, though I will refrain for now since I am not sure this is the appropriate place to do so.  I would be happy to take a stab at editing the doc page myself, though since I am very new to github I am concerned that I would end up creating more problems than I would fix, so it might be better to have someone with more experience do it.  I would be happy to help though.\r\n\r\n    One thing I will say though: I would really love it if some TF expert would add a fully fleshed out template op to the user op documentation page with all the bells and whistles, and with clear instructions on exactly how to compile and run it.  It should have both GPU support and a gradient implementation.  And ideally it would be multi-threaded (if the \"example\" example isn't already - its not obvious to me either way).  The template would be provided with everything you need, and would have a clearly labeled code block where the user can add their own code:  \"here is a for loop that iterates over every element in the tensor.  write whatever you want here.\"  If you can make it really easy for users to add their own, high-quality operators, you might be able to cut down on your workload responding to problems with custom ops and with users requesting new ops.  And I think that a template that we can fill in would be enough to do that for many people.\r\n\r\n### Source code / logs\r\n\r\n=========================================== start test.py:\r\nimport tensorflow as tf\r\nzero_out_module = tf.load_op_library('./zero_out.so')\r\nwith tf.Session(''):\r\n  print \"zero_out:\"\r\n  print(zero_out_module.zero_out([[1, 2], [3, 4]]).eval())\r\n\r\nexample_module = tf.load_op_library('./example.so')\r\nwith tf.Session(''):\r\n  print \"example:\"\r\n  try:\r\n    print(example_module.example([[1, 2], [3, 4]]).eval())\r\n  except AttributeError as err:\r\n    print \"Error: \", err\r\n    \r\n  \r\nprint \"Analysis of zero_out_module:\"  \r\nprint zero_out_module.__dict__.keys()\r\nprint zero_out_module.OP_LIST\r\n\r\nprint \"Analysis of example_module:\"\r\nprint example_module.__dict__.keys()\r\nprint example_module.OP_LIST\r\n\r\n====================================== end test.py\r\n\r\nOutput of running test.py\r\neric@EricDesktop:~/tensorflow/tensorflow/core/user_ops$ python test.py2017-09-24 14:14:08.183509: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2017-09-24 14:14:08.183794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Found device 0 with properties: \r\nname: GeForce GTX 670 major: 3 minor: 0 memoryClockRate(GHz): 1.0455\r\npciBusID: 0000:04:00.0\r\ntotalMemory: 3.94GiB freeMemory: 3.66GiB\r\n2017-09-24 14:14:08.208238: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2017-09-24 14:14:08.208514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Found device 1 with properties: \r\nname: GeForce GTX 670 major: 3 minor: 0 memoryClockRate(GHz): 1.0455\r\npciBusID: 0000:03:00.0\r\ntotalMemory: 3.94GiB freeMemory: 3.66GiB\r\n2017-09-24 14:14:08.208964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:980] Device peer to peer matrix\r\n2017-09-24 14:14:08.208988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] DMA: 0 1 \r\n2017-09-24 14:14:08.208994: I tensorflow/core/common_runtime/gpu/gpu_device.cc:996] 0:   Y Y \r\n2017-09-24 14:14:08.209000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:996] 1:   Y Y \r\n2017-09-24 14:14:08.209012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1055] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 670, pci bus id: 0000:04:00.0, compute capability: 3.0)\r\n2017-09-24 14:14:08.209020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1055] Creating TensorFlow device (/device:GPU:1) -> (device: 1, name: GeForce GTX 670, pci bus id: 0000:03:00.0, compute capability: 3.0)\r\nzero_out:\r\n[[1 0]\r\n [0 0]]\r\n2017-09-24 14:14:08.239952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1055] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 670, pci bus id: 0000:04:00.0, compute capability: 3.0)\r\n2017-09-24 14:14:08.239970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1055] Creating TensorFlow device (/device:GPU:1) -> (device: 1, name: GeForce GTX 670, pci bus id: 0000:03:00.0, compute capability: 3.0)\r\nexample:\r\nError:  'module' object has no attribute 'example'\r\nAnalysis of zero_out_module:\r\n['_op_def_pb2', '_op_def_lib', '_op_def_registry', '_ops', '_collections', '_common_shapes', '__builtins__', 'zero_out', '__package__', '_op_def_library', 'OP_LIST', 'LIB_HANDLE', '__name__', '_InitOpDefLibrary', '__doc__']\r\nop {\r\n  name: \"ZeroOut\"\r\n  input_arg {\r\n    name: \"to_zero\"\r\n    type: DT_INT32\r\n  }\r\n  output_arg {\r\n    name: \"zeroed\"\r\n    type: DT_INT32\r\n  }\r\n}\r\n\r\nAnalysis of example_module:\r\n['_op_def_pb2', '_op_def_lib', '_op_def_registry', '_ops', '_collections', '_common_shapes', '__builtins__', '__package__', '_op_def_library', 'OP_LIST', 'LIB_HANDLE', '__name__', '_InitOpDefLibrary', '__doc__']\r\n\r\n\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "Hi, \r\n\r\nI think there might be a possible documentation error in that of `tf.stack`. It's said that the numpy equivalent is `np.asarray`. But `np.asarray([])` will take lists of arbitrary shapes and makes it to a `ndarray` whereas `tf.stack` requires all the dimensions of objects in the list to be same. So the equivalent ideally would be `np.stack`.\r\n\r\nCheers, \r\nRamana"
  },
  {
    "labels": ["documentation"],
    "text": "Examples of broken links include\r\n\r\nhttps://github.com/tensorflow/models/blob/master/object_detection/create_pascal_tf_record.py\r\nhttps://github.com/tensorflow/models/blob/master/object_detection/g3doc/running_pets.md\r\n\r\nThanks!\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits shows the signature\r\n\r\n    softmax_cross_entropy_with_logits(\r\n        _sentinel=None,\r\n        labels=None,\r\n        logits=None,\r\n        dim=-1,\r\n        name=None\r\n    )\r\n\r\nIn Python 3, the syntax for `_sentinel=None` is just `*`, and the signature would be\r\n\r\n    softmax_cross_entropy_with_logits(\r\n        *,\r\n        labels,\r\n        logits,\r\n        dim=-1,\r\n        name=None\r\n    )\r\n\r\nwhere I've additionally removed the false defaults from labels and logits.  This can't be done to the code which has to be 2.7 compatible, but it could be done to the documentation."
  },
  {
    "labels": [null, "documentation"],
    "text": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes (see below)\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.3.0\r\n- **Python version**: 3.5.4\r\n- **Bazel version (if compiling from source)**: -\r\n- **CUDA/cuDNN version**: 8/6\r\n- **GPU model and memory**: GTX 1080, 8GB\r\n- **Exact command to reproduce**: run the script\r\n\r\n### Describe the problem\r\nIt seems that by default `list_files`' behaviour when a pattern contains `*`s is to match files at any depth in the directory tree. This is in contrast, for example, with `glob`'s default behaviour.\r\nI could not find any mention of how `*` is evaluated in [its documentation](https://www.tensorflow.org/api_docs/python/tf/contrib/data/Dataset#list_files) or any examples of its usage in the [pogrammer's guide](https://www.tensorflow.org/programmers_guide/datasets).\r\nCould the documentation be improved specifying how exactly `*`s are handled?\r\n\r\n### Source code / logs\r\nSample dataset structure on filesystem:\r\n\r\n```\r\nDATASET_ROOT\r\n    _should_be_ignored\r\n        class3\r\n            subclass31\r\n                sample.txt\r\n            subclass32\r\n                sample.txt\r\n        class4\r\n            subclass41\r\n                sample.txt\r\n            subclass42\r\n                sample.txt\r\n    class1\r\n        subclass11\r\n            sample.txt\r\n        subclass12\r\n            sample.txt\r\n    class2\r\n        subclass21\r\n            sample.txt\r\n        subclass22\r\n            sample.txt\r\n```\r\n\r\nSmall script to test the behaviour:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport glob\r\n\r\nROOT = 'C:/Users/1/Desktop/test_dataset'\r\nglob_files = glob.glob('{}/*/*/*.txt'.format(ROOT))\r\n\r\ndataset = tf.contrib.data.Dataset.list_files('{}/*/*/*.txt'.format(ROOT))\r\nit = dataset.make_one_shot_iterator()\r\n\r\nfiles_found = []\r\nwith tf.Session() as sess:\r\n  while True:\r\n    try:\r\n      files_found.append(sess.run(it.get_next()))\r\n    except tf.errors.OutOfRangeError:\r\n      break\r\n```\r\n\r\nOutputs:\r\n```\r\nglob_files\r\nOut[16]: \r\n['C:/Users/1/Desktop/test_dataset\\\\class1\\\\subclass11\\\\sample.txt',\r\n 'C:/Users/1/Desktop/test_dataset\\\\class1\\\\subclass12\\\\sample.txt',\r\n 'C:/Users/1/Desktop/test_dataset\\\\class2\\\\subclass21\\\\sample.txt',\r\n 'C:/Users/1/Desktop/test_dataset\\\\class2\\\\subclass22\\\\sample.txt']\r\n\r\nfiles_found\r\nOut[4]: \r\n[b'C:\\\\Users\\\\1\\\\Desktop\\\\test_dataset\\\\class1\\\\subclass11\\\\sample.txt',\r\n b'C:\\\\Users\\\\1\\\\Desktop\\\\test_dataset\\\\class1\\\\subclass12\\\\sample.txt',\r\n b'C:\\\\Users\\\\1\\\\Desktop\\\\test_dataset\\\\class2\\\\subclass21\\\\sample.txt',\r\n b'C:\\\\Users\\\\1\\\\Desktop\\\\test_dataset\\\\class2\\\\subclass22\\\\sample.txt',\r\n b'C:\\\\Users\\\\1\\\\Desktop\\\\test_dataset\\\\_should_be_ignored\\\\class3\\\\subclass31\\\\sample.txt',\r\n b'C:\\\\Users\\\\1\\\\Desktop\\\\test_dataset\\\\_should_be_ignored\\\\class3\\\\subclass32\\\\sample.txt',\r\n b'C:\\\\Users\\\\1\\\\Desktop\\\\test_dataset\\\\_should_be_ignored\\\\class4\\\\subclass41\\\\sample.txt',\r\n b'C:\\\\Users\\\\1\\\\Desktop\\\\test_dataset\\\\_should_be_ignored\\\\class4\\\\subclass42\\\\sample.txt']\r\n```\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "https://www.tensorflow.org/api_docs/python/tf/argmax\r\n\r\n- The documentation does not explain what an \"index\" is. I can imagine a billion definitions of \"index\". Is it the same as the \"index\" in tf.one_hot?\r\n- The documentation does not explain what happens if axis is set to None.\r\n- \"For vectors, use axis = 0.\": Why?\r\n- The documentation should clearly explain how the rank+shape of the returned tensor correlates with the rank+shape of the input tensor.\r\n- The documentation incorrectly indicates that there is a guide if you click \"See the guide\", but it takes you to a function reference/index. A redundant 3 sentence description is not a \"guide\".\r\n\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "In [Performance Guide -> Comparing Compiler Optimizations](https://www.tensorflow.org/performance/performance_guide#comparing_compiler_optimizations), the numbers shared for inference on InceptionV3 and ResNet-50 models are exactly the same.\r\n\r\nI'm assuming this is incorrect?"
  },
  {
    "labels": [null, "documentation"],
    "text": "For successful build on Ubuntu it's required to do much more than stated on the installation instructions!\r\n\r\nMy system:\r\n```\r\nCUDA support: YES\r\nBazel: 0.5.4\r\ngcc (Ubuntu 5.4.1-8ubuntu1) 5.4.1 20170304\r\nLinux Desktop 4.10.0-33-generic #37-Ubuntu SMP Fri Aug 11 10:55:28 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\nCPU i7-7820x (with AVX512 support)\r\n```\r\n\r\nIt's required change the build command:\r\n\r\n`bazel build --config=opt --config=cuda --cxxopt=\"-fabi-version=0\" //tensorflow/tools/pip_package:build_pip_package --verbose_failures`\r\n\r\nAnd it's still not enough :( I still can't make successful build..."
  },
  {
    "labels": ["documentation"],
    "text": "Okay in tutorial its say to make zero mean do r-128/128 but in code its r-128/255\r\nBelow is the code provided in ipython notebook\r\nimage_size = 28  # Pixel width and height.\r\npixel_depth = 255.0  # Number of levels per pixel.\r\n\r\ndef load_letter(folder, min_num_images):\r\n  \"\"\"Load the data for a single letter label.\"\"\"\r\n  image_files = os.listdir(folder)\r\n  dataset = np.ndarray(shape=(len(image_files), image_size, image_size),\r\n                         dtype=np.float32)\r\n  print(folder)\r\n  num_images = 0\r\n  for image in image_files:\r\n    image_file = os.path.join(folder, image)\r\n    try:\r\n      image_data = (ndimage.imread(image_file).astype(float) - \r\n                    pixel_depth / 2) / pixel_depth\r\n      if image_data.shape != (image_size, image_size):\r\n        raise Exception('Unexpected image shape: %s' % str(image_data.shape))\r\n      dataset[num_images, :, :] = image_data\r\n      num_images = num_images + 1\r\n    except IOError as e:\r\n      print('Could not read:', image_file, ':', e, '- it\\'s ok, skipping.')"
  },
  {
    "labels": [null, "documentation"],
    "text": "Hello,\r\n\r\nTanhGrad() documentation says: \"Specifically, `grad = dy * (1 - y*y)`, where `y = tanh(x)`, and `dy`\r\nis the corresponding input gradient.\" https://github.com/tensorflow/tensorflow/blob/bab2db47f60d59d843d661903a8d28227600dd60/tensorflow/core/ops/math_ops.cc#L323 which is correct and looks good.\r\n\r\nBut operation has following declaration of inputs:\r\n  Input(\"x: T\")                                                \r\n  .Input(\"y: T\")                                           \r\nhttps://github.com/tensorflow/tensorflow/blob/bab2db47f60d59d843d661903a8d28227600dd60/tensorflow/core/ops/math_ops.cc#L200\r\n\r\nwhat doesn't correlate with the documentated formula: grad = dy * (1 - y*y).\r\nCould you please rename inputs with respect to documentation like this:\r\n\r\n  Input(\"y: T\")                                                \r\n  .Input(\"dy: T\")   \r\n\r\nThanks."
  },
  {
    "labels": [null, "documentation"],
    "text": "------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Amazon Linux 2017.03\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: release v1.3.0\r\n- **Python version**: 3.6.2\r\n- **Bazel version (if compiling from source)**: 0.5.4\r\n- **CUDA/cuDNN version**: CUDA 7.5/cuDNN 5.1.10\r\n- **GPU model and memory**: Tesla K80\r\n- **Exact command to reproduce**: remove _patch_ command and try to compile\r\n\r\n### Describe the problem\r\nThere's a wrong error message when you try to compile TensorFlow without `patch` command installed. It's not a big deal but could take a couple of hours to figure it out.\r\n\r\n### Source code / logs\r\n`\r\nERROR: /home/ec2-user/workplace/tensorflow/tensorflow/tools/pip_package/BUILD:100:1: no such package '@boringssl//': Traceback (most recent call last):\r\n\tFile \"/home/ec2-user/workplace/tensorflow/tensorflow/workspace.bzl\", line 116\r\n\t\t_apply_patch(repo_ctx, repo_ctx.attr.patch_file)\r\n\tFile \"/home/ec2-user/workplace/tensorflow/tensorflow/workspace.bzl\", line 107, in _apply_patch\r\n\t\t_execute_and_check_ret_code(repo_ctx, cmd)\r\n\tFile \"/home/ec2-user/workplace/tensorflow/tensorflow/workspace.bzl\", line 91, in _execute_and_check_ret_code\r\n\t\tfail(\"Non-zero return code({1}) when ...))\r\nNon-zero return code(256) when executing 'patch -p1 -d /home/ec2-user/.cache/bazel/_bazel_ec2-user/4ee13f1db5bfc278f4537815cf99cd27/external/boringssl -i /home/ec2-user/workplace/tensorflow/third_party/boringssl/add_boringssl_s390x.patch':\r\nStdout:\r\nStderr: java.io.IOException: Cannot run program \"patch\" (in directory \"/home/ec2-user/.cache/bazel/_bazel_ec2-user/4ee13f1db5bfc278f4537815cf99cd27/external/boringssl\"): error=2, No such file or directory and referenced by '//tensorflow/tools/pip_package:licenses'.\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted.\r\n`"
  },
  {
    "labels": ["documentation"],
    "text": "Hello , \r\n\r\n\r\nI have noticed that the method AttentionWrapper.zero_state( batch_size,dtype) does not have any description of its functionality in the  documentation website , below is a reference link : \r\nhttps://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/AttentionWrapper\r\n\r\nI really hope that this gets fixed , I have spent a couple of days trying to debug a code that I have written until I realized that I was misusing the method . \r\n\r\n\r\nthank you "
  },
  {
    "labels": ["documentation"],
    "text": "The SSL certificate for https://tensorflow.org (*not* https://www.tensorflow.org) expired on June 29."
  },
  {
    "labels": [null, "documentation"],
    "text": "On this page:\r\n\r\nhttps://www.tensorflow.org/install/install_linux#installing_with_anaconda\r\n\r\nStep 4 says: \r\n\r\n> where tfBinaryURL is the URL of the TensorFlow Python package. For example, the following command installs the CPU-only version of TensorFlow for Python 2.7:\r\n\r\nHowever, the example command below it actually installs TensorFlow for Python 3.4, not 2.7:\r\n\r\n> pip install --ignore-installed --upgrade \\\r\n>  https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.3.0-cp34-cp34m-linux_x86_64.whl"
  },
  {
    "labels": ["documentation"],
    "text": "Hello,\r\nThe tutorial code on the main website is missing a line that makes it crash when testing.\r\nHere is the page of the tutorial: https://www.tensorflow.org/get_started/get_started\r\nHere is the said code:\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n# Declare list of features, we only have one real-valued feature\r\ndef model(features, labels, mode):\r\n  # Build a linear model and predict values\r\n  W = tf.get_variable(\"W\", [1], dtype=tf.float64)\r\n  b = tf.get_variable(\"b\", [1], dtype=tf.float64)\r\n  y = W*features['x'] + b\r\n  # Loss sub-graph\r\n  loss = tf.reduce_sum(tf.square(y - labels))\r\n  # Training sub-graph\r\n  global_step = tf.train.get_global_step()\r\n  optimizer = tf.train.GradientDescentOptimizer(0.01)\r\n  train = tf.group(optimizer.minimize(loss),\r\n                   tf.assign_add(global_step, 1))\r\n  # ModelFnOps connects subgraphs we built to the\r\n  # appropriate functionality.\r\n  return tf.contrib.learn.ModelFnOps(\r\n      mode=mode, predictions=y,\r\n      loss=loss,\r\n      train_op=train)\r\n\r\nestimator = tf.contrib.learn.Estimator(model_fn=model)\r\n# define our data sets\r\nx_train = np.array([1., 2., 3., 4.])\r\ny_train = np.array([0., -1., -2., -3.])\r\nx_eval = np.array([2., 5., 8., 1.])\r\ny_eval = np.array([-1.01, -4.1, -7, 0.])\r\ninput_fn = tf.contrib.learn.io.numpy_input_fn({\"x\": x_train}, y_train, 4, num_epochs=1000)\r\n\r\n# train\r\nestimator.fit(input_fn=input_fn, steps=1000)\r\n# Here we evaluate how well our model did. \r\ntrain_loss = estimator.evaluate(input_fn=input_fn)\r\neval_loss = estimator.evaluate(input_fn=eval_input_fn)\r\nprint(\"train loss: %r\"% train_loss)\r\nprint(\"eval loss: %r\"% eval_loss)\r\n```\r\n\r\nThe `eval_input_fn` is missing, just add this line:\r\n```\r\neval_input_fn = tf.contrib.learn.io.numpy_input_fn({\"x\": x_eval}, y_eval, 4, num_epochs=1000)\r\n```\r\nafter the `input_fn = tf.contrib.learn.io.numpy_input_fn({\"x\": x_train}, y_train, 4, num_epochs=1000)` line.\r\nHope it'll help someone."
  },
  {
    "labels": [null, "documentation"],
    "text": "OS: Ubuntu 16.04 64bits\r\nAndroid Version: 7.1 (Nougat)\r\nNDK Version: android-ndk-r12b\r\n\r\nHexagon build readme should be revisited after recent code changes.\r\n\r\n\r\nI used same command as given in the readme.md\r\n`\r\ntensorflow/tensorflow/contrib/makefile/build_all_android.sh -x /home/kzos/TFHEXLIBS -t hexagon_graph_execution -s /home/kzos/experiment/tensorflow/tensorflow/contrib/makefile/sub_makefiles/hexagon_graph_execution/Makefile.in\r\n`\r\n\r\nI am getting below error:\r\n'\r\ntensorflow/contrib/makefile/Makefile:46: *** \"hexagon is only supported on Android\".  Stop.\r\n`\r\n\r\n\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "The tf.pow() function has an edge case which causes it to hang with no error message.\r\n\r\nIf you try to evaluate tf.pow(x,y), when x is an integer (and thus the output tensor is also an integer), while y is a negative value, tensorflow hangs trying to cast the fraction as an integer.\r\n\r\nExamples;\r\n\r\nsess.run(tf.pow([5,2],[-2,3]))\r\nsess.run(tf.pow([5],[-2]))\r\nsess.run(tf.pow(5, -2))\r\nsess.run(tf.pow(tf.constant(5), tf.constant(-2)))"
  },
  {
    "labels": ["documentation"],
    "text": "Source page: https://www.tensorflow.org/extend/tool_developers/\r\n\r\nBad link (`graph_run_run2.pbtxt`): https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tensorboard/components/tf_tensorboard/test/data/graph_run_run2.pbtxt"
  },
  {
    "labels": ["documentation"],
    "text": "View[ API DOC](https://www.tensorflow.org/versions/master/api_docs/python/tf/parse_example).\r\n\r\nThe description maybe wrong?\r\n`Each FixedLenFeature df maps to a Tensor of the specified type (or tf.float32 if not specified) and shape (serialized.size(),) + df.shape.`\r\n\r\nBut the example shows:\r\nFor dense results in two serialized Examples:\r\n\r\n```\r\n[\r\n  features {\r\n    feature { key: \"age\" value { int64_list { value: [ 0 ] } } }\r\n    feature { key: \"gender\" value { bytes_list { value: [ \"f\" ] } } }\r\n   },\r\n   features {\r\n    feature { key: \"age\" value { int64_list { value: [] } } }\r\n    feature { key: \"gender\" value { bytes_list { value: [ \"f\" ] } } }\r\n  }\r\n]\r\n```\r\nWe can use arguments:\r\n\r\n```\r\nexample_names: [\"input0\", \"input1\"],\r\nfeatures: {\r\n    \"age\": FixedLenFeature([], dtype=tf.int64, default_value=-1),\r\n    \"gender\": FixedLenFeature([], dtype=tf.string),\r\n}\r\n```\r\nAnd the expected output is:\r\n```\r\n\r\n{\r\n  \"age\": [[0], [-1]],\r\n  \"gender\": [[\"f\"], [\"f\"]],\r\n}\r\n```\r\nThe shape of output is (2, 1) not equal to (2, ) + (), where  (2,) is `(serialized.size(),)` and () is `df.shape`.\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "There is incorrect tfBinaryURL at tensorflow.org.\r\n\r\nIn case of Installing with Anaconda in Linux, the example shows the following command for Python 2.7.\r\n(tensorflow)$ pip install --ignore-installed --upgrade \\\r\n https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.2.1-cp34-cp34m-linux_x86_64.whl\r\nBut this is for Python 3.4 so correct command is below.\r\n(tensorflow)$ pip install --ignore-installed --upgrade \\\r\n https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.2.1-cp27-none-linux_x86_64.whl\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "The docs [here]( https://www.tensorflow.org/versions/r0.12/api_docs/python/image/working_with_bounding_boxes)  for bounding boxes  have an error :\r\nThe paragraph reading \r\n\r\n`For example, if an image is 100 x 200 pixels and the bounding box is [0.1, 0.2, 0.5, 0.9], the bottom-left and upper-right coordinates of the bounding box will be (10, 40) to (50, 180).`\r\n\r\nwould better go something like:\r\n\r\n`For example, if an image is 100 x 200 pixels and the bounding box is [0.1, 0.2, 0.5, 0.9], the upper-left and bottom-right coordinates of the bounding box will be (10, 40) to (50, 180), using a somewhat idiosyncratic (y,x) notation, or (40,10) to (180,50) using the rather more common (x,y) notation for points in a plane.  All this is with 'usual' coordinate axes (origin in the top left corner, increasing x to right and increasing y going down)`"
  },
  {
    "labels": [null, "documentation"],
    "text": "On the tutorial of creating estimators using tf.contrib.learn there doesn't seem to be any mention of how to create your own RunConfig object in order to specify the configurations for an Estimator run. The configuration in particular I wanted to find was on how to write summaries after custom sized steps. I eventually found it in the RunConfig description, but I think it would be worthwhile to mention it in the tutorial.\r\n\r\nLink to the tutorial:\r\nhttps://www.tensorflow.org/extend/estimators\r\n\r\nLink to the RunConfig description:\r\nhttps://www.tensorflow.org/api_docs/python/tf/contrib/learn/RunConfig\r\n\r\nI was wondering if the tutorial could be updated to show how to create your own RunConfig object and use it with the Estimator. \r\n"
  },
  {
    "labels": ["documentation"],
    "text": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **TensorFlow installed from (source or binary)**: 1.3.0rc0\r\n- **Python version**: 3.6\r\n- **CUDA/cuDNN version**: 8/6\r\n- **GPU model and memory**: GTX 1080\r\n- **Exact command to reproduce**:\r\n\r\nThe following sample is taken from [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/programmers_guide/datasets.md) and works in TF 1.2.1 \r\n\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ndef _read_py_function(filename, label):\r\n  return np.zeros((100,100,1)), label\r\n\r\ndef _resize_function(image_decoded, label):\r\n  image_decoded.set_shape([None, None, None])\r\n  image_resized = tf.image.resize_images(image_decoded, [28, 28])\r\n  return image_resized, label\r\n\r\nfilenames = np.array([\"/var/data/image1.jpg\", \"/var/data/image2.jpg\"])\r\nlabels = np.array([0, 37])\r\n\r\ndataset = tf.contrib.data.Dataset.from_tensor_slices((filenames, labels))\r\ndataset = dataset.map(\r\n    lambda filename, label: tf.py_func(\r\n        _read_py_function, [filename, label], [tf.uint8, label.dtype]))\r\ndataset = dataset.map(_resize_function)\r\n```\r\nIn 1.3.0rc0 the following error is produced\r\n\r\n```\r\nCannot convert a list containing a tensor of dtype <dtype: 'int32'> to <dtype: 'uint8'> (Tensor is: <tf.Tensor 'PyFunc:1' shape=<unknown> dtype=int32>)\r\n```\r\n\r\nThis is due to the breaking change mentioned in [release notes](https://github.com/tensorflow/tensorflow/blob/r1.3/RELEASE.md). To fix, one now has to introduce an explicit `tuple()` like so\r\n\r\n```python\r\ndataset = dataset.map(\r\n    lambda filename, label: tuple(tf.py_func(\r\n        _read_py_function, [filename, label], [tf.uint8, label.dtype])))\r\n```\r\nThis should at least be mentioned in the API docs / programmer guide.\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "I would like to propose that we make a separate repository in github for jupyter notebooks.\r\n\r\nI think it should be separate from the main tensorflow github so that people can check it out without having to check out all of tensorflow.\r\n\r\nI've created such a github and will work on it by myself for now but I think eventually there should be something more official or at least maybe what I have can be considered official enough to have pointers to it from the main tensorflow github.\r\n\r\nhttps://github.com/reedkotler/tensorflow-notebooks\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "Any way to contribute to the installation instructions for Windows? I deal with a lot of people having installation instructions on Stack Overflow etc. and there are a couple of things on the Install pages that could do with being corrected, clarified or changed. Happy to do these myself if you'd like. I'll list them below:\r\n\r\n- _\"TensorFlow only supports version 3.5.x of Python on Windows.\"_ is no longer true since 1.2 as 3.6 is supported.\r\n\r\n- The r1.3 version of the install page introduces this new line: _\"TensorFlow will not load if it cannot find cuDNN64_5.dll. To use a different version of cuDNN, you must build from source.\"_ however I thought that 1.3 was built with cuDNN 6. Users may find this conflict confusing because, as I found with #11645, 1.3.0 will NOT load with cuDNN64_5.dll. Shouldn't this change to `cuDNN64_6.dll`?\r\n\r\n- Anaconda Installation slightly misleading? I use anaconda to run our tensorflow environments without a problem. I download via `pip install tensorflow(-gpu)` instead of the unsupported `conda` version and, from a user's point of view, there's no reason for it be unsupported. is there a reason that a pypi installation put in an anaconda environment would act differently enough to virtual env/root install to be unsupported? I also don't see why the installation page can't recommend downloading straight from pypi instead of using the long `storage.googleapis...` url. Especially as 3.6 is now supported.\r\n\r\nHappy to implement these changes if I knew where. Are the markdown files in docs_src linked to the website? If so i'll pop a PR into there.\r\n\r\nCheers"
  },
  {
    "labels": ["documentation"],
    "text": "With the old input pipeline functions, in tf.train.batch() you could specify the \"allow_smaller_final_batch\" parameter, which would allow or disallow a smaller final batch. With the new input pipeline functions in tf.contrib.data, the batch function allows a smaller final batch by default, and (to the best of my knowledge) there is no way to skip this last half-batch to ensure all batch sizes are equal.\r\n\r\nIs there a possibility that a \"allow_smaller_final_batch\" flag could be added to the new batch function?"
  },
  {
    "labels": ["documentation"],
    "text": "In instructions specified at: https://www.tensorflow.org/install/install_linux#ValidateYourInstallation\r\n\r\nit states:\r\n\r\n For example, the following command installs the CPU-only version of TensorFlow for Python 2.7:\r\n\r\n (tensorflow)$ pip install --ignore-installed --upgrade \\\r\n https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.2.1-cp34-cp34m-linux_x86_64.whl\r\n\r\nHowever it is for Python **3.4** (not 2.7)"
  },
  {
    "labels": ["documentation"],
    "text": "I made a small example to illustrate, which makes some synthetic data with unbalanced classes and tries to take balanced samples from it:\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.python.framework import ops\r\nfrom tensorflow.python.framework import dtypes\r\n\r\nbatch_size = 10\r\ndata = ['a']*9990+['b']*10\r\nlabels = [1]*9990+[0]*10\r\ndata_tensor = ops.convert_to_tensor(data, dtype=dtypes.string)\r\nlabel_tensor = ops.convert_to_tensor(labels)\r\ntarget_probs = [0.5,0.5]\r\ndata_batch, label_batch = tf.contrib.training.stratified_sample(\r\n    data_tensor, label_tensor, target_probs, batch_size,\r\n    queue_capacity=2*batch_size)\r\n\r\nwith tf.Session() as sess:\r\n    d,l = sess.run(data_batch,label_batch)\r\nprint('percentage \"a\" = %.3f' % (np.sum(l)/len(l)))\r\n```\r\n\r\nThis gives the error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/jason/code/scrap.py\", line 59, in <module>\r\n    test_stratified_sample()\r\n  File \"/home/jason/code/scrap.py\", line 50, in test_stratified_sample\r\n    label_tensor, target_probs, batch_size, queue_capacity=2*batch_size)\r\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/contrib/training/python/training/sampling_ops.py\", line 191, in stratified_sample\r\n    with ops.name_scope(name, 'stratified_sample', tensors + [labels]):\r\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/math_ops.py\", line 829, in binary_op_wrapper\r\n    y = ops.convert_to_tensor(y, dtype=x.dtype.base_dtype, name=\"y\")\r\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\", line 676, in convert_to_tensor\r\n    as_ref=False)\r\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\", line 741, in internal_convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/constant_op.py\", line 113, in _constant_tensor_conversion_function\r\n    return constant(v, dtype=dtype, name=name)\r\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/constant_op.py\", line 102, in constant\r\n    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))\r\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/tensor_util.py\", line 374, in make_tensor_proto\r\n    _AssertCompatible(values, dtype)\r\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/tensor_util.py\", line 302, in _AssertCompatible\r\n    (dtype.name, repr(mismatch), type(mismatch).__name__))\r\nTypeError: Expected string, got list containing Tensors of type '_Message' instead.\r\n```\r\n\r\nAll the searching I did on this TypeError message returned legitimate bugs, not user errors, so I'm putting this here. For completeness:\r\n`python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` gives ('v1.2.0-0-g12f033d', '1.2.0')"
  },
  {
    "labels": ["documentation"],
    "text": "\r\n### System information\r\n- macOS 10.12.5\r\n- installed from binary\r\n- Tensorflow v1.2.0-1751-g43a819e13 1.2.1\r\n- Python 3.6.1\r\n- Bazel 0.5.2-homebrew\r\n\r\n### Describe the problem\r\nThe custom model section of the [\"Getting Started With TensorFlow\" guide](https://www.tensorflow.org/get_started/get_started) doesn't define \"eval_input_fn\".\r\n\r\nI ran across the error when I copied the code line by line and ran it on my machine. I fixed it by adding the following definition after \"input_fn\" is defined:\r\n\r\n```\r\neval_input_fn = tf.contrib.learn.io.numpy_input_fn({\"x\":x_eval}, y_eval,\r\n                                                   4, num_epochs = 1000);\r\n```\r\n\r\n### Source code / logs\r\nCode in Guide:\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n# Declare list of features, we only have one real-valued feature\r\ndef model(features, labels, mode):\r\n  # Build a linear model and predict values\r\n  W = tf.get_variable(\"W\", [1], dtype=tf.float64)\r\n  b = tf.get_variable(\"b\", [1], dtype=tf.float64)\r\n  y = W*features['x'] + b\r\n  # Loss sub-graph\r\n  loss = tf.reduce_sum(tf.square(y - labels))\r\n  # Training sub-graph\r\n  global_step = tf.train.get_global_step()\r\n  optimizer = tf.train.GradientDescentOptimizer(0.01)\r\n  train = tf.group(optimizer.minimize(loss),\r\n                   tf.assign_add(global_step, 1))\r\n  # ModelFnOps connects subgraphs we built to the\r\n  # appropriate functionality.\r\n  return tf.contrib.learn.ModelFnOps(\r\n      mode=mode, predictions=y,\r\n      loss=loss,\r\n      train_op=train)\r\n\r\nestimator = tf.contrib.learn.Estimator(model_fn=model)\r\n# define our data sets\r\nx_train = np.array([1., 2., 3., 4.])\r\ny_train = np.array([0., -1., -2., -3.])\r\nx_eval = np.array([2., 5., 8., 1.])\r\ny_eval = np.array([-1.01, -4.1, -7, 0.])\r\ninput_fn = tf.contrib.learn.io.numpy_input_fn({\"x\": x_train}, y_train, 4, num_epochs=1000)\r\n\r\n# WHERE I ADDED THE DEFINITION\r\n\r\n# train\r\nestimator.fit(input_fn=input_fn, steps=1000)\r\n# Here we evaluate how well our model did. \r\ntrain_loss = estimator.evaluate(input_fn=input_fn)\r\neval_loss = estimator.evaluate(input_fn=eval_input_fn)\r\nprint(\"train loss: %r\"% train_loss)\r\nprint(\"eval loss: %r\"% eval_loss)\r\n```\r\n\r\nError:\r\n```\r\nTraceback (most recent call last):\r\n  File \"custom_model.py\", line 37, in <module>\r\n    eval_loss = estimator.evaluate(input_fn=eval_input_fn);\r\nNameError: name 'eval_input_fn' is not defined\r\n```"
  },
  {
    "labels": ["documentation"],
    "text": "Hello,\r\n\r\nI would like to submit that there is a programming bug on line 29 of the \"custom model tutorial\" within Getting Started with Tensorflow. \r\n\r\nThe line should read:\r\n\r\ninput_fn = tf.contrib.learn.io.numpy_input_fn({\"x\":x_train}, y_train, batch_size=4, num_epochs=1000)\r\n\r\n\r\n​Best regards.\r\nJeff​"
  },
  {
    "labels": [null, "documentation"],
    "text": "Operating System: macOS Sierra 10.12.3\r\nThe version of virtualenv is 15.1.0 \r\nissue like these:\r\n`admindeMacBook-Air:~ admin$ virtualenv --system-site-packages ~/tensorflow`\r\n`Using base prefix '//anaconda'`\r\n`New python executable in /Users/admin/tensorflow/bin/python`\r\n`dyld: Library not loaded: @loader_path/../lib/libpython3.5m.dylib`\r\n`  Referenced from: /Users/admin/tensorflow/bin/python`\r\n`  Reason: image not found`\r\n`ERROR: The executable /Users/admin/tensorflow/bin/python is not functioning`\r\n`ERROR: It thinks sys.prefix is '/Users/admin' (should be '/Users/admin/tensorflow')`\r\n`ERROR: virtualenv is not compatible with this system or executable`\r\n\r\nI have tried many ways like homebrew, upgrade py, but it does not work at all.\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "python /tensorflow/tensorflow/examples/image_retraining/retrain.py \\\r\n  --bottleneck_dir=bottlenecks \\\r\n  --model_dir=inception \\\r\n  --summaries_dir=training_summaries/long \\\r\n  --output_graph=retrained_graph.pb \\\r\n  --output_labels=retrained_labels.txt \\\r\n  --image_dir=flower_photos\r\n\r\nThe path is wrong for retrain.py with 4000 iterations (default)\r\nProvided the reader is following the article, path should be \r\npython retrain.py \\\r\n  --bottleneck_dir=bottlenecks \\\r\n  --model_dir=inception \\\r\n  --summaries_dir=training_summaries/long \\\r\n  --output_graph=retrained_graph.pb \\\r\n  --output_labels=retrained_labels.txt \\\r\n  --image_dir=flower_photos"
  },
  {
    "labels": ["documentation"],
    "text": "The link (https://www.tensorflow.org/get_started/tensorboard_histograms) to the \"TensorBoard Histogram Dashboard\" documentation is broken (404). If that section is currently in the process of being written perhaps add a dummy page saying so."
  },
  {
    "labels": [null, "documentation"],
    "text": "### System information\r\nNot Applicable\r\n\r\n### Describe the problem\r\n[API](https://www.tensorflow.org/api_docs/python/tf/nn/max_pool) states that ksize has length >= 4, the size of window for each dimension of the input tensor. However, value is a 4-D Tensor so doesn't this mean that ksize should be length == 4? Same for strides.\r\n\r\nDigging into maxpooling_op.cc shows that there's some check that does `==`. Line 212:\r\n\r\n```\r\n    OP_REQUIRES(context, ksize_.size() == 4,\r\n                errors::InvalidArgument(\"Sliding window ksize field must \"\r\n                                        \"specify 4 dimensions\"));\r\n```\r\n\r\n\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes. See below.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: All platforms\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.0\r\n- **Bazel version (if compiling from source)**: 0.4.5\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\ntf.image.resize_bicubic() produces weird artifacts in output image. To reproduce, please save this image as bbf.png, and run the program below:\r\n\r\nhttps://www.dramafever.com/st/news/images/e09901b7-bb86-4acd-94e3-ee93d2e301cc.png\r\n\r\nThis is what tf.image.resize_bicubic() produces:\r\n\r\n![output](https://user-images.githubusercontent.com/19349719/27169091-41a12772-515d-11e7-9e17-6240f4a07634.jpg)\r\n\r\n### Source code / logs\r\n```\r\nimport tensorflow as tf\r\n\r\nwith open('bbf.png', 'rb') as f:\r\n    image_bytes = f.read()\r\n\r\nimage = tf.image.decode_image(image_bytes)\r\nimage = tf.expand_dims(image, 0)\r\n\r\nresized_image = tf.image.resize_bicubic(image, [256, 256])\r\n\r\nresized_image = tf.cast(resized_image, tf.uint8)\r\nresized_image = tf.squeeze(resized_image)\r\nencoded_image = tf.image.encode_jpeg(resized_image)\r\n\r\nwith tf.Session() as sess:\r\n    jpg_image = sess.run(encoded_image)\r\n    with open('output.jpg', 'wb') as f:\r\n        f.write(jpg_image)\r\n```"
  },
  {
    "labels": ["documentation"],
    "text": "### Describe the problem\r\nFile `cifar10_input.py` is referenced in documentation, but is missing on `master`.\r\n\r\nDocumentation piece:\r\nhttps://www.tensorflow.org/programmers_guide/reading_data\r\n\r\nr0.7 version\r\nhttps://github.com/tensorflow/tensorflow/blob/r0.7/tensorflow/models/image/cifar10/cifar10_input.py\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "On the main page of Tensorflow tutorial for CIFAR-10 i.e.\r\n( [https://www.tensorflow.org/tutorials/deep_cnn#model_inputs](url) ), the links in the **[Code Organisation](https://www.tensorflow.org/tutorials/deep_cnn#code_organization)** section are ALL broken. \r\nTo be precise, the on clicking them - **Github** page says '_Page not found_'\r\n\r\nPlease remove this bug ASAP"
  },
  {
    "labels": [null, "documentation"],
    "text": "According to the docstring of `tf.train.Scaffold`, there is a `global_step` attribute with the following description:\r\n\r\n* `global_step`: A tensor containing the global step counter.  Picked\r\n    from and stored into the `GLOBAL_STEP` collection in the graph by default.\r\n\r\n(see https://github.com/tensorflow/tensorflow/blob/f60b6bdcb59f5538f3301207eabc30c10a9b6d46/tensorflow/python/training/monitored_session.py#L84)\r\n\r\nThe problem is that no such attribute actually exists.\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "\r\n### System information\r\n- **Custom code, a minimal reproducible example provided below**:\r\n- **Linux Ubuntu 14.04**:\r\n- **TensorFlow installed from binary using pip**:\r\n- **TensorFlow version 1.0.1 and 1.1.0**:\r\n- **CUDA 8.0/cuDNN 5.1**:\r\n- **GeForce GTX 1080**:\r\n\r\n\r\n### Problem\r\nVariable scopes and sharing works different in versions 1.0.1 and 1.1.0. I try to enter a non-reusing variable scope after executing tf.get_variable_scope().reuse_variables(). This results in different values of tf.get_variable_scope().reuse inside this scope. When using version 1.0.1 it is False while when using 1.1.0 it is True. [The sharing variable guide](https://www.tensorflow.org/versions/r1.0/programmers_guide/variable_scope) states that setting reuse = False inside a reusing scope is not the desired behavior, but the guide is completely the same for both versions. Moreover, no changes in handling variable scopes are mentioned in release notes for version 1.1. \r\n\r\n### Source code / logs\r\n```\r\nimport tensorflow as tf\r\nprint tf.__version__\r\n\r\nwith tf.variable_scope('foo'):\r\n    assert tf.get_variable_scope().reuse == False, tf.get_variable_scope().reuse\r\n    tf.get_variable_scope().reuse_variables()\r\n    assert tf.get_variable_scope().reuse == True, tf.get_variable_scope().reuse\r\n    with tf.variable_scope(tf.get_variable_scope(), reuse=False):\r\n       print tf.get_variable_scope().reuse\r\n```\r\nOutput:\r\n\r\n- Version 1.0.1\r\n```\r\n1.0.1\r\nFalse\r\n```\r\n- Version 1.1.0\r\n```\r\n1.1.0\r\nTrue\r\n```"
  },
  {
    "labels": ["documentation"],
    "text": "Quick feature/docs request. I've noticed a few people on Stack Overflow asking about running Tensorflow on 32-bit machines. I'm aware that some people have had some success as described by @mrry 's post here:\r\n\r\n[S/O: \"TensorFlow on 32-bit Linux?\"](https://stackoverflow.com/a/33635450/7604321)\r\n\r\nOne example of a confused user trying to use Windows: \r\n\r\n[S/O: \"how to install tensorflow for windows 7 32bit system?i installed python 3.5(32 bit) into my system and also installed anaconda 3.4.4(32 bit)\"](https://stackoverflow.com/questions/44449972/how-to-install-tensorflow-for-windows-7-32bit-systemi-installed-python-3-532-b)\r\n\r\nI was wondering whether it was worth putting a little system requirement that reminded users that Tensorflow is only supported on 64 bit machines on the install page? Unless it is not then perhaps some little clarification? Cheers"
  },
  {
    "labels": [null, "documentation"],
    "text": "[RecordInput is in the tf 1.2 code](https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/python/ops/data_flow_ops.py#L1602) but I don't see it in the [tf 1.2 API docs](https://www.tensorflow.org/versions/r1.2/api_docs/python/). Should it be present?\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "\r\nThe key in the TensorBoard UI indicates a \"Reference edge\" as a single-headed arrow:\r\n\r\n[![enter image description here][1]][1]\r\n\r\nwhile the documentation shows these as double-headed arrows:\r\n\r\n[![enter image description here][2]][2]\r\n\r\nMoreover, it appears that the edges indicated as references edges in the UI (according to the key there) are not in fact such edges. For example neither \r\n\r\n    cs = tf.constant([1,2,3], name='const_share')\r\n    vs = tf.Variable([1,2,3], name='var_share')\r\n    tf.add(cs, vs, name='opVS1')\r\n    tf.add(vs, cs, name='opVS2')\r\n\r\n<img src=\"https://i.stack.imgur.com/8z1Bn.png\" height=\"350\">\r\n\r\nnote\r\n\r\n    tf.add([4],[3], name='opA')\r\n\r\n[![enter image description here][3]][3]\r\n\r\nshould include reference edges (should they?). But in both cases the key in the UI says that they do.\r\n\r\n  [1]: https://i.stack.imgur.com/5MhdF.png\r\n  [2]: https://i.stack.imgur.com/fWRZL.png\r\n  [3]: https://i.stack.imgur.com/eZHmm.png"
  },
  {
    "labels": [null, "documentation"],
    "text": "The current DeepDream guide located [here](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/tutorials/deepdream), uses the inception5h model. From what I can tell, it does not appear very straightforward in terms of how to fine tune the model in order to create different DeepDream hallucinations from a custom data set. It also does not appear to be relatively easy to change the model that the guide uses. \r\n\r\nI think that an additional guide which shows individuals how to fine tune a model for the purposes of DeepDream would be useful for those trying to explore the artistic and visual aspects of TensorFlow models. I haven't been able to find any guide for creating custom DeepDream models in Tensorflow, so I am not sure where to start.\r\n\r\n\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "I found that some ops have incorrect \"defined in\" paths in the [`contrib.layers` docs](https://www.tensorflow.org/api_docs/python/tf/contrib/layers).\r\n\r\nExamples: `avg_pool2d, batch_norm, bias_add, conv2d, conv2d_in_plane, conv2d_transpose, dropout, flatten, fully_connected, layer_norm, one_hot_encoding, separable_conv2d, softmax`\r\n\r\nIt always uses [`tensorflow/contrib/framework/python/ops/arg_scope.py`](https://github.com/tensorflow/tensorflow/blob/r1.1/tensorflow/contrib/framework/python/ops/arg_scope.py) which is clearly outright wrong.\r\n\r\nThis seems to be the case for all ops defined in [`tensorflow/contrib/layers/python/layers/layers.py`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/layers.py) which are annotated with `@add_arg_scope`"
  },
  {
    "labels": ["documentation"],
    "text": "According to the [doc](https://www.tensorflow.org/versions/master/api_docs/python/tf/tanh), the `tanh` operation supports floating point inputs as well as fixed point inputs of type qint32. However, in the latest master, a `TypeError` raised when running following code:\r\n```\r\nimport tensorflow as tf\r\nsess = tf.InteractiveSession()\r\nx = tf.constant([1.,2.,3.], dtype=tf.float32)\r\n\r\nfrom tensorflow.python.ops.gen_array_ops import quantize_v2\r\nx_quant = quantize_v2(x, min_range=0., max_range=4., T=tf.qint32)\r\ny_quant = tf.nn.tanh(x_quant[0])\r\n```\r\nThe complete error message is \r\n```\r\nTypeError: Value passed to parameter 'x' has DataType qint32 not in list of allowed values: float16, float32, float64, complex64, complex128\r\n```\r\n\r\nAccording to the backend function `_tanh` in `gen_math_ops.py`:\r\n```\r\ndef _tanh(x, name=None):\r\n  r\"\"\"Computes hyperbolic tangent of `x` element-wise.\r\n\r\n  Args:\r\n    x: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`, `complex64`, `complex128`.\r\n    name: A name for the operation (optional).\r\n```\r\nIt shows that it doesn't support qint32.\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nyes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Ubuntu 14.04\r\n- **TensorFlow installed from (source or binary)**:\r\nBinary\r\n- **TensorFlow version (use command below)**:\r\n1.1\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n8.0/5.1.5\r\n- **GPU model and memory**:\r\nTitan X Pascal\r\n- **Exact command to reproduce**:\r\n```\r\nimport sys\r\nimport tensorflow as tf\r\nfrom tensorflow.python import debug as tf_debug\r\n\r\nbase = tf.ones([10], dtype=tf.float32, name='base')\r\nstacked = tf.stack([base, base], name='stacked')\r\nconcat = tf.concat([[base], [base]], axis=0, name='concat')\r\n\r\nsession = tf.Session()\r\nsession = tf_debug.LocalCLIDebugWrapperSession(session)\r\n\r\nwith session.as_default():\r\n    res = session.run([ stacked, concat])\r\nprint res\r\n```\r\n\r\n### Describe the problem\r\n\r\nWhen using the TensorflowDebugger with stacked/concated, the stacked/concated nodes do not appear in the set of dumped nodes once a run has completed.  In addition nodes that fed into these nodes are not dumped."
  },
  {
    "labels": ["documentation"],
    "text": "There are some codeblocks in C++ documentation , written with github-style fenced markdown, \r\nthat are not rendering as `<code>`.\r\n\r\nEg: https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/depth-to-space\r\n\r\n![screenshot of a page with docs not formatted as code](https://cloud.githubusercontent.com/assets/5127634/26518496/5c312d9e-42e4-11e7-856a-972268bcf757.png)\r\n\r\nIt looks like something is going wrong with the site generation,\r\nthat when translating markdown, it does not pickup these blocks.\r\n\r\nIn the pages I quickly checked it seems to occur in the Summary sections, eg in:\r\n\r\n- https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/depth-to-space\r\n- https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/batch-to-space\r\n- https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/batch-to-space-n-d\r\n\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "it always give error:\"no such target '//:inception/download_and_preprocess_imagenet': target 'inception/download_and_preprocess_imagenet' not declared in package '' defined by /home/hank/tensorflow/BUILD.\"\r\nthe BUILD file is empty."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "I want to be able to run tensorboard in development mode and make some changes.\r\n\r\nfrom the [DEVELOPMENT document:](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tensorboard/DEVELOPMENT.md)\r\n\r\n> bazel run third_party/tensorflow/tensorboard/components/tf_tensorboard:demo\r\n\r\nbut this command seems to be obsolete from the directory structure (there is no target inside /third_party).\r\n\r\nalso seems there is a `.idea` folder committed in the repository. \r\nWould be nice to know how the core team setups their environment.\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "According to this [comment](https://github.com/tensorflow/tensorflow/issues/9934#issuecomment-302817142)  and other related issues currently there is some commands and types that iOS users can't load from `frozen.pb` graph. So we could use any TF API in python but not in iOS. It is hard to guess what python API will not been supported in iOS. So is there any documentation or instructions of how to write solution using python API and what functions and types could be used to make `frozen.pb` graph be fully supported by iOS API?\r\n\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes?\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS Sierra 10.12.3\r\n- **TensorFlow installed from (source or binary)**: binary, via pip\r\n- **TensorFlow version (use command below)**: 1.1.0 (v1.1.0-rc0-61-g1ec6ed5)\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**:\r\n\r\n```python\r\nimport tensorflow as tf\r\ncategorical = tf.contrib.distributions.Categorical(probs = [0.25, 0.5, 0.25])\r\nmultinomial = tf.contrib.distributions.Multinomial(total_count = 1., probs = [0.25, 0.5, 0.25])\r\nmvn = tf.contrib.distributions.MultivariateNormalDiag(loc = [0., 0., 0.], scale_diag= [1., 1., 1.])\r\n\r\n# expected values (points 1 and 2)\r\n\r\n# The docs for Categorical say value should be float or double, but it expects an int\r\ncategorical.log_prob([0, 0, 1]) \r\n# <tf.Tensor 'Categorical_2/log_prob/Neg:0' shape=(3,) dtype=float32>\r\ncategorical.log_prob([0., 0., 1.])\r\n# TypeError: Value passed to parameter 'labels' has DataType float32 not in list of allowed values: int32, int64\r\n\r\n# The docs for Categorical say value should be float or double, which is how it behaves (though this is unlike categorical)\r\nmultinomial.log_prob([0, 0, 1]) \r\n# ValueError: Tensor conversion requested dtype int32 for Tensor with dtype float32: 'Tensor(\"Multinomial_2/log_prob/Log:0\", shape=(3,), dtype=float32)'\r\nmultinomial.log_prob([0., 0., 1.])\r\n# <tf.Tensor 'Multinomial_1/log_prob/sub:0' shape=() dtype=float32>\r\n\r\n# output shape (points 3 and 4)\r\n\r\n# The docs for both say that the output should be:\r\n# \"a Tensor of 'shape sample_shape(x) + self.batch_shape' with values of type self.dtype\"\r\n# though sample_shape doesn't seem to be relevant here, it's an argument to param_shapes() and sample()\r\n\r\n# for Categorical (with int value), the result is a vector, matching the shape of value\r\ncategorical.log_prob([0, 0, 1]) \r\n# <tf.Tensor 'Categorical_2/log_prob/Neg:0' shape=(3,) dtype=float32>\r\n\r\n# for Multinomial (with float value), the result is a scalar\r\nmultinomial.log_prob([0., 0., 1.])\r\n# <tf.Tensor 'Multinomial_1/log_prob/sub:0' shape=() dtype=float32>\r\n\r\n# for Multivariate Normal the result is a scalar\r\nmvn.log_prob([0.1, 0.2, 0.3])\r\n# <tf.Tensor 'MultivariateNormalDiag_2/log_prob/add:0' shape=() dtype=float32>\r\n```\r\n\r\n### Describe the problem\r\nThere are four related issues:\r\n\r\n1. The expected type of `value` for the `log_prob()` method in `tf.contrib.distributions.Categorical` is inconsistent with the documentation.\r\n\r\n2. The expected values for `tf.contrib.distributions.Categorical` and `tf.contrib.distributions.Multinomial` are inconsistent with one another, which is odd as the categorical distribution is a special case of the multinomial, with `total_count  = 1`\r\n\r\n3. The output dimensions for `tf.contrib.distributions.Categorical` and `tf.contrib.distributions.Multinomial` are inconsistent with the documentation\r\n\r\n4. The output dimensions for `tf.contrib.distributions.Categorical` are a vector, which doesn't really make sense for a multivariate distribution, and is inconsistent with `tf.contrib.distributions.Multinomial` and `tf.contrib.distributions.MultivariateNormal*`\r\n\r\nDetails are in the code snippet above\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "### System information\r\n- **Have I used stock example script provided in TensorFlow from https://www.tensorflow.org/get_started/get_started\r\n\r\n- **OS Platform and Distribution : Ubuntu 16.04.2 LTS (GNU/Linux 4.4.0-78-generic x86_64)\r\n- **TensorFlow installed from binary\r\n- **TensorFlow version: ('v1.1.0-rc0-61-g1ec6ed5', '1.1.0')\r\n- **CUDA/cuDNN version**: Not using\r\n- **GPU model and memory**: Not using\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nKicks out an WARNING, \"WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\" when I am running one of the the getting started scripts.\r\n\r\nScript from https://www.tensorflow.org/get_started/get_started\r\n\r\n```import numpy as np\r\nimport tensorflow as tf\r\n# Declare list of features, we only have one real-valued feature\r\ndef model(features, labels, mode):\r\n  # Build a linear model and predict values\r\n  W = tf.get_variable(\"W\", [1], dtype=tf.float64)\r\n  b = tf.get_variable(\"b\", [1], dtype=tf.float64)\r\n  y = W*features['x'] + b\r\n  # Loss sub-graph\r\n  loss = tf.reduce_sum(tf.square(y - labels))\r\n  # Training sub-graph\r\n  global_step = tf.train.get_global_step()\r\n  optimizer = tf.train.GradientDescentOptimizer(0.01)\r\n  train = tf.group(optimizer.minimize(loss),\r\n                   tf.assign_add(global_step, 1))\r\n  # ModelFnOps connects subgraphs we built to the\r\n  # appropriate functionality.\r\n  return tf.contrib.learn.ModelFnOps(\r\n      mode=mode, predictions=y,\r\n      loss=loss,\r\n      train_op=train)\r\n\r\nestimator = tf.contrib.learn.Estimator(model_fn=model)\r\n# define our data set\r\nx = np.array([1., 2., 3., 4.])\r\ny = np.array([0., -1., -2., -3.])\r\ninput_fn = tf.contrib.learn.io.numpy_input_fn({\"x\": x}, y, 4, num_epochs=1000)\r\n\r\n# train\r\nestimator.fit(input_fn=input_fn, steps=1000)\r\n# evaluate our model\r\nprint(estimator.evaluate(input_fn=input_fn, steps=10))\r\n```\r\n\r\nAccording to page it should do this:\r\n\r\n```\r\nWhen run, it produces\r\n\r\n{'loss': 5.9819476e-11, 'global_step': 1000}\r\n\r\n```\r\n\r\nBut what I get is an error and an output that never appears the same...\r\n`WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp5JlIIa\r\n2017-05-19 13:24:03.968664: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-19 13:24:03.968718: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-19 13:24:03.968731: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\nWARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\r\n{'loss': 2.003922e-11, 'global_step': 1000}\r\n`\r\n\r\nNext run:\r\n`\r\nWARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\r\n{'loss': 4.1125374e-11, 'global_step': 1000}\r\n`\r\nNext run:\r\n`\r\nWARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\r\n{'loss': 3.8334693e-11, 'global_step': 1000}\r\n`\r\nI am just learning machine learning and would like to continue on.  Not sure if this is a bug or a documentation error or what."
  },
  {
    "labels": ["documentation"],
    "text": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows/Ubuntu\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: 1.1.0\r\n- **Bazel version (if compiling from source)**: /\r\n- **CUDA/cuDNN version**: 5\r\n- **GPU model and memory**: K40\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\nIs it just me or is there quite a large disconnect between the two versions of Estimator. The tutorial in the docs guides you through the contrib version but I understand that it has also been moved to tf.Estimator? However in the docs it appears that almost all functionality, e.g. canned estimators or .fit() appears to be missing or altered and there is little documentation to explain this new API.\r\n\r\nHave I misunderstood something here? I imagine that we are preferred to use tf.estimator because using the contrib version kicks up all sorts of warning about how it will be deprecated last year! Although the estimator tutorial still uses it and also .fit() which I can't clearly see the replacement for in the new API. Is there going to be any example code or tutorial for the new tf.Estimator API as I feel it desperately needs it. The contrib version was difficult enough to understand that I gave up but want to try again! Thanks\r\n\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "The second link, in the highlights session of the webpage\r\n\r\n[Vector Representations](https://www.tensorflow.org/tutorials/word2vec)\r\n\r\nis broken or outdated.\r\n\r\nThis is the link that's not working (404 from github)\r\n\r\n[https://www.github.com/tensorflow/tensorflow/blob/r1.1/tensorflow_models/tutorials/embedding/word2vec.py](https://www.github.com/tensorflow/tensorflow/blob/r1.1/tensorflow_models/tutorials/embedding/word2vec.py)\r\n\r\n\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "Please go to Stack Overflow for help and support:\r\n\r\nhttp://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.1rc\r\n- **Bazel version (if compiling from source)**: \r\n- **CUDA/cuDNN version**: No CUDA\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\n\r\nI am using tensorflow function tf.nn.separable_conv2d. I want to understand why  channel_multiplier * in_channels > out_channels is not allowed. It was not clear anywhere from the documentation.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "There is a wrong html link in text in the tutorial \"Vector Representations of Words\" at address https://www.tensorflow.org/tutorials/word2vec\r\n\r\nThe text is in the first paragraph after the bullet points in the Highlights section at the top of the page.\r\n\r\nThe link for:\r\n\r\n**tensorflow_models/tutorials/embedding/word2vec.py** \r\nhttps://www.github.com/tensorflow/tensorflow/blob/r1.1/tensorflow_models/tutorials/embedding/word2vec.py\r\n\r\nis wrong, it should point to the following address:\r\n\r\nhttps://github.com/tensorflow/models/blob/master/tutorials/embedding/word2vec.py\r\n\r\nI hope that this is helpful."
  },
  {
    "labels": ["documentation"],
    "text": "https://www.tensorflow.org/versions/ says that 0.12 is most recent stable branch, which is causing new users to install the older version --\r\nhttps://github.com/tensorflow/tensorflow/issues/9590#issuecomment-301211285"
  },
  {
    "labels": [null, "documentation"],
    "text": "Issue #7405 was a bug filed that tf.complex_abs() was removed in 1.0.  At the bottom it says that tf.abs() now does that work, but the docs for tf.abs() only mention float.  I confirmed that tf.abs() does in fact do as the comment on the issue describes (https://github.com/tensorflow/tensorflow/blob/r1.1/tensorflow/python/ops/math_ops.py#L225)\r\n\r\nPlease incorporate the info from https://www.tensorflow.org/versions/r0.11/api_docs/python/math_ops/complex_number_functions#complex_abs \r\n\r\ninto\r\nhttps://www.tensorflow.org/api_docs/python/tf/abs\r\n\r\n... specifically the parts about it computing sqrt(a^2 + b^2) for complex numbers.\r\n"
  },
  {
    "labels": ["documentation"],
    "text": ">>bazel-bin/tensorflow/examples/image_retraining/retrain --image_dir /Training_image\r\nLooking for images in 'non-human'\r\nLooking for images in 'human'\r\nCreating bottleneck at /tmp/bottleneck/non-human/Data__negatives_jpeg_cr_night_512x384_cr_night_512x384_rCR_m26_a10_d2005-04-07_t22-38_wN.jpg.txt\r\n2017-05-09 01:56:48.890091: W tensorflow/core/framework/op_def_util.cc:332] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().\r\nNot a JPEG file: starts with 0x89 0x50\r\nTraceback (most recent call last):\r\n  File \"/bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/examples/image_retraining/retrain.py\", line 1105, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/examples/image_retraining/retrain.py\", line 844, in main\r\n    bottleneck_tensor)\r\n  File \"bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/examples/image_retraining/retrain.py\", line 469, in cache_bottlenecks\r\n    jpeg_data_tensor, bottleneck_tensor)\r\n  File \"bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/examples/image_retraining/retrain.py\", line 417, in get_or_create_bottleneck\r\n    bottleneck_tensor)\r\n  File \"bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/examples/image_retraining/retrain.py\", line 376, in create_bottleneck_file\r\n    raise RuntimeError('Error during processing file %s' % image_path)\r\nRuntimeError: Error during processing file /Training_images/non-human/Data__negatives_jpeg_cr_night_512x384\r\n\r\nHow to fix this?"
  },
  {
    "labels": [null, "documentation"],
    "text": "Is it necessary to add more description for optimizers such as Adagrad, Adadelta, FTRL and so on just as what [Adam](https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer) does? Since these are several quite new optimizers and I think it's better to show users more details about these optimizers so that they can understand why do these optimizers work better than SGD in some situations.\r\n\r\nIf more descriptions are welcomed, I'm glad to make new PRs to do this.\r\n\r\nPlease go to Stack Overflow for help and support:\r\n\r\nhttp://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n"
  },
  {
    "labels": ["documentation"],
    "text": "### System information\r\nn/a\r\n\r\n### Describe the problem\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/gather includes an image, https://www.tensorflow.org/api_docs/images/Gather.png, but this does not exist.  Gather.png doesn't seem to exist anywhere in the TF repository."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "The [instructions](https://www.tensorflow.org/install/install_linux#InstallingAnaconda) say to \r\n1. create a new **empty** environment \r\n2. activate it\r\n3. install tensorflow via pip. \r\n\r\nBut pip is not installed in the new environment, so the third command will call the first pip inside the PATH system variable, that usually is the pip installed in the root conda environment. The ultimate result is that tensorflow is installed in the root environment.\r\n\r\nTo solve this issue, it's sufficient to install pip in the new environment:\r\n`conda create --name tensorflow pip`\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "I am learning about Convolutional Neural Networks from the tutorial:\r\nhttps://www.tensorflow.org/tutorials/deep_cnn\r\n \r\nInside it there is a link for getting the code but it is not working:\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.1/tensorflow_models/tutorials/image/cifar10/\r\n\r\nhow can I get the code?\r\n\r\n\r\n"
  },
  {
    "labels": [null, "documentation"],
    "text": "This is with reference to: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/layers.py#L1850\r\n\r\nThe line says \"if `batch_norm_params` is None\" but there is no batch_norm_params argument included in the function, and it doesn't seem that batch_norm is implemented within the function as an option. Is the batch_norm function included in the regularizer function or has it not been implemented by default within the function?\r\n\r\nThanks for your help."
  },
  {
    "labels": [null, null, "documentation"],
    "text": "On page: \r\n[https://www.tensorflow.org/install/install_mac#the_url_of_the_tensorflow_python_package](https://www.tensorflow.org/install/install_mac#the_url_of_the_tensorflow_python_package)\r\n\r\nThis link is broken:\r\n[https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow_gpu-1.1.0-py3-none-any.whl](https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow_gpu-1.1.0-py3-none-any.whl)"
  }
]
